- en: Introduction to Embedding-Based Recommender Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入式推荐系统介绍
- en: 原文：[https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919](https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919](https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919)
- en: '[Recommendation System](https://medium.com/tag/recommendation-system)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[推荐系统](https://medium.com/tag/recommendation-system)'
- en: Learn to build a simple matrix factorization recommender in TensorFlow
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习在 TensorFlow 中构建一个简单的矩阵分解推荐系统
- en: '[](https://dr-robert-kuebler.medium.com/?source=post_page-----956faceb1919--------------------------------)[![Dr.
    Robert Kübler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page-----956faceb1919--------------------------------)[](https://towardsdatascience.com/?source=post_page-----956faceb1919--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----956faceb1919--------------------------------)
    [Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=post_page-----956faceb1919--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dr-robert-kuebler.medium.com/?source=post_page-----956faceb1919--------------------------------)[![Dr.
    Robert Kübler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page-----956faceb1919--------------------------------)[](https://towardsdatascience.com/?source=post_page-----956faceb1919--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----956faceb1919--------------------------------)
    [Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=post_page-----956faceb1919--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----956faceb1919--------------------------------)
    ·13 min read·Jan 25, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----956faceb1919--------------------------------)
    ·阅读时间 13 分钟·2023年1月25日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ff12d44a9188531303b168fa10bb28cf.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff12d44a9188531303b168fa10bb28cf.png)'
- en: Photo by [Johannes Plenio](https://unsplash.com/es/@jplenio?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Johannes Plenio](https://unsplash.com/es/@jplenio?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'They are everywhere: these sometimes fantastic, sometimes poor, and sometimes
    even funny **recommendations** on major websites like Amazon, Netflix, or Spotify,
    telling you what to buy, watch or listen to next. While **recommender systems**
    are convenient for us users — we get inspired to try new things — **the companies
    especially benefit** from them.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些推荐在像亚马逊、Netflix或Spotify这样的大型网站上随处可见，有时非常出色，有时却很糟糕，甚至有时很搞笑，告诉你下一步买什么、看什么或听什么。虽然**推荐系统**对我们用户来说很方便——我们可以受到启发去尝试新事物——但**公司特别受益**于它们。
- en: 'To understand to which extent, let us take a look at some numbers from the
    paper [**Measuring the Business Value of Recommender Systems**](https://arxiv.org/abs/1908.08328)
    by Dietmar Jannach and Michael Jugovac [1]. From their paper:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解具体程度，我们可以查看Dietmar Jannach和Michael Jugovac在论文中给出的一些数据，[**测量推荐系统的商业价值**](https://arxiv.org/abs/1908.08328)
    [1]。从他们的论文中：
- en: '**Netflix:** “75 % of what people watch is from some sort of recommendation”
    ([this one is even from Medium!](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429))'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Netflix：** “75% 的观看内容来源于某种推荐”（[这个甚至来自 Medium！](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)）'
- en: '**Youtube:** “60 % of the clicks on the home screen are on the recommendations”'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**YouTube：** “60% 的主页点击来自推荐”'
- en: '**Amazon:** “about 35 % of their sales originate from cross-sales (i.e., recommendation)”,
    where *their* means Amazon'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**亚马逊：** “约35%的销售来源于交叉销售（即推荐）”，其中*their*指的是亚马逊'
- en: In this paper [1] you can find more interesting statements about increased CTRs,
    engagement, and sales that you can get from employing recommender systems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇论文 [1] 中，你可以找到更多关于提高点击率、参与度和销售的有趣声明，这些都来源于使用推荐系统。
- en: So, it seems like recommenders are the greatest thing since sliced bread, and
    I also agree that recommenders are one of the best and most interesting things
    that emerged from the field of machine learning. That’s why in this article, I
    want to show you
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，看起来推荐系统就像是面包切片以来最伟大的发明一样，我也同意推荐系统是机器学习领域中出现的最优秀、最有趣的事物之一。这就是为什么在本文中，我想向你展示
- en: how to design an easy *collaborative* recommender (matrix factorization)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何设计一个简单的*协作*推荐系统（矩阵分解）
- en: how to implement it in TensorFlow
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 TensorFlow 中实现它
- en: what the advantages and disadvantages are.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优缺点是什么。
- en: You can find the code on [my Github](https://github.com/Garve/Towards-Data-Science---Notebooks/blob/main/TDS%20-%20Introduction%20to%20Embedding-Based%20Recommender%20Systems.ipynb).
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在 [我的 Github](https://github.com/Garve/Towards-Data-Science---Notebooks/blob/main/TDS%20-%20Introduction%20to%20Embedding-Based%20Recommender%20Systems.ipynb)
    上找到代码。
- en: Before we start, let us grab some data we can play with.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们获取一些可以操作的数据。
- en: Getting the Data
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'If you don’t have it yet, get **tensorflow_datasets** via `pip install tensorflow-datasets`
    . You can download any dataset they offer, but we will stick to a true classic:
    movielens! We take the smallest version of the movielens data consisting of 1,000,000
    rows, so training is faster later.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有，请通过 `pip install tensorflow-datasets` 获取 **tensorflow_datasets**。你可以下载他们提供的任何数据集，但我们将坚持使用真正经典的
    movielens！我们选择 movielens 数据中最小的版本，包含 1,000,000 行，这样后续训练会更快。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`data` is a dictionary containing TensorFlow DataSets, which are great. But
    to keep it simpler, let’s cast it into a pandas dataframe, so everyone is on the
    same page.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`data` 是一个包含 TensorFlow 数据集的字典，这些数据集非常棒。但为了简化，我们将其转换为 pandas 数据框，这样大家就能保持一致。'
- en: '***Note:*** *Usually, you would keep it as a TensorFlow dataset, especially
    if the data gets even larger since pandas is extremely hungry on your RAM. Do
    not try do convert it to a pandas dataframe for the 25,000,000 version of the
    movielens dataset!*'
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***注意：*** *通常，你会将其保留为 TensorFlow 数据集，尤其是当数据量变得更大时，因为 pandas 对 RAM 的需求非常高。不要尝试将
    movielens 数据集的 25,000,000 版本转换为 pandas 数据框！*'
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/42723a437fbc07c68cb766cdd8982721.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42723a437fbc07c68cb766cdd8982721.png)'
- en: Image by the author.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者。
- en: '***⚠️ Warning:*** *Don’t print the entire dataframe since this is a styled
    dataframe that’s configured to display all 1,000,000 rows by default!*'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***⚠️ 警告：*** *不要打印整个数据框，因为这是一个样式化的数据框，默认情况下会显示所有 1,000,000 行！*'
- en: We can see an abundance of data. Each row consists of a
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到大量的数据。每一行包括
- en: user (**user_id**),
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户 (**user_id**)，
- en: a movie (**movie_id**),
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个电影 (**movie_id**)，
- en: the rating that the user gave to the movie (**user_rating**), expressed as an
    integer between 1 and 5 (stars), and
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户对电影的评分 (**user_rating**)，以 1 到 5 的整数（星级）表示，并且
- en: a lot more features about the user and movie.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于用户和电影的更多特征。
- en: '*In this tutorial, let us only use the bare minimum:* ***user_id****,* ***movie_id,***
    *and* ***user_rating*** *since very often this is the only data we have. Having
    more features about users and movies is usually a luxary, so let us directly deal
    with the harder, but broadly applicable case.'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*在本教程中，让我们只使用最基本的：***user_id***、***movie_id*** 和 ***user_rating***，因为这通常是我们唯一拥有的数据。拥有更多关于用户和电影的特征通常是一种奢侈，所以让我们直接处理更难但广泛适用的情况。*'
- en: Recommender trained on this kind of interaction data are called* ***collaborative
    —*** *a model is trained on the interactions of many users to make recommendations
    for a single user.* One for all, all for one!
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于这种交互数据训练的推荐系统称为* ***协同过滤 —*** *一个模型在许多用户的交互数据上进行训练，以便为单个用户提供推荐。* 一人为大家，大家为一人！
- en: 'We will also keep the **timestamp** to conduct a temporal train-test split
    since this resembles how we train in real life: we train now, but we want the
    model to work well tomorrow. So we should evaluate the model quality like this
    as well.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还会保留**时间戳**以进行时间上的训练-测试拆分，因为这类似于我们在现实生活中的训练方式：我们现在训练，但希望模型明天表现良好。所以我们也应该以这种方式评估模型质量。
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`filtered_data` contains'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`filtered_data` 包含'
- en: '![](../Images/1df5a8858010c3f9d946b01758b00d02.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1df5a8858010c3f9d946b01758b00d02.png)'
- en: Image by the author.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者。
- en: Cold Start Problem
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 冷启动问题
- en: If we split the data in any way, we may run into something called the **cold
    start problem**, meaning that some users or movies are only present in the test
    set, but not in the training set. In our case, funnily enough, user 1 is such
    an example.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以任何方式拆分数据，我们可能会遇到所谓的**冷启动问题**，这意味着某些用户或电影只出现在测试集中，而不在训练集中。在我们的例子中，有趣的是，用户
    1 就是这样一个例子。
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It is a bit like a category of a categorical feature that only appears in the
    test set. It makes learning harder, but still, the model has to deal with it somehow.
    The recommender that we will build soon is quite prone to the cold start problem,
    but there are other types of recommenders that can deal with new users or movies
    in a better way. This is something for another article, though.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有点像仅出现在测试集中的分类特征类别。这使得学习更困难，但模型仍然必须以某种方式处理它。我们将要构建的推荐系统很容易受到冷启动问题的影响，但还有其他类型的推荐系统可以更好地处理新用户或电影。这是另一个文章的内容。
- en: Let’s build train and test dataframes and move on.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建训练和测试数据框并继续。
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Embeddings Crash Course
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入速成课程
- en: 'Now that we know what the data looks like, let us define the model **signature**,
    meaning what goes in and what comes out. In our case, it is quite simple: The
    input should be a **user_id** and a **movie_id**, and the output should be the
    **user_rating**, i.e. how the user rates the movie.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道数据的样子了，让我们定义模型的**签名**，即输入和输出是什么。在我们的例子中，这非常简单：输入应该是**user_id**和**movie_id**，输出应该是**user_rating**，即用户对电影的评分。
- en: '![](../Images/9763a829d99b952731e4bd03c81fba56.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9763a829d99b952731e4bd03c81fba56.png)'
- en: Image by the author.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: But what could such a model look like? This is a tough one, especially for data
    science beginners. The **users and movies are categories**, even if we encoded
    them as integers. So, treating them like numbers and merely training a model with
    them is not purposeful.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的模型可能是什么样的呢？这很难，尤其是对于数据科学初学者。**用户和电影是类别**，即使我们将它们编码为整数。因此，将它们视为数字并仅用它们训练模型是不够有意义的。
- en: Something Horrible!
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 糟糕的事情！
- en: 'For the curious readers, I will do it anyway. The following is an example of
    how **not** to do it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于好奇的读者，我还是会做的。以下是一个**不要**这样做的示例：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The *r*² is about 0.07, which is about as good as a regressor that only outputs
    the mean of the ratings, independently of the user and movie inputs. The mean
    absolute error is about 0.85, meaning that we miss the true rating by about 0.85
    stars on average.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*r*²约为 0.07，这和一个仅输出评分均值的回归器差不多，不管用户和电影的输入如何。平均绝对误差约为 0.85，这意味着我们平均错过了真实评分约
    0.85 星。'
- en: Instead of doing it like this, I will show you how to use embeddings to build
    a more meaningful and better model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我将展示如何使用嵌入构建一个更有意义和更好的模型，而不是这样做。
- en: One-Hot Encoding as a Special Case of Embeddings
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一热编码作为嵌入的特例
- en: One way to encode categorical variables such as our users or movies is with
    vectors, i.e. a tuple of numbers — called **embeddings** in this context. This
    is a useful technique to keep in mind, not only for recommender systems but **whenever
    you deal with categorical data**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 编码诸如用户或电影这样的类别变量的一种方式是使用向量，即一组数字——在这个上下文中称为**嵌入**。这是一种有用的技术，不仅仅是推荐系统，**任何涉及类别数据的情况**都可以使用。
- en: '![](../Images/d44666d456372bc6d8e7a40848516e0e.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d44666d456372bc6d8e7a40848516e0e.png)'
- en: Image by the author.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: A very simple example of turning categories into numbers is **one-hot/dummy
    encoding.** However,the resulting embeddings are **high-dimensional** for high-cardinality
    categorical features, leading us right into the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)
    trap when trying to work with them.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将类别转换为数字的一个非常简单的例子是**一热/虚拟编码**。然而，对于高卡特性类别特征，结果嵌入是**高维**的，这使得我们在尝试使用它们时陷入了[维度诅咒](https://en.wikipedia.org/wiki/Curse_of_dimensionality)的陷阱。
- en: Another drawback is that each pair of two vectors have the same distance from
    each other. As an example, if you take a feature with three categories that are
    encoded as [1, 0, 0], [0, 1, 0], and [0, 0, 1], each category has the same distance
    to each other category in common metrics such as Euclidean and other [Mikowski
    distances](https://en.wikipedia.org/wiki/Minkowski_distance), or cosine similarity.
    This might be fine for nominal features, but for **ordinal** features such as
    *hot*, *mild,* or *cold* weather, it would be nicer if *hot* is closer to *mild*
    than *cold*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个缺点是每对两个向量之间的距离是相同的。例如，如果你取一个具有三个类别的特征，编码为 [1, 0, 0]，[0, 1, 0] 和 [0, 0, 1]，每个类别与其他类别在常见的度量标准（如欧几里得和其他
    [闵可夫斯基距离](https://en.wikipedia.org/wiki/Minkowski_distance)）中具有相同的距离。这对于名义特征可能没问题，但对于**序数**特征如*热*、*温暖*或*冷*天气，如果*热*离*温暖*比*冷*更近会更好。
- en: Clearly, this is bad, so we have to think of something different.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这是不好的，因此我们必须考虑其他方案。
- en: The Real Deal
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际情况
- en: '**Embeddings allow us to create shorter vectors with more meaning than one-hot
    encoded vectors.**'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**嵌入允许我们创建比一热编码向量更有意义的更短的向量。**'
- en: 'They are readily available within deep learning frameworks such as TensorFlow
    and PyTorch. On a very high level, they work like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习框架如 TensorFlow 和 PyTorch 中，它们随时可用。总体上，它们的工作方式如下：
- en: You specify an **embedding dimension**, i.e. how long the vector should be.
    This is a hyperparameter that you could tune, among others.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你指定一个**嵌入维度**，即向量的长度。这是一个你可以调整的超参数之一。
- en: The embeddings for each category get initialized randomly, just as any other
    weight in your neural network.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个类别的嵌入被随机初始化，就像神经网络中的其他权重一样。
- en: Training pushes the embeddings to be more useful to the model.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练使嵌入对模型更有用。
- en: This is actually not a conceptionally new operation since you can **simulate**
    it by **first one-hot encoding** the category and **then using a linear (dense)
    layer** without activation function and bias. The embedding layer is just more
    performant since it’s just doing a lookup instead of calculating a matrix product as done in the linear layer.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这并不是一个概念上新的操作，因为你可以通过**首先进行独热编码**类别，**然后使用没有激活函数和偏置的线性（密集）层**来**模拟**它。嵌入层更高效，因为它只是进行查找，而不是像线性层中那样计算矩阵乘积。
- en: '![](../Images/cc22cb4729f899280b6534830b3460a5.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc22cb4729f899280b6534830b3460a5.png)'
- en: Image by the author.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Building the Model
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建模型
- en: So, now that we have all of the ingredients, let’s build a model! First, we
    will define the high-level architecture of the model, and then we will build it
    in TensorFlow, although it is similarly easy in PyTorch if you prefer this.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经具备了所有的要素，让我们来构建一个模型吧！首先，我们将定义模型的高层次架构，然后在 TensorFlow 中构建它，虽然如果你更喜欢 PyTorch，它也同样容易。
- en: Architecture
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构
- en: Alright, so two categorical variables (**user_id** and **movie_id**) enter the
    model, then we embed them. We end up with two vectors, preferably of the same
    length. In the end, we want to end up with a single number, the **user_rating**.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，那么两个分类变量（**user_id** 和 **movie_id**）进入模型，然后我们进行嵌入。我们最终得到两个向量，最好是相同长度的。最后，我们希望得到一个单一的数字，即**user_rating**。
- en: '***Note:*** *We will model it as a regression problem, but you can also see
    it as a classification task.*'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***注意：*** *我们将其建模为回归问题，但你也可以将其视为分类任务。*'
- en: So, how can we make a single number out of two vectors of the same length? There
    are many ways, but one of the easiest and most efficient ones is by just taking
    the **dot product**.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何将两个相同长度的向量合并为一个单一的数字呢？有很多方法，但其中一种最简单且高效的方法是直接计算**点积**。
- en: '![](../Images/a7dbfbaf27676c2a35180020c0a20615.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7dbfbaf27676c2a35180020c0a20615.png)'
- en: Image by the author.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '***Note:*** *The approach that we will be taking in the following is also called*
    ***matrix factorization*** *since we compute dot products all over the place,
    just as if you multiply two matrices.*'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***注意：*** *我们将在接下来的内容中采用的方法也称为* ***矩阵分解*** *，因为我们会在各处计算点积，就像你乘以两个矩阵一样。*'
- en: 'Nothing too crazy, I would argue. Now we are able to look at how the model
    should work:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我会说这并没有什么太疯狂的地方。现在我们可以看看模型应该如何工作：
- en: '![](../Images/525d2726b9eb8d72477491bf01ae5c53.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/525d2726b9eb8d72477491bf01ae5c53.png)'
- en: Image by the author.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'As a formula, we created this:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个公式，我们创建了这个：
- en: '![](../Images/e107de2352c6aa5fc868c96529d954bf.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e107de2352c6aa5fc868c96529d954bf.png)'
- en: Image by the author.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: which reads as **“the rating of movie *m* from user *u* equals embedding of
    user *u* dot product embedding of movie *m*”**.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这表示**“用户 *u* 对电影 *m* 的评分等于用户 *u* 的嵌入与电影 *m* 的嵌入的点积”**。
- en: Implementation in TensorFlow, Version One
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow 实现，第一个版本
- en: 'The implementation is actually a piece of cake if you know basic TensorFlow.
    The only thing to pay attention to is that the embedding layers want the categories
    to be represented as integers from 1 to *number_of_categories*. Very often you
    find people populating some dictionary like {“user_8323”: 1, “user_1122”: 2, …}
    and an inverse dictionary like {1: “user_8323”, 2: “user_1122”, …} to achieve
    this, but TensorFlow has some nice layers to take care of them as well. We will
    use the `[IntegerLookup](https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup)`
    here. A nice feature of this layer: unknown categories get mapped to 0 by default.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你了解基本的 TensorFlow，实现实际上是轻而易举的。唯一需要注意的是，嵌入层希望类别被表示为从 1 到 *number_of_categories*
    的整数。你经常会看到有人填充一些字典，如 {“user_8323”: 1, “user_1122”: 2, …} 以及一个反向字典，如 {1: “user_8323”,
    2: “user_1122”, …} 来实现这一点，但 TensorFlow 也有一些很好的层来处理这些。我们将在这里使用 `[IntegerLookup](https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup)`。这个层的一个好特性是：未知类别默认映射为
    0。'
- en: Before we start, we have to grab all the unique users and movies **from the
    training set** first.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们必须首先从**训练集**中获取所有唯一的用户和电影。
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Using the functional API of Keras, you can implement the above ideas like this:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Keras 的功能 API，你可以这样实现上述想法：
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Since we gave the user and movie input layers nice names, we can train the
    model like this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们给用户和电影输入层起了好名字，我们可以像这样训练模型：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We could evaluate this model on the test set now, but we can already see here
    that it’s probably quite bad because `val_mean_absolute_error` is about 3\. That
    means that we are on average 3 stars off, which is horrible in a 5-star system.
    This is even worse than our bad model from before, which is quite an achievement.
    😅 But why is that? Let’s explore this in the next section.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以在测试集上评估这个模型，但我们已经可以看到，它可能非常糟糕，因为`val_mean_absolute_error`约为3。这意味着我们平均偏差为3星，在5星系统中这是非常糟糕的。这比我们之前的糟糕模型还要差，这是一个了不起的成就。😅
    但这为什么呢？让我们在下一部分深入探讨一下。
- en: Implementation in TensorFlow, Version Two
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow 实现，版本二
- en: 'We have built a regression model that can potentially output any real number
    so far. It is very hard for the model to learn that it should output numbers in
    the special range between 1 to 5 but we can make it easier for the model with
    a simple trick: just squash the output range as we do it for logistic regression.
    Just instead of a [0, 1] interval, let’s scale and shift it to [1, 5].'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经构建了一个回归模型，可以输出任何实数。模型很难学习应该输出在1到5之间的特殊范围的数字，但我们可以用一个简单的技巧来简化这一点：只需像处理逻辑回归一样压缩输出范围。只不过是将[0,
    1]区间缩放和移动到[1, 5]。
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As a formula:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 公式如下：
- en: '![](../Images/b2df904a2383d151cae118d356c93023.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2df904a2383d151cae118d356c93023.png)'
- en: Image by the author.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: where *σ* is the sigmoid function. Training is as above and evaluating it on
    the test set gives us
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *σ* 是 sigmoid 函数。训练如上所述，测试集上的评估结果是
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This is much better than the model before and also our bad baseline. In case
    you want an *r*² score as well:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这比之前的模型和我们糟糕的基准要好得多。如果你还想要一个*r*²得分：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let’s do a small final adjustment to end up with an even better model.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个小的最终调整，以得到一个更好的模型。
- en: Implementation in TensorFlow, Final Version
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow 实现，最终版本
- en: Additionally to the embeddings, we can also associate a **bias term** to each
    movie and user. This captures that some users tend to give only rather positive
    (or negative) ratings, and also that some movies only tend to get positive (or
    negative) reviews. This way, the **biases** can do the **rough work** while the
    **embeddings** do the **fine-tuning**. For example, a user that mostly gives 4
    stars for everything will have some fixed bias, a **single number, and no vector**.
    The embeddings then only have to focus on explaining why this user sometimes gives
    3 or 5 stars.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 除了嵌入，我们还可以为每部电影和每个用户关联一个**偏置项**。这捕捉到一些用户往往只给出相对积极（或消极）的评分，以及一些电影往往只收到积极（或消极）的评论。这样，**偏置项**可以进行**粗略调整**，而**嵌入**则进行**精细调整**。例如，一个通常给4星的用户将有一个固定的偏置，一个**单一数字，而不是向量**。嵌入仅需专注于解释为什么这个用户有时给3星或5星。
- en: The formula then becomes
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 公式变为
- en: '![](../Images/75abd763d3245efbe4dc491f8eafc77b.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75abd763d3245efbe4dc491f8eafc77b.png)'
- en: Image by the author.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'where *bᵤ* and *bₘ* are the biases of user *u* and movie *m* respectively.
    As code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *bᵤ* 和 *bₘ* 分别是用户 *u* 和电影 *m* 的偏置项。作为代码：
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If you like the `plot_model` output of Keras:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢 Keras 的`plot_model`输出：
- en: '![](../Images/b175aebb262f0e3808e06a4612b3af5c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b175aebb262f0e3808e06a4612b3af5c.png)'
- en: Image by the author.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '![](../Images/84b0b3e30c35ade68fc1704bc7f4560a.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/84b0b3e30c35ade68fc1704bc7f4560a.png)'
- en: Image by the author, created with [https://netron.app/](https://netron.app/).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供，创建于[https://netron.app/](https://netron.app/)。
- en: As already indicated, the model performance improves again.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如已指出，模型性能再次改善。
- en: MSE ≈ 0.89
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MSE ≈ 0.89
- en: MAE ≈ 0.746
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MAE ≈ 0.746
- en: '*r*² ≈ 0.245'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*r*² ≈ 0.245'
- en: Nice! We got the lowest MAE and MSE (and hence the highest *r*²) with this version.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！我们在这个版本中得到了最低的MAE和MSE（因此*r*²最高）。
- en: Making Predictions
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进行预测
- en: In order to answer questions like “What would user 1 rate movie 2 and movie
    3?”, you can do a simple
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答像“用户1会给电影2和电影3多少分？”这样的问题，你可以做一个简单的
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In order to get all ratings of user 1, you could do
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取用户1的所有评分，你可以做
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Conclusion
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we have seen that recommenders have a large impact on businesses,
    that’s why there are widely used. Building a good recommender is not as straightforward
    as other models since you often have to deal with high-cardinality categorical
    features, rendering simple tricks like one-hot encoding useless.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们已经看到推荐系统对业务有很大的影响，这也是它们被广泛使用的原因。构建一个好的推荐系统不像其他模型那样简单，因为你通常需要处理高基数的分类特征，使得简单的技巧如独热编码变得无效。
- en: We learned how to circumvent this problem by using embeddings in our neural
    network architecture. We added some more simple tricks to end up with a not-to-shabby
    matrix factorization model, even without tuning any hyperparameters. We could
    improve the model even further by
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何通过在神经网络架构中使用嵌入来规避这个问题。我们添加了一些简单的技巧，最终得到了一个不算差的矩阵分解模型，即使没有调整任何超参数。我们还可以通过
- en: optimizing the embedding dimension (that we just set to 32 so far)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化嵌入维度（我们目前设定为32）
- en: applying regularization to the embeddings
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对嵌入应用正则化
- en: building a proper time-split validation set, not a random one as we did
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个适当的时间划分验证集，而不是像我们所做的那样随机生成的
- en: retraining it on the complete training dataset (including the validation set)
    after we know the best hyperparameters
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们知道最佳超参数之后，在完整的训练数据集（包括验证集）上重新训练模型
- en: One of the biggest advantages is that we can apply the model in most contexts
    since we only need interaction (rating) data of users and movies. We do not need
    to know any more things about the users and movies, such as age, gender, genre,
    … so usually, we can get going immediately.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 最大的优势之一是我们可以在大多数情况下应用这个模型，因为我们只需要用户和电影的交互（评分）数据。我们不需要了解更多关于用户和电影的信息，例如年龄、性别、类型等等，因此通常我们可以立即开始。
- en: The price that we pay for this is that we cannot output meaningful embeddings
    for unknown users or movies — the **cold start problem**. The model will output
    *something*, but the quality will be horrible.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为此付出的代价是我们无法为未知的用户或电影输出有意义的嵌入——**冷启动问题**。模型会输出*某些东西*，但质量会很差。
- en: 'However, if we happen to have user and movie data, we can do smarter things
    and incorporate these features in a straightforward way as well. This mitigates
    the cold start problem and might even improve the model on known users and movies.
    You can read about it here:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我们恰好拥有用户和电影数据，我们可以做得更聪明，并且可以以直接的方式将这些特征融入进来。这可以缓解冷启动问题，甚至可能改善已知用户和电影的模型。你可以在这里阅读相关内容：
- en: '[](/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b?source=post_page-----956faceb1919--------------------------------)
    [## A Performant Recommender System Without Cold Start Problem'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b?source=post_page-----956faceb1919--------------------------------)
    [## 一个高效的推荐系统，解决冷启动问题'
- en: When collaboration and content-based recommenders merge
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 当协作和基于内容的推荐系统合并时
- en: towardsdatascience.com](/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b?source=post_page-----956faceb1919--------------------------------)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b?source=post_page-----956faceb1919--------------------------------)
- en: References
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] D. Jannach and M. Jugovac, [Measuring the Business Value of Recommender
    Systems](https://arxiv.org/abs/1908.08328) (2019), ACM Transactions on Management
    Information Systems (TMIS) 10.4 (2019): 1–23'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] D. Jannach 和 M. Jugovac, [推荐系统的商业价值测量](https://arxiv.org/abs/1908.08328)
    (2019), ACM Transactions on Management Information Systems (TMIS) 10.4 (2019):
    1–23'
- en: I hope that you learned something new, interesting, and useful today. Thanks
    for reading!
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你今天学到了新的、有趣的、有用的东西。感谢阅读！
- en: '**As the last point, if you**'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**最后一点，如果你**'
- en: '**want to support me in writing more about machine learning and**'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**想要支持我写更多关于机器学习的内容**'
- en: '**plan to get a Medium subscription anyway,**'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无论如何，计划获取一个 Medium 订阅，**'
- en: '**why not do it** [**via this link**](https://dr-robert-kuebler.medium.com/membership)**?
    This would help me a lot! 😊**'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么不通过这个链接** [**支持我**](https://dr-robert-kuebler.medium.com/membership)**呢？这对我帮助很大！😊**'
- en: '*To be transparent, the price for you does not change, but about half of the
    subscription fees go directly to me.*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*为了透明，您的价格不会改变，但大约一半的订阅费用会直接给我。*'
- en: '**Thanks a lot, if you consider supporting me!**'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**非常感谢，如果你考虑支持我！**'
- en: '*If you have any questions, write me on* [*LinkedIn*](https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/)*!*'
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如果你有任何问题，请在* [*LinkedIn*](https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/)*上联系我！*'
