- en: Deploying Multiple Models with SageMaker Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SageMaker Pipelines 部署多个模型
- en: 原文：[https://towardsdatascience.com/deploying-multiple-models-with-sagemaker-pipelines-fb7363094c50](https://towardsdatascience.com/deploying-multiple-models-with-sagemaker-pipelines-fb7363094c50)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deploying-multiple-models-with-sagemaker-pipelines-fb7363094c50](https://towardsdatascience.com/deploying-multiple-models-with-sagemaker-pipelines-fb7363094c50)
- en: Applying MLOps best practices to advanced serving options
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用 MLOps 最佳实践于高级服务选项
- en: '[](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)
    ·8 min read·Mar 23, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)
    ·8 分钟阅读·2023年3月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c86ec39899ba0ad0ba89fd4df2d483db.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c86ec39899ba0ad0ba89fd4df2d483db.png)'
- en: Image from [Unsplash](https://unsplash.com/photos/f7uCQxhucw4) by [Growtika](https://unsplash.com/@growtika)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [Unsplash](https://unsplash.com/photos/f7uCQxhucw4) 由 [Growtika](https://unsplash.com/@growtika)
    提供
- en: MLOps is an essential practice to productionizing your Machine Learning workflows.
    With MLOps you can establish workflows that are catered for the ML lifecycle.
    These make it easier to centrally maintain resources, update/track models, and
    in general simplify the process as your ML experimentation scales up.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 是将你的机器学习工作流投入生产的关键实践。通过 MLOps，你可以建立适用于 ML 生命周期的工作流。这使得集中维护资源、更新/跟踪模型变得更容易，并且随着你的
    ML 实验规模的扩大，整个过程变得更加简化。
- en: A key MLOps tool within the [Amazon SageMaker](https://aws.amazon.com/sagemaker/)
    ecosystem is [SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/).
    With SageMaker Pipelines you can define workflows that are composed of different
    defined ML **steps**. You can also structure these workflows by defining **parameters**
    that you can inject as variables into your Pipeline. For a more general introduction
    to SageMaker Pipelines, please refer to the [linked article](/an-introduction-to-sagemaker-pipelines-4018a819352d).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon SageMaker](https://aws.amazon.com/sagemaker/) 生态系统中的一个关键 MLOps 工具是
    [SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/)。通过 SageMaker
    Pipelines，你可以定义由不同的 ML **步骤** 组成的工作流。你还可以通过定义 **参数** 来结构化这些工作流，并将这些参数作为变量注入到你的管道中。有关
    SageMaker Pipelines 的更一般介绍，请参考 [相关文章](/an-introduction-to-sagemaker-pipelines-4018a819352d)。'
- en: Defining a Pipeline in itself is not heavily complicated, but there’s a few
    advanced use-cases that need some extra configuring. Specifically, say that you
    are training multiple models that are needed for inference in your ML use-case.
    Within SageMaker there is a hosting option known as [Multi-Model Endpoints](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html)
    (MME) where you can host several models on a singular endpoint and invoke a target
    model. However, within SageMaker Pipelines there’s no native support for defining
    or deploying a MME natively at the moment. In this blog post we’ll take a look
    at how we can utilize a [Pipelines Lambda Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-lambda)
    to deploy a Multi-Model Endpoint in a custom manner, while adhering to MLOPs best
    practices.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 定义管道本身并不复杂，但有一些高级用例需要额外的配置。具体来说，假设你正在训练多个模型，这些模型在你的机器学习用例中用于推理。在 SageMaker 中，有一个被称为
    [多模型端点](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html)（MME）的托管选项，你可以在单个端点上托管多个模型并调用目标模型。然而，目前在
    SageMaker Pipelines 中没有原生支持定义或部署 MME。在这篇博客文章中，我们将探讨如何利用 [Pipelines Lambda 步骤](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-lambda)
    以自定义方式部署多模型端点，同时遵循 MLOps 最佳实践。
- en: '**NOTE**: For those of you new to AWS, make sure you make an account at the
    following [link](https://aws.amazon.com/console/) if you want to follow along.
    The article also assumes an intermediate understanding of SageMaker Deployment,
    I would suggest following this [article](https://aws.amazon.com/blogs/machine-learning/part-2-model-hosting-patterns-in-amazon-sagemaker-getting-started-with-deploying-real-time-models-on-sagemaker/)
    for understanding Deployment/Inference more in depth. In particular, for SageMaker
    Multi-Model Endpoints I would refer to the following [blog](https://aws.amazon.com/blogs/machine-learning/part-3-model-hosting-patterns-in-amazon-sagemaker-run-and-optimize-multi-model-inference-with-amazon-sagemaker-multi-model-endpoints/).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：如果你是AWS的新手，请确保在以下[链接](https://aws.amazon.com/console/)上注册一个账户，以便跟随操作。本文还假设你对SageMaker部署有中级了解，我建议参考这篇[文章](https://aws.amazon.com/blogs/machine-learning/part-2-model-hosting-patterns-in-amazon-sagemaker-getting-started-with-deploying-real-time-models-on-sagemaker/)以深入理解部署/推理。特别是，对于SageMaker多模型终端，我建议参考以下[博客](https://aws.amazon.com/blogs/machine-learning/part-3-model-hosting-patterns-in-amazon-sagemaker-run-and-optimize-multi-model-inference-with-amazon-sagemaker-multi-model-endpoints/)。'
- en: Setup
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置
- en: For this example, we will be working in [SageMaker Studio](https://aws.amazon.com/sagemaker/studio/),
    where we have access to the visual interfaces for SageMaker Pipelines and other
    SageMaker components. For development we will be utilizing a Studio Notebook Instance
    with a Data Science Kernel on an ml.t3.medium instance. To get started we need
    to first import the necessary libraries for the different steps we will be utilizing
    within SageMaker Pipelines.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将在[SageMaker Studio](https://aws.amazon.com/sagemaker/studio/)中工作，这里我们可以访问SageMaker管道和其他SageMaker组件的可视化界面。为了开发，我们将利用一个带有数据科学内核的Studio
    Notebook实例，在一个ml.t3.medium实例上。要开始，我们首先需要导入在SageMaker管道中将要使用的不同步骤所需的库。
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next we create a [Pipeline Session](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#pipeline-context),
    this Pipeline Session ensures none of the training jobs are actually executed
    within the notebook until the Pipeline itself is executed.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个[管道会话](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#pipeline-context)，这个管道会话确保在管道实际执行之前，没有任何训练作业会在笔记本中实际执行。
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For this example we’ll utilize the [Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone)
    (CC BY 4.0) and run a [SageMaker XGBoost algorithm](https://aws.plainenglish.io/end-to-end-example-of-sagemaker-xgboost-eb9eae8a5207)
    on it for a regression model. You can download the dataset from the publicly available
    Amazon datasets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将利用[Abalone数据集](https://archive.ics.uci.edu/ml/datasets/abalone)（CC
    BY 4.0）并在其上运行[SageMaker XGBoost算法](https://aws.plainenglish.io/end-to-end-example-of-sagemaker-xgboost-eb9eae8a5207)来进行回归模型。你可以从公开可用的Amazon数据集中下载该数据集。
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can then [parameterize](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html)
    our Pipeline by defining defaults for both the training dataset and instance type.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以[参数化](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html)我们的管道，通过定义训练数据集和实例类型的默认值。
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We then also retrieve the [AWS provided container](https://aws.plainenglish.io/how-to-retrieve-amazon-sagemaker-deep-learning-images-ff4a5866299e)
    for XGBoost that we will be utilizing for training and inference.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们还会检索[AWS提供的容器](https://aws.plainenglish.io/how-to-retrieve-amazon-sagemaker-deep-learning-images-ff4a5866299e)，这是我们将用于训练和推理的XGBoost容器。
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Training Setup
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练设置
- en: For the training portion of our Pipeline we will be configuring the SageMaker
    XGBoost algorithm for our regression Abalone dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们管道的训练部分，我们将配置SageMaker XGBoost算法以适应我们的回归Abalone数据集。
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For our second estimator we then change our hyperparameters to adjust our model
    training so we have two separate models behind our Multi-Model Endpoint.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第二个估算器，我们将更改超参数来调整模型训练，这样我们就在我们的多模型终端后面有两个独立的模型。
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We then configure our training inputs for both estimators to point towards the
    parameter we defined for our S3 training dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们配置两个估算器的训练输入，以指向我们为S3训练数据集定义的参数。
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We then define two separate Training Steps that will be executed in parallel
    via our Pipeline.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们定义两个独立的训练步骤，这些步骤将通过我们的管道并行执行。
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Lambda Step
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda步骤
- en: A [Lambda Step](https://aws.amazon.com/blogs/machine-learning/use-a-sagemaker-pipeline-lambda-step-for-lightweight-model-deployments/)
    essentially allows you to plug in a Lambda function within your Pipeline. For
    every SageMaker Training Job a model.tar.gz is emitted containing the trained
    model artifacts. Here we will utilize the Lambda step to retrieve the trained
    model artifacts and deploy them to a SageMaker Multi-Model Endpoint.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[Lambda 步骤](https://aws.amazon.com/blogs/machine-learning/use-a-sagemaker-pipeline-lambda-step-for-lightweight-model-deployments/)
    本质上允许你在管道中插入 Lambda 函数。每个 SageMaker 训练作业都会生成一个包含训练模型工件的 model.tar.gz 文件。这里我们将利用
    Lambda 步骤来检索训练好的模型工件，并将其部署到 SageMaker 多模型端点。'
- en: Before we can do that we need to give our Lambda function proper permissions
    to work with SageMaker. We can use the following existing [script](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-pipelines/tabular/lambda-step/iam_helper.py)
    to create an IAM Role for our Lambda Function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，我们需要给予 Lambda 函数适当的权限来使用 SageMaker。我们可以使用以下现有 [脚本](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-pipelines/tabular/lambda-step/iam_helper.py)
    来为 Lambda 函数创建一个 IAM 角色。
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After we’ve defined our Lambda role we can create a Lambda function that does
    a few things for us:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了 Lambda 角色后，我们可以创建一个 Lambda 函数，为我们完成一些任务：
- en: Takes each individual model.tar.gz from each training job and places it into
    a central S3 location containing both tarballs. For **MME they expect all model
    tarballs to be in one singular S3 path**.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将每个训练作业的 model.tar.gz 文件放入包含两个 tarball 的中央 S3 位置。对于**MME 他们期望所有模型 tarball 都在一个单一的
    S3 路径中**。
- en: Utilizes the boto3 client with SageMaker to create a SageMaker Model, Endpoint
    Configuration, and Endpoint.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 boto3 客户端与 SageMaker 一起创建 SageMaker 模型、端点配置和端点。
- en: We can utilize the following helper functions to achieve the first task, by
    copying the training job artifacts into a central S3 location with both model
    tarballs.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用以下辅助函数来完成第一个任务，将训练作业工件复制到包含两个模型 tarball 的中央 S3 位置。
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The next steps for our Lambda function will be creating the necessary SageMaker
    entities for creating a real-time endpoint:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 Lambda 函数的下一步是创建实时端点所需的 SageMaker 实体：
- en: '[SageMaker Model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_model.html):
    Contains the model data and container image, also defines Multi-Model vs Single
    Model endpoint.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker 模型](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_model.html)：包含模型数据和容器镜像，同时定义了多模型与单模型端点。'
- en: '[SageMaker Endpoint Configuration](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint_config.html):
    Defines the hardware behind an endpoint, the instance type and count.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker 端点配置](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint_config.html)：定义了端点背后的硬件、实例类型和数量。'
- en: '[SageMaker Endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint.html):
    Your REST endpoint that you can invoke for inference, for MME you also specify
    the model that you want to perform inference against.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SageMaker 端点](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint.html)：可以调用进行推理的
    REST 端点，对于 MME，你还需要指定要进行推理的模型。'
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We return a successful message with our Lambda function once we are able to
    start creating an endpoint.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们能够开始创建端点，我们会通过 Lambda 函数返回成功消息。
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We then define this Lambda function in the necessary Lambda Step format for
    our Pipeline to pick up on.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们以管道所需的 Lambda 步骤格式定义此 Lambda 函数。
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We also define what we are returning from the Lambda in the form of output parameters.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了 Lambda 函数返回的输出参数。
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We then define our inputs with the two different trained model artifacts from
    the training steps that we defined earlier in our notebook.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们定义输入，使用在之前的笔记本中定义的两个不同训练模型工件。
- en: '[PRE16]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Pipeline Execution & Sample Inference
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道执行与示例推理
- en: Now that we have our different steps configured we can stitch all of this together
    into a singular Pipeline. We point towards our three different steps and the different
    parameters we defined. Note that you can also define further parameters than we
    did here depending on your use case.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已配置好不同的步骤，可以将它们组合成一个单一的管道。我们指向我们定义的三个不同步骤及其参数。请注意，根据你的用例，你还可以定义比我们这里更多的参数。
- en: '[PRE17]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can now execute the Pipeline with the following commands.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用以下命令执行管道。
- en: '[PRE18]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Post execution we notice that in the Studio UI for the Pipelines tab a Directed
    Acylic Graph (DAG) has been created for your Pipeline to display your workflow.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 执行后，我们注意到在 Pipelines 标签的 Studio UI 中，为你的 Pipeline 创建了一个有向无环图（DAG）以显示你的工作流。
- en: '![](../Images/5fe04b0971554aafc89456a4f2bf49f6.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fe04b0971554aafc89456a4f2bf49f6.png)'
- en: MME DAG (Screenshot by Author)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: MME DAG（作者截图）
- en: After a few minutes you should also see an endpoint has been created in the
    SageMaker Console.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，你还应该在 SageMaker 控制台中看到已创建的端点。
- en: '![](../Images/b77bb0a33a35294968e306c3735a5112.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b77bb0a33a35294968e306c3735a5112.png)'
- en: Endpoint Created (Screenshot by Author)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 端点创建完成（作者截图）
- en: We can then test this endpoint with a sample inference to ensure it’s working
    properly.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一个示例推断来测试这个端点，以确保它正常工作。
- en: '[PRE19]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Additional Resources & Conclusion
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附加资源与总结
- en: '[](https://github.com/RamVegiraju/sagemaker-pipelines-examples?source=post_page-----fb7363094c50--------------------------------)
    [## GitHub - RamVegiraju/sagemaker-pipelines-examples: SageMaker Pipelines Examples
    Repo'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/RamVegiraju/sagemaker-pipelines-examples?source=post_page-----fb7363094c50--------------------------------)
    [## GitHub - RamVegiraju/sagemaker-pipelines-examples: SageMaker Pipelines 示例库'
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab or…
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 此时你无法执行该操作。你在另一个标签页或窗口中登录了。你在另一个标签页中退出了…
- en: github.com](https://github.com/RamVegiraju/sagemaker-pipelines-examples?source=post_page-----fb7363094c50--------------------------------)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/RamVegiraju/sagemaker-pipelines-examples?source=post_page-----fb7363094c50--------------------------------)
- en: The code for the entire example can be found at the link above (stay tuned for
    more Pipelines examples). This example combines an advanced hosting option with
    MLOPs best practices. It’s crucial to utilize MLOPs tools as you scale up your
    ML experimentation as it helps simplify and parameterize your efforts so that
    it’s easier for teams to collaborate and track. I hope this article was a good
    overview of using Pipelines for a specific Hosting use-case in MME. As always
    all feedback is appreciated, thank you for reading!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 整个示例的代码可以在上面的链接中找到（敬请关注更多 Pipelines 示例）。这个示例将高级托管选项与 MLOPs 最佳实践结合起来。在你扩展 ML
    实验时，利用 MLOPs 工具至关重要，因为它有助于简化和参数化你的工作，使团队更容易协作和跟踪。我希望这篇文章对在 MME 中使用 Pipelines 进行特定托管用例提供了一个良好的概述。像往常一样，任何反馈都很受欢迎，感谢阅读！
- en: '*If you enjoyed this article feel free to connect with me on* [*LinkedIn*](https://www.linkedin.com/in/ram-vegiraju-81272b162/)
    *and subscribe to my Medium* [*Newsletter*](https://ram-vegiraju.medium.com/subscribe)*.
    If you’re new to Medium, sign up using my* [*Membership Referral*](https://ram-vegiraju.medium.com/membership)*.*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章，可以随时通过* [*LinkedIn*](https://www.linkedin.com/in/ram-vegiraju-81272b162/)
    *与我联系，并订阅我的 Medium* [*Newsletter*](https://ram-vegiraju.medium.com/subscribe)*。如果你是
    Medium 新手，可以使用我的* [*会员推荐链接*](https://ram-vegiraju.medium.com/membership)*进行注册。*'
