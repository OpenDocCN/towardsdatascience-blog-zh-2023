# 使用 LangChain 将对话作为有向图

> 原文：[https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c](https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c)

## 构建一个聊天机器人，旨在了解关于新潜在客户的关键信息。

[](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[![Daniel Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------) [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----46d70e1a846c--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----46d70e1a846c--------------------------------) ·18分钟阅读·2023年9月25日

--

![](../Images/e4c31cbbc41f201ecdab003a52889978.png)

图片由 Daniel Warfield 使用 MidJourney 制作。所有图片均由作者提供，除非另有说明。

在这篇文章中，我们将使用 LangChain 在房地产环境中进行线索资格审查。我们设想一个场景，新潜在客户首次联系房地产代理。我们将设计一个系统，与新潜在线索沟通，以提取关键信息，然后由房地产代理接手。

**这对谁有用？** 任何对在实际环境中应用自然语言处理（NLP）感兴趣的人。

**这篇文章的高级程度如何？** 这个例子在概念上很直接，但如果你对 Python 和语言模型没有牢固的理解，可能会很难跟上。

**先决条件：** 基础的 Python 编程知识以及对语言模型的高级理解。

# 问题描述

这个用例直接受到了我作为承包商时收到的工作请求的启发。潜在客户拥有一家房地产公司，并发现他们的代理在每次对话开始时花费了大量时间执行相同的重复任务：线索资格审查。

线索资格审查是房地产术语中对线索的初步筛选。获取他们的联系信息、预算等。这是一个相当广泛的术语，具体细节可能因组织而异。在这篇文章中，我们将“资格审查”线索的以下信息视为有效：

1.  **姓名：** 线索的姓名。

1.  **联系信息：** 线索的电子邮件或电话号码。

1.  **融资：** 他们的月租预算。

1.  **准备情况：** 他们能多快与代理见面。

# 方法

## 天真的方法

尽管大型语言模型非常强大，但它们需要对用例进行适当的上下文化才能持续成功。例如，你可以给语言模型一个提示，类似于：

[PRE0]

然后，你可以将新的客户放入一个与该提示初始化的模型的聊天房间中。这将是开始在特定业务环境中尝试 LLM 的好方法，同时也是开始意识到 LLM 对某些类型反馈的脆弱性的好方法。如果用户问了一个无害但无关的问题，比如“你昨晚看比赛了吗？”或“是的，我在路上走时看到你们的建筑了。”对某些用例来说这可能是个严重的问题，也可能不是，但对话周围的严格结构可以帮助保持对话的正常进行。

## 对话作为有向图

我们可以将对话框架设为有向图，其中每个节点代表某个对话状态，每条边代表改变对话状态的动力，如完成的介绍或获得的信息。

![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)

在我们尝试解决的问题的背景下，有向图遍历的示例

这是我们为这个问题构建的最基本的有向图。值得注意的是，这种方法可以根据系统的需要轻松地扩展、收缩或以其他方式改变。

例如，如果你的客户持续向聊天机器人询问体育问题，而这在初始设计阶段没有预料到，那么你可以添加相关逻辑以检查此类问题并作出适当回应。

![](../Images/d75387683582c046884ecfc7107d4be1.png)

处理与体育相关的问题的示例修改。我们将继续使用原始的简单图，但很容易看出，通过向现有有向图中添加额外元素，可以缓解出现的边界情况和性能较差的场景。

当创建一个以自然方式与人类互动的新系统时，它必须能够轻松迭代以应对新出现的意外问题。为了本示例的目的，我们将保持简单，但可扩展性是这种方法的核心能力之一。

# 关键技术

我们将使用 LangChain 来完成大部分繁重的工作。具体来说，我们将使用：

1.  **一个 LLM：** 我们将使用 OpenAI 的 Text DaVinci 3 模型。

1.  **输出解析：** 我们将使用 LangChain 的 Pydantic 解析器将结果解析成易于处理的格式。

我们还将从头开始实现一个**有向图**，并在该图中内置一些功能以实现所需的功能。

## 模型

在这个示例中，我们使用的是 OpenAI 的*Text Davinci 3* 模型。虽然你可以使用几乎任何现代的大型语言模型，但我选择使用这个特定模型，因为它在 LangChain 示例和文档中被广泛使用。

LangChain 尽力成为一个强大而稳健的框架，但处理大型语言模型的工作很繁琐。不同的模型对给定的提示可能会有截然不同的行为。我发现 Text Davinci 3 对来自 LangChain 的提示反应一致。

LangChain 允许你使用自托管模型、Hugging Face 上免费托管的模型或来自其他多个来源的模型。随意尝试你选择的模型；它们之间的切换相当简单（尽管根据我的经验，你可能需要根据你使用的特定模型调整提示）。

Text Davinci 3 是一个变换器模型，随意阅读以下文章以获取更多信息：

[## 变换器 — 直观且详尽的解释](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)

### 又一篇探讨现代机器学习浪潮的文章。希望你会觉得这篇直观且发人深省…

[medium.com](https://medium.com/@danielwarfield1/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=post_page-----46d70e1a846c--------------------------------)

## LangChain 解析

LangChain 拥有多种解析器，旨在与大型语言模型配合使用。我们将使用 PydanticOutputParser。

LangChain 解析器不仅从 LLM 响应中提取关键信息，还修改提示以引导 LLM 提供更多可解析的响应。使用 Pydantic 解析器时，你首先定义一个表示你希望从 LLM 中获得结果格式的类。假设你想从 LLM 中获得一个笑话，包括开场白和笑点：

[PRE1]

然后你可以定义要发送给模型的实际查询。

[PRE2]

这个查询随后被解析器修改，结合用户的查询和有关最终解析格式的信息，以构建对 LLM 的提示。

[PRE3]

这个特定示例的提示如下：

[PRE4]

{"properties": {"setup": {"title": "开场白", "description": "设置笑话的提问", "type": "string"}, "punchline": {"title": "笑点", "description": "解决笑话的回答", "type": "string"}}, "required": ["setup", "punchline"]}

[PRE5]

注意用户的查询“告诉我一个关于鹦鹉的笑话”是如何与关于所需最终格式的信息结合的。

然后，这个格式化的查询可以传递给模型，解析器可以用来提取结果：

[PRE6]

这是这个特定示例的结果：

[PRE7]

PydanticOutputParser 既强大又灵活，这就是它在 LangChain 中最常用的解析器的原因。我们将在本篇文章中进一步探讨这个解析器。OutputFixingParser 和 RetryOutputParser 是另外两个非常有用的输出解析器，在本篇文章中不会详细探讨，但在此用例中肯定可以使用。

## 对话作为一个有向图

我们将把对话抽象为一个有向图。

![](../Images/d9cdbcb8fe724aeec7bb01e703f9417a.png)

最基本形式的这种方法。它是一个对话状态的序列，当从对方接收到特定信息时，对话状态就会进展。

每个节点和边都需要自定义，但会遵循相同的一般结构：

![](../Images/bd5c5a4cb2bb07c7bd42bfda364c635e.png)

节点和边的工作原理。蓝色的框表示对话状态，因此蓝色框表示单个节点及其功能。红色的框表示在对话状态之间过渡所需的步骤，因此红色框表示边及其功能。

值得注意的是，LangChain 具有类似的结构，称为 Chain。我们在这篇文章中不会讨论 Chains，但它们对于直接和顺序的 LLM 任务很有用。

# 定义节点和边

这里我们开始编码一个支持 LLM 的定向图，具有上述核心结构。我们将使用 Pydantic 解析器来处理输入验证步骤以及实际内容解析。

我提供了代码作为参考，但不要被代码的长度吓到。你可以快速浏览代码，或者完全不参考代码。最终的笔记本可以在这里找到：

[](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw) [## Google Colaboratory

### 编辑描述

colab.research.google.com](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU?source=post_page-----46d70e1a846c--------------------------------#scrollTo=IgzZooHUoIQw)

## 通用工具

出于演示目的，所有这些内容将存在于一个 Jupyter 笔记本中，模型之间的最终往返将在最后一个单元格中执行。为了提高可读性，我们将定义三个函数：一个用于模型输出给用户，一个用于用户输入给模型，另一个用于打印演示所需的关键信息，如解析结果。

[PRE8]

## 定义边

正如代码所示，边缘接受一些输入，将其与条件进行比较，如果条件满足，则解析输入。边缘包含相关的逻辑来记录尝试失败的次数，并负责告诉更高级别的单元是否应该沿着边缘在定向图中继续前进。

[PRE9]

我在代码中创建了一些单元测试 [这里](https://colab.research.google.com/drive/1oSKFO2ho6BN__pZp0uQNwP-HWeXGPpKU#scrollTo=Dc7XI7NlU71j&line=1&uniqifier=1)，展示了边缘的功能。

## 定义节点

现在我们有了一个处理输入验证和解析的边，我们可以定义一个处理对话状态的节点。节点请求用户输入，并将该输入传递给来自该节点的定向边。如果没有一条边成功执行，节点会再次询问用户输入。

[PRE10]

实现了这个，我们可以开始看到对话的进行。我们将实现一个请求联系信息的节点，以及两个边：一个尝试解析有效的邮箱，另一个尝试解析有效的电话号码。

[PRE11]

这是几个具有单一节点的对话示例：

[PRE12]

[PRE13]

[PRE14]

在示例 1 中，用户包括了一些无关的信息，但在响应中有一个有效的邮箱。在示例 2 中，用户在第一次响应中没有有效的邮箱或电话号码，但在第二次响应中有一个。在示例 3 中，用户没有有效的响应，其中一个边缘放弃并允许对话继续。

值得注意的是，从用户体验的角度来看，这种方法感觉有点机械。虽然在本文中没有探讨，但很容易想象用户输入如何被用来构造系统的输出，可能通过字符串格式化或请求LLM格式化响应。

# 定义对话

现在我们有了节点和边缘，并定义了它们的功能，我们可以将所有这些整合在一起，创建最终的对话。我们之前已经覆盖了一个大致的蓝图，但让我们修改它，以更好地反映图实际要做的事情。请回顾以下内容：

+   **节点有初始提示和重试提示**

+   **边缘有一个条件、一个解析提示和一个解析结构**。条件是一个关于用户输入的布尔问题。如果条件满足，则根据解析提示和用户输入解析解析结构。这是通过请求大型语言模型将用户输入重新格式化为可解析的表示，使用pydantic解析器来完成的。

让我们根据这些定义构建一个对话图：

![](../Images/403d709d4121109480cb4aac503222f4.png)

我们将要实现的对话图，包括所有必要的节点和边缘参数。

从上面的图示可以看出，已经做了一些提示工程以适应某些边缘情况。例如，预算的解析提示允许解析器解析用户响应，例如“我的预算大约是1.5k”。

由于LLMs的灵活性，究竟如何实现这样的图完全取决于工程师。如果价格解析在未来成为问题，可以有几个边，每个边有不同的条件和解析提示。例如，可以想象一个边检查预算是否超过某个值，从而暗示他们提供的是年度预算而不是月度预算。这个系统的强大之处在于可以无缝添加或删除这些修改。

# 实现对话图

我们已经完成了所有的重头戏，现在只需要编码并查看它是如何工作的。以下是实现代码：

[PRE15]

以下是一些示例对话：

[PRE16]

[PRE17]

[PRE18]

# 结论

在本文中，我们将一个潜在客户资格的用例格式化为有向图，实施了必要的解析功能和数据结构，并制作了一个示例图，该图从用户那里提取关键信息。正如示例对话所示，这个系统并不完美，但由于有向图的性质，我们可以轻松添加新节点，以缓解某些边界情况的影响。

尽管本文未讨论，但还有许多方法可以改进这个系统：

+   我们可以使用不同的LangChain解析器来尝试重试或纠正查询。

+   我们可以使用LLM缓存来尝试缓存某些常见响应，从而节省预算。

+   我们可以将该系统与矢量数据库连接，以便对知识库进行问答。

+   我们可以使用LLM来构建用户的提示，并提供有关对话的上下文，以鼓励更自然的回应。

尽管我的合同工作没有成功，但我认为这种方法突显了一个灵活且强大的框架，该框架具有可扩展性，适用于各种应用。

# 关注获取更多信息！

我描述了机器学习领域的论文和概念，重点放在实际和直观的解释上。

**致谢：** 本文档中的所有图片均由**丹尼尔·沃菲尔德**创建，除非另有来源说明。您可以将此帖中的任何图片用于个人非商业用途，只需引用本文， [https://danielwarfield.dev](https://danielwarfield.dev/)，或两者兼用。
