["```py\nYou are a high school history teacher grading homework assignments. \\\nBased on the homework question indicated by “Q:” and the correct answer \\\nindicated by “A:”, your task is to determine whether the student's answer is \\\ncorrect.\nGrading is binary; therefore, student answers can be correct or wrong.\nSimple misspellings are okay.\n\nQ: {question}\nA: {correct_answer}\n\nStudent Answer: {student_answer}\n```", "```py\nWrite me a birthday message for my dad.\n```", "```py\nWrite me a birthday message for my dad no longer than 200 \\\ncharacters. This is a big birthday because he is turning 50\\. To celebrate, \\\nI booked us a boys' trip to Cancun. Be sure to include some cheeky humor, he \\\nloves that.\n```", "```py\nGiven the title of a Towards Data Science blog article, write a subtitle for it.\n\nTitle: Prompt Engineering—How to trick AI into solving your problems\nSubtitle:\n```", "```py\nGiven the title of a Towards Data Science blog article, write a subtitle for it.\n\nTitle: A Practical Introduction to LLMs\nSubtitle: 3 levels of using LLMs in practice\n\nTitle: Cracking Open the OpenAI (Python) API\nSubtitle: A complete beginner-friendly introduction with example code\n\nTitle: Prompt Engineering-How to trick AI into solving your problems\nSubtitle:\n```", "```py to highlight a body of text, use markup languages like Markdown or HTML to format text, use JSON to organize information, etc.\n\nNow, let’s see this in action.\n\n***Without Trick***\n\n```", "```py\n\n***With Trick***\n\n```", "```py\n\n## **Trick 4: Chain of Thought**\n\nThis trick was proposed by Wei et al. [7]. The basic idea is to guide an LLM to think “step by step”. This helps break down complex problems into manageable sub-problems, which gives the LLM “time to think” [3,5]. Zhang et al. showed that this could be as simple as including the text “*Let’s think step by step*” in the prompt [8].\n\nThis notion can be extended to any recipe-like process. For example, if I want to create a LinkedIn post based on my latest Medium blog, I can guide the LLM to mirror the step-by-step process I follow.\n\n***Without Trick***\n\n```", "```py\n\n***With Trick***\n\n```", "```py\n\n## **Trick 5: Chatbot Personas**\n\nA somewhat surprising technique that tends to improve LLM performance is to prompt it to take on a particular persona e.g. “*you are an expert*”. This is helpful because you may not know the best way to describe your problem to the LLM, but you may know who would help you solve that problem [[1](https://arxiv.org/abs/2302.11382)]. Here’s what this might look like in practice.\n\n***Without Trick***\n\n```", "```py\n\n***With Trick***\n\n```", "```py\n\n## **Trick 6: Flipped Approach**\n\nIt can be difficult to optimally prompt an LLM when **we do not know what it knows or how it thinks**. That is where the “flipped approach” can be helpful. This is where you prompt the LLM to ask you questions until it has a sufficient understanding (i.e. context) of the problem you are trying to solve.\n\n***Without Trick***\n\n```", "```py\n\n***With Trick***\n\n```", "```py\n\n## **Trick 7: Reflect, Review, and Refine**\n\nThis final trick prompts the model to reflect on its past responses to improve them. Common use cases are having the model critically evaluate its own work by asking it if it “*completed the assignment*” or having it “*explain the reasoning and assumptions*” behind a response [1, 3].\n\nAdditionally, you can ask the LLM to refine not only its responses but **your prompts**. This is a simple way to automatically rewrite prompts so that they are easier for the model to “understand”.\n\n***With Trick***\n\n```", "```py\n\n# **Example Code: Automatic Grader with LangChain**\n\nNow that we’ve reviewed several prompting heuristics let’s see how we can apply them to a specific use case. To do this, we will return to the automatic grader example from before.\n\n```", "```py\n\nOn second look, a few of the previously mentioned tricks should be apparent i.e. **Trick 6**: chatbot persona, **Trick 3**: use structured text, and **Trick 1**: be descriptive. This is what good prompting typically looks like in practice, namely combining multiple techniques in a single prompt.\n\nWhile we could copy-paste this prompt template into ChatGPT and replace the *question*, *correct_answer*, and *student_answer* fields, **this is not a scalable way to implement the automatic grader**. Rather, what we want is to integrate this prompt into a larger software system so that we can build a user-friendly application that a human can use.\n\n## LangChain\n\nOne way we can do this is via **LangChain**, which is **a Python library that helps simplify building applications on top of large language models**. It does this by providing a variety of handy abstractions for using LLMs programmatically.\n\nThe central class that does this is called **chain** (hence the library name). This abstracts the process of generating a prompt, sending it to an LLM, and parsing the output so that it can be easily called and integrated into a larger script.\n\nLet’s see how to use LangChain for our automatic grader use case. The example code is available on the [GitHub Repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example) for this article.\n\n## Imports\n\nWe first start by importing the necessary library modules.\n\n```", "```py\n\nHere we will use gpt-3.5-turbo which requires a secret key for OpenAI’s API. If you don’t have one, I gave a step-by-step guide on how to get one in a [past article](/cracking-open-the-openai-python-api-230e4cae7971) of this series. I like to store the secret key in a separate Python file (*sk.py*) and import it with the following line of code.\n\n```", "```py\n\n## Our 1st chain\n\nTo define our chain, we need two core elements: the **LLM** and the **prompt**. We start by creating an object for the LLM.\n\n```", "```py\n\nLangChain has a class specifically for OpenAI (and many other) chat models. I pass in my secret API key and set the temperature to 0\\. The default model here is *gpt-3.5-turbo*, but you can alternatively use *gpt-4* using the “model_name” input argument. You can further customize the chat model by setting other [input arguments](https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html#langchain.chat_models.openai.ChatOpenAI).\n\nNext, we define our **prompt template**. This object allows us to generate prompts dynamically via input strings that automatically update a base template. Here’s what that looks like.\n\n```", "```py\n\nWith our LLM and prompt, we can now define our chain.\n\n```", "```py\n\nNext, we can pass inputs to the chain and obtain a grade in one line of code.\n\n```", "```py\n\nWhile this chain can perform the grading task effectively, its outputs may not be suitable for an automated process. For instance, in the above code block, the LLM correctly said the student’s answer of “FDR” was wrong, but it would be better if the LLM gave us an output in a standard format that could be used in downstream processing.\n\n## Output parser\n\nThis is where **output parsers** come in handy. These are functions we can integrate into a chain to convert LLM outputs to a standard format. Let’s see how we can make an output parser that converts the LLM response to a boolean (i.e. *True* or *False*) output.\n\n```", "```py\n\nHere, we create a simple output parser that checks if the word “wrong” is in the LLM’s output. If not, we return *True*, indicating the student's correct answer. Otherwise, we return *False*, indicating the student's answer was incorrect.\n\nWe can then incorporate this output parser into our chain to seamlessly parse text when we run the chain.\n\n```", "```py\n\nFinally, we can run the chain for a whole list of student answers and print the outputs.\n\n```"]