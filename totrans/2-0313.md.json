["```py\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nds = tfds.load('deep_weeds', split='train', shuffle_files=True)\n```", "```py\nimport numpy as np\nimages_main = []\nimages_anomaly = []\nlabels_main= []\nlabels_anomaly = []\nds = ds.prefetch(tf.data.AUTOTUNE)\nfor example in ds:\n  #print(np.array(example['label']))\n  if np.array(example['label']) == 5:\n    images_main.append(example[\"image\"])\n    labels_main.append(example[\"label\"])\n  if np.array(example['label']) == 1:\n    images_anomaly.append(example[\"image\"])\n    labels_anomaly.append(example[\"label\"])\n```", "```py\nnp.array(images_main).shape\n```", "```py\n(1009, 256, 256, 3)\n```", "```py\nparc = round(len(labels_anomaly) * 0.01)\nimages_anomaly = np.array(images_anomaly)[:parc]\n# stacking the main images and anomaly images together\ntotal_images = np.vstack([images_main, images_anomaly])\n```", "```py\ntotal_images.shape\n```", "```py\n(1020, 256, 256, 3)\n```", "```py\n# import the necessary packages\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import load_model\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport cv2\n```", "```py\n(train_x, test_x) = train_test_split(total_images, test_size=0.2, random_state=0)\n```", "```py\nclass Convolution_Autoencoder:\n  @staticmethod\n  def build(width, height, depth, filters=(16, 32, 64), latentDim=32):\n    input_shape = (height, width, depth)\n    chanDim = -1\n\n    inputs = Input(shape=input_shape)\n    x = inputs\n\n    for f in filters:\n      x = Conv2D(f, (3, 3), strides = 2, padding=\"same\")(x)\n      x = LeakyReLU(alpha=0.3)(x)\n      x = BatchNormalization(axis=chanDim)(x)\n\n    volume = K.int_shape(x)\n    x = Flatten()(x)\n    latent = Dense(latentDim)(x)\n\n    #encoder model\n    encoder = Model(inputs, latent, name=\"encoder\")\n\n    #compressed representation\n    latent_layer_input = Input(shape=(latentDim,))\n    x = Dense(np.prod(volume[1:]))(latent_layer_input)\n\n    x = Reshape((volume[1], volume[2], volume[3]))(x)\n\n    #Recostructing the image with a decoder model\n    for f in filters[::-1]:\n      x = Conv2DTranspose(f, (3, 3), strides=2, padding=\"same\")(x)\n      x = LeakyReLU(alpha=0.3)(x)\n      x = BatchNormalization(axis=chanDim)(x)\n\n    x = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n\n    outputs = Activation(\"sigmoid\")(x)\n\n    decoder = Model(latent_layer_input, outputs, name=\"decoder\")\n\n    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n\n    return (encoder, decoder, autoencoder)\n```", "```py\nepochs = 50\nlr_start = 0.001\nbatchSize = 32\n\n(encoder, decoder, autoencoder) = Convolution_Autoencoder.build(256, 256, 3)\nopt = tf.keras.optimizers.legacy.Adam(lr = lr_start, decay = lr_start / epochs)\nautoencoder.compile(loss = \"mse\", optimizer = opt)\n```", "```py\nautoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n```", "```py\nhistory = autoencoder.fit(\n train_x, train_x,\n validation_data=(test_x, test_x),\n epochs=30,\n batch_size=batchSize)\n```", "```py\nEpoch 1/30\n26/26 [==============================] - 15s 157ms/step - loss: 12963.2842 - val_loss: 13428.3906\nEpoch 2/30\n26/26 [==============================] - 2s 87ms/step - loss: 12924.1787 - val_loss: 13392.3418\nEpoch 3/30\n26/26 [==============================] - 2s 88ms/step - loss: 12911.4551 - val_loss: 13401.3350\nEpoch 4/30\n26/26 [==============================] - 2s 92ms/step - loss: 12905.8975 - val_loss: 13344.5596\n...\n...\nEpoch 27/30\n26/26 [==============================] - 2s 89ms/step - loss: 12890.9102 - val_loss: 13322.1299\nEpoch 28/30\n26/26 [==============================] - 2s 89ms/step - loss: 12890.8701 - val_loss: 13322.0820\nEpoch 29/30\n26/26 [==============================] - 2s 89ms/step - loss: 12890.8428 - val_loss: 13322.0488\n```", "```py\ndecoded = autoencoder.predict(test_x)\nerrors = []\n\nfor (image, recon) in zip(total_images, decoded):\n  mse = np.mean((image - recon) ** 2)\n  errors.append(mse)\n```", "```py\nthresh = np.quantile(errors, 0.95)\nidxs = np.where(np.array(errors) >= thresh)[0]\nidxs\n```", "```py\narray([  9,  10,  35,  59,  84, 134, 146, 188, 200, 201, 202])\n```", "```py\nfor i in idxs:\n  if total_images[i] in images_anomaly:\n    print(True)\n```", "```py\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n```", "```py\nlen(images_anomaly)\n```", "```py\n11\n```"]