- en: How to Write Expert Prompts for ChatGPT (GPT-4) and Other Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä¸ºChatGPTï¼ˆGPT-4ï¼‰å’Œå…¶ä»–è¯­è¨€æ¨¡å‹ç¼–å†™ä¸“å®¶æç¤º
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550](https://towardsdatascience.com/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550](https://towardsdatascience.com/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550)
- en: A beginner-friendly guide to prompt engineering with LLMs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸LLMsä¸€èµ·è¿›è¡Œæç¤ºå·¥ç¨‹çš„é€‚åˆåˆå­¦è€…çš„æŒ‡å—
- en: '[](https://nabil-alouani.medium.com/?source=post_page-----23133dc85550--------------------------------)[![Nabil
    Alouani](../Images/8ceea018e9b15413d318bfb710bb0011.png)](https://nabil-alouani.medium.com/?source=post_page-----23133dc85550--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23133dc85550--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23133dc85550--------------------------------)
    [Nabil Alouani](https://nabil-alouani.medium.com/?source=post_page-----23133dc85550--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://nabil-alouani.medium.com/?source=post_page-----23133dc85550--------------------------------)[![Nabil
    Alouani](../Images/8ceea018e9b15413d318bfb710bb0011.png)](https://nabil-alouani.medium.com/?source=post_page-----23133dc85550--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23133dc85550--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23133dc85550--------------------------------)
    [Nabil Alouani](https://nabil-alouani.medium.com/?source=post_page-----23133dc85550--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----23133dc85550--------------------------------)
    Â·63 min readÂ·Nov 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨åœ¨[Towards Data Science](https://towardsdatascience.com/?source=post_page-----23133dc85550--------------------------------)
    Â·é˜…è¯»63åˆ†é’ŸÂ·2023å¹´11æœˆ1æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1d2088f1c56684c0f65cee8b56f3ca2d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d2088f1c56684c0f65cee8b56f3ca2d.png)'
- en: Image by author via Midjourney.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…é€šè¿‡Midjourneyæä¾›çš„å›¾ç‰‡ã€‚
- en: Prompt Engineering is a fancy way to say, â€œWrite better and better instructions
    for an AI model until it does exactly what you want.â€
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå·¥ç¨‹æ˜¯ä¸€ç§èŠ±å“¨çš„è¯´æ³•ï¼Œæ„æ€æ˜¯â€œä¸ºAIæ¨¡å‹ç¼–å†™æ›´å¥½çš„æŒ‡ä»¤ï¼Œç›´åˆ°å®ƒå®Œå…¨æŒ‰ç…§ä½ çš„è¦æ±‚æ‰§è¡Œâ€ã€‚
- en: Writing prompts is a bit like riding a bike. You donâ€™t need a Ph.D. in mechanical
    physics to learn how to keep your balance. A bit of theory can help but the most
    important part is trial and error.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–å†™æç¤ºæœ‰ç‚¹åƒéª‘è‡ªè¡Œè½¦ã€‚ä½ ä¸éœ€è¦åœ¨æœºæ¢°ç‰©ç†å­¦ä¸Šæœ‰åšå£«å­¦ä½æ‰èƒ½å­¦ä¼šä¿æŒå¹³è¡¡ã€‚ä¸€ç‚¹ç†è®ºå¯ä»¥å¸®åŠ©ï¼Œä½†æœ€é‡è¦çš„éƒ¨åˆ†æ˜¯åå¤è¯•éªŒã€‚
- en: Consider this guide as the â€œbit of theoryâ€ that will help you prepare for riding
    the AI bike. Youâ€™ll find a list of techniques illustrated with explanations, examples,
    and templates you can test on your favorite models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æŠŠè¿™ä¸ªæŒ‡å—çœ‹ä½œæ˜¯ä¸ºéª‘AIè‡ªè¡Œè½¦åšå‡†å¤‡çš„â€œä¸€ç‚¹ç†è®ºâ€ã€‚ä½ ä¼šæ‰¾åˆ°ä¸€ç³»åˆ—æŠ€æœ¯ï¼ŒåŒ…æ‹¬è§£é‡Šã€ç¤ºä¾‹å’Œæ¨¡æ¿ï¼Œä½ å¯ä»¥åœ¨ä½ å–œæ¬¢çš„æ¨¡å‹ä¸Šè¿›è¡Œæµ‹è¯•ã€‚
- en: The guide focuses on ChatGPT (GPT-4), but every single technique shared below
    applies to other Large Language Models (LLMs) like Claude and LLaMA.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—ä¾§é‡äºChatGPTï¼ˆGPT-4ï¼‰ï¼Œä½†ä¸‹é¢åˆ†äº«çš„æ¯ä¸€ç§æŠ€æœ¯éƒ½é€‚ç”¨äºå…¶ä»–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¦‚Claudeå’ŒLLaMAã€‚
- en: Table of contents
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç›®å½•
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Disclaimer:'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…è´£å£°æ˜ï¼š
- en: Although this guide is skewed towards ChatGPT, I have no personal interest in
    promoting the product. Iâ€™m not sponsored by OpenAI, Microsoft, or anyone else.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æœ¬æŒ‡å—åå‘äºChatGPTï¼Œä½†æˆ‘å¹¶æ²¡æœ‰ä¸ªäººåˆ©ç›Šæ¥æ¨å¹¿è¿™ä¸ªäº§å“ã€‚æˆ‘æ²¡æœ‰å¾—åˆ°OpenAIã€å¾®è½¯æˆ–å…¶ä»–ä»»ä½•äººçš„èµåŠ©ã€‚
- en: Whatâ€™s in this guide?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæŒ‡å—åŒ…æ‹¬ä»€ä¹ˆå†…å®¹ï¼Ÿ
- en: 'The guide includes seven â€œGood to knowâ€ sections and more than 25 prompt engineering
    techniques. Each section starts with an icon that indicates its type, as shown
    below:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æŒ‡å—åŒ…æ‹¬ä¸ƒä¸ªâ€œå¥½å¥½çŸ¥é“â€éƒ¨åˆ†å’Œè¶…è¿‡25ç§æç¤ºå·¥ç¨‹æŠ€æœ¯ã€‚æ¯ä¸ªéƒ¨åˆ†éƒ½ä»¥ä¸€ä¸ªå›¾æ ‡å¼€å¤´ï¼Œè¡¨ç¤ºå…¶ç±»å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: ğŸ’¡ â€œGood to knowâ€ section.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ’¡ â€œå¥½å¥½çŸ¥é“â€éƒ¨åˆ†ã€‚
- en: ğŸŸ¢ Beginner-friendly technique.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸŸ¢ é€‚åˆåˆå­¦è€…çš„æŠ€æœ¯ã€‚
- en: ğŸŸ¡ Intermediate technique.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸŸ¡ ä¸­çº§æŠ€æœ¯ã€‚
- en: ğŸŸ  Advanced technique.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸŸ  é«˜çº§æŠ€æœ¯ã€‚
- en: â€œGood to knowâ€ sections provide specific points to keep in mind when writing
    prompts. Beginner-friendly techniques can be used right away. Intermediate and
    advanced techniques require preparation and a pinch of patience.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: â€œå¥½å¥½çŸ¥é“â€éƒ¨åˆ†æä¾›äº†åœ¨ç¼–å†™æç¤ºæ—¶è¦è®°ä½çš„å…·ä½“è¦ç‚¹ã€‚é€‚åˆåˆå­¦è€…çš„æŠ€æœ¯å¯ä»¥ç«‹å³ä½¿ç”¨ã€‚ä¸­çº§å’Œé«˜çº§æŠ€æœ¯éœ€è¦å‡†å¤‡å’Œä¸€ç‚¹è€å¿ƒã€‚
- en: All of the techniques discussed in the guide derive from AI research papers
    and first-hand experience. Citations and direct links are available at the end
    of the guide. There are two techniques I (re)named to make them easier to remember.
    They are marked with a star like this*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡å—ä¸­è®¨è®ºçš„æ‰€æœ‰æŠ€æœ¯éƒ½æ¥æºäºAIç ”ç©¶è®ºæ–‡å’Œç¬¬ä¸€æ‰‹ç»éªŒã€‚å¼•ç”¨å’Œç›´æ¥é“¾æ¥å¯åœ¨æŒ‡å—æœ«å°¾æ‰¾åˆ°ã€‚æœ‰ä¸¤ç§æŠ€æœ¯æˆ‘é‡æ–°å‘½åï¼Œä»¥ä¾¿è®°å¿†ã€‚å®ƒä»¬ç”¨æ˜Ÿå·æ ‡è®°ï¼Œå°±åƒè¿™æ ·*ã€‚
- en: 'Each prompt has the following format:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæç¤ºçš„æ ¼å¼å¦‚ä¸‹ï¼š
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Hereâ€™s an example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­ï¼š
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ğŸ’¡ Why should you care about Prompt Engineering?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¡ ä¸ºä»€ä¹ˆä½ åº”è¯¥å…³å¿ƒæç¤ºå·¥ç¨‹ï¼Ÿ
- en: Generative AI continues to make its way into every digital tool we use every
    day â€” like web browsers, social media apps, and even PowerPoint presentations.
    The better Language Models get, the more weâ€™ll use them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIç»§ç»­è¿›å…¥æˆ‘ä»¬æ¯å¤©ä½¿ç”¨çš„æ¯ä¸ªæ•°å­—å·¥å…·ä¸­ï¼Œå¦‚ç½‘ç»œæµè§ˆå™¨ã€ç¤¾äº¤åª’ä½“åº”ç”¨ç”šè‡³PowerPointæ¼”ç¤ºæ–‡ç¨¿ã€‚è¯­è¨€æ¨¡å‹è¶Šå¥½ï¼Œæˆ‘ä»¬å°±ä¼šè¶Šå¤šåœ°ä½¿ç”¨å®ƒä»¬ã€‚
- en: Prompt engineering is the language we use to interact with AI models to achieve
    an increasing number of tasks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå·¥ç¨‹æ˜¯æˆ‘ä»¬ç”¨æ¥ä¸AIæ¨¡å‹äº¤äº’ä»¥å®Œæˆè¶Šæ¥è¶Šå¤šä»»åŠ¡çš„è¯­è¨€ã€‚
- en: Picture the near future as a foreign country. You know youâ€™ll have to live there
    for a couple of years, but you donâ€™t speak the local language. Every time you
    buy groceries, book a trip, or negotiate a deal, you have to hire someone to do
    the talking for you.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æŠŠè¿‘æœŸæœªæ¥æƒ³è±¡æˆä¸€ä¸ªå¤–å›½å›½å®¶ã€‚ä½ çŸ¥é“ä½ å°†åœ¨é‚£é‡Œç”Ÿæ´»å‡ å¹´ï¼Œä½†ä½ ä¸ä¼šè¯´å½“åœ°çš„è¯­è¨€ã€‚æ¯æ¬¡ä½ è´­ä¹°é£Ÿå“ã€é¢„è®¢æ—…è¡Œæˆ–è°ˆåˆ¤äº¤æ˜“æ—¶ï¼Œä½ éƒ½å¿…é¡»é›‡ä½£äººæ¥æ›¿ä½ è¯´è¯ã€‚
- en: It sounds inefficient and unfun, doesnâ€™t it?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¬èµ·æ¥æ•ˆç‡ä½ä¸‹ä¸”ä¸å¥½ç©ï¼Œä¸æ˜¯å—ï¼Ÿ
- en: Now imagine you could learn the local language before you moved to this foreign
    country. Instead of hiring someone who speaks the language of AI, you learn to
    write prompts. Pick the right words and AI will give you what you wantâ€” be it
    emails, code, or monthly reports.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æƒ³è±¡ä¸€ä¸‹ï¼Œåœ¨ä½ æ¬åˆ°è¿™ä¸ªå¤–å›½å›½å®¶ä¹‹å‰ï¼Œä½ å¯ä»¥å­¦ä¹ å½“åœ°çš„è¯­è¨€ã€‚ä¸å…¶é›‡ä½£ä¼šè¯´AIè¯­è¨€çš„äººï¼Œä½ å­¦ä¼šå†™æç¤ºã€‚é€‰æ‹©åˆé€‚çš„è¯è¯­ï¼ŒAIå°†ç»™ä½ æƒ³è¦çš„ä¸œè¥¿â€”â€”æ— è®ºæ˜¯ç”µå­é‚®ä»¶ã€ä»£ç è¿˜æ˜¯æœˆåº¦æŠ¥å‘Šã€‚
- en: But hold on, you may say. Isnâ€™t Prompt Engineering bound to disappear?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ç­‰ç­‰ï¼Œä½ å¯èƒ½ä¼šè¯´ã€‚æç¤ºå·¥ç¨‹ä¸æ˜¯æ³¨å®šè¦æ¶ˆå¤±å—ï¼Ÿ
- en: Probably yes, because the goal is to make it easier for humans to use AI systems.
    Perhaps in the future, messy voice prompts could be enough to create whatever
    crosses your mind. Heck, we may even develop AI that can read your mind in real
    time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½æ˜¯çš„ï¼Œå› ä¸ºç›®æ ‡æ˜¯ä½¿äººç±»æ›´å®¹æ˜“ä½¿ç”¨AIç³»ç»Ÿã€‚ä¹Ÿè®¸åœ¨æœªæ¥ï¼Œæ··ä¹±çš„è¯­éŸ³æç¤ºå°±è¶³ä»¥åˆ›é€ ä½ æƒ³è±¡çš„ä»»ä½•ä¸œè¥¿ã€‚æˆ‘ä»¬ç”šè‡³å¯èƒ½å¼€å‘å‡ºèƒ½å¤Ÿå®æ—¶è¯»å–ä½ çš„æ€ç»´çš„AIã€‚
- en: In these cases, Prompt Engineering becomes a temporary skill. Itâ€™ll become obsolete
    as soon as AI learns to guess human intentions based on half-baked sentences and
    brain signals.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæç¤ºå·¥ç¨‹æˆä¸ºä¸€ç§ä¸´æ—¶æŠ€èƒ½ã€‚ä¸€æ—¦AIèƒ½å¤Ÿæ ¹æ®ä¸å®Œæ•´çš„å¥å­å’Œè„‘ç”µä¿¡å·çŒœæµ‹äººç±»æ„å›¾ï¼Œå®ƒå°†å˜å¾—è¿‡æ—¶ã€‚
- en: You can wait for that to happen, or you can get a headstart.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ç­‰å¾…è¿™ç§æƒ…å†µå‘ç”Ÿï¼Œæˆ–è€…ä½ å¯ä»¥æå‰å¼€å§‹ã€‚
- en: ğŸ’¡ Why is Prompt Engineering harder than you think?
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¡ ä¸ºä»€ä¹ˆæç¤ºå·¥ç¨‹æ¯”ä½ æƒ³è±¡çš„æ›´éš¾ï¼Ÿ
- en: The short answer is â€œan illusion of ease.â€
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€çŸ­çš„ç­”æ¡ˆæ˜¯â€œä¸€ç§è½»æ¾çš„é”™è§‰â€ã€‚
- en: Since we use natural language to write prompts, we donâ€™t see it as a complex
    skill that requires practice. All you have to do is write instructions in plain
    English, right?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬ä½¿ç”¨è‡ªç„¶è¯­è¨€ç¼–å†™æç¤ºï¼Œæˆ‘ä»¬ä¸è®¤ä¸ºå®ƒæ˜¯ä¸€é¡¹éœ€è¦ç»ƒä¹ çš„å¤æ‚æŠ€èƒ½ã€‚ä½ æ‰€è¦åšçš„å°±æ˜¯ç”¨ç®€å•çš„è‹±è¯­å†™å‡ºæŒ‡ä»¤ï¼Œå¯¹å—ï¼Ÿ
- en: Well, not exactly.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œä¸å®Œå…¨æ˜¯è¿™æ ·ã€‚
- en: Yes, when you talk to humans, you prompt them the same way youâ€™d prompt an AI.
    Both humans and AI use inner models to respond to your prompt. Except humans and
    AI systems have different models of reality.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œå½“ä½ ä¸äººç±»äº¤è°ˆæ—¶ï¼Œä½ ä¼šä»¥ä¸æç¤ºAIç›¸åŒçš„æ–¹å¼æç¤ºä»–ä»¬ã€‚äººç±»å’ŒAIéƒ½ä½¿ç”¨å†…éƒ¨æ¨¡å‹æ¥å›åº”ä½ çš„æç¤ºã€‚åªæ˜¯äººç±»å’ŒAIç³»ç»Ÿå¯¹ç°å®æœ‰ä¸åŒçš„æ¨¡å‹ã€‚
- en: The human model draws on cognitive abilities, past experiences, theoretical
    knowledge, and real-time sensory data. Language Models, on the other hand, rely
    solely on language patterns.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: äººç±»æ¨¡å‹ä¾èµ–äºè®¤çŸ¥èƒ½åŠ›ã€è¿‡å»çš„ç»éªŒã€ç†è®ºçŸ¥è¯†å’Œå®æ—¶æ„Ÿå®˜æ•°æ®ã€‚è€Œè¯­è¨€æ¨¡å‹åˆ™ä»…ä¾èµ–äºè¯­è¨€æ¨¡å¼ã€‚
- en: You could say that human software and AI software run on different operating
    systems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è¯´äººç±»è½¯ä»¶å’ŒAIè½¯ä»¶è¿è¡Œåœ¨ä¸åŒçš„æ“ä½œç³»ç»Ÿä¸Šã€‚
- en: So when you interact with a Language Model, itâ€™s as if youâ€™re interacting with
    an alien. Sure the alien responds to your natural language but it doesnâ€™t behave
    the same way a fellow human would â€” which means youâ€™ll have to adapt your prompts.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å½“ä½ ä¸è¯­è¨€æ¨¡å‹äº¤äº’æ—¶ï¼Œå°±å¥½åƒä½ åœ¨ä¸ä¸€ä¸ªå¤–æ˜Ÿäººäº¤äº’ã€‚å½“ç„¶ï¼Œè¿™ä¸ªå¤–æ˜Ÿäººä¼šå›åº”ä½ çš„è‡ªç„¶è¯­è¨€ï¼Œä½†å®ƒçš„è¡Œä¸ºæ–¹å¼ä¸äººç±»ä¸åŒï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦è°ƒæ•´ä½ çš„æç¤ºã€‚
- en: Compared to humans, AI systems require more details, precise explanations, clearer
    instructions, and a bit of repetition. You want to be intentional with each word
    you write â€” almost as if you were writing code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸äººç±»ç›¸æ¯”ï¼ŒAIç³»ç»Ÿéœ€è¦æ›´å¤šç»†èŠ‚ã€ç²¾ç¡®çš„è§£é‡Šã€æ¸…æ™°çš„æŒ‡ç¤ºå’Œä¸€äº›é‡å¤ã€‚ä½ å¸Œæœ›æ¯ä¸ªå†™å‡ºçš„è¯éƒ½æ˜¯æœ‰æ„ä¹‰çš„ï¼Œå°±åƒä½ åœ¨ç¼–å†™ä»£ç ä¸€æ ·ã€‚
- en: The analogy of â€œEnglish as a programming languageâ€ is spot-on until you consider
    one crucial detail. Unlike with code, every single prompt gets a response, regardless
    of its quality. Even prompts that include typos and unclear sentences generate
    *something*. In contrast, incorrect code doesnâ€™t generate anything (except for
    frustrating error messages).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: â€œè‹±è¯­ä½œä¸ºä¸€ç§ç¼–ç¨‹è¯­è¨€â€çš„ç±»æ¯”åœ¨è€ƒè™‘ä¸€ä¸ªè‡³å…³é‡è¦çš„ç»†èŠ‚ä¹‹å‰æ˜¯å®Œç¾çš„ã€‚ä¸ä»£ç ä¸åŒï¼Œæ¯ä¸ªæç¤ºéƒ½ä¼šå¾—åˆ°å›åº”ï¼Œæ— è®ºå…¶è´¨é‡å¦‚ä½•ã€‚å³ä½¿åŒ…å«æ‹¼å†™é”™è¯¯å’Œä¸æ¸…æ™°å¥å­çš„æç¤ºä¹Ÿä¼šäº§ç”Ÿ*æŸç§ä¸œè¥¿*ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¸æ­£ç¡®çš„ä»£ç ä¸ä¼šäº§ç”Ÿä»»ä½•ä¸œè¥¿ï¼ˆé™¤äº†ä»¤äººæ²®ä¸§çš„é”™è¯¯æ¶ˆæ¯ï¼‰ã€‚
- en: This always-generate-something property makes the illusion of ease even stronger.
    Messy prompts produce results, so why bother improving them?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ€»æ˜¯äº§ç”Ÿç»“æœçš„ç‰¹æ€§ä½¿å¾—è½»æ¾çš„é”™è§‰æ›´åŠ å¼ºçƒˆã€‚æ··ä¹±çš„æç¤ºä¹Ÿä¼šäº§ç”Ÿç»“æœï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆè¦è´¹å¿ƒæ”¹è¿›å®ƒä»¬å‘¢ï¼Ÿ
- en: Casual AI users donâ€™t feel the need to work on their prompt engineering skills,
    so they mistakenly believe itâ€™s an easy feat.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬çš„AIç”¨æˆ·ä¸è§‰å¾—æœ‰å¿…è¦æé«˜ä»–ä»¬çš„æç¤ºå·¥ç¨‹æŠ€èƒ½ï¼Œæ‰€ä»¥ä»–ä»¬é”™è¯¯åœ°è®¤ä¸ºè¿™æ˜¯ä¸€ä»¶å®¹æ˜“çš„äº‹æƒ…ã€‚
- en: In a way, prompt engineering is like dancing. You watch a tutorial on TikTok
    where a professional dancer demonstrates a few hip-hop steps and you think â€œOh
    this is actually easy!â€
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œæç¤ºå·¥ç¨‹å°±åƒè·³èˆã€‚ä½ åœ¨TikTokä¸Šçœ‹äº†ä¸€ä¸ªä¸“ä¸šèˆè€…æ¼”ç¤ºäº†ä¸€äº›å˜»å“ˆèˆæ­¥çš„æ•™ç¨‹ï¼Œä½ ä¼šè§‰å¾—â€œå“¦ï¼Œè¿™å…¶å®å¾ˆå®¹æ˜“ï¼â€
- en: Notice how easy this move looks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„è¿™ä¸€ä¸¾åŠ¨çœ‹èµ·æ¥å¤šä¹ˆå®¹æ˜“ã€‚
- en: But once you try to reproduce those very same â€œeasy steps,â€ you realize your
    body has its own laws of physics. All of a sudden, moving sideways while bouncing
    your body and waving your arms seems impossible.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä¸€æ—¦ä½ å°è¯•é‡ç°é‚£äº›â€œå®¹æ˜“çš„æ­¥éª¤â€ï¼Œä½ ä¼šæ„è¯†åˆ°ä½ çš„èº«ä½“æœ‰è‡ªå·±çš„ç‰©ç†è§„å¾‹ã€‚çªç„¶é—´ï¼Œä¸€è¾¹ç§»åŠ¨èº«ä½“ï¼Œä¸€è¾¹æŒ¥èˆç€æ‰‹è‡‚ä¼¼ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚
- en: Just like dancing, Prompt Engineering is harder than it looks, but it gets easier
    with every prompt you write.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒè·³èˆä¸€æ ·ï¼Œæç¤ºå·¥ç¨‹æ¯”çœ‹èµ·æ¥æ›´éš¾ï¼Œä½†æ¯å†™ä¸€ä¸ªæç¤ºéƒ½ä¼šå˜å¾—æ›´å®¹æ˜“ã€‚
- en: ğŸ’¡ You donâ€™t need prompt ideas, you need problems
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¡ ä½ ä¸éœ€è¦æç¤ºçš„æƒ³æ³•ï¼Œä½ éœ€è¦é—®é¢˜
- en: 'The best prompts come from good ideas, and good ideas are born from interesting
    problems. Hereâ€™s a simple framework you can use to find problems worth solving:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¥½çš„æç¤ºæ¥è‡ªå¥½çš„æƒ³æ³•ï¼Œè€Œå¥½çš„æƒ³æ³•æºäºæœ‰è¶£çš„é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„æ¡†æ¶ï¼Œä½ å¯ä»¥ç”¨å®ƒæ¥æ‰¾åˆ°å€¼å¾—è§£å†³çš„é—®é¢˜ï¼š
- en: List all the tasks you carry out on a computer (for work or otherwise).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ—å‡ºä½ åœ¨è®¡ç®—æœºä¸Šè¿›è¡Œçš„æ‰€æœ‰ä»»åŠ¡ï¼ˆå·¥ä½œæˆ–å…¶ä»–ï¼‰ã€‚
- en: Isolate the tasks that require text analysis and/or writing.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç¦»éœ€è¦æ–‡æœ¬åˆ†æå’Œ/æˆ–æ’°å†™çš„ä»»åŠ¡ã€‚
- en: Describe the results you want to achieve from each task.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æè¿°ä½ å¸Œæœ›ä»æ¯ä¸ªä»»åŠ¡ä¸­å®ç°çš„ç»“æœã€‚
- en: '**Example of a useful problem:** â€œEvery Monday, I file a performance report
    to my client for each advertisement I ran the week before. I need to comment on
    every Key Performance Indicator (KPI) to make the data easier to understand by
    non-experts.â€'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ‰ç”¨é—®é¢˜çš„ä¾‹å­ï¼š** â€œæ¯ä¸ªæ˜ŸæœŸä¸€ï¼Œæˆ‘å‘å®¢æˆ·æäº¤ä¸Šå‘¨è¿è¡Œçš„æ¯ä¸ªå¹¿å‘Šçš„ç»©æ•ˆæŠ¥å‘Šã€‚æˆ‘éœ€è¦è¯„è®ºæ¯ä¸ªå…³é”®ç»©æ•ˆæŒ‡æ ‡ï¼ˆKPIï¼‰ï¼Œä»¥ä¾¿éä¸“ä¸šäººå£«æ›´å®¹æ˜“ç†è§£æ•°æ®ã€‚â€'
- en: '**How prompting can help:** Write a prompt that comments on each KPI you submit.
    Ask your AI model to use storytelling techniques and fun analogies to make the
    report lighter and more accessible.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**æç¤ºå¦‚ä½•å¸®åŠ©ï¼š** æ’°å†™æ¯ä¸ªæäº¤çš„KPIçš„æç¤ºã€‚è¦æ±‚ä½ çš„AIæ¨¡å‹ä½¿ç”¨è®²æ•…äº‹çš„æŠ€å·§å’Œæœ‰è¶£çš„ç±»æ¯”ï¼Œä½¿æŠ¥å‘Šæ›´è½»æ¾æ˜“æ‡‚ã€‚'
- en: ğŸ’¡ Watch out for AI hallucinations
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¡ å°å¿ƒAIå¹»è§‰
- en: Whatever the model you pick, remember that chatbots often hallucinate, writing
    information thatâ€™s factually wrong. This behavior stems from LLMs being trained
    on giant datasets filled with logical errors and nonsense.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºä½ é€‰æ‹©å“ªç§æ¨¡å‹ï¼Œè®°ä½èŠå¤©æœºå™¨äººç»å¸¸ä¼šäº§ç”Ÿå¹»è§‰ï¼Œå†™å‡ºäº‹å®é”™è¯¯çš„ä¿¡æ¯ã€‚è¿™ç§è¡Œä¸ºæºè‡ªLLMsåœ¨å·¨å¤§çš„æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œè¿™äº›æ•°æ®é›†å……æ»¡äº†é€»è¾‘é”™è¯¯å’Œèƒ¡è¨€ä¹±è¯­ã€‚
- en: Fine-tuning and Reinforcement Learning based on Human Feedback (RLHF) helps
    LLMs reduce inaccuracies and bias, but there are still loopholes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºäººç±»åé¦ˆçš„å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æœ‰åŠ©äºLLMså‡å°‘ä¸å‡†ç¡®æ€§å’Œåè§ï¼Œä½†ä»ç„¶å­˜åœ¨æ¼æ´ã€‚
- en: 'I took a few swings on the hallucination problem in other pieces. Youâ€™ll find
    the links below. For now, hereâ€™s a sneak peek:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨å…¶ä»–æ–‡ç« ä¸­å·²ç»å¯¹å¹»è§‰é—®é¢˜è¿›è¡Œäº†ä¸€äº›å°è¯•ã€‚ä½ å¯ä»¥åœ¨ä¸‹é¢æ‰¾åˆ°é“¾æ¥ã€‚ç°åœ¨ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªé¢„è§ˆï¼š
- en: You may think chatbots tell the truth by default, and sometimes, they happen
    to hallucinate. But itâ€™s more accurate to say chatbots write pure bullshit that
    sometimes matches reality.
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½è®¤ä¸ºèŠå¤©æœºå™¨äººé»˜è®¤ä¼šè¯´å®è¯ï¼Œæœ‰æ—¶å€™ä»–ä»¬ä¼šäº§ç”Ÿå¹»è§‰ã€‚ä½†æ›´å‡†ç¡®åœ°è¯´ï¼ŒèŠå¤©æœºå™¨äººå†™å‡ºçº¯ç²¹çš„èƒ¡è¯´å…«é“ï¼Œæœ‰æ—¶å€™ä¸ç°å®ç›¸åŒ¹é…ã€‚
- en: ''
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By â€œbullshit,â€ I donâ€™t mean the slang we use to describe nonsense, but a philosophical
    definition brought by Harry Frankfurt.
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é€šè¿‡â€œèƒ¡è¯´å…«é“â€ï¼Œæˆ‘ä¸æ˜¯æŒ‡æˆ‘ä»¬ç”¨æ¥æè¿°æ— æ„ä¹‰çš„ä¿šè¯­ï¼Œè€Œæ˜¯å“ˆé‡ŒÂ·å¼—å…°å…‹ç¦æå‡ºçš„ä¸€ä¸ªå“²å­¦å®šä¹‰ã€‚
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Harry Frankfurt described bullshit as information that has no relationship to
    reality. When you lie, you distort reality. When you tell the truth, you describe
    your representation of reality. But when you bullshit, you make things up with
    no consideration of what reality might be like.
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å“ˆé‡ŒÂ·å¼—å…°å…‹ç¦ç‰¹å°†èƒ¡è¯´å…«é“æè¿°ä¸ºä¸ç°å®æ²¡æœ‰å…³ç³»çš„ä¿¡æ¯ã€‚å½“ä½ æ’’è°æ—¶ï¼Œä½ æ‰­æ›²äº†ç°å®ã€‚å½“ä½ è¯´çœŸè¯æ—¶ï¼Œä½ æè¿°äº†ä½ å¯¹ç°å®çš„è¡¨è¾¾ã€‚ä½†æ˜¯å½“ä½ èƒ¡è¯´å…«é“æ—¶ï¼Œä½ ç¼–é€ äº†ä¸€äº›ä¸ç°å®æ— å…³çš„ä¸œè¥¿ã€‚
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*â€œIt is just this lack of connection to a concern with truth â€”* ***this indifference
    to how things really are*** *â€” that I regard as of the essence of bullshit.*'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*â€œæ­£æ˜¯è¿™ç§ä¸çœŸç›¸å…³è”çš„ç¼ºä¹è¿æ¥â€”â€”* ***å¯¹äº‹ç‰©çœŸå®æƒ…å†µçš„æ¼ ä¸å…³å¿ƒ*** *â€”â€”æˆ‘è®¤ä¸ºæ˜¯èƒ¡è¯´å…«é“çš„æœ¬è´¨ã€‚â€*'
- en: ''
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This points to a similar and fundamental aspect of the essential nature of
    bullshit:* ***although it is produced without concern with the truth, it need
    not be false****.â€*'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*è¿™æŒ‡å‘äº†èƒ¡è¯´å…«é“çš„ä¸€ä¸ªç±»ä¼¼è€ŒåŸºæœ¬çš„æ–¹é¢ï¼š* ***å°½ç®¡å®ƒæ˜¯åœ¨ä¸å…³å¿ƒçœŸç›¸çš„æƒ…å†µä¸‹äº§ç”Ÿçš„ï¼Œä½†å®ƒä¸ä¸€å®šæ˜¯é”™è¯¯çš„****ã€‚â€*'
- en: ''
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*â€”* [*On Bullshit by Harry Frankfurt*](https://www.goodreads.com/author/quotes/219.Harry_G_Frankfurt)
    *[Emphasis mine].*'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*â€”* [*ã€Šèƒ¡è¯´å…«é“ã€‹å“ˆé‡ŒÂ·å¼—å…°å…‹ç¦ç‰¹è‘—*](https://www.goodreads.com/author/quotes/219.Harry_G_Frankfurt)
    *[Emphasis mine].*'
- en: Language Models are highly-plausible bullshitters that often land on truth,
    so you canâ€™t fully trust them. You must fact-check their outputs, especially when
    dealing with non-fiction.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¯­è¨€æ¨¡å‹æ˜¯é«˜åº¦å¯ä¿¡çš„èƒ¡è¯´å…«é“è€…ï¼Œé€šå¸¸èƒ½å¤Ÿæ¥è¿‘çœŸç›¸ï¼Œå› æ­¤ä½ ä¸èƒ½å®Œå…¨ä¿¡ä»»å®ƒä»¬ã€‚åœ¨å¤„ç†éè™šæ„å†…å®¹æ—¶ï¼Œä½ å¿…é¡»å¯¹å®ƒä»¬çš„è¾“å‡ºè¿›è¡Œäº‹å®æ ¸æŸ¥ã€‚
- en: '[](https://nabilalouani.substack.com/p/artificial-disinformation-can-chatbots?source=post_page-----23133dc85550--------------------------------)
    [## Artificial Disinformation: Can Chatbots Destroy Trust on the Internet?'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://nabilalouani.substack.com/p/artificial-disinformation-can-chatbots?source=post_page-----23133dc85550--------------------------------)
    [## äººå·¥è™šå‡ä¿¡æ¯ï¼šèŠå¤©æœºå™¨äººèƒ½ç ´åäº’è”ç½‘ä¸Šçš„ä¿¡ä»»å—ï¼Ÿ'
- en: Soon after ChatGPT came out, a clock started ticking inside my head. It's like
    when you see a bolt of lightning sliceâ€¦
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ChatGPTå‘å¸ƒåä¸ä¹…ï¼Œæˆ‘è„‘æµ·ä¸­å¼€å§‹å€’è®¡æ—¶ã€‚å°±åƒå½“ä½ çœ‹åˆ°ä¸€é“é—ªç”µåˆ’è¿‡æ—¶...
- en: nabilalouani.substack.com](https://nabilalouani.substack.com/p/artificial-disinformation-can-chatbots?source=post_page-----23133dc85550--------------------------------)
    [](https://nabilalouani.substack.com/p/chatgpt-hype-is-proof-nobody-really?source=post_page-----23133dc85550--------------------------------)
    [## ChatGPT Hype is Proof Nobody Really Understands AI
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: nabilalouani.substack.com](https://nabilalouani.substack.com/p/artificial-disinformation-can-chatbots?source=post_page-----23133dc85550--------------------------------)
    [](https://nabilalouani.substack.com/p/chatgpt-hype-is-proof-nobody-really?source=post_page-----23133dc85550--------------------------------)
    [## èŠå¤©GPTçš„ç‚’ä½œè¯æ˜æ²¡æœ‰äººçœŸæ­£ç†è§£äººå·¥æ™ºèƒ½
- en: Large Language Models are dumber than your neighbor's cat
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹æ¯”ä½ é‚»å±…çš„çŒ«æ›´ç¬¨
- en: nabilalouani.substack.com](https://nabilalouani.substack.com/p/chatgpt-hype-is-proof-nobody-really?source=post_page-----23133dc85550--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: nabilalouani.substack.com](https://nabilalouani.substack.com/p/chatgpt-hype-is-proof-nobody-really?source=post_page-----23133dc85550--------------------------------)
- en: ğŸŸ¢ The Basics of Prompting
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ æç¤ºçš„åŸºç¡€çŸ¥è¯†
- en: Each prompt is a bridge between what you want and what your Language Model generates.
    The shape of your bridge depends on the problem you want to solve, but the underlying
    structure remains the same.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæç¤ºéƒ½æ˜¯ä½ æƒ³è¦è§£å†³çš„é—®é¢˜å’Œä½ çš„è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ä¹‹é—´çš„æ¡¥æ¢ã€‚ä½ çš„æ¡¥çš„å½¢çŠ¶å–å†³äºä½ æƒ³è¦è§£å†³çš„é—®é¢˜ï¼Œä½†åŸºæœ¬ç»“æ„ä¿æŒä¸å˜ã€‚
- en: 'Picture this structure as six pillars:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹è¿™ä¸ªç»“æ„å°±åƒæ˜¯å…­æ ¹æŸ±å­ï¼š
- en: Be specific.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦å…·ä½“æ˜ç¡®ã€‚
- en: Use placeholders <like_this> to build flexible templates. (More on this in a
    dedicated section).
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å ä½ç¬¦<like_this>æ„å»ºçµæ´»çš„æ¨¡æ¿ã€‚ï¼ˆåœ¨ä¸“é—¨çš„éƒ¨åˆ†ä¸­è¯¦ç»†ä»‹ç»ï¼‰ã€‚
- en: Prioritize **what to do** over what not to do.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¼˜å…ˆè€ƒè™‘**è¦åšä»€ä¹ˆ**è€Œä¸æ˜¯ä¸è¦åšä»€ä¹ˆã€‚
- en: Specify the desired format of the output. (More on this in a dedicated section).
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å®šæ‰€éœ€è¾“å‡ºçš„æ ¼å¼ã€‚ï¼ˆåœ¨ä¸“é—¨çš„éƒ¨åˆ†ä¸­è¯¦ç»†ä»‹ç»ï¼‰ã€‚
- en: 'Use double hashtags like this ## to separate different parts of your prompt.
    A prompt can include instructions, examples, and the desired format.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŒäº•å·ï¼ˆ##ï¼‰æ¥åˆ†éš”æç¤ºçš„ä¸åŒéƒ¨åˆ†ã€‚æç¤ºå¯ä»¥åŒ…æ‹¬è¯´æ˜ã€ç¤ºä¾‹å’Œæ‰€éœ€æ ¼å¼ã€‚
- en: Revise your prompt to remove the fluff.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¿®æ”¹ä½ çš„æç¤ºä»¥å»é™¤åºŸè¯ã€‚
- en: 'Hereâ€™s an example:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªä¾‹å­ï¼š
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ğŸŸ¢ Specify the context (also called â€œPrimingâ€)
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ æŒ‡å®šä¸Šä¸‹æ–‡ï¼ˆä¹Ÿç§°ä¸ºâ€œå¯åŠ¨â€ï¼‰
- en: For each question you write, your Large Language Model can generate thousands
    of different answers. When you provide context, you help your LLM narrow down
    the range of possible outcomes.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä½ å†™çš„æ¯ä¸ªé—®é¢˜ï¼Œä½ çš„å¤§å‹è¯­è¨€æ¨¡å‹å¯ä»¥ç”Ÿæˆæˆåƒä¸Šä¸‡ä¸ªä¸åŒçš„ç­”æ¡ˆã€‚å½“ä½ æä¾›ä¸Šä¸‹æ–‡æ—¶ï¼Œä½ å¸®åŠ©ä½ çš„LLMç¼©å°äº†å¯èƒ½ç»“æœçš„èŒƒå›´ã€‚
- en: Say you want a non-boring meal plan for the upcoming week. Adding your diet
    restrictions and personal preferences makes it more likely to get relevant suggestions
    for every single meal.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ æƒ³è¦ä¸€ä¸ªå³å°†åˆ°æ¥çš„ä¸€å‘¨ä¸­ä¸æ— èŠçš„é¥®é£Ÿè®¡åˆ’ã€‚æ·»åŠ ä½ çš„é¥®é£Ÿé™åˆ¶å’Œä¸ªäººåå¥½å¯ä»¥æ›´æœ‰å¯èƒ½è·å¾—æ¯é¤ç›¸å…³çš„å»ºè®®ã€‚
- en: There are multiple ways you can introduce context into your prompt. Itâ€™s like
    mentally preparing your Language Model for the task, hence the name â€œPriming.â€
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å¤šç§æ–¹å¼å¯ä»¥åœ¨æç¤ºä¸­å¼•å…¥ä¸Šä¸‹æ–‡ã€‚è¿™å°±åƒæ˜¯ä¸ºä»»åŠ¡åšå¿ƒç†å‡†å¤‡ï¼Œå› æ­¤è¢«ç§°ä¸ºâ€œå¯åŠ¨â€ã€‚
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ğŸŸ¢ Specify the desired format
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ æŒ‡å®šæ‰€éœ€æ ¼å¼
- en: This one is straightforward. All you have to do is add a sentence to your prompt
    where you describe the format you want.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå¾ˆç®€å•ã€‚ä½ åªéœ€è¦åœ¨æç¤ºä¸­æ·»åŠ ä¸€å¥æè¿°æ‰€éœ€æ ¼å¼çš„å¥å­ã€‚
- en: 'Hereâ€™s a list you can draw from:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªä½ å¯ä»¥å‚è€ƒçš„åˆ—è¡¨ï¼š
- en: Bullet-points;
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®€è¦è¯´æ˜ï¼›
- en: Articles and blog posts;
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–‡ç« å’Œåšå®¢æ–‡ç« ï¼›
- en: Essays and research papers;
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®ºæ–‡å’Œç ”ç©¶è®ºæ–‡ï¼›
- en: Short stories and creative writing pieces;
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çŸ­ç¯‡å°è¯´å’Œåˆ›æ„å†™ä½œä½œå“ï¼›
- en: Poems and song lyrics;
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯—æ­Œå’Œæ­Œè¯ï¼›
- en: Newsletters and press releases;
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè®¯å’Œæ–°é—»ç¨¿ï¼›
- en: Social media posts and captions;
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¤¾äº¤åª’ä½“å¸–å­å’Œæ ‡é¢˜ï¼›
- en: Advertisements and marketing copy;
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹¿å‘Šå’Œè¥é”€æ–‡æ¡ˆï¼›
- en: Email templates and business correspondence;
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”µå­é‚®ä»¶æ¨¡æ¿å’Œå•†åŠ¡å¾€æ¥ï¼›
- en: Product descriptions and reviews;
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº§å“æè¿°å’Œè¯„è®ºï¼›
- en: Tutorials and how-to guides;
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•™ç¨‹å’ŒæŒ‡å—ï¼›
- en: Frequently Asked Questions (FAQs);
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸¸è§é—®é¢˜è§£ç­”ï¼ˆFAQï¼‰ï¼›
- en: Transcripts and interviews;
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®°å½•å’Œé‡‡è®¿ï¼›
- en: Reports and memos;
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŠ¥å‘Šå’Œå¤‡å¿˜å½•ï¼›
- en: Screenplays and scripts for plays or podcasts;
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”µå½±å‰§æœ¬å’Œæˆå‰§æˆ–æ’­å®¢è„šæœ¬ï¼›
- en: Speeches and presentations;
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¼”è®²å’Œå±•ç¤ºï¼›
- en: Summaries and abstracts;
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‘˜è¦å’Œæ¦‚è¿°ï¼›
- en: Technical documentation and manuals;
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŠ€æœ¯æ–‡æ¡£å’Œæ‰‹å†Œï¼›
- en: Educational materials, such as lesson plans or course syllabi;
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•™è‚²ææ–™ï¼Œå¦‚æ•™æ¡ˆæˆ–è¯¾ç¨‹å¤§çº²ï¼›
- en: Opinion pieces and editorials;
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§‚ç‚¹æ–‡ç« å’Œç¤¾è®ºï¼›
- en: Personal statements, cover letters, and resumes.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ªäººé™ˆè¿°ã€æ±‚èŒä¿¡å’Œç®€å†ã€‚
- en: 'Below are three examples of how to introduce format inside a basic prompt:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨åŸºæœ¬æç¤ºä¸­å¼•å…¥æ ¼å¼çš„ä¸‰ä¸ªç¤ºä¾‹ï¼š
- en: '[PRE5]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Note:** if you use a non-specialized Language Model to generate legal contracts,
    make sure you run them by legal experts.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š**å¦‚æœä½ ä½¿ç”¨éä¸“ä¸šçš„è¯­è¨€æ¨¡å‹ç”Ÿæˆæ³•å¾‹åˆåŒï¼Œè¯·ç¡®ä¿è¯·æ³•å¾‹ä¸“å®¶å®¡æ ¸ã€‚'
- en: ğŸŸ¢ Use <placeholders>
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ ä½¿ç”¨<å ä½ç¬¦>
- en: Placeholders <like_this> help you achieve two separate goals.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: <åƒè¿™æ ·çš„>å ä½ç¬¦å¯ä»¥å¸®åŠ©ä½ å®ç°ä¸¤ä¸ªç‹¬ç«‹çš„ç›®æ ‡ã€‚
- en: Use <placeholders> to write flexible prompts that can take different inputs.
    You have to indicate the content of each placeholder in your prompt. In this case,
    **a placeholder is a parameter.**
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨<å ä½ç¬¦>ç¼–å†™çµæ´»çš„æç¤ºï¼Œå¯ä»¥æ¥å—ä¸åŒçš„è¾“å…¥ã€‚ä½ å¿…é¡»åœ¨æç¤ºä¸­æŒ‡ç¤ºæ¯ä¸ªå ä½ç¬¦çš„å†…å®¹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ**å ä½ç¬¦æ˜¯ä¸€ä¸ªå‚æ•°**ã€‚
- en: Use empty <placeholders> to illustrate the desired format. Here you donâ€™t have
    to write the content of each placeholder. Your LLM will guess what each placeholder
    stands for, especially when you use known frameworks like User Stories or cover
    letters. In this case, **a placeholder is an instruction.**
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç©ºçš„<å ä½ç¬¦>æ¥è¯´æ˜æ‰€éœ€æ ¼å¼ã€‚åœ¨è¿™é‡Œï¼Œä½ ä¸éœ€è¦ç¼–å†™æ¯ä¸ªå ä½ç¬¦çš„å†…å®¹ã€‚ä½ çš„LLMä¼šçŒœæµ‹æ¯ä¸ªå ä½ç¬¦ä»£è¡¨ä»€ä¹ˆï¼Œç‰¹åˆ«æ˜¯å½“ä½ ä½¿ç”¨åƒç”¨æˆ·æ•…äº‹æˆ–æ±‚èŒä¿¡è¿™æ ·çš„å·²çŸ¥æ¡†æ¶æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ**å ä½ç¬¦æ˜¯ä¸€æ¡æŒ‡ä»¤**ã€‚
- en: ğŸŸ¢ How to use placeholders as parameters
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸŸ¢ å¦‚ä½•å°†å ä½ç¬¦ç”¨ä½œå‚æ•°
- en: '[PRE6]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ğŸŸ¢ How to use placeholders as instructions
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸŸ¢ å¦‚ä½•å°†å ä½ç¬¦ç”¨ä½œæŒ‡ä»¤
- en: '[PRE7]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ğŸŸ¢ Specify the style/tone
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ æŒ‡å®šé£æ ¼/è¯­æ°”
- en: Each chatbot has a default style defined by its creators. For instance, ChatGPT
    sounds friendly and nuanced, but you can ask it to change its tone to fit your
    preferences and needs.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªèŠå¤©æœºå™¨äººéƒ½æœ‰ä¸€ä¸ªé»˜è®¤çš„é£æ ¼ï¼Œç”±å…¶åˆ›å»ºè€…å®šä¹‰ã€‚ä¾‹å¦‚ï¼ŒChatGPTå¬èµ·æ¥å‹å¥½è€Œç»†è‡´ï¼Œä½†ä½ å¯ä»¥è¦æ±‚å®ƒæ”¹å˜è¯­æ°”ä»¥é€‚åº”ä½ çš„åå¥½å’Œéœ€æ±‚ã€‚
- en: You can even ask your Language Model to mimic the tone of a fictional/real person.
    Usually, the result is an over-the-top parody of whoever ChatGPT tries to emulate.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç”šè‡³å¯ä»¥è¦æ±‚ä½ çš„è¯­è¨€æ¨¡å‹æ¨¡ä»¿ä¸€ä¸ªè™šæ„/çœŸå®äººç‰©çš„è¯­æ°”ã€‚é€šå¸¸ï¼Œç»“æœæ˜¯ChatGPTè¯•å›¾æ¨¡ä»¿çš„äººçš„å¤¸å¼ æ¨¡ä»¿ã€‚
- en: 'Here are a few examples of styles you can pick from:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€äº›ä½ å¯ä»¥é€‰æ‹©çš„é£æ ¼ç¤ºä¾‹ï¼š
- en: '**Generic styles:** formal, informal, persuasive, conversational, sarcastic,
    dramatic, condescending, nuanced, biased, humorous, optimistic, pessimistic, etc.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é€šç”¨é£æ ¼ï¼š**æ­£å¼ã€éæ­£å¼ã€æœ‰è¯´æœåŠ›çš„ã€å¯¹è¯å¼çš„ã€è®½åˆºçš„ã€æˆå‰§æ€§çš„ã€å±…é«˜ä¸´ä¸‹çš„ã€ç»†å¾®çš„ã€æœ‰åè§çš„ã€å¹½é»˜çš„ã€ä¹è§‚çš„ã€æ‚²è§‚çš„ç­‰ã€‚'
- en: '**Domain-specific styles:** academic, legal, political, technical, medical,
    news, scientific, marketing, creative, instructional, etc.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é¢†åŸŸç‰¹å®šé£æ ¼ï¼š**å­¦æœ¯ã€æ³•å¾‹ã€æ”¿æ²»ã€æŠ€æœ¯ã€åŒ»å­¦ã€æ–°é—»ã€ç§‘å­¦ã€è¥é”€ã€åˆ›æ„ã€æ•™å­¦ç­‰ã€‚'
- en: '**Mimicking the style of a real person:** Agatha Christie, Daniel Kahneman,
    J.K Rowling, James Baldwin, Hajime Isayama, etc.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡ä»¿çœŸå®äººç‰©çš„é£æ ¼ï¼š**é˜¿åŠ èÂ·å…‹é‡Œæ–¯è’‚ã€ä¸¹å°¼å°”Â·å¡å°¼æ›¼ã€J.K.ç½—ç³ã€è©¹å§†æ–¯Â·é²å¾·æ¸©ã€è««å±±å‰µç­‰ã€‚'
- en: 'Hereâ€™s how you can specify the style in a prompt:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨æç¤ºä¸­æŒ‡å®šé£æ ¼çš„ç¤ºä¾‹ï¼š
- en: '[PRE8]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ğŸŸ¢ Specify the length of the desired response
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ æŒ‡å®šæ‰€éœ€å“åº”çš„é•¿åº¦
- en: Length is a proxy for the level of detail you want in a response. Length is
    also a constraint you sometimes must consider when writing specific formats like
    tweets, SEO descriptions, and titles.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: é•¿åº¦æ˜¯ä½ å¸Œæœ›å›åº”ä¸­åŒ…å«çš„è¯¦ç»†ç¨‹åº¦çš„ä»£ç†ã€‚é•¿åº¦æœ‰æ—¶ä¹Ÿæ˜¯ä½ åœ¨å†™ç‰¹å®šæ ¼å¼ï¼ˆå¦‚æ¨æ–‡ã€SEOæè¿°å’Œæ ‡é¢˜ï¼‰æ—¶å¿…é¡»è€ƒè™‘çš„çº¦æŸã€‚
- en: 'Here are three examples of how you can specify length in a prompt:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨æç¤ºä¸­æŒ‡å®šé•¿åº¦çš„ä¸‰ä¸ªç¤ºä¾‹ï¼š
- en: '[PRE9]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ğŸŸ¢Specify the target audience
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢æŒ‡å®šç›®æ ‡å—ä¼—
- en: Language Models are trained on billions of words taken from diverse sources,
    including Wikipedia, research papers, and Reddit. Each source has its own audience,
    and each audience consumes information differently.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: è¯­è¨€æ¨¡å‹æ˜¯åœ¨åŒ…æ‹¬ç»´åŸºç™¾ç§‘ã€ç ”ç©¶è®ºæ–‡å’ŒRedditåœ¨å†…çš„å„ç§æ¥æºä¸­è®­ç»ƒçš„æ•°åäº¿å­—ã€‚æ¯ä¸ªæ¥æºéƒ½æœ‰è‡ªå·±çš„å—ä¼—ï¼Œæ¯ä¸ªå—ä¼—éƒ½ä»¥ä¸åŒçš„æ–¹å¼æ¶ˆè´¹ä¿¡æ¯ã€‚
- en: When you specify the target audience, you tell your model to adapt the content,
    the examples, and the vocabulary.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ æŒ‡å®šç›®æ ‡å—ä¼—æ—¶ï¼Œä½ å‘Šè¯‰ä½ çš„æ¨¡å‹è¦è°ƒæ•´å†…å®¹ã€ä¾‹å­å’Œè¯æ±‡ã€‚
- en: 'Consider two potential audiences for a prompt about the benefits of exercise:
    general adult readers and medical professionals.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä¸€ä¸ªå…³äºè¿åŠ¨å¥½å¤„çš„æç¤ºçš„ä¸¤ä¸ªæ½œåœ¨å—ä¼—ï¼šä¸€èˆ¬æˆå¹´è¯»è€…å’ŒåŒ»å­¦ä¸“ä¸šäººå£«ã€‚
- en: For the first audience, you want your Language Model to use relatable examples
    and simple explanations. In contrast, the second audience would expect you to
    evoke studies and use technical terminology.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¬¬ä¸€ä¸ªå—ä¼—ï¼Œä½ å¸Œæœ›ä½ çš„è¯­è¨€æ¨¡å‹ä½¿ç”¨æ˜“äºç†è§£çš„ä¾‹å­å’Œç®€å•çš„è§£é‡Šã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç¬¬äºŒä¸ªå—ä¼—å¸Œæœ›ä½ å”¤èµ·ç ”ç©¶å¹¶ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ã€‚
- en: Even if the topic remains the same, the desired output can be extremely different.
    Thatâ€™s why you want to indicate the target audience in your prompts/
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿ä¸»é¢˜ä¿æŒä¸å˜ï¼ŒæœŸæœ›çš„è¾“å‡ºä¹Ÿå¯èƒ½å®Œå…¨ä¸åŒã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ è¦åœ¨æç¤ºä¸­æŒ‡æ˜ç›®æ ‡å—ä¼—çš„åŸå› ã€‚
- en: 'Here are what the prompts would look like for the â€œbenefits of exerciseâ€ example:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯â€œè¿åŠ¨å¥½å¤„â€ç¤ºä¾‹çš„æç¤ºï¼š
- en: '[PRE10]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: One common mistake people make when writing prompts is to consider â€œstyleâ€ and
    â€œtarget audienceâ€ as the same parameter. In reality, the style determines *how
    the text sounds* and the target audience decides *which words to use*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: äººä»¬åœ¨å†™æç¤ºæ—¶å¸¸çŠ¯çš„ä¸€ä¸ªé”™è¯¯æ˜¯å°†â€œé£æ ¼â€å’Œâ€œç›®æ ‡å—ä¼—â€è§†ä¸ºç›¸åŒçš„å‚æ•°ã€‚å®é™…ä¸Šï¼Œé£æ ¼å†³å®šäº†*æ–‡æœ¬å¬èµ·æ¥çš„æ ·å­*ï¼Œè€Œç›®æ ‡å—ä¼—å†³å®šäº†*ä½¿ç”¨å“ªäº›è¯è¯­*ã€‚
- en: 'Below is another set of examples of how to introduce the target audience in
    a prompt:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨æç¤ºä¸­ä»‹ç»ç›®æ ‡å—ä¼—çš„å¦ä¸€ç»„ç¤ºä¾‹ï¼š
- en: '[PRE11]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ğŸŸ¢ Many-Examples Prompting
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ Many-Examplesæç¤º
- en: I stole this technique from [Simon Willison](https://twitter.com/simonw), who
    uses Many-Examples prompting to push Language Models beyond their comfort zone.
    When ChatGPT and other models write a response, they predict the most likely answer
    â€” but the most likely answer is often the least creative.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»[Simon Willison](https://twitter.com/simonw)é‚£é‡Œå·äº†è¿™ä¸ªæŠ€å·§ï¼Œä»–ä½¿ç”¨Many-Examplesæç¤ºæ¥æ¨åŠ¨è¯­è¨€æ¨¡å‹è¶…è¶Šå…¶èˆ’é€‚åŒºã€‚å½“ChatGPTå’Œå…¶ä»–æ¨¡å‹å†™å‡ºå›åº”æ—¶ï¼Œå®ƒä»¬ä¼šé¢„æµ‹æœ€å¯èƒ½çš„ç­”æ¡ˆï¼Œä½†æœ€å¯èƒ½çš„ç­”æ¡ˆå¾€å¾€æ˜¯æœ€ä¸åˆ›é€ æ€§çš„ã€‚
- en: If you ask your model to exhaust its reserve of common answers, however, itâ€™ll
    have no choice but to explore new possibilities.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¦æ±‚ä½ çš„æ¨¡å‹è€—å°½å¸¸è§ç­”æ¡ˆçš„å‚¨å¤‡ï¼Œå®ƒå°†åˆ«æ— é€‰æ‹©ï¼Œåªèƒ½æ¢ç´¢æ–°çš„å¯èƒ½æ€§ã€‚
- en: 'Many-Examples prompting is particularly useful for tasks that involve imagination.
    Here are a few instances where the technique can shine:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Many-Examplesæç¤ºå¯¹æ¶‰åŠæƒ³è±¡åŠ›çš„ä»»åŠ¡ç‰¹åˆ«æœ‰ç”¨ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›æŠ€æœ¯å¯ä»¥å‘æŒ¥ä½œç”¨çš„å®ä¾‹ï¼š
- en: Optimize code by examining a list of possible variations;
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡æ£€æŸ¥å¯èƒ½çš„å˜ä½“åˆ—è¡¨æ¥ä¼˜åŒ–ä»£ç ï¼›
- en: Brainstorm ideas for new products/features;
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºæ–°äº§å“/åŠŸèƒ½è¿›è¡Œå¤´è„‘é£æš´ï¼›
- en: Inspire creative names for products/domains/companies;
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¿€å‘äº§å“/åŸŸå/å…¬å¸çš„åˆ›æ„åç§°ï¼›
- en: Reformulate sentences or create slogans;
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡æ–°æ„é€ å¥å­æˆ–åˆ›å»ºå£å·ï¼›
- en: Find a destination for your holidays;
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾ä¸€ä¸ªåº¦å‡çš„ç›®çš„åœ°ï¼›
- en: Upgrade your CV by looking for new skills to learn;
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡å¯»æ‰¾è¦å­¦ä¹ çš„æ–°æŠ€èƒ½æ¥å‡çº§ä½ çš„ç®€å†ï¼›
- en: Find new hobbies;
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾æ–°çš„çˆ±å¥½ï¼›
- en: Browse of list of books/movies/songs based on your personal preferences. (Bing
    works better than ChatGPT for this one);
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¹æ®ä¸ªäººå–œå¥½æµè§ˆä¹¦ç±/ç”µå½±/æ­Œæ›²åˆ—è¡¨ã€‚ï¼ˆBingåœ¨è¿™æ–¹é¢æ¯”ChatGPTæ›´æœ‰æ•ˆï¼‰ï¼›
- en: Explore diverse perspectives on the same topic;
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¢ç´¢åŒä¸€ä¸»é¢˜çš„å¤šå…ƒåŒ–è§‚ç‚¹ï¼›
- en: Generate as much information as possible for a given topic. Here you can combine
    Many-Examples prompting with Knowledge Generation (more on this later).
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºç»™å®šä¸»é¢˜ç”Ÿæˆå°½å¯èƒ½å¤šçš„ä¿¡æ¯ã€‚åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥å°†Many-Examplesæç¤ºä¸çŸ¥è¯†ç”Ÿæˆç»“åˆèµ·æ¥ï¼ˆç¨åä¼šè¯¦ç»†ä»‹ç»ï¼‰ã€‚
- en: 'Here are two basic formulations you can use Many-Examples prompting:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä½ å¯ä»¥ä½¿ç”¨çš„ä¸¤ç§åŸºæœ¬Many-Examplesæç¤ºçš„å…¬å¼ï¼š
- en: '[PRE12]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Use the second option when the first one fails.Sometimes when you ask for a
    large number of examples, ChatGPT will complain. Itâ€™ll say something like: â€œAs
    an AI language model, I am not aware of 50 distinct possible answers. However,
    I can provide you with a list of several answers that can be helpful.â€'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç¬¬ä¸€ä¸ªé€‰é¡¹å¤±è´¥æ—¶ä½¿ç”¨ç¬¬äºŒä¸ªé€‰é¡¹ã€‚æœ‰æ—¶å½“ä½ è¦æ±‚å¤§é‡çš„ä¾‹å­æ—¶ï¼ŒChatGPTä¼šæŠ±æ€¨ã€‚å®ƒä¼šè¯´ç±»ä¼¼äºï¼šâ€œä½œä¸ºä¸€ä¸ªAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä¸çŸ¥é“50ä¸ªä¸åŒçš„å¯èƒ½ç­”æ¡ˆã€‚ä½†æ˜¯ï¼Œæˆ‘å¯ä»¥ä¸ºä½ æä¾›ä¸€äº›æœ‰ç”¨çš„ç­”æ¡ˆåˆ—è¡¨ã€‚â€
- en: From there, ChatGPT will stop at 20 possible answers, but you can use the â€œPlease
    add 5 more distinct answersâ€ to keep the generative ball rolling. Once the same
    answers keep showing up, it means youâ€™ve emptied your modelâ€™s creative jar.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œå¼€å§‹ï¼ŒChatGPTå°†åœåœ¨20ä¸ªå¯èƒ½çš„ç­”æ¡ˆä¸Šï¼Œä½†ä½ å¯ä»¥ä½¿ç”¨â€œè¯·å†æ·»åŠ 5ä¸ªä¸åŒçš„ç­”æ¡ˆâ€æ¥ä¿æŒç”Ÿæˆçš„è¿ç»­æ€§ã€‚ä¸€æ—¦ç›¸åŒçš„ç­”æ¡ˆä¸æ–­å‡ºç°ï¼Œè¿™æ„å‘³ç€ä½ å·²ç»è€—å°½äº†æ¨¡å‹çš„åˆ›é€ åŠ›ã€‚
- en: ğŸŸ¢ Temperature Control
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ æ¸©åº¦æ§åˆ¶
- en: Temperature is a parameter that influences the â€œrandomnessâ€ of the response
    generated by your language model. It typically ranges from 0 to 1, but in some
    instances, you can bring the temperature beyond 1.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: æ¸©åº¦æ˜¯å½±å“è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å“åº”â€œéšæœºæ€§â€çš„å‚æ•°ã€‚å®ƒé€šå¸¸èŒƒå›´ä»0åˆ°1ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å°†æ¸©åº¦æé«˜åˆ°1ä»¥ä¸Šã€‚
- en: Lower temperatures (between 0.1 and 0.3) produce the most likely response. In
    other words, you get the most â€œconservativeâ€ output. **Low temperatures are particularly
    useful when generating code because you get the most stable output.**
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½æ¸©ï¼ˆåœ¨0.1å’Œ0.3ä¹‹é—´ï¼‰äº§ç”Ÿæœ€å¯èƒ½çš„å“åº”ã€‚æ¢å¥è¯è¯´ï¼Œä½ ä¼šå¾—åˆ°æœ€â€œä¿å®ˆâ€çš„è¾“å‡ºã€‚**åœ¨ç”Ÿæˆä»£ç æ—¶ï¼Œä½æ¸©ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºä½ ä¼šå¾—åˆ°æœ€ç¨³å®šçš„è¾“å‡ºã€‚**
- en: Higher temperatures (between 0.7 and 0.9) lead to more creative responses.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ›´é«˜çš„æ¸©åº¦ï¼ˆåœ¨0.7å’Œ0.9ä¹‹é—´ï¼‰ä¼šå¯¼è‡´æ›´æœ‰åˆ›æ„çš„å“åº”ã€‚
- en: 'One way to memorize the use of temperature: â€œCold for code; hot for prose.â€
    Hereâ€™s how you can introduce it in a prompt:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ä½¿ç”¨æ¸©åº¦çš„ä¸€ç§æ–¹æ³•ï¼šâ€œå†·ç”¨äºä»£ç ï¼›çƒ­ç”¨äºæ•£æ–‡ã€‚â€ä»¥ä¸‹æ˜¯ä½ å¯ä»¥åœ¨æç¤ºä¸­ä»‹ç»å®ƒçš„æ–¹å¼ï¼š
- en: '[PRE13]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ğŸŸ¢ Zero-Shot Prompting (no examples)
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ é›¶æ ·æœ¬æç¤ºï¼ˆæ²¡æœ‰ä¾‹å­ï¼‰
- en: Zero-shot prompting is to write an instruction for your AI model without providing
    context or examples. The basic format of zero-shot involves two parts often called
    â€œTextâ€ and â€œDesired Result.â€
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: é›¶æ ·æœ¬æç¤ºæ˜¯ä¸ºä½ çš„AIæ¨¡å‹ç¼–å†™æŒ‡ä»¤ï¼Œè€Œä¸æä¾›ä¸Šä¸‹æ–‡æˆ–ä¾‹å­ã€‚é›¶æ ·æœ¬çš„åŸºæœ¬æ ¼å¼é€šå¸¸åŒ…æ‹¬é€šå¸¸ç§°ä¸ºâ€œæ–‡æœ¬â€å’Œâ€œæœŸæœ›ç»“æœâ€çš„ä¸¤éƒ¨åˆ†ã€‚
- en: 'Here are two examples of zero-shot prompts:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸¤ä¸ªé›¶æ ·æœ¬æç¤ºçš„ä¾‹å­ï¼š
- en: '[PRE14]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This particular format of zero-shot prompting is rare outside of AI labs where
    experts use the technique to test the capabilities of their models.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§ç‰¹å®šæ ¼å¼çš„é›¶æ ·æœ¬æç¤ºåœ¨AIå®éªŒå®¤ä¹‹å¤–å¾ˆå°‘è§ï¼Œä¸“å®¶ä»¬åœ¨é‚£é‡Œä½¿ç”¨è¿™ç§æŠ€æœ¯æ¥æµ‹è¯•ä»–ä»¬çš„æ¨¡å‹çš„èƒ½åŠ›ã€‚
- en: The most common format of zero-shot prompting is the one you use naturally.
    You just type your question. You donâ€™t need the â€œText + Desired outputâ€ format.
    Thatâ€™s because user-friendly models like ChatGPT and Bard are optimized for dialogue
    â€” and every dialogue is a series of zero-shots.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: é›¶æ ·æœ¬æç¤ºçš„æœ€å¸¸è§æ ¼å¼æ˜¯ä½ è‡ªç„¶è€Œç„¶åœ°ä½¿ç”¨çš„æ ¼å¼ã€‚ä½ åªéœ€è¾“å…¥ä½ çš„é—®é¢˜ã€‚ä½ ä¸éœ€è¦â€œæ–‡æœ¬+æœŸæœ›è¾“å‡ºâ€çš„æ ¼å¼ã€‚è¿™æ˜¯å› ä¸ºåƒChatGPTå’ŒBardè¿™æ ·ç”¨æˆ·å‹å¥½çš„æ¨¡å‹éƒ½ç»è¿‡äº†å¯¹è¯ä¼˜åŒ–
    â€”â€” æ¯ä¸€æ¬¡å¯¹è¯éƒ½æ˜¯ä¸€æ¬¡é›¶æ ·æœ¬ã€‚
- en: You could say chatbots are zero-shot machines.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è¯´èŠå¤©æœºå™¨äººæ˜¯é›¶æ ·æœ¬æœºå™¨ã€‚
- en: ğŸŸ¢ Few-Shot Prompting (several high-quality examples)
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ å°‘æ ·æœ¬æç¤ºï¼ˆå‡ ä¸ªé«˜è´¨é‡çš„ä¾‹å­ï¼‰
- en: Few-shot prompting is also known as in-context learning. You give your Language
    Model a bunch of high-quality examples to improve its â€œguesses.â€ The number of
    examples depends on your model, but you can start with three to five inputs.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: å°‘æ ·æœ¬æç¤ºä¹Ÿè¢«ç§°ä¸ºä¸Šä¸‹æ–‡å­¦ä¹ ã€‚ä½ ç»™ä½ çš„è¯­è¨€æ¨¡å‹ä¸€å †é«˜è´¨é‡çš„ä¾‹å­æ¥æ”¹å–„å®ƒçš„â€œçŒœæµ‹â€ã€‚ä¾‹å­çš„æ•°é‡å–å†³äºä½ çš„æ¨¡å‹ï¼Œä½†ä½ å¯ä»¥ä»ä¸‰åˆ°äº”ä¸ªè¾“å…¥å¼€å§‹ã€‚
- en: 'Hereâ€™s an example:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€ä¸ªä¾‹å­ï¼š
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Itâ€™s not necessary to add a number to each example (like #1, #2, #3), but doing
    so can improve the output. Another element you want to add to your examples is
    â€œnoise.â€'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸éœ€è¦ä¸ºæ¯ä¸ªä¾‹å­æ·»åŠ ç¼–å·ï¼ˆå¦‚#1ã€#2ã€#3ï¼‰ï¼Œä½†è¿™æ ·åšå¯ä»¥æ”¹å–„è¾“å‡ºã€‚ä½ æƒ³è¦æ·»åŠ åˆ°ä½ çš„ä¾‹å­ä¸­çš„å¦ä¸€ä¸ªå…ƒç´ æ˜¯â€œå™ªéŸ³â€ã€‚
- en: Noise is information thatâ€™s not useful for the task given to your Language Model.
    In the â€œToneâ€ examples, I introduced misleading sentences to confuse the system
    and force it to focus on the â€œsignal.â€
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: å™ªéŸ³æ˜¯å¯¹ä½ çš„è¯­è¨€æ¨¡å‹ç»™å®šçš„ä»»åŠ¡æ²¡æœ‰ç”¨çš„ä¿¡æ¯ã€‚åœ¨â€œè¯­æ°”â€ä¾‹å­ä¸­ï¼Œæˆ‘å¼•å…¥äº†è¯¯å¯¼æ€§çš„å¥å­æ¥æ··æ·†ç³»ç»Ÿï¼Œå¹¶è¿«ä½¿å®ƒä¸“æ³¨äºâ€œä¿¡å·â€ã€‚
- en: If you make the task too obvious for your Language Model, it may underperform
    when faced with complex examples.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è®©ä»»åŠ¡å¯¹ä½ çš„è¯­è¨€æ¨¡å‹æ¥è¯´å¤ªæ˜æ˜¾ï¼Œå½“é¢å¯¹å¤æ‚çš„ä¾‹å­æ—¶ï¼Œå®ƒå¯èƒ½è¡¨ç°ä¸ä½³ã€‚
- en: ğŸŸ¢ Zero-Shot/Few-Shot â€” The simple version
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ é›¶æ ·æœ¬/å°‘æ ·æœ¬ â€” ç®€å•ç‰ˆæœ¬
- en: 'If you want to remember something from zero-shot and few-shot, remember the
    following:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³è®°ä½é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬ä¸­çš„ä¸€äº›ä¸œè¥¿ï¼Œè®°ä½ä»¥ä¸‹å†…å®¹ï¼š
- en: '**When your Language Model fails to give you the desired response, add high-quality
    examples to your prompt.**'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å½“ä½ çš„è¯­è¨€æ¨¡å‹æ— æ³•ç»™å‡ºä½ æƒ³è¦çš„å“åº”æ—¶ï¼Œå‘ä½ çš„æç¤ºæ·»åŠ é«˜è´¨é‡çš„ä¾‹å­ã€‚**'
- en: Hereâ€™s an illustration of how few-shot can help you improve ChatGPTâ€™s output.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯å°‘é‡æç¤ºå¦‚ä½•å¸®åŠ©ä½ æ”¹è¿›ChatGPTçš„è¾“å‡ºçš„ç¤ºä¾‹ã€‚
- en: '[PRE16]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ğŸ’¡ In-context Learning vs. Chat History
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¡ ä¸Šä¸‹æ–‡å­¦ä¹  vs. èŠå¤©å†å²
- en: The first usable version of every Language Model is often a jack of all trades.
    It can perform a variety of tasks at an average-ish level. If you want to specialize
    your model (and consequently improve its output), you have two options. You could
    either retrain it using new specific data or use in-context learning. AI people
    usually use a combination of both.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ç§è¯­è¨€æ¨¡å‹çš„ç¬¬ä¸€ä¸ªå¯ç”¨ç‰ˆæœ¬é€šå¸¸æ˜¯ä¸‡é‡‘æ²¹ã€‚å®ƒå¯ä»¥ä»¥ä¸€ç§å¹³å‡æ°´å¹³æ‰§è¡Œå„ç§ä»»åŠ¡ã€‚å¦‚æœä½ æƒ³è®©ä½ çš„æ¨¡å‹ä¸“ä¸šåŒ–ï¼ˆä»è€Œæé«˜å…¶è¾“å‡ºï¼‰ï¼Œä½ æœ‰ä¸¤ä¸ªé€‰æ‹©ã€‚ä½ å¯ä»¥ä½¿ç”¨æ–°çš„ç‰¹å®šæ•°æ®å¯¹å…¶è¿›è¡Œé‡æ–°è®­ç»ƒï¼Œæˆ–è€…ä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚AIäººå‘˜é€šå¸¸ä¼šä¸¤è€…ç»“åˆä½¿ç”¨ã€‚
- en: In-context learning is a prompting technique that allows you to steer the responses
    of your LLMs in a specific direction. All you need are a few examples, just like
    few-shot prompting.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šä¸‹æ–‡å­¦ä¹ æ˜¯ä¸€ç§æç¤ºæŠ€æœ¯ï¼Œå¯ä»¥è®©ä½ å¼•å¯¼è¯­è¨€æ¨¡å‹çš„å“åº”æœç‰¹å®šæ–¹å‘å‘å±•ã€‚ä½ åªéœ€è¦ä¸€äº›ç¤ºä¾‹ï¼Œå°±åƒå°‘é‡æç¤ºä¸€æ ·ã€‚
- en: The reason AI experts love in-context learning is efficiency. Instead of using
    a ton of high-quality data to adapt a raw model, you can use a very limited number
    of well-formatted examples.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: AIä¸“å®¶å–œæ¬¢ä¸Šä¸‹æ–‡å­¦ä¹ çš„åŸå› æ˜¯æ•ˆç‡ã€‚ä½ ä¸éœ€è¦ä½¿ç”¨å¤§é‡é«˜è´¨é‡çš„æ•°æ®æ¥è°ƒæ•´åŸå§‹æ¨¡å‹ï¼Œåªéœ€ä½¿ç”¨éå¸¸æœ‰é™æ•°é‡çš„æ ¼å¼è‰¯å¥½çš„ç¤ºä¾‹å³å¯ã€‚
- en: Hereâ€™s a summary of In-Context Learning published by Princeton University.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ™®æ—æ–¯é¡¿å¤§å­¦å‘å¸ƒçš„ä¸Šä¸‹æ–‡å­¦ä¹ æ‘˜è¦ã€‚
- en: In-context learning was popularized in the original GPT-3 paper as a way to
    use language models to learn tasks given only a few examples.[[1]](http://ai.stanford.edu/blog/understanding-incontext/#f1)
  id: totrans-205
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸Šä¸‹æ–‡å­¦ä¹ åœ¨åŸå§‹GPT-3è®ºæ–‡ä¸­è¢«æ¨å¹¿ä¸ºä¸€ç§åªä½¿ç”¨å°‘é‡ç¤ºä¾‹å°±èƒ½è®©è¯­è¨€æ¨¡å‹å­¦ä¹ ä»»åŠ¡çš„æ–¹æ³•ã€‚[[1]](http://ai.stanford.edu/blog/understanding-incontext/#f1)
- en: ''
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: During in-context learning, we give the LM a prompt that consists of a list
    of input-output pairs that demonstrate a task. At the end of the prompt, we append
    a test input and allow the LM to make a prediction just by conditioning on the
    prompt and predicting the next tokens.
  id: totrans-207
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ æœŸé—´ï¼Œæˆ‘ä»¬ç»™è¯­è¨€æ¨¡å‹ä¸€ä¸ªæç¤ºï¼Œå…¶ä¸­åŒ…å«ä¸€ç³»åˆ—å±•ç¤ºä»»åŠ¡çš„è¾“å…¥-è¾“å‡ºå¯¹ã€‚åœ¨æç¤ºçš„æœ«å°¾ï¼Œæˆ‘ä»¬é™„åŠ ä¸€ä¸ªæµ‹è¯•è¾“å…¥ï¼Œå¹¶å…è®¸è¯­è¨€æ¨¡å‹ä»…é€šè¿‡å¯¹æç¤ºè¿›è¡Œæ¡ä»¶åŒ–å¹¶é¢„æµ‹ä¸‹ä¸€ä¸ªæ ‡è®°æ¥è¿›è¡Œé¢„æµ‹ã€‚
- en: ''
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To correctly answer the two prompts below, the model needs to read the training
    examples to figure out the input distribution (financial or general news), output
    distribution (Positive/Negative or topic), input-output mapping (sentiment or
    topic classification), and the formatting.
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¦æ­£ç¡®å›ç­”ä¸‹é¢çš„ä¸¤ä¸ªæç¤ºï¼Œæ¨¡å‹éœ€è¦é˜…è¯»è®­ç»ƒç¤ºä¾‹ä»¥æ‰¾å‡ºè¾“å…¥åˆ†å¸ƒï¼ˆè´¢ç»æˆ–ä¸€èˆ¬æ–°é—»ï¼‰ã€è¾“å‡ºåˆ†å¸ƒï¼ˆç§¯æ/æ¶ˆææˆ–ä¸»é¢˜ï¼‰ã€è¾“å…¥-è¾“å‡ºæ˜ å°„ï¼ˆæƒ…æ„Ÿæˆ–ä¸»é¢˜åˆ†ç±»ï¼‰å’Œæ ¼å¼ã€‚
- en: '![](../Images/97294ea04f70fdc5faf9722c5942496f.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97294ea04f70fdc5faf9722c5942496f.png)'
- en: Examples of In-Context Learning. [Source](http://ai.stanford.edu/blog/understanding-incontext/)
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šä¸‹æ–‡å­¦ä¹ çš„ä¾‹å­ã€‚[æ¥æº](http://ai.stanford.edu/blog/understanding-incontext/)
- en: You can derive numerous applications from in-context learning â€” such as generating
    code, automated spreadsheets, and numerous other text-oriented tasks.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä»ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­å¾—åˆ°è®¸å¤šåº”ç”¨ï¼Œæ¯”å¦‚ç”Ÿæˆä»£ç ã€è‡ªåŠ¨åŒ–ç”µå­è¡¨æ ¼å’Œè®¸å¤šå…¶ä»–é¢å‘æ–‡æœ¬çš„ä»»åŠ¡ã€‚
- en: 'ChatGPT, however, is another story. OpenAI sacrificed ChatGPTâ€™s ability to
    use in-context learning to introduce a new feature: Chat history. Sure, you lose
    the flexibility of the model, but you get a user-friendly interface that allows
    for lengthy conversations.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼ŒChatGPTåˆæ˜¯å¦ä¸€å›äº‹ã€‚OpenAIç‰ºç‰²äº†ChatGPTä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ çš„èƒ½åŠ›ï¼Œå¼•å…¥äº†ä¸€ä¸ªæ–°åŠŸèƒ½ï¼šèŠå¤©å†å²ã€‚å½“ç„¶ï¼Œä½ ä¼šå¤±å»æ¨¡å‹çš„çµæ´»æ€§ï¼Œä½†ä½ ä¼šå¾—åˆ°ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„ç•Œé¢ï¼Œå¯ä»¥è¿›è¡Œé•¿æ—¶é—´çš„å¯¹è¯ã€‚
- en: You could argue chat history is a variant of in-context learning because ChatGPTâ€™s
    responses evolve depending on the content of the chat history tab youâ€™re using.
    For instance, if you feed a list of recipes into a ChatGPT tab, itâ€™ll be able
    to perform specific tasks on your input*.* This involves summary, continuation,
    and editing.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è®¤ä¸ºèŠå¤©å†å²æ˜¯ä¸Šä¸‹æ–‡å­¦ä¹ çš„ä¸€ç§å˜ä½“ï¼Œå› ä¸ºChatGPTçš„å“åº”ä¼šæ ¹æ®ä½ ä½¿ç”¨çš„èŠå¤©å†å²æ ‡ç­¾çš„å†…å®¹è€Œæ¼”å˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ å°†ä¸€ç³»åˆ—é£Ÿè°±è¾“å…¥åˆ°ChatGPTæ ‡ç­¾ä¸­ï¼Œå®ƒå°†èƒ½å¤Ÿå¯¹ä½ çš„è¾“å…¥æ‰§è¡Œç‰¹å®šä»»åŠ¡*ã€‚*
    è¿™æ¶‰åŠæ‘˜è¦ã€å»¶ç»­å’Œç¼–è¾‘ã€‚
- en: Why is this important?
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ
- en: 'Depending on your needs and future discoveries, you may need to pick one of
    two options:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ çš„éœ€æ±‚å’Œæœªæ¥çš„å‘ç°ï¼Œä½ å¯èƒ½éœ€è¦é€‰æ‹©ä»¥ä¸‹ä¸¤ä¸ªé€‰é¡¹ä¸­çš„ä¸€ä¸ªï¼š
- en: Use in-context learning to fine-tune a â€œrawâ€ model like GPT-4, OpenLLaMa, or
    Falcon. In other words, you can create a customized chatbot but the process can
    be tedious.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ æ¥å¾®è°ƒåƒGPT-4ã€OpenLLaMaæˆ–Falconè¿™æ ·çš„â€œåŸå§‹â€æ¨¡å‹ã€‚æ¢å¥è¯è¯´ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ä¸ªå®šåˆ¶çš„èŠå¤©æœºå™¨äººï¼Œä½†è¿™ä¸ªè¿‡ç¨‹å¯èƒ½ä¼šå¾ˆç¹çã€‚
- en: Use chat history to leverage â€œmemoryâ€ and â€œlong conversations.â€ Itâ€™s easier
    to customize your output but the quality may go down over time.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ©ç”¨â€œè®°å¿†â€å’Œâ€œé•¿å¯¹è¯â€æ¥ä½¿ç”¨èŠå¤©å†å²ã€‚è¿™æ ·æ›´å®¹æ˜“å®šåˆ¶ä½ çš„è¾“å‡ºï¼Œä½†éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè´¨é‡å¯èƒ½ä¼šä¸‹é™ã€‚
- en: ğŸŸ¡ Chain of Thought Prompting
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¡ æ€ç»´é“¾æç¤º
- en: Chain of Thought (CoT) prompting means you tell your Language Model to **reason
    step by step** before arriving at a final response. Itâ€™s as if you ask your model
    to think out loud.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: æ€ç»´é“¾ï¼ˆCoTï¼‰æç¤ºæ„å‘³ç€åœ¨æœ€ç»ˆå“åº”ä¹‹å‰å‘Šè¯‰ä½ çš„è¯­è¨€æ¨¡å‹**é€æ­¥æ¨ç†**ã€‚å°±å¥½åƒä½ è¦æ±‚ä½ çš„æ¨¡å‹å¤§å£°æ€è€ƒä¸€æ ·ã€‚
- en: Suppose I ask you to calculate 4x3\. You could instantly compute the operation
    inside your head and say, â€œ12.â€ But if I ask you to use a â€œchain of thought,â€
    youâ€™d split your reasoning into four steps.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘è®©ä½ è®¡ç®— 4x3ã€‚ä½ å¯ä»¥ç«‹å³åœ¨è„‘æµ·ä¸­è®¡ç®—è¿™ä¸ªæ“ä½œï¼Œå¹¶è¯´ï¼šâ€œ12â€ã€‚ä½†å¦‚æœæˆ‘è¦æ±‚ä½ ä½¿ç”¨â€œæ€ç»´é“¾â€ï¼Œä½ ä¼šå°†ä½ çš„æ¨ç†åˆ†æˆå››ä¸ªæ­¥éª¤ã€‚
- en: 4x3 = 4+4+4
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4x3 = 4+4+4
- en: 4+4+4 = (4+4) + 4
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4+4+4 = (4+4) + 4
- en: (4+4) + 4 = 8+4
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4+4) + 4 = 8+4
- en: 8+4 = 12
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 8+4 = 12
- en: CoT prompts are typically used to solve logical riddles. The idea is to break
    down complex problems into smaller, more manageable questions.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: CoT æç¤ºé€šå¸¸ç”¨äºè§£å†³é€»è¾‘è°œé¢˜ã€‚å…¶æ€æƒ³æ˜¯å°†å¤æ‚çš„é—®é¢˜åˆ†è§£ä¸ºæ›´å°ã€æ›´æ˜“ç®¡ç†çš„é—®é¢˜ã€‚
- en: Language Models predict the next token in a sequence of words, and their predictions
    are more accurate when they deal with common patterns found in abundance inside
    training data. But sometimes, you need to tap into uncommon patterns to answer
    uncommon questions.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: è¯­è¨€æ¨¡å‹é¢„æµ‹å•è¯åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªæ ‡è®°ï¼Œå½“å®ƒä»¬å¤„ç†è®­ç»ƒæ•°æ®ä¸­ä¸°å¯Œçš„å¸¸è§æ¨¡å¼æ—¶ï¼Œå®ƒä»¬çš„é¢„æµ‹æ›´å‡†ç¡®ã€‚ä½†æœ‰æ—¶ï¼Œä½ éœ€è¦åˆ©ç”¨ä¸å¸¸è§çš„æ¨¡å¼æ¥å›ç­”ä¸å¸¸è§çš„é—®é¢˜ã€‚
- en: 'Consider the following riddle: â€œIf eggs are $0.12 a dozen, how many eggs can
    you get for a dollar?â€'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä»¥ä¸‹è°œé¢˜ï¼šâ€œå¦‚æœé¸¡è›‹ä¸€æ‰“å– 0.12 ç¾å…ƒï¼Œä½ å¯ä»¥ç”¨ä¸€ç¾å…ƒä¹°å¤šå°‘ä¸ªé¸¡è›‹ï¼Ÿâ€
- en: 'If you force ChatGPT to give an immediate response, itâ€™ll write: â€You can get
    10 dozen eggs for a dollar,â€ which is a wrong answer.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¼ºè¿« ChatGPT ç«‹å³ç»™å‡ºç­”æ¡ˆï¼Œå®ƒä¼šå†™é“ï¼šâ€œä½ å¯ä»¥ç”¨ä¸€ç¾å…ƒä¹° 10 æ‰“é¸¡è›‹â€ï¼Œè¿™æ˜¯ä¸€ä¸ªé”™è¯¯çš„ç­”æ¡ˆã€‚
- en: '![](../Images/7a46f56a22764a947e872e1b4cd6744b.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a46f56a22764a947e872e1b4cd6744b.png)'
- en: The prompt forces ChatGPT to give an immediate answer (no chain of thought).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå¼ºåˆ¶ ChatGPT ç«‹å³ç»™å‡ºç­”æ¡ˆï¼ˆæ²¡æœ‰æ€ç»´é“¾ï¼‰ã€‚
- en: Now, if you ask ChatGPT to reason step by step, it gives a different answer
    â€” the right answer.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¦‚æœä½ è¦æ±‚ ChatGPT é€æ­¥æ¨ç†ï¼Œå®ƒä¼šç»™å‡ºä¸€ä¸ªä¸åŒçš„ç­”æ¡ˆâ€”â€”æ­£ç¡®çš„ç­”æ¡ˆã€‚
- en: '![](../Images/56c5edbad984077a2d309882e6a4b28b.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56c5edbad984077a2d309882e6a4b28b.png)'
- en: The latest versions of ChatGPT often (but not always) use CoT when they respond
    to prompts.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT çš„æœ€æ–°ç‰ˆæœ¬é€šå¸¸ï¼ˆä½†ä¸æ€»æ˜¯ï¼‰åœ¨å“åº”æç¤ºæ—¶ä½¿ç”¨ CoTã€‚
- en: Hereâ€™s another example that illustrates the difference between standard prompting
    and Chain of Thought.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¦ä¸€ä¸ªä¾‹å­ï¼Œè¯´æ˜äº†æ ‡å‡†æç¤ºå’Œæ€ç»´é“¾ä¹‹é—´çš„åŒºåˆ«ã€‚
- en: '![](../Images/6673d19d2c756c392c58499590e51e37.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6673d19d2c756c392c58499590e51e37.png)'
- en: Notice the addition of a chain of thought in the second input (highlighted in
    blue). [Source](https://learnprompting.org/docs/intermediate/chain_of_thought#fn-1)
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ç¬¬äºŒä¸ªè¾“å…¥ä¸­æ€ç»´é“¾çš„æ·»åŠ ï¼ˆä»¥è“è‰²çªå‡ºæ˜¾ç¤ºï¼‰ã€‚[æ¥æº](https://learnprompting.org/docs/intermediate/chain_of_thought#fn-1)
- en: There are two ways you can use Chain of Thought prompting.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä½¿ç”¨æ€ç»´é“¾æç¤ºçš„ä¸¤ç§æ–¹å¼ã€‚
- en: ğŸŸ¢ Zero-Shot Chain of Thought
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸŸ¢ é›¶æç¤ºæ€ç»´é“¾
- en: 'Add one sentence at the end of your prompt to make your Language Model apply
    CoT. The top-performing sentences I found are:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½ çš„æç¤ºæœ«å°¾æ·»åŠ ä¸€å¥è¯ï¼Œè®©ä½ çš„è¯­è¨€æ¨¡å‹åº”ç”¨ CoTã€‚æˆ‘å‘ç°çš„è¡¨ç°æœ€å¥½çš„å¥å­æ˜¯ï¼š
- en: '**â€œâ€¦.Letâ€™s think step by step.â€**'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€œâ€¦.è®©æˆ‘ä»¬é€æ­¥æ€è€ƒã€‚â€**'
- en: '**â€œâ€¦.Please proceed step by step to be sure you arrive at the right answer.â€**'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€œâ€¦.è¯·é€æ­¥è¿›è¡Œï¼Œç¡®ä¿ä½ å¾—åˆ°æ­£ç¡®çš„ç­”æ¡ˆã€‚â€**'
- en: 'Hereâ€™s how you can incorporate them in your prompts:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨ä½ çš„æç¤ºä¸­åŠ å…¥å®ƒä»¬ï¼š
- en: '[PRE17]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Usually, Zero-shot CoT is enough to solve logic puzzles. But if your Language
    Model fails, you can try the second flavor of CoT prompting.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œé›¶æç¤ºæ€ç»´é“¾è¶³ä»¥è§£å†³é€»è¾‘è°œé¢˜ã€‚ä½†å¦‚æœä½ çš„è¯­è¨€æ¨¡å‹å¤±è´¥äº†ï¼Œä½ å¯ä»¥å°è¯•ç¬¬äºŒç§æ€ç»´é“¾æç¤ºã€‚
- en: ğŸŸ¡ **Few-Shot Chain of Thought**
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸŸ¡ **å°‘é‡æç¤ºæ€ç»´é“¾**
- en: Much like the standard few-shot prompting, you want to feed your Language Model
    high-quality examples before submitting your question. Each example must include
    multiple steps of reasoningâ€” and the more logical steps you add, the better the
    response.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒæ ‡å‡†çš„å°‘é‡æç¤ºä¸€æ ·ï¼Œä½ éœ€è¦åœ¨æäº¤é—®é¢˜ä¹‹å‰å‘ä½ çš„è¯­è¨€æ¨¡å‹æä¾›é«˜è´¨é‡çš„ç¤ºä¾‹ã€‚æ¯ä¸ªç¤ºä¾‹å¿…é¡»åŒ…æ‹¬å¤šä¸ªæ¨ç†æ­¥éª¤ï¼Œè€Œä¸”ä½ æ·»åŠ çš„é€»è¾‘æ­¥éª¤è¶Šå¤šï¼Œå“åº”å°±è¶Šå¥½ã€‚
- en: 'Hereâ€™s an example of a prompt that combines Few-Shot and Chain of Thought:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€ä¸ªç»“åˆäº†å°‘é‡æç¤ºå’Œæ€ç»´é“¾çš„æç¤ºçš„ä¾‹å­ï¼š
- en: '[PRE18]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ğŸŸ¢ Role Prompting
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ è§’è‰²æç¤º
- en: 'Assigning a specific role to your Language Model helps it capture more and
    better semantic relationships (ie: logic and meaning).'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä½ çš„è¯­è¨€æ¨¡å‹åˆ†é…ä¸€ä¸ªç‰¹å®šçš„è§’è‰²æœ‰åŠ©äºå®ƒæ•æ‰æ›´å¤šå’Œæ›´å¥½çš„è¯­ä¹‰å…³ç³»ï¼ˆå³ï¼šé€»è¾‘å’Œå«ä¹‰ï¼‰ã€‚
- en: In a way, Role Prompting helps you nudge your model to focus on specific information
    inside its training data. Itâ€™s a shortcut to specify many variables at once â€”
    like context, style, perspective, and vocabulary.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œè§’è‰²æç¤ºå¸®åŠ©ä½ ä¿ƒä½¿ä½ çš„æ¨¡å‹ä¸“æ³¨äºå…¶è®­ç»ƒæ•°æ®ä¸­çš„ç‰¹å®šä¿¡æ¯ã€‚è¿™æ˜¯ä¸€ç§ä¸€æ¬¡æ€§æŒ‡å®šå¤šä¸ªå˜é‡çš„å¿«æ·æ–¹å¼ï¼Œæ¯”å¦‚ä¸Šä¸‹æ–‡ã€é£æ ¼ã€è§‚ç‚¹å’Œè¯æ±‡ã€‚
- en: Depending on the task at hand, you can use different versions of Role Prompting.
    Below are a few examples that may inspire you.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ‰‹å¤´çš„ä»»åŠ¡ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸åŒç‰ˆæœ¬çš„è§’è‰²æç¤ºã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½ä¼šå¯å‘ä½ çš„ä¾‹å­ã€‚
- en: Mimic a personal style.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡ä»¿ä¸ªäººé£æ ¼ã€‚
- en: Emulate specific expertise like a lawyer or a strategic planner.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡ä»¿åƒå¾‹å¸ˆæˆ–æˆ˜ç•¥è§„åˆ’å¸ˆè¿™æ ·çš„ç‰¹å®šä¸“ä¸šçŸ¥è¯†ã€‚
- en: Emulate your counterpart in a conversation like your professor, your ex, or
    your boss.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡ä»¿ä½ åœ¨å¯¹è¯ä¸­çš„å¯¹åº”è€…ï¼Œæ¯”å¦‚ä½ çš„æ•™æˆã€å‰ä»»æˆ–è€æ¿ã€‚
- en: Generate multiple points of view.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¤šä¸ªè§‚ç‚¹ã€‚
- en: Behave like a mini-app that corrects typos, compiles your code, or generates
    Excel formulas.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¡¨ç°å¾—åƒä¸€ä¸ªçº æ­£æ‹¼å†™é”™è¯¯ã€ç¼–è¯‘ä½ çš„ä»£ç æˆ–ç”ŸæˆExcelå…¬å¼çš„è¿·ä½ åº”ç”¨ç¨‹åºã€‚
- en: '[PRE19]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Thereâ€™s an advanced version of role prompting that weâ€™ll explore in a specific
    section called â€œAll-In-One Prompting.â€
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨ä¸€ä¸ªåä¸ºâ€œå…¨èƒ½æç¤ºâ€çš„ç‰¹å®šéƒ¨åˆ†ä¸­æ¢è®¨è§’è‰²æç¤ºçš„é«˜çº§ç‰ˆæœ¬ã€‚
- en: ğŸŸ¢ Knowledge Generation Prompting
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ çŸ¥è¯†ç”Ÿæˆæç¤º
- en: The goal of Knowledge Generation prompting is to make your Language Model retrieve
    specific bits of information from its giant pool of training data. Picture this
    technique as asking your model to do some research before writing a final response.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ¥è¯†ç”Ÿæˆæç¤ºçš„ç›®æ ‡æ˜¯è®©ä½ çš„è¯­è¨€æ¨¡å‹ä»å…¶åºå¤§çš„è®­ç»ƒæ•°æ®ä¸­æ£€ç´¢ç‰¹å®šçš„ä¿¡æ¯ç‰‡æ®µã€‚æƒ³è±¡ä¸€ä¸‹è¿™ç§æŠ€æœ¯å°±åƒæ˜¯åœ¨å†™æœ€ç»ˆå›ç­”ä¹‹å‰è¦æ±‚ä½ çš„æ¨¡å‹è¿›è¡Œä¸€äº›ç ”ç©¶ã€‚
- en: Suppose you want your model to write a blog post about growing flowers on your
    balcony. Instead of asking your model to write the blog right away, you can prompt
    it to generate key points about gardening, flowers, and space management.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ æƒ³è®©ä½ çš„æ¨¡å‹å†™ä¸€ç¯‡å…³äºåœ¨é˜³å°ä¸Šç§èŠ±çš„åšå®¢æ–‡ç« ã€‚ä¸å…¶ç«‹å³è¦æ±‚ä½ çš„æ¨¡å‹å†™åšå®¢ï¼Œä¸å¦‚æç¤ºå®ƒç”Ÿæˆå…³äºå›­è‰ºã€èŠ±å‰å’Œç©ºé—´ç®¡ç†çš„å…³é”®è¦ç‚¹ã€‚
- en: Once you get the desired key point, make sure to attend to your fact-checking
    duties. From there, prompt your model to use the â€œknowledgeâ€ it generated to write
    an article.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ å¾—åˆ°äº†æœŸæœ›çš„å…³é”®ç‚¹ï¼Œä¸€å®šè¦å±¥è¡Œä½ çš„äº‹å®æ ¸æŸ¥èŒè´£ã€‚ä»é‚£é‡Œï¼Œæç¤ºä½ çš„æ¨¡å‹ä½¿ç”¨å®ƒç”Ÿæˆçš„â€œçŸ¥è¯†â€æ¥æ’°å†™ä¸€ç¯‡æ–‡ç« ã€‚
- en: Knowledge Generation improves the output quality because it forces your model
    to focus on specific points instead of trying to answer a vague prompt.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ¥è¯†ç”Ÿæˆå¯ä»¥æé«˜è¾“å‡ºè´¨é‡ï¼Œå› ä¸ºå®ƒè¿«ä½¿ä½ çš„æ¨¡å‹ä¸“æ³¨äºç‰¹å®šçš„è¦ç‚¹ï¼Œè€Œä¸æ˜¯è¯•å›¾å›ç­”æ¨¡ç³Šçš„æç¤ºã€‚
- en: 'Hereâ€™s how you can introduce Knowledge Generation into your prompts:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¦‚ä½•å°†çŸ¥è¯†ç”Ÿæˆå¼•å…¥åˆ°ä½ çš„æç¤ºä¸­çš„æ–¹æ³•ï¼š
- en: '[PRE20]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Knowledge Generation Prompting and ChatGPT Plugins**'
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çŸ¥è¯†ç”Ÿæˆæç¤ºå’ŒChatGPTæ’ä»¶**'
- en: You can use ChatGPT plugins to both generate knowledge and help with fact-checking.
    Make sure to try as many plugins as possible because most of them are still clunky.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä½¿ç”¨ChatGPTæ’ä»¶æ¥ç”ŸæˆçŸ¥è¯†å¹¶å¸®åŠ©æ ¸å®äº‹å®ã€‚ä¸€å®šè¦å°è¯•å°½å¯èƒ½å¤šçš„æ’ä»¶ï¼Œå› ä¸ºå®ƒä»¬ä¸­çš„å¤§å¤šæ•°ä»ç„¶æœ‰äº›ç¬¨æ‹™ã€‚
- en: ğŸŸ  Knowledge Integration Prompting*
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ  çŸ¥è¯†æ•´åˆæç¤º*
- en: The main weakness of Knowledge Generation prompting is the timeline. GPT-4â€™s
    training data stops in September 2021, which means all the content that came afterward
    is unknown to the model.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ¥è¯†ç”Ÿæˆæç¤ºçš„ä¸»è¦å¼±ç‚¹æ˜¯æ—¶é—´è¡¨ã€‚GPT-4çš„è®­ç»ƒæ•°æ®æ­¢äº2021å¹´9æœˆï¼Œè¿™æ„å‘³ç€ä¹‹åå‡ºç°çš„æ‰€æœ‰å†…å®¹å¯¹æ¨¡å‹æ¥è¯´éƒ½æ˜¯æœªçŸ¥çš„ã€‚
- en: The cutoff date isnâ€™t a problem when you deal with timeless topics like gardening,
    writing, and cooking, but if youâ€™re chasing the latest information, you need a
    complementary trick.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: æˆªæ­¢æ—¥æœŸå¯¹äºå¤„ç†å›­è‰ºã€å†™ä½œå’Œçƒ¹é¥ªç­‰æ°¸æ’è¯é¢˜å¹¶ä¸æ˜¯é—®é¢˜ï¼Œä½†å¦‚æœä½ è¿½æ±‚æœ€æ–°ä¿¡æ¯ï¼Œä½ éœ€è¦ä¸€ä¸ªè¡¥å……çš„æŠ€å·§ã€‚
- en: You can use plugins, chatbots with online browsing, or Knowledge Integration
    prompting.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä½¿ç”¨æ’ä»¶ã€å¸¦æœ‰åœ¨çº¿æµè§ˆåŠŸèƒ½çš„èŠå¤©æœºå™¨äººï¼Œæˆ–è€…çŸ¥è¯†æ•´åˆæç¤ºã€‚
- en: All you have to do is feed recent data into your model to help it catch up with
    the news. In a way, you make your offline model integrate new knowledge.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æ‰€éœ€è¦åšçš„å°±æ˜¯å°†æœ€æ–°çš„æ•°æ®è¾“å…¥åˆ°ä½ çš„æ¨¡å‹ä¸­ï¼Œä»¥å¸®åŠ©å®ƒè·Ÿä¸Šæ–°é—»ã€‚åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œä½ è®©ä½ çš„ç¦»çº¿æ¨¡å‹æ•´åˆæ–°çš„çŸ¥è¯†ã€‚
- en: For API users, [GPT-4 can process up to 32,000 tokens](https://www.semrush.com/blog/gpt-4/),
    which represent about 25,000 words. This includes both the user prompt and the
    answer. For users of ChatGPT Plus, GPT-4 can take up to 4096 tokens as input,
    which is approximately 3,000 words.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºAPIç”¨æˆ·ï¼Œ[GPT-4å¯ä»¥å¤„ç†é«˜è¾¾32,000ä¸ªæ ‡è®°](https://www.semrush.com/blog/gpt-4/)ï¼Œå¤§çº¦ç›¸å½“äº25,000ä¸ªå•è¯ã€‚è¿™åŒ…æ‹¬ç”¨æˆ·æç¤ºå’Œç­”æ¡ˆã€‚å¯¹äºChatGPT
    Plusçš„ç”¨æˆ·ï¼ŒGPT-4å¯ä»¥æ¥å—é«˜è¾¾4096ä¸ªæ ‡è®°çš„è¾“å…¥ï¼Œå¤§çº¦ç›¸å½“äº3,000ä¸ªå•è¯ã€‚
- en: You can use these 3,000 words and the chat history feature to â€œteachâ€ ChatGPT-4
    new information. The model itself wonâ€™t integrate the data, but you can generate
    prompts that leverage the â€œnew informationâ€ you just added.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä½¿ç”¨è¿™ 3,000 ä¸ªå•è¯å’ŒèŠå¤©è®°å½•åŠŸèƒ½æ¥â€œæ•™å¯¼â€ ChatGPT-4 æ–°çš„ä¿¡æ¯ã€‚æ¨¡å‹æœ¬èº«ä¸ä¼šæ•´åˆæ•°æ®ï¼Œä½†ä½ å¯ä»¥ç”Ÿæˆåˆ©ç”¨åˆšåˆšæ·»åŠ çš„â€œæ–°ä¿¡æ¯â€çš„æç¤ºã€‚
- en: 'Below is a framework you can use to apply Knowledge Integration prompting:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ä½ å¯ä»¥åº”ç”¨çŸ¥è¯†æ•´åˆæç¤ºçš„æ¡†æ¶ï¼š
- en: Find a relevant source, like a research paper or a documented article.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ç›¸å…³çš„æ¥æºï¼Œæ¯”å¦‚ç ”ç©¶è®ºæ–‡æˆ–å·²è®°å½•çš„æ–‡ç« ã€‚
- en: Identify the most informative parts of the paper at hand.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®å®šæ‰‹å¤´è®ºæ–‡ä¸­æœ€å…·ä¿¡æ¯é‡çš„éƒ¨åˆ†ã€‚
- en: Cut the parts into chunks of 3,000 words.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿™äº›éƒ¨åˆ†åˆ‡æˆ 3,000 ä¸ªå•è¯çš„ç‰‡æ®µã€‚
- en: Feed the chunks into ChatGPT-4 and ask it to explain each section in simple
    words. You can also ask for quotes and examples.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿™äº›ç‰‡æ®µè¾“å…¥åˆ° ChatGPT-4 ä¸­ï¼Œå¹¶è¦æ±‚å®ƒç”¨ç®€å•çš„è¯è¯­è§£é‡Šæ¯ä¸ªéƒ¨åˆ†ã€‚ä½ ä¹Ÿå¯ä»¥è¦æ±‚å¼•ç”¨å’Œä¾‹å­ã€‚
- en: Use ChatGPT-4's output for a new prompt.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ ChatGPT-4 çš„è¾“å‡ºè¿›è¡Œæ–°çš„æç¤ºã€‚
- en: 'Example:'
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼š
- en: Letâ€™s say youâ€™re an AI researcher specializing in Large Language Models. Your
    current task is to reference material thatâ€™s relevant to your thesis.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ æ˜¯ä¸€ä½ä¸“é—¨ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹çš„äººå·¥æ™ºèƒ½ç ”ç©¶å‘˜ã€‚ä½ ç›®å‰çš„ä»»åŠ¡æ˜¯å¼•ç”¨ä¸ä½ çš„è®ºæ–‡ç›¸å…³çš„ææ–™ã€‚
- en: You found an interesting paper titled *Language Models Can Solve Computer Tasks*.
    You want to take notes before skimming the other 122 papers you bookmarked last
    week.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æ‰¾åˆ°äº†ä¸€ç¯‡æœ‰è¶£çš„è®ºæ–‡ï¼Œæ ‡é¢˜ä¸º*è¯­è¨€æ¨¡å‹å¯ä»¥è§£å†³è®¡ç®—æœºä»»åŠ¡*ã€‚åœ¨æµè§ˆä½ ä¸Šå‘¨æ”¶è—çš„å…¶ä»– 122 ç¯‡è®ºæ–‡ä¹‹å‰ï¼Œä½ æƒ³å…ˆåšç¬”è®°ã€‚
- en: Here are the steps you can follow to get ChatGPT to help you take quick notes.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä½ å¯ä»¥éµå¾ªçš„æ­¥éª¤ï¼Œè®© ChatGPT å¸®åŠ©ä½ å¿«é€Ÿè®°å½•ç¬”è®°ã€‚
- en: First, identify the passage you want to summarize. In this example, weâ€™ll select
    the discussion part which makes for about 1,000 words.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œç¡®å®šä½ æƒ³è¦æ€»ç»“çš„æ®µè½ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†é€‰æ‹©è®¨è®ºéƒ¨åˆ†ï¼Œå¤§çº¦æœ‰ 1,000 ä¸ªå•è¯ã€‚
- en: '![](../Images/f0a39e870bbe222ab75222daf50028f4.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0a39e870bbe222ab75222daf50028f4.png)'
- en: '[Source](https://arxiv.org/abs/2302.08399).'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¥æº](https://arxiv.org/abs/2302.08399)ã€‚'
- en: Cut these lengthy passages into chunks of 3,000 words (not needed in this example).
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿™äº›å†—é•¿çš„æ®µè½åˆ‡æˆ 3,000 ä¸ªå•è¯çš„ç‰‡æ®µï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­ä¸éœ€è¦ï¼‰ã€‚
- en: Feed these chunks of text to ChatGPT.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿™äº›æ–‡æœ¬ç‰‡æ®µè¾“å…¥åˆ° ChatGPT ä¸­ã€‚
- en: Ask ChatGPT to write a summary of the text you provided.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¦æ±‚ ChatGPT å†™å‡ºä½ æä¾›çš„æ–‡æœ¬çš„æ‘˜è¦ã€‚
- en: Repeat the process for all the papers you want to summarize.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œæ€»ç»“ä½ æƒ³è¦æ¦‚æ‹¬çš„æ‰€æœ‰è®ºæ–‡ã€‚
- en: Donâ€™t forget to fact-check.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸è¦å¿˜è®°äº‹å®æ ¸æŸ¥ã€‚
- en: Use your freshly created reading notes to find common threads, and confront
    opposing results.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä½ æ–°åˆ›å»ºçš„é˜…è¯»ç¬”è®°æ‰¾å‡ºå…±åŒçš„çº¿ç´¢ï¼Œå¹¶å¯¹æŠ—ç›¸åçš„ç»“æœã€‚
- en: 'Hereâ€™s what the framework looks like in practice:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œæ¡†æ¶çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼š
- en: '[PRE21]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**Note:** if the final output is too long, ChatGPT will stop writing its response
    midway. In this case, you can prompt it with the word â€œContinue,â€ and it will
    resume writing from the point it was cut off.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š**å¦‚æœæœ€ç»ˆè¾“å‡ºå¤ªé•¿ï¼ŒChatGPT å°†åœ¨ä¸­é€”åœæ­¢å†™ä½œã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥æç¤ºå®ƒä½¿ç”¨â€œç»§ç»­â€è¿™ä¸ªè¯ï¼Œå®ƒå°†ä»è¢«åˆ‡æ–­çš„åœ°æ–¹ç»§ç»­å†™ä½œã€‚'
- en: ğŸŸ¢ **Knowledge Integration* and Microsoft Edge**
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸŸ¢ **çŸ¥è¯†æ•´åˆ* å’Œ Microsoft Edge**
- en: When using Knowledge Integration prompts, you can use the â€œChatâ€ feature of
    Microsoft Edge for more efficiency.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½¿ç”¨çŸ¥è¯†æ•´åˆæç¤ºæ—¶ï¼Œä½ å¯ä»¥ä½¿ç”¨ Microsoft Edge çš„â€œèŠå¤©â€åŠŸèƒ½æ¥æé«˜æ•ˆç‡ã€‚
- en: Instead of navigating the material yourself, you can open a web page or a PDF
    in Edge and use the Chat feature to summarize the content. From there, inject
    the summary into ChatGPT and use it for another prompt like the one we saw in
    the previous example.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ‰“å¼€ Edge ä¸­çš„ç½‘é¡µæˆ– PDFï¼Œå¹¶ä½¿ç”¨èŠå¤©åŠŸèƒ½æ¥æ€»ç»“å†…å®¹ï¼Œè€Œä¸æ˜¯è‡ªå·±æµè§ˆææ–™ã€‚ç„¶åï¼Œå°†æ€»ç»“æ³¨å…¥åˆ° ChatGPT ä¸­ï¼Œå¹¶ç”¨å®ƒè¿›è¡Œå¦ä¸€ä¸ªæç¤ºï¼Œå°±åƒæˆ‘ä»¬åœ¨å‰é¢çš„ä¾‹å­ä¸­çœ‹åˆ°çš„é‚£æ ·ã€‚
- en: 'Hereâ€™s a prompt you can use to summarize a document using Microsoft Edge:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ä½ å¯ä»¥ä½¿ç”¨ Microsoft Edge æ€»ç»“æ–‡æ¡£çš„æç¤ºï¼š
- en: '[PRE22]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ğŸŸ  Directional Stimulus (DS) Prompting
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ  æ–¹å‘åˆºæ¿€ï¼ˆDSï¼‰æç¤º
- en: 'The original version of DS Prompting involves two steps:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: DS Prompting çš„åŸå§‹ç‰ˆæœ¬åŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤ï¼š
- en: Train a Language Model to generate a **specific type of hint** from a given
    text.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®­ç»ƒä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œä»ç»™å®šçš„æ–‡æœ¬ä¸­ç”Ÿæˆ**ç‰¹å®šç±»å‹çš„æç¤º**ã€‚
- en: Use **another Language Model** to summarize the same text using the hint generated
    by the first Language Model.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨**å¦ä¸€ä¸ªè¯­è¨€æ¨¡å‹**æ¥ä½¿ç”¨ç¬¬ä¸€ä¸ªè¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æç¤ºæ¥æ€»ç»“ç›¸åŒçš„æ–‡æœ¬ã€‚
- en: For this guide, weâ€™ll use a simpler version of DS Prompting where we **use the
    same model to perform both tasks**.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæœ¬æŒ‡å—ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ DS Prompting çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œåœ¨è¿™ä¸ªç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬**ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹æ‰§è¡Œä¸¤é¡¹ä»»åŠ¡**ã€‚
- en: '![](../Images/f78e881ebb239c356e1eecd86b892c54.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f78e881ebb239c356e1eecd86b892c54.png)'
- en: Comparison between Standard Prompting and Direction Stimulus Prompting. [Source](https://arxiv.org/abs/2302.11520)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡å‡†æç¤ºå’Œæ–¹å‘åˆºæ¿€æç¤ºçš„æ¯”è¾ƒã€‚[æ¥æº](https://arxiv.org/abs/2302.11520)
- en: The best (and perhaps only) use case for DS Prompting is to summarize research
    papers and other academic-like texts.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: DSæç¤ºçš„æœ€ä½³ï¼ˆä¹Ÿè®¸æ˜¯å”¯ä¸€çš„ï¼‰ç”¨ä¾‹æ˜¯æ€»ç»“ç ”ç©¶è®ºæ–‡å’Œå…¶ä»–ç±»ä¼¼å­¦æœ¯æ–‡æœ¬ã€‚
- en: 'Suppose you want to summarize a paper titled *Guiding Large Language Models
    via Directional Stimulus Prompting*. Here are the steps you want to follow:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ æƒ³è¦æ€»ç»“ä¸€ç¯‡åä¸ºã€Šé€šè¿‡å®šå‘åˆºæ¿€æç¤ºå¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹ã€‹çš„è®ºæ–‡ã€‚ä»¥ä¸‹æ˜¯ä½ æƒ³è¦éµå¾ªçš„æ­¥éª¤ï¼š
- en: Identify the passage you want to summarize.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®å®šä½ æƒ³è¦æ€»ç»“çš„æ®µè½ã€‚
- en: Cut these lengthy passages into chunks your Language Model can handle. (3,000
    words in the case of ChatGPT-4).
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿™äº›å†—é•¿çš„æ®µè½åˆ‡æˆä½ çš„è¯­è¨€æ¨¡å‹å¯ä»¥å¤„ç†çš„å—ã€‚ï¼ˆåœ¨ChatGPT-4çš„æƒ…å†µä¸‹ä¸º3,000ä¸ªå•è¯ï¼‰ã€‚
- en: Feed the chunks of text into ChatGPT.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ–‡æœ¬å—è¾“å…¥ChatGPTã€‚
- en: Ask ChatGPT to write a hint about the paper involving key information like names,
    addresses, dates, places, and events.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¦æ±‚ChatGPTå†™ä¸€æ¡å…³äºæ¶‰åŠå…³é”®ä¿¡æ¯ï¼ˆå¦‚å§“åã€åœ°å€ã€æ—¥æœŸã€åœ°ç‚¹å’Œäº‹ä»¶ï¼‰çš„è®ºæ–‡çš„æç¤ºã€‚
- en: Use Few-Shot prompting to show ChatGPT the desired output.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Few-Shotæç¤ºå‘ChatGPTå±•ç¤ºæ‰€éœ€çš„è¾“å‡ºã€‚
- en: Once you get the â€œhint,â€ fact-check it and adjust your Few-Shot prompt if necessary.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ å¾—åˆ°äº†â€œæç¤ºâ€ï¼Œå¯¹å…¶è¿›è¡Œäº‹å®æ ¸æŸ¥ï¼Œå¹¶æ ¹æ®éœ€è¦è°ƒæ•´ä½ çš„Few-Shotæç¤ºã€‚
- en: Submit your â€œhintâ€ generating prompt in a new tab.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ–°æ ‡ç­¾é¡µä¸­æäº¤ä½ çš„â€œæç¤ºâ€ç”Ÿæˆæç¤ºã€‚
- en: Run the prompt to get a â€œhintâ€ for the text you want.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿è¡Œæç¤ºä»¥è·å¾—ä½ æƒ³è¦çš„æ–‡æœ¬çš„â€œæç¤ºâ€ã€‚
- en: In the same tab, prompt ChatGPT to summarize the last submitted text using the
    â€œhint.â€
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨åŒä¸€ä¸ªæ ‡ç­¾é¡µä¸­ï¼Œæç¤ºChatGPTä½¿ç”¨â€œæç¤ºâ€æ¥æ€»ç»“æœ€åæäº¤çš„æ–‡æœ¬ã€‚
- en: 'Hereâ€™s what Directional Stimilus prompting looks like in practice:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å®è·µä¸­çš„å®šå‘åˆºæ¿€æç¤ºçš„æ ·å­ï¼š
- en: '[PRE23]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ğŸŸ¡ Recursive Criticism and Improvement (RCI) Prompting
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¡ é€’å½’æ‰¹è¯„å’Œæ”¹è¿›ï¼ˆRCIï¼‰æç¤º
- en: 'Despite the fancy name, Recursive Criticism and Improvement prompting is a
    simple technique. You can break it down into three steps:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡åå­—å¾ˆèŠ±å“¨ï¼Œé€’å½’æ‰¹è¯„å’Œæ”¹è¿›æç¤ºæ˜¯ä¸€ç§ç®€å•çš„æŠ€æœ¯ã€‚ä½ å¯ä»¥å°†å…¶åˆ†è§£ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š
- en: Prompt your LLM to generate an output based on an initial prompt (often a Zero-Shot).
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æç¤ºä½ çš„LLMæ ¹æ®åˆå§‹æç¤ºï¼ˆé€šå¸¸æ˜¯é›¶æç¤ºï¼‰ç”Ÿæˆè¾“å‡ºã€‚
- en: Prompt your model to identify potential problems with the output it generated.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æç¤ºä½ çš„æ¨¡å‹è¯†åˆ«ç”Ÿæˆçš„è¾“å‡ºä¸­çš„æ½œåœ¨é—®é¢˜ã€‚
- en: Prompt your model to generate an updated output based on the identified problem.
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æç¤ºä½ çš„æ¨¡å‹æ ¹æ®ç¡®å®šçš„é—®é¢˜ç”Ÿæˆæ›´æ–°çš„è¾“å‡ºã€‚
- en: RCI enhances your LLMsâ€™ reasoning abilities in situations like writing code
    and solving logic puzzles. In fact, researchers found that RCI can outperform
    Chain of Thought (CoT) in some instances.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: RCIå¯ä»¥å¢å¼ºä½ çš„LLMsåœ¨ç¼–å†™ä»£ç å’Œè§£å†³é€»è¾‘è°œé¢˜ç­‰æƒ…å†µä¸‹çš„æ¨ç†èƒ½åŠ›ã€‚äº‹å®ä¸Šï¼Œç ”ç©¶äººå‘˜å‘ç°ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼ŒRCIå¯ä»¥èƒœè¿‡æ€ç»´é“¾ï¼ˆCoTï¼‰ã€‚
- en: '![](../Images/e55390bc1927cbb3543c5bba8feaa118.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e55390bc1927cbb3543c5bba8feaa118.png)'
- en: An example where RCI outperforms Chain of Thought prompting. [Source](https://arxiv.org/abs/2303.17491)
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªRCIä¼˜äºæ€ç»´é“¾æç¤ºçš„ä¾‹å­ã€‚[æ¥æº](https://arxiv.org/abs/2303.17491)
- en: Even better, when you combine RCI with CoT prompting (â€œLetâ€™s think step by stepâ€),
    you get better results than either of the methods used separately.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¥½çš„æ˜¯ï¼Œå½“ä½ å°†RCIä¸CoTæç¤ºï¼ˆâ€œè®©æˆ‘ä»¬é€æ­¥æ€è€ƒâ€ï¼‰ç»“åˆèµ·æ¥æ—¶ï¼Œä½ ä¼šè·å¾—æ¯”å•ç‹¬ä½¿ç”¨ä»»ä½•ä¸€ç§æ–¹æ³•éƒ½æ›´å¥½çš„ç»“æœã€‚
- en: 'Hereâ€™s a framework you can apply to practice RCI:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå¯ä»¥åº”ç”¨äºå®è·µRCIçš„æ¡†æ¶ï¼š
- en: Prompt your model with an instruction of your choice.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨ä½ é€‰æ‹©çš„æŒ‡ä»¤æç¤ºä½ çš„æ¨¡å‹ã€‚
- en: In the same tab, add a new prompt where you ask your model to â€œ**review the
    previous answer and find potential problems in it**.â€
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨åŒä¸€ä¸ªæ ‡ç­¾é¡µä¸­ï¼Œæ·»åŠ ä¸€ä¸ªæ–°çš„æç¤ºï¼Œè¦æ±‚ä½ çš„æ¨¡å‹â€œ**å®¡æŸ¥ä¹‹å‰çš„ç­”æ¡ˆå¹¶æ‰¾å‡ºå…¶ä¸­çš„æ½œåœ¨é—®é¢˜**ã€‚â€
- en: 'If thereâ€™s an error, ChatGPT will try to find it and correct it at the same
    time. Other models can stop after describing the error. In such a case, you can
    add the following prompt: â€œ**Based on the problems you found, improve your answer**.â€'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæœ‰é”™è¯¯ï¼ŒChatGPTå°†å°è¯•åœ¨æè¿°é”™è¯¯åæ‰¾åˆ°å¹¶çº æ­£å®ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥æ·»åŠ ä»¥ä¸‹æç¤ºï¼šâ€œ**æ ¹æ®ä½ æ‰¾åˆ°çš„é—®é¢˜ï¼Œæ”¹è¿›ä½ çš„ç­”æ¡ˆ**ã€‚â€
- en: 'Another option is to combine the two previous prompts into one: â€œ**Please review
    your answer and find every potential problem within it**. **Based on the problems
    you found, improve your answer.**â€'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé€‰é¡¹æ˜¯å°†å‰ä¸¤ä¸ªæç¤ºåˆå¹¶ä¸ºä¸€ä¸ªï¼šâ€œ**è¯·æ£€æŸ¥ä½ çš„ç­”æ¡ˆå¹¶æ‰¾å‡ºå…¶ä¸­çš„æ¯ä¸ªæ½œåœ¨é—®é¢˜**ã€‚**æ ¹æ®ä½ æ‰¾åˆ°çš„é—®é¢˜ï¼Œæ”¹è¿›ä½ çš„ç­”æ¡ˆ**ã€‚â€
- en: Hereâ€™s an example where RCI prompting helped â€œoptimizeâ€ a simple Python script.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªRCIæç¤ºå¸®åŠ©â€œä¼˜åŒ–â€ä¸€ä¸ªç®€å•çš„Pythonè„šæœ¬çš„ä¾‹å­ã€‚
- en: '[PRE24]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/356eed96ddba204cd7bab98928487a8b.png)![](../Images/965fb4a13ef4d494f2802cc1075953e5.png)![](../Images/08806cc37a0a5b7975244543ff5fa424.png)![](../Images/d15f4757b1102b1431bcbc8989ff206b.png)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/356eed96ddba204cd7bab98928487a8b.png)![](../Images/965fb4a13ef4d494f2802cc1075953e5.png)![](../Images/08806cc37a0a5b7975244543ff5fa424.png)![](../Images/d15f4757b1102b1431bcbc8989ff206b.png)'
- en: ğŸŸ¡ Self-Refinement Prompting
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¡ è‡ªæˆ‘å®Œå–„æç¤º
- en: Self-refinement is a variant of RCI prompting. But instead of asking your model
    to find *problems*, you ask it to provide *feedback*. The two techniques are identical
    when the goal is precision and accuracy.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªæˆ‘æ”¹è¿›æ˜¯ RCI æç¤ºçš„ä¸€ç§å˜ä½“ã€‚ä½†ä¸å…¶è¦æ±‚æ¨¡å‹æ‰¾åˆ°*é—®é¢˜*ä¸åŒï¼Œä½ è¦æ±‚å®ƒæä¾›*åé¦ˆ*ã€‚å½“ç›®æ ‡æ˜¯ç²¾ç¡®æ€§å’Œå‡†ç¡®æ€§æ—¶ï¼Œè¿™ä¸¤ç§æŠ€æœ¯æ˜¯ç›¸åŒçš„ã€‚
- en: On the other hand, if you seek creativity and subjective responses, Self-Refinement
    prompts give you more options than RCI.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œå¦‚æœä½ å¯»æ±‚åˆ›é€ åŠ›å’Œä¸»è§‚å›ç­”ï¼Œè‡ªæˆ‘æ”¹è¿›æç¤ºæ¯” RCI æä¾›æ›´å¤šé€‰é¡¹ã€‚
- en: For instance, when you prompt your model to generate a poem, what youâ€™re looking
    for isnâ€™t a clear-cut formula. Rather, itâ€™s an emotion-charged depiction of a
    human experience.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå½“ä½ æç¤ºä½ çš„æ¨¡å‹ç”Ÿæˆä¸€é¦–è¯—æ—¶ï¼Œä½ å¯»æ±‚çš„ä¸æ˜¯ä¸€ä¸ªæ˜ç¡®çš„å…¬å¼ï¼Œè€Œæ˜¯ä¸€ä¸ªå……æ»¡æƒ…æ„Ÿçš„äººç±»ä½“éªŒçš„æç»˜ã€‚
- en: 'In this case, you start by prompting your model to write a poem and then engage
    in a refinement loop where you:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ é¦–å…ˆæç¤ºä½ çš„æ¨¡å‹å†™ä¸€é¦–è¯—ï¼Œç„¶åå‚ä¸ä¸€ä¸ªæ”¹è¿›å¾ªç¯ï¼Œå…¶ä¸­ä½ ï¼š
- en: Ask your model to give feedback on its own response. Use a role prompt to improve
    the quality of the feedback, then add the desired instruction.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯·ä½ çš„æ¨¡å‹å¯¹è‡ªå·±çš„å›ç­”è¿›è¡Œåé¦ˆã€‚ä½¿ç”¨è§’è‰²æç¤ºæ¥æé«˜åé¦ˆçš„è´¨é‡ï¼Œç„¶åæ·»åŠ æ‰€éœ€çš„æŒ‡ç¤ºã€‚
- en: '[PRE25]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Ask your model to improve its response based on its own feedback.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯·ä½ çš„æ¨¡å‹æ ¹æ®è‡ªå·±çš„åé¦ˆæ”¹è¿›å›ç­”ã€‚
- en: '[PRE26]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Add your own feedback if needed.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœ‰éœ€è¦ï¼Œè¯·æ·»åŠ ä½ è‡ªå·±çš„åé¦ˆã€‚
- en: Repeat the previous steps until you reach the desired outcome.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡å¤å‰é¢çš„æ­¥éª¤ï¼Œç›´åˆ°è¾¾åˆ°æœŸæœ›çš„ç»“æœã€‚
- en: 'Hereâ€™s an example:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­ï¼š
- en: '[PRE27]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](../Images/1ddc6eff6b34693531ca32ffa3a41ab7.png)![](../Images/d098a59d548a1f9b579c1bbbd7b81ca1.png)![](../Images/b7b4505794f10c643ff1c94f8c94b063.png)![](../Images/49e3993a7e50a759bcc342d861efed64.png)![](../Images/37ed832b4959c4b04246c37fdf7e190b.png)![](../Images/8410316a2c525b922c1a0703eb3b894c.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ddc6eff6b34693531ca32ffa3a41ab7.png)![](../Images/d098a59d548a1f9b579c1bbbd7b81ca1.png)![](../Images/b7b4505794f10c643ff1c94f8c94b063.png)![](../Images/49e3993a7e50a759bcc342d861efed64.png)![](../Images/37ed832b4959c4b04246c37fdf7e190b.png)![](../Images/8410316a2c525b922c1a0703eb3b894c.png)'
- en: ChatGPTâ€™s output for a series of Self-Refinement prompts about writing a Linkedin
    post.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT å¯¹ä¸€ç³»åˆ—å…³äºæ’°å†™é¢†è‹±å¸–å­çš„è‡ªæˆ‘æ”¹è¿›æç¤ºçš„è¾“å‡ºã€‚
- en: I kept the quality of the prompts low to illustrate a crucial point of self-refinement
    prompting. Depending on how you steer the feedback loop, **you may end up degrading
    the output.** It takes practice and domain-specific expertise to maximize the
    potential of self-refinement prompting.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†æç¤ºçš„è´¨é‡ä¿æŒè¾ƒä½ï¼Œä»¥è¯´æ˜è‡ªæˆ‘æ”¹è¿›æç¤ºçš„ä¸€ä¸ªå…³é”®ç‚¹ã€‚æ ¹æ®ä½ å¦‚ä½•å¼•å¯¼åé¦ˆå¾ªç¯ï¼Œ**ä½ å¯èƒ½ä¼šé™ä½è¾“å‡ºçš„è´¨é‡**ã€‚è¦æœ€å¤§é™åº¦åœ°å‘æŒ¥è‡ªæˆ‘æ”¹è¿›æç¤ºçš„æ½œåŠ›ï¼Œéœ€è¦å®è·µå’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†ã€‚
- en: Thereâ€™s a dedicated section about iterations and refinement. Itâ€™s titled â€œIterate
    until you have to revert.â€
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ä¸ªä¸“é—¨è®²è¿°è¿­ä»£å’Œæ”¹è¿›çš„éƒ¨åˆ†ï¼Œæ ‡é¢˜ä¸ºâ€œè¿­ä»£ç›´åˆ°å¿…é¡»è¿˜åŸâ€ã€‚
- en: ğŸŸ¡ Reverse Prompt Engineering
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¡ é€†å‘æç¤ºå·¥ç¨‹
- en: Reverse engineering is the art of building things backward â€” and you can use
    it on prompts.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: é€†å‘å·¥ç¨‹æ˜¯å‘åæ„å»ºäº‹ç‰©çš„è‰ºæœ¯ï¼Œä½ å¯ä»¥åœ¨æç¤ºä¸Šä½¿ç”¨å®ƒã€‚
- en: Instead of writing a prompt to generate a response, start with a high-quality
    version of the desired response and work your way back to a prompt.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦å†™ä¸€ä¸ªæç¤ºæ¥ç”Ÿæˆå›ç­”ï¼Œè€Œæ˜¯ä»æœŸæœ›çš„å›ç­”çš„é«˜è´¨é‡ç‰ˆæœ¬å¼€å§‹ï¼Œç„¶åé€æ­¥å›æº¯åˆ°æç¤ºã€‚
- en: Another way to highlight the difference between classic prompting and reverse
    prompt engineering is to turn each technique into a question.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§çªå‡ºç»å…¸æç¤ºå’Œé€†å‘æç¤ºå·¥ç¨‹ä¹‹é—´å·®å¼‚çš„æ–¹æ³•æ˜¯å°†æ¯ç§æŠ€æœ¯è½¬åŒ–ä¸ºä¸€ä¸ªé—®é¢˜ã€‚
- en: 'Traditional prompting: â€œHere are the directions. Can you get me there?â€'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿæç¤ºï¼šâ€œè¿™æ˜¯æ–¹å‘ã€‚ä½ èƒ½å¸®æˆ‘åˆ°é‚£é‡Œå—ï¼Ÿâ€
- en: 'Reverse-Engineered prompting: â€œHereâ€™s the destination I want to reach. Can
    you show me the directions to get there?â€'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€†å‘å·¥ç¨‹æç¤ºï¼šâ€œè¿™æ˜¯æˆ‘æƒ³è¦è¾¾åˆ°çš„ç›®çš„åœ°ã€‚ä½ èƒ½ç»™æˆ‘å±•ç¤ºåˆ°è¾¾é‚£é‡Œçš„è·¯çº¿å—ï¼Ÿâ€
- en: This method shines in two situations. The first is when seek inspiration to
    write your prompt. The second is when your goal is to generate output with very
    specific formats â€” like a board game, a landing page, or a recipe. Letâ€™s explore
    an example involving the latter.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•åœ¨ä¸¤ç§æƒ…å†µä¸‹éå¸¸å‡ºè‰²ã€‚ç¬¬ä¸€ç§æƒ…å†µæ˜¯å½“ä½ å¯»æ±‚çµæ„Ÿæ¥å†™ä½ çš„æç¤ºæ—¶ã€‚ç¬¬äºŒç§æƒ…å†µæ˜¯å½“ä½ çš„ç›®æ ‡æ˜¯ç”Ÿæˆå…·æœ‰éå¸¸ç‰¹å®šæ ¼å¼çš„è¾“å‡ºï¼Œæ¯”å¦‚æ£‹ç›˜æ¸¸æˆã€è½åœ°é¡µæˆ–é£Ÿè°±ã€‚è®©æˆ‘ä»¬æ¢ç´¢ä¸€ä¸ªæ¶‰åŠåè€…çš„ä¾‹å­ã€‚
- en: '[PRE28]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ğŸŸ¡ Prompt Revision
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¡ æç¤ºä¿®è®¢
- en: This technique may seem similar to Reverse Prompt Engineering, but thereâ€™s a
    tiny difference. Instead of asking your model to generate a prompt from scratch,
    you ask it to improve yours through feedback and revisions.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æŠ€æœ¯å¯èƒ½ä¸é€†å‘æç¤ºå·¥ç¨‹ç›¸ä¼¼ï¼Œä½†æœ‰ä¸€ä¸ªå¾®å°çš„åŒºåˆ«ã€‚ä½ ä¸æ˜¯è¦æ±‚ä½ çš„æ¨¡å‹ä»å¤´å¼€å§‹ç”Ÿæˆæç¤ºï¼Œè€Œæ˜¯é€šè¿‡åé¦ˆå’Œä¿®è®¢æ¥æ”¹è¿›ä½ çš„æç¤ºã€‚
- en: Prompt Revision is useful for intermediate and expert prompt engineers. Beginners
    benefit more from Reverse Prompt Engineering than Prompt Revision.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºä¿®è®¢å¯¹ä¸­çº§å’Œä¸“å®¶çº§æç¤ºå·¥ç¨‹å¸ˆå¾ˆæœ‰ç”¨ã€‚åˆå­¦è€…æ¯”èµ·æç¤ºä¿®è®¢æ›´é€‚åˆé€†å‘æç¤ºå·¥ç¨‹ã€‚
- en: '**When youâ€™re a beginner**, **you donâ€™t have enough skills to recognize your
    mistakes.** Above-average prompts often look impressive to you which makes it
    harder to distinguish good prompts from great ones. Thatâ€™s why you want to stick
    to the basics until you develop reflexes and intuitions.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å½“ä½ æ˜¯ä¸€ä¸ªåˆå­¦è€…æ—¶**ï¼Œ**ä½ æ²¡æœ‰è¶³å¤Ÿçš„æŠ€èƒ½æ¥è¯†åˆ«ä½ çš„é”™è¯¯ã€‚**å¯¹ä½ æ¥è¯´ï¼Œé«˜äºå¹³å‡æ°´å¹³çš„æç¤ºé€šå¸¸çœ‹èµ·æ¥ä»¤äººå°è±¡æ·±åˆ»ï¼Œè¿™ä½¿å¾—åŒºåˆ†å¥½çš„æç¤ºå’Œä¼˜ç§€çš„æç¤ºæ›´åŠ å›°éš¾ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ è¦åšæŒåŸºç¡€çŸ¥è¯†ï¼Œç›´åˆ°ä½ åŸ¹å…»å‡ºååº”å’Œç›´è§‰ã€‚'
- en: '**When you reach an intermediate level, you learn to identify your weaknesses.**
    Prompt Revision helps you identify and overcome your blind spots. It can also
    provide subtle changes that can improve your promptsâ€™ output. Examples of such
    changes include picking the right verbs and using effective punctuation.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å½“ä½ è¾¾åˆ°ä¸­çº§æ°´å¹³æ—¶ï¼Œä½ å­¦ä¼šäº†è¯†åˆ«è‡ªå·±çš„å¼±ç‚¹ã€‚**æç¤ºä¿®è®¢å¯ä»¥å¸®åŠ©ä½ è¯†åˆ«å’Œå…‹æœä½ çš„ç›²ç‚¹ã€‚å®ƒè¿˜å¯ä»¥æä¾›å¾®å°çš„å˜åŒ–ï¼Œä»¥æ”¹å–„ä½ çš„æç¤ºè¾“å‡ºã€‚è¿™äº›å˜åŒ–çš„ä¾‹å­åŒ…æ‹¬é€‰æ‹©æ­£ç¡®çš„åŠ¨è¯å’Œä½¿ç”¨æœ‰æ•ˆçš„æ ‡ç‚¹ç¬¦å·ã€‚'
- en: '**When you approach the expert level, you start to optimize every word you
    write in a prompt.** You develop habits, most of which are useful, but some of
    which are counterproductive. In a way, prompting is a bit like cycling â€” at the
    beginning, you master the correct posture but you later find (bad) shortcuts that
    work just for you. Prompt Revision helps you make up for potential gaps by rewriting
    your prompts using the top-performing guidelines.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å½“ä½ è¾¾åˆ°ä¸“å®¶çº§åˆ«æ—¶ï¼Œä½ å¼€å§‹ä¼˜åŒ–ä½ åœ¨æç¤ºä¸­å†™çš„æ¯ä¸€ä¸ªå­—ã€‚**ä½ å…»æˆäº†ä¸€äº›ä¹ æƒ¯ï¼Œå…¶ä¸­å¤§éƒ¨åˆ†æ˜¯æœ‰ç”¨çš„ï¼Œä½†æœ‰äº›æ˜¯é€‚å¾—å…¶åçš„ã€‚åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œæç¤ºæœ‰ç‚¹åƒéª‘è‡ªè¡Œè½¦â€”â€”ä¸€å¼€å§‹ï¼Œä½ æŒæ¡äº†æ­£ç¡®çš„å§¿åŠ¿ï¼Œä½†åæ¥ä½ å‘ç°äº†ï¼ˆä¸å¥½çš„ï¼‰æ·å¾„ï¼Œè¿™äº›æ·å¾„åªé€‚åˆä½ è‡ªå·±ã€‚æç¤ºä¿®è®¢å¯ä»¥é€šè¿‡ä½¿ç”¨è¡¨ç°æœ€ä½³çš„æŒ‡å—æ¥é‡å†™ä½ çš„æç¤ºï¼Œå¼¥è¡¥æ½œåœ¨çš„å·®è·ã€‚'
- en: Hereâ€™s a Prompt Revision example shared by [Alex Albert,](https://twitter.com/alexalbert__?lang=en)
    a prompt engineer and jailbreaker.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªç”±[äºšå†å…‹æ–¯Â·é˜¿å°”ä¼¯ç‰¹](https://twitter.com/alexalbert__?lang=en)ï¼ˆä¸€ä½æç¤ºå·¥ç¨‹å¸ˆå’Œè¶Šç‹±è€…ï¼‰åˆ†äº«çš„æç¤ºä¿®è®¢ç¤ºä¾‹ã€‚
- en: '[PRE29]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: ğŸŸ¡ Program Simulation Prompting
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¡ç¨‹åºæ¨¡æ‹Ÿæç¤º
- en: Program Simulation is a particular case of Role prompting where you ask your
    model to behave like a mini app.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨‹åºæ¨¡æ‹Ÿæ˜¯è§’è‰²æç¤ºçš„ä¸€ä¸ªç‰¹æ®Šæƒ…å†µï¼Œä½ è¦æ±‚ä½ çš„æ¨¡å‹åƒä¸€ä¸ªå°å‹åº”ç”¨ç¨‹åºä¸€æ ·è¿è¡Œã€‚
- en: Technically, your model wonâ€™t develop an app from scratch and run it on some
    invisible server. Instead, your LLM will behave like a small program that operates
    inside a chat tab.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æŠ€æœ¯ä¸Šè®²ï¼Œä½ çš„æ¨¡å‹ä¸ä¼šä»å¤´å¼€å§‹å¼€å‘ä¸€ä¸ªåº”ç”¨ç¨‹åºå¹¶åœ¨æŸä¸ªçœ‹ä¸è§çš„æœåŠ¡å™¨ä¸Šè¿è¡Œã€‚ç›¸åï¼Œä½ çš„LLMå°†åƒä¸€ä¸ªåœ¨èŠå¤©æ ‡ç­¾å†…è¿è¡Œçš„å°ç¨‹åºä¸€æ ·è¿è¡Œã€‚
- en: The emulated program functions like an automated voice message system. Think
    of when you call a fancy restaurant and hear a recorded voice telling you to â€œtype
    1 to make a new reservation or type 2 to cancel an existing reservation.â€
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿçš„ç¨‹åºçš„åŠŸèƒ½ç±»ä¼¼äºè‡ªåŠ¨è¯­éŸ³ç•™è¨€ç³»ç»Ÿã€‚æƒ³è±¡ä¸€ä¸‹å½“ä½ æ‰“ç”µè¯ç»™ä¸€ä¸ªé«˜æ¡£é¤å…æ—¶ï¼Œå¬åˆ°ä¸€ä¸ªå½•éŸ³å‘Šè¯‰ä½ â€œæŒ‰1é”®è¿›è¡Œæ–°é¢„è®¢ï¼ŒæŒ‰2é”®å–æ¶ˆç°æœ‰é¢„è®¢ã€‚â€
- en: '![](../Images/b1e2767521f1cc6b9fc8756c14f6d2b9.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1e2767521f1cc6b9fc8756c14f6d2b9.png)'
- en: You can see the output of a Program Simulation prompt as a decision tree where
    every possible outcome is pre-determined by a script. Your prompt makes for the
    script or at least part of it.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å°†ç¨‹åºæ¨¡æ‹Ÿæç¤ºçš„è¾“å‡ºçœ‹ä½œæ˜¯ä¸€ä¸ªå†³ç­–æ ‘ï¼Œå…¶ä¸­æ¯ä¸ªå¯èƒ½çš„ç»“æœéƒ½æ˜¯ç”±è„šæœ¬é¢„å…ˆç¡®å®šçš„ã€‚ä½ çš„æç¤ºå°±æ˜¯è„šæœ¬ï¼Œæˆ–è€…è‡³å°‘æ˜¯å…¶ä¸­çš„ä¸€éƒ¨åˆ†ã€‚
- en: In fact, you can write a prompt that defines the main branches of the decision
    tree and let your LLM fill in the blanks.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œä½ å¯ä»¥ç¼–å†™ä¸€ä¸ªå®šä¹‰å†³ç­–æ ‘ä¸»è¦åˆ†æ”¯çš„æç¤ºï¼Œç„¶åè®©ä½ çš„LLMå¡«å……ç©ºç™½ã€‚
- en: 'Letâ€™s illustrate with an example:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜ï¼š
- en: '[PRE30]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Notice how the prompt only defines the five main branches of the desired decision
    tree. The description of each of these five branches is an implicit instruction
    for your LLM to complete the decision tree.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æç¤ºåªå®šä¹‰äº†æ‰€éœ€å†³ç­–æ ‘çš„äº”ä¸ªä¸»è¦åˆ†æ”¯ã€‚æ¯ä¸ªåˆ†æ”¯çš„æè¿°éƒ½æ˜¯å¯¹ä½ çš„LLMå®Œæˆå†³ç­–æ ‘çš„éšå«æŒ‡ä»¤ã€‚
- en: 'Hereâ€™s what the output of the previous prompt looks like:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å‰ä¸€ä¸ªæç¤ºçš„è¾“å‡ºç»“æœï¼š
- en: '![](../Images/1aa6b2e28a7230ac97b5073f6b34ff4a.png)![](../Images/3461dec317e5a6fbffc25ac53fa601ca.png)![](../Images/7b3e99cf7342181387e5f4fddcb89122.png)![](../Images/fb811e3b30b89c0bddf8aee337739e2e.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1aa6b2e28a7230ac97b5073f6b34ff4a.png)![](../Images/3461dec317e5a6fbffc25ac53fa601ca.png)![](../Images/7b3e99cf7342181387e5f4fddcb89122.png)![](../Images/fb811e3b30b89c0bddf8aee337739e2e.png)'
- en: Example of Program Simulation prompting.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨‹åºæ¨¡æ‹Ÿæç¤ºçš„ç¤ºä¾‹ã€‚
- en: ğŸŸ  All-In-One (AIO) Prompting*
  id: totrans-387
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ å…¨èƒ½æç¤ºï¼ˆAIOï¼‰*
- en: All-In-One (AIO) is an extended version of Role Prompting where you give your
    model a detailed list of instructions, turning it into a â€œspecializedâ€ version
    of itself.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: All-In-Oneï¼ˆAIOï¼‰æ˜¯è§’è‰²æç¤ºçš„æ‰©å±•ç‰ˆæœ¬ï¼Œä½ å¯ä»¥ç»™ä½ çš„æ¨¡å‹æä¾›è¯¦ç»†çš„æŒ‡ä»¤åˆ—è¡¨ï¼Œå°†å…¶è½¬å˜ä¸ºä¸€ä¸ªâ€œä¸“é—¨â€çš„ç‰ˆæœ¬ã€‚
- en: I called it All-In-One because you can combine all of the previous techniques
    to emulate a specialized LLM inside another LLM.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç§°ä¹‹ä¸ºå…¨èƒ½æç¤ºï¼Œå› ä¸ºä½ å¯ä»¥å°†ä¹‹å‰çš„æ‰€æœ‰æŠ€å·§ç»“åˆèµ·æ¥ï¼Œæ¨¡æ‹Ÿä¸€ä¸ªä¸“é—¨çš„LLMåœ¨å¦ä¸€ä¸ªLLMå†…éƒ¨è¿è¡Œã€‚
- en: Microsoft used a similar approach to create Bing Chat out of GPT-4\. They fine-tuned
    some version of GPT-4 and equipped it with extra functions like online search
    and annotations.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: å¾®è½¯ä½¿ç”¨ç±»ä¼¼çš„æ–¹æ³•ï¼Œå°†Bing Chatä»GPT-4ä¸­åˆ›å»ºå‡ºæ¥ã€‚ä»–ä»¬å¯¹æŸä¸ªç‰ˆæœ¬çš„GPT-4è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶é…å¤‡äº†åœ¨çº¿æœç´¢å’Œæ³¨é‡Šç­‰é¢å¤–åŠŸèƒ½ã€‚
- en: All-In-One prompting involves two steps.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: All-In-Oneæç¤ºåŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤ã€‚
- en: Prompt your model to behave as if it were a raw version of itself. Technically
    speaking, it wonâ€™t do that, but itâ€™ll pretend as if it does, which is good enough.
    Youâ€™ll be able to steer the behavior of ChatGPT (and other models) in a specific
    direction.
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æç¤ºä½ çš„æ¨¡å‹è¡¨ç°å¾—å¥½åƒå®ƒæ˜¯ä¸€ä¸ªåŸå§‹ç‰ˆæœ¬çš„è‡ªå·±ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œå®ƒä¸ä¼šè¿™æ ·åšï¼Œä½†å®ƒä¼šå‡è£…è‡ªå·±è¿™æ ·åšï¼Œè¿™å·²ç»è¶³å¤Ÿå¥½äº†ã€‚ä½ å°†èƒ½å¤Ÿå¼•å¯¼ChatGPTï¼ˆå’Œå…¶ä»–æ¨¡å‹ï¼‰çš„è¡Œä¸ºæœç‰¹å®šæ–¹å‘å‘å±•ã€‚
- en: Prompt your model as if youâ€™re â€œfine-tuningâ€ it. Note that fine-tuning is much
    more complex than writing a lengthy prompt. The real process involves training
    your model on new data, applying reinforcement learning through human feedback,
    and other adjustments. In the case of AIO prompting, youâ€™ll only ask your LLM
    to behave in a very precise manner, similar to Role prompting but with a more
    significant amount of details.
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æç¤ºä½ çš„æ¨¡å‹å°±åƒä½ åœ¨â€œå¾®è°ƒâ€å®ƒä¸€æ ·ã€‚è¯·æ³¨æ„ï¼Œå¾®è°ƒæ¯”ç¼–å†™å†—é•¿çš„æç¤ºè¦å¤æ‚å¾—å¤šã€‚çœŸæ­£çš„è¿‡ç¨‹æ¶‰åŠåœ¨æ–°æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œé€šè¿‡äººç±»åé¦ˆåº”ç”¨å¼ºåŒ–å­¦ä¹ ä»¥åŠå…¶ä»–è°ƒæ•´ã€‚åœ¨AIOæç¤ºçš„æƒ…å†µä¸‹ï¼Œä½ åªéœ€è¦æ±‚ä½ çš„LLMä»¥éå¸¸ç²¾ç¡®çš„æ–¹å¼è¡Œä¸ºï¼Œç±»ä¼¼äºè§’è‰²æç¤ºï¼Œä½†å…·æœ‰æ›´å¤šçš„ç»†èŠ‚ã€‚
- en: 'Letâ€™s illustrate AIO prompting with an example:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜AIOæç¤ºï¼š
- en: '[PRE31]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As discussed above, the second part of AIO combines many techniques. For instance,
    thereâ€™s role prompting, temperature control, chain-of-thought, and knowledge integration.
    You donâ€™t have to use every single prompting technique you know, only the relevant
    ones.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šæ‰€è¿°ï¼ŒAIOçš„ç¬¬äºŒéƒ¨åˆ†ç»“åˆäº†è®¸å¤šæŠ€æœ¯ã€‚ä¾‹å¦‚ï¼Œæœ‰è§’è‰²æç¤ºã€æ¸©åº¦æ§åˆ¶ã€æ€ç»´é“¾å’ŒçŸ¥è¯†æ•´åˆã€‚ä½ ä¸å¿…ä½¿ç”¨ä½ æ‰€çŸ¥é“çš„æ¯ä¸€ç§æç¤ºæŠ€æœ¯ï¼Œåªéœ€ä½¿ç”¨ç›¸å…³çš„æŠ€æœ¯å³å¯ã€‚
- en: Now letâ€™s go through a simple template you can use to generate your own AI assistants
    using AIO prompting.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„æ¨¡æ¿æ¥ç”Ÿæˆä½ è‡ªå·±çš„AIåŠ©æ‰‹ï¼Œä½¿ç”¨AIOæç¤ºã€‚
- en: ğŸŸ¢ Template for All-In-One (AIO) Prompting
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ All-In-Oneï¼ˆAIOï¼‰æç¤ºæ¨¡æ¿
- en: When writing an AIO prompt, be as specific as possible and adjust the prompt
    to the problem you want to solve. (You can also ask Bernard to help you improve
    your original prompt).
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¼–å†™AIOæç¤ºæ—¶ï¼Œå°½å¯èƒ½å…·ä½“ï¼Œå¹¶æ ¹æ®ä½ æƒ³è§£å†³çš„é—®é¢˜è°ƒæ•´æç¤ºã€‚ï¼ˆä½ ä¹Ÿå¯ä»¥è¯·ä¼¯çº³å¾·å¸®åŠ©ä½ æ”¹è¿›åŸå§‹æç¤ºï¼‰ã€‚
- en: Test your prompt over and over again until you reach a satisfying result. Remember,
    Language Models like ChatGPT (GPT-4) have powerful capabilities, but most of these
    capabilities remain asleep until you wake them up.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤æµ‹è¯•ä½ çš„æç¤ºï¼Œç›´åˆ°è¾¾åˆ°æ»¡æ„çš„ç»“æœã€‚è®°ä½ï¼ŒChatGPTï¼ˆGPT-4ï¼‰ç­‰è¯­è¨€æ¨¡å‹å…·æœ‰å¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†å¤§éƒ¨åˆ†è¿™äº›èƒ½åŠ›åœ¨ä½ å”¤é†’å®ƒä»¬ä¹‹å‰éƒ½å¤„äºä¼‘çœ çŠ¶æ€ã€‚
- en: The following template wonâ€™t take you there right away, but itâ€™ll put you on
    track. Youâ€™ll find generic labels like <Topic_name> to make it easier to understand
    AIO prompting.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ¨¡æ¿ä¸ä¼šç«‹å³å¸®åŠ©ä½ è¾¾åˆ°ç›®æ ‡ï¼Œä½†å®ƒä¼šè®©ä½ èµ°ä¸Šæ­£è½¨ã€‚ä½ ä¼šå‘ç°åƒ<Topic_name>è¿™æ ·çš„é€šç”¨æ ‡ç­¾ï¼Œä»¥ä¾¿æ›´å®¹æ˜“ç†è§£AIOæç¤ºã€‚
- en: '[PRE32]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Hereâ€™s how to use the template.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯å¦‚ä½•ä½¿ç”¨æ¨¡æ¿çš„æ–¹æ³•ã€‚
- en: Replace <Model_name> with a name of your choosing.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨ä½ é€‰æ‹©çš„åç§°æ›¿æ¢<Model_name>ã€‚
- en: Replace <Field_name> with the expertise you want your model to emulate.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨ä½ æƒ³è¦ä½ çš„æ¨¡å‹æ¨¡æ‹Ÿçš„ä¸“ä¸šçŸ¥è¯†æ›¿æ¢<Field_name>ã€‚
- en: Replace <Topic_name> with a specific topic within the area of expertise you
    chose.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨ä½ é€‰æ‹©çš„ä¸“ä¸šé¢†åŸŸä¸­çš„ç‰¹å®šä¸»é¢˜æ›¿æ¢<Topic_name>ã€‚
- en: Replace <Tone_type> with the desired tone.
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨æ‰€éœ€çš„è¯­æ°”ç±»å‹æ›¿æ¢<Tone_type>ã€‚
- en: Replace <Style_type> with the desired style.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨æ‰€éœ€çš„é£æ ¼ç±»å‹æ›¿æ¢<Style_type>ã€‚
- en: Remove the name of the techniques from the initial template.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»åˆå§‹æ¨¡æ¿ä¸­åˆ é™¤æŠ€æœ¯åç§°ã€‚
- en: Add your own instructions.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ ä½ è‡ªå·±çš„è¯´æ˜ã€‚
- en: Test your prompt.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹è¯•ä½ çš„æç¤ºã€‚
- en: Adjust it.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è°ƒæ•´å®ƒã€‚
- en: Iterate until you reach a satisfying result.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå¤è¿­ä»£ï¼Œç›´åˆ°è¾¾åˆ°æ»¡æ„çš„ç»“æœã€‚
- en: ğŸŸ¢ More examples of All-In-One Prompting*
  id: totrans-414
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŸ¢ æ›´å¤šAll-In-Oneæç¤ºç¤ºä¾‹*
- en: The following is a list of AIO examples covering various applications. Modify
    them to make them your own. Youâ€™ll find a few hints to help you get started.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æ¶µç›–å„ç§åº”ç”¨çš„AIOç¤ºä¾‹åˆ—è¡¨ã€‚ä¿®æ”¹å®ƒä»¬ä½¿å…¶æˆä¸ºä½ è‡ªå·±çš„ã€‚ä½ ä¼šæ‰¾åˆ°ä¸€äº›æç¤ºæ¥å¸®åŠ©ä½ å…¥é—¨ã€‚
- en: Dolores, the Email Muse
  id: totrans-416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤šæ´›ä¸½ä¸ï¼Œç”µå­é‚®ä»¶çµæ„Ÿ
- en: '[PRE33]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Robert Ford, the Coding Master
  id: totrans-418
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç½—ä¼¯ç‰¹Â·ç¦ç‰¹ï¼Œç¼–ç å¤§å¸ˆ
- en: '[PRE34]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Lee Sizemore, the Outlandish Chef
  id: totrans-420
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æÂ·è¥¿å…¹è«å°”ï¼Œå¥‡å¼‚çš„å¨å¸ˆ
- en: '[PRE35]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Maeve the Mastermind
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¢…èŠ™ï¼Œç­–åˆ’å¤§å¸ˆ
- en: '[PRE36]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The secret sauce of AIO prompting is your professional expertise. The more you
    know about a topic, the higher the quality of your prompt because youâ€™ll think
    of details that others may miss.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: AIOæç¤ºçš„ç§˜å¯†æ­¦å™¨æ˜¯ä½ çš„ä¸“ä¸šçŸ¥è¯†ã€‚ä½ å¯¹ä¸€ä¸ªä¸»é¢˜äº†è§£å¾—è¶Šå¤šï¼Œä½ çš„æç¤ºè´¨é‡å°±è¶Šé«˜ï¼Œå› ä¸ºä½ ä¼šæƒ³åˆ°å…¶ä»–äººå¯èƒ½ä¼šå¿½ç•¥çš„ç»†èŠ‚ã€‚
- en: Prompt engineering is an empirical science, and the best way to learn it is
    through regular practice. Hit the keyboard as much as possible and make sure to
    keep in touch with AI literature to upgrade your techniques.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå·¥ç¨‹æ˜¯ä¸€é—¨ç»éªŒç§‘å­¦ï¼Œå­¦ä¹ å®ƒçš„æœ€ä½³æ–¹å¼æ˜¯é€šè¿‡å®šæœŸç»ƒä¹ ã€‚å°½å¯èƒ½å¤šåœ°æ•²å‡»é”®ç›˜ï¼Œå¹¶ç¡®ä¿ä¸äººå·¥æ™ºèƒ½æ–‡çŒ®ä¿æŒè”ç³»ï¼Œä»¥æå‡ä½ çš„æŠ€æœ¯ã€‚
- en: ğŸ’¡ Iterate until you have to revert
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¡ è¿­ä»£ç›´åˆ°ä½ ä¸å¾—ä¸å›é€€
- en: The output of Language Models is like a decision tree with thousands of possible
    outcomes. Each word predicted by the model branches out into a set of new possibilities,
    most of which are invisible to you. The only part thatâ€™s under your control is
    the starting point â€” and thatâ€™s your prompt.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: è¯­è¨€æ¨¡å‹çš„è¾“å‡ºå°±åƒä¸€ä¸ªå†³ç­–æ ‘ï¼Œæœ‰æˆåƒä¸Šä¸‡ç§å¯èƒ½çš„ç»“æœã€‚æ¨¡å‹é¢„æµ‹çš„æ¯ä¸ªè¯éƒ½ä¼šåˆ†æ”¯å‡ºä¸€ç³»åˆ—æ–°çš„å¯èƒ½æ€§ï¼Œå…¶ä¸­å¤§éƒ¨åˆ†å¯¹ä½ æ¥è¯´æ˜¯ä¸å¯è§çš„ã€‚å”¯ä¸€åœ¨ä½ æ§åˆ¶ä¹‹ä¸‹çš„æ˜¯èµ·ç‚¹
    â€”â€” ä¹Ÿå°±æ˜¯ä½ çš„æç¤ºã€‚
- en: One major difference between Language Models and decision trees is the presence
    of randomness. The same prompt doesnâ€™t always generate the same response. Itâ€™s
    the price we pay for creativity.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: è¯­è¨€æ¨¡å‹å’Œå†³ç­–æ ‘ä¹‹é—´çš„ä¸€ä¸ªä¸»è¦åŒºåˆ«æ˜¯å­˜åœ¨éšæœºæ€§ã€‚åŒä¸€ä¸ªæç¤ºå¹¶ä¸æ€»æ˜¯ç”Ÿæˆç›¸åŒçš„å“åº”ã€‚è¿™æ˜¯æˆ‘ä»¬ä¸ºåˆ›é€ åŠ›ä»˜å‡ºçš„ä»£ä»·ã€‚
- en: Thereâ€™s also the alignment tax, where the modelâ€™s behavior (and capability)
    can change to meet (new) restrictions. And to top things off, nobody really knows
    whatâ€™s happening inside Language Models.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰å¯¹é½ç¨ï¼Œæ¨¡å‹çš„è¡Œä¸ºï¼ˆå’Œèƒ½åŠ›ï¼‰å¯èƒ½ä¼šæ”¹å˜ä»¥æ»¡è¶³ï¼ˆæ–°çš„ï¼‰é™åˆ¶ã€‚æ›´ç³Ÿçš„æ˜¯ï¼Œæ²¡æœ‰äººçœŸæ­£çŸ¥é“è¯­è¨€æ¨¡å‹å†…éƒ¨å‘ç”Ÿäº†ä»€ä¹ˆã€‚
- en: 'In short, when you use a Language Model, youâ€™re interacting with an unpredictable
    black box. You canâ€™t really rely on exact science: trial and error is your best
    option.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€è€Œè¨€ä¹‹ï¼Œå½“ä½ ä½¿ç”¨è¯­è¨€æ¨¡å‹æ—¶ï¼Œä½ æ­£åœ¨ä¸ä¸€ä¸ªä¸å¯é¢„æµ‹çš„é»‘åŒ£å­è¿›è¡Œäº¤äº’ã€‚ä½ ä¸èƒ½çœŸæ­£ä¾èµ–ç²¾ç¡®çš„ç§‘å­¦ï¼šè¯•é”™æ˜¯ä½ æœ€å¥½çš„é€‰æ‹©ã€‚
- en: 'The rule is simple: Iterate on your prompt until the latest version of your
    output becomes worse than the previous one. In other words, iterate until you
    have to revert.'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: è§„åˆ™å¾ˆç®€å•ï¼šåœ¨ä½ çš„æç¤ºä¸Šè¿›è¡Œè¿­ä»£ï¼Œç›´åˆ°æœ€æ–°ç‰ˆæœ¬çš„è¾“å‡ºå˜å¾—æ¯”ä¹‹å‰çš„æ›´ç³Ÿã€‚æ¢å¥è¯è¯´ï¼Œè¿­ä»£ç›´åˆ°ä½ ä¸å¾—ä¸å›é€€ã€‚
- en: 'Iteration comes in two flavors: either try different versions of the same prompt
    or guide the model through a succession of prompts. In most cases, youâ€™ll use
    a combination of both.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: è¿­ä»£æœ‰ä¸¤ç§æ–¹å¼ï¼šè¦ä¹ˆå°è¯•åŒä¸€ä¸ªæç¤ºçš„ä¸åŒç‰ˆæœ¬ï¼Œè¦ä¹ˆé€šè¿‡ä¸€ç³»åˆ—æç¤ºå¼•å¯¼æ¨¡å‹ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ ä¼šåŒæ—¶ä½¿ç”¨ä¸¤ç§æ–¹å¼ã€‚
- en: '![](../Images/f5595a1f463d23797dc7226e13debd22.png)'
  id: totrans-433
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5595a1f463d23797dc7226e13debd22.png)'
- en: Illustration of how the quality of your output evolves with prompt iterations.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: è¯´æ˜äº†éšç€æç¤ºè¿­ä»£æ¬¡æ•°çš„å¢åŠ ï¼Œä½ çš„è¾“å‡ºè´¨é‡æ˜¯å¦‚ä½•å‘å±•çš„ã€‚
- en: To better understand how the iterative process works, picture prompting as a
    concave function (or a bell curve). Your first iterations are likely to get you
    better results, but at some point, your new prompt will start to generate worse
    output compared to its predecessors.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ›´å¥½åœ°ç†è§£è¿­ä»£è¿‡ç¨‹çš„å·¥ä½œåŸç†ï¼ŒæŠŠæç¤ºæƒ³è±¡æˆä¸€ä¸ªå‡¹å‡½æ•°ï¼ˆæˆ–è€…é’Ÿå½¢æ›²çº¿ï¼‰ã€‚ä½ çš„ç¬¬ä¸€æ¬¡è¿­ä»£å¾ˆå¯èƒ½ä¼šå¸¦æ¥æ›´å¥½çš„ç»“æœï¼Œä½†åœ¨æŸä¸ªæ—¶åˆ»ï¼Œä½ çš„æ–°æç¤ºå°†å¼€å§‹ç”Ÿæˆæ¯”ä¹‹å‰æ›´ç³Ÿçš„è¾“å‡ºã€‚
- en: Pay attention to the inflection point, and when you reach it, you want to either
    settle or start a new chain of prompts.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æ‹ç‚¹ï¼Œå½“ä½ åˆ°è¾¾æ‹ç‚¹æ—¶ï¼Œä½ è¦ä¹ˆåœä¸‹æ¥ï¼Œè¦ä¹ˆå¼€å§‹ä¸€ä¸ªæ–°çš„æç¤ºé“¾ã€‚
- en: '![](../Images/ab92c7ad4c30803f0a95414186fe7b02.png)'
  id: totrans-437
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab92c7ad4c30803f0a95414186fe7b02.png)'
- en: Illustration of how successive chains of prompt iterations can improve your
    final prompt.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: è¯´æ˜äº†è¿ç»­çš„æç¤ºè¿­ä»£é“¾å¦‚ä½•æ”¹è¿›ä½ çš„æœ€ç»ˆæç¤ºã€‚
- en: You can use the following framework to get yourself started with the iterative
    process.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ¡†æ¶æ¥å¼€å§‹è¿­ä»£è¿‡ç¨‹ã€‚
- en: Use Many-Examples prompting to generate ideas.
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å¤šä¾‹æç¤ºæ¥ç”Ÿæˆæƒ³æ³•ã€‚
- en: '**â€œPlease provide me with a list of 50 suggestions on how to improve this prompt/response.â€**'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**â€œè¯·ç»™æˆ‘æä¾›ä¸€ä¸ªå…³äºå¦‚ä½•æ”¹è¿›è¿™ä¸ªæç¤º/å“åº”çš„å»ºè®®åˆ—è¡¨ã€‚â€**'
- en: Use **Prompt Revision/Bernard** to improve your prompts.
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨**æç¤ºä¿®è®¢/ä¼¯çº³å¾·**æ¥æ”¹è¿›ä½ çš„æç¤ºã€‚
- en: Rewrite the same prompt using **different words** and examine the responses.
    Different words trigger different responses.
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨**ä¸åŒçš„è¯**é‡å†™ç›¸åŒçš„æç¤ºï¼Œå¹¶æ£€æŸ¥å“åº”ã€‚ä¸åŒçš„è¯è§¦å‘ä¸åŒçš„å“åº”ã€‚
- en: '**Create a library of prompts for each model you use**. Make sure to update
    your library every now and then.'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸ºä½ ä½¿ç”¨çš„æ¯ä¸ªæ¨¡å‹åˆ›å»ºä¸€ä¸ªæç¤ºåº“**ã€‚ç¡®ä¿å®šæœŸæ›´æ–°ä½ çš„åº“ã€‚'
- en: Study how Language Models work to understand how they generate responses.
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç ”ç©¶è¯­è¨€æ¨¡å‹çš„å·¥ä½œåŸç†ï¼Œäº†è§£å®ƒä»¬å¦‚ä½•ç”Ÿæˆå“åº”ã€‚
- en: Whenever your output is stuck in the mud, give your prompts a few tweaks to
    push it out. Try different verbs. Mix prompting techniques. Switch models. Sleep
    on it. Start again tomorrow.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯å½“ä½ çš„è¾“å‡ºé™·å…¥åƒµå±€æ—¶ï¼Œå¯¹ä½ çš„æç¤ºè¿›è¡Œä¸€äº›è°ƒæ•´æ¥æ¨åŠ¨å®ƒã€‚å°è¯•ä¸åŒçš„åŠ¨è¯ã€‚æ··åˆæç¤ºæŠ€å·§ã€‚åˆ‡æ¢æ¨¡å‹ã€‚ç¡ä¸€è§‰ã€‚æ˜å¤©é‡æ–°å¼€å§‹ã€‚
- en: ğŸ’¡ With great powerâ€¦
  id: totrans-447
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ’¡ åŠ›é‡è¶Šå¤§â€¦
- en: We let the AI genie out of the bottle before we could figure out the risks involved,
    let alone how to deal with them.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨å¼„æ¸…æ¥šæ¶‰åŠçš„é£é™©ä¹‹å‰å°±æŠŠäººå·¥æ™ºèƒ½ç²¾çµæ”¾å‡ºäº†ç“¶å­ï¼Œæ›´ä¸ç”¨è¯´å¦‚ä½•å¤„ç†å®ƒä»¬äº†ã€‚
- en: Iâ€™m particularly worried about large-scale misinformation. But there are other
    risks like rapid displacements in the job market, prompt injection attacks, scams,
    and ultimately the alignment problem.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç‰¹åˆ«æ‹…å¿ƒå¤§è§„æ¨¡çš„é”™è¯¯ä¿¡æ¯ã€‚ä½†è¿˜æœ‰å…¶ä»–é£é™©ï¼Œæ¯”å¦‚å·¥ä½œå¸‚åœºçš„å¿«é€Ÿè½¬ç§»ï¼Œæç¤ºæ³¨å…¥æ”»å‡»ï¼Œè¯ˆéª—ï¼Œä»¥åŠæœ€ç»ˆçš„å¯¹é½é—®é¢˜ã€‚
- en: For now, the best we can do is to learn how to use generative AI to create more
    good than harm.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼Œæˆ‘ä»¬èƒ½åšçš„æœ€å¥½çš„äº‹æƒ…å°±æ˜¯å­¦ä¼šå¦‚ä½•åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åˆ›é€ æ›´å¤šçš„åˆ©å¤§äºå¼Šã€‚
- en: Below youâ€™ll find six short ethical rules that will seem obvious but are still
    worth mentioning.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢ä½ ä¼šå‘ç°å…­æ¡çŸ­å°çš„é“å¾·è§„åˆ™ï¼Œå®ƒä»¬ä¼¼ä¹æ˜¯æ˜¾è€Œæ˜“è§çš„ï¼Œä½†ä»ç„¶å€¼å¾—ä¸€æã€‚
- en: '**Maintain ethical standards:** Uphold your moral principles and avoid using
    AI-generated content that promotes harmful ideas or misinformation.'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¿æŒé“å¾·æ ‡å‡†ï¼š**åšæŒä½ çš„é“å¾·åŸåˆ™ï¼Œé¿å…ä½¿ç”¨ä¿ƒè¿›æœ‰å®³æ€æƒ³æˆ–é”™è¯¯ä¿¡æ¯çš„AIç”Ÿæˆå†…å®¹ã€‚'
- en: '**Be transparent:** Clearly disclose the use of AI in your content creation
    process so your audience knows the origin of the information theyâ€™re consuming.'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é€æ˜ï¼š**æ¸…æ¥šåœ°æŠ«éœ²åœ¨ä½ çš„å†…å®¹åˆ›ä½œè¿‡ç¨‹ä¸­ä½¿ç”¨äººå·¥æ™ºèƒ½ï¼Œè¿™æ ·ä½ çš„è§‚ä¼—å°±çŸ¥é“ä»–ä»¬æ¶ˆè´¹çš„ä¿¡æ¯çš„æ¥æºã€‚'
- en: '**Use AI as an upgrade, not a replacement:** Tech companies will make a choice:
    either achieve the same results with ten times fewer people or keep the same number
    of employees and produce ten times more. The latter option paints a brighter future.'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å°†AIç”¨ä½œå‡çº§ï¼Œè€Œä¸æ˜¯æ›¿ä»£ï¼š**ç§‘æŠ€å…¬å¸å°†åšå‡ºé€‰æ‹©ï¼šè¦ä¹ˆç”¨ååˆ†ä¹‹ä¸€çš„äººå‘˜è¾¾åˆ°ç›¸åŒçš„ç»“æœï¼Œè¦ä¹ˆä¿æŒç›¸åŒæ•°é‡çš„å‘˜å·¥ï¼Œäº§å‡ºåå€çš„æˆæœã€‚åè€…é€‰é¡¹æç»˜äº†ä¸€ä¸ªæ›´å…‰æ˜çš„æœªæ¥ã€‚'
- en: '**Verify facts and accuracy:** Always double-check the information generated
    by AI chatbots. The same goes for code. Misinformation and harmful code can make
    their way into your output. Switch on your skeptic mode.'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**éªŒè¯äº‹å®å’Œå‡†ç¡®æ€§ï¼š**å§‹ç»ˆè¦ä»”ç»†æ£€æŸ¥ç”±AIèŠå¤©æœºå™¨äººç”Ÿæˆçš„ä¿¡æ¯ã€‚åŒæ ·é€‚ç”¨äºä»£ç ã€‚é”™è¯¯ä¿¡æ¯å’Œæœ‰å®³ä»£ç å¯èƒ½ä¼šè¿›å…¥ä½ çš„è¾“å‡ºã€‚æ‰“å¼€ä½ çš„æ€€ç–‘æ¨¡å¼ã€‚'
- en: '**Never disclose sensitive data:** OpenAI[keeps a record](https://www.androidauthority.com/does-chatgpt-save-data-conversations-3310883/)
    of all of your exchanges with ChatGPT. The same may apply to other companies.
    Assume everything you type into a chatbot can leak.'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ°¸è¿œä¸è¦æ³„éœ²æ•æ„Ÿæ•°æ®ï¼š**OpenAI[è®°å½•](https://www.androidauthority.com/does-chatgpt-save-data-conversations-3310883/)äº†ä½ ä¸ChatGPTçš„æ‰€æœ‰äº¤æµã€‚å…¶ä»–å…¬å¸å¯èƒ½ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å‡è®¾ä½ è¾“å…¥åˆ°èŠå¤©æœºå™¨äººä¸­çš„ä¸€åˆ‡éƒ½å¯èƒ½æ³„éœ²ã€‚'
- en: '**Watch for biases:** Chatbots can inadvertently perpetuate biases found in
    their training data. Be vigilant. You can use specific prompts to limit bias by
    asking a Language Model to consider multiple perspectives or provide a balanced
    view.'
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ³¨æ„åè§ï¼š**èŠå¤©æœºå™¨äººå¯èƒ½æ— æ„ä¸­å»¶ç»­å…¶è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„åè§ã€‚è¦ä¿æŒè­¦æƒ•ã€‚ä½ å¯ä»¥ä½¿ç”¨ç‰¹å®šæç¤ºæ¥é™åˆ¶åè§ï¼Œé€šè¿‡è¦æ±‚è¯­è¨€æ¨¡å‹è€ƒè™‘å¤šä¸ªè§‚ç‚¹æˆ–æä¾›ä¸€ä¸ªå¹³è¡¡çš„è§‚ç‚¹ã€‚'
- en: '[PRE37]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Conclusion
  id: totrans-459
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Prompt Engineering split the world into two camps. The first pictures it as
    a bug â€” and the underlying argument is that AI models will get better and better
    at responding to natural language. Thereâ€™s a possible future where AI models will
    be able to guess what we want them to do, similar to how social media algorithms
    can guess which content we want to see.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå·¥ç¨‹å°†ä¸–ç•Œåˆ†ä¸ºä¸¤ä¸ªé˜µè¥ã€‚ç¬¬ä¸€ä¸ªå°†å…¶è§†ä¸ºä¸€ä¸ªbugâ€”â€”å…¶æ ¹æœ¬è®ºç‚¹æ˜¯AIæ¨¡å‹å°†è¶Šæ¥è¶Šæ“…é•¿å›åº”è‡ªç„¶è¯­è¨€ã€‚æœ‰å¯èƒ½çš„æœªæ¥æ˜¯ï¼ŒAIæ¨¡å‹å°†èƒ½å¤ŸçŒœæµ‹æˆ‘ä»¬æƒ³è®©å®ƒä»¬åšä»€ä¹ˆï¼Œç±»ä¼¼äºç¤¾äº¤åª’ä½“ç®—æ³•å¯ä»¥çŒœæµ‹æˆ‘ä»¬æƒ³çœ‹åˆ°å“ªäº›å†…å®¹ã€‚
- en: The second camp pictures Prompt Engineering as an essential skill in tomorrowâ€™s
    job market. The argument is generative AI models will be everywhere. Weâ€™ll use
    them to write code, generate reports, analyze data, and even prepare seminars.
    In such a scenario, Prompt Engineering becomes as essential as writing (non-boring)
    emails.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªé˜µè¥å°†æç¤ºå·¥ç¨‹è§†ä¸ºæ˜å¤©å·¥ä½œå¸‚åœºä¸Šçš„ä¸€é¡¹å¿…ä¸å¯å°‘çš„æŠ€èƒ½ã€‚å…¶è®ºç‚¹æ˜¯ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹å°†æ— å¤„ä¸åœ¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å®ƒä»¬æ¥ç¼–å†™ä»£ç ï¼Œç”ŸæˆæŠ¥å‘Šï¼Œåˆ†ææ•°æ®ï¼Œç”šè‡³å‡†å¤‡ç ”è®¨ä¼šã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæç¤ºå·¥ç¨‹å°±åƒå†™ï¼ˆéæ— èŠçš„ï¼‰ç”µå­é‚®ä»¶ä¸€æ ·é‡è¦ã€‚
- en: The world is never black or white but always some shade of gray â€” and the future
    of Prompt Engineering is no exception. You can take a bet or you can play it sage.
    If you increase your Prompt Engineering skills and it turns out to be a short-lived
    skill, then youâ€™ll lose a few dozen hours of your life.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸–ç•Œä»æ¥ä¸æ˜¯é»‘ç™½åˆ†æ˜çš„ï¼Œè€Œæ€»æ˜¯ä¸€äº›ç°è‰²çš„é˜´å½±â€”â€”Prompt Engineeringçš„æœªæ¥ä¹Ÿä¸ä¾‹å¤–ã€‚ä½ å¯ä»¥èµŒä¸€æŠŠï¼Œä¹Ÿå¯ä»¥è°¨æ…è¡Œäº‹ã€‚å¦‚æœä½ æé«˜äº†ä½ çš„æç¤ºå·¥ç¨‹æŠ€èƒ½ï¼Œç»“æœè¯æ˜å®ƒæ˜¯ä¸€ä¸ªçŸ­æš‚çš„æŠ€èƒ½ï¼Œé‚£ä¹ˆä½ å°†å¤±å»å‡ åä¸ªå°æ—¶çš„ç”Ÿæ´»ã€‚
- en: In contrast, if you ignore Prompt Engineering, it later becomes a non-negotiable
    skill you may miss out on potential career upgrades. So itâ€™s probably worth the
    detour.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¦‚æœä½ å¿½è§†äº†æç¤ºå·¥ç¨‹ï¼Œé‚£ä¹ˆä»¥åå®ƒå¯èƒ½ä¼šæˆä¸ºä½ é”™è¿‡æ½œåœ¨èŒä¸šæ™‹å‡çš„ä¸€é¡¹ä¸å¯å¦¥åçš„æŠ€èƒ½ã€‚æ‰€ä»¥è¿™å¯èƒ½æ˜¯å€¼å¾—ç»•é“è€Œè¡Œçš„ã€‚
- en: References (in no particular order)
  id: totrans-464
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®ï¼ˆæ— ç‰¹å®šé¡ºåºï¼‰
- en: '*Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E.,
    Le, Q., & Zhou, D.* [***Chain of Thought Prompting Elicits Reasoning in Large
    Language Models***](https://arxiv.org/abs/2201.11903) ***â€”*** *(2022).*'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é­, J., ç‹, X., Schuurmans, D., Bosma, M., Ichter, B., å¤, F., é½, E., ä¹, Q.,
    & å‘¨, D.* [***æ€ç»´é“¾æç¤ºå¼•å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†***](https://arxiv.org/abs/2201.11903) ***â€”*** *(2022).*'
- en: '*Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y.* [***Large Language
    Models are Zero-Shot Reasoner***](https://arxiv.org/abs/2205.11916) ***â€”*** *(2022).*'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å°å²›, T., é¡¾, S. S., Reid, M., æ¾å°¾, Y., & å²©æ²¢, Y.* [***å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯é›¶-shotæ¨ç†å™¨***](https://arxiv.org/abs/2205.11916)
    ***â€”*** *(2022).*'
- en: '*Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., &
    Hajishirzi, H.* [***Generated Knowledge Prompting for Commonsense Reasoning***](https://arxiv.org/abs/2110.08387)
    ***â€”*** *(2021).*'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ˜, J., åˆ˜, A., å¢, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi,
    H.* [***ç”Ÿæˆçš„çŸ¥è¯†æç¤ºç”¨äºå¸¸è¯†æ¨ç†***](https://arxiv.org/abs/2110.08387) ***â€”*** *(2021).*'
- en: '*Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery,
    A., & Zhou, D.* [***Self-Consistency Improves Chain of Thought Reasoning in Language
    Model***](https://arxiv.org/abs/2203.11171) ***â€”*** *(2022).*'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç‹, X., é­, J., Schuurmans, D., ä¹, Q., é½, E., Narang, S., Chowdhery, A., & å‘¨,
    D.* [***è‡ªæ´½æ€§æ”¹å–„è¯­è¨€æ¨¡å‹çš„æ€ç»´é“¾æ¨ç†***](https://arxiv.org/abs/2203.11171) ***â€”*** *(2022).*'
- en: '*Zhou, D., SchÃ¤rli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans,
    D., Cui, C., Bousquet, O., Le, Q., & Chi, E.* [***Least-to-Most Prompting Enables
    Complex Reasoning in Large Language Models***](https://arxiv.org/abs/2205.10625)
    ***â€”*** *(2022).*'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å‘¨, D., SchÃ¤rli, N., ä¾¯, L., é­, J., Scales, N., ç‹, X., Schuurmans, D., å´”, C.,
    Bousquet, O., ä¹, Q., & é½, E.* [***ä»æœ€å°‘åˆ°æœ€å¤šæç¤ºä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œå¤æ‚æ¨ç†***](https://arxiv.org/abs/2205.10625)
    ***â€”*** *(2022).*'
- en: Geunwoo Kim, Pierre Baldi, Stephen McAleer. [***Language Models Can Solve Computer
    Tasks***](https://arxiv.org/abs/2303.17491) â€”*(2023)*.
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geunwoo Kim, Pierre Baldi, Stephen McAleer. [***è¯­è¨€æ¨¡å‹å¯ä»¥è§£å†³è®¡ç®—æœºä»»åŠ¡***](https://arxiv.org/abs/2303.17491)
    â€”*(2023)*.
- en: Murray Shanahan, Kyle McDonell, Laria Reynolds. [Role-Play with Large Language
    Models](https://arxiv.org/abs/2305.16367) â€”*(2023)*.
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Murray Shanahan, Kyle McDonell, Laria Reynolds. [å¤§å‹è¯­è¨€æ¨¡å‹çš„è§’è‰²æ‰®æ¼”](https://arxiv.org/abs/2305.16367)
    â€”*(2023)*.
- en: Alex Albert. [***Jailbreak Chat***](https://www.jailbreakchat.com/) â€”*(2022â€“2023)*.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alex Albert. [***è¶Šç‹±èŠå¤©***](https://www.jailbreakchat.com/) â€”*(2022â€“2023)*.
- en: Sander Schulhoff, Anaum Khan, Fady Yanni. [***LearnPrompting.com***](https://learnprompting.org/)
    â€”*(2023)*.
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sander Schulhoff, Anaum Khan, Fady Yanni. [***LearnPrompting.com***](https://learnprompting.org/)
    â€”*(2023)*.
- en: Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, Weizhu
    Chen. [***What Makes Good In-Context Examples for GPT-3?***](https://arxiv.org/abs/2101.06804)
    â€”*(2021)*.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, Weizhu
    Chen. [***GPT-3çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ***](https://arxiv.org/abs/2101.06804) â€”*(2021)*.
- en: Lilian Weng. [***Prompt Engineering***](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)â€”*(2023)*.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lilian Weng. [***æç¤ºå·¥ç¨‹***](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)â€”*(2023)*.
- en: Cognitive Revolution Youtube Channel. [***The Art of Prompting ChatGPT With
    Riley Goodside***](https://www.youtube.com/watch?v=zg3H-9nxkyI&ab_channel=CognitiveRevolution%22HowAIChangesEverything%22)
    â€”*(2023)*.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¤çŸ¥é©å‘½Youtubeé¢‘é“ã€‚ [***ç”¨Riley Goodsideæç¤ºChatGPTçš„è‰ºæœ¯***](https://www.youtube.com/watch?v=zg3H-9nxkyI&ab_channel=CognitiveRevolution%22HowAIChangesEverything%22)
    â€”*(2023)*.
- en: 'Giuseppe Scalamogna; [***New ChatGPT Prompt Engineering Technique: Program
    Simulation***](/new-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b)
    â€”*(2023)*.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Giuseppe Scalamogna; [***æ–°çš„ChatGPTæç¤ºå·¥ç¨‹æŠ€æœ¯ï¼šç¨‹åºæ¨¡æ‹Ÿ***](/new-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b)
    â€”*(2023)*.
- en: Sang Michael Xie, Sewon Min. [***How Does In-Context Learning Work?***](http://ai.stanford.edu/blog/understanding-incontext/)â€”*(2022)*.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sang Michael Xie, Sewon Min. [***ä¸Šä¸‹æ–‡å­¦ä¹ æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ***](http://ai.stanford.edu/blog/understanding-incontext/)â€”*(2022)*.
- en: Alberto Romero. [***Prompt Engineering Is Probably More Important Than You Think***](https://thealgorithmicbridge.substack.com/p/prompt-engineering-is-probably-more)â€”(2023).
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alberto Romero. [***æç¤ºå·¥ç¨‹å¯èƒ½æ¯”ä½ æƒ³è±¡çš„æ›´é‡è¦***](https://thealgorithmicbridge.substack.com/p/prompt-engineering-is-probably-more)â€”(2023).
- en: Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, Xifeng Yan.[***Guiding
    Large Language Models via Directional Stimulus Prompting***](https://arxiv.org/abs/2302.11520)*â€”(2023).*
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, Xifeng Yan.[***é€šè¿‡å®šå‘åˆºæ¿€æç¤ºå¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹***](https://arxiv.org/abs/2302.11520)*â€”(2023).*
- en: Yao Fu, Hao Peng, Tushar Khot. [***How does GPT Obtain its Ability?***](https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1)
    *â€”(2022).*
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao Fu, Hao Peng, Tushar Khot. [***GPTæ˜¯å¦‚ä½•è·å¾—å…¶èƒ½åŠ›çš„ï¼Ÿ***](https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1)
    *â€”(2022).*
- en: '**Note regarding the images:** Unless otherwise noted, all images and screenshots
    are by the author.'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '**å…³äºå›¾ç‰‡çš„è¯´æ˜ï¼š** é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å’Œæˆªå›¾å‡ç”±ä½œè€…æä¾›ã€‚'
- en: Contact section
  id: totrans-483
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è”ç³»æ–¹å¼
- en: '[Become a Medium member to support me here](https://nabil-alouani.medium.com/membership).'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æˆä¸ºMediumä¼šå‘˜ï¼Œåœ¨è¿™é‡Œæ”¯æŒæˆ‘](https://nabil-alouani.medium.com/membership)ã€‚'
- en: '[Join my Subtack](https://nabilalouani.substack.com/).'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åŠ å…¥æˆ‘çš„Subtack](https://nabilalouani.substack.com/)ã€‚'
- en: 'Write me an email: nabil@nabilalouani.com.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™æˆ‘å†™å°é‚®ä»¶ï¼šnabil@nabilalouani.comã€‚
