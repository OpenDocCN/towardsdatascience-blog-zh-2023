["```py\n# config.py\nclass Templates:\n    embedding_template = \"\"\"Industries accepted:\n{industry_focus}\n\nFunding vehicle:\n{funding_vehicle}\"\"\"\n\nTemplates.embedding_template.format(\n    industry_focus=industry_focus, \n    funding_vehicle=funding_vehicle\n)\n```", "```py\n# List[(id, vector, metadata)]\n[\n  (\"A\", [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], {\"genre\": \"comedy\", \"year\": 2020}),\n  (\"B\", [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], {\"genre\": \"documentary\", \"year\": 2019}),\n  (\"C\", [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3], {\"genre\": \"comedy\", \"year\": 2019}),\n  (\"D\", [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4], {\"genre\": \"drama\"}),\n  (\"E\", [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], {\"genre\": \"drama\"})\n]\n```", "```py\n# pip install -U sentence-transformers\nfrom sentence_transformers import SentenceTransformer\n\nclass SentenceTransformersEmbedding:\n    \"\"\"Embedding using the SentenceTransformers library (https://www.sbert.net)\"\"\"\n\n    def __init__(\n            self,\n            model_name: str = \"all-MiniLM-L6-v2\"\n        ) -> None:\n        self.model = SentenceTransformer(model_name)\n\n    def get_embeddding(self, texts: Union[str, List[str]]) -> List:\n        # We need to return a list instead of an array for Pinecone\n        return self.model.encode(texts).tolist()\n```", "```py\ndef prepare_from_payload(self, incubators: List[Incubator]) -> List[Tuple[str, List[float], Mapping[str, Any]]]:\n        \"\"\"Prepare payload containing incubators data to export to Pinecone vector database.\n\n        Args:\n            incubators (List[Incubator]): List of Incubator containing the incubator information that will be sent to Pinecone. \n\n        Returns:\n            List[Tuple[str, List[float], Mapping[str, Any]]]: Prepared data for Pinecone. Check official documentation (https://docs.pinecone.io/docs/metadata-filtering#inserting-metadata-into-an-index). \n        \"\"\"\n        data = []\n        for incubator in incubators:\n            metadata = {key: value for key, value in incubator.model_dump(exclude={\"incubator_id\"}).items()}\n            additional_information_text = Templates.embedding_template.format(incubator.industry_focus, incubator.funding_vehicle)\n            embedding = self.embedding_generator.get_embeddding(additional_information_text)\n            incubator_data = (incubator.incubator_id, embedding, metadata)\n            data.append(incubator_data)\n        return data\n```", "```py\nfrom pydantic import BaseModel\nfrom datetime import date\n\nclass Incubator(BaseModel):\n    incubator_id: str\n    name: str \n    application_open: int = 1\n    next_deadline: date = date.max\n    funding_amount: int = 0 # Maximal amount the incubator can fund\n    attendance_requirement: Literal[\"in-person\", \"remote\", \"hybrid\"] = \"in-person\"\n    incorporation: Literal[\"incorporated\", \"unincorporated\"] = \"regardless\"\n    minimum_cofounders: int = 0\n    minimum_employees: int = 0\n    previous_funding_accepted: int = 1\n    ...\n\nclass Incubators(BaseModel):\n    incubators: List[Incubator]\n```", "```py\nprint(Incubator(\n  incubator_id=\"id\", \n  name=\"incubator_on_fire\",\n  industry_focus=\"Health tech\",\n  funding_vehicle=\"Grant\"\n))\n\n# Output\n{\n    'id': 'id'\n    'name': 'incubator_on_fire', \n    'application_open': 1, \n    'next_deadline': datetime.date(9999, 12, 31), \n    'funding_amount': 0, \n    'attendance_requirement': 'in-person', \n    'incorporation': 'regardless', \n    'minimum_cofounders': 0, \n    'minimum_employees': 0, \n    'woman_founders': 0,\n    'student_founders': 0,\n    'industry_focus': 'Health tech',\n    'funding_vehicle': 'Grant'\n     ...\n}\n```", "```py\nimport os\n\nfrom fastapi import FastAPI, HTTPException\nfrom app.models import Incubators\n\nfrom features import FeatureEngine\nfrom embedding import SentenceTransformersEmbedding\n\nPINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\nENVIRONMENT = os.getenv(\"ENVIRONMENT\")\n\napp = FastAPI()\n\n@app.post(\"/upsert\")\ndef upsert(incubators: Incubators):\n    try:\n        embedding_generator = SentenceTransformersEmbedding()\n        feature_engine = FeatureEngine(embedding_generator=embedding_generator)\n        data = feature_engine.prepare_from_payload(incubators=incubators.incubators)\n        vectors = [pinecone.Vector(id=id, values=values, metadata=metadata) for id, values, metadata in data]\n        pinecone.init(api_key=PINECONE_API_KEY, environment=ENVIRONMENT)\n        index = pinecone.Index(index_name=VectorDatabaseConfig.index_name)\n        index.upsert(vectors=vectors)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n```", "```py\nimport pinecone\n\npinecone.init(api_key=PINECONE_API_KEY, environment=ENVIRONMENT)\nindex = pinecone.Index(\"example-index\")\nindex.query(\n    vector=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n    filter={\n        \"genre\": {\"$eq\": \"documentary\"},\n        \"year\": 2019\n    },\n    top_k=5,\n    include_metadata=True\n)\n```", "```py\n# $in statement\n{\n  \"genre\": { \"$in\": [\"comedy\", \"documentary\", \"drama\"] }\n}\n\n# Multi criteria\n{\n  \"genre\": { \"$eq\": \"drama\" },\n  \"year\": { \"$gte\": 2020 }\n}\n\n# $or statement\n{\n  \"$or\": [{ \"genre\": { \"$eq\": \"drama\" } }, { \"year\": { \"$gte\": 2020 } }]\n}\n```", "```py\nclass Criterion(ABC):\n        \"\"\"Incubators criterion template used to build the filter object.\n        Each subclass of this class is a specific rule case used incubators and start-ups data.\n\n        Args:\n                name (str): incubators metadata name as it is in the vectordatabase.\n        \"\"\"\n        def __init__(\n                self,\n                name: str,\n        ) -> None:\n                self.name = name\n\nclass NormalCriterion(Criterion):\n    \"\"\"Basic rule for creating to filter data based on this criterion.\n    It takes this form:\n\n    ```", "```py\n    With `payload` the start-up information.\n\n    Example:\n    ```", "```py\n    This will filter all incubators with a maximal funding capacity greater than 10000.\n\n    Args:\n        condition_type (str): comparison element like \"$eq\" (equal), \"$lte\" (lower than or equal), \"$gt\" (greater than)\nThe complete list is available on the pinecone documentaton (https://docs.pinecone.io/docs/metadata-filtering#metadata-query-language).\n        startup_correspondance (str): start-up correspondance from the payload\n    \"\"\"\n    def __init__(\n        self, \n        name: str, \n        condition_type: str,\n        startup_correspondance: str\n    ) -> None:\n        self.condition_type = condition_type\n        self.startup_correspondance = startup_correspondance\n        super().__init__(name=name)\n```", "```py\nclass InclusiveCriterion(Criterion):\n    \"\"\"If condition validated, considers all.\n\n    Example:\n\n    Being women founders should match women-founders-only incubators, but also the other incubators.\n    Same for MVP, Ready_to_pay, Students founders, etc...\n\n    ```", "```py\n\nThose `Criterion` classes are used along their respective method to build the `filter_object` :\n\n```", "```pypython\n        {metadata_name: {condition_type: startup_value}}\n        ```", "```py\n\n```", "```py\n\nAll these `Criterion` classes are stored inside another class object we call `Criteria` . This class acts as a repository of all the criteria to consider for filtering the database and can be easily modified to add or remove any criterion.\n\n```", "```py\n\nOnce all the criteria are added to the `Criteria` object, we iterate over it and build the `filter_object` based on the start-up information. For each `Criterion` case, we add a filter element to the `filter_object` .\n\n```", "```pybash\n          filter={\n              'application_open': 1,\n              '$or': [{'attendance_requirement': {'$in': ['remote']}}, {'country': {'$eq': 'estonia'}, 'city': {'$eq': 'tallinn'}}],\n              'funding_amount': {'$gte': 12000},\n              'other_costs': {'$eq': 0},\n              'previous_funding_accepted': {'$eq': 1},\n              'working_product_requirement': {'$eq': 0}\n          }\n          ```", "```py\n\nAs you can see in the code, we built four different `Criterion` templates to consider many cases: `NormalCriterion` , `InclusiveCriterion` , `ConditionalCriterion` , and `DefaultCriterion` .\n\nIn the future of the project, more categories can be added without changing the algorithm core, making it **customizable**.\n\nOnce the `filter_object` is created with the `_get_filter()` method, the vector database can be queried with the Pinecone `index.query()` method:\n\n```", "```py\n\nThe matching tool algorithm is created. We then served it through an API endpoint using FastAPI and Pydantic.\n\n```", "```py\n\nAs `Incubator` built with Pydantic, we created the object `Startup` object to ensure the start-up data comes in the right format:\n\n```", "```py\n\nAn advantage of using Pydantic with FastAPI is that the API payload (here the start-up information) doesn’t have to be complete. For example, if there is missing information, Pydantic will automatically replace it with its default value, or not consider it at all in the algorithm (defined by the `None` statement).\n\nThe core of the API is now set up. We can now make the code ready for shipment using Docker and CI/CD with Pytest.\n\n# Delivering the API\n\n## Integration test with Pytest\n\nDuring the development of the code, unitests and integration tests were created to ensure no modifications would break the algorithm.\n\nFurthermore, creating the test algorithms not only provides a CI/CD process but also gives my client indications about how the code is supposed to work.\n\nTo build an integration test with FastAPI, we used the `TestClient` provided within the library. It uses the `httpx` library instead of `requests` making a call to the API.\n\nThe data used as validation of the code is stored in an external JSON file `data/integration_test_data.json`\n\n```", "```py\n\n![](../Images/22eebeee23c8c90f06356030ea650f9f.png)\n\nRun Pytest on all “test” scripts\n\nOnce all tests passed, we created the **Dockerfile** to containerize the code.\n\n## Docker\n\nTo create a Docker container, we simply create a Dockerfile within the repository:\n\n```", "```py\n\n![](../Images/7e49fcd169430e8cf431ed67184378f2.png)\n\nStructure of the repository\n\nHere’s what each line does:\n\n*   `FROM` import the docker image from the hub with all the basic elements required to run Python 3.9 in this case.\n*   `WORKDIR` specifies the location of the code within the container\n*   `ENV PYTHONPATH = /src` specifies which directory Python has to look into to import internal modules.\n*   `COPY` copies the files in the attributed directory.\n*   `RUN` is triggered during the Docker image creation, and before the Docker container build. This way, `pip install -r requirements.txt` only runs once.\n*   `EXPOSE` exposes a container port of our choice, here’s the port 8001\\. The API port should match the container port.\n*   `CMD ['uvicorn”, “app.api.app”, “ — host”, “0.0.0.0”, “ — port 8001]`runs the FastAPI API. It is important here to indicate the host as `0.0.0.0` to enable calls from outside the container.\n\nWe then created the Docker image by running in the CLI:\n\n```", "```py\n\nFinally, to run the container, one has just to write:\n\n```"]