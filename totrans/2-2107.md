# 时间序列预测：深度学习与统计学——谁能赢？

> 原文：[https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df](https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df)

## 关于最终难题的全面指南

[](https://medium.com/@nikoskafritsas?source=post_page-----c568389d02df--------------------------------)[![Nikos Kafritsas](../Images/de965cfcd8fbd8e1baf849017d365cbb.png)](https://medium.com/@nikoskafritsas?source=post_page-----c568389d02df--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c568389d02df--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c568389d02df--------------------------------) [Nikos Kafritsas](https://medium.com/@nikoskafritsas?source=post_page-----c568389d02df--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----c568389d02df--------------------------------) ·14 分钟阅读·2023年4月5日

--

![](../Images/91b4bda3cb99b5a14f28d669d8fa4454.png)

使用稳定扩散创建[1]

**近年来，深度学习在 NLP 领域取得了显著进展。**

时间序列，本质上也具有顺序性，提出了一个问题：*如果我们将预训练变压器的全部能力应用于时间序列预测会发生什么？*

然而，一些论文，如[2]和[3]，对深度学习模型进行了详细审查。这些论文并没有呈现出完整的画面。即使在 NLP 案例中，有些人将 GPT 模型的突破归因于“*更多的数据和计算能力*”而不是“*更好的 ML 研究*”。

本文旨在澄清混淆并提供客观观点，使用来自学术界和行业的可靠数据和来源。具体内容包括：

+   **深度学习**和**统计模型**的优缺点。

+   何时使用统计模型，何时使用深度学习。

+   如何处理预测案例。

+   如何通过选择适合你情况和数据集的最佳模型来节省时间和金钱。

让我们深入探讨。

> 我刚刚发布了[**AI Horizon Forecast**](https://aihorizonforecast.substack.com)**，**这是一个专注于时间序列和创新 AI 研究的新闻简报。订阅[这里](https://aihorizonforecast.substack.com)以拓宽视野！

[](https://aihorizonforecast.substack.com/p/autogluon-timeseries-creating-powerful?source=post_page-----c568389d02df--------------------------------) [## AutoGluon-TimeSeries：创建强大的集成预测 - 完整教程

### 亚马逊的时间序列预测框架应有尽有。

aihorizonforecast.substack.com](https://aihorizonforecast.substack.com/p/autogluon-timeseries-creating-powerful?source=post_page-----c568389d02df--------------------------------)

# Makridakis 等人的论文[4]

我们不能讨论不同预测模型的进展，而不考虑从**Makridakis竞赛（M竞赛）**中获得的见解。

Makridakis竞赛是一系列大规模挑战，展示了时间序列预测的最新进展。

最近，Makridakis等人发表了一篇新论文，内容如下：

+   总结了前五次M竞赛中的预测现状。

+   提供了各种统计、机器学习和深度学习预测模型的广泛基准。

> **注：** 我们将在本文后面讨论论文的局限性。

## 基准设置

传统上，Makridakis及其同事会发布总结最后一次M竞赛结果的论文。

然而，作者首次在实验中引入了深度学习模型。为什么？

与NLP不同，直到2018–2019年，首批DL预测模型才足够成熟以挑战传统预测模型。实际上，在2018年的M4竞赛中，ML/DL模型排名最后。

![](../Images/ade71ca0a631e914e519cd932c42006e.png)

**图1：** 2018年Makridakis等人检查的八种统计和十种ML预测方法的预测准确率（sMAPE）。所有ML方法都排在最后。

现在，让我们来看看在**新**论文中使用的DL/ML模型：

+   **多层感知机（MLP）：** 我们熟悉的前馈网络。

+   **WaveNet：** 一种自回归神经网络，结合了卷积层（2016年）。

+   **Transformer：** 原始Transformer，介绍于2017年。

+   [**DeepAR**](https://medium.com/towards-data-science/deepar-mastering-time-series-forecasting-with-deep-learning-bc717771ce85)**：** 亚马逊首个成功的自回归网络，结合了LSTMs（2017年）

> **注：** 那项研究的深度学习模型已不再是SOTA（最先进的技术）（更多内容请稍后）。另外，MLP被认为是ML模型而不是“深度”模型。

基准的统计模型是**ARIMA**和**ETS**（指数平滑）—— 这些是广为人知且经过实践验证的模型。

此外：

+   ML/DL模型首先通过超参数调优进行了微调。

+   统计模型是以**逐系列**的方式训练的。相反，DL模型是**全球**性的（一个模型训练于数据集的所有时间序列）。因此，它们利用了*跨学习*。

+   作者使用了集成方法：从深度学习模型创建了一个**Ensemble-DL**模型，另一个**Ensemble-S**由统计模型组成。集成方法是预测的中位数。

+   **Ensemble-DL**由200个模型组成，每个类别有50个模型：DeepAR、Transformer、WaveNet和MLP。

+   研究使用了M3数据集：首先，作者测试了1,045个时间序列，然后是完整数据集（3,003个序列）。

+   作者使用 **MASE**（*均值绝对尺度误差*）和 **SMAPE**（*均值绝对百分比误差*）来测量预测准确性。这些误差度量常用于预测。

接下来，我们提供了从基准测试中获得的结果和结论的总结。

# 1. 深度学习模型更好

作者总结道，平均而言，DL 模型优于统计模型。结果显示在 **图2** 中：

![](../Images/c2c408fbc353c3770e58de0b677be013.png)

**图2：** 所有模型的平均排名及 95% 置信区间，使用 sMAPE 进行排名。

**Ensemble-DL** 模型显然优于 **Ensemble-S**。此外，DeepAR 的结果与 **Ensemble-S** 非常相似。

有趣的是，**图2** 显示虽然 **Ensemble-DL** 优于 **Ensemble-S**，但只有 DeepAR 击败了单独的统计模型。这是为什么呢？

我们将在文章后面回答这个问题。

# 2. 但是，深度学习模型是昂贵的

深度学习模型需要大量的训练时间（和资金）。这是预期之中的。结果显示在 **图3** 中：

![](../Images/7ae77f636242bc7f97e59c822a7bcea8.png)

**图3：** SMAPE 与计算时间的关系。ln(CT) 为零对应大约 1 分钟的计算时间，而 ln(CT) 为 2、4、6、8 和 10 分别对应大约 7 分钟、1 小时、7 小时、2 天和 15 天的计算时间。

计算差异是显著的。

因此，降低 10% 的预测误差需要额外大约 15 天的计算时间 (**Ensemble-DL**)。虽然这个数字看起来很庞大，但有一些因素需要考虑：

1.  作者没有说明他们使用了什么类型的硬件。

1.  他们也没有提到是否使用了任何并行化或训练优化。

1.  如果在集成中使用较少的模型，**Ensemble-DL** 的计算时间可以显著减少。这在 **图4** 中显示了：

![](../Images/b944af6cece9a2d33eef11b463345c05.png)

**图4：** **Ensemble-DL** 模型中模型数量与 SMAPE 的关系。

我之前提到过，**Ensemble-DL** 模型是 200 个 DL 模型的集成。

**图4** 显示，75 个模型可以以只有 200 个模型三分之一的计算成本实现相当的准确性。如果使用更聪明的集成方法，这个数字可以进一步减少。

最后，当前论文并未探讨深度学习模型的迁移学习能力。我们将在后面讨论这一点。

# **3. 集成就是你需要的一切**

集成的威力是不容置疑的 (**图2**，**图3**)。

**Ensemble-DL** 和 **Ensemble-SL** 都是表现最好的模型。其理念是，每个单独的模型在捕捉不同的时间动态方面都表现出色。结合它们的预测可以识别复杂的模式和进行准确的外推。

# 4. 短期预测与长期预测

作者调查了模型在短期和长期预测能力上的差异。

确实如此。

**图5**展示了每个模型在每个预测期的准确性。例如，第1列显示了一步预测误差。类似地，第18列显示了第18步预测的误差。

![](../Images/26653f7678bc42c6b860bd9c7fe8eb09.png)

**图5：** 1045个系列中每个模型的sMAPE误差——数值越低越好（[点击这里查看完整图像](https://gist.github.com/nkafr/ef8d2a84aafd626bc603cc4234291135)）

这里有三个关键观察点：

+   首先，长期预测的准确性低于短期预测（这并不意外）。

+   在前4个预测期内，**统计模型胜出。** 在此之后，**深度学习模型开始变得更好，Ensemble-DL胜出。**

+   具体来说，在第一个预测期内，**Ensemble-S**的准确率高出8.1%。然而，在最后一个预测期，**Ensemble-DL**的准确率高出8.5%。

如果你考虑这个问题，就会明白：

+   统计模型是自回归的。随着预测期的增加，误差会累积。

+   相对而言，深度学习模型是多输出模型。因此，它们的预测误差分布在整个预测序列中。

+   唯一的深度学习自回归模型是DeepAR。这就是为什么DeepAR在前几个预测期表现非常好，而其他深度学习模型表现相对较差的原因。

# 5\. 深度学习模型在更多数据下是否有所改善？

在之前的实验中，作者只使用了M3数据集中的1,045个时间序列。

接下来，作者使用完整的数据集（3,003个系列）重新进行了实验。他们还分析了每个预测期的预测损失。结果如**图6**所示：

![](../Images/4618207b7663ce42dc9d9917e0793f47.png)

**图6：** 3003个系列中每个模型的sMAPE误差——数值越低越好（[点击这里查看完整图像](https://gist.github.com/nkafr/f1c86b825271abf55ce8577691ac669d)）

现在，**Ensemble-DL**和**Ensemble-S**之间的差距缩小了。统计模型在第一个预测期与深度学习模型相当，但之后，Ensemble-DL超越了它们。

让我们进一步分析**Ensemble-DL**和**Ensemble-S**之间的差异：

![](../Images/236bd9ebe811660305d9da620d17148e.png)

**图7：** Ensemble-DL相对于Ensemble-S的百分比改善（[点击这里查看完整图像](https://gist.github.com/nkafr/d742007a350ab94c3827e191fc7e203c)）

随着预测步数的增加，深度学习模型优于统计集合模型。

# 6\. 趋势和季节性分析

最后，作者调查了统计模型和深度学习模型如何处理重要的时间序列特征，如趋势和季节性。

为此，作者使用了[5]中的方法论。具体来说，他们拟合了一个多元线性回归模型，将sMAPE误差与5个关键时间序列特征相关联：**预测能力（**错误的随机性**）**、**趋势**、**季节性**、**线性**和**稳定性（**决定数据正态性的最佳Box-Cox参数变换**）**。结果如**图8**所示：

![](../Images/0b9990bd9c33f21416f7c186681903e3.png)

**图 8：** 不同指标的线性回归系数0。数值越低越好。

我们观察到：

+   深度学习模型在**嘈杂、趋势化**和**非线性**数据上表现更佳。

+   统计模型更适用于**季节性**和**低方差**的数据，以及**线性关系**的数据。

这些见解是非常宝贵的。

因此，在选择适合您的用例的模型之前，进行广泛的探索性数据分析（EDA）并了解数据的性质是至关重要的。

# 研究的局限性

这篇论文无疑是对当前时间序列预测领域状态的最佳研究之一，但它也存在一些局限性。让我们来看看这些局限性：

## 缺乏 ML 算法：树 / Boosted Trees

Boosted Trees 模型家族在时间序列预测问题中占有重要地位。

最受欢迎的模型有 XGBoost、LightGBM 和 CatBoost。此外，LightGBM 赢得了 M5 竞赛。

这些模型在表格型数据中表现出色。事实上，到今天为止，Boosted Trees 仍然是表格数据的最佳选择。然而，本文使用的 M3 数据集非常简单，因为它主要包含单变量序列。

在未来的研究中，将 Boosted Trees 添加到数据集中，特别是对于更复杂的数据集，将是一个很好的主意。

## 选择 M3 作为基准数据集

IJF 期刊主编 Rob Hyndman 教授说：“*自 2000 年以来，M3 数据集一直用于测试预测方法；新提出的方法必须超越 M3 才能在 IJF 上发表。*”

然而，按现代标准，M3 数据集被认为是小型和简单的，因此不具备现代预测应用和实际场景的代表性。

当然，数据集的选择并不会减少研究的价值。然而，进行一次使用更大数据集的未来基准测试可能会提供有价值的见解。

## 深度学习模型还不是最先进的（SOTA）。

现在，是时候处理眼前的主要问题了。

该研究中的深度学习模型远未达到最先进水平。

该研究将亚马逊的 DeepAR 识别为在理论预测准确性方面最好的深度学习模型。因此，DeepAR 是唯一一个能够在单独层面上超越统计模型的模型。然而，DeepAR 模型现在已经超过 6 年了。

亚马逊随后发布了其改进版的 DeepAR，称为 [**Deep GPVAR**](https://medium.com/towards-data-science/deep-gpvar-upgrading-deepar-for-multi-dimensional-forecasting-e39204d90af3)。实际上，**Deep GPVAR** 也已过时——亚马逊最新的深度预测模型是 MQTransformer，它于 2020 年发布。

此外，其他强大的模型，如[**时序融合变换器**](https://medium.com/towards-data-science/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91)（TFT）和[**N-BEATS**](https://medium.com/towards-data-science/n-beats-time-series-forecasting-with-neural-basis-expansion-af09ea39f538)（最近被N-HITS超越），在深度学习集成中也没有被使用。

因此，研究中使用的深度学习模型至少落后于当前技术水平的两代。不容置疑，当前一代深度预测模型将产生更好的结果。

## 预测并不是一切

准确性在预测中至关重要，但并不是唯一重要的因素。其他关键领域包括：

+   不确定性量化

+   预测可解释性

+   零-shot学习 / 元学习

+   政策转变隔离

说到**零-shot学习**，它是AI中最有前途的领域之一。

> 零-shot学习是模型在没有专门训练的情况下，正确估计未见数据的能力。这种学习方法更好地反映了人类的认知。

所有的深度学习模型，包括GPT模型，都是基于这一原则的。

利用这一原则的首批广受好评的预测模型是[N-BEATS / N-HITS](https://medium.com/towards-data-science/n-beats-time-series-forecasting-with-neural-basis-expansion-af09ea39f538)。这些模型可以在庞大的时间序列数据集上进行训练，并在完全新的数据上进行预测，其准确性与模型专门训练过的数据相当。

*零-shot学习*只是*元学习*的一个特定实例。自此以来，在时间序列上的元学习取得了进一步的进展。以[M6竞赛](https://m6competition.com)为例，其目标是检验数据科学预测与计量经济学是否能像传奇投资者（如沃伦·巴菲特）一样击败市场。[获胜解决方案是一种新型架构，其中使用了神经网络和元学习](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4355794)。

不幸的是，本研究并未探索深度学习模型在零-shot学习设置中的竞争优势。

# Nixtla研究

Nixtla，一家在时间序列预测领域有前景的初创公司，最近发布了对Makridakis等人论文[4]的[基准](https://github.com/Nixtla/statsforecast/tree/main/experiments/m3)后续研究。

具体来说，Nixtla团队添加了2个额外的模型：[复杂指数平滑](https://onlinelibrary.wiley.com/doi/full/10.1002/nav.22074)和[动态优化Theta](https://nixtla.github.io/statsforecast/models.html#dynamic-optimized-theta-method)。

这些模型的加入缩小了统计模型和深度学习模型之间的差距。此外，Nixtla团队正确地指出了这两类模型在成本和资源需求上的显著差异。

确实，许多数据科学家被深度学习的过度炒作所误导，缺乏解决预测问题的正确方法。

我们将在下一部分进一步讨论这个问题。但在此之前，我们需要解决深度学习面临的批评。

# 深度学习受到批评

过去十年中，深度学习的发展是惊人的。至今尚无减缓的迹象。

然而，每一个威胁到现状的革命性突破通常都会遭遇怀疑和批评。以GPT-4为例：这一新发展在下一个十年威胁到20%的美国工作岗位[6]。

深度学习和变换器在自然语言处理领域的主导地位是不容否认的。然而，面试中人们却提出类似这样的问题：

> 自然语言处理（NLP）的进步是归功于更好的研究，还是仅仅因为数据的增加和计算能力的提升？

在时间序列预测中，情况更为糟糕。要理解这一点的原因，你必须首先了解传统上是如何处理预测问题的。

在机器学习/深度学习广泛应用之前，预测完全是关于为数据集制定正确的转换。这包括使时间序列平稳，去除趋势和季节性，考虑波动性，并使用如box-cox变换等技术。所有这些方法都需要手动干预，并且对数学和时间序列有深刻理解。

随着机器学习的出现，时间序列算法变得更加自动化。你可以在几乎没有预处理的情况下直接应用这些算法（尽管额外的预处理和特征工程总是有帮助的）。如今，许多改进工作主要集中在超参数调优上。

因此，使用高级数学和统计学的人难以理解机器学习/深度学习算法能够超越传统统计模型的事实。而有趣的是，研究人员对一些深度学习概念真正有效的原因和机制却一无所知。

# 最近文献中的时间序列预测

就我所知，现有文献缺乏足够的证据来说明各种预测模型的优缺点。以下两篇论文是最相关的：

## 变换器模型对于时间序列预测是否有效？

一篇有趣的论文[2]展示了某些预测变换器模型的弱点。该论文举例说明了现代变换器模型中使用的位置信息编码方案如何未能捕捉时间序列的时间动态。这一点确实是正确的——**自注意力机制是不变的**。然而，论文未提及那些已经有效解决此问题的变换器模型。

例如，谷歌的 [Temporal Fusion Transformer](https://medium.com/towards-data-science/temporal-fusion-transformer-googles-model-for-interpretable-time-series-forecasting-5aa17beb621)（TFT）使用编码器-解码器 LSTM 层来创建时间感知和上下文感知的嵌入。此外，TFT 使用了为时间序列问题适配的新颖注意力机制，以捕捉时间动态并提供可解释性。

类似地，亚马逊的 MQTransformer 使用其新颖的位置编码方案（***上下文相关的季节性编码***）和注意力机制（**反馈感知注意力**）。

## 我们真的需要深度学习模型来进行时间序列预测吗？

这篇论文 [3] 也很有趣，因为它比较了 **统计**、**提升树**、**机器学习** 和 **深度学习** 类别的各种预测方法。

不幸的是，它未能达到其标题所述，因为在 12 个模型中表现最好的还是谷歌的 TFT，这是一种纯粹的深度学习模型。论文提到：

> …… 表 5 中的结果强调了配置了滚动预测的 GBRT 的竞争力，但也显示了显著强大的基于变换器的模型，如 TFT [12]，确实超越了提升回归树的表现。

总的来说，阅读复杂的预测论文和模型时要小心，特别是关于出版来源的部分。[国际预测期刊 (IJF)](https://www.sciencedirect.com/journal/international-journal-of-forecasting) 就是一个专注于预测的信誉良好的期刊的例子。

# 如何处理预测问题

这并不简单。每个数据集都是独特的，每个项目的目标也各不相同，使得预测变得具有挑战性。

然而，本文提供了一些可能对大多数方法有益的通用建议。

正如你从本文中了解到的，深度学习模型是预测项目中的一种新兴趋势，但它们仍处于早期阶段。尽管它们具有潜力，但也可能存在陷阱。

不建议立即将深度学习模型作为项目的首选。根据 Makridakis 等人和 Nixtla 的研究，最好从统计模型开始。3–4 个统计模型的集成可能比你预期的更强大。此外，尝试使用提升树，特别是如果你有表格数据的话。对于小型数据集（数千条数据），这些方法可能已足够。

深度学习模型可能提供额外的 3–10% 准确度提升。然而，训练这些模型可能耗时且昂贵。对于一些领域，如金融和零售，这额外的准确度提升可能更具价值，并使使用深度学习模型成为合理选择。更准确的产品销售预测或 ETF 的收盘价可能会转化为数千美元的增量收入。

另一方面，像 N-BEATS 和 N-HITS 这样的深度学习模型具有迁移学习能力。

如果构建了足够大的时间序列数据集，并且一个愿意的实体对这 2 个模型进行预训练并共享其参数，我们可以直接使用这些模型并实现顶尖的预测准确性（或先对我们的数据集进行少量微调）。

# 结束语

时间序列预测是数据科学的一个关键领域。

但与其他领域相比，它也被严重低估。Makridakis 等人[4]的论文为未来提供了一些有价值的见解，但仍有很多工作和研究需要完成。

此外，深度学习模型在预测中的应用仍未被广泛探索。

例如，**多模态**架构在深度学习中随处可见。这些架构利用多个领域来学习特定任务。例如，[**CLIP**](https://medium.com/p/f8ee408958b1)（由**DALLE-2**和**Stable Diffusion**使用）结合了*自然语言处理*和*计算机视觉*。

基准 M3 数据集仅包含 3,003 个时间序列，每个序列最多 500 个观测值。相比之下，成功的 [**Deep GPVAR**](https://medium.com/p/e39204d90af3) 预测模型包含平均 44K 个参数。相比之下，Facebook 的 LLaMA 语言 Transformer 模型的最小版本拥有 70 亿个参数，并在 1 万亿个令牌上进行训练。

因此，关于原始问题，没有明确的答案说明哪个模型是最好的，因为每个模型都有其优缺点。

相反，本文旨在提供所有必要的信息，帮助您选择最适合您项目或案例的模型。

# 感谢阅读！

+   关注我 [Linkedin](https://www.linkedin.com/in/nikos-kafritsas-b3699180/)！

+   订阅我的 [新闻通讯](https://aihorizonforecast.substack.com/welcome)，AI Horizon Forecast！

[](https://aihorizonforecast.substack.com/p/autogluon-timeseries-creating-powerful?source=post_page-----c568389d02df--------------------------------) [## AutoGluon-TimeSeries：创建强大的集成预测——完整教程

### 亚马逊的时间序列预测框架具备了一切。

[aihorizonforecast.substack.com](https://aihorizonforecast.substack.com/p/autogluon-timeseries-creating-powerful?source=post_page-----c568389d02df--------------------------------)

# 参考文献

[1] 从 Stable Diffusion 创建，文本提示为“一个蓝青色时间序列抽象，闪亮的数字画，概念艺术”

[2] Ailing Zeng 等人 [*变压器在时间序列预测中是否有效？*](https://arxiv.org/pdf/2205.13504.pdf)（2022年8月）

[3] Shereen Elsayed 等人 [*我们真的需要深度学习模型来进行时间序列预测吗？*](https://arxiv.org/pdf/2101.02118.pdf)（2021年10月）

[4] Makridakis 等人 [*统计学、机器学习和深度学习预测方法：比较与前进方向*](https://www.tandfonline.com/doi/epdf/10.1080/01605682.2022.2118629) *（2022年8月）*

[5] Kang 等人 [*可视化预测算法性能使用时间序列实例空间*](https://www.sciencedirect.com/science/article/abs/pii/S0169207016301030) *（《国际预测学杂志》，2017年）*

[6] Eloundou 等人 [*GPTs 即 GPTs：大型语言模型对劳动市场潜在影响的早期观察*](https://arxiv.org/pdf/2303.10130.pdf)（2023年3月）

文章中使用的所有图像均来自[4]。 [M3 数据集以及所有 M 数据集“可以在不需进一步许可的情况下自由使用”](https://forecasters.org/resources/time-series-data/)。
