- en: How to Detect Drift in Machine Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-detect-drift-in-machine-learning-models-8a0be4049eed](https://towardsdatascience.com/how-to-detect-drift-in-machine-learning-models-8a0be4049eed)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This might be the reason why your model performance degrades in production*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@edwin.tan?source=post_page-----8a0be4049eed--------------------------------)[![Edwin
    Tan](../Images/7db7b2f72bdbeb1675df3a2c6eddf91f.png)](https://medium.com/@edwin.tan?source=post_page-----8a0be4049eed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8a0be4049eed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8a0be4049eed--------------------------------)
    [Edwin Tan](https://medium.com/@edwin.tan?source=post_page-----8a0be4049eed--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8a0be4049eed--------------------------------)
    ·8 min read·Feb 6, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have you ever gotten awesome results on your test set only to have your models
    perform poorly in production after some time? If so, you might be experiencing
    model decay. Model decay is the gradual decline in the performance of a machine
    learning model over time. In this article we will be discussing about how data
    drift causes model decay and how we setup early detection for drift.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/848e5f894f69fdf863aa02d8252caf76.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Samuel Wong](https://unsplash.com/@samuelwong?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**What is drift in machine learning?**'
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, model drift refers to a change in the underlying distribution
    of the data that a model has been trained on, leading to a decrease in its performance
    on new, unseen data. This can occur when a model is deployed in a real-world setting
    and the distribution of data it encounters changes over time. For example, a model
    trained on pre-covid data may not perform as well on data during the Covid19 pandemic
    due to changes in the underlying distribution of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is it important to track model drift?**'
  prefs: []
  type: TYPE_NORMAL
- en: Tracking drift is important because it can help ensure that a machine learning
    model continues to make accurate predictions over time. As the model is deployed
    in the real-world, the distribution of data it encounters may change, which can
    cause the model’s performance to degrade. By tracking drift, we can detect when
    this occurs and take appropriate action to adapt the model, such as retraining
    it on new data. This can help prevent the model from making increasingly inaccurate
    predictions, which can have serious consequences in certain applications such
    as fraud detection, credit scoring and medical diagnosis. Tracking model drift
    is also important for compliance and regulatory reasons. Organizations might be
    required to maintain accurate records and have an auditable trail of their model’s
    performance over time.
  prefs: []
  type: TYPE_NORMAL
- en: Types of drift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here the different types of drift that might affect your models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Concept drift** is the change in relationship between the independent and
    target variable. This occurs when the underlying concept or task that the model
    is trying to learn changes over time. For example, a model trained to detect fraudulent
    credit card transactions may experience concept drift if the type of fraud changes
    over time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Covariate shift** is the shift in independent variable. This occurs when
    the distribution of the input variables changes over time, but the underlying
    concept or task remains the same. For example, a model trained on data from one
    geographic location may experience covariate shift if it is deployed in a different
    location with different distribution of input variables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Prior probability shift** is the shift in target variable. For example, a
    model trained on a dataset where the classes are balanced may experience prior
    probability shift if it is deployed on a dataset where one class is much more
    prevalent than the other.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Methods to detect drift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here are some common ways to detect model decay and drift.
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitor model performance**'
  prefs: []
  type: TYPE_NORMAL
- en: This involves calculating metrics such as MSE, RMSE for regression models and
    AUC ROC, Accuracy, Precision, Recall and F1 for classification. Large deviation
    between production and test performance can raise an alarm on potential drift
    happening.
  prefs: []
  type: TYPE_NORMAL
- en: However this method might be impractical in situations where there is a large
    time gap between the time of prediction and obtaining the ground truth. For example,
    in a bank telemarketing campaign where a machine learning model predicts customer’s
    propensity to buy a particular product. The campaign might last for few months
    and we can only conclude if the customer make a purchase during the campaign at
    the end of the campaign period. If we rely solely on model performance as an indicator
    of model drift, we will only be able to get an alert on drift at the end of the
    campaign.
  prefs: []
  type: TYPE_NORMAL
- en: While model performance is a useful indicator, it is a lagging indicator. We
    can take a proactive approach in detecting drift by monitoring the input features.
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitor changes in input features**'
  prefs: []
  type: TYPE_NORMAL
- en: A simple way to monitor changes in input features is through descriptive statistics.
    Descriptive statistics are numbers used to provide a summary about a set of data.
    Common descriptive statistics for numerical values are mean, median, mode, minimum
    and maximum. A change in descriptive statistics can raise an alert on potential
    drift.
  prefs: []
  type: TYPE_NORMAL
- en: We can also monitor changes to the distributions of input features. Common statistics
    test used to monitor changes in distributions are Kolmogorov-Smirnov test, Population
    Stability Index (PSI), Wasserstein distance also known as the Earth-Mover Distance,
    Kullback-Leibler divergence and Jensen-Shannon distance.
  prefs: []
  type: TYPE_NORMAL
- en: In this article we will walk through an example on how to use Evidently, a model
    monitoring tool in python that leverages on various statistical tests, to detect
    drift in machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following example, we will:'
  prefs: []
  type: TYPE_NORMAL
- en: Train a model to predict the housing resale price
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use Evidently AI’s pre-built reports to monitor the fitted model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visual Studio Code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python packages required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Get the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be using a subset of the Singapore resale housing price dataset[1].
    The dataset provided by the Housing Development Board shows the transactions of
    resale houses. It includes information such as year-month of the transaction,
    flat type, location, size of the flat and the resale price.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We perform the following pre-processing steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create date features `year` and `month`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converted `remaining_lease`column from string to float type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: rename the `resale_price` column to `target`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s split the data into 3 sets based on the transaction date.
  prefs: []
  type: TYPE_NORMAL
- en: '`Train`: This is the set which we use for training, it contains data from 2020\.
    The labels in this set is known to us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Test`: This is the holdout set which we use to get the test result. It contains
    data from 2021\. The labels in this set is known to us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Score`:This is the set of unseen records used for scoring in production. We
    should not have the labels for this set, therefore we will be dropping the `target`
    column to simulate a real world case. It contains data from 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Train Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We use the trained regression model to predict on the test, score and train
    set. Note that at this point we only have the target columns for train and test
    set, not the score set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Pre-built Reports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Evidently AI comes with a wide range of pre-built metrics and tests known as
    metric and test preset. These are groups of relevant metrics or tests presented
    to you in a single report.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below are some [metric presets](https://docs.evidentlyai.com/reference/all-metrics):'
  prefs: []
  type: TYPE_NORMAL
- en: '`DataQualityPreset`: Evaluate data quality and provides descriptive statistics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DataDriftPreset`: Evaluates data drift in individual columns and the dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TargetDriftPreset`: Evaluates prediction or target drift'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RegressionPreset`: Evaluates quality of a regression model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ClassificationPreset`: Evaluates quality of a classification model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Below are some [test presets](https://docs.evidentlyai.com/reference/all-tests):'
  prefs: []
  type: TYPE_NORMAL
- en: '`NoTargetPerformanceTestPreset`: Evaluate data drift in the prediction the
    prediction column and data quality check across all columns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DataDriftTestPreset`: Evaluates data drift in individual columns and the dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DataQualityTestPreset`: Evaluate data quality and provides descriptive statistics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-built Metric
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s examine how the metrics preset work.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We set the train and the test set as the reference and current dataset respectively.
    Notice that we did not choose which statistical test to perform for the columns.
    Evidently has made the choice for us based on characteristics of the input data.
    Read more of how they make such decision [here](https://docs.evidentlyai.com/reference/data-drift-algorithm).
  prefs: []
  type: TYPE_NORMAL
- en: We can either display the HTML as a Jupyter Notebook cell output nor save it
    as a HTML file. Here is how the HTML file looks like when we open it in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/69bbf15b2a1fb4c723bfdc4101e80cd3.png)'
  prefs: []
  type: TYPE_IMG
- en: GIF by author
  prefs: []
  type: TYPE_NORMAL
- en: 'The report contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A summary of number and proportion of columns where drift is detected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data distribution and drift magnitude for every column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correlation between features and target / prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The results can also be output as Json or a python dictionary in the following
    manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Pre-built Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use the test preset in similar fashion. We set the train and score set
    as the reference and current dataset respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note that the score set only has prediction, it does not have ground truth i.e.
    target column yet, hence the target column in the reference dataset was dropped.
    Here is how the result look like.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aed79d23bdf15a05694169a68355c4d9.png)'
  prefs: []
  type: TYPE_IMG
- en: GIF by author
  prefs: []
  type: TYPE_NORMAL
- en: '`NoTargetPerformanceTestPreset`provides concise summary of the data drift,
    quality and integrity. The result can also be output as Json or python dictionary
    in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, model drift in machine learning refers to a change in the underlying
    distribution of data that can result in decreased performance. It is important
    to track model drift to ensure accuracy of predictions and for compliance and
    regulatory reasons. There are different types of drift, including concept drift,
    covariate shift, and prior probability shift. Methods to detect drift include
    monitoring model performance and descriptive statistics of input features, as
    well as monitoring changes in the distribution of input features using statistical
    tests. By using tools like Evidently AI, we can proactively detect and address
    model drift to ensure the performance and reliability of their machine learning
    models over time.
  prefs: []
  type: TYPE_NORMAL
- en: '[Join medium](https://medium.com/@edwin.tan/membership) to read more articles
    like this!'
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] *Contains information from HDB Resale Price accessed on 31st Jan 2023 from*
    [Resale Flat Prices-Data.gov.sg](https://data.gov.sg/dataset/resale-flat-prices)
    which is made available under the terms of the Singapore Open Data Licence version
    1.0* [Singapore Open Data Licence-Data.gov.sg](https://data.gov.sg/open-data-licence)'
  prefs: []
  type: TYPE_NORMAL
