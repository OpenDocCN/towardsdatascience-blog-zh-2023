["```py\ndef get_random_candidate(features):\n   \"\"\"Get a random set of features.\"\"\"\n\n  candidate_size = np.random.randint(1, len(features)+1)\n  candidate = np.random.choice(features, replace=False, size=candidate_size)\n\n  return candidate\n```", "```py\nfor iteration in n_iterations:\n  # Step 1: Propose a candidate (i.e. a list of features).\n  candidate = get_random_candidate(X_train.columns)\n\n  # Step 2: Train a model on those features\n  model = model.fit(X_train.loc[:, candidate], y_train)\n\n  # Step 3: Get the predictions made by the model on the validation set.\n  preds_valid = model.predict_proba(X_valid.loc[:, candidate])\n\n  # Step 3: Compute the performance metric on the validation set.\n  ap_valid = average_precision_score(y_valid, preds_valid)\n```", "```py\nfrom pycaret.datasets import get_data\nfrom sklearn.model_selection import train_test_split\n\ndf = get_data(\"concrete\", verbose=False)\nX, y = df.drop(\"strength\", axis=1), df[\"strength\"]\nX_train, X_valid, y_train , y_valid = train_test_split(X, y)\n```", "```py\nfrom lightgbm import LGBMRegressor\n\nmodel = LGBMRegressor(verbose=-1).fit(X_train, y_train)\n```", "```py\nfrom shap import TreeExplainer\n\nshap_explainer = TreeExplainer(model)\nshap_expected_value = shap_explainer.expected_value\nshap_valid = shap_explainer.shap_values(X_valid)\n```", "```py\nimport numpy as np\n\npred_valid = model.predict(X_valid)\npred_valid_proxy = shap_expected_value + shap_valid.sum(axis=1)\n\nassert (np.abs(approx_pred_valid - pred_valid) < 1e-10).all()\n```", "```py\ncandidate_features = [...]\n\napprox_pred_valid = shap_expected_value + shap_valid[candidate_features].sum(axis=1)\n```", "```py\n# Step 0: Train a model on the dataset with all the features and compute the\n# SHAP values on the validation set.\nshap_valid = model.fit(X_train, y_train).get_shap_values(X_valid)\n\nfor iteration in n_iterations:\n  # Step 1: Propose a candidate (i.e. a list of features).\n  candidate = get_random_candidate(X_train.columns)\n\n  # Step 2: Get the predictions on the validation set \n  # (by summing the SHAP values of the respective features).\n  pred_valid = shap_valid.loc[:, candidate].sum(axis=1)\n\n  # Step 3: Compute the performance metric on the validation set.\n  ap_valid = average_precision_score(y_valid, pred_valid) \n```"]