- en: 'When AI Goes Astray: High-Profile Machine Learning Mishaps in the Real World'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/when-ai-goes-astray-high-profile-machine-learning-mishaps-in-the-real-world-26bd58692195](https://towardsdatascience.com/when-ai-goes-astray-high-profile-machine-learning-mishaps-in-the-real-world-26bd58692195)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A tour of infamous machine learning blunders and failures that caught the world’s
    attention
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://kennethleungty.medium.com/?source=post_page-----26bd58692195--------------------------------)[![Kenneth
    Leung](../Images/2514dffb34529d6d757c0c4ec5f98334.png)](https://kennethleungty.medium.com/?source=post_page-----26bd58692195--------------------------------)[](https://towardsdatascience.com/?source=post_page-----26bd58692195--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----26bd58692195--------------------------------)
    [Kenneth Leung](https://kennethleungty.medium.com/?source=post_page-----26bd58692195--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----26bd58692195--------------------------------)
    ·6 min read·Aug 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09242ff40162d09e9b281e8a1f92d26b.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [NEOM](https://unsplash.com/@neom?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/AdkJ-LgpTrE?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: The transformative potential of artificial intelligence (AI) and machine learning
    has often made headlines in the news, with plenty of reports on its positive impact
    in diverse fields ranging from healthcare to finance.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, no technology is immune to missteps. While the success stories paint a
    picture of machine learning's wonderful capabilities, it is equally crucial to
    highlight its pitfalls to understand the full spectrum of its impact.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we explore numerous high-profile machine learning blunders
    so that we can draw lessons for more informed implementations in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Contents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In particular, we will look at a noteworthy case from each of the following
    categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '***(1)*** [*Classic Machine Learning*](#8b4a)***(2)*** [*Computer Vision*](#0630)***(3)***
    [*Forecasting*](#4d00)***(4)*** [*Image Generation*](#802b)***(5)*** [*Natural
    Language Processing*](#bfc3)***(6)*** [*Recommendation Systems*](#ead8)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***A comprehensive compilation of high-profile machine learning mishaps can
    be found in the following GitHub repo called Failed-ML:***'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/kennethleungty/Failed-ML?source=post_page-----26bd58692195--------------------------------)
    [## GitHub — kennethleungty/Failed-ML: Compilation of high-profile real-world
    examples'
  prefs: []
  type: TYPE_NORMAL
- en: github.com](https://github.com/kennethleungty/Failed-ML?source=post_page-----26bd58692195--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*(1) Classic Machine Learning*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Headline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Amazon AI recruitment system:** Amazon''s AI-powered automated recruitment
    system was canceled after evidence of discrimination against female candidates.'
  prefs: []
  type: TYPE_NORMAL
- en: Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon developed an AI-powered recruitment tool to identify top candidates from
    a decade's worth of resumes. However, since the tech industry is predominantly
    male, the system exhibited biases against female applicants.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, it started downgrading resumes containing the word "women's" or
    those from graduates of two women-only colleges while favoring certain terms (e.g.,
    'executed') that appeared more frequently in male resumes.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon attempted to rectify these biases but faced challenges in eliminating
    the discriminatory tendencies. Consequently, they discontinued the project in
    early 2017, emphasizing that the system was never utilized for actual candidate
    evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: Key Lesson
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bias in training data can be perpetuated in machine learning models and lead
    to unintended and discriminatory outcomes in AI systems, emphasizing the importance
    of diverse and representative datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Link to Report
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://finance.yahoo.com/news/amazon-reportedly-killed-ai-recruitment-100042269.html?source=post_page-----26bd58692195--------------------------------)
    [## Amazon Reportedly Killed an AI Recruitment System'
  prefs: []
  type: TYPE_NORMAL
- en: finance.yahoo.com](https://finance.yahoo.com/news/amazon-reportedly-killed-ai-recruitment-100042269.html?source=post_page-----26bd58692195--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: (2) Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Headline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Google''s AI for diabetic retinopathy detection**: The retina scanning tool
    fared much worse in real-life settings than in controlled experiments, with issues
    such as rejected scans from poor scan quality and delays from intermittent internet
    connectivity when uploading images to the cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Google Health outfitted 11 clinics across Thailand with a deep-learning system
    trained to spot signs of eye disease in diabetic patients. During in-lab experiments,
    the system could identify signs of diabetic retinopathy from an eye scan with
    more than 90% accuracy and give a result in less than 10 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: However, when deployed on the ground, the AI system often fails to give a result
    due to poor image quality, rejecting more than a fifth of the images.
  prefs: []
  type: TYPE_NORMAL
- en: Nurses also felt frustrated when they believed the rejected scans showed no
    signs of disease or when they had to retake and edit an image that the AI system
    had rejected. Poor internet connections in several clinics also caused delays
    in uploading images to the cloud for processing.
  prefs: []
  type: TYPE_NORMAL
- en: Key Lesson
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to tailor AI tools to the specific conditions and constraints
    of real-world environments, including factors like image quality and offline availability.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/?source=post_page-----26bd58692195--------------------------------)
    [## Google''s medical AI was super accurate in a lab. Real life was a different
    story.'
  prefs: []
  type: TYPE_NORMAL
- en: www.technologyreview.com](https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/?source=post_page-----26bd58692195--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: (3) Forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Headline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Zillow instant-buying (iBuying) algorithms**: Zillow suffered significant
    losses in their home-flipping business due to inaccurately overestimated prices
    from their machine learning models for property valuation.'
  prefs: []
  type: TYPE_NORMAL
- en: Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Real estate companies like Zillow have been using the iBuying business model,
    where they purchase homes directly from sellers and then re-list them after doing
    minor work.
  prefs: []
  type: TYPE_NORMAL
- en: One of the first steps in Zillow's decision to purchase any home is the "Zestimate"
    — a machine-learning-assisted estimate of a home's market value in the future
    based on a model trained on millions of home valuations and relying on data such
    as a home's condition and ZIP code.
  prefs: []
  type: TYPE_NORMAL
- en: However, Zillow's system misjudged future home values, leading them to make
    numerous above-market offers to homeowners, particularly during the real estate
    volatility caused by the COVID-19 pandemic.
  prefs: []
  type: TYPE_NORMAL
- en: This misjudgment eventually resulted in the shutdown of Zillow's instant-buying
    operation and a projected loss of $380 million.
  prefs: []
  type: TYPE_NORMAL
- en: Key Lesson
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Continuous model monitoring, evaluation, and retraining are critical so that
    data drift from new events (resulting in changes in test data distribution) is
    captured in the models for up-to-date predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://www.wired.com/story/zillow-ibuyer-real-estate/?source=post_page-----26bd58692195--------------------------------)
    [## Why Zillow Couldn''t Make Algorithmic House Pricing Work'
  prefs: []
  type: TYPE_NORMAL
- en: www.wired.com](https://www.wired.com/story/zillow-ibuyer-real-estate/?source=post_page-----26bd58692195--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: (4) Image Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Headline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Stable Diffusion (text-to-image model)**: Stable Diffusion exhibited racial
    and gender bias in the thousands of generated images related to job titles and
    crime.'
  prefs: []
  type: TYPE_NORMAL
- en: Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An analysis by Bloomberg of over 5,000 images produced with Stable Diffusion
    uncovered significant racial and gender biases.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Fitzpatrick Skin Scale for categorization, they found that images
    generated for high-paying jobs predominantly featured subjects with lighter skin
    tones, while darker skin tones were linked with lower-paying occupations like
    "fast-food worker."
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, gender analysis revealed that for every image depicting a woman,
    almost three images depicted men, with most high-paying jobs being dominated by
    male representations with lighter skin tones.
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion derives its data from LAION-5B, the world's most extensive
    publicly available image-text dataset sourced from various online sites, including
    depictions of violence, hate symbols, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Key Lesson
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Auditing the data used for machine learning is vital. For example, if images
    depicting amplified stereotypes find their way back into future models via augmented
    training data, next-generation text-to-image models could become even more biased,
    creating a snowball effect of compounding bias.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[https://www.bloomberg.com/graphics/2023-generative-ai-bias](https://www.bloomberg.com/graphics/2023-generative-ai-bias/)'
  prefs: []
  type: TYPE_NORMAL
- en: (5) Natural Language Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Headline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**ChatGPT citations**: A lawyer used the popular chatbot ChatGPT to supplement
    his findings but was provided with completely fabricated past cases that do not
    exist.'
  prefs: []
  type: TYPE_NORMAL
- en: Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a lawyer named Steven Schwartz used ChatGPT to aid in preparing a court
    filing for a lawsuit relating to an injury due to an airline's negligence, things
    quickly went awry.
  prefs: []
  type: TYPE_NORMAL
- en: The brief he submitted included citations from several supposedly relevant court
    decisions, but neither the airline's attorneys nor the presiding judge could locate
    any of those cited decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Schwartz, who had practiced law for three decades, admitted to using ChatGPT
    for legal research, unaware of its potential to produce fabricated content. He
    had even asked ChatGPT to verify the validity of the cases, to which it erroneously
    confirmed their existence.
  prefs: []
  type: TYPE_NORMAL
- en: Key Lesson
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Relying solely on the outputs of generative models like ChatGPT without human
    verification can lead to significant inaccuracies, underscoring the need for human
    oversight (i.e., human-in-the-loop system) and cross-referencing with trusted
    sources.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html?source=post_page-----26bd58692195--------------------------------)
    [## Here''s What Happens When Your Lawyer Uses ChatGPT'
  prefs: []
  type: TYPE_NORMAL
- en: www.nytimes.com](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html?source=post_page-----26bd58692195--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: (6) Recommendation Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Headline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**IBM Watson for oncology:** IBM''s Watson allegedly provided numerous unsafe
    and incorrect recommendations for treating cancer patients.'
  prefs: []
  type: TYPE_NORMAL
- en: Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once seen as the future of cancer research, IBM's Watson supercomputer has reportedly
    been making unsafe recommendations for cancer treatments.
  prefs: []
  type: TYPE_NORMAL
- en: A notable instance is when it advised giving medication to a cancer patient
    with severe bleeding, a drug that could potentially exacerbate the bleeding. However,
    this suggestion was noted to be hypothetical and not applied to an actual patient.
  prefs: []
  type: TYPE_NORMAL
- en: The underlying issue stems from the nature of the data fed into Watson. IBM
    researchers have been inputting hypothetical or "synthetic" cases to enable the
    system to be trained on a wider variety of patient scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: However, this also meant that many recommendations were largely based on the
    treatment preferences of a select few doctors providing the data rather than insights
    derived from real patient cases.
  prefs: []
  type: TYPE_NORMAL
- en: Key Lesson
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The quality and representativeness of training data are paramount in machine
    learning, especially in critical applications like healthcare, to avoid biased
    and potentially harmful outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://www.theverge.com/2018/7/26/17619382/ibms-watson-cancer-ai-healthcare-science?source=post_page-----26bd58692195--------------------------------)
    [## IBM''s Watson gave unsafe recommendations for treating cancer'
  prefs: []
  type: TYPE_NORMAL
- en: www.theverge.com](https://www.theverge.com/2018/7/26/17619382/ibms-watson-cancer-ai-healthcare-science?source=post_page-----26bd58692195--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping it up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While machine learning has brought many benefits, we must remember that it is
    imperfect, as illustrated by the numerous real-world mistakes in this article.
    It is critical that we learn from these errors so we can leverage AI and machine
    learning better in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Check out [**this GitHub repo**](https://github.com/kennethleungty/Failed-ML)
    for the full compilation of machine learning blunders.
  prefs: []
  type: TYPE_NORMAL
- en: Before you go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I welcome you to **join me on a journey of data science discovery!** Follow
    this [Medium](https://kennethleungty.medium.com/) page and visit my [GitHub](https://github.com/kennethleungty)
    to stay updated with more engaging and practical content. Meanwhile, have fun
    exploring both the successes and slip-ups in machine learning!
  prefs: []
  type: TYPE_NORMAL
- en: '[](/running-llama-2-on-cpu-inference-for-document-q-a-3d636037a3d8?source=post_page-----26bd58692195--------------------------------)
    [## Running Llama 2 on CPU Inference Locally for Document Q&A'
  prefs: []
  type: TYPE_NORMAL
- en: Clearly explained guide for running quantized open-source LLM applications on
    CPUs using LLama 2, C Transformers, GGML…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/running-llama-2-on-cpu-inference-for-document-q-a-3d636037a3d8?source=post_page-----26bd58692195--------------------------------)
    [](/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f?source=post_page-----26bd58692195--------------------------------)
    [## Micro, Macro & Weighted Averages of F1 Score, Clearly Explained
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the concepts behind the micro average, macro average, and weighted
    average of F1 score…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f?source=post_page-----26bd58692195--------------------------------)
    [](https://medium.com/geekculture/how-to-create-clickable-table-of-contents-for-your-medium-posts-e81e22f83142?source=post_page-----26bd58692195--------------------------------)
    [## Create a Clickable Table of Contents for Your Medium Posts
  prefs: []
  type: TYPE_NORMAL
- en: Simple trick to create a dynamic table of contents to allow easy scroll navigation
    for your readers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/geekculture/how-to-create-clickable-table-of-contents-for-your-medium-posts-e81e22f83142?source=post_page-----26bd58692195--------------------------------)
  prefs: []
  type: TYPE_NORMAL
