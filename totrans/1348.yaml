- en: Introduction to Forecasting Ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/introduction-to-forecasting-ensembles-f63877a2498](https://towardsdatascience.com/introduction-to-forecasting-ensembles-f63877a2498)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**A cheap trick to boost forecasting performance**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://vcerq.medium.com/?source=post_page-----f63877a2498--------------------------------)[![Vitor
    Cerqueira](../Images/9e52f462c6bc20453d3ea273eb52114b.png)](https://vcerq.medium.com/?source=post_page-----f63877a2498--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f63877a2498--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f63877a2498--------------------------------)
    [Vitor Cerqueira](https://vcerq.medium.com/?source=post_page-----f63877a2498--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f63877a2498--------------------------------)
    ·5 min read·Jan 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41f1f4833476c2b810d89fef95d3e395.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Natalie Pedigo](https://unsplash.com/@nataliepedigo?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: If you need to squeeze in an extra bit of performance, a forecast combination
    might be what you’re looking for.
  prefs: []
  type: TYPE_NORMAL
- en: Forecast combination is the process of combining the predictions of many models.
    This technique is also known as ensemble forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Here, you’ll learn the 3 main steps of creating an ensemble for forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Why Use an Ensemble?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No forecasting method is perfect.
  prefs: []
  type: TYPE_NORMAL
- en: There are several techniques for creating forecasting models. Examples include
    classical approaches such as ARIMA or exponential smoothing. Or machine learning
    methods, such as decision trees or neural networks. You can [check my previous
    article](https://medium.com/towards-data-science/machine-learning-for-forecasting-transformations-and-feature-extraction-bbbea9de0ac2)
    on how to do supervised learning with time series.
  prefs: []
  type: TYPE_NORMAL
- en: Each approach has its own assumptions about the data, which do not always hold.
    Every method has its strengths and limitations. Managing these two is a key motivation
    for ensembles.
  prefs: []
  type: TYPE_NORMAL
- en: Combining several models can often lead to more accurate predictions. One reason
    for this is that it reduces the chance of picking the wrong model.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, an ensemble can be useful to convey the uncertainty of future observations.
    High forecast variability among the models suggests greater uncertainty. This
    aspect is valuable for decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do ensembles work?
  prefs: []
  type: TYPE_NORMAL
- en: 3 Stages of Building an Ensemble
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Building an ensemble is a 3-stage process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Creation: building different individual models;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pruning: removing poor or redundant models;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Integration: combining the models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/a8262299001405020ff310588f63670a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The steps of building an ensemble. First, you create many models.
    Then, you remove poor or redundant models. The rest are combined for forecasting.
    Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive a bit deeper into each step.
  prefs: []
  type: TYPE_NORMAL
- en: Creation Step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/998c33333b1c542098f2a4da9f222638.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mourizal Zativa](https://unsplash.com/@mourimoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to create the models that constitute the ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: Diversity among the models is a key thing you should mind. Each model should
    provide good but different predictions from the others. Highly correlated models
    reduce the effectiveness of the ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how do you foster diversity when building ensembles? There are two main
    strategies to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: Changing the learning method or its parameters;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Manipulating the training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Different methods hold different assumptions about the data. So, this leads
    to a natural diversity within the ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: An ensemble is called heterogeneous if its models are trained using different
    algorithms. For example linear models and decision trees. Otherwise, the ensemble
    is called homogeneous. Random Forests are an example of a homogeneous ensemble
    of decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: How is diversity encouraged in homogeneous ensembles like Random Forests?
  prefs: []
  type: TYPE_NORMAL
- en: 'The input data for Random Forests is manipulated in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: The training data for each tree is sampled with replacement. This process is
    known as bagging;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within each tree, a random subset of the features is selected at each split.
    This further increases diversity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The article in reference [3] provides an excellent review of diversity in ensembles.
  prefs: []
  type: TYPE_NORMAL
- en: Pruning Step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/b62bbeef903dedc277fb110f782a878c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Matt Briney](https://unsplash.com/@mbriney?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Many models are built during the creation step.
  prefs: []
  type: TYPE_NORMAL
- en: There’s a bit of randomness to this process. But, there’s no guarantee that
    all models will be useful or improve diversity.
  prefs: []
  type: TYPE_NORMAL
- en: A way to remedy this issue is to prune the ensemble. This involves removing
    unwanted models. A model should be discarded because of its poor performance or
    because it is redundant.
  prefs: []
  type: TYPE_NORMAL
- en: After removing unwanted models you get a better ensemble. One with better forecasting
    performance and fewer models to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Integration Step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final stage is integration. This is when you combine the predictions of
    the individual models.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest approach to do this is by taking the average of the predictions.
    Or, in the case of classification, by majority voting. An alternative is to assign
    different weights to each model and take a weighted average. One way to determine
    the weights is based on past performance. If a model has performed well, you give
    it a higher weight.
  prefs: []
  type: TYPE_NORMAL
- en: Hands-On
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s build a forecasting ensemble using Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the code, which is explained in the comments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As a case study, the goal is to forecast the production of beer. You can check
    the source of this data in reference [3]. We created 6 forecasting models using
    the *statsforecast* library. These include AutoARIMA, Holt-Winters, or AutoETS.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the forecasts of the 6 models are averaged to form the ensemble forecasts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’re the forecasts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07284e5d2ff4cea194aa9a6049a53261.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Forecasts of many models and their combination. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, here’s the mean absolute error of each approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3e7caa809dcb842a5bd2f183ad2f102b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Mean absolute error of each method. Image by Author.'
  prefs: []
  type: TYPE_NORMAL
- en: The ensemble is able to perform better than any individual model.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the ensemble contains only 6 models. But, ensembles often have
    many more models (up to hundreds). Still, there’s a diminishing returns effect
    as more models are added.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the catch?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While ensembles improve forecasting performance they have a few limitations.
  prefs: []
  type: TYPE_NORMAL
- en: You have to maintain several models instead of one. This leads to extra computational
    costs. For example, if you need to deploy the models in small devices there may
    not be enough storage space. If the data is sampled with a high frequency, the
    time to get and combine all forecasts may be too high.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensembles lack transparency. In some domains, transparent models are essential
    for trustworthiness and adoption by practitioners.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take-Aways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensembles combine the predictions of several models. This often leads to better
    forecasting performance;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ensembles are built in 3 stages: creation, pruning, and integration;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main limitations of ensembles are the extra computational costs and lack
    of transparency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks for reading, and see you in the next story!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Aiolfi, Marco, and Allan Timmermann. “Persistence in forecasting performance
    and conditional combination strategies.” *Journal of Econometrics* 135.1–2 (2006):
    31–53.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Brown, Gavin, et al. “Diversity creation methods: a survey and categorisation.”
    *Information fusion* 6.1 (2005): 5–20.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Quarterly Australian Beer production (GPL ≥ 2 licence) [https://www.rdocumentation.org/packages/fpp/versions/0.5/topics/ausbeer](https://www.rdocumentation.org/packages/fpp/versions/0.5/topics/ausbeer)'
  prefs: []
  type: TYPE_NORMAL
