- en: 'Unraveling the Design Pattern of Physics-Informed Neural Networks: Part 04'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­ç¤ºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„è®¾è®¡æ¨¡å¼ï¼šç¬¬04éƒ¨åˆ†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)
- en: Leveraging gradient-enhanced learning to improve PINN training efficiency
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ©ç”¨æ¢¯åº¦å¢å¼ºå­¦ä¹ æé«˜ PINN è®­ç»ƒæ•ˆç‡
- en: '[](https://shuaiguo.medium.com/?source=post_page-----c778f4829dde--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----c778f4829dde--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c778f4829dde--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c778f4829dde--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----c778f4829dde--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----c778f4829dde--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----c778f4829dde--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c778f4829dde--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c778f4829dde--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----c778f4829dde--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c778f4829dde--------------------------------)
    Â·7 min readÂ·May 29, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c778f4829dde--------------------------------)
    Â·7 min readÂ·2023å¹´5æœˆ29æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e855acaf7bff2a3df94f4786a4b3f626.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e855acaf7bff2a3df94f4786a4b3f626.png)'
- en: Photo by [Hassaan Qaiser](https://unsplash.com/es/@hassaanhre?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Hassaan Qaiser](https://unsplash.com/es/@hassaanhre?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Welcome to the 4th blog of this series, where we continue our exciting journey
    of exploring design patterns of physics-informed neural networks (PINN)ğŸ™Œ
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿æ¥åˆ°æœ¬ç³»åˆ—çš„ç¬¬4ç¯‡åšå®¢ï¼Œæˆ‘ä»¬å°†ç»§ç»­æ¿€åŠ¨äººå¿ƒçš„æ—…ç¨‹ï¼Œæ¢ç´¢ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNï¼‰çš„è®¾è®¡æ¨¡å¼ğŸ™Œ
- en: In this blog, we will check out a research paper that proposed a new variant
    of PINN called *gradient-enhanced* PINN. More concretely, we will look into the
    **problem**,the **solution**,the **benchmark**, as well asthe **strengths & weaknesses**,
    to distill the design pattern proposed by the paper.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸€ç¯‡æå‡ºäº†æ–°çš„ PINN å˜ä½“çš„ç ”ç©¶è®ºæ–‡ï¼Œè¿™ç§å˜ä½“è¢«ç§°ä¸º *æ¢¯åº¦å¢å¼º* PINNã€‚æ›´å…·ä½“åœ°ï¼Œæˆ‘ä»¬å°†ç ”ç©¶ **é—®é¢˜**ã€**è§£å†³æ–¹æ¡ˆ**ã€**åŸºå‡†**ä»¥åŠ
    **ä¼˜ç¼ºç‚¹**ï¼Œä»¥æç‚¼è®ºæ–‡æå‡ºçš„è®¾è®¡æ¨¡å¼ã€‚
- en: 'As this series continues to expand, the collection of PINN design patterns
    grows even richer*ğŸ™Œ* Hereâ€™s a sneak peek at what awaits you:'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: éšç€æœ¬ç³»åˆ—çš„ä¸æ–­æ‰©å±•ï¼ŒPINN è®¾è®¡æ¨¡å¼çš„é›†åˆå˜å¾—æ›´åŠ ä¸°å¯Œ*ğŸ™Œ* è¿™é‡Œæ˜¯æœªæ¥å†…å®¹çš„ä¸€äº›é¢„è§ˆï¼š
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 01: ä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 02: åŠ¨æ€è§£å†³æ–¹æ¡ˆåŒºé—´æ‰©å±•](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 03: training PINN with gradient boosting](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 03: ä½¿ç”¨æ¢¯åº¦æå‡è®­ç»ƒ PINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 05: automated hyperparameter tuning](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 05: è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 06: å› æœ PINN è®­ç»ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: ''
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Letâ€™s get started!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Paper at a glance ğŸ”
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Title**: Gradient-enhanced physics-informed neural networks for forward and
    inverse PDE problems'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authors**: J. Yu, L. Lu, X. Meng, G. E. Karniadakis'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Institutes**: St. Markâ€™s School of Texas, University of Pennsylvania, Brown
    University'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Link**: [arXiv](https://arxiv.org/abs/2111.02801)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. Design pattern ğŸ¨
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 2.1 Problem ğŸ¯
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, it is commonly observed that conventional PINNs tend to have limited
    accuracy even with many training points, especially when dealing with challenging
    PDEs with stiff solutions. This limitation impacts the current state of research
    and applications in PINNs by restricting their effectiveness in solving diverse
    forward and inverse PDE problems with high precision.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c58b062804e13c1d4d790b5587653193.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: PINN workflow. Conventional PINNs usually limited accuracy even with many residual
    points. One promising way to boost PINNsâ€™ accuracy is by training PINNs with **gradient-enhanced
    learning** algorithms. (Image by this blog author)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Solution ğŸ’¡
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One promising way to boost PINNsâ€™ accuracy is by adopting a **gradient-enhanced
    learning** approach to train PINN.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Gradient-enhanced learning has been proven to be useful in traditional machine
    learning [2]. As shown in the illustration below, in addition to the usual input-output
    pair (*x*, *y*), gradient-enhanced learning also incorporates the known value
    of the function gradient *dy/dx* as an extra supervision signal. This type of
    learning can be effective if the gradient information can be cheaply obtained
    (e.g., analytically available, easily measured, etc.)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd281200e61a443229cf7d5d15aadecc.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
- en: Convention learning (upper) only requires the model predictions at x to match
    with true function value f(x); Gradient-enhanced learning (lower) additionally
    requires that the derivative of the model predictions at x matches with known
    gradient value df(x)/dx. (Image adapted from [Wikipedia](https://en.wikipedia.org/wiki/Gradient-enhanced_kriging))
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: The same idea can also be applied to PINN training, as demonstrated in the paper.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Take a simple 2D Laplaceâ€™s equation (âˆ‚Â²u/âˆ‚xÂ² + âˆ‚Â²u/âˆ‚yÂ² = 0) as an example, when
    employing a PINN to solve the equation, we would enforce the PDE residual *f*
    to be zero, where *f* = âˆ‚Â²u/âˆ‚xÂ² + âˆ‚Â²u/âˆ‚yÂ². *f* essentially measures if the prediction
    aligns with the governing equation and constitutes the PDE loss term in the overall
    loss function used to train PINN.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'In gradient-enhanced PINN (gPINN), we can additionally enforce the derivatives
    of the PDE residual to be zero as well:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a49af02caaa7dc18432776d74e7ae8e.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: 'The rationale to do this is simple: because *f* is zero across the entire simulation
    domain, we know that the gradients of *f* are also zero. As a result, we would
    have two additional loss terms besides the usual PDE loss *f* = 0.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Why the solution might work ğŸ› ï¸
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key that could make gPINN effective is the fact that the gradient provides
    additional information about the functionâ€™s behavior. As a result, it can guide
    the learning process more effectively. This feature is known in the domain of
    traditional machine learning, but the current paper shows that the same benefits
    can also be gained for PINN training.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Benchmark â±ï¸
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The paper considered a total of 6 different benchmark problems, including 2
    forward problems, 2 inverse problems, and 2 PDEs with stiff solutions addressed
    by the standard gPINN and gPINN+RAR ([*residual-based adaptive refinement*](https://arxiv.org/abs/1907.04502)
    for sampling residual points):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '1D Poisson equation (forward problem, solved with standard gPINN): the Poisson
    equation is a fundamental partial differential equation in mathematical physics
    relating the distribution of matter in a system.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/833223fa631bf933277f33cafc3ed08a.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: 'Dirichlet boundary conditions: u( x=0 ) = 0, u( x=Ï€ ) = Ï€'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'Diffusion-reaction equation (forward problem, solved with standard gPINN):
    this equation models reactions combined with the diffusion of substances. The
    forward problem here involves predicting the concentration of substances given
    initial conditions and reaction rates.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/842c5e8e188e87957e95862bdffc06be.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: D=1 (diffusion coefficient)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/82ff8d1718fe7b8bf4d43485c1b228ff.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: R is the chemical reaction
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/252a01226b67f6aa3c442b361396597d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Initial and boundary conditions
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Brinkman-Forchheimer equation (inverse problem to identify the effective viscosity
    **Î½â‚‘** and permeability **K,** solved with standard gPINN): this equation describes
    flow in porous media, which is prevalent in fields such as oil recovery and groundwater
    flow.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/ccee13a1a26aed5cd3d00ad1b6576926.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: 'Boundary condition: u(0) = u(1) = 0, H=1, Î½=1e-3, Îµ=0.4, g=1'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '1D diffusion-reaction system (inverse problem to identify the space-dependent
    reaction rate *k*(*x*), solved with standard gPINN): similar to the second problem,
    this is also a diffusion-reaction equation.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/433c23f5d6e6c2e570cda37f4fc1d8b2.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: Diffusion coefficient Î» = 0.01, f = sin(2Ï€x). A separate neural network is used
    to approximate k, in addition to the network to predict u.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '1D Burgers equation (forward problem, solved with gPINN+RAR): this is a fundamental
    equation in fluid dynamics, combining non-linear convection and diffusion.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/56936edbc82f61fde41a791b3801fe7e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
- en: 'Initial condition: u(x, 0) =-sin(Ï€x), boundary conditions: u(-1, t) = u(1,
    t) = 0, Î½=0.01/Ï€'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'Allen-Cahn equation (forward problem, solved with gPINN+RAR): this equation
    models the process of phase separation, which is crucial in materials science.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/1a40486adc81c5d8901efbae2211a6d3.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: 'Initial condition: u(x, 0) = xÂ² cos(Ï€x), boundary conditions: u(-1, t) = u(1,
    t) = -1, D = 0.001'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'The benchmark studies yielded that:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: the proposed gradient-enhanced PINN learning (gPINN) achieved higher accuracy
    with fewer residual points compared to conventional PINN;
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: gPINN combined with advanced residual points sampling schemes (e.g., RAR) delivered
    the best performance for challenging PDEs.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.5 Strengths and Weaknesses âš¡
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Strengths** ğŸ’ª'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Improved accuracy of not only the function predictions but also the function
    derivatives predictions.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Faster convergence rate.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performs better than traditional PINN with fewer training points.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suitable for both forward and inverse problems.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be easily combined with advanced residual points sampling schemes ([see
    previous blog](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527))
    to further enhance the performance, especially in PDEs with solutions that have
    steep gradients.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weaknesses** ğŸ“‰'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Introduced new weighting parameters for balancing the gradient loss terms in
    the overall PINN loss function.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increased complexity of the model training, as well as a potentially increased
    computational cost.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.6 Alternatives ğŸ”€
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As this is the first paper that introduced the gradient-enhanced learning paradigm
    to the PINN field, there are currently no other similar approaches in the same
    line. In the paper, all the comparisons are conducted between vanilla PINN, gPINN,
    as well as gPINN+RAR sampling scheme.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 3 Potential Future Improvements ğŸŒŸ
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several possibilities to further improve the proposed strategy:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Automated parameter tuning for the weights of the gradient loss term.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved selection of residual points to evaluate the extra gradient loss. The
    current paper uses the same residual points to evaluate both PDE residuals and
    the gradients of PDE residuals. However, better performance may be achieved if
    the two sets of residual points are not the same.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More efficient automatic differentiation strategy for computing high-order derivatives.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4 Takeaways ğŸ“
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this blog, we looked at enhancing PINN accuracy and training efficiency
    through gradient-enhanced learning. Here are the highlights of the design pattern
    proposed in the paper:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[Problem]: How to enhance PINNsâ€™ accuracy and training efficiency?'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Solution]: **Gradient-enhanced learning**, where not only the PDE residuals
    but also their gradients are enforced to be zero in the PINN loss function.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Potential benefits]: 1\. Better performance than naive PINN with fewer residual
    points. 2\. Improved accuracy of not only the function predictions but also the
    function derivatives predictions'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As usual, I have prepared a PINN design card to summarize the takeaways:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/740382790faf3b8bde92d713de0b1855.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: PINN design pattern proposed in the paper. (Image by this blog author)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope you found this blog useful! To learn more about PINN design patterns,
    feel free to check out other posts in this series:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›æ‚¨è§‰å¾—è¿™ç¯‡åšå®¢æœ‰ç”¨ï¼è¦äº†è§£æ›´å¤šå…³äº PINN è®¾è®¡æ¨¡å¼çš„å†…å®¹ï¼Œè¯·éšæ—¶æŸ¥çœ‹æœ¬ç³»åˆ—çš„å…¶ä»–æ–‡ç« ï¼š
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 01ï¼šä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 02ï¼šåŠ¨æ€è§£å†³æ–¹æ¡ˆåŒºé—´æ‰©å±•](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: '[PINN design pattern 03: PINN training with gradient boost](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 03ï¼šå¸¦æœ‰æ¢¯åº¦æå‡çš„ PINN è®­ç»ƒ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: '[PINN design pattern 05: Hyperparameter tuning for PINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 05ï¼šPINN çš„è¶…å‚æ•°è°ƒæ•´](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 06ï¼šå› æœ PINN è®­ç»ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 07ï¼šä½¿ç”¨ PINN è¿›è¡Œä¸»åŠ¨å­¦ä¹ ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Looking forward to sharing more insights with you in the upcoming blogs!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸå¾…åœ¨æ¥ä¸‹æ¥çš„åšå®¢ä¸­ä¸æ‚¨åˆ†äº«æ›´å¤šè§è§£ï¼
- en: Reference ğŸ“‘
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒ ğŸ“‘
- en: '[1] Yu et al., Gradient-enhanced physics-informed neural networks for forward
    and inverse PDE problems, [arXiv](https://arxiv.org/abs/2111.02801), 2021.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Yu ç­‰ï¼ŒåŸºäºæ¢¯åº¦å¢å¼ºçš„ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œç”¨äºæ­£å‘å’Œåå‘ PDE é—®é¢˜ï¼Œ[arXiv](https://arxiv.org/abs/2111.02801)ï¼Œ2021å¹´ã€‚'
- en: '[2] Laurent et al., An overview of gradient-enhanced metamodels with applications,
    [Arch Computat Methods Eng](https://link.springer.com/article/10.1007/s11831-017-9226-3#article-info),
    2019.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Laurent ç­‰ï¼Œæ¢¯åº¦å¢å¼ºå…ƒæ¨¡å‹çš„æ¦‚è¿°åŠåº”ç”¨ï¼Œ[Arch Computat Methods Eng](https://link.springer.com/article/10.1007/s11831-017-9226-3#article-info)ï¼Œ2019å¹´ã€‚'
