- en: Why Data Scientists Should Adopt Machine Learning (ML) Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么数据科学家应该采用机器学习（ML）管道
- en: 原文：[https://towardsdatascience.com/why-should-data-scientists-adopt-machine-learning-ml-pipelines-8fc5e24920dd](https://towardsdatascience.com/why-should-data-scientists-adopt-machine-learning-ml-pipelines-8fc5e24920dd)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/why-should-data-scientists-adopt-machine-learning-ml-pipelines-8fc5e24920dd](https://towardsdatascience.com/why-should-data-scientists-adopt-machine-learning-ml-pipelines-8fc5e24920dd)
- en: Opinion
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 意见
- en: MLOps in Practice — as a data scientist, are you handing over a notebook or
    an ML pipeline to your ML engineers or DevOps engineers for the ML model to be
    deployed in a production environment?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps 实践 — 作为数据科学家，你是将一个笔记本还是一个 ML 管道交给你的 ML 工程师或 DevOps 工程师，以便在生产环境中部署 ML 模型？
- en: '[](https://medium.com/@weiyunna91?source=post_page-----8fc5e24920dd--------------------------------)[![YUNNA
    WEI](../Images/ffd0dd5c697dd2b4640ade49274d2bf9.png)](https://medium.com/@weiyunna91?source=post_page-----8fc5e24920dd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8fc5e24920dd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8fc5e24920dd--------------------------------)
    [YUNNA WEI](https://medium.com/@weiyunna91?source=post_page-----8fc5e24920dd--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@weiyunna91?source=post_page-----8fc5e24920dd--------------------------------)[![YUNNA
    WEI](../Images/ffd0dd5c697dd2b4640ade49274d2bf9.png)](https://medium.com/@weiyunna91?source=post_page-----8fc5e24920dd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8fc5e24920dd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8fc5e24920dd--------------------------------)
    [YUNNA WEI](https://medium.com/@weiyunna91?source=post_page-----8fc5e24920dd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8fc5e24920dd--------------------------------)
    ·9 min read·Feb 1, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8fc5e24920dd--------------------------------)
    ·9 分钟阅读·2023年2月1日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Background
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背景
- en: 'In my previous articles :'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前的文章中：
- en: '[Learn the Core of MLOps — Building Machine Learning (ML) Pipelines](https://medium.com/towards-data-science/learn-the-core-of-mlops-building-machine-learning-ml-pipelines-7242b77520b7)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习 MLOps 核心 — 构建机器学习（ML）管道](https://medium.com/towards-data-science/learn-the-core-of-mlops-building-machine-learning-ml-pipelines-7242b77520b7)'
- en: '[MLOps in Practice — De-constructing an ML Solution Architecture into 10 components](/mlops-in-practice-de-constructing-an-ml-solution-architecture-into-10-components-c55c88d8fc7a?sk=a14ce7ead68a2f90868d7a063eea84e3)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 实践 — 将 ML 解决方案架构分解为 10 个组件](/mlops-in-practice-de-constructing-an-ml-solution-architecture-into-10-components-c55c88d8fc7a?sk=a14ce7ead68a2f90868d7a063eea84e3)'
- en: 'I talked about the importance of building ML pipelines. In today’s article,
    I will deep dive into the topic of ML pipelines and explain in detail:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我谈到了构建 ML 管道的重要性。在今天的文章中，我将深入探讨 ML 管道的主题，并详细解释：
- en: Why is it necessary and important to build ML pipelines
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么构建 ML 管道是必要且重要的
- en: What are the key components of a ML pipeline
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ML 管道的关键组件是什么
- en: Why and how data scientists should adopt ML pipelines?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么以及数据科学家如何采用 ML 管道？
- en: '![](../Images/b81b7321cd7004472582896baf58d71b.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b81b7321cd7004472582896baf58d71b.png)'
- en: Photo by [Jon Tyson](https://unsplash.com/@jontyson?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Jon Tyson](https://unsplash.com/@jontyson?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。
- en: Why is it necessary and important to build ML pipelines?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么构建 ML 管道是必要且重要的？
- en: It is quite common that data scientists start developing ML models in a notebook
    environment. Within a notebook, they experiment with different datasets, different
    feature engineering techniques, as well as different combinations of parameters
    and hyperparameters, in order to find the best-performing ML models. After what
    can be multiple rounds of performance tuning and feature engineering, they find
    the ideal ML model. They continue to validate this model’s performance with test
    data to make sure the model is not “overfitted” and that it meets the business
    requirements. It is very likely that the model validation codes are developed
    and run in the same notebook environment. When they are happy with the overall
    model performance, they will ***handover*** a notebook (with codes potentially
    covering data ingestion, data exploration, feature engineering, model training
    and logging and model validation) to an ML engineer or DevOps engineer, for the
    model to be deployed in a production environment.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家在笔记本环境中开发ML模型是很常见的。在笔记本中，他们会实验不同的数据集、不同的特征工程技术，以及不同的参数和超参数组合，以找到表现最佳的ML模型。在经过多轮性能调优和特征工程之后，他们找到理想的ML模型。他们继续用测试数据验证模型的性能，以确保模型没有“过拟合”并且满足业务要求。模型验证代码很可能是在同一个笔记本环境中开发和运行的。当他们对整体模型性能满意时，他们会***交接***一个笔记本（其中的代码可能涵盖数据摄取、数据探索、特征工程、模型训练和日志记录以及模型验证）给ML工程师或DevOps工程师，以便将模型部署到生产环境中。
- en: 'However, there are many problems that could arise from this handover process:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个交接过程可能会出现许多问题：
- en: '**Slow and manual iterations** — When an issue is detected in the deployed
    ML system, data scientists need to go back to their notebooks to find a solution
    and handover the solution to the production engineers again for deploying the
    change to the production environment. The same process repeats every time when
    there is a need to update the model. There could be endless handovers. This is
    a very slow iteration. What’s worse, this manual and slow iteration could potentially
    cause significant business loss.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓慢和手动的迭代** — 当在部署的ML系统中检测到问题时，数据科学家需要回到他们的笔记本中寻找解决方案，并再次将解决方案交给生产工程师，以便将更改部署到生产环境中。每次需要更新模型时，这个过程都会重复。这可能会有无尽的交接。这是一种非常缓慢的迭代方式。更糟糕的是，这种手动和缓慢的迭代可能会导致显著的业务损失。'
- en: '**Duplicated effort** — It is very likely that codes produced by data scientists
    in a notebook environment are not production-ready. Hence, ML engineers need to
    put in the effort to rewrite and test the codes and convert the codes into modules
    for production deployment. An ML pipeline can minimize the code-rewriting effort
    significantly. I will explain why in the later part of this article.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重复工作** — 数据科学家在笔记本环境中生成的代码很可能不适合生产环境。因此，ML工程师需要投入精力重新编写和测试代码，并将代码转换为生产部署的模块。ML管道可以显著减少代码重写的工作量。我将在本文后面解释原因。'
- en: '**Error prone** — ML applications are quite dependency-reliant, meaning data
    scientists need to import various external libraries to assist the model training
    process. For example, they generally leverage Pandas for data cleaning and feature
    engineering, ML/DL frameworks for feature and model development, Numpy for tensor
    and array computation. Other than these popular libraries, they are also likely
    to use some niche libraries for their particular environment. Because of this
    dependency-reliant nature, there could be errors raised when the library used
    in the production environment mismatch with the original ones used in the development
    environment. In the previous point, we mentioned that there is a lot of code rewriting
    when the notebook gets handed over to the ML engineers. There could also be a
    lot of unintentional errors created during code translation, such as misconfigurations
    of model hyperparameters, unbalanced training and test split, data leak due to
    misuse of feature engineering logics.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易出错** — ML 应用程序依赖于各种外部库来辅助模型训练过程，这使得数据科学家需要导入这些库。例如，他们通常利用 Pandas 进行数据清洗和特征工程，利用
    ML/DL 框架进行特征和模型开发，利用 Numpy 进行张量和数组计算。除了这些流行的库，他们还可能会使用一些适合特定环境的小众库。由于这种依赖性，生产环境中使用的库与开发环境中使用的库不匹配时可能会引发错误。在前一点中，我们提到当笔记本被交给
    ML 工程师时，通常会有大量的代码重写。在代码转换过程中可能会产生很多无意中的错误，比如模型超参数配置错误、训练和测试集不平衡、由于特征工程逻辑误用导致的数据泄露。'
- en: '**Hard to scale** — Because a lot of time and effort is spent on this handover
    process, it is very difficult for the team of data scientists and ML engineers
    to go large-scale. If organizations want to develop more ML applications, they
    need to recruit more data scientists and engineers. Therefore getting rid of this
    manual handover between data scientists and ML engineers can significantly improve
    team efficiency and more ML applications can be built, with limited resources.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**难以扩展** — 由于在这个交接过程中花费了大量时间和精力，因此数据科学家和 ML 工程师团队很难实现大规模扩展。如果组织想要开发更多的 ML 应用程序，他们需要招聘更多的数据科学家和工程师。因此，消除数据科学家和
    ML 工程师之间的手动交接可以显著提高团队效率，从而在有限的资源下构建更多的 ML 应用程序。'
- en: Now let’s see how ML pipelines can streamline or even remove this manual handover
    process and bridge the gap between the notebook ML model experimentations in a
    development environment and ML model deployment in a production environment. The
    ultimate goal is that ML applications get deployed and updated in a fast, automated
    and safe manner.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 ML 流水线如何简化或甚至消除这一手动交接过程，并弥合开发环境中的笔记本 ML 模型实验和生产环境中的 ML 模型部署之间的差距。最终目标是以快速、自动和安全的方式部署和更新
    ML 应用程序。
- en: First Let’s understand what an ML pipeline is.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们了解一下什么是 ML 流水线。
- en: What is a ML pipeline and the key components of a ML pipeline
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 ML 流水线以及 ML 流水线的关键组件
- en: 'Before we deep dive into what a ML pipeline is, let’s first understand what
    a “pipeline” is. Below is a definition from Wikipedia:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解 ML 流水线之前，我们首先要理解“流水线”是什么。以下是来自维基百科的定义：
- en: In computing, a pipeline, also known as a data pipeline, is **a set of data
    processing elements** **connected** in series, where the **output** of one element
    is the **input** of the next one. The elements of a pipeline are often executed
    **in parallel** or **in time-sliced fashion**. Some amount of **buffer storage**
    is often inserted between elements.
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在计算中，流水线，也称为数据流水线，是**一组数据处理元素****串联**在一起的，其中一个元素的**输出**是下一个元素的**输入**。流水线的元素通常**并行**或**按时间切片**执行。在元素之间通常会插入一些**缓冲存储**。
- en: 'There are a few key components in the above definition and they apply to a
    ML pipeline perfectly as well. Let’s see how it works:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 上述定义中有几个关键组件，这些组件同样适用于 ML 流水线。让我们看看它是如何工作的：
- en: A set of data processing elements — The first part of the definition talks about
    a set of data processing elements. This is very straight forward. If we apply
    this to an ML pipeline, the set of data processing elements could include data
    ingestion, data pre-processing, feature engineering, model training, model prediction
    and so on. For your ML pipelines, you could customize each component and add as
    many components in a pipeline as you need. Each component performs one task and
    all tasks combined deliver a pipeline. Dividing a workflow into multiple elements
    is very useful for ML applications. The reason is, each element in a ML pipeline
    could potentially require very different compute resources. Allocating appropriate
    compute resources for each element, instead of using a giant compute for the whole
    workflow provides a good opportunity for improving compute efficiency.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一组数据处理元素 — 定义的第一部分讨论了一组数据处理元素。这是非常直接的。如果我们将其应用于 ML 管道，则数据处理元素的集合可能包括数据摄取、数据预处理、特征工程、模型训练、模型预测等。对于你的
    ML 管道，你可以自定义每个组件，并根据需要在管道中添加多个组件。每个组件执行一个任务，所有任务结合起来形成一个管道。将工作流分解为多个元素对于 ML 应用非常有用。原因是，ML
    管道中的每个元素可能需要非常不同的计算资源。为每个元素分配适当的计算资源，而不是为整个工作流使用巨大的计算资源，这为提高计算效率提供了良好的机会。
- en: Connected — The second element is that these components are connected. They
    do not run completely independently from each other. More importantly, the dependencies
    of the above mentioned data processing elements are captured. In the context of
    an ML pipeline, the data ingestion step must be finished before running data pre-processing,
    or the model training step must be complete before model prediction.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接 — 第二个元素是这些组件是相互连接的。它们不是完全独立运行的。更重要的是，捕捉了上述数据处理元素的依赖关系。在 ML 管道的上下文中，数据摄取步骤必须在运行数据预处理之前完成，或者模型训练步骤必须在模型预测之前完成。
- en: Input / Output — Each data processing element in a pipeline has an input and
    output. Often, the output artifacts of one element are used as input artifacts
    to a subsequent step. These artifacts will be stored in a central location, such
    as an artifact repository.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入/输出 — 管道中的每个数据处理元素都有输入和输出。通常，一个元素的输出文档作为后续步骤的输入文档使用。这些文档将存储在中央位置，如文档库。
- en: In parallel / In time-sliced fashion — Defines the execution order of each element
    in an ML pipeline. “In parallel” means two elements can run at the same time;
    while “in time-sliced fashion”, means there is dependency between two elements.
    One element has to wait until the other one finishes.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 并行/分时执行 — 定义 ML 管道中每个元素的执行顺序。“并行”意味着两个元素可以同时运行；而“分时执行”则意味着两个元素之间有依赖关系。一个元素必须等到另一个完成后才能执行。
- en: Buffer storage — Buffer storage is the artifacts repository that we mentioned
    in the Input / Output section. The buffer storage provides a central location
    for data artifacts so that downstream elements can consume the outputs of upstream
    elements, logs and metrics for monitoring and tracking purposes. With the artifacts
    repository in place, you can re-use the outputs of some elements instead of running
    every element when you need to re-run the workflow. This also can improve pipeline
    efficiency and reduce compute costs. Additionally You can also set up a database
    for your ML metadata including Experiments, jobs, pipeline runs, and metrics.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 缓冲存储 — 缓冲存储是我们在输入/输出部分提到的文档库。缓冲存储提供了一个中央位置，用于数据文档，以便下游元素可以使用上游元素的输出、日志和用于监控和跟踪的指标。通过文档库，你可以重用某些元素的输出，而不是在需要重新运行工作流时运行每个元素。这也可以提高管道效率并降低计算成本。此外，你还可以为
    ML 元数据设置数据库，包括实验、作业、管道运行和指标。
- en: 'Below is a sample of what an ML training pipeline could look like:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个 ML 训练管道可能的示例：
- en: '![](../Images/30011013f21152e4fab79bb17bf5c214.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30011013f21152e4fab79bb17bf5c214.png)'
- en: A sample ML model training pipeline | Image by Author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例 ML 模型训练管道 | 作者提供的图像
- en: 'This sample ML training pipeline includes 10 tasks. Generally an ML pipeline
    is defined using either a Python SDK or a YAML file. For each task, you can define
    the following configurations:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例 ML 训练管道包括 10 个任务。通常，ML 管道是通过 Python SDK 或 YAML 文件定义的。对于每个任务，你可以定义以下配置：
- en: Name — the name of the task
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称 — 任务的名称
- en: Description — a description to the task
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述 — 对任务的描述
- en: Input — the input settings of the task
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入 — 任务的输入设置
- en: Output — the output settings of the task
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出 — 任务的输出设置
- en: Compute — the underlying compute resources used to execute the task
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算 — 用于执行任务的底层计算资源
- en: Parameters — additional parameters supplied to run the task
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数 — 运行任务时提供的附加参数
- en: Requirements — environment dependencies required to be installed in the compute
    resources
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需求 — 在计算资源中需要安装的环境依赖关系
- en: Task dependencies — the connected upstream and downstream tasks.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务依赖关系 — 连接的上游和下游任务。
- en: '![](../Images/0ca68993941a6fac75def855b38bdf69.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ca68993941a6fac75def855b38bdf69.png)'
- en: Configurations of an ML pipeline task | Image by Author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ML 流水线任务的配置 | 图片作者
- en: The benefits of adopting ML pipelines
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 采用 ML 流水线的好处
- en: 'Compared to having all the codes in one notebook, modularizing the codes into
    ML pipelines provides the following characteristics:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与将所有代码放在一个笔记本中相比，将代码模块化为 ML 流水线提供了以下特点：
- en: Self-contained — Each task in an ML pipeline is a self-contained processing
    unit. You can define the necessary configurations and dependencies and select
    the most appropriate compute resources for each task.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自包含 — ML 流水线中的每个任务都是一个自包含的处理单元。你可以定义必要的配置和依赖关系，并为每个任务选择最合适的计算资源。
- en: Re-use — Because each task is self-contained and the task outputs and related
    metadata are stored in a central artifact location. Therefore you have the flexibility
    to decide what tasks may be skipped when triggering a pipeline re-run. For example,
    if you just want to re-run the model training task, you can reuse the outputs
    of the previous tasks such as data processing and feature engineering.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重用 — 因为每个任务都是自包含的，任务输出和相关的元数据都存储在一个中央工件位置。因此，你可以灵活决定在触发流水线重新运行时可以跳过哪些任务。例如，如果你只想重新运行模型训练任务，你可以重用之前任务的输出，如数据处理和特征工程。
- en: Modularized codes — In a pipeline, each task is modularized with configurations
    and dependencies, which is aligned with the general DevOps standards. This can
    reduce the code-rewriting effort required from ML engineers and minimize the potential
    errors brought by this code-rewriting process.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模块化代码 — 在流水线中，每个任务都模块化了配置和依赖关系，这与通用的 DevOps 标准一致。这可以减少 ML 工程师所需的代码重写工作，并最小化此代码重写过程带来的潜在错误。
- en: 'Therefore building an ML pipeline brings the following benefits:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，构建 ML 流水线带来了以下好处：
- en: Fast iteration — Once an ML solution is deployed into the production environment,
    data scientists can update the pipeline whenever necessary and their code changes
    will be merged and deployed following the defined DevOps standards. This can significantly
    reduce the time required to update an ML model and reduce the iteration cycle
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速迭代 — 一旦 ML 解决方案部署到生产环境中，数据科学家可以在必要时更新流水线，他们的代码更改将按照定义的 DevOps 标准合并并部署。这可以显著减少更新
    ML 模型所需的时间，并缩短迭代周期。
- en: Full automation — Once an ML solution is deployed into the production environment,
    all the code changes will follow defined DevOps standards and get deployed automatically.
    Therefore, no manual handover will be required between data scientists and ML
    engineers.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全自动化 — 一旦 ML 解决方案部署到生产环境中，所有代码更改将遵循定义的 DevOps 标准并自动部署。因此，数据科学家和 ML 工程师之间无需手动交接。
- en: Production ready — Because all the codes are modularized in a pipeline, the
    codes handed over by data scientists are pretty much production ready and the
    re-writing efforts could be very minimal.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产就绪 — 因为所有代码都模块化在流水线中，数据科学家交付的代码基本上是生产就绪的，重写工作可以非常少。
- en: Better collaboration — The way ML pipelines are constructed avoids a lot of
    unnecessary communication between data scientists and ML engineers, as the pipeline
    definitions and task configurations contain pretty much all the necessary information
    for ML engineers to deploy the pipelines. If all the codes are in one big notebook,
    ML engineers definitely will need more communication with data scientists to seek
    clarity.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好的协作 — ML 流水线的构建方式避免了数据科学家和 ML 工程师之间大量不必要的沟通，因为流水线定义和任务配置包含了 ML 工程师部署流水线所需的几乎所有信息。如果所有代码都在一个大笔记本中，ML
    工程师肯定需要更多的沟通来寻求明确性。
- en: Execution at scale — The fast iteration and full automation characteristics
    of an ML pipeline minimize the manual effort required to operate ML solutions
    in a production environment. Hence, the same number of data scientists and ML
    engineers are able to handle a much larger number of ML applications. This allows
    organizations to scale the benefits of ML and AI with limited resources.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大规模执行 — ML管道的快速迭代和完全自动化特性最小化了在生产环境中操作ML解决方案所需的人工努力。因此，相同数量的数据科学家和ML工程师能够处理更多的ML应用。这使得组织能够在有限的资源下扩展ML和AI的好处。
- en: '![](../Images/e918d667d30e121999dfd8fd7f11abec.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e918d667d30e121999dfd8fd7f11abec.png)'
- en: Benefits of ML pipelines | Image by Author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ML管道的好处 | 图片作者
- en: 'To summarize, I would love to reiterate:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我想重申：
- en: The output of a notebook is a model; while the output of a pipeline is a piece
    of software. **At the production stage, it is the *ML system* that gets deployed,
    not the *ML model*.** Therefore, ML pipelines are a great mechanism to bridge
    the gap between the ML development environment (which is notebook-driven) and
    the ML production environment (which is system-driven).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本的输出是一个模型；而管道的输出是一段软件。**在生产阶段，部署的是*ML系统*，而不是*ML模型*。** 因此，ML管道是弥合ML开发环境（以笔记本驱动）和ML生产环境（以系统驱动）之间差距的绝佳机制。
- en: Open source frameworks for implementing ML pipelines
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现ML管道的开源框架
- en: 'If you are now more motivated to generate ML pipelines, instead of producing
    a notebook, below is a list of open source frameworks that you can leverage:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在更有动力生成ML管道，而不是创建笔记本，下面是您可以利用的一些开源框架的列表：
- en: '[ZenML](https://zenml.io/home) — the open source MLOps framework for unifying
    your ML stack'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ZenML](https://zenml.io/home) — 用于统一您的ML技术栈的开源MLOps框架'
- en: '[MLflow Recipes](https://www.mlflow.org/docs/latest/recipes.html#) — a module
    of [MLflow](https://www.mlflow.org/) that enables data scientists to quickly develop
    high-quality models and deploy them to production'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLflow Recipes](https://www.mlflow.org/docs/latest/recipes.html#) — [MLflow](https://www.mlflow.org/)
    的一个模块，使数据科学家能够快速开发高质量的模型并将其部署到生产环境中'
- en: '[Metaflow](https://metaflow.org/) — a framework for real-life data science
    and ML'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Metaflow](https://metaflow.org/) — 适用于现实世界数据科学和ML的框架'
- en: '[Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/) —
    Kubeflow Pipelines (KFP) is a platform for building and deploying portable and
    scalable machine learning (ML) workflows by using Docker containers'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/) —
    Kubeflow Pipelines (KFP) 是一个通过使用Docker容器来构建和部署可移植且可扩展的机器学习 (ML) 工作流的平台'
- en: '[MLRun](https://www.mlrun.org/) — The open source MLOps orchestration framework'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLRun](https://www.mlrun.org/) — 开源MLOps编排框架'
- en: If you would like to see me write hands-on tutorials on building ML pipelines,
    please follow me on Medium and leave a comment to let me know which specific framework
    you are most interested in.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望看到我撰写关于构建ML管道的实践教程，请在Medium上关注我，并留言告诉我您最感兴趣的具体框架。
- en: If you want to see more guides, deep dives, and insights around modern and efficient
    data+AI stack, please subscribe to my free newsletter — [***Efficient Data+AI
    Stack***](https://yunnawei.substack.com/), thanks!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想查看更多关于现代和高效的数据+AI技术栈的指南、深入探讨和见解，请订阅我的免费通讯——[***高效的数据+AI技术栈***](https://yunnawei.substack.com/)，谢谢！
- en: 'Note: Just in case you haven’t become a Medium member yet, and you really should,
    as you’ll get unlimited access to Medium, you can sign up using my [referral link](https://medium.com/@weiyunna91/membership)!'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注：如果您还没有成为Medium会员，您真的应该成为会员，这样您可以无限制访问Medium，您可以使用我的[推荐链接](https://medium.com/@weiyunna91/membership)注册！
- en: Thanks so much for your support!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢您的支持！
