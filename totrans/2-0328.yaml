- en: Are You Still Using the Elbow Method?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你还在使用Elbow方法吗？
- en: 原文：[https://towardsdatascience.com/are-you-still-using-the-elbow-method-5d271b3063bd](https://towardsdatascience.com/are-you-still-using-the-elbow-method-5d271b3063bd)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/are-you-still-using-the-elbow-method-5d271b3063bd](https://towardsdatascience.com/are-you-still-using-the-elbow-method-5d271b3063bd)
- en: The Elbow method is the most popular way to find the number of clusters for
    k-means. But there are much better alternatives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Elbow方法是确定k-means聚类数目最受欢迎的方式。但还有更好的替代方法。
- en: '[](https://medium.com/@mazzanti.sam?source=post_page-----5d271b3063bd--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----5d271b3063bd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5d271b3063bd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5d271b3063bd--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----5d271b3063bd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mazzanti.sam?source=post_page-----5d271b3063bd--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----5d271b3063bd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5d271b3063bd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5d271b3063bd--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----5d271b3063bd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5d271b3063bd--------------------------------)
    ·7 min read·Feb 3, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----5d271b3063bd--------------------------------)
    ·7分钟阅读·2023年2月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/fbbd66b6178605b4c0396fa820bbdeb2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbbd66b6178605b4c0396fa820bbdeb2.png)'
- en: '[Image by Author]'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[作者提供的图片]'
- en: 'I asked ChatGPT to advise me on how to choose the right number of clusters
    for *k*-means. This was the answer:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我请ChatGPT建议如何选择*k*-means的合适聚类数目。这是回答：
- en: '![](../Images/d2ed1bb5798d85dd0b8771d5e9c3196f.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2ed1bb5798d85dd0b8771d5e9c3196f.png)'
- en: '[Screenshot from ChatGPT: [https://chat.openai.com/chat](https://chat.openai.com/chat)]'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[来自ChatGPT的截图: [https://chat.openai.com/chat](https://chat.openai.com/chat)]'
- en: ChatGPT suggests using the so-called “Elbow method”, which is by far the most
    cited method in many online and offline sources.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT建议使用所谓的“Elbow方法”，这是迄今为止在许多在线和离线来源中被引用最多的方法。
- en: However, **the popularity of the Elbow method is pretty inexplicable**! In fact,
    as we will see in this article, this method is almost always outperformed by different
    existing approaches.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，**Elbow方法的流行程度实在难以解释**！事实上，正如我们将在本文中看到的，这种方法几乎总是被不同的现有方法超越。
- en: Read on if you want to know how to easily beat the Elbow method when deciding
    the best number of clusters for a dataset.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道如何轻松超越Elbow方法来确定数据集的最佳聚类数目，请继续阅读。
- en: Testing the elbow
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试肘部
- en: The logic behind the Elbow method is the following.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Elbow方法背后的逻辑如下。
- en: Since we want to know what is the best number of clusters (*k*), we try different
    values for *k*, for instance, all the integer values between 1 and the square
    root of the number of observations of the dataset. At each iteration, we record
    the so-called “inertia”.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们想知道最佳聚类数目（*k*），我们尝试不同的*k*值，例如，所有整数值从1到数据集观测值数量的平方根。在每次迭代中，我们记录所谓的“惯性”。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Inertia is the sum of squared distances between each point and the center of
    the cluster it belongs to. Thus, it makes sense to expect that inertia gets smaller
    as *k* increases. In fact, as there are more clusters, each cluster is smaller,
    so each point is closer to the center of its cluster. Eventually, when *k* equals
    the number of data points, inertia is necessarily zero.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 惯性是每个点与其所属聚类中心之间的平方距离之和。因此，可以预期惯性随着*k*的增加而减小。事实上，随着聚类数目的增加，每个聚类会更小，因此每个点离其聚类中心更近。最终，当*k*等于数据点的数量时，惯性必然为零。
- en: The idea is that the best value for *k* is the point of maximum curvature of
    the inertia curve. This is the point where a lower value of inertia is not worth
    the additional complexity (i.e. more clusters). This point is called **the elbow
    of the curve**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 其核心思想是* k*的最佳值是惯性曲线的最大曲率点。这个点是惯性值较低但额外复杂度（即更多的聚类）不值得的地方。这个点被称为**曲线的肘部**。
- en: 'To locate the elbow of the inertia curve we can use a Python library called
    `kneed`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定位惯性曲线的肘部，我们可以使用一个名为`kneed`的Python库：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s see the example of a two-dimensional dataset made of 3 clusters:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个由 3 个簇组成的二维数据集的例子：
- en: '![](../Images/988d391ac64f9fc838bf1a1643b2680c.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/988d391ac64f9fc838bf1a1643b2680c.png)'
- en: The elbow method on a toy dataset. [Image by Author]
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在玩具数据集上的肘部法则。 [图片来源：作者]
- en: 'In this case, the Elbow method guessed the right number of clusters: 3\. But
    will it work also on other datasets?'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，肘部法则猜对了正确的簇数：3。但它在其他数据集上也会有效吗？
- en: Let’s see.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看。
- en: '![](../Images/b65c0c71aea043d31c3025a9c5ad7558.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b65c0c71aea043d31c3025a9c5ad7558.png)'
- en: Equally sized clusters. [Image by Author]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 等大小的簇。 [图片来源：作者]
- en: The Elbow method guessed the correct number of clusters in three datasets (2,
    3, and 5), but it severely underestimated it in the other two examples (10 and
    25).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 肘部法则在三个数据集（2、3 和 5）中猜对了正确的簇数，但在另外两个例子（10 和 25）中严重低估了簇数。
- en: Ok, the Elbow method probably didn’t work as we hoped. But is there something
    better on the market?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，肘部法则可能没有如我们所希望的那样有效。但是市场上有没有更好的方法？
- en: Beyond the Elbow method
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越肘部法则
- en: The Elbow method is based on inertia, which is a score of the goodness of fit
    of clusters. But if we want to use a different method, we will need to use a different
    score.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 肘部法则是基于惯性（inertia）的，它是一个聚类拟合优度的评分。但如果我们想使用不同的方法，我们就需要使用不同的评分。
- en: Let’s take a look at the options that are directly available in Scikit-Learn.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Scikit-Learn 中直接可用的选项。
- en: '![](../Images/9c3ca009425b3b4a073070bcd215e413.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c3ca009425b3b4a073070bcd215e413.png)'
- en: List of clustering metrics available in Scikit-Learn. [Screenshot from [Scikit-Learn
    documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)]
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Learn 中可用的聚类指标列表。 [来自 [Scikit-Learn 文档](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)
    的截图]
- en: Actually, many of these metrics won’t work out for us, because they require
    `labels_true` as an input, and we want to test these methods in the scenario in
    which we don’t have the true labels.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，许多这些指标对我们不起作用，因为它们需要 `labels_true` 作为输入，而我们希望在没有真实标签的情况下测试这些方法。
- en: Thus, out of this list, we could only use the metrics that take `X` and `labels`
    as input. Thus, only “Calinski-Harabasz”, “Davies-Bouldin” and “Silhouette” will
    work for us.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这个列表中，我们只能使用那些以 `X` 和 `labels` 作为输入的指标。因此，只有“Calinski-Harabasz”、“Davies-Bouldin”和“Silhouette”对我们有效。
- en: 'Besides these, I will add another score that is not implemented in Scikit-Learn.
    The score is “BIC” (Bayesian Information Criterion), and I will include it because
    [this paper](https://arxiv.org/abs/2212.12189) shows that it performs really well.
    For BIC, I will use the implementation made by Bob Hancock in [this GitHub repository](https://github.com/bobhancock/goxmeans/tree/a78e909e374c6f97ddd04a239658c7c5b7365e5c).
    Since the code is in GoLang, I have translated it to the following Python function:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，我还将添加一个在 Scikit-Learn 中未实现的评分指标。这个评分是“BIC”（贝叶斯信息准则），我会包含它，因为[这篇论文](https://arxiv.org/abs/2212.12189)显示它表现得非常好。对于
    BIC，我将使用 Bob Hancock 在[这个 GitHub 仓库](https://github.com/bobhancock/goxmeans/tree/a78e909e374c6f97ddd04a239658c7c5b7365e5c)中实现的版本。由于代码是用
    GoLang 编写的，我已经将其翻译成了以下 Python 函数：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To sum up, we now have five scores to compare:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们现在有五个评分可以进行比较：
- en: '**Inertia (elbow method)**;'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Inertia（肘部法则）**；'
- en: '**Calinski-Harabasz**;'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Calinski-Harabasz**；'
- en: '**Davies-Bouldin**;'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Davies-Bouldin**；'
- en: '**Silhouette**;'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Silhouette**；'
- en: '**BIC**.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**BIC**。'
- en: 'The procedure is the same: for each dataset, we fit a *k*-means using *k* =
    1, *k* = 2, *k* = 3, … For each *k*, we calculate these five scores. This means
    that we end up with five curves, one for each metric.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 流程是一样的：对于每个数据集，我们使用 *k* = 1、*k* = 2、*k* = 3 等来拟合 *k*-均值。对于每个 *k*，我们计算这五个评分。这意味着我们会得到五条曲线，每条曲线对应一个指标。
- en: 'At this point, how do we decide what is the optimal *k*? For inertia we already
    know the answer: it’s the point that lies in the “elbow”. The other scores are
    even simpler to use because their behaviour is either “higher-is-better” or “lower-is-better”:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们如何决定最佳的 *k* 值？对于惯性（inertia），我们已经知道答案：它是位于“肘部”处的点。其他评分的使用更为简单，因为它们的行为要么是“越高越好”，要么是“越低越好”：
- en: '**Inertia** → **elbow is better**;'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Inertia** → **肘部法则更好**；'
- en: '**Calinski-Harabasz** → **higher is better**;'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Calinski-Harabasz** → **越高越好**；'
- en: '**Davies-Bouldin** → **lower is better**;'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Davies-Bouldin** → **越低越好**；'
- en: '**Silhouette** → **higher is better**;'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Silhouette** → **越高越好**；'
- en: '**BIC** → **higher is better**.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**BIC** → **越高越好**。'
- en: So let’s see how these scores would work on our five datasets.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们看看这些评分在我们的五个数据集上的表现如何。
- en: '![](../Images/df9b5d33c479479d7d64ec9d916e8433.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df9b5d33c479479d7d64ec9d916e8433.png)'
- en: Five datasets and the respective curves. [Image by Author]
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 五个数据集及其各自的曲线。[作者提供的图片]
- en: 'As we have seen, the Elbow method guessed correctly three datasets and missed
    completely the target in the remaining two. Instead, **the other methods guessed
    correctly all the datasets** (except for Davies-Bouldin on the fifth dataset,
    which anyway is very close to the real number: 24 instead of 25).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，肘部法则正确猜测了三个数据集，但在剩下的两个数据集中完全失误。相反，**其他方法正确猜测了所有数据集**（除了Davies-Bouldin在第五个数据集上的结果，不过它非常接近真实值：24而非25）。
- en: 'But maybe these datasets were too easy. In fact, all the datasets were made
    of equally sized clusters. This is an unlikely situation: **in most real datasets,
    we expect the clusters to have a different number of observations**.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 但也许这些数据集太简单了。实际上，所有数据集都是由大小相同的簇组成的。这种情况不太可能出现：**在大多数真实数据集中，我们期望簇的观测值数量是不同的**。
- en: So let’s see what happens with clusters of unequal size.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们看看不等大小的簇会发生什么。
- en: '![](../Images/2a33502a2f71db975470ace06a54f2c4.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a33502a2f71db975470ace06a54f2c4.png)'
- en: Five datasets with clusters of different sizes. [Image by Author]
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 不同大小簇的五个数据集。[作者提供的图片]
- en: This time, the difference between the Elbow method and the other methods is
    even more evident than before. Indeed, whereas the Elbow method made the right
    choice only for one cluster, the other four methods guessed correctly all five
    datasets.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，肘部法则与其他方法之间的差异比之前更为明显。事实上，尽管肘部法则只对一个簇做出了正确的选择，但其他四种方法都正确猜测了所有五个数据集。
- en: These examples are interesting but they still don’t tell us which method is
    preferable. In order to answer that question we should make a larger-scale comparison.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子很有趣，但它们仍然没有告诉我们哪种方法更优。为了回答这个问题，我们应该进行大规模的比较。
- en: A systematic comparison
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系统性比较
- en: I built 30 datasets, each one with a different number of clusters, from 1 to
    30\. Each cluster has a different number of observations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我构建了30个数据集，每个数据集有不同数量的簇，从1到30。每个簇有不同数量的观测值。
- en: For each dataset, I tried different values of *k* and recorded the five resulting
    scores (Inertia, Calinski-Harabasz, Davies-Bouldin, Silhouette, and BIC). Then,
    according to the rules we have seen above, I have identified the value of *k*
    recommended by each method.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个数据集，我尝试了不同的*k*值，并记录了五个结果分数（Inertia、Calinski-Harabasz、Davies-Bouldin、Silhouette和BIC）。然后，根据我们上面看到的规则，我确定了每种方法推荐的*k*值。
- en: To decide which method is the winner, I then plotted the true number of clusters
    of each dataset (*x*-axis) and the number of clusters suggested by each method
    (*y*-axis). Clearly, the best method is the one that gets closer to the bisector.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定哪种方法是赢家，我绘制了每个数据集的真实簇数量（*x*-轴）和每种方法建议的簇数量（*y*-轴）。显然，最佳方法是与对角线距离最近的。
- en: '![](../Images/ead232e3735aecdbdd502528a494619d.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ead232e3735aecdbdd502528a494619d.png)'
- en: True number of clusters (x-axis) and number of clusters estimated by each method
    (y-axis). [Image by Author]
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 真实簇的数量（x轴）和每种方法估计的簇数量（y轴）。[作者提供的图片]
- en: From the plot, it is clear that **the Elbow method is by far the worst-performing**.
    Davies-Bouldin and Silhouette are right most of the time, or at least very close
    to the ground truth (except when the true *k* equals 1). But **the clear winners
    (on par) are Calinski-Harabasz and BIC**.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以明显看出，**肘部法则是表现最差的**。Davies-Bouldin和Silhouette大多数时候是正确的，或者至少非常接近真实值（除了当真实的*k*等于1时）。但**明显的赢家（并列）是Calinski-Harabasz和BIC**。
- en: 'We can also summarize these visual insights by counting **how many times a
    method guessed the true number of clusters (accuracy) and how far off they were,
    on average, from the ground truth (average distance)**:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过计算**方法正确猜测簇的真实数量的次数（准确性）以及它们平均偏离真实值的距离**来总结这些视觉见解：
- en: '![](../Images/b259717a67fcc3c495f44663a9d3d99b.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b259717a67fcc3c495f44663a9d3d99b.png)'
- en: Accuracy and average distance from the ground truth. [Image by Author]
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性和与真实值的平均距离。[作者提供的图片]
- en: Calinski-Harabasz and BIC were right in 97% of the cases (29 out of 30), which
    is pretty impressive. Silhouette was right 73% of the time (22 out of 30) and
    Davies-Bouldin 70% (21 out of 30). The Elbow method is pretty far from the others,
    at only 13% (4 out of 30).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Calinski-Harabasz和BIC在97%的情况下（30个数据集中的29个）是正确的，这相当令人印象深刻。Silhouette在73%的时间（30个数据集中的22个）是正确的，而Davies-Bouldin在70%的情况下（30个数据集中的21个）是正确的。肘部法则则远远落后，只有13%（30个数据集中的4个）。
- en: Conclusions
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we have seen that, despite its popularity, **the Elbow method
    is pretty much the worst choice one can do when setting the number of clusters
    for a dataset**. Indeed, all the four alternatives that we tested did much better
    than the Elbow method. In particular, Calinski-Harabasz and BIC performed extremely
    well, with only one mistake out of 30 datasets.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们看到，尽管它很受欢迎，**肘部法则实际上是设置数据集聚类数量时最差的选择**。事实上，我们测试的所有四种替代方法都比肘部法则表现得好得多。特别是，Calinski-Harabasz和BIC表现极为出色，在30个数据集中只有一个错误。
- en: You can find all the Python code used for this article in [this notebook](https://github.com/smazzanti/are_you_still_using_elbow_method/blob/main/are-you-still-using-elbow-method.ipynb).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这个笔记本](https://github.com/smazzanti/are_you_still_using_elbow_method/blob/main/are-you-still-using-elbow-method.ipynb)中找到本文使用的所有Python代码。
- en: '*Thank you for reading!*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢阅读！*'
- en: '*If you find my work useful, you can subscribe to* [***get an email every time
    that I publish a new article***](https://medium.com/@mazzanti.sam/subscribe) *(usually
    once a month).*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你觉得我的工作有用，你可以订阅* [***每次发布新文章时获取邮件通知***](https://medium.com/@mazzanti.sam/subscribe)
    *(通常是每月一次)。*'
- en: '*If you want to support my work, you can* [***buy me a coffee***](https://ko-fi.com/samuelemazzanti)*.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你想支持我的工作，你可以* [***请我喝杯咖啡***](https://ko-fi.com/samuelemazzanti)*。*'
- en: '*If you’d like,* [***add me on Linkedin***](https://www.linkedin.com/in/samuelemazzanti/)*!*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你愿意，* [***在Linkedin上添加我***](https://www.linkedin.com/in/samuelemazzanti/)*！*'
