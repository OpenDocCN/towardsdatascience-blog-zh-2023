- en: 'Meet Gemini: Google’s Largest and Most Powerful AI Model'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认识 Gemini：谷歌最大、最强大的 AI 模型
- en: 原文：[https://towardsdatascience.com/meet-gemini-googles-largest-and-most-powerful-ai-model-2ffd2f07490f](https://towardsdatascience.com/meet-gemini-googles-largest-and-most-powerful-ai-model-2ffd2f07490f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/meet-gemini-googles-largest-and-most-powerful-ai-model-2ffd2f07490f](https://towardsdatascience.com/meet-gemini-googles-largest-and-most-powerful-ai-model-2ffd2f07490f)
- en: This next-gen AI model outperformed ChatGPT on almost all academic benchmarks.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这个下一代 AI 模型在几乎所有学术基准测试中超过了 ChatGPT。
- en: '[](https://natassha6789.medium.com/?source=post_page-----2ffd2f07490f--------------------------------)[![Natassha
    Selvaraj](../Images/adea0c904ea1a62e8961d82e4d0dd643.png)](https://natassha6789.medium.com/?source=post_page-----2ffd2f07490f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ffd2f07490f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ffd2f07490f--------------------------------)
    [Natassha Selvaraj](https://natassha6789.medium.com/?source=post_page-----2ffd2f07490f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://natassha6789.medium.com/?source=post_page-----2ffd2f07490f--------------------------------)[![Natassha
    Selvaraj](../Images/adea0c904ea1a62e8961d82e4d0dd643.png)](https://natassha6789.medium.com/?source=post_page-----2ffd2f07490f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ffd2f07490f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ffd2f07490f--------------------------------)
    [Natassha Selvaraj](https://natassha6789.medium.com/?source=post_page-----2ffd2f07490f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ffd2f07490f--------------------------------)
    ·6 min read·Dec 9, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ffd2f07490f--------------------------------)
    ·6 分钟阅读·2023年12月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/4c9beca1db4c3e59c67d1b0bb75d5e28.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c9beca1db4c3e59c67d1b0bb75d5e28.png)'
- en: Photo by [Mitchell Luo](https://unsplash.com/@mitchel3uo?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/google-logo-neon-light-signage-jz4ca36oJ_M?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Mitchell Luo](https://unsplash.com/@mitchel3uo?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    拍摄，来源于 [Unsplash](https://unsplash.com/photos/google-logo-neon-light-signage-jz4ca36oJ_M?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: When OpenAI released ChatGPT last November, there was a pressing question on
    everyone’s minds — what are the tech giants doing?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当 OpenAI 去年11月发布 ChatGPT 时，每个人心中都有一个迫切的问题——科技巨头们在做什么？
- en: When will companies like Google respond to this development?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 像谷歌这样的公司会何时回应这一发展？
- en: We now have our answer.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了答案。
- en: 'On December 6, 2023, Google announced their latest AI model: Gemini.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年12月6日，谷歌宣布了他们最新的 AI 模型：Gemini。
- en: According to the company’s CEO Sundar Pichai, this technology is a huge leap
    forward in artificial intelligence, and will affect virtually all of Google’s
    products.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 根据公司首席执行官 Sundar Pichai 的说法，这项技术是人工智能的巨大飞跃，将影响几乎所有谷歌的产品。
- en: Gemini comes in 3 sizes
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gemini 提供 3 种尺寸
- en: The current version of the model is called Gemini 1.0\. It can work with text,
    images, videos, and audio, and comes in 3 different sizes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当前版本的模型称为 Gemini 1.0。它可以处理文本、图像、视频和音频，并且有 3 种不同的尺寸。
- en: '**Gemini Nano** is a small, more efficient version that can be run natively
    and on Android devices.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**Gemini Nano** 是一个小型、高效的版本，可以在原生环境和 Android 设备上运行。'
- en: '**Gemini Pro**, the middle tier version, strikes a balance between between
    capability and efficiency. This model performs significantly better than Google’s
    previous flagship model, PaLM-2\. It currently powers the Bard chatbot.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**Gemini Pro**，中级版本，在能力和效率之间取得了平衡。这个模型的表现比谷歌之前的旗舰模型 PaLM-2 好得多。目前它为 Bard 聊天机器人提供支持。'
- en: Finally, **Gemini Ultra** is the most powerful model in the series. It excels
    at complex reasoning, and has outperformed OpenAI’s GPT-4 model on various benchmarks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，**Gemini Ultra** 是系列中最强大的模型。它在复杂推理方面表现出色，并且在各种基准测试中超越了 OpenAI 的 GPT-4 模型。
- en: Gemini Ultra hasn’t been made publicly available just yet. Google has announced
    that the model will be launched early next year, although no specific time-frame
    has been provided.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini Ultra 尚未公开发布。谷歌宣布该模型将在明年初推出，尽管没有提供具体的时间框架。
- en: How does Gemini differ from OpenAI’s GPT Models?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gemini 与 OpenAI 的 GPT 模型有何不同？
- en: OpenAI’s ChatGPT is currently powered by 2 AI models — GPT-3.5 for the free
    version and GPT-4 for the paid version.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 的 ChatGPT 目前由 2 个 AI 模型提供支持——免费版的 GPT-3.5 和付费版的 GPT-4。
- en: A few months ago, OpenAI announced that GPT-4 had multimodal capabilities (i.e.
    it was able to [process text, audio, and images](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak)).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 几个月前，OpenAI 宣布 GPT-4 具有多模态能力（即能够 [处理文本、音频和图像](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak)）。
- en: However, although it can process various data types, the model’s primary design
    and functionality is focused on **text-based inputs and outputs**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管它可以处理各种数据类型，模型的主要设计和功能仍然集中在 **基于文本的输入和输出** 上。
- en: This means that GPT-4 is a text-based framework, and vision and audio processing
    models are built on top of it as a secondary stage.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这意味着 GPT-4 是一个基于文本的框架，视觉和音频处理模型在其基础上作为第二阶段构建。
- en: 'For instance, combining **GPT-4** with an image generation model like **DALLE-3**
    allows you to translate text into an image that looks like this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，将 **GPT-4** 与图像生成模型 **DALLE-3** 结合，可以将文本转换为如下所示的图像：
- en: '![](../Images/d6978ba99da710593480d920255bb0c3.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6978ba99da710593480d920255bb0c3.png)'
- en: While GPT-4’s training for processing other modalities is separate from its
    text-based training, Gemini is trained on a diverse dataset of text, images, videos,
    and audio from the start.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 GPT-4 在处理其他模态的训练与其基于文本的训练是分开的，但 Gemini 从一开始就接受了文本、图像、视频和音频的多样化数据集训练。
- en: In simple terms, **multimodal capabilities are built into Gemini** from the
    ground up, to ensure that it natively understands all data types.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，**多模态能力是从基础上构建到 Gemini 中的**，以确保它能原生理解所有数据类型。
- en: This architectural difference means that Gemini is able to generalize more easily,
    as it understands information from text, images, audio and video.
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这种架构差异意味着 Gemini 更容易进行泛化，因为它理解来自文本、图像、音频和视频的信息。
- en: Models like GPT-4 and DALLE-3, on the other hand, are fine-tuned for **specific
    tasks** (GPT-4 for text, DALLE-3 for images).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 像 GPT-4 和 DALLE-3 这样的模型，则针对 **特定任务** 进行了微调（GPT-4 针对文本，DALLE-3 针对图像）。
- en: 'In Google Deepmind’s research paper on Gemini, the following question is posed:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Deepmind 关于 Gemini 的研究论文中，提出了以下问题：
- en: One open question is whether this joint training can result in a model which
    has strong capabilities in each domain — even when compared to models and approaches
    that are narrowly tailored to single domains.
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个未解的问题是，这种联合训练是否能产生一个在每个领域都有强大能力的模型——即使与针对单一领域的模型和方法相比。
- en: 'This question addresses a fundamental challenge in the field of AI: the tradeoff
    between specialized and generalized models.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题涉及 AI 领域中的一个基本挑战：专业化模型与通用模型之间的权衡。
- en: Models that are designed for a single domain usually perform better for that
    specific task, as compared to a model developed through joint training.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 针对单一领域设计的模型通常在该特定任务上的表现更好，相比之下，通过联合训练开发的模型可能表现较差。
- en: Let’s now compare Gemini’s performance against state-of-the-art models that
    have been tailored to specific domains.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将 Gemini 的表现与专门针对特定领域的最先进模型进行比较。
- en: Gemini outperforms ChatGPT in almost all benchmarks
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gemini 在几乎所有基准测试中都超过了 ChatGPT
- en: In Google Deepmind’s latest [report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
    on Gemini, the model’s performance is evaluated against other algorithms like
    Claude 2, PaLM-2, GPT-3.5, and GPT-4.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Deepmind 最新的 [报告](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
    中，模型的性能与其他算法如 Claude 2、PaLM-2、GPT-3.5 和 GPT-4 进行了比较。
- en: 'Here’s how Gemini fares against the best models in various domains:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 Gemini 在各个领域与最佳模型的对比：
- en: Text
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本
- en: 'Gemini’s performance on text benchmarks against existing models:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini 在文本基准测试中的表现与现有模型的对比：
- en: '![](../Images/14357c9ccd0e41831ef95cca25f2cf60.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14357c9ccd0e41831ef95cca25f2cf60.png)'
- en: Image from [Deepmind’s technical report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Deepmind 的技术报告](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
- en: In a number of text-based benchmarks that cover reasoning abilities, reading
    comprehension, STEM, and coding, notice that Gemini Ultra outperforms OpenAI’s
    GPT-4 model in 8 out of 9 assessments.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在涵盖推理能力、阅读理解、STEM 和编码的多个基于文本的基准测试中，注意到 Gemini Ultra 在 9 个评估中的 8 个中优于 OpenAI
    的 GPT-4 模型。
- en: According to the Google Deepmind report, the model performed best when a technique
    called “**chain-of-thought**” prompting was used.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Google Deepmind 的报告，当使用一种名为“**链式思维**”的提示技术时，模型表现最佳。
- en: In chain-of-thought prompting, you break down a problem and guide AI through
    a step-by-step reasoning process, similar to the way a human figures things out.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在思维链提示中，你将一个问题分解，并引导AI通过逐步推理的过程，类似于人类解决问题的方式。
- en: This tends to be more effective than simply throwing an entire question at an
    AI model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常比单纯地将整个问题抛给AI模型更有效。
- en: You can read [this](https://www.promptingguide.ai/techniques/cot) guide to learn
    more about chain-of-thought prompting.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以阅读[这个](https://www.promptingguide.ai/techniques/cot)指南，了解更多关于思维链提示的信息。
- en: Also, notice how **Gemini Pro** (the middle-tier version), which currently powers
    Bard, appears to surpass GPT-3.5 in almost every benchmark.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请注意**Gemini Pro**（中档版本），目前为Bard提供支持，在几乎所有基准测试中都超越了GPT-3.5。
- en: I have been experimenting with Gemini Pro ever since its release, and personally,
    find its responses to be on par with that of GPT-3.5.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 自Gemini Pro发布以来，我一直在进行实验，个人认为它的响应与GPT-3.5相当。
- en: I plan to perform a more detailed comparison between their reasoning and coding
    capabilities, and will publish a follow-up article soon.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我计划对它们的推理和编码能力进行更详细的比较，并会尽快发布后续文章。
- en: Image Understanding
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像理解
- en: 'Even without prior training on specific tasks, Gemini Ultra’s vision capabilities
    surpassed other models that were fine-tuned for those benchmarks:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在特定任务上没有先前的训练，Gemini Ultra的视觉能力仍然超过了那些为这些基准测试进行了微调的其他模型：
- en: '![](../Images/7bba453c75a96927269895677efe3d79.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7bba453c75a96927269895677efe3d79.png)'
- en: Image from [Deepmind’s technical report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 来源于[Deepmind的技术报告](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)
- en: The first benchmark, [MMMU](https://mmmu-benchmark.github.io/), consists of
    college-level questions across 6 disciplines — business, science, humanities,
    art, tech, and medicine.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个基准测试，[MMMU](https://mmmu-benchmark.github.io/)，包含了6个学科的大学级问题——商业、科学、人文学科、艺术、技术和医学。
- en: Not only does this benchmark demand strong reasoning skills and college-level
    expertise, but the questions are also **uniquely based on images**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基准不仅要求强大的推理能力和大学级的专业知识，而且问题也**独特地基于图像**。
- en: Answering these questions accurately isn’t easy since the model must do two
    things —interpret visual elements and perform complex textual analysis.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 准确回答这些问题并不容易，因为模型必须做两件事——解释视觉元素和进行复杂的文本分析。
- en: Gemini Ultra surpassed all other AI models in this benchmark, highlighting its
    strong multimodal capabilities and the ability to generalize.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini Ultra在这个基准测试中超过了所有其他AI模型，突显了其强大的多模态能力和泛化能力。
- en: Video Understanding
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频理解
- en: Gemini Ultra also achieved state-of-the-art performance in video-related tasks
    — it was able to **add captions** and **answer questions based on videos**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini Ultra在视频相关任务中也达到了最先进的性能——它能够**添加字幕**和**根据视频回答问题**。
- en: For example, given [this](https://www.youtube.com/watch?v=VmWxjmJ3mvs) video
    of a person playing soccer, the model was asked to provide recommendations as
    to how the player could improve their technique.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，给定[这个](https://www.youtube.com/watch?v=VmWxjmJ3mvs)足球比赛视频，该模型被要求提供有关如何提高球员技术的建议。
- en: 'Here is Gemini’s response upon analyzing the video:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Gemini在分析视频后的回应：
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Similarly, Gemini Ultra demonstrated exceptional performance in image generation
    and audio understanding tasks. You can read the complete report [here](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Gemini Ultra在图像生成和音频理解任务中表现出了卓越的性能。你可以在[这里](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)阅读完整报告。
- en: While the model’s performance seems promising on academic benchmarks, keep in
    mind that a 4–5% improvement in a research environment may not necessarily make
    any real-world impact.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管该模型在学术基准测试中的表现看起来很有前景，但请记住，在研究环境中4-5%的改进可能未必会对现实世界产生实际影响。
- en: In my opinion, integrating AI models into other applications and productizing
    them for specific use-cases (like automated data analysis or enhanced search capabilities)
    is going to have a larger impact than a marginal performance improvement.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，将AI模型整合到其他应用程序中并为特定用例（如自动化数据分析或增强搜索能力）进行产品化，将比性能的边际改进产生更大的影响。
- en: I’m looking forward to see how Google is going to integrate this new model into
    its suite of products, especially Google Analytics, to generate more advanced
    insights and predictions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我期待看到Google如何将这个新模型整合到其产品套件中，特别是Google Analytics，以生成更先进的见解和预测。
- en: My biggest takeaway from the paper on Gemini is that a model built with multimodality
    at its core can surpass algorithms designed for specific tasks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我从关于Gemini的论文中得到的最大收获是，一个以多模态为核心构建的模型可以超越专为特定任务设计的算法。
- en: This approach could be a significant step towards achieving **artificial general
    intelligence** (AGI), where the goal is to build an AI model that can apply its
    intelligence to a broad range of tasks.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能是实现**人工通用智能**（AGI）的重要一步，其目标是建立一个可以应用于广泛任务的AI模型。
- en: Here’s how you can get started with Gemini
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下面是如何开始使用Gemini的方法。
- en: As mentioned earlier in this article, you can start using Gemini Pro today by
    accessing the [Bard chatbot](https://bard.google.com/chat).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本文前面提到的，你可以通过访问[Bard聊天机器人](https://bard.google.com/chat)今天开始使用Gemini Pro。
- en: Google has also announced that Gemini Nano (the lightest version) will soon
    be [integrated into Pixel smartphones](https://store.google.com/intl/en/ideas/articles/pixel-feature-drop-december-2023/),
    starting with the Pixel 8 Pro.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌还宣布，Gemini Nano（最轻版本）将很快被[集成到Pixel智能手机](https://store.google.com/intl/en/ideas/articles/pixel-feature-drop-december-2023/)中，从Pixel
    8 Pro开始。
- en: This will allow you to create automated summaries of conversations using the
    Recorder app, and generate high-quality response suggestions on WhatsApp.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这将允许你使用Recorder应用创建对话的自动总结，并在WhatsApp上生成高质量的回复建议。
- en: Finally, Gemini will be made available to developers on December 13th, through
    Google Generative AI Studio. You can also sign up to this live session by Google
    on how you can start [building applications using Gemini](https://www.googlecloudcommunity.com/gc/Cloud-Events/Building-Transformative-Applications-with-Gemini-on-Google-Cloud/ec-p/677873#M437)
    on Google Cloud.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Gemini将于12月13日通过Google Generative AI Studio向开发者开放。你还可以注册谷歌的实时讲座，了解如何在Google
    Cloud上[使用Gemini构建应用程序](https://www.googlecloudcommunity.com/gc/Cloud-Events/Building-Transformative-Applications-with-Gemini-on-Google-Cloud/ec-p/677873#M437)。
