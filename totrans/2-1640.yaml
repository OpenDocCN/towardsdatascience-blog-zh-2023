- en: 'PCA/LDA/ICA : a components analysis algorithms comparison'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PCA/LDA/ICA：组件分析算法比较
- en: 原文：[https://towardsdatascience.com/pca-lda-ica-a-components-analysis-algorithms-comparison-c5762c4148ff](https://towardsdatascience.com/pca-lda-ica-a-components-analysis-algorithms-comparison-c5762c4148ff)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pca-lda-ica-a-components-analysis-algorithms-comparison-c5762c4148ff](https://towardsdatascience.com/pca-lda-ica-a-components-analysis-algorithms-comparison-c5762c4148ff)
- en: Review the concepts and differences between these famous algorithms
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回顾这些著名算法的概念和差异
- en: '[](https://mocquin.medium.com/?source=post_page-----c5762c4148ff--------------------------------)[![Yoann
    Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----c5762c4148ff--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c5762c4148ff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c5762c4148ff--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----c5762c4148ff--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Yoann Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----c5762c4148ff--------------------------------)
    [![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c5762c4148ff--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----c5762c4148ff--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c5762c4148ff--------------------------------)
    ·8 min read·Feb 19, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----c5762c4148ff--------------------------------)
    ·8分钟阅读·2023年2月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Before diving and comparing the algorithms, let’s review them independently.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入比较算法之前，让我们先独立回顾一下它们。
- en: '*Note that is article does not aim at explaining each algorithm in depth, but
    rather compare their goals and results.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意，本文章并不旨在深入解释每个算法，而是比较它们的目标和结果。*'
- en: 'If you want to know more about the difference between PCA and ZCA, check out
    my previous post based on numpy :'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于PCA和ZCA的区别，请查看我之前基于numpy的文章：
- en: '[](/pca-whitening-vs-zca-whitening-a-numpy-2d-visual-518b32033edf?source=post_page-----c5762c4148ff--------------------------------)
    [## PCA-whitening vs ZCA-whitening : a numpy 2d visual'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[## PCA-whitening vs ZCA-whitening：一个numpy 2D可视化'
- en: The process of whitening data consists in a transformation such that the transformed
    data has identity matrix as…
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据白化的过程包括一种变换，使得变换后的数据具有单位矩阵作为…
- en: towardsdatascience.com](/pca-whitening-vs-zca-whitening-a-numpy-2d-visual-518b32033edf?source=post_page-----c5762c4148ff--------------------------------)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/pca-whitening-vs-zca-whitening-a-numpy-2d-visual-518b32033edf?source=post_page-----c5762c4148ff--------------------------------)'
- en: 'PCA : Principal Component Analysis'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PCA：主成分分析
- en: PCA is an unsupervised linear dimensionality reduction technique that aims to
    find a new set of orthogonal variables that captures the most important sources
    of variability in the data.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PCA是一种无监督的线性降维技术，旨在找到一组新的正交变量，这些变量捕捉数据中最重要的变异来源。
- en: It is widely used for feature extraction and data compression, and can be used
    for exploratory data analysis or as a preprocessing step for machine learning
    algorithms.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它广泛用于特征提取和数据压缩，并且可以用于探索性数据分析或作为机器学习算法的预处理步骤。
- en: The resulting components are ranked by the amount of variance they explain,
    and can be used to visualize and interpret the data, as well as for clustering
    or classification tasks.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的组件根据它们解释的方差量进行排名，可以用来可视化和解释数据，以及用于聚类或分类任务。
- en: 'LDA : Linear Discriminant Analysis'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LDA：线性判别分析
- en: LDA is a supervised linear dimensionality reduction technique that aims to find
    a new set of variables that maximizes the separation between classes while minimizing
    the variation within each class.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LDA是一种监督式线性降维技术，旨在找到一组新的变量，这些变量最大限度地提高类之间的分离，同时最小化每个类内的变化。
- en: It is widely used for feature extraction and classification, and can be used
    to reduce the dimensionality of the data while preserving the discriminative information
    between classes.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PCA广泛用于特征提取和分类，并且可以在保留类间判别信息的同时减少数据的维度。
- en: The resulting components are ranked by their discriminative power, and can be
    used to visualize and interpret the data, as well as for classification or regression
    tasks.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果组件按其区分能力排序，可以用来可视化和解释数据，以及进行分类或回归任务。
- en: 'ICA : Independent Component Analysis'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ICA：独立成分分析
- en: ICA is an unsupervised linear dimensionality reduction technique that aims to
    find a new set of variables that are statistically independent and non-Gaussian.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICA 是一种无监督的线性降维技术，旨在找到一组统计上独立且非高斯的变量。
- en: It is widely used for signal processing and source separation, and can be used
    to extract underlying sources of variability in the data that are not accessible
    through other techniques.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它广泛用于信号处理和源分离，可以用来提取数据中其他技术无法访问的潜在变异源。
- en: The resulting components are ranked by their independence, and can be used to
    visualize and interpret the data, as well as for clustering or classification
    tasks.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果组件按其独立性排序，可以用来可视化和解释数据，以及进行聚类或分类任务。
- en: Results on the iris dataset
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 鸢尾花数据集的结果
- en: 'Let’s compare their results on the famous iris dataset using sklearn. First
    let’s plot the iris dataset using a pairplot on each of the 4 numerical features,
    and color as the categorical feature :'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 sklearn 比较它们在著名的鸢尾花数据集上的结果。首先，使用每个 4 个数值特征的 pairplot 绘制鸢尾花数据集，并将颜色作为类别特征：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/e21a5a91b7240a59fc855aecd97a9f20.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e21a5a91b7240a59fc855aecd97a9f20.png)'
- en: 'Image by author : the iris dataset pairplot'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：鸢尾花数据集的 pairplot
- en: We can now compute each transformation and plot the results. Notice we use only
    2 components, since LDA requires at most (N-1) components where N is the number
    of categories (here equal to 3 since there are 3 types of iris flowers).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算每个变换并绘制结果。注意我们只使用了 2 个组件，因为 LDA 最多需要 (N-1) 个组件，其中 N 是类别的数量（这里等于 3，因为有
    3 种鸢尾花类型）。
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code loads the Iris dataset, applies LDA, PCA, and ICA with 2 components
    each, and then plots the results using different colors for each class.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码加载了鸢尾花数据集，应用了 LDA、PCA 和 ICA，每种方法使用 2 个组件，然后使用不同的颜色绘制每个类别的结果。
- en: Notice that it is generally a good practice to standardize the data before applying
    PCA, ICA, or LDA. Standardization is important because these techniques are sensitive
    to the scale of the input features. Standardizing the data ensures that each feature
    has a mean of zero and a standard deviation of one, which puts all the features
    on the same scale and avoids one feature dominating over the others.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，通常在应用 PCA、ICA 或 LDA 之前对数据进行标准化是一个好习惯。标准化很重要，因为这些技术对输入特征的尺度很敏感。标准化数据可以确保每个特征具有零均值和单位标准差，这使所有特征处于相同的尺度上，避免了某一特征对其他特征的支配。
- en: Since LDA is a supervised dimensionality reduction technique, it takes class
    labels as input. In contrast, PCA and ICA are unsupervised techniques, meaning
    that they only use the input data and do not take class labels into account.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 LDA 是一种有监督的降维技术，它以类别标签作为输入。相比之下，PCA 和 ICA 是无监督的技术，这意味着它们仅使用输入数据而不考虑类别标签。
- en: The results of LDA can be interpreted as a projection of the data onto a space
    that maximizes class separation, whereas the results of PCA and ICA can be interpreted
    as a projection of the data onto a space that captures the most important sources
    of variability or independence, respectively.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LDA 的结果可以解释为将数据投影到一个最大化类别分离的空间，而 PCA 和 ICA 的结果可以解释为将数据投影到一个分别捕捉最重要的变异源或独立源的空间。
- en: '![](../Images/5c694162272d0a7c305fdff2a639d80b.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c694162272d0a7c305fdff2a639d80b.png)'
- en: 'Image by author : Comparison of LDA, PCA and ICA on iris dataset'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：LDA、PCA 和 ICA 在鸢尾花数据集上的比较
- en: 'Notice that ICA still shows separation between the category, althought not
    its purpose : that’s because the categories are already quite sorted in the input
    dataset.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，尽管 ICA 的目的不是分离类别，但它仍然显示了类别之间的分离：这是因为类别在输入数据集中已经相当有序。
- en: Let’s put the LDA aside and focus on the differences between PCA and ICA- since
    LDA is a supervised technique, focuses on separating categories and enforces a
    maximum of component, while PCA and ICA focus on creating a new matrix with the
    same shape as the input matrix.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时放下 LDA，关注 PCA 和 ICA 之间的区别——因为 LDA 是一种有监督的技术，专注于分离类别并强制最大组件数量，而 PCA 和 ICA
    侧重于创建一个与输入矩阵形状相同的新矩阵。
- en: 'Let’s see the ouputs for 4 components, both for PCA and ICA :'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看 PCA 和 ICA 的 4 个组件的输出：
- en: '![](../Images/f8ebe69b93f0e70c3343ba2e7e8c2e2b.png)![](../Images/662ce9b0c5d9e375135f26d2ce21867b.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8ebe69b93f0e70c3343ba2e7e8c2e2b.png)![](../Images/662ce9b0c5d9e375135f26d2ce21867b.png)'
- en: 'Left : pairplot of PCA / Right : pairplot of ICA (images by author)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 左：PCA的配对图 / 右：ICA的配对图（图片由作者提供）
- en: 'Let’s also compare the correlation matrix for each transformed data : notice
    that both methods result in uncorrelated vectors (in other words, the transformed
    data features are orthogonal). That is because it’s a constraint in the PCA algorithm
    — each new vector must be orthogonal to the previous ones-, and a consequence
    of the ICA algorithm — which implies that the original dataset are independent
    signals that have been mixed together and must be reconstructed.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以比较每个转换数据的相关性矩阵：注意到两种方法都产生了不相关的向量（换句话说，转换后的数据特征是正交的）。这是因为这是PCA算法中的一个约束——每个新向量必须正交于之前的向量——而ICA算法的一个结果——这意味着原始数据集是混合在一起的独立信号，必须被重构。
- en: '![](../Images/9fa1ad50c63f0f26fc02699da4374e2d.png)![](../Images/febab233a24837aac0ef85e4019273a9.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9fa1ad50c63f0f26fc02699da4374e2d.png)![](../Images/febab233a24837aac0ef85e4019273a9.png)'
- en: 'Left : correlation heatmap of ICA / Right : correlation heatmap of PCA (images
    by author)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 左：ICA的相关性热图 / 右：PCA的相关性热图（图片由作者提供）
- en: 'So PCA and ICA seem to give results with similar properties : that is because
    of the 2 following reasons :'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 所以PCA和ICA似乎给出了具有类似属性的结果：这是由于以下两个原因：
- en: the independance is “encoded” in both algorithms
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立性在这两种算法中都“编码”了
- en: the iris dataset exhibits well separeted classes
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鸢尾花数据集展示了良好的类分离
- en: That’s why we need another example, more fitted for the ICA.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我们需要另一个例子，更适合ICA的原因。
- en: 'Another example :'
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另一个例子：
- en: 'Let’s see another example : we first generate a synthetic dataset with two
    independent sources, a sine wave and a square wave, which are mixed together as
    a linear combination to create a mixed signal.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个例子：我们首先生成一个合成数据集，其中包含两个独立的源，一个正弦波和一个方波，它们被线性组合在一起以创建一个混合信号。
- en: 'The actual, true, independant signals are the following :'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的、真正的、独立的信号如下：
- en: '![](../Images/2b946d7257636cf8e299e1725cf74bb3.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b946d7257636cf8e299e1725cf74bb3.png)'
- en: 'They are mixed together, as 2 linear combinations :'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 它们被线性组合在一起，作为2个线性组合：
- en: '![](../Images/0dcdd153cb87196744e755c93a376e03.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dcdd153cb87196744e755c93a376e03.png)'
- en: 'Let’s see how PCA and ICA perform on this new dataset :'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看PCA和ICA在这个新数据集上的表现：
- en: '![](../Images/8210745ad64f961a94995c7923ebaf0d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8210745ad64f961a94995c7923ebaf0d.png)'
- en: 'Notice how PCA created a new component that exhibits a lot of variance, as
    a linear combination of the inputs, but that absolutely does not match the original
    data : that’s indeed not the purpose of PCA.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 注意PCA如何创建了一个新的组件，它作为输入的线性组合展示了大量的方差，但这绝对不匹配原始数据：这确实不是PCA的目的。
- en: On the opposite, ICA performed very well in recovering the original dataset,
    independantly of variance composition.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，ICA在恢复原始数据集方面表现非常好，无论方差组成如何。
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'The PCA, LDA, and ICA algorithms might seem like a custom version of each other,
    but they really do not have the same purpose. To summup:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: PCA、LDA和ICA算法可能看起来像是彼此的定制版本，但它们的目的实际上并不相同。总结如下：
- en: PCA aims to create new components that hold the maximum variance of the input
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PCA旨在创建新的组件，这些组件包含输入数据的最大方差
- en: LDA aims to create new components that separate clusters based on a categorical
    feature
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LDA旨在创建基于类别特征分离簇的新组件
- en: ICA aims to retrieve original features that are mixed together in a linear combination
    in the input dataset
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICA旨在恢复在输入数据集中线性组合在一起的原始特征
- en: Hopefully, you understand better the differences between these algorithm and
    will be able to quickly identify the one you need in the future.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你能更好地理解这些算法之间的差异，并能够在未来快速识别你需要的算法。
- en: '**If you liked this story, make sure to follow me and help me reach my 100
    subscribers goal :)**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你喜欢这个故事，确保关注我并帮助我实现100个订阅者的目标 :)**'
- en: 'Check out some of my other stories below :'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 查看下面的一些其他故事：
- en: '[](/300-times-faster-resolution-of-finite-difference-method-using-numpy-de28cdade4e1?source=post_page-----c5762c4148ff--------------------------------)
    [## 300-times faster resolution of Finite-Difference Method using numpy'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/300-times-faster-resolution-of-finite-difference-method-using-numpy-de28cdade4e1?source=post_page-----c5762c4148ff--------------------------------)
    [## 使用numpy的有限差分法实现300倍更快的分辨率'
- en: Finite-difference method is a powerfull technique to solve complex problems,
    and numpy makes it fast !
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有限差分法是一种强大的技术来解决复杂问题，numpy使它变得快速！
- en: towardsdatascience.com](/300-times-faster-resolution-of-finite-difference-method-using-numpy-de28cdade4e1?source=post_page-----c5762c4148ff--------------------------------)
    [](/wrapping-numpys-arrays-971e015e14bb?source=post_page-----c5762c4148ff--------------------------------)
    [## Wrapping numpy’s arrays
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用 numpy 提升有限差分方法的分辨率 300 倍](https://medium.com/analytics-vidhya/deep-dive-into-seaborn-palettes-7b5fae5a258e?source=post_page-----c5762c4148ff--------------------------------)
    [](/wrapping-numpys-arrays-971e015e14bb?source=post_page-----c5762c4148ff--------------------------------)
    [## 使用 numpy 提升有限差分方法的分辨率 300 倍'
- en: The container approach.
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器方法。
- en: towardsdatascience.com](/wrapping-numpys-arrays-971e015e14bb?source=post_page-----c5762c4148ff--------------------------------)
    [](https://medium.com/analytics-vidhya/deep-dive-into-seaborn-palettes-7b5fae5a258e?source=post_page-----c5762c4148ff--------------------------------)
    [## Deep dive into seaborn palettes
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[深入了解 seaborn 调色板](https://medium.com/analytics-vidhya/deep-dive-into-seaborn-palettes-7b5fae5a258e?source=post_page-----c5762c4148ff--------------------------------)
    [](https://medium.com/analytics-vidhya/deep-dive-into-seaborn-palettes-7b5fae5a258e?source=post_page-----c5762c4148ff--------------------------------)
    [## 深入了解 seaborn 调色板'
- en: Drowning in seaborn palettes ?
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 被 seaborn 调色板淹没了吗？
- en: 'medium.com](https://medium.com/analytics-vidhya/deep-dive-into-seaborn-palettes-7b5fae5a258e?source=post_page-----c5762c4148ff--------------------------------)
    [](/pca-whitening-vs-zca-whitening-a-numpy-2d-visual-518b32033edf?source=post_page-----c5762c4148ff--------------------------------)
    [## PCA-whitening vs ZCA-whitening : a numpy 2d visual'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[PCA-whitening 与 ZCA-whitening：一个 numpy 2d 可视化](https://medium.com/analytics-vidhya/deep-dive-into-seaborn-palettes-7b5fae5a258e?source=post_page-----c5762c4148ff--------------------------------)
    [](/pca-whitening-vs-zca-whitening-a-numpy-2d-visual-518b32033edf?source=post_page-----c5762c4148ff--------------------------------)
    [## PCA-whitening 与 ZCA-whitening：一个 numpy 2d 可视化'
- en: The process of whitening data consists in a transformation such that the transformed
    data has identity matrix as…
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据白化的过程包括一种变换，使得变换后的数据具有单位矩阵作为…
- en: towardsdatascience.com](/pca-whitening-vs-zca-whitening-a-numpy-2d-visual-518b32033edf?source=post_page-----c5762c4148ff--------------------------------)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[包裹 numpy 的数组](https://medium.com/analytics-vidhya/deep-dive-into-seaborn-palettes-7b5fae5a258e?source=post_page-----c5762c4148ff--------------------------------)
    [](/wrapping-numpys-arrays-971e015e14bb?source=post_page-----c5762c4148ff--------------------------------)
    [## 包裹 numpy 的数组'
