- en: How to Measure the Carbon Footprint using Python and Vertex AI Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ç”¨Pythonå’ŒVertex AI Pipelinesæµ‹é‡ç¢³è¶³è¿¹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-mesure-the-carbon-footprint-using-vertex-ai-pipelines-3d6bc9695e7b](https://towardsdatascience.com/how-to-mesure-the-carbon-footprint-using-vertex-ai-pipelines-3d6bc9695e7b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-mesure-the-carbon-footprint-using-vertex-ai-pipelines-3d6bc9695e7b](https://towardsdatascience.com/how-to-mesure-the-carbon-footprint-using-vertex-ai-pipelines-3d6bc9695e7b)
- en: A step-by-step guide on tracking carbon emissions using Vertex AI Pipelines
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºä½¿ç”¨Vertex AI Pipelinesè·Ÿè¸ªç¢³æ’æ”¾çš„é€æ­¥æŒ‡å—
- en: '[](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)
    Â·9 min readÂ·Jan 31, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3d6bc9695e7b--------------------------------)
    Â·9åˆ†é’Ÿé˜…è¯»Â·2023å¹´1æœˆ31æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6f604577434a098bfe1758e826444eb3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f604577434a098bfe1758e826444eb3.png)'
- en: image generated by the Author with Midjourney.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…ä½¿ç”¨Midjourneyç”Ÿæˆã€‚
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠ¨æœº
- en: Machine learning has become a regular part of our daily lives, therefore it
    is time to consider its potential impacts on the environment. Otherwise, Mother
    Nature might just give us an â€˜*I told you soâ€™* in the form of natural disasters
    leading to severe human suffering. One way we can help combat climate change is
    by starting to measure and reduce the carbon footprint of our machine-learning
    models. The carbon footprint measures the total greenhouse gas emissions caused
    by services, products, persons, organizations, or events. In the case of machine
    learning, it includes the energy required to train and run models, as well as
    the energy used by the hardware on which theyâ€™re running.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·²ç»æˆä¸ºæˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»çš„ä¸€éƒ¨åˆ†ï¼Œå› æ­¤æ˜¯æ—¶å€™è€ƒè™‘å®ƒå¯¹ç¯å¢ƒçš„æ½œåœ¨å½±å“äº†ã€‚å¦åˆ™ï¼Œå¤§è‡ªç„¶å¯èƒ½ä¼šä»¥è‡ªç„¶ç¾å®³çš„å½¢å¼ç»™æˆ‘ä»¬ä¸€ä¸ªâ€˜*æˆ‘æ—©å°±è¯´è¿‡äº†*â€™çš„æ•™è®­ï¼Œå¯¼è‡´ä¸¥é‡çš„äººç±»ç—›è‹¦ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å¼€å§‹æµ‹é‡å’Œå‡å°‘æœºå™¨å­¦ä¹ æ¨¡å‹çš„ç¢³è¶³è¿¹æ¥å¸®åŠ©åº”å¯¹æ°”å€™å˜åŒ–ã€‚ç¢³è¶³è¿¹è¡¡é‡çš„æ˜¯æœåŠ¡ã€äº§å“ã€ä¸ªäººã€ç»„ç»‡æˆ–äº‹ä»¶é€ æˆçš„æ¸©å®¤æ°”ä½“æ’æ”¾æ€»é‡ã€‚åœ¨æœºå™¨å­¦ä¹ çš„æƒ…å†µä¸‹ï¼Œå®ƒåŒ…æ‹¬è®­ç»ƒå’Œè¿è¡Œæ¨¡å‹æ‰€éœ€çš„èƒ½æºï¼Œä»¥åŠè¿è¡Œè¿™äº›æ¨¡å‹çš„ç¡¬ä»¶æ‰€ç”¨çš„èƒ½æºã€‚
- en: In this article, I will provide feedback on two open-source Python libraries,
    [CodeCarbon](https://pypi.org/project/codecarbon/) and [CarbonTracker](https://github.com/lfwa/carbontracker),
    which are able to estimate the carbon footprint. I will also include a step-by-step
    guide for using them in Vertex AI pipelines. Lastly, I will list practical considerations
    for reducing the carbon footprint. So, letâ€™s start doing our part in saving the
    planet before itâ€™s too late! ğŸ’š
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å¯¹ä¸¤ä¸ªå¼€æºPythonåº“ [CodeCarbon](https://pypi.org/project/codecarbon/) å’Œ [CarbonTracker](https://github.com/lfwa/carbontracker)
    æä¾›åé¦ˆï¼Œå®ƒä»¬èƒ½å¤Ÿä¼°ç®—ç¢³è¶³è¿¹ã€‚æˆ‘è¿˜å°†åŒ…æ‹¬ä¸€ä¸ªåœ¨Vertex AIç®¡é“ä¸­ä½¿ç”¨å®ƒä»¬çš„é€æ­¥æŒ‡å—ã€‚æœ€åï¼Œæˆ‘å°†åˆ—å‡ºå‡å°‘ç¢³è¶³è¿¹çš„å®é™…è€ƒè™‘å› ç´ ã€‚æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬åœ¨ä¸ºæ—¶å·²æ™šä¹‹å‰å¼€å§‹ä¸ºæ‹¯æ•‘åœ°çƒè´¡çŒ®è‡ªå·±çš„åŠ›é‡å§ï¼ğŸ’š
- en: I. Carbon Footprint in Python ğŸ“—
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: I. Pythonä¸­çš„ç¢³è¶³è¿¹ ğŸ“—
- en: Two of the most popular libraries for measuring the carbon footprint in Python
    are [CodeCarbon](https://pypi.org/project/codecarbon/) and [CarbonTracker](https://github.com/lfwa/carbontracker).
    The truth is that we do not have many open-source alternatives. But I believe
    we will have more options available once the community begins to integrate carbon
    footprint into the machine learning systems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæµ‹é‡Pythonä¸­ç¢³è¶³è¿¹çš„ä¸¤ä¸ªæœ€æµè¡Œçš„åº“æ˜¯ [CodeCarbon](https://pypi.org/project/codecarbon/) å’Œ
    [CarbonTracker](https://github.com/lfwa/carbontracker)ã€‚äº‹å®æ˜¯æˆ‘ä»¬æ²¡æœ‰å¾ˆå¤šå¼€æºçš„æ›¿ä»£æ–¹æ¡ˆã€‚ä½†æˆ‘ç›¸ä¿¡ï¼Œä¸€æ—¦ç¤¾åŒºå¼€å§‹å°†ç¢³è¶³è¿¹é›†æˆåˆ°æœºå™¨å­¦ä¹ ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬å°†ä¼šæœ‰æ›´å¤šçš„é€‰æ‹©ã€‚
- en: Letâ€™s say a few words about the libraries.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å…ˆè¯´å‡ å¥å…³äºåº“çš„å†…å®¹ã€‚
- en: CodeCarbon
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CodeCarbon
- en: It is an open-source Python library that estimates the CO2 produced while running
    the code. The project was initiated by Yoshua Bengio. One of the things I appreciate
    most about it is that is very easy to use, has good documentation, and nice [Dashboard](https://dashboard.codecarbon.io/).
    The estimation is done by measuring the power consumption of the total GPUs, CPUs,
    and RAM. Then it applies the [regional carbon intensity of electricity](https://ourworldindata.org/grapher/carbon-intensity-electricity)
    of your [cloud](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/cloud/impact.csv)
    provider or [country](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/private_infra/eu-carbon-intensity-electricity.csv)
    if you are using a local machine or on-premise cluster. Refer to the table below
    to see the carbon intensity across various energy sources.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯ä¸€ä¸ªå¼€æºPythonåº“ï¼Œç”¨äºä¼°ç®—è¿è¡Œä»£ç æ—¶äº§ç”Ÿçš„CO2ã€‚è¯¥é¡¹ç›®ç”±Yoshua Bengioå‘èµ·ã€‚æˆ‘æœ€æ¬£èµçš„ä¸€ç‚¹æ˜¯å®ƒéå¸¸æ˜“äºä½¿ç”¨ï¼Œæ–‡æ¡£è‰¯å¥½ï¼Œå¹¶ä¸”æœ‰ä¸€ä¸ªå¾ˆæ£’çš„[ä»ªè¡¨ç›˜](https://dashboard.codecarbon.io/)ã€‚ä¼°ç®—é€šè¿‡æµ‹é‡æ€»GPUã€CPUå’ŒRAMçš„åŠŸè€—æ¥å®Œæˆã€‚ç„¶åï¼Œå®ƒåº”ç”¨æ‚¨çš„[äº‘](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/cloud/impact.csv)æä¾›å•†æˆ–[å›½å®¶](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/private_infra/eu-carbon-intensity-electricity.csv)çš„[åŒºåŸŸç¢³å¼ºåº¦](https://ourworldindata.org/grapher/carbon-intensity-electricity)ï¼Œå¦‚æœæ‚¨ä½¿ç”¨æœ¬åœ°è®¡ç®—æœºæˆ–æœ¬åœ°é›†ç¾¤ã€‚è¯·å‚è€ƒä¸‹è¡¨ä»¥æŸ¥çœ‹å„ç§èƒ½æºæ¥æºçš„ç¢³å¼ºåº¦ã€‚
- en: '![](../Images/e20e8c07b5ad541c58a06916294dd5b6.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e20e8c07b5ad541c58a06916294dd5b6.png)'
- en: '@[CodeCarbon](https://mlco2.github.io/codecarbon/methodology.html#) source'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '@[CodeCarbon](https://mlco2.github.io/codecarbon/methodology.html#) æ¥æº'
- en: 'The carbon dioxide emissions estimation (COâ‚‚eq) is calculated as below:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: äºŒæ°§åŒ–ç¢³æ’æ”¾ä¼°ç®—ï¼ˆCOâ‚‚eqï¼‰è®¡ç®—å¦‚ä¸‹ï¼š
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that CodeCarbon uses a world average of [**475 gCO2.eq/KWh**](https://www.iea.org/reports/global-energy-co2-status-report-2019/emissions)
    when the carbon intensity is not available. The emissions are saved into a CSV
    file named `emissions.csv.`
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå½“ç¢³å¼ºåº¦ä¸å¯ç”¨æ—¶ï¼ŒCodeCarbonä½¿ç”¨ä¸–ç•Œå¹³å‡å€¼[**475 gCO2.eq/KWh**](https://www.iea.org/reports/global-energy-co2-status-report-2019/emissions)ã€‚æ’æ”¾é‡è¢«ä¿å­˜åˆ°åä¸º`emissions.csv.`çš„CSVæ–‡ä»¶ä¸­ã€‚
- en: In terms of supported infrastructure, it is compatible with NVIDIA GPUs that
    support [NVIDIA Management Library (NVML](https://developer.nvidia.com/nvidia-management-library-nvml))
    and Intel CPUs that [support Intel RAPL](http://web.eece.maine.edu/~vweaver/projects/rapl/rapl_support.html)
    . If your CPU is not on the [list of supported CPUs](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/hardware/cpu_power.csv)
    then it will estimate the power consumption of the CPUs as 50% of their thermal
    design power(TDP) using a default TDP average of 85W.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ”¯æŒçš„åŸºç¡€è®¾æ–½æ–¹é¢ï¼Œå®ƒå…¼å®¹æ”¯æŒ[NVIDIAç®¡ç†åº“ï¼ˆNVMLï¼‰](https://developer.nvidia.com/nvidia-management-library-nvml)çš„NVIDIA
    GPUå’Œæ”¯æŒ[Intel RAPL](http://web.eece.maine.edu/~vweaver/projects/rapl/rapl_support.html)çš„Intel
    CPUã€‚å¦‚æœæ‚¨çš„CPUä¸åœ¨[æ”¯æŒçš„CPUåˆ—è¡¨](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/hardware/cpu_power.csv)ä¸Šï¼Œå®ƒå°†ä¼°ç®—CPUçš„åŠŸè€—ä¸ºå…¶çƒ­è®¾è®¡åŠŸè€—ï¼ˆTDPï¼‰çš„50%ï¼Œé»˜è®¤TDPå¹³å‡å€¼ä¸º85Wã€‚
- en: 'To install it use pip:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨pipå®‰è£…ï¼š
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'It supports two modes: `online mode` or `offline mode` .'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ”¯æŒä¸¤ç§æ¨¡å¼ï¼š`åœ¨çº¿æ¨¡å¼` æˆ– `ç¦»çº¿æ¨¡å¼`ã€‚
- en: '`The Online mode` needs an internet connection to retrieve your geographical
    location. See below an example of using it with or without a decorator:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`åœ¨çº¿æ¨¡å¼` éœ€è¦äº’è”ç½‘è¿æ¥æ¥è·å–æ‚¨çš„åœ°ç†ä½ç½®ã€‚è¯·å‚è§ä¸‹é¢ä½¿ç”¨å®ƒçš„ç¤ºä¾‹ï¼Œå¸¦æœ‰æˆ–ä¸å¸¦è£…é¥°å™¨ï¼š'
- en: '`The Offline mode` can be used when your setup doesnâ€™t have access to the internet.
    It requires specifying the 3-letter alphabet ISO Code of the country. You can
    find a list of country **ISO** codes on [Wikipedia](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`ç¦»çº¿æ¨¡å¼` å¯ä»¥åœ¨æ‚¨çš„è®¾ç½®æ— æ³•è®¿é—®äº’è”ç½‘æ—¶ä½¿ç”¨ã€‚å®ƒéœ€è¦æŒ‡å®šå›½å®¶çš„3ä¸ªå­—æ¯ISOä»£ç ã€‚æ‚¨å¯ä»¥åœ¨[ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes)ä¸Šæ‰¾åˆ°å›½å®¶**ISO**ä»£ç çš„åˆ—è¡¨ã€‚'
- en: CarbonTracker
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CarbonTracker
- en: '[CarbonTracker](https://arxiv.org/abs/2007.03051) is an open-source library
    aiming to estimate the carbon footprint of training a deep learning model by measuring
    the power consumption of the hardware used for training. Currently, it supports
    GPU, CPU, and DRAM components. It is compatible with NVIDIA GPUs that support
    [NVIDIA Management Library (NVML](https://developer.nvidia.com/nvidia-management-library-nvml),
    Intel CPUs that support [Intel RAP](http://web.eece.maine.edu/~vweaver/projects/rapl/rapl_support.html)L,
    Slurm, and Google Colab / Jupyter Notebook. It is easy to use but unfortunately,
    the documentation is limited.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[CarbonTracker](https://arxiv.org/abs/2007.03051) æ˜¯ä¸€ä¸ªå¼€æºåº“ï¼Œæ—¨åœ¨é€šè¿‡æµ‹é‡è®­ç»ƒæ‰€ç”¨ç¡¬ä»¶çš„åŠŸè€—æ¥ä¼°ç®—è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç¢³è¶³è¿¹ã€‚ç›®å‰ï¼Œå®ƒæ”¯æŒ
    GPUã€CPU å’Œ DRAM ç»„ä»¶ã€‚å®ƒä¸æ”¯æŒ[NVIDIA ç®¡ç†åº“ (NVML)](https://developer.nvidia.com/nvidia-management-library-nvml)çš„
    NVIDIA GPUã€æ”¯æŒ[Intel RAP](http://web.eece.maine.edu/~vweaver/projects/rapl/rapl_support.html)çš„
    Intel CPUã€Slurm å’Œ Google Colab / Jupyter Notebook å…¼å®¹ã€‚ä½¿ç”¨èµ·æ¥å¾ˆç®€å•ï¼Œä½†ä¸å¹¸çš„æ˜¯ï¼Œæ–‡æ¡£æœ‰é™ã€‚'
- en: 'To estimate the carbon footprint it uses the formula :'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¼°ç®—ç¢³è¶³è¿¹ï¼Œå®ƒä½¿ç”¨ä»¥ä¸‹å…¬å¼ï¼š
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `Energy Consumption`is computed based on PUE (Power Usage Effectiveness),
    a metric used to measure the energy efficiency of data centers. It is calculated
    by dividing the total amount of energy used by a data center by the energy used
    by the IT equipment (e.g. servers, storage, etc.).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`Energy Consumption` æ˜¯åŸºäº PUEï¼ˆåŠŸè€—ä½¿ç”¨æ•ˆç‡ï¼‰è®¡ç®—çš„ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè¡¡é‡æ•°æ®ä¸­å¿ƒèƒ½æºæ•ˆç‡çš„æŒ‡æ ‡ã€‚å®ƒé€šè¿‡å°†æ•°æ®ä¸­å¿ƒä½¿ç”¨çš„æ€»èƒ½é‡é™¤ä»¥
    IT è®¾å¤‡ï¼ˆå¦‚æœåŠ¡å™¨ã€å­˜å‚¨ç­‰ï¼‰ä½¿ç”¨çš„èƒ½é‡æ¥è®¡ç®—ã€‚'
- en: It uses the same `Carbon Intensity` per [cloud](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/cloud/impact.csv)
    or [country](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/private_infra/eu-carbon-intensity-electricity.csv)
    as `codecarbon.` It applies a world average of [**475 gCO2.eq/KWh**](https://www.iea.org/reports/global-energy-co2-status-report-2019/emissions)when
    the carbon intensity is not available.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä½¿ç”¨ä¸ `codecarbon` ç›¸åŒçš„æ¯ä¸ª[äº‘](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/cloud/impact.csv)æˆ–[å›½å®¶](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/private_infra/eu-carbon-intensity-electricity.csv)çš„
    `Carbon Intensity`ã€‚å½“ç¢³å¼ºåº¦ä¸å¯ç”¨æ—¶ï¼Œåº”ç”¨[**475 gCO2.eq/KWh**](https://www.iea.org/reports/global-energy-co2-status-report-2019/emissions)çš„å…¨çƒå¹³å‡å€¼ã€‚
- en: 'Can be installed with pip:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥é€šè¿‡ pip å®‰è£…ï¼š
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The usage is simple as you can see in the example below:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹é¢çš„ç¤ºä¾‹æ‰€ç¤ºï¼š
- en: 'It has also the capability to gather and store logs in a defined directory:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿˜å…·å¤‡åœ¨æŒ‡å®šç›®å½•ä¸­æ”¶é›†å’Œå­˜å‚¨æ—¥å¿—çš„èƒ½åŠ›ï¼š
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now that we have an idea about CodeCarbon and CarbonTracker we are going to
    use them in a Vertex AI Pipeline.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯¹ CodeCarbon å’Œ CarbonTracker æœ‰äº†ä¸€å®šäº†è§£ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†åœ¨ Vertex AI Pipeline ä¸­ä½¿ç”¨å®ƒä»¬ã€‚
- en: II. Case study with Vertex AI PipelinesğŸ‘·
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: II. ä½¿ç”¨ Vertex AI Pipelines çš„æ¡ˆä¾‹ç ”ç©¶ğŸ‘·
- en: The fun part begins right now ğŸ˜„
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„éƒ¨åˆ†ç°åœ¨å¼€å§‹ ğŸ˜„
- en: Before proceeding with the Vertex AI Pipelines, I invite you to read [**my article**](https://medium.com/towards-data-science/how-to-set-up-custom-vertex-ai-pipelines-step-by-step-467487f81cad)
    which shows how to use Vertex AI Pipelines.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»§ç»­ Vertex AI Pipelines ä¹‹å‰ï¼Œæˆ‘é‚€è¯·ä½ é˜…è¯»[**æˆ‘çš„æ–‡ç« **](https://medium.com/towards-data-science/how-to-set-up-custom-vertex-ai-pipelines-step-by-step-467487f81cad)ï¼Œè¯¥æ–‡ç« å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨
    Vertex AI Pipelinesã€‚
- en: 'Next, I will demonstrate how to track the carbon footprint in two scenarios:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘å°†æ¼”ç¤ºå¦‚ä½•åœ¨ä¸¤ç§åœºæ™¯ä¸­è·Ÿè¸ªç¢³è¶³è¿¹ï¼š
- en: 1\. Supervised machine learning with CodeCarbon only (CarbonTracker supports
    only deep learning).
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1\. ä»…ä½¿ç”¨ CodeCarbon è¿›è¡Œçš„ç›‘ç£å­¦ä¹ ï¼ˆCarbonTracker ä»…æ”¯æŒæ·±åº¦å­¦ä¹ ï¼‰ã€‚
- en: 2\. Deep learning with CodeCarbon & CarbonTracker.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2\. ä½¿ç”¨ CodeCarbon å’Œ CarbonTracker è¿›è¡Œæ·±åº¦å­¦ä¹ ã€‚
- en: '*1\. Carbon Footprint on supervised machine learning on CPU*'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*1\. CPU ä¸Šç›‘ç£å­¦ä¹ çš„ç¢³è¶³è¿¹*'
- en: We are going to track the carbon emissions while training a Random Forest algorithm
    to **â€œ*Predict the wine quality*â€.** The data is downloaded from [UCI Machine
    Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality) @source
    [Cortez et al., 2009]. Check the section [The Use Case](https://medium.com/towards-data-science/how-to-set-up-custom-vertex-ai-pipelines-step-by-step-467487f81cad)
    in my article for more details on the dataset. The notebook is available on [GitHub](https://github.com/anabild/mlops/tree/main/notebook).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è·Ÿè¸ªè®­ç»ƒéšæœºæ£®æ—ç®—æ³•ä»¥**â€œ*é¢„æµ‹è‘¡è„é…’è´¨é‡*â€**æ—¶çš„ç¢³æ’æ”¾ã€‚æ•°æ®ä»[UCI æœºå™¨å­¦ä¹ åº“](https://archive.ics.uci.edu/ml/datasets/wine+quality)ä¸‹è½½ï¼Œ@source
    [Cortez ç­‰, 2009]ã€‚æœ‰å…³æ•°æ®é›†çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·æŸ¥çœ‹æˆ‘çš„æ–‡ç« ä¸­çš„[ç”¨ä¾‹](https://medium.com/towards-data-science/how-to-set-up-custom-vertex-ai-pipelines-step-by-step-467487f81cad)éƒ¨åˆ†ã€‚ç¬”è®°æœ¬å¯åœ¨[GitHub](https://github.com/anabild/mlops/tree/main/notebook)ä¸Šè·å–ã€‚
- en: 'To measure the carbon emissions during training we need to modify the `train_winequality`
    custom Kubeflow component in the notebook as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æµ‹é‡è®­ç»ƒæœŸé—´çš„ç¢³æ’æ”¾ï¼Œæˆ‘ä»¬éœ€è¦æŒ‰å¦‚ä¸‹æ–¹å¼ä¿®æ”¹ç¬”è®°æœ¬ä¸­çš„ `train_winequality` è‡ªå®šä¹‰ Kubeflow ç»„ä»¶ï¼š
- en: Add `codecarbon`to `packages_to_install`list.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°† `codecarbon` æ·»åŠ åˆ° `packages_to_install` åˆ—è¡¨ä¸­ã€‚
- en: Add a metric to track the value of the CO2 estimations `kpi_co2:Output[Metrics].`
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ ä¸€ä¸ªæŒ‡æ ‡ä»¥è·Ÿè¸ª CO2 ä¼°ç®—å€¼ `kpi_co2:Output[Metrics].`
- en: Import `OfflineEmissionsTracker` to use the offline mode (no internet connection
    on the setup).
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¼å…¥ `OfflineEmissionsTracker` ä»¥ä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼ˆè®¾ç½®æ—¶æ²¡æœ‰äº’è”ç½‘è¿æ¥ï¼‰ã€‚
- en: Instantiate the codecarbon tracker `tracker = OfflineEmissionsTracker(country_iso_code=â€BELâ€).`
    BEL stands for Belgium. Pay attention that the country should match the selected
    Google Cloud region, `europe-west1` in our case.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ä¾‹åŒ– codecarbon è·Ÿè¸ªå™¨ `tracker = OfflineEmissionsTracker(country_iso_code=â€BELâ€).`
    BEL ä»£è¡¨æ¯”åˆ©æ—¶ã€‚æ³¨æ„å›½å®¶ä»£ç åº”ä¸æ‰€é€‰çš„ Google Cloud åŒºåŸŸåŒ¹é…ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ `europe-west1`ã€‚
- en: Start tracking with `tracker.start().`
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `tracker.start().` å¼€å§‹è·Ÿè¸ªã€‚
- en: Start training the model using .fit() method.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ .fit() æ–¹æ³•å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚
- en: Stop tracking with `tracker.stop()`
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `tracker.stop()` åœæ­¢è·Ÿè¸ª
- en: Log the emissions `kpi_co2.log_metric(â€œemissionsâ€, float(emissions)).`
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®°å½•æ’æ”¾ `kpi_co2.log_metric(â€œemissionsâ€, float(emissions)).`
- en: See below my example.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è§ä¸‹æ–¹æˆ‘çš„ç¤ºä¾‹ã€‚
- en: Once you update the `train_winequality` component and run again the notebook
    you should see the `kpi_co2` metric artifact on the pipeline graph.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ æ›´æ–° `train_winequality` ç»„ä»¶å¹¶é‡æ–°è¿è¡Œç¬”è®°æœ¬ï¼Œä½ åº”è¯¥ä¼šåœ¨ç®¡é“å›¾ä¸Šçœ‹åˆ° `kpi_co2` æŒ‡æ ‡å·¥ä»¶ã€‚
- en: '![](../Images/472f269f1a098b40451796a2a78c2caa.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/472f269f1a098b40451796a2a78c2caa.png)'
- en: image by the author
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: Then, go under the NODE INFO tab to check the value of the estimation of the
    CO2 emissions in kg/kWh.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œè¿›å…¥ NODE INFO æ ‡ç­¾ä»¥æ£€æŸ¥ CO2 æ’æ”¾ä¼°ç®—å€¼ï¼ˆä»¥ kg/kWh ä¸ºå•ä½ï¼‰ã€‚
- en: '![](../Images/1fb66273dede602228515c1be85dc6bd.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fb66273dede602228515c1be85dc6bd.png)'
- en: â—ï¸ Be aware that to create a Vertex AI Pipeline without monitoring until completion
    you can use **submit** instead of **run**.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: â—ï¸ è¯·æ³¨æ„ï¼Œè¦åˆ›å»ºä¸€ä¸ª Vertex AI Pipeline å¹¶åœ¨å®Œæˆä¹‹å‰ä¸è¿›è¡Œç›‘æ§ï¼Œä½ å¯ä»¥ä½¿ç”¨ **submit** è€Œä¸æ˜¯ **run**ã€‚
- en: Now letâ€™s do the exercise using a deep-learning algorithm.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨æ·±åº¦å­¦ä¹ ç®—æ³•è¿›è¡Œç»ƒä¹ ã€‚
- en: '**2\. Carbon Footprint using deep learning on GPU**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2. ç¢³è¶³è¿¹ä½¿ç”¨ GPU ä¸Šçš„æ·±åº¦å­¦ä¹ **'
- en: In this exercise, we are going to train a deep-learning model using [Keras](https://keras.io/)
    (open-source Python deep-learning library) and [Tensorflow](https://www.tensorflow.org/)
    (open-source machine learning framework). The goal is to determine if a photo
    includes any of the labels listed in Table 1\. To achieve this we perform image
    classification using a custom *Convolutional Neural Networks* (CNN) architecture.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Keras](https://keras.io/)ï¼ˆå¼€æº Python æ·±åº¦å­¦ä¹ åº“ï¼‰å’Œ [Tensorflow](https://www.tensorflow.org/)ï¼ˆå¼€æºæœºå™¨å­¦ä¹ æ¡†æ¶ï¼‰è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ç›®æ ‡æ˜¯ç¡®å®šç…§ç‰‡æ˜¯å¦åŒ…å«è¡¨
    1 ä¸­åˆ—å‡ºçš„ä»»ä½•æ ‡ç­¾ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªå®šä¹‰çš„ *å·ç§¯ç¥ç»ç½‘ç»œ*ï¼ˆCNNï¼‰æ¶æ„è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚
- en: '**2.1 Data description**'
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2.1 æ•°æ®æè¿°**'
- en: 'We use the Fashion-MNIST held by Zalando SE dataset available in Keras licensed
    under the [MIT license](https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).
    It includes 60,000 images for training and 10.000 for testing. Each image is a
    28x28 grayscale of 10 different fashion categories labeled with one of the 10
    classes as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ Keras æä¾›çš„ç”± Zalando SE æä¾›çš„ Fashion-MNIST æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŸºäº[MIT è®¸å¯è¯](https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE)ã€‚å®ƒåŒ…æ‹¬
    60,000 å¼ ç”¨äºè®­ç»ƒçš„å›¾ç‰‡å’Œ 10,000 å¼ ç”¨äºæµ‹è¯•çš„å›¾ç‰‡ã€‚æ¯å¼ å›¾ç‰‡éƒ½æ˜¯ä¸€ä¸ª 28x28 çš„ç°åº¦å›¾åƒï¼Œå±äº 10 ç§ä¸åŒçš„æ—¶å°šç±»åˆ«ï¼Œå¹¶æ ‡è®°ä¸ºä»¥ä¸‹ 10
    ä¸ªç±»åˆ«ä¹‹ä¸€ï¼š
- en: '![](../Images/8726bb05aeb51ca2fd2d1963e3ac4a9e.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8726bb05aeb51ca2fd2d1963e3ac4a9e.png)'
- en: 'Table 1: Contains the labels of the photos.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 1ï¼šåŒ…å«ç…§ç‰‡çš„æ ‡ç­¾ã€‚
- en: 2.2 Set up the environment
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 è®¾ç½®ç¯å¢ƒ
- en: Vertex AI Workbench
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vertex AI Workbench
- en: Python 3
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3
- en: Kubeflow pipeline components
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubeflow ç®¡é“ç»„ä»¶
- en: Pre-build images using NVIDIA TESLA T4 GPU
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ NVIDIA TESLA T4 GPU é¢„æ„å»ºé•œåƒ
- en: Tensorflow 2.11
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tensorflow 2.11
- en: Codecarbon
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Codecarbon
- en: CarbonTracker
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CarbonTracker
- en: Then install Google Cloud Pipeline Components and TensorFlow with pip.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½¿ç”¨ pip å®‰è£… Google Cloud Pipeline ç»„ä»¶å’Œ TensorFlowã€‚
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Import the libraries.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼å…¥åº“ã€‚
- en: Define global variables.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰å…¨å±€å˜é‡ã€‚
- en: 2.3 Create a custom deep-learning component
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 åˆ›å»ºè‡ªå®šä¹‰æ·±åº¦å­¦ä¹ ç»„ä»¶
- en: Iâ€™ll be using as base image the `tf-gpu.2â€“11:latest` pre-built docker image
    that contains TensorFlow and GPU in Artifact Registry. See the available pre-built
    images for [prediction](https://console.cloud.google.com/artifacts/docker/vertex-ai/europe/prediction)
    and [training](https://console.cloud.google.com/artifacts/docker/vertex-ai/europe/training)
    in Europe. Note that Google released pre-build images also the [Container Registry.](https://console.cloud.google.com/gcr/images/deeplearning-platform-release/GLOBAL)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†ä½¿ç”¨`tf-gpu.2â€“11:latest`ä½œä¸ºåŸºç¡€é•œåƒï¼Œè¯¥é•œåƒåŒ…å«TensorFlowå’ŒGPUï¼Œå­˜å‚¨åœ¨Artifact Registryä¸­ã€‚è¯·å‚è§æ¬§æ´²çš„[é¢„æµ‹](https://console.cloud.google.com/artifacts/docker/vertex-ai/europe/prediction)å’Œ[è®­ç»ƒ](https://console.cloud.google.com/artifacts/docker/vertex-ai/europe/training)çš„é¢„æ„å»ºé•œåƒã€‚è¯·æ³¨æ„ï¼ŒGoogleè¿˜åœ¨[Container
    Registry](https://console.cloud.google.com/gcr/images/deeplearning-platform-release/GLOBAL)ä¸­å‘å¸ƒäº†é¢„æ„å»ºé•œåƒã€‚
- en: 'To enable `codecarbon` and `carbontracker` we are going to proceed as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¯ç”¨`codecarbon`å’Œ`carbontracker`ï¼Œæˆ‘ä»¬å°†æŒ‰å¦‚ä¸‹æ­¥éª¤è¿›è¡Œï¼š
- en: Add `codecarbon and carbontracker`to `packages_to_install`list.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†`codecarbonå’Œcarbontracker`æ·»åŠ åˆ°`packages_to_install`åˆ—è¡¨ä¸­ã€‚
- en: Add metric to track the estimations `kpi_co2:Output[Metrics].`
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ åº¦é‡æ¥è·Ÿè¸ªä¼°è®¡å€¼`kpi_co2:Output[Metrics]`ã€‚
- en: Import CarbonTracker and the log parser.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¼å…¥CarbonTrackerå’Œæ—¥å¿—è§£æå™¨ã€‚
- en: Define a directory to redirect the logs of the `carbontracker` e.g `DIR_LOG="log"`
    .
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®šä¹‰ä¸€ä¸ªç›®å½•æ¥é‡å®šå‘`carbontracker`çš„æ—¥å¿—ï¼Œä¾‹å¦‚`DIR_LOG="log"`ã€‚
- en: Load train images and rescale them.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½è®­ç»ƒå›¾åƒå¹¶è¿›è¡Œç¼©æ”¾ã€‚
- en: Use `keras.Sequential` API to define the layers of your CNN.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`keras.Sequential` APIæ¥å®šä¹‰CNNçš„å±‚ã€‚
- en: Compile the model.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼–è¯‘æ¨¡å‹ã€‚
- en: Start `codecarbon` and specify the ISO code NLD for Netherlands region.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯åŠ¨`codecarbon`å¹¶æŒ‡å®šè·å…°åœ°åŒºçš„ISOä»£ç NLDã€‚
- en: Specifythe number of epochs and the log directory for carbontracker `carbontracker
    = CarbonTracker(epochs=epochs, log_dir=â€./â€+DIR_LOG+â€/â€).`
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŒ‡å®šepochsçš„æ•°é‡å’Œcarbontrackerçš„æ—¥å¿—ç›®å½•`carbontracker = CarbonTracker(epochs=epochs,
    log_dir=â€./â€+DIR_LOG+â€/â€)`ã€‚
- en: Start carbontracker `carbontracker.epoch_start().`
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯åŠ¨carbontracker `carbontracker.epoch_start()`ã€‚
- en: Fit model on the training data.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‹Ÿåˆæ¨¡å‹ã€‚
- en: 'Stop carbontracker : `carbontracker.epoch_end()` & codecarbon `codecarbon.stop().`'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœæ­¢carbontrackerï¼š`carbontracker.epoch_end()` & codecarbon `codecarbon.stop()`ã€‚
- en: Log the emissions values and save the model.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®°å½•æ’æ”¾å€¼å¹¶ä¿å­˜æ¨¡å‹ã€‚
- en: 2.4 Evaluate the model
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 è¯„ä¼°æ¨¡å‹
- en: The evaluation component relies on a pre-compiled GPU Tensorflow 2.11 base image.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°ç»„ä»¶ä¾èµ–äºé¢„ç¼–è¯‘çš„GPU Tensorflow 2.11åŸºç¡€é•œåƒã€‚
- en: It takes in input the trained model. Then it loads the `fashion.mist` test dataset.
    It resizes and reshapes the test images, evaluates the model, and computes the
    accuracy, loss, and confusion matrix.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ã€‚ç„¶ååŠ è½½`fashion.mist`æµ‹è¯•æ•°æ®é›†ã€‚å®ƒè°ƒæ•´å’Œé‡å¡‘æµ‹è¯•å›¾åƒï¼Œè¯„ä¼°æ¨¡å‹ï¼Œå¹¶è®¡ç®—å‡†ç¡®ç‡ã€æŸå¤±å’Œæ··æ·†çŸ©é˜µã€‚
- en: 2.5 Create and submit the pipeline
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 åˆ›å»ºå¹¶æäº¤ç®¡é“
- en: The pipeline facilitates the orchestration of a serverless workflow. Our pipeline
    has two steps training (deep_learning_mist_task) and evaluation (model _evaluation_task).
    It takes as input a few parameters like the learning_rate, the number of epochs,
    the batch_size, the API endpoint, the project id, and the serving URI.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®¡é“ä¿ƒè¿›äº†æ— æœåŠ¡å™¨å·¥ä½œæµçš„ç¼–æ’ã€‚æˆ‘ä»¬çš„ç®¡é“æœ‰ä¸¤ä¸ªæ­¥éª¤ï¼šè®­ç»ƒï¼ˆdeep_learning_mist_taskï¼‰å’Œè¯„ä¼°ï¼ˆmodel_evaluation_taskï¼‰ã€‚å®ƒæ¥å—ä¸€äº›å‚æ•°ï¼Œå¦‚learning_rateã€epochsçš„æ•°é‡ã€batch_sizeã€APIç«¯ç‚¹ã€é¡¹ç›®IDå’ŒæœåŠ¡URIã€‚
- en: 'To specify the machine configuration for a pipeline step use:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä¸ºç®¡é“æ­¥éª¤æŒ‡å®šæœºå™¨é…ç½®ï¼Œè¯·ä½¿ç”¨ï¼š
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The available values for GPU_TYPE are:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: GPU_TYPEçš„å¯ç”¨å€¼åŒ…æ‹¬ï¼š
- en: NVIDIA_TESLA_A100,
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA_TESLA_A100ï¼Œ
- en: NVIDIA_TESLA_K80,
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA_TESLA_K80ï¼Œ
- en: NVIDIA_TESLA_P4,
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA_TESLA_P4ï¼Œ
- en: NVIDIA_TESLA_P100,
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA_TESLA_P100ï¼Œ
- en: NVIDIA_TESLA_T4,
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA_TESLA_T4ï¼Œ
- en: NVIDIA_TESLA_V10.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA_TESLA_V10ã€‚
- en: The GPU_LIMIT is a positive number indicating the GPU limit.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: GPU_LIMITæ˜¯ä¸€ä¸ªè¡¨ç¤ºGPUé™åˆ¶çš„æ­£æ•°ã€‚
- en: 'Once the pipeline is executed you should see the following graph:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰§è¡Œç®¡é“åï¼Œä½ åº”è¯¥ä¼šçœ‹åˆ°ä»¥ä¸‹å›¾è¡¨ï¼š
- en: '![](../Images/3b69ee5a1987773220d77ba6dbc929ca.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b69ee5a1987773220d77ba6dbc929ca.png)'
- en: image by the Author
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: Go to the ***Summary*** tab to see the estimation of the CO2 emissions during
    training.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬åˆ°***æ€»ç»“***é€‰é¡¹å¡ä»¥æŸ¥çœ‹è®­ç»ƒæœŸé—´CO2æ’æ”¾çš„ä¼°ç®—å€¼ã€‚
- en: '![](../Images/03640f96a2246f6a34e2668a7c9a9617.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03640f96a2246f6a34e2668a7c9a9617.png)'
- en: image by the Author
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: We can notice that the CO2 estimations are different because the energy consumption
    formula differs between the two libraries. To be honest, I prefer Codecarbon as
    it has more compatibility and better documentation.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°CO2ä¼°ç®—å€¼ä¸åŒï¼Œå› ä¸ºä¸¤ä¸ªåº“ä¹‹é—´çš„èƒ½è€—å…¬å¼ä¸åŒã€‚è¯´å®è¯ï¼Œæˆ‘æ›´å–œæ¬¢Codecarbonï¼Œå› ä¸ºå®ƒæœ‰æ›´å¥½çš„å…¼å®¹æ€§å’Œæ–‡æ¡£ã€‚
- en: III. Few practices to reduce Carbon Footprint ğŸ’¡
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: III. å‡å°‘ç¢³è¶³è¿¹çš„å‡ ä¸ªå®è·µğŸ’¡
- en: I suggest taking into account some practical considerations while designing
    AI algorithms.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å»ºè®®åœ¨è®¾è®¡AIç®—æ³•æ—¶è€ƒè™‘ä¸€äº›å®é™…é—®é¢˜ã€‚
- en: Consider integrating carbon footprint into the **entire lifecycle of a machine
    learning model**, from data collection to model deployment.
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è€ƒè™‘å°†ç¢³è¶³è¿¹æ•´åˆåˆ°**æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸ**ä¸­ï¼Œä»æ•°æ®æ”¶é›†åˆ°æ¨¡å‹éƒ¨ç½²ã€‚
- en: ''
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Look for machines equipped with appropriate processors** (CPU/GPU/TPU)s that
    fit your use case.'
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**å¯»æ‰¾é…å¤‡é€‚å½“å¤„ç†å™¨**ï¼ˆCPU/GPU/TPUï¼‰çš„æœºå™¨ï¼Œä»¥é€‚åº”ä½ çš„ç”¨ä¾‹ã€‚'
- en: ''
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Choose a cloud region with a low carbon footprint.** For instance, Google
    Cloud Platform indicates for each available region if it is low CO2.'
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**é€‰æ‹©ç¢³è¶³è¿¹è¾ƒä½çš„äº‘åŒºåŸŸ**ã€‚ä¾‹å¦‚ï¼ŒGoogle Cloud Platform ä¼šæŒ‡ç¤ºæ¯ä¸ªå¯ç”¨åŒºåŸŸæ˜¯å¦ä½ CO2ã€‚'
- en: ''
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Integrate carbon footprint trackers** in your ML ecosystem.'
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä½ çš„æœºå™¨å­¦ä¹ ç”Ÿæ€ç³»ç»Ÿä¸­**é›†æˆç¢³è¶³è¿¹è·Ÿè¸ªå™¨**ã€‚
- en: ''
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Select efficient model architecture**s. Have a look at [sparse models](https://ai.googleblog.com/2021/03/constructing-transformers-for-longer.html)
    that may reduce energy consumption.'
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**é€‰æ‹©é«˜æ•ˆçš„æ¨¡å‹æ¶æ„**ã€‚æŸ¥çœ‹å¯èƒ½å‡å°‘èƒ½è€—çš„[sparse models](https://ai.googleblog.com/2021/03/constructing-transformers-for-longer.html)ã€‚'
- en: ''
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Encourage teams to use the cloud**, as it has been shown to be [more energy-efficient](https://www.morganclaypool.com/doi/10.2200/S00874ED3V01Y201809CAC046).'
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**é¼“åŠ±å›¢é˜Ÿä½¿ç”¨äº‘**ï¼Œå› ä¸ºç ”ç©¶è¡¨æ˜å®ƒ[æ›´å…·èƒ½æºæ•ˆç‡](https://www.morganclaypool.com/doi/10.2200/S00874ED3V01Y201809CAC046)ã€‚'
- en: ''
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Use pre-built models** as much as possible rather than training from scratch.'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°½å¯èƒ½**ä½¿ç”¨é¢„æ„å»ºæ¨¡å‹**ï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒã€‚
- en: ''
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Share datasets, feature stores, and pre-build** specialized models across
    the organization.'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**åœ¨ç»„ç»‡ä¸­å…±äº«æ•°æ®é›†ã€ç‰¹å¾åº“å’Œé¢„æ„å»º**çš„ä¸“ä¸šæ¨¡å‹ã€‚'
- en: Key takeaways
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…³é”®è¦ç‚¹
- en: In conclusion, I recommend using Codecarbon as it performs well on both machine
    learning (CPUs) and deep learning algorithms (GPUs) and has more infrastructure
    compatibility. Regarding CarbonTraker, I encountered difficulties with getting
    it to run on Google Cloud CPUs getting CPUs unsupported errors, leading to wasted
    time. If you plan to use a GPU keep in mind to verify the GPU [availabilit](https://cloud.google.com/compute/docs/gpus/gpu-regions-zones)y
    before using it. Additionally, I strongly suggest checking t[he GPU pricing](https://cloud.google.com/compute/gpus-pricing#gpu-pricing)
    to aim for lower costs. Lastly, itâ€™s important to remember that reducing carbon
    footprint in machine learning is a continuous process and new techniques and technologies
    are being constantly developed to address it. Make sure to keep track of updates
    regarding carbon footprint reduction strategies.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä¹‹ï¼Œæˆ‘æ¨èä½¿ç”¨Codecarbonï¼Œå› ä¸ºå®ƒåœ¨æœºå™¨å­¦ä¹ ï¼ˆCPUï¼‰å’Œæ·±åº¦å­¦ä¹ ç®—æ³•ï¼ˆGPUï¼‰ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¥½çš„åŸºç¡€è®¾æ–½å…¼å®¹æ€§ã€‚å…³äºCarbonTrakerï¼Œæˆ‘åœ¨Google
    Cloud CPUä¸Šé‡åˆ°äº†æ— æ³•è¿è¡Œçš„é”™è¯¯ï¼Œå¯¼è‡´æµªè´¹æ—¶é—´ã€‚å¦‚æœä½ æ‰“ç®—ä½¿ç”¨GPUï¼Œè®°å¾—åœ¨ä½¿ç”¨å‰éªŒè¯GPU[å¯ç”¨æ€§](https://cloud.google.com/compute/docs/gpus/gpu-regions-zones)ã€‚æ­¤å¤–ï¼Œæˆ‘å¼ºçƒˆå»ºè®®æ£€æŸ¥[GPUå®šä»·](https://cloud.google.com/compute/gpus-pricing#gpu-pricing)ä»¥æœŸæœ›æ›´ä½çš„æˆæœ¬ã€‚æœ€åï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œå‡å°‘æœºå™¨å­¦ä¹ ä¸­çš„ç¢³è¶³è¿¹æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œæ–°æŠ€æœ¯å’ŒæŠ€æœ¯ä¸æ–­å‘å±•ä»¥åº”å¯¹è¿™ä¸€é—®é¢˜ã€‚ç¡®ä¿è·Ÿè¸ªæœ‰å…³ç¢³è¶³è¿¹å‡å°‘ç­–ç•¥çš„æ›´æ–°ã€‚
- en: The notebooks are available on my [GitHub](https://github.com/anabild/mlops/tree/main/notebook)
    account.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬”è®°æœ¬å¯ä»¥åœ¨æˆ‘çš„[GitHub](https://github.com/anabild/mlops/tree/main/notebook)è´¦æˆ·ä¸­æ‰¾åˆ°ã€‚
- en: I hope you enjoyed the article.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ã€‚
- en: Thank you for reading!
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è°¢è°¢é˜…è¯»ï¼
- en: Donâ€™t forget to [subscribe](https://medium.com/subscribe/@anna.bildea) if you
    want to get my future stories in your inbox.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³åœ¨æ”¶ä»¶ç®±ä¸­æ”¶åˆ°æˆ‘çš„æœªæ¥æ•…äº‹ï¼Œåˆ«å¿˜äº†[è®¢é˜…](https://medium.com/subscribe/@anna.bildea)ã€‚
- en: '*If you enjoy reading my story and want to support me as a writer, consider
    signing up to become a Medium member and gain access to thousands of Data Engineering
    and Data Science articles.*'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦‚æœä½ å–œæ¬¢é˜…è¯»æˆ‘çš„æ•…äº‹å¹¶å¸Œæœ›æ”¯æŒæˆ‘æˆä¸ºä½œè€…ï¼Œè¯·è€ƒè™‘æ³¨å†Œæˆä¸ºMediumä¼šå‘˜ï¼Œå¹¶è·å¾—æ•°åƒç¯‡æ•°æ®å·¥ç¨‹å’Œæ•°æ®ç§‘å­¦æ–‡ç« çš„è®¿é—®æƒé™ã€‚*'
- en: '[](https://medium.com/@anna.bildea/membership?source=post_page-----3d6bc9695e7b--------------------------------)
    [## Join Medium with my referral link â€” Bildea Ana'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea/membership?source=post_page-----3d6bc9695e7b--------------------------------)
    [## ä½¿ç”¨æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥Medium â€” Bildea Ana'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every storyâ€¦
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½œä¸ºMediumä¼šå‘˜ï¼Œä½ çš„ä¼šå‘˜è´¹çš„ä¸€éƒ¨åˆ†å°†ç”¨äºä½ é˜…è¯»çš„ä½œè€…ï¼Œå¹¶ä¸”ä½ å¯ä»¥å®Œå…¨è®¿é—®æ¯ä¸€ä¸ªæ•…äº‹â€¦â€¦
- en: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----3d6bc9695e7b--------------------------------)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----3d6bc9695e7b--------------------------------)
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/)
    *and* [Twitter](https://twitter.com/AnaBildea)!'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*åœ¨* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/) *å’Œ*
    [Twitter](https://twitter.com/AnaBildea) *ä¸Šæ‰¾åˆ°æˆ‘ï¼*'
- en: See my collection of MLops articles
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹æˆ‘çš„MLopsæ–‡ç« é›†åˆ
- en: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[å®‰å¨œÂ·æ¯”å°”è¿ªäºšåšå£«](https://medium.com/@anna.bildea?source=post_page-----3d6bc9695e7b--------------------------------)'
- en: MLOps - AI in Production
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps - AIåœ¨ç”Ÿäº§ä¸­
- en: '[View list](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----3d6bc9695e7b--------------------------------)4
    stories![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----3d6bc9695e7b--------------------------------)4
    ä¸ªæ•…äº‹![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
