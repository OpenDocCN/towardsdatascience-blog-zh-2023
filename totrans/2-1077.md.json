["```py\n{\n  \"result\": [\n   {\n     \"id\": 1,\n     \"branch_name\": \"Scranton\",\n     \"employees\": 50,\n     \"location\": \"Scranton, PA\",\n     ...\n   }\n ]\n}\n```", "```py\n{\n\"result\": {\n  \"branch_id\": 1,\n  \"employees\": [\n   {\n     \"id\": 1234,\n     \"occupation\": \"data engineer\",\n     \"name\": \"John Doe\",\n     ...\n   },\n   {\n     \"id\": 1235,\n     \"occupation\": \"salesperson\",\n     \"name\": \"Jim Doe\",\n     ...\n   },\n   ...\n  ],\n  ...\n }\n}\n```", "```py\n{\n  \"result\": {\n  \"employee_id\": 1235,\n  \"sales: [\n   {\n     \"id\": 3972,\n     \"transaction_timestamp\": \"2023-01-01 23:43:23\",\n     ...\n   },\n   {\n     \"id\": 4002,\n     \"transaction_timestamp\": \"2023-01-05 12:23:31\",\n     ...\n   },\n   ...\n  ],\n  ...\n }\n}\n```", "```py\nCascading-ETL-pipeline\n├── LICENSE\n├── README.md\n├── branches\n│   ├── Pipfile\n│   ├── Pipfile.lock\n│   ├── lambda_function.py\n│   ├── requirements.txt\n│   └── service\n│       ├── config.py\n│       └── service.py\n├── sales\n│   ├── Pipfile\n│   ├── Pipfile.lock\n│   ├── lambda_function.py\n│   ├── requirements.txt\n│   └── service\n│       ├── config.py\n│       └── service.py\n├── salespersons\n│   ├── Pipfile\n│   ├── Pipfile.lock\n│   ├── lambda_function.py\n│   ├── requirements.txt\n│   └── service\n│       ├── config.py\n│       └── service.py\n├── template.yml\n└── utils.py\n```", "```py\nimport json\nimport logging\nfrom pythonjsonlogger import jsonlogger\nfrom service import service, config\n\n# Load environment\nENV = config.load_env()\n\nLOGGER = logging.getLogger()\n# Replace the LambdaLoggerHandler formatter :\nLOGGER.handlers[0].setFormatter(jsonlogger.JsonFormatter())\n# Set default logging level\nLOGGING_LEVEL = getattr(logging, ENV[\"LOGGING_LEVEL\"])\nLOGGER.setLevel(LOGGING_LEVEL)\n\ndef _lambda_context(context):\n    \"\"\"\n    Extract information relevant from context object.\n\n    Args:\n        context: The context object provided by the Lambda runtime.\n\n    Returns:\n        dict: A dictionary containing relevant information from the context object.\n\n    \"\"\"\n    return {\n        \"function_name\": context.function_name,\n        \"function_version\": context.function_version,\n    }\n\n# @datadog_lambda_wrapper\ndef lambda_handler(event, context):\n    \"\"\"\n    Handle the Lambda event.\n\n    Args:\n        event(dict): The event object containing input data for the Lambda function.\n        context(dict): The context object provided by the Lambda runtime.\n\n    Returns:\n        dict: A dictionary containing the response for the Lambda function.\n\n    \"\"\"\n    LOGGER.info(\"Starting lambda executing.\", extra=_lambda_context(context))\n    service.main(event, ENV)\n    LOGGER.info(\"Successful lambda execution.\", extra=_lambda_context(context))\n    return {\"statusCode\": 200}\n```", "```py\nimport os\nimport sys\nimport logging\n\nLOGGER = logging.getLogger(__name__)\n\ndef load_env():\n    \"\"\"Load environment variables.\n\n    Returns:\n       dict: A dictionary containing the loaded environment variables.\n\n    Raises:\n        KeyError: If any required environment variable is missing.\n\n    Notes:\n        - The function attempts to load several environment variables including:\n        - If any of the required environment variables are missing, a KeyError is raised.\n        - The function logs an exception message indicating the missing environment variable and exits the program with a status code of 1.\n    \"\"\"\n    try:\n        return {\n            \"LOGGING_LEVEL\": os.environ[\"LOGGING_LEVEL\"],\n            \"APP_ENV\": os.environ[\"APP_ENV\"],\n            \"SQS\": os.environ[\"SQS\"],\n            \"DB\": os.environ[\"DB\"],\n        }\n    except KeyError as error:\n        LOGGER.exception(\"Enviroment variable %s is required.\", error)\n        sys.exit(1)\n```", "```py\nimport logging, requests, sys\nfrom utils import *\nfrom boto3.dynamodb.conditions import Key\n\nLOGGER = logging.getLogger(__name__)\n\ndef main(event, environment):\n    \"\"\"Process invoking event data and update the DynamoDB table based on specified branches.\n\n    Args:\n        event (dict): A JSON-formatted document that contains data for a Lambda function to process.\n        environment (dict): A context object that provides methods and properties about the invocation, function and runtime environment.\n\n    Returns:\n        None\n\n    Raises:\n        SystemExit: If an exception occurs during the execution.\n\n    Notes:\n        - If `event` does not contain the 'branches' key, the function will default to processing information for all branches.\n        - The function retrieves branch-specific information from a URL and updates the DynamoDB table accordingly.\n        - The updated information is then delivered to an SQS queue for further processing.\n\n    \"\"\"\n    LOGGER.info(event)\n\n    if not event.get(\"branches\"):\n        # default to look up all branches if the value is an empty list\n        branches = [\n            \"Scranton\",\n            \"Akron\",\n            \"Buffalo\",\n            \"Rochester\",\n            \"Syracuse\",\n            \"Utica\",\n            \"Binghamton\",\n            \"Albany\",\n            \"Nashua\",\n            \"Pittsfield\",\n            \"Stamford\",\n            \"Yonkers\",\n            \"New York\",\n        ]\n    else:\n        branches = event[\"branches\"]  # should be an array\n\n    queue = environment[\"SQS\"]\n    table = environment[\"DB\"]\n\n    try:\n        for branch in branches:\n            # go to a path that allows users to retrieve all information of the specified branch(es) based on input date range\n            response = requests.get(\n                url=f\"www.dundermifflinpaper.com/branches/?branch={branch}\"\n            )\n            response = response.json()\n            branches = response.get(\"result\")\n            for result in branches:\n                if not upToDate(\n                    table,\n                    Key(\"branch_id\").eq(str(result[\"id\"])),\n                    result,\n                    \"branch_\",\n                ):\n                    # only update DynamoDB table when it's NOT complete ingesting\n                    update_info(table, result)\n\n            deliver_message(queue, str({\"branch\": result[\"branch_id\"]}))\n            LOGGER.info(f\"sending branch {result['branch_id']} for the next stage\")\n\n    except Exception as e:\n        LOGGER.error(str(e), exc_info=True)\n        sys.exit(1)\n```", "```py\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: 'AWS::Serverless-2016-10-31'\nParameters:  #   Type: String\n  Environment:\n    Type: String\nResources:\n  # =========================================================================================\n  # IAM ROLES, POLICIES, PERMISSIONS\n  # =========================================================================================\n  LambdaRole:\n    Type: AWS::IAM::Role\n    Properties:\n      RoleName: !Sub '${AWS::StackName}-lambda-role'\n      AssumeRolePolicyDocument:\n        Version: '2012-10-17'\n        Statement:\n        - Effect: Allow\n          Principal:\n            Service:\n            - lambda.amazonaws.com\n            - events.amazonaws.com\n          Action:\n          - sts:AssumeRole\n      ManagedPolicyArns:\n      - arn:aws:iam::aws:policy/AWSLambdaExecute\n      - arn:aws:iam::aws:policy/AmazonSQSFullAccess\n      - arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess\n      Path: '/'\n  LambdaPolicy:\n    Type: AWS::IAM::Policy\n    Properties:\n      PolicyName: !Sub '${AWS::StackName}-lambda-policy'\n      PolicyDocument:\n        Version: '2012-10-17'\n        Statement:\n        - Sid: EventBusAccess\n          Effect: Allow\n          Action:\n          - events:PutEvents\n          Resource: '*'\n        - Sid: LambdaInvokeAccess\n          Effect: Allow\n          Action:\n          - lambda:InvokeFunction\n          Resource: \"*\"\n        - Sid: LogAccess\n          Effect: Allow\n          Action:\n          - logs:CreateLogGroup\n          - logs:CreateLogStream\n          - logs:PutLogEvents\n          Resource: arn:aws:logs:*:*:*\n      Roles:\n      - !Ref LambdaRole\n  # =========================================================================================\n  # AWS LAMBDA FUNCTIONS\n  # ========================================================================================= \n  BranchCollector:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: !Sub branch-collector-${Environment}\n      Handler: lambda_function.lambda_handler\n      Runtime: python3.9\n      CodeUri: branches/\n      Description: updating branch info in our DynamoDB table\n      MemorySize: 128\n      Timeout: 900\n      Role: !GetAtt LambdaRole.Arn\n      Environment:\n        Variables:\n          LOGGING_LEVEL: INFO\n          APP_ENV: !Ref Environment\n          SQS: !Ref EmployeeQueue\n          DB: !Sub branches-${Environment}\n      DeadLetterQueue:\n        Type: SQS\n        TargetArn: \n          Fn::GetAtt: BranchFunctionDeadLetterQueue.Arn\n      Events:\n        StartScheduledEvent:\n          Type: Schedule\n          Properties:\n            Schedule: rate(1 hour)\n\n  SalespersonCollector:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: !Sub salesperson-collector-${Environment}\n      Handler: lambda_function.lambda_handler\n      Runtime: python3.9\n      CodeUri: salespersons/\n      Description: updating salesperson info in our DynamoDB table\n      MemorySize: 128\n      Timeout: 900\n      Role: !GetAtt LambdaRole.Arn\n      ReservedConcurrentExecutions: 5\n      Environment:\n        Variables:\n          LOGGING_LEVEL: INFO\n          APP_ENV: !Ref Environment\n          SOURCE_SQS: !Ref EmployeeQueue\n          TARGET_SQS: !Ref SaleQueue\n          DB: !Sub salespersons-${Environment}\n      DeadLetterQueue:\n        Type: SQS\n        TargetArn: \n          Fn::GetAtt: EmployeeFunctionDeadLetterQueue.Arn\n      Events:\n        StartScheduledEvent:\n          Type: Schedule\n          Properties:\n            # every minute\n            Schedule: rate(1 minute)\n\n  SaleCollector:\n    Type: AWS::Serverless::Function\n    Properties:\n      FunctionName: !Sub sale-collector-${Environment}\n      Handler: lambda_function.lambda_handler\n      Runtime: python3.9\n      CodeUri: sales/\n      Description: updating sales info in our DynamoDB table\n      MemorySize: 128\n      Timeout: 900\n      ReservedConcurrentExecutions: 3\n      Role:\n        Fn::GetAtt:\n        - LambdaRole\n        - Arn\n      Environment:\n        Variables:\n          LOGGING_LEVEL: INFO\n          APP_ENV: !Ref Environment\n          SQS: !Ref SaleQueue\n          DB: !Sub sales-${Environment}\n      DeadLetterQueue:\n        Type: SQS\n        TargetArn: \n          Fn::GetAtt: SaleFunctionDeadLetterQueue.Arn\n      Events:\n        StartScheduledEvent:\n          Type: Schedule\n          Properties:\n            # every minute\n            Schedule: rate(1 minute)\n\n  # =========================================================================================\n  # AWS DynamoDB TABLES\n  # ========================================================================================= \n  BranchDynamoDBTable: \n    Type: AWS::DynamoDB::Table\n    DeletionPolicy: Delete\n    Properties:\n      BillingMode: PAY_PER_REQUEST \n      AttributeDefinitions: \n        - \n          AttributeName: \"branch_id\"\n          AttributeType: \"S\"\n      KeySchema: \n        - \n          AttributeName: \"branch_id\"\n          KeyType: \"HASH\"\n      StreamSpecification:\n        StreamViewType: NEW_IMAGE\n      TableName: !Sub branch-${Environment}\n\n  SalespersonDynamoDBTable: \n    Type: AWS::DynamoDB::Table\n    DeletionPolicy: Delete\n    Properties:\n      BillingMode: PAY_PER_REQUEST \n      AttributeDefinitions: \n        - \n          AttributeName: \"employee_id\"\n          AttributeType: \"S\"\n        - \n          AttributeName: \"branch_id\"\n          AttributeType: \"S\"\n      KeySchema: \n        - \n          AttributeName: \"employee_id\"\n          KeyType: \"HASH\"\n        - \n          AttributeName: \"branch_id\"\n          KeyType: \"RANGE\"\n      StreamSpecification:\n        StreamViewType: NEW_IMAGE\n      TableName: !Sub salesperson-${Environment}\n\n  SaleDynamoDBTable:\n    Type: AWS::DynamoDB::Table\n    DeletionPolicy: Delete\n    Properties:\n      BillingMode: PAY_PER_REQUEST \n      AttributeDefinitions: \n        - \n          AttributeName: \"sale_id\"\n          AttributeType: \"S\"\n        - \n          AttributeName: \"employee_id\"\n          AttributeType: \"S\"\n      KeySchema: \n        - \n          AttributeName: \"sale_id\"\n          KeyType: \"HASH\"\n        - \n          AttributeName: \"employee_id\"\n          KeyType: \"RANGE\"\n      StreamSpecification:\n        StreamViewType: NEW_IMAGE\n      TableName: !Sub sale-${Environment}\n\n  # =========================================================================================\n  # AWS SQS QUEUES\n  # ========================================================================================= \n  EmployeeQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: !Sub employee-queue-${Environment}\n      VisibilityTimeout: 900\n      RedrivePolicy:\n        deadLetterTargetArn: \n          Fn::GetAtt: EmployeeWorkloadDeadLetterQueue.Arn\n        maxReceiveCount: 10\n\n  EmployeeWorkloadDeadLetterQueue: \n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: !Sub employee-workload-dead-letter-queue-${Environment}\n      MessageRetentionPeriod: 1209600\n\n  BranchFunctionDeadLetterQueue: \n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: !Sub branch-function-dead-letter-queue-${Environment}\n      MessageRetentionPeriod: 1209600\n\n  SaleQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: !Sub sale-queue-${Environment}\n      VisibilityTimeout: 900\n      RedrivePolicy:\n        deadLetterTargetArn: \n          Fn::GetAtt: SaleWorkloadDeadLetterQueue.Arn\n        maxReceiveCount: 10\n\n  SaleWorkloadDeadLetterQueue: \n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: !Sub sale-workload-dead-letter-queue-${Environment}\n      MessageRetentionPeriod: 1209600\n\n  EmployeeFunctionDeadLetterQueue: \n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: !Sub employee-function-dead-letter-queue-${Environment}\n      MessageRetentionPeriod: 1209600\n\n  SaleFunctionDeadLetterQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: !Sub sale-function-dead-letter-queue-${Environment}\n      MessageRetentionPeriod: 1209600\n\n  # =========================================================================================\n  # AWS CLOUDWATCH ALARMS\n  # =========================================================================================\n  BranchErrorAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref BranchCollector\n      EvaluationPeriods: 1\n      MetricName: Errors\n      Namespace: AWS/Lambda\n      Period: 300\n      Statistic: Sum\n      Threshold: '1'\n      AlarmActions: \n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n  BranchDurationAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref BranchCollector\n      EvaluationPeriods: 1\n      MetricName: Duration\n      Namespace: AWS/Lambda\n      Period: 60\n      Statistic: Maximum\n      Threshold: '750000'\n      AlarmActions:\n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n  BranchThrottleAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref BranchCollector\n      EvaluationPeriods: 1\n      MetricName: Throttles\n      Namespace: AWS/Lambda\n      Period: 300\n      Statistic: Sum\n      Threshold: '1'\n      AlarmActions:\n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n\n  SalespersonErrorAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref SalespersonCollector\n      EvaluationPeriods: 1\n      MetricName: Errors\n      Namespace: AWS/Lambda\n      Period: 300\n      Statistic: Sum\n      Threshold: '1'\n      AlarmActions: \n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n  SalespersonDurationAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref SalespersonCollector\n      EvaluationPeriods: 1\n      MetricName: Duration\n      Namespace: AWS/Lambda\n      Period: 60\n      Statistic: Maximum\n      Threshold: '750000'\n      AlarmActions:\n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n  SalespersonThrottleAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref SalespersonCollector\n      EvaluationPeriods: 1\n      MetricName: Throttles\n      Namespace: AWS/Lambda\n      Period: 300\n      Statistic: Sum\n      Threshold: '1'\n      AlarmActions:\n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n\n  SaleErrorAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref SaleCollector\n      EvaluationPeriods: 1\n      MetricName: Errors\n      Namespace: AWS/Lambda\n      Period: 300\n      Statistic: Sum\n      Threshold: '1'\n      AlarmActions: \n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n  SaleDurationAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref SaleCollector\n      EvaluationPeriods: 1\n      MetricName: Duration\n      Namespace: AWS/Lambda\n      Period: 60\n      Statistic: Maximum\n      Threshold: '750000'\n      AlarmActions:\n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n  SaleThrottleAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref SaleCollector\n      EvaluationPeriods: 1\n      MetricName: Throttles\n      Namespace: AWS/Lambda\n      Period: 300\n      Statistic: Sum\n      Threshold: '1'\n      AlarmActions:\n        - arn:aws:sns:us-east-1:{id}:{alarm-action-name}\n```", "```py\ndef upToDate(table_name, condition, result, prefix):\n    \"\"\"\n    Check if a record in a given specified DynamoDB table is up-to-date, which means that it's no different from the API retrieval.\n\n    Args:\n        table_name (str): The name of the DynamoDB table to check.\n        condition (boto3.dynamodb.conditions.Key): The key condition expression for querying the table.\n        result (dict): The record to check for ingestion completion.\n        prefix (str): The prefix used for key matching.\n\n    Returns:\n        bool: True if the ingestion is completed, False otherwise.\n\n    Notes:\n        - The function queries the specified DynamoDB table using the provided condition.\n        - It retrieves the items matching the condition.\n        - The function compares the key-value pairs of the result with the retrieved items, accounting for the provided prefix if applicable.\n        - If all key-value pairs match between the result and the retrieved items, the ingestion is considered completed.\n        - The function returns True if the ingestion is completed, and False otherwise.\n\n    \"\"\"\n    table = dynamodb.Table(table_name)\n    retrieval = table.query(KeyConditionExpression=condition)[\"Items\"]\n\n    existing_items = 0\n    if len(retrieval) > 0:\n        for key in retrieval.keys():\n            if key.upper() not in reserved_words:\n                if result[key] == retrieval[0].get(key):\n                    existing_items += 1\n            elif result[\"key\"] == retrieval[0].get(prefix + key):\n                existing_items += 1\n\n    completed = len(retrieval) and existing_items == len(result.items())\n    # len(retrieval) == 0: the item doesn't exist in DynamoDB at all\n    # existing_items == len(result.items()): the item exists and all its key-value pairs\n    # are synced up with API\n    return completed\n```", "```py\npip install -r requirements.txt\n```", "```py\n# copy utils.py to each folder\nfor d in */; do cp utils.py \"$d\"; done\n# build the cloudformation\nsam build -u\n# invoke the functions locally for local testing\n# event.json should be like:\n# {\n#    \"branches\": [\"Scranton\"]\n# }\n# env.json should be like:\n# {\n#    \"Parameters\": {\n#        \"Environment\": \"local\"\n#    }\n# }\nsam local invoke \"BranchCollector\" -e branch.json --env-vars env.json\nsam local invoke \"SalespersonCollector\" -e branch.json --env-vars env.json\nsam local invoke \"SalesCollector\" -e branch.json --env-vars env.json\n# deploy it onto AWS\nsam deploy --parameter-overrides Environment=dev\n```"]