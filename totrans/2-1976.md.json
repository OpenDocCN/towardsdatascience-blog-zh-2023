["```py\n# Load a blank English model\nnlp = spacy.blank(\"en\")\n\n#Create the EntityRuler\nruler = nlp.add_pipe(\"entity_ruler\")\n```", "```py\n# Define patterns\npatterns = [\n    {\"label\": \"ALKANE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*ane$\"}}]},\n    {\"label\": \"ALKENE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*ene$\"}}]},\n    {\"label\": \"ALKYNE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*yne$\"}}]}\n]\n\nruler.add_patterns(patterns)\n```", "```py\ntext = \"Ethane,  propene, and butyne are all examples of hydrocarbons.\"\n\ndoc = nlp(text)\n\n#extract entities\nfor ent in doc.ents:\n    print (ent.text, ent.start_char, ent.end_char, ent.label_)\n```", "```py\nEthane 0 6 ALKANE\npropene 9 16 ALKENE\nbutyne 22 28 ALKYNE\n```", "```py\n# Define patterns\npatterns = [\n    {\"label\": \"ALKANE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*anes?$\"}}]},\n    {\"label\": \"ALKENE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*enes?$\"}}]},\n    {\"label\": \"ALKYNE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*ynes?$\"}}]},\n]\n```", "```py\nGive me a set of 50 unique sentences each dealing with unique alkanes\n```", "```py\ndoc = nlp(chem_text)\n\ncorpus = []\n\nfor sent in doc.sents:\n    corpus.append(sent.text.strip())\n```", "```py\nDATA = []\n\n#iterate over the corpus again\nfor sentence in corpus:\n    doc = nlp(sentence)\n\n    #remember, entities needs to be a dictionary in index 1 of the list, so it needs to be an empty list\n    entities = []\n\n    #extract entities\n    for ent in doc.ents:\n\n        #appending to entities in the correct format\n        entities.append([ent.start_char, ent.end_char, ent.label_])\n\n    DATA.append([sentence, {\"entities\": entities}])\n```", "```py\n# Define patterns\npatterns = [\n    {\"label\": \"ALKANE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*anes?$\"}}]},\n    {\"label\": \"ALKENE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*enes?$\"}}]},\n    {\"label\": \"ALKYNE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*ynes?$\"}}]},\n    {\"label\": \"ALCOHOL\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*ols?$\"}}]},\n    {\"label\": \"ALDEHYDE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*(al|als|aldehyde|aldehydes)$\"}}]},\n    {\"label\": \"KETONE\", \"pattern\": [{\"TEXT\": {\"REGEX\": \".*ones?$\"}}]},\n    {\"label\": \"C_ACID\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"\\b\\w+ic\\b\"}}, {\"TEXT\": {\"IN\": [\"acid\", \"acids\"]}}]}\n]\n```", "```py\n# List of words to be ignored\nignore_set = {\"essential\", \"crystals\", \"potential\",\"materials\",\"bioorthogonal\",\"terminal\",\"chemicals\",\n              \"spiral\",\"natural\",\"positional\",\"structural\",\"special\",\"yne\",\"chemical\",\"positional\",\n              \"terminal\",\"hormone\",\"functional\",\"animal\",\"agricultural\",\"typical\",\"floral\",\"pharmaceuticals\",\n              \"medical\",\"central\",\"recreational\"}  # Convert ignore list to set\n\nDATA = []\n\n# Iterate over the corpus\nfor sentence in corpus:\n    doc = nlp(sentence)\n\n    entities = []\n\n    # Extract entities\n    for ent in doc.ents:\n        # Check if entity is not in the ignore set\n        if ent.text.lower() not in ignore_set:\n            # Appending to entities in the correct format\n            entities.append([ent.start_char, ent.end_char, ent.label_])\n\n    DATA.append([sentence, {\"entities\": entities}])\n```", "```py\n# Split the data\ntrain_data, valid_data = train_test_split(DATA, test_size=0.2, random_state=42)\n```", "```py\nimport wikipediaapi\n\n# Define your user agent\nuser_agent = \"MyApp/1.0 (your@email)\"\n\n# Initialize Wikipedia API and spaCy\nwiki_wiki = wikipediaapi.Wikipedia(user_agent,'en')\n\n# Function to get Wikipedia article\ndef get_wikipedia_article(page_title):\n    page = wiki_wiki.page(page_title)\n    return page.text if page.exists() else None\n\n# Function to perform NER on text\ndef perform_ner(text):\n    doc = nlp(text)\n    return [(ent.text, ent.label_) for ent in doc.ents]\n```", "```py\n# Query Wikipedia for an article\narticle_title = \"Benzene\"  # Replace with your desired article title\narticle_content = get_wikipedia_article(article_title)\n```", "```py\ndef get_compound_info(compound_name):\n    base_url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name\"\n    response = requests.get(f\"{base_url}/{compound_name}/JSON\")\n    if response.status_code == 200:\n        return response.json()\n    else:\n        return None\ncompound_name = \"benzene\"\ncompound_info = get_compound_info(compound_name)\n```", "```py\n# List of specific chemical compound types\nchemical_compounds = ['alkane', 'alkene', 'alkyne', 'ketone', 'aldehyde', 'alcohol', 'carboxylic acid']\n\n# Function to update 'Chemical Compound' column\ndef update_chemical_compound(row):\n    entity = row['Entity'].lower()\n    if any(compound in entity for compound in chemical_compounds + [c + 's' for c in chemical_compounds]):\n        return 1\n    return row['Correct']\n\n# Apply the function to each row\ndf_unique['Chemical Compound'] = df_unique.apply(update_chemical_compound, axis=1)\n```", "```py\ndf_merged = pd.merge(df_ents2, df_unique[['Entity', 'Chemical Compound']], on='Entity', how='left')\n```", "```py\n# Dropping rows where 'Chemical Compound' is 0\ndf_filtered = df_merged[df_merged['Chemical Compound'] != 0]\n```"]