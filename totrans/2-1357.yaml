- en: 'Introduction to PyTorch: from training loop to prediction'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/introduction-to-pytorch-from-training-loop-to-prediction-a70372764432](https://towardsdatascience.com/introduction-to-pytorch-from-training-loop-to-prediction-a70372764432)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*An introduction to PyTorch’s training loop and general approach to tackle
    the library’s steeper initial learning curve*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@theDrewDag?source=post_page-----a70372764432--------------------------------)[![Andrea
    D''Agostino](../Images/58c7c218815f25278aae59cea44d8771.png)](https://medium.com/@theDrewDag?source=post_page-----a70372764432--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a70372764432--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a70372764432--------------------------------)
    [Andrea D''Agostino](https://medium.com/@theDrewDag?source=post_page-----a70372764432--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a70372764432--------------------------------)
    ·14 min read·Mar 28, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/39bd895d764577c1f195119868a023ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: In this post we will cover how to implement a logistic regression model using
    PyTorch in Python.
  prefs: []
  type: TYPE_NORMAL
- en: '**PyTorch is one of the most famous and used deep learning frameworks** by
    the community of data scientists and machine learning engineers in the world,
    and thus learning this tool becomes an essential step in your learning path if
    you want to build a career in the field of applied AI.'
  prefs: []
  type: TYPE_NORMAL
- en: It joins TensorFlow, another very famous deep learning framework developed by
    Google.
  prefs: []
  type: TYPE_NORMAL
- en: There are no notable fundamental differences, except for the structure and organization
    of their APIs, which can be very different.
  prefs: []
  type: TYPE_NORMAL
- en: While both frameworks allow us to create very complex neural networks, PyTorch
    is generally preferred due to its more *pythonic* style and the freedom it allows
    the developer to integrate custom logic into the software.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the **Sklearn breast cancer dataset**, an open source dataset already
    used previously in some of my previous article to train a binary classification
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal is to explain how to:'
  prefs: []
  type: TYPE_NORMAL
- en: go from a pandas dataframe to PyTorch’s Datasets and DataLoaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: create a neural network for binary classification in PyTorch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: create predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: evaluate the performance of our model with utility functions and matplotlib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use this network to make predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this article **we will have a clear idea of how to create a neural
    network in PyTorch and how the training loop works.**
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Install PyTorch and other dependencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We start our project by creating a virtual environment in a dedicated folder.
  prefs: []
  type: TYPE_NORMAL
- en: Visit this link to learn how to create a virtual environment with Conda.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-set-up-a-development-environment-for-machine-learning-b015a91bda8a?source=post_page-----a70372764432--------------------------------)
    [## How to Set Up a Development Environment for Machine Learning'
  prefs: []
  type: TYPE_NORMAL
- en: How to install, activate, and use a virtual environment for machine learning
    and data science-related tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-set-up-a-development-environment-for-machine-learning-b015a91bda8a?source=post_page-----a70372764432--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Once our virtual environment has been created, we can run the command
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: in the terminal. This command will install the latest version of PyTorch, which
    as of this writing is version 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: Starting a notebook, we can check the library version using `torch.__version__`
    after doing `import torch`.
  prefs: []
  type: TYPE_NORMAL
- en: We can verify that PyTorch is correctly installed in the environment by importing
    and launching a small test script, as shown in the official guide.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If the script executes correctly then we are ready to proceed with the project.
    Otherwise I suggest the reader to refer to the official guide located here [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s continue with the installation of the additional dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: Sklearn; `pip install scikit-learn`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas; `pip install pandas`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matplotlib; `pip install matplotlib`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Libraries like Numpy are automatically install when you install PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: Import and explore the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s start by importing the installed libraries and breast cancer dataset from
    Sklearn with the following code snippet
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Let’s create a dataframe dedicated to holding our X and y like this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6de5745961fab2ab6db54bbca2a26f6a.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of the dataframe. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to create a model that can predict the target column based on the
    characteristics in the other columns.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go do a minimum of exploratory analysis to get some awareness of the dataset.
    We will use the sweetviz library to automatically create an analysis report.
  prefs: []
  type: TYPE_NORMAL
- en: We can install sweetviz with the command `pip install sweetviz` and create an
    EDA (exploratory data analysis) report with this piece of code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6fad2c75b0b924be07485ffb418ebf66.png)'
  prefs: []
  type: TYPE_IMG
- en: Sweetviz analyzing our dataset. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Sweetviz will create a report right in our notebook for us to explore.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/321ed6120d3081ba0f5b948dc8335335.png)'
  prefs: []
  type: TYPE_IMG
- en: “Association” tab in Sweetviz. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: We see how several columns are highly associated with a value of 0 or 1 of our
    target column.
  prefs: []
  type: TYPE_NORMAL
- en: Being a multidimensional dataset and having variables with different distributions,
    a neural network is a valid option to model this data. That said, this dataset
    can also be modeled by simpler models, such as decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: We will now import two other libraries in order to visualize the dataset. **We**
    **will use PCA (Principal Component Analysis)** from Sklearn and Seaborn to visualize
    the multidimensional dataset.
  prefs: []
  type: TYPE_NORMAL
- en: PCA will help us compress the large number of variables into just two, which
    we will use as the X and Y axis in a Seaborn scatterplot. Seaborn takes an additional
    parameter called *hue* to color the dots based on an additional variable. We will
    use our target.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/49fd8751c34d14f60d7717deed2fa64a.png)'
  prefs: []
  type: TYPE_IMG
- en: PCA projection of the breast cancer dataset. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: We see how class 1 data points group based on common characteristics. It will
    be the goal of our neural network to classify the rows between targets 0 or 1.
  prefs: []
  type: TYPE_NORMAL
- en: Create the datasets and dataloaders classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTorch provides `Dataset` and `DataLoader` objects to allow us to efficiently
    organize and load our data into the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: It would be possible to use pandas directly, but this would have disadvantages
    because it would make our code less efficient.
  prefs: []
  type: TYPE_NORMAL
- en: The `Dataset` class allows us to specify the right format for your data and
    apply the retrieval and transformation logics that are often fundamental (think
    of the data augmentation applied to images).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how to create a PyTorch `Dataset` object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This is a class that inherits from `Dataset` and allows the `DataLoader`, which
    we will create shortly, to efficiently retrieve batches of data.
  prefs: []
  type: TYPE_NORMAL
- en: The class takes X and y as input.
  prefs: []
  type: TYPE_NORMAL
- en: Training, validation and test datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before proceeding to the following steps, it is important to create training,
    validation and test sets.
  prefs: []
  type: TYPE_NORMAL
- en: These will help us evaluate the performance of our model and understand the
    quality of the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: For the interested reader, I suggest reading the article [6 Things You Should
    Do Before Training Your Model](https://medium.com/towards-data-science/6-things-you-should-do-before-training-your-model-51703ab5e125)
    and [what is cross-validation in machine learning](https://medium.com/towards-data-science/what-is-cross-validation-in-machine-learning-14d2a509d6a5)
    to better understand why splitting our data into three partitions is an effective
    method for performance evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: With Sklearn this becomes easy with the `train_test_split` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: With this small snippet of code we created our training, validation and test
    sets according to controllable splits.
  prefs: []
  type: TYPE_NORMAL
- en: Data normalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When doing deep learning, even for a simple task like binary classification,
    it is always necessary to normalize our data.
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing means bringing all the values of the various columns in the dataset
    to the same numerical scale. This helps the neural network converge more effectively
    and thus make accurate predictions faster.
  prefs: []
  type: TYPE_NORMAL
- en: We will use Sklearn’s `StandardScaler`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Notice how `fit_trasform` is applied only to the training set, while `transform`
    is applied to the other two datasets. This is to avoid *data leakage* — when information
    from our validation or test set is unintentionally leaked into our training set.
    We want our training set to be the only source of learning, unaffected by test
    data.
  prefs: []
  type: TYPE_NORMAL
- en: This data is now ready to be input to the `BreastCancerDataset` class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We import the dataloader and initialize the objects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The power of the `DataLoader` is that it allows us to specify whether to shuffling
    our data and in what number of batches the data should be supplied to the model.
    **The batch size is to be considered a hyperparameter** of the model and therefore
    can impact the results of our inferences.
  prefs: []
  type: TYPE_NORMAL
- en: Neural network implementation in PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating a model in PyTorch might sound complex, but it really only requires
    understanding a few basic concepts.
  prefs: []
  type: TYPE_NORMAL
- en: When writing a model in PyTorch, we will use an **object-based approach**, like
    with datasets. It means that we will create a class like class `MyModel` which
    inherits from PyTorch’s `nn.Module` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: PyTorch is an autodifferentiation software. It means that when we write a neural
    network based on the backpropagation algorithm, the calculation of the derivatives
    to calculate the loss is done automatically behind the scenes. This requires writing
    some dedicated code that might get confusing the first time around.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I advise the reader who wants to know the basics of how neural networks work
    to consult the article Introduction to neural networks — weights, biases and activation
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/mlearning-ai/introduction-to-neural-networks-weights-biases-and-activation-270ebf2545aa?source=post_page-----a70372764432--------------------------------)
    [## Introduction to neural networks — weights, biases and activation'
  prefs: []
  type: TYPE_NORMAL
- en: How a neural network learns through a weights, bias and activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/mlearning-ai/introduction-to-neural-networks-weights-biases-and-activation-270ebf2545aa?source=post_page-----a70372764432--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: That said, let’s see what the code for writing a logistic regression model looks
    like.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Our class inherits from `nn.Module`. This class provides the methods behind
    the scenes that make the model work.
  prefs: []
  type: TYPE_NORMAL
- en: __init__ method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `__init__` method of a class contains the logic that runs when instantiating
    a class in Python. Here we pass two arguments: the number of features and the
    number of classes to predict.'
  prefs: []
  type: TYPE_NORMAL
- en: '`num_features` corresponds to the number of columns that make up our dataset
    minus our target variable, while `num_classes` corresponds to the number of results
    that the neural network must return.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the two arguments and their class variables, we see the `super().__init__()`
    line. The super function initializes the init method of the parent class. This
    allows us to have the functionality of `nn.Module` within our model.
  prefs: []
  type: TYPE_NORMAL
- en: Always in the init block, we implement a linear layer called `self.linear1`,
    which takes as arguments the number of features and the number of results to return.
  prefs: []
  type: TYPE_NORMAL
- en: forward() method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By writing the `forward` method we tell Python to override the same method within
    PyTorch’s `nn.Module` parent class. In fact, this method is called when performing
    a forward pass — that is, when our data passes from one layer to another.
  prefs: []
  type: TYPE_NORMAL
- en: '`forward` accepts input *x* which contains the features on which the model
    will calibrate its performance.'
  prefs: []
  type: TYPE_NORMAL
- en: The input passes through the first layer, creating the `logits` variable. The
    logits are the neural network calculations that are not yet converted into probabilities
    by the final activation function, which in this case is a sigmoid. In fact, they
    are the internal representation of the neural network before being mapped to a
    function that allows it to be interpreted.
  prefs: []
  type: TYPE_NORMAL
- en: In this case the sigmoid function will map the logits to probabilities between
    0 and 1\. If the output is less than 0, then the class will be 0 otherwise it
    will be 1\. This happens in the line `self.probs = torch.sigmoid(x)`.
  prefs: []
  type: TYPE_NORMAL
- en: Utility functions for plotting and accuracy calculation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s create utility functions to use in the training loop that we will see
    shortly. These two are used to compute the accuracy at the end of each epoch and
    to display the performance curves at the end of the training.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Model training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we come to the part where most deep learning newcomers struggle: the PyTorch
    training loop.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the code and then comment it
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Unlike TensorFlow, PyTorch requires us to write a training loop in pure Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see the procedure step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: We instantiate the model and the optimizer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We decide on a number of epochs
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We create a for loop that iterates through the epochs
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each epoch, we set the model to training mode with `model.train()` and cycle
    through the `train_loader`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each batch of the `train_loader`, calculate the loss, bring the calculation
    of the derivatives to 0 with `optimizer.zero_grad()` and update the weights of
    the network with `optimizer.step()`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point the training loop is complete, and if you want you can integrate
    the same logic on the validation dataloader as written in the code.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the result of the training after the launch of this code
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8b039bdc7a62f8aa7aebf2d91394de93.png)'
  prefs: []
  type: TYPE_IMG
- en: Training in progress. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Neural network performance evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We use the previously created utility function to plot loss in training and
    validation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/da44d373ae986d30b40f3f83af8bb26f.png)'
  prefs: []
  type: TYPE_IMG
- en: Performances of the neural network. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Our binary classification model quickly converges to high accuracy, and we see
    how the loss drops at the end of each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset turns out to be simple to model and the low number of examples does
    not help to see a more gradual convergence towards high performance by the network.
  prefs: []
  type: TYPE_NORMAL
- en: I emphasize that it is possible to integrate the *TensorBoard* software into
    PyTorch to be able to log performance metrics automatically between the various
    experiments.
  prefs: []
  type: TYPE_NORMAL
- en: Create predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have reached the end of this guide. Let’s see the code to create predictions
    for our entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s import the `metrics` package from Sklearn which allows us to quickly
    calculate the confusion matrix and classification report directly on our pandas
    dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ba65cf7b416913d92c62633c77ee824a.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary of performance on the entire dataset with a classification report. Image
    by author.
  prefs: []
  type: TYPE_NORMAL
- en: And the confusion matrix, which shows the number of correct answers on the diagonal
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here is a small function to create a classification line that separates the
    classes in the PCA graph
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: And here’s how the model separates benign from malignant cells
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c5978be235283290009ada45213ed782.png)'
  prefs: []
  type: TYPE_IMG
- en: Classification boundary visualized. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article we have seen how to create a binary classification model with
    PyTorch, starting from a Pandas dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve seen what the training loop looks like, how to evaluate the model, and
    how to create predictions and visualizations to aid interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: With PyTorch it is possible to create very complex neural networks … just think
    that Tesla, the manufacturer of electric cars based on AI, uses PyTorch to create
    its models.
  prefs: []
  type: TYPE_NORMAL
- en: For those who want to start their deep learning journey, learning PyTorch as
    early as possible becomes a high priority task as it allows you to build important
    technologies that can solve complex data-driven problems.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you want to support my content creation activity, feel free to follow
    my referral link below and join Medium’s membership program**. I will receive
    a portion of your investment and you’ll be able to access Medium’s plethora of
    articles on data science and more in a seamless way.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@theDrewDag/membership?source=post_page-----a70372764432--------------------------------)
    [## Join Medium with my referral link - Andrea D''Agostino'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Andrea D'Agostino (and thousands of other writers on Medium).
    Your membership fee directly…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@theDrewDag/membership?source=post_page-----a70372764432--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Recommended Reads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the interested, here are a list of books that I recommended for each ML-related
    topic. There are ESSENTIAL books in my opinion and have greatly impacted my professional
    career.
  prefs: []
  type: TYPE_NORMAL
- en: '*Disclaimer: these are Amazon affiliate links. I will receive a small commission
    from Amazon for referring you these items. Your experience won’t change and you
    won’t be charged more, but it will help me scale my business and produce even
    more content around AI.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Intro to ML:** [*Confident Data Skills: Master the Fundamentals of Working
    with Data and Supercharge Your Career*](https://amzn.to/3ZzKTz6)by Kirill Eremenko'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sklearn / TensorFlow:** [*Hands-On Machine Learning with Scikit-Learn, Keras,
    and TensorFlow*](https://amzn.to/433F4Nm) by Aurelien Géron'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NLP:** [*Text as Data: A New Framework for Machine Learning and the Social
    Sciences*](https://amzn.to/3zvH43j)by Justin Grimmer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sklearn / PyTorch:** [*Machine Learning with PyTorch and Scikit-Learn: Develop
    machine learning and deep learning models with Python*](https://amzn.to/3Gcavve)
    by Sebastian Raschka'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Viz:** [*Storytelling with Data: A Data Visualization Guide for Business
    Professionals*](https://amzn.to/3HUtGtB) by Cole Knaflic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Useful Links (written by me)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Learn how to perform a top-tier Exploratory Data Analysis in Python:** [*Exploratory
    Data Analysis in Python — A Step-by-Step Process*](/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learn the basics of TensorFlow:** [*Get started with TensorFlow 2.0 — Introduction
    to deep learning*](https://medium.com/towards-data-science/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Perform text clustering with TF-IDF in Python:** [*Text Clustering with TF-IDF
    in Python*](https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
