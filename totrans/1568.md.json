["```py\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\npreprocessed_text = \"translate English to German: the weather is good\"\ntokenizer = T5Tokenizer.from_pretrained('t5-base',\n                                        max_length=64,\n                                        model_max_length=512,\n                                        legacy=False)\ntokens = tokenizer.encode(preprocessed_text,\n                          return_tensors=\"pt\",\n                          max_length=512,\n                          truncation=True)\n\nmodel = T5ForConditionalGeneration.from_pretrained('t5-base')\noutputs = model.generate(tokens, min_length=4, max_length=32)\n\nprint(\"Result:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n\n#> Result: Das Wetter ist gut.\n```", "```py\nfrom transformers import pipeline\n\ntranslator = pipeline(\"translation_en_to_de\", model=\"t5-base\")\nprint(translator(\"the weather is good\"))\n\n#> [{'translation_text': 'Das Wetter ist gut.'}] \n```", "```py\nbody = '''Obviously, the lunar surface is covered with craters, left \nfrom previous collisions of meteorites with the Moon. Where does math go? \nWhile a meteorite collision is a random event, its frequency \nobeys probability theory laws. There is no atmosphere on the Moon's \nsurface, no erosion, and no wind. Therefore the lunar surface is an \nideal \"book\" in which the events of the last tens of thousands of \nyears are recorded. By studying the Moon, we can calculate how often \nsuch objects fall on its surface.\n\nA study of the lunar surface with high-resolution cameras is ongoing. \nIt has been estimated that at least 220 new craters have formed on the \nMoon over the past 7 years. This check is also vital because \nthese calculations can help assess the danger to the Earth.'''\n\npreprocessed_text = f\"summarize: {body}\"\n\ntokenizer = T5Tokenizer.from_pretrained('t5-base', \n                                        max_length=256,\n                                        model_max_length=512,\n                                        legacy=False)\ntokens = tokenizer.encode(preprocessed_text,\n                          return_tensors=\"pt\",\n                          max_length=256,\n                          truncation=True)\n\nmodel = T5ForConditionalGeneration.from_pretrained('t5-base')\noutputs = model.generate(tokens,\n                         min_length=4,\n                         max_length=64)\n\nprint(\"Result:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n\n#> the lunar surface is an ideal \"book\" in which the events of the last \n#> tens of thousands of years are recorded. by studying the Moon, we can \n#> calculate how often such objects are falling on its surface.\n```", "```py\nsummarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\")\nsummarizer(body, min_length=4, max_length=64)\n\n#> [{'summary_text': 'the lunar surface is an ideal \"book\" in which the \n#>  events of the last tens of thousands of years are recorded . it has been\n#>  estimated that at least 220 new craters have formed on the Moon over the \n#>  past 7 years .'}]\n```", "```py\nfor prefix in model.config.task_specific_params:\n    print(f\"{prefix}: {model.config.task_specific_params[prefix]}\")\n\n#> summarization: \n#>   {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 200, 'min_length': 30, 'no_repeat_ngram_size': 3, 'num_beams': 4, 'prefix': 'summarize: '}\n#> translation_en_to_de: \n#>   {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to German: '}\n#> translation_en_to_fr: \n#>   {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to French: '}\n#> translation_en_to_ro: \n#>   {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to Romanian: '}\n```", "```py\nbody = '''Obviously, the lunar surface is covered with craters, left \nfrom previous collisions of meteorites with the Moon. Where does math go? \nWhile a meteorite collision is a random event, its frequency \nobeys probability theory laws. There is no atmosphere on the Moon's \nsurface, no erosion, and no wind. Therefore the lunar surface is an \nideal \"book\" in which the events of the last tens of thousands of \nyears are recorded. By studying the Moon, we can calculate how often \nsuch objects fall on its surface.\n\nA study of the lunar surface with high-resolution cameras is ongoing. \nIt has been estimated that at least 220 new craters have formed on the \nMoon over the past 7 years. This check is also vital because \nthese calculations can help assess the danger to the Earth.'''\n\nquestion_answerer = pipeline(\"question-answering\",\n                             model='distilbert-base-cased-distilled-squad')\n\nresult = question_answerer(question=\"Which surface has collision with meteorites\",\n                           context=body)\nprint(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n\n#> Answer: 'the Moon', score: 0.4401, start: 93, end: 101\n\nresult = question_answerer(question=\"How many craters were formed\",\n                           context=body)\nprint(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n\n#> Answer: 'at least 220', score: 0.5302, start: 600, end: 612\n\nresult = question_answerer(question=\"Is there atmosphere on the moon\",\n                           context=body)\nprint(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n\n#> Answer: 'There is no', score: 0.2468, start: 220, end: 231\n```", "```py\nfrom transformers import GPT2Config, GPT2Model,\n                         TFGPT2LMHeadModel, GPT2Tokenizer\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ninput_ids = tokenizer.encode(\"I am going to say\",\n                             return_tensors='tf')\nmodel = TFGPT2LMHeadModel.from_pretrained(\"gpt2\",\n                                  pad_token_id=tokenizer.eos_token_id)\noutput = model.generate(input_ids,\n                        max_length=128,\n                        early_stopping=True,\n                        do_sample=True,\n                        top_k=20)\nprint(\"Output:\", tokenizer.decode(output[0], skip_special_tokens=True))\n\n#> Output: I am going to say something. It is very hard for people to \n#> believe me because I do not have to speak English. But the fact that \n#> you are writing a book on it is one thing. You have to have this \n#> knowledge which is not from what you read; it is from an educated...\n```", "```py\nfrom transformers import pipeline\n\ngenerator = pipeline('text-generation', model='gpt2')\ngenerator(\"I am going to say\", max_length=128, num_return_sequences=1)\n\n#> I am going to say this: I have had several bad experiences with the \n#> internet in the years since my first connection. While there ...\n```", "```py\nAm going to say that communication is a vital skill in today's interconnected\nworld. Whether it's expressing your thoughts and ideas, building relationships,\nor resolving conflicts, effective communication plays a central role in almost\nevery aspect of our lives. It's not just about the words we use but also our\ntone, body language, and the context in which we communicate.\n```", "```py\nfrom transformers import pipeline\n\nsentiment_pipeline = pipeline(\"sentiment-analysis\",\n                         model='distilbert-base-uncased-finetuned-sst-2-english')\ndata = [\"It was not bad\",\n        \"I expected to love it but I was wrong\"]\nsentiment_pipeline(data)\n\n#> [{'label': 'POSITIVE', 'score': 0.9995607733726501},\n#>  {'label': 'NEGATIVE', 'score': 0.997614860534668}]\n```", "```py\nfrom transformers import pipeline\n\nbody = \"Hi, my name is Dmitrii. I am in London, I work in Super Company, \" \\\n       \"I have a question about the hotel reservation.\"\n\nner = pipeline(\"ner\",\n               model=\"dslim/bert-base-NER\",\n               aggregation_strategy='average')\nner(body)\n\n#> [{'entity_group': 'PER',\n#>  'score': 0.7563127,\n#>  'word': 'Dmitrii',\n#>  'start': 15,\n#>  'end': 22},\n#> {'entity_group': 'LOC',\n#>  'score': 0.99956125,\n#>  'word': 'London',\n#>  'start': 32,\n#>  'end': 38},\n#> {'entity_group': 'ORG',\n#>  'score': 0.99759734,\n#>  'word': 'Super Company',\n#>  'start': 50,\n#>  'end': 63}]\n```", "```py\nfrom keybert import KeyBERT\n\nbody = \"Hi, my name is Dmitrii. I am in London, I work in Super Company, \" \\\n       \"I have a question about the hotel reservation.\"\n\nkw_model = KeyBERT()\nkeywords = kw_model.extract_keywords(body,\n                                     keyphrase_ngram_range=(1, 1),\n                                     diversity=0.8,\n                                     stop_words=None)\nprint(keywords)\n\n#> [('reservation', 0.5935), ('hotel', 0.5729), ('london', 0.2705), \n#>  ('dmitrii', 0.2), ('company', 0.1817)]\n```"]