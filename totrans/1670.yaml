- en: Practical Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4](https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tips and tricks for successful prompting with LLMs…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    ·15 min read·Jul 30, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e25abf0c0a3c6577a9a7741aa923ce0d.png)'
  prefs: []
  type: TYPE_IMG
- en: (Photo by [Jan Kahánek](https://unsplash.com/@honza_kahanek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/g3O5ZtRk2E4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  prefs: []
  type: TYPE_NORMAL
- en: Due to their text-to-text format, large language models (LLMs) are capable of
    solving a wide variety of tasks with a single model. Such a capability was originally
    demonstrated via zero and few-shot learning with models like [GPT-2](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)
    and [GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [5, 6]. When fine-tuned to align with human preferences and instructions, however,
    LLMs become even more compelling, enabling popular generative applications such
    as [coding assistants](https://cameronrwolfe.substack.com/i/93578656/evaluating-large-language-models-trained-on-code),
    [information-seeking dialogue agents](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback),
    and [chat-based search experiences](http://microsoft.com/en-us/bing?form=MW00X7&ef_id=_k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&OCID=AIDcmmf8m4fdss_SEM__k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&gclid=Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB&ch=).
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to the applications that they make possible, LLMs have seen a quick rise
    to fame both in research communities and popular culture. During this rise, we
    have also witnessed the development of a new, complementary field: *prompt engineering*.
    At a high-level, LLMs operate by *i)* taking text (i.e., a prompt) as input and
    *ii)* producing textual output from which we can extract something useful (e.g.,
    a classification, summarization, translation, etc.). The flexibility of this approach
    is beneficial. At the same time, however, we must determine how to properly construct
    out input prompt such that the LLM has the best chance of generating the desired
    output.'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering is an empirical science that studies how different prompting
    strategies can be use to optimize LLM performance. Although a variety of approaches
    exist, we will spend this overview building an understanding of the general mechanics
    of prompting, as well as a few fundamental (but incredibly effective!) prompting
    techniques like zero/few-shot learning and instruction prompting. Along the way,
    we will learn practical tricks and takeaways that can immediately be adopted to
    become a more effective prompt engineer and LLM practitioner.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1a0220b74f6f1c01275c291596366bf2.png)'
  prefs: []
  type: TYPE_IMG
- en: (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Understanding LLMs.** Due to its focus upon prompting, this overview will
    not explain the [history](https://twitter.com/cwolferesearch/status/1639378997627826176?s=20)
    or [mechanics](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)
    of language models. To gain a better general understanding of language models
    (which is an important prerequisite for deeply understanding prompting), I’ve
    written a variety of overviews that are available. These overviews are listed
    below (in order of importance):'
  prefs: []
  type: TYPE_NORMAL
- en: Language Modeling Basics (GPT and GPT-2) [[link](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Importance of Scale for Language Models (GPT-3) [[link](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modern [[link](https://cameronrwolfe.substack.com/p/modern-llms-mt-nlg-chinchilla-gopher)]
    and Specialized [[link](https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica)]
    LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PaLM](https://cameronrwolfe.substack.com/p/palm-efficiently-training-massive),
    T5 (Part [One](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part)
    and [Two](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part-354)),
    LLaMA (Part [One](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone)
    and [Two](https://cameronrwolfe.substack.com/p/beyond-llama-the-power-of-open-llms))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompting at a Glance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/914b11eef522b79e77115962b7e15d3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Language models can solve a variety of tasks using their generic, text-to-text
    format (from [1])
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the current hype around LLMs, we might ask ourselves: *what are the fundamental
    strengths of LLMs that make them so powerful?* Although there’s not a single answer
    to this question (e.g., [model scale](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners),
    [massive pre-training data](https://cameronrwolfe.substack.com/i/91134599/training-compute-optimal-llms),
    [human feedback](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback),
    etc.), one major strength of LLMs is their generic, text-to-text format. These
    models are experts at [next-token prediction](https://cameronrwolfe.substack.com/i/85568430/language-modeling),
    and so many different tasks can be solved by properly tuning and leveraging this
    skill!'
  prefs: []
  type: TYPE_NORMAL
- en: To solve a task, all we need to do is *i)* provide textual input to the model
    that contains relevant information and *ii)* extract output from text returned
    by the model. Such a unified approach can be used for translation, summarization,
    question answering, classification, and more. However, the story is not (quite)
    that simple. Namely, the wording and structure of the prompt (i.e., the inputted
    text) provided to the LLM can significantly impact the model’s accuracy. In other
    words, *prompt engineering is a huge deal.*
  prefs: []
  type: TYPE_NORMAL
- en: What is prompt engineering?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “Prompt engineering is a relatively new discipline for developing and optimizing
    prompts to efficiently use LMs for a wide variety of applications and research
    topics.” *— from [2]*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Given that properly crafting the contents of our prompt is important to achieving
    useful results with an LLM, prompt engineering has gained a lot of interest in
    recent months. However, it’s an empirical science — discovering the best-possible
    prompts is typically heuristic-based and requires experimentation. We can discover
    better prompts by [tracking and versioning](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)
    our prompts over time and testing different ideas to see what works.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/149b3b2fec56875d26509c1e39e0b80c.png)'
  prefs: []
  type: TYPE_IMG
- en: Prompting an LLM with instructions (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Components of a prompt.** There are a variety of options for how a prompt
    can be created. However, most prompts are comprised of the same few (optional)
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Input Data*: this is the actual data that the LLM is expected to process (e.g.,
    the sentence being translated or classified, the document being summarized, etc.).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exemplars*: one of the best ways to demonstrate the correct behavior to an
    LLM is to provide a few concrete examples of input-output pairs inside of the
    prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Instruction*: instead of showing concrete exemplars of correct behavior in
    the prompt, we could just textually describe what to do via an instruction; see
    above.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Indicators*: providing input to an LLM in a fixed and predictable structure
    is helpful, so we might separate different parts of our prompt by using indicators;
    see below.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Context*: Beyond the components described above, we may want to provide extra
    “context” or information to the LLM in some way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d06bf9cbd0b01696444f4cfcd782607e.png)'
  prefs: []
  type: TYPE_IMG
- en: Indicators can be used to structure prompts in a variety of ways (created by
    author)
  prefs: []
  type: TYPE_NORMAL
- en: '**General tips.** The details of prompt engineering differ a lot depending
    on the model being used and what task we are trying to solve. However, there are
    a few generally-accepted principles for prompt engineering that are helpful to
    keep in mind [1, 3].'
  prefs: []
  type: TYPE_NORMAL
- en: '*Start simple*: start with a simple prompt, then slowly modify the prompt while
    tracking empirical results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Be direct*: if we want the LLM to match a specific style or format, we should
    state this clearly and directly. Stating exactly what you want gets the message
    across.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Specificity*: ambiguity is the enemy of every prompt engineer. We should make
    the prompt detailed and specific without going overboard and providing an input
    that is too long (i.e., there are [limitations](https://platform.openai.com/docs/models/gpt-3)
    to how long the prompt can be!).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exemplars are powerful*: if describing what we want is difficult, it might
    be useful to provide concrete examples of correct output or behavior for several
    different inputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/bf8809fbbb1b85d1a059cf3740534820.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualizing the context window for a language model (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**The context window.** As we consider different prompting tips and approaches,
    we need to remember that we can only include a limited amount of information in
    our prompt. All LLMs have a pre-defined context window that sets a limit on the
    total number of tokens (i.e., words or sub-words in a textual sequence) that can
    be processed at a time. Context window size differs between models, but there
    is currently a strong push towards increasing context window sizes. For example,
    GPT-4 has a context window of 32K tokens, which is [4X bigger](https://platform.openai.com/docs/models/overview)
    than any prior model from OpenAI.'
  prefs: []
  type: TYPE_NORMAL
- en: Common Prompting Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/3220b2cdf3baa56668d27fc8f96bcc47.png)'
  prefs: []
  type: TYPE_IMG
- en: The emergence of zero and few-shot learning (from [4, 5, 6])
  prefs: []
  type: TYPE_NORMAL
- en: Although LLMs have seen a recent explosion due to popular models like [ChatGPT](https://openai.com/blog/chatgpt),
    prompting has been around [for a while](https://twitter.com/cwolferesearch/status/1639378997627826176?s=20).
    Originally, models like [GPT](https://cameronrwolfe.substack.com/i/85568430/improving-language-understanding-by-generative-pre-training-gpt)
    [4] were fine-tuned to solve downstream tasks. With the proposal of [GPT-2](https://cameronrwolfe.substack.com/i/85568430/language-models-are-unsupervised-multitask-learners-gpt)
    [5], we saw researchers start to use zero-shot learning to solve multiple downstream
    tasks with a single [foundation model](https://cameronrwolfe.substack.com/i/85568430/creating-foundation-models).
    Finally, GPT-3 showed us that language models become really good at few-shot learning
    as they grow in size. In this section, we will walk through these ideas to gain
    a better idea of how zero and few-shot learning work, as well as provide details
    on a few more complex prompting techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-Shot Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/d32631e3be2a49eae91f90c24acb9602.png)'
  prefs: []
  type: TYPE_IMG
- en: (from [6])
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind zero-shot learning is quite simple. We just feed a description
    of the task being solved and the relevant input data to an LLM and let it generate
    a result; see above. Due to the massive amount of pre-training data they observe,
    LLMs are often pretty capable of solving tasks in this way. Namely, they can leverage
    their knowledge base to solve a (relatively) large number of tasks; see the examples
    below (produced with [GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/079e9678916528832a844a0673085c3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Zero-shot learning with GPT-3.5 (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot learning was explored extensively by models like GPT-2 and performs
    well in some cases. However, *what should we do if zero-shot learning does not
    solve our task?* In many cases, we can drastically improve the performance of
    an LLM by providing more specific and concrete information. In particular, we
    can start adding examples of desired output to the prompt, allowing the model
    to replicate patterns from data seen in the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Few-Shot Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Beyond just a task description, we can augment our prompt with high-quality
    input-output examples. This technique forms the basis of few-shot learning, which
    attempts to improve LLM performance by providing explicit examples of correct
    behavior. If used properly and applied to the correct model, few-shot learning
    is incredibly effective, as demonstrated by the breakthrough capabilities of LLMs
    like [GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [6]; see below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8760cfa248087a2512e44e35d54cea13.png)'
  prefs: []
  type: TYPE_IMG
- en: (from [3])
  prefs: []
  type: TYPE_NORMAL
- en: However, learning how to properly leverage the few-shot learning capabilities
    of LLMs can be complicated. *What examples should we include in the prompt? Is
    there a correct way to structure the prompt? Do changes to the prompt significantly
    affect the LLM?*
  prefs: []
  type: TYPE_NORMAL
- en: 'Most LLMs are sensitive to the manner in which the prompt is constructed, making
    prompt engineering both difficult and important. Although recent models like GPT-4
    seem to be less sensitive to small perturbations in the prompt [2], the research
    community [7] has provided us with some tips for properly using few-shot learning
    that are still helpful to understand:'
  prefs: []
  type: TYPE_NORMAL
- en: Exemplar ordering is important, and permuting few-shot examples can drastically
    change LLM performance. Including more few-shot examples does not solve this problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The distribution of labels in the few-shot examples matters and should match
    the actual distribution of data in the wild. Surprisingly, the correctness of
    labels is not as important.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs tend to be biased towards repeating the last of the few-shot examples (i.e.,
    recency bias).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exemplars that are included in the prompt should be diverse and randomly ordered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimal data sampling.** Selecting examples that are diverse, randomly-ordered,
    and related to the test example is best. Beyond these basic intuitions, however,
    a significant amount of research has been done to determine how to select optimal
    exemplars for a prompt. For example, few-show learning samples can be chosen via
    diversity selection [8], uncertainty-based selection [9], or even selection based
    on similarity to the test example [10].'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/727b0fd0968d79861e6d9f4d24bec555.png)'
  prefs: []
  type: TYPE_IMG
- en: (from [3])
  prefs: []
  type: TYPE_NORMAL
- en: '**Few-shot learning vs. fine-tuning.** Prior to moving on, I want to address
    a notable [point of confusion](https://twitter.com/NaveenGRao/status/1650255798365462530?s=20).
    *Few-shot learning is not fine-tuning.* Few-shot learning presents examples to
    the LLM inside of the prompt, which can then be used as relevant context for generating
    the correct output. This process is referred to as “in-context learning”; see
    above. The model’s parameters are not modified by few-shot learning. In contrast,
    fine-tuning explicitly trains the model (i.e., updates its weights via backpropagation)
    over a chosen dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Instruction Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/912eb44c92e90896a71a5e7ddd886249.png)'
  prefs: []
  type: TYPE_IMG
- en: Using an instruction tuned language model as a coding assistant (from [15])
  prefs: []
  type: TYPE_NORMAL
- en: 'Few-shot learning is incredibly powerful, but it has a notable drawback: *exemplars
    consume a lot of tokens*. Given that the context window of an LLM is limited,
    we might want to explore prompting methods that do not consume as many tokens.
    For example, *can we textually explain the correct behavior to an LLM?* The short
    answer is yes! This technique, which just includes a written instruction as part
    of the prompt, is known as instruction prompting, and it performs best with a
    particular type of LLM.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Instruction tuning and alignment.** Recent development of language models
    has heavily focused upon improving instruction following capabilities. Pre-trained
    LLMs are not good at following instructions out-of-the-box. However, teaching
    these models how to follow instructions makes them a lot better at accomplishing
    what the user wants (i.e., improves human [alignment](https://openai.com/blog/our-approach-to-alignment-research)).
    Instruction following LLMs power a variety of useful applications from information
    seeking dialogue agents (e.g., [ChatGPT](https://openai.com/blog/chatgpt)) to
    coding assistants (e.g., [Codex](https://cameronrwolfe.substack.com/i/93578656/evaluating-large-language-models-trained-on-code)
    [13]); see below.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3d74e918539cfd634dc24318e08a6f7c.png)'
  prefs: []
  type: TYPE_IMG
- en: (from [13, 14])
  prefs: []
  type: TYPE_NORMAL
- en: As has been [discussed extensively](https://cameronrwolfe.substack.com/i/91134599/a-primer-on-language-modeling)
    in prior posts, the first step in creating an LLM is pre-training the model using
    a [language modeling objective](https://cameronrwolfe.substack.com/i/85568430/language-modeling)
    over a large, unlabeled corpus of text. During this process, the model gains information
    and learns to accurately perform next-token prediction. However, the model’s output
    is not always interesting, compelling, or helpful, and the model usually struggles
    to comply with complex instructions. To encourage such behavior, we need to go
    [beyond basic pre-training](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20).
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating instruction-following LLMs.** There are a couple of different approaches
    for teaching an LLM how how to follow instructions. For example, we can perform
    [instruction tuning](https://twitter.com/cwolferesearch/status/1652064977493057545?s=20)
    [12], or fine-tune the LLM over examples of dialogues that include instructions.
    Several notable models adopt this approach, such as [LLaMA](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone)
    (and [its variants](https://cameronrwolfe.substack.com/p/beyond-llama-the-power-of-open-llms))
    [15], all FLAN models [12], OPT-IML [16], and more. Alternatively, we could use
    the [three-step approach](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    comprised of [supervised fine-tuning (SFT)](https://cameronrwolfe.substack.com/i/93578656/refining-llm-behavior)
    and reinforcement learning from human feedback (RLHF); see below. This methodology
    has led to the creation of incredible models such as ChatGPT, [GPT-4](https://openai.com/research/gpt-4),
    [Sparrow](https://cameronrwolfe.substack.com/i/93578656/improving-alignment-of-dialogue-agents-via-targeted-human-judgements)
    [17], and more.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1930f6d4b45842bdbc6598b6d91273d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Aligning LLMs based on human feedback (from [13])
  prefs: []
  type: TYPE_NORMAL
- en: '**crafting useful instructions.** If we have access to an LLM that has been
    trained to follow instructions, we can accomplish a lot by prompting the model
    with useful and informative instructions. Here are some key tips and ideas for
    using instruction prompting:'
  prefs: []
  type: TYPE_NORMAL
- en: Just like the rest of our prompt, the instruction should be specific and detailed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We should avoid telling the LLM to not do something in the prompt. Rather, we
    should focus on telling the LLM what to do.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an input structure with indicators that clearly identify the instruction
    within the prompt is helpful; see below.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/cd645bcd6b8e83cf78f6877c427a45fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Different formats for instruction prompting (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Role prompting.** Another interesting prompting technique that is tangentially
    related to instruction prompting is role prompting, which assigns a “role” or
    persona to the model. This role is assigned within the prompt via a textual snippet
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: You are a famous and brilliant mathematician.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are a doctor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are a musical expert.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interestingly, recent LLMs are able to assume and maintain such roles quite
    well throughout a dialogue [18]; see below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9565b160964aebf82c685d04680e4931.png)'
  prefs: []
  type: TYPE_IMG
- en: Role prompting with LaMDA (from [18])
  prefs: []
  type: TYPE_NORMAL
- en: Going further, role prompting isn’t just a fun trick. Providing a role to the
    LLM can actually improve performance (e.g., role prompting GPT-3 as a “brilliant
    mathematician” can [improve performance](https://learnprompting.org/docs/basics/roles)
    on arithmetic-based questions). However, role prompting only improves performance
    in certain cases.
  prefs: []
  type: TYPE_NORMAL
- en: “When assigning a role to the AI, we are giving it some context. This context
    helps the AI understand the question better. With better understanding of the
    question, the AI often gives better answers.” *— from* [*learnprompting.org*](https://learnprompting.org/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Instruction prompting in the real world.** Prompting LLMs with instructions
    is an incredibly powerful tool that we can use for a variety of applications.
    To understand how to leverage this technique, we can look no further than the
    recent release of [ChatGPT plugins](https://openai.com/blog/chatgpt-plugins),
    which included an open-source [information retrieval API](https://github.com/openai/chatgpt-retrieval-plugin).
    Inside of this API, there are two specific modules provided for [extracting metadata
    from documents](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/services/extract_metadata.py)
    and [filtering personally identifiable information (PII)](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/services/pii_detection.py).
    Interestingly, these services are entirely LLM-based and use the prompts shown
    below.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/59bb362f9965d9a835e81c103b770630.png)'
  prefs: []
  type: TYPE_IMG
- en: Prompts for metadata extraction and PII detection in the ChatGPT information
    retrieval API (created by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Within these prompts, the LLM is provided with specific and detailed instructions
    regarding how to perform its desired task. Some notable aspects of the instructions
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: The desired output format (either json or true/false) is explicitly stated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The instruction uses a structured format (i.e., bullet-separated list) to describe
    important information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The task of the LLM (i.e., identifying PII or extracting metadata) is explicitly
    stated in the prompt.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interestingly, these prompts tell the model what not to do on multiple occasions,
    which is typically advised against.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trusting an LLM to accurately perform critical tasks like PII detection might
    not be the best idea given their limitations. Nonetheless, such an approach demonstrates
    the incredible potential of instruction prompting. Instead of writing an entire
    program or service, we may be able to quickly solve a lot of tasks by just writing
    a prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “Writing a really great prompt for a chatbot persona is an amazingly high-leverage
    skill and an early example of programming in a little bit of natural language”
    *—* [*Sam Altman*](https://twitter.com/sama/status/1627796054040285184?s=20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If we learn nothing else from this overview, we should know that constructing
    the correct prompt (i.e., prompt engineering) is a large part of successfully
    leveraging LLMs in practice. Language models, due to their text-to-text structure,
    are incredibly generic and can be used to solve a variety of tasks. However, we
    must provide these models with detailed and appropriate context for them to perform
    well. Although optimal prompting techniques differ depending on the model and
    tasks, there are many high-level takeaways that we can leverage to maximize chances
    of success.
  prefs: []
  type: TYPE_NORMAL
- en: '**from zero to few-shot learning.** Given their extensive pre-training (and,
    these days, fine-tuning) datasets, LLMs contain a ton of information and are capable
    of solving a variety of tasks out-of-the-box. To do this, we only provide the
    model with a task description and relevant input data, then the model is expected
    to generate the correct output. However, zero-shot learning can only perform so
    well due to the limited context provided to the model. To improve upon the performance
    of zero-shot learning, we should leverage few-show learning by inserting exemplars
    in the prompt.'
  prefs: []
  type: TYPE_NORMAL
- en: '**instruction-following LLMs.** Although it performs well, few-shot learning
    typically consumes a lot of tokens, which is a problem given the limited context
    window of most LLMs. To work around this, we can adopt an instruction prompting
    approach that provides a precise, textual description of the LLM’s desired behavior
    as opposed to capturing this behavior with concrete examples of correct output.
    Instruction prompting is powerful, but it requires a specific form of LLM that
    has been fine-tuned (e.g., via instruction tuning or RLHF) to work well. Pre-trained
    LLMs are not great at following instructions out of the box.'
  prefs: []
  type: TYPE_NORMAL
- en: '**tips and tricks.** Prompt engineering comes with a variety of tricks and
    best practices that can be adopted. Typically, such techniques fluctuate with
    each new model release (e.g., GPT-4 is much better at handling unstructured prompts
    compared to prior models [2]), but a few principles have remained applicable for
    quite some time. First, we should always start with a simple prompt, then slowly
    add complexity. As we develop our prompt, we should aim to be specific and detailed,
    while avoiding being overly verbose (due to the limited context window). Finally,
    to truly maximize LLM performance, we usually need to leverage few-shot learning,
    instruction prompting, or a [more complex approach](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms).'
  prefs: []
  type: TYPE_NORMAL
- en: Closing Remarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. You can also check out my [other
    writings](https://medium.com/@wolfecameron) on medium! If you liked it, please
    follow me on [twitter](https://twitter.com/cwolferesearch) or subscribe to my
    [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/), where
    I help readers build a deeper understanding of topics in AI research via understandable
    overviews of popular papers.
  prefs: []
  type: TYPE_NORMAL
- en: Bibliography
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Raffel, Colin, et al. “Exploring the limits of transfer learning with a
    unified text-to-text transformer.” *The Journal of Machine Learning Research*
    21.1 (2020): 5485–5551.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Saravia, Elvis, et al. “Prompt Engineering Guide”, [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
    (2022).'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Weng, Lilian. (Mar 2023). Prompt Engineering. Lil’Log. [https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Radford, Alec, et al. “Improving language understanding by generative pre-training.”
    (2018).'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Radford, Alec, et al. “Language Models are Unsupervised Multitask Learners.”'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] Brown, Tom, et al. “Language models are few-shot learners.” *Advances in
    neural information processing systems* 33 (2020): 1877–1901.'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021\.
    Calibrate before use: Improving few-shot performance of language models. ICML.'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] Su, Hongjin, et al. “Selective annotation makes language models better
    few-shot learners.” *arXiv preprint arXiv:2209.01975* (2022).'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] Diao, Shizhe, et al. “Active Prompting with Chain-of-Thought for Large
    Language Models.” *arXiv preprint arXiv:2302.12246* (2023).'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] Liu, Jiachang, et al. “What Makes Good In-Context Examples for GPT-$3
    $?.” *arXiv preprint arXiv:2101.06804* (2021).'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] Wei, Jason, et al. “Chain of thought prompting elicits reasoning in large
    language models.” *arXiv preprint arXiv:2201.11903* (2022).'
  prefs: []
  type: TYPE_NORMAL
- en: '[12] Wei, Jason, et al. “Finetuned language models are zero-shot learners.”
    *arXiv preprint arXiv:2109.01652* (2021).'
  prefs: []
  type: TYPE_NORMAL
- en: '[13] Chen, Mark, et al. “Evaluating large language models trained on code.”
    *arXiv preprint arXiv:2107.03374* (2021).'
  prefs: []
  type: TYPE_NORMAL
- en: '[14] Ouyang, Long, et al. “Training language models to follow instructions
    with human feedback.” *Advances in Neural Information Processing Systems* 35 (2022):
    27730–27744.'
  prefs: []
  type: TYPE_NORMAL
- en: '[15] Touvron, Hugo, et al. “Llama: Open and efficient foundation language models.”
    *arXiv preprint arXiv:2302.13971* (2023).'
  prefs: []
  type: TYPE_NORMAL
- en: '[16] Iyer, Srinivasan, et al. “OPT-IML: Scaling Language Model Instruction
    Meta Learning through the Lens of Generalization.” *arXiv preprint arXiv:2212.12017*
    (2022).'
  prefs: []
  type: TYPE_NORMAL
- en: '[17] Glaese, Amelia, et al. “Improving alignment of dialogue agents via targeted
    human judgements.” *arXiv preprint arXiv:2209.14375* (2022).'
  prefs: []
  type: TYPE_NORMAL
- en: '[18] Thoppilan, Romal, et al. “Lamda: Language models for dialog applications.”
    *arXiv preprint arXiv:2201.08239* (2022).'
  prefs: []
  type: TYPE_NORMAL
