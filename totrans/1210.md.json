["```py\nconda create -n chatbot_env\nconda activate chatbot_env\nconda install diffusers transformers accelerate xformers hvplot panel notebook -c pytorch -c conda-forge\n```", "```py\nimport io\n\nimport numpy as np\nimport panel as pn\nimport param\nimport PIL\nimport requests\nimport torch\n\nfrom diffusers import StableDiffusionInstructPix2PixPipeline\n\npn.extension('texteditor', template=\"bootstrap\", sizing_mode='stretch_width')\n```", "```py\nmodel_id = \"timbrooks/instruct-pix2pix\"\n\npipe = pn.state.cache['pipe'] = StableDiffusionInstructPix2PixPipeline.from_pretrained(\n    model_id, torch_dtype=torch.float16\n).to(\"cuda\")\n\ndef normalize_image(value, width):\n    \"\"\"\n    normalize image to RBG channels and to the same size\n    \"\"\"\n    b = io.BytesIO(value)\n    image = PIL.Image.open(b).convert(\"RGB\")\n    aspect = image.size[1] / image.size[0]\n    height = int(aspect * width)\n    return image.resize((width, height), PIL.Image.LANCZOS)\n\ndef new_image(prompt, image, img_guidance, guidance, steps, width=600):\n    \"\"\"\n    create a new image from the StableDiffusionInstructPix2PixPipeline model\n    \"\"\"\n    edit = pipe(\n        prompt,\n        image=image,\n        image_guidance_scale=img_guidance,\n        guidance_scale=guidance,\n        num_inference_steps=steps,\n    ).images[0]\n    return edit\n```", "```py\nfile_input = pn.widgets.FileInput(width=600)\nprompt = pn.widgets.TextEditor(\n    value=\"\", placeholder=\"Enter image editing instruction here...\", height=160, toolbar=False\n)\nimg_guidance = pn.widgets.DiscreteSlider(\n    name=\"Image guidance scale\", options=list(np.arange(1, 10.5, 0.5)), value=1.5\n)\nguidance = pn.widgets.DiscreteSlider(\n    name=\"Guidance scale\", options=list(np.arange(1, 10.5, 0.5)), value=7\n)\nsteps = pn.widgets.IntSlider(\n    name=\"Inference Steps\", start=1, end=100, step=1, value=20\n)\nrun_button = pn.widgets.Button(name=\"Run!\")\n\nwidgets = pn.Row(\n    pn.Column(prompt, run_button, margin=5),\n    pn.Card(\n        pn.Column(img_guidance, guidance, steps),\n        title=\"Advanced settings\", margin=10\n    ), width=600\n)\n```", "```py\n# define global variables to keep track of things\nconvos = []  # store all panel objects in a list\nimage = None\nfilename = None\n\ndef get_conversations(_, img, img_guidance, guidance, steps, width=600):\n    \"\"\"\n    Get all the conversations in a Panel object\n    \"\"\"\n    global image, filename\n    prompt_text = prompt.value\n    prompt.value = \"\"\n\n    # if the filename changes, open the image again\n    if filename != file_input.filename:\n        filename = file_input.filename\n        image = normalize_image(file_input.value, width)\n        convos.clear()\n\n    # if there is a prompt run output\n    if prompt_text:\n        image = new_image(prompt_text, image, img_guidance, guidance, steps)\n        convos.extend([\n            pn.Row(\n                pn.panel(\"\\U0001F60A\", width=10),\n                prompt_text,\n                width=600\n            ),\n            pn.Row(\n                pn.panel(image, align='end', width=500),\n                pn.panel(\"\\U0001F916\", width=10),\n                align='end'\n            )\n        ])\n    return pn.Column(*convos, margin=15, width=575)\n```", "```py\n# bind widgets to functions\ninteractive_upload = pn.panel(pn.bind(pn.panel, file_input, width=575, min_height=400, margin=15))\n\ninteractive_conversation = pn.panel(\n    pn.bind(\n        get_conversations, run_button, file_input, img_guidance, guidance, steps\n    ), loading_indicator=True\n)\n```", "```py\n # layout\npn.Column(\n    \"## \\U0001F60A Upload an image file and start editing!\",\n    file_input,\n    interactive_upload,\n    interactive_conversation,\n    widgets\n).servable(title=\"Panel Stable Diffusion InstructPix2pix Image Editing Chatbot\")\n```"]