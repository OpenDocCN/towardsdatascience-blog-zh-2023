# 通过早期停止改善你的提升算法

> 原文：[https://towardsdatascience.com/improve-your-boosting-algorithms-with-early-stopping-99616bd15d83](https://towardsdatascience.com/improve-your-boosting-algorithms-with-early-stopping-99616bd15d83)

## 概述及Python实现

[](https://medium.com/@aashishnair?source=post_page-----99616bd15d83--------------------------------)[![Aashish Nair](../Images/23f4b3839e464419332b690a4098d824.png)](https://medium.com/@aashishnair?source=post_page-----99616bd15d83--------------------------------)[](https://towardsdatascience.com/?source=post_page-----99616bd15d83--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----99616bd15d83--------------------------------) [Aashish Nair](https://medium.com/@aashishnair?source=post_page-----99616bd15d83--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----99616bd15d83--------------------------------) ·6分钟阅读·2023年5月15日

--

![](../Images/931b4e752e9becf6f9f8aadda8a47114.png)

照片由[Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

提升算法在数据科学领域非常流行，这一点毋庸置疑。结合提升的模型表现出色，这也是它们在学术界和工业界都很常见的原因。

也就是说，如果这些类型的算法没有正确配置，会得到次优结果。

一个常常被低估的特性是**早期停止**。

在这里，我们将对早期停止进行高层次的概述，并解释为何它应当被纳入你的提升算法中。

## 提升回顾

在深入早期停止之前，让我们简要讨论一下提升算法。

简而言之，利用提升的算法会训练一系列顺序模型，每个模型旨在解决前一个模型所犯的错误。

提升算法遵循以下步骤：

1.  训练一个带有初始权重的弱模型

1.  评估第一个模型的“错误”

1.  训练一个新的模型，修改权重以解决前一个模型的问题

1.  评估这个新模型的“错误”

1.  重复步骤3或4，直到满足特定标准（例如，迭代次数、模型性能等）

理论上，提升算法是确定特定模型最优权重的完美解决方案。

毕竟，如果模型不断从之前的错误中学习，执行更多的迭代应该会带来更好的结果。那么，为什么不进行尽可能多的迭代呢？拥有接近无限数量的模型，我们可以实现最佳性能！

不幸的是，通常情况并非如此。

## 更多迭代≠更好

在选择的迭代次数后，模型将调整其权重，并可能在训练数据上变得更擅长泛化。然而，如果算法超过理想的迭代次数，它将开始捕捉噪声，并在未见过的数据上表现不佳。

换句话说，使用过多迭代的提升算法容易过拟合。

## 找到合适的迭代次数

现在我们知道提升算法需要足够的迭代次数来找到模型的最佳权重，但又不能过多以避免过拟合。

关键是找到“最佳点”：一个既不高也不低的迭代次数。

然而，确定理想的迭代次数可能具有挑战性，因为这个数字因情况而异。影响这个数字的因素有很多，包括底层数据和正在训练的模型。

一种解决方法是使用提前停止。

## 提前停止

提前停止意味着如果个别模型在验证集上的表现经过一定次数的迭代后没有改善，就会提前结束提升模型的训练。

本质上，与其训练弱模型固定次数，我们可以配置它，仅在显示更好结果时继续训练。

这种提前停止的好处一目了然。通过这种技术，我们可以确保模型在过拟合之前停止训练，从而提高性能。它还减少了训练过程的运行时间，因为它减少了迭代次数。

## 案例研究

最好用案例研究来演示提前停止。让我们使用Scikit Learn库中的内置泰坦尼克数据集。

目标是训练一个有*提前停止*和*无提前停止*的轻量级梯度提升机（LGBM），并比较它们在f1分数和运行时间方面的结果。

1.  **没有提前停止**

让我们创建一个LGBM分类器，使用1000次迭代（在`n_estimators`超参数中指定），并对测试集进行评估。

![](../Images/d2a881d19c821e019689a2b29159dbf7.png)

F-1 Score（作者创建）

接下来，让我们使用`%%timeit`命令来确定这些操作的运行时间：

![](../Images/fb3069130edaeedc2ff51db60e6a7545.png)

代码输出（作者创建）

通过使用具有1000次迭代的提升算法，模型在约473毫秒内产生了约0.85的f-1分数。

还不错，但我们真的需要1000次迭代吗？

为了更清楚地了解，让我们查看模型的f-1分数如何随着迭代次数的增加而变化。

![](../Images/579a0fe9be6c17c78ed32086c94bc4fc.png)

代码输出（作者创建）

令人震惊的是，模型在测试集上的表现在前50次迭代后稳步下降！

显然，对于这个数据集，提升算法不需要那么多的迭代次数就能达到最佳性能。

**2\. 使用提前停止**

这次让我们看看在加入提前停止后，模型的表现如何。

在 LGBM 分类器中使用提前停止需要明确设置两个超参数。第一个叫做 `eval_set`，它包含验证集。验证集是模型在每次迭代时用来评估其性能的数据集。

第二个超参数叫做 `early_stopping_rounds`，它包含了模型可以在没有对验证集表现进行更大提升的情况下运行的迭代次数。如果在这些迭代内性能没有提升，模型将提前停止训练。

对于这个案例，`early_stopping_rounds` 的值被设置为 20。这意味着如果模型在 20 次迭代内其对验证集的 f-1 分数没有超过前几次的结果，即使它被配置为运行 1000 次迭代，训练过程也会停止。

![](../Images/ce247c549354e33dbca97f77940d317d.png)

代码输出（由作者创建）

使用提前停止的模型获得了约 0.92 的 f-1 分数，这相比于不使用提前停止的模型有了显著的提高！

此外，由于使用了较少的迭代次数，模型现在应该可以在更短的时间内完成训练。我们可以通过 `%%timeit` 操作来确认这一点。

![](../Images/4ce1f52c15ee1a103be4a397d45589d3.png)

正如预期的那样，*使用* 提前停止的模型在训练时间上仅为*不使用* 提前停止的模型的一小部分。

## 结论

![](../Images/727edf2cd6c22ef7f2a648bc2c6f4ffa.png)

[Prateek Katyal](https://unsplash.com/@prateekkatyal?utm_source=medium&utm_medium=referral) 摄影，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

总的来说，利用提升方法的算法通常更加稳健，因为它们从多个弱模型中“学习”。然而，最大化这些算法使用的迭代次数并不是一个可行的解决方案。

不同的使用场景会需要不同的迭代次数，这就是为什么算法中使用的理想迭代次数应基于单个模型的表现。

因此，提前停止是一种具有巨大实际价值的技术。它使用验证集作为算法是否需要更多迭代或提前停止的指标。如案例研究中所解释和演示的，提前停止使得模型在较少的训练时间内获得更好的性能。

祝你在数据科学的工作中好运！
