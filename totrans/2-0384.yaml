- en: 'Beyond Precision and Recall: A Deep Dive Deep into the Tversky Index'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7](https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploring an alternative classification metric
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[![Mikhail
    Klassen](../Images/9c4a6cc856fd4061f682e95a1c145c36.png)](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    [Mikhail Klassen](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    ·7 min read·Sep 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/007d37c92072ebd8b214107ae1e5014e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ricardo Arce](https://unsplash.com/@jrarce?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: In the world of data science, metrics are the compass that guide our models
    to success. While many are familiar with the classic measures of precision and
    recall, there are actually a wide range of other options that are worth exploring.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll dive into the Tversky index. This metric, a generalization
    of the Dice and Jaccard coefficients, can be extremely useful when trying to balance
    precision and recall against each other. When implemented as a loss function for
    neural networks, it can be a powerful way to deal with class imbalances.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: A quick refresher on precision and recall
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you are a detective tasked with capturing criminals in your town. In
    truth, there are 10 criminals roaming the streets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: In your first month, you bring in 8 suspects you assume to be criminals. Only
    4 of them end up being guilty, while the other 4 are innocent.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: If you were a machine learning model, you’d be evaluated against your precision
    and recall.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision** asks: “of all those you caught, how many were criminals?”'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '**Recall** asks: “of all the criminals in the town, how many did you catch?”'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision** is a metric that captures how accurate your predictions are,
    not counting how many true positives you miss (false negatives). **Recall** measures
    how many of the true positives you capture, irrespective of how many false positives
    you get.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: How do your detective skills rate against these metrics?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: precision = 4 / (4 + 4) = 0.5
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: recall = 4 / (4 + 6) = 0.4
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Balancing precision and recall: the F1 metric'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In an ideal world, your classifier has both high precision and high recall.
    As a measure of how well your classifier is doing against both, the F1 statistic
    measures the harmonic mean between the two:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7780f4c972fd0400459e034122a091b8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: This metric is also sometimes called the Dice similarity coefficient (DSC).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'Measuring similarity another way: the Jaccard coefficient'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another way of measuring the similarity between two sets is the **Jaccard similarity
    coefficient**, which is often used in computer vision applications where the goal
    is to identify objects.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/93776d9f2a4381aa34277c333f838c81.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: 'An object-detection algorithm predicts a bounding box around a stop sign (red).
    Human annotators have labeled the desired bounding region (green). Credit: [Adrian
    Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/),
    [CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'The Jaccard coefficient measures the ratio of the intersection of the two sets
    and their union:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f36d0ce33b094ef866693b6e7fe8a613.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Depicted visually, the intersection-over-union (IoU) is
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68c50f484216e713a23508d0a3663211.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: 'The Jaccard similarity coefficient is also known as the intersection-over-union
    (IoU). Credit: [Adrian Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/),
    [CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Tversky index
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Tversky index is a generalization of the Dice coefficient (F1 metric) and
    the Jaccard coefficient and is also used to compare the similarity of two sets,
    *X* and *Y*.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'The index can be formulated as:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/057b8fea01957d2c7a78a331d79a27d1.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
- en: 'If the language of set theory isn’t all that familiar, let’s break it down:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '*| X* ∩ *Y |* represents the number of common elements between sets *X* and
    *Y*.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*| X* ∖ *Y |* represents the number of elements that are in *X* but not in
    *Y*. It is called the relative complement of *Y* in *X.*'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*| Y* ∖ *X |* represents the number of elements that are in *Y* but not in
    *X*. It is called the relative complement of *X* in *Y*.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*α* and *β* are parameters that determine the relative importance of false
    positives and false negatives, respectively.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The parameters *α* and *β* are important. If we set *α* = *β* = 0.5, we get
    back the Dice coefficient. If we set *α* = *β* = 1.0, we get the Jaccard coefficient.
    In general, we keep *α* + *β* = 1, and this allows us to shift the weight between
    false negatives and false positives.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: True positives, false positives, and false negatives
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s talk about it in the context of classification. Let’s assume *X*
    is the ground truth and *Y* is our prediction. In such a scenario:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∩ *Y*: True positives (items correctly predicted as positive)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*X* ∖ *Y*: False negatives (items that were positive but predicted as negative)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y* ∖ *X*: False positives (items that were negative but predicted as positive)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y* ∖ *X*：假阳性（实际为负例但被预测为正例的项）'
- en: How does it relate to precision and recall?
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它与精确度和召回率有什么关系？
- en: 'Let’s go back to our definitions of precision and recall:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到精确度和召回率的定义：
- en: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
- en: Precision is the fraction of true positive predictions among all the predicted
    positives. It tells us how many of the predicted positive instances are actually
    positive.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 精确度是所有预测为正例中的真正正例的比例。它告诉我们预测为正例的实例中实际有多少是正例。
- en: Recall, also known as the sensitivity or true positive rate (TPR), is the fraction
    of true positive predictions among all the actual positives. It tells us how many
    of the actual positive instances were correctly predicted by the model.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 召回率，也称为敏感性或真正率（TPR），是所有实际正例中真正预测的比例。它告诉我们模型正确预测了多少实际正例。
- en: With these interpretations in mind, let’s link the Tversky index to precision
    and recall.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑这些解释后，让我们将 Tversky 指数与精确度和召回率联系起来。
- en: 'When *α* = 1 and *β* = 0:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当*α* = 1且*β* = 0时：
- en: '![](../Images/26e20271cd771050d2d74030b938560b.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26e20271cd771050d2d74030b938560b.png)'
- en: This is the definition of **Recall**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**召回率**的定义。
- en: 'When *α* = 0 and *β* = 1:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当*α* = 0且*β* = 1时：
- en: '![](../Images/54c843a0469ca561246e2a39d7138141.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54c843a0469ca561246e2a39d7138141.png)'
- en: This is the definition of **Precision**.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**精确度**的定义。
- en: Thus, by tweaking the parameters *α* and *β*, the Tversky index can reflect
    either precision or recall, or any weighted mix of both. This makes the Tversky
    index a flexible metric, allowing one to prioritize recall over precision or vice-versa
    depending on the application’s needs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整参数*α*和*β*，Tversky 指数可以反映出精确度或召回率，或两者的加权混合。这使得 Tversky 指数成为一个灵活的度量标准，根据应用需求，可以优先考虑召回率或精确度。
- en: 'Applied to neural networks: the Tversky loss'
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用于神经网络：Tversky 损失
- en: The Tverksy index can be used as a loss function in machine learning applications.
    In neural networks performing classification tasks, such as semantic image segmentation,
    we can use the Tversky index to define a loss function. This is an alternative
    to the usual categorical cross-entropy that is typically employed.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Tversky 指数可以作为机器学习应用中的损失函数。在执行分类任务的神经网络中，如语义图像分割，我们可以使用 Tversky 指数来定义损失函数。这是对通常使用的分类交叉熵的一种替代。
- en: Since the optimizer always tries to minimize the loss, the Tversky Loss (TL)
    is just defined as
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于优化器总是尝试最小化损失，Tversky 损失（TL）仅定义为
- en: '![](../Images/1e9158bdf335ef2345f444aab5f7769e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e9158bdf335ef2345f444aab5f7769e.png)'
- en: where TI is the Tversky index.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 TI 是 Tversky 指数。
- en: Alternatively, it can be defined as
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，它可以被定义为
- en: '![](../Images/331b239fc8608147d12c3cb29f5c8244.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/331b239fc8608147d12c3cb29f5c8244.png)'
- en: Here it will always assume a value between 0 and 1\. Thus, as the loss approaches
    0, our classifier approaches perfect accuracy.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里它的值始终在 0 和 1 之间。因此，随着损失接近 0，我们的分类器接近完美准确度。
- en: The advantage of using the Tversky Loss is that we can tweak the *α* and *β*
    parameters in order to favor recall or precision.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Tversky 损失的优点是我们可以调整*α*和*β*参数，以偏向召回率或精确度。
- en: The Focal Tversky loss
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 焦点 Tversky 损失
- en: Focal Tversky loss is an advanced loss function designed to address class imbalance
    issues in segmentation tasks, especially in medical imaging. It is defined as
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 焦点 Tversky 损失是一个先进的损失函数，旨在解决分割任务中的类别不平衡问题，特别是在医学成像中。它定义为
- en: '![](../Images/eea60aa8fc5ea3310d1e73e726d248dd.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eea60aa8fc5ea3310d1e73e726d248dd.png)'
- en: By incorporating both the Tversky index, which is a generalization of the Dice
    coefficient that weighs false positives and false negatives differently, and a
    focal modulation (γ)to give more importance to hard-to-segment instances, this
    loss function becomes more sensitive to small and ambiguous structures.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合 Tversky 指数（它是对 Dice 系数的推广，按不同方式权衡假阳性和假阴性）和一个焦点调节（γ），以赋予难以分割的实例更多重要性，这个损失函数对小而模糊的结构变得更敏感。
- en: In scenarios where certain regions or classes are underrepresented or where
    certain misclassifications are costlier than others, standard loss functions like
    categorical cross-entropy may not perform optimally. Under such circumstances,
    a researcher might choose Focal Tversky loss as it prioritizes the learning of
    challenging and rare regions, offering better segmentation performance in the
    presence of imbalances and subtle features.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'For more on the Focal Tversky loss, check out this other article from Towards
    Data Science:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
    [## Dealing with class imbalanced image datasets using the Focal Tversky Loss'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: A comparison of losses in class imbalanced problems and why the Focal Tversky
    Loss might be the best option for you
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the landscape of classification metrics, the Tversky Index emerges as a versatile
    and adaptable tool. By bridging the gap between traditional metrics like the Dice
    and Jaccard coefficients, it offers data scientists a more nuanced tool to evaluate
    their models. Its flexibility in balancing false positives and false negatives
    through the α and β parameters ensures that it can be tailored to specific needs.
    As a loss function in neural networks, particularly with a focal parameter, it
    becomes a powerful tool for training deep neural networks as well.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
