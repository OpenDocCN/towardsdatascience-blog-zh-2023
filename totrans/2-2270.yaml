- en: Using LazyPredict for Evaluating ML Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/using-lazypredict-for-evaluating-ml-algorithms-f912a43eef2](https://towardsdatascience.com/using-lazypredict-for-evaluating-ml-algorithms-f912a43eef2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Automate the process of selecting the best machine learning algorithms using
    the LazyPredict library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://weimenglee.medium.com/?source=post_page-----f912a43eef2--------------------------------)[![Wei-Meng
    Lee](../Images/10fc13e8a6858502d6a7b89fcaad7a10.png)](https://weimenglee.medium.com/?source=post_page-----f912a43eef2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f912a43eef2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f912a43eef2--------------------------------)
    [Wei-Meng Lee](https://weimenglee.medium.com/?source=post_page-----f912a43eef2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f912a43eef2--------------------------------)
    ·10 min read·Mar 27, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c5978871674c655a78ca67c37e7a48b0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Victoriano Izquierdo](https://unsplash.com/@victoriano?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating machine learning algorithms is a common task performed by data scientists.
    While a data scientist needs to know the different types of machine learning algorithms
    to use for different types of problems, it is nevertheless paramount that he puts
    the different algorithms to work on his/her specific dataset. Only by doing that
    would he/she have a better sense of which algorithm to use to train the model
    and how to perform hyper-parameter tuning after that. However, choosing the right
    algorithms is a time-consuming and exhausting process. Ideally, there should be
    an automated process where you just need to supply your data and the ideal machine
    learning algorithm to use would be chosen for you.
  prefs: []
  type: TYPE_NORMAL
- en: The answer to this is **LazyPredict**. **LazyPredict** is a Python library that
    helps you to partially automate the process of selecting the best algorithm to
    train your dataset. By supplying your data, LazyPredict would use more than 60
    ML algorithms to train a model. And the end result would be presented to you.
    From there on, you would be able to choose the best performing ML algorithm to
    further train or refine using your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting Machine Learning (ML) Models the Manual Way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To appreciate the beauty of LazyPredict, it is always good to understand how
    things are usually done manually. So for this section, I am doing to make use
    of the diabetes dataset as an example and see how we can use it to evaluate several
    ML algorithms and choose the ideal algorithm that works best with it. For simplicity,
    we are going to use the following ML algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-Nearest Neighbors (KNN)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support Vector Machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diabetes Dataset**: [https://www.kaggle.com/datasets/mathchi/diabetes-data-set](https://www.kaggle.com/datasets/mathchi/diabetes-data-set).
    **Licensing**: [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step would be to load the diabetes.csv file into a Pandas DataFrame
    and then print out its details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Specifically, there are no `NaN` values in the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a look at the dataframe itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Observe that some columns have 0 values, such as the **Pregnancies**, **SkinThickness**,
    **Insulin**, and **Outcome**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c732ffa6b35623502d2968d58b72bb2.png)'
  prefs: []
  type: TYPE_IMG
- en: All images by author
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since there are no `NaN` values in the dataframe, let’s now check to see which
    specific columns have 0 values in them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'From the output below, you can see that only the **DiabetesPedigreeFunction**
    and **Age** columns have no 0 values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For the other columns that have 0 values in them, only the **Pregnancies** and
    **Outcome** columns are allowed to have 0 values — a 0 for **Pregnancies** simply
    mean that the patient was never pregnant before and a 0 for **Outcome** means
    that the patient is not diabetic. For the other columns, having a 0 for value
    is simply not logical — 0 skin thickness, really?
  prefs: []
  type: TYPE_NORMAL
- en: 'So let’s now replace the 0 values in these columns so they have more meaning
    values. The first step is to replace the 0’s with `NaN`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/416fc5a3328be1dd62c0ff02462af3e4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, replace the `NaN`s with the mean of each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now verify that all columns have no 0 values except **Pregnancies**
    and **Outcome**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Examining the Correlation Between the Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While we have several features in the dataset, not all features contribute
    towards the outcome. Hence it is useful to calculate the correlation factor of
    each columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the outcome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Plotting the Correlation Between Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Visualizing the correlations between features using a heatmap makes understanding
    the numbers much easier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the heat map for the correlation factors. We are interested to see
    which features are highly correlated (either positively or negatively) to the
    **Outcome**. So we will look at the **Outcome** column and focus on those cells
    which are dark red (positively correlated) and dark blue (negatively correlated;
    none in this case):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/970dc725765cbae211fe480e2aa9747d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also find the top correlated features programmatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that the top 3 correlated features to **Outcome** are **Glucose**,
    **BMI**, and **Age**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating the Machine Learning Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the data cleaned, the next step would be to choose the different algorithms
    to train the model using your data.
  prefs: []
  type: TYPE_NORMAL
- en: Using LogisticRegression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s first use logistic regression to train a model. We shall use cross validation
    to score the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'For logistic regression, I obtained a score of 0.7669856459330144\. I will
    append the result to a list so that later on we can do a comparison among all
    the other models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Using K-Nearest Neighbors**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next up, we will use the K-Nearest Neighbors algorithm to train the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We will try different values of K and then score them individually. We will
    pick the highest score and print out the optimal value of K. Here is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Using Support Vector Machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The final algorithm that we want to use is Support Vector Machines (SVM). There
    are two types of kernels that we will try for SVM. Let’s try out the `linear`
    kernel first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Followed by the `rbf` (Radial Basis Function) kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Selecting the Best Performing Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have trained the dataset using the different algorithms, we can
    collate all the results and display them for comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the figure below, KNN is the winner, but the others are
    not too far behind as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e59277a5822d41fc1ed5f561ab728b73.png)'
  prefs: []
  type: TYPE_IMG
- en: With this result, you now know that KNN is the best algorithm to use for this
    particular dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Using LazyPredict for Classification Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we know from the previous result that KNN performs the best using the
    four algorithms that we used, the conclusion is not definitive. For all you know,
    there might be other better algorithms that are more suitable for your dataset.
    This is where you will use LazyPredict to automatically train your dataset using
    the different algorithms available.
  prefs: []
  type: TYPE_NORMAL
- en: LazyPredict supports regression and classification algorithms.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With regards to the dataset, I am going to use the one that I have cleaned earlier.
    You can use the raw data that you obtained from reading the CSV files and LazyPredict
    will automatically preprocess your data — it will replace your missing values
    with the mean (for numeric columns) and a constant value (for categorical columns).
    It will then standardize your numeric columns and encode your categorical columns.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is always better to perform the data preprocessing yourself as you
    are the best person to understand your own data (as evident in our dataset where
    for certain columns 0 values are not acceptable).
  prefs: []
  type: TYPE_NORMAL
- en: 'And so I am going to extract the features from the first 8 columns of the cleaned
    dataframe `df` and the ninth column as the label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, install LazyPredict:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'For classification problems, import the `LazyClassifier` class. You also import
    and the other required module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the `LazyClassifier` class, in particular set the `predictions`
    parameter to `True`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Split the dataset into 80% training and 20% test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now use the `clf` classifier to fit (train) your data using the various
    classification algorithms and predict the outcome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `scores` variable is a dataframe that shows the various ML models and their
    respective metrics such as accuracy, ROC AUC, F1 Score, etc:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/39f19b3d0558c343283a6eb1224864fc.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the result is pretty close to our initial test, where K-Nearest
    Neighbor performs pretty well (second best performing model in this case). Of
    course, now we know that the **ExtraTreesClassifier** algorithm works better.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `predictions` variable is a dataframe containing the predicted value for
    each model used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d125ae90676d2d1a9304692f014dd974.png)'
  prefs: []
  type: TYPE_IMG
- en: Using LazyPredict for Regression Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before I end this article, let’s use `LazyPredict` to work on a regression
    problem. This time, we will make use of the Boston dataset that is shipped with
    the `sk-learn` library. For regression problem, use the `LazyRegressor` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the evaluation is here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c33a90f023b5b08ee63c74f8561099f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And the predicted value for each algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d9a5c77baacbaa6415faa8a5cd719f65.png)'
  prefs: []
  type: TYPE_IMG
- en: '**If you like reading my articles and that it helped your career/study, please
    consider signing up as a Medium member. It is $5 a month, and it gives you unlimited
    access to all the articles (including mine) on Medium. If you sign up using the
    following link, I will earn a small commission (at no additional cost to you).
    Your support means that I will be able to devote more time on writing articles
    like this.**'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://weimenglee.medium.com/membership?source=post_page-----f912a43eef2--------------------------------)
    [## Join Medium with my referral link - Wei-Meng Lee'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Wei-Meng Lee (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: weimenglee.medium.com](https://weimenglee.medium.com/membership?source=post_page-----f912a43eef2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This article showed you how the process of selecting machine learning algorithms
    can be simplified using the **LazyPredict** library. Once you have identified
    the ideal algorithm to use, you should further refine your model by using hyper-parameter
    tuning. If you want a quick introduction to this topic, check out my earlier article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/tuning-the-hyperparameters-of-your-machine-learning-model-using-gridsearchcv-7fc2bb76ff27?source=post_page-----f912a43eef2--------------------------------)
    [## Tuning the Hyperparameters of your Machine Learning Model using GridSearchCV'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to use the GridSearchCV function in sklearn to optimize your machine
    learning model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/tuning-the-hyperparameters-of-your-machine-learning-model-using-gridsearchcv-7fc2bb76ff27?source=post_page-----f912a43eef2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
