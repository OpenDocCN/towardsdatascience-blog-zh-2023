- en: 'Beam Search: the Most Used Algorithm in Sequence Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Beam Search: 序列模型中使用最广泛的算法'
- en: 原文：[https://towardsdatascience.com/beam-search-the-most-used-algorithm-in-sequence-models-107d56b23556](https://towardsdatascience.com/beam-search-the-most-used-algorithm-in-sequence-models-107d56b23556)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/beam-search-the-most-used-algorithm-in-sequence-models-107d56b23556](https://towardsdatascience.com/beam-search-the-most-used-algorithm-in-sequence-models-107d56b23556)
- en: Learn the working principles of the most famous algorithm for text translation
    and speech recognition.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习最著名的文本翻译和语音识别算法的工作原理。
- en: '[](https://medium.com/@riccardo.andreoni?source=post_page-----107d56b23556--------------------------------)[![Riccardo
    Andreoni](../Images/5e22581e419639b373019a809d6e65c1.png)](https://medium.com/@riccardo.andreoni?source=post_page-----107d56b23556--------------------------------)[](https://towardsdatascience.com/?source=post_page-----107d56b23556--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----107d56b23556--------------------------------)
    [Riccardo Andreoni](https://medium.com/@riccardo.andreoni?source=post_page-----107d56b23556--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@riccardo.andreoni?source=post_page-----107d56b23556--------------------------------)[![Riccardo
    Andreoni](../Images/5e22581e419639b373019a809d6e65c1.png)](https://medium.com/@riccardo.andreoni?source=post_page-----107d56b23556--------------------------------)[](https://towardsdatascience.com/?source=post_page-----107d56b23556--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----107d56b23556--------------------------------)
    [Riccardo Andreoni](https://medium.com/@riccardo.andreoni?source=post_page-----107d56b23556--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----107d56b23556--------------------------------)
    ·6 min read·Dec 13, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----107d56b23556--------------------------------)
    ·阅读时间 6 分钟·2023年12月13日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c11105c573f0bc16e297b233f7f830a9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c11105c573f0bc16e297b233f7f830a9.png)'
- en: 'Beam Search allows to consider multiple streams of candidates. Image source:
    [unsplash.com](https://unsplash.com/photos/multi-colored-light-streaks-on-white-background-ylMP3TetKoQ).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Beam Search 允许考虑多个候选流。图片来源：[unsplash.com](https://unsplash.com/photos/multi-colored-light-streaks-on-white-background-ylMP3TetKoQ)。
- en: Imagine you’re an [AI](https://en.wikipedia.org/wiki/Artificial_intelligence)
    language model, like [ChatGPT](https://chat.openai.com/), completing a sentence.
    How do you choose the next word to make it not just **grammatically correct**
    but also **contextually relevant**? This is where [**Beam Search**](https://en.wikipedia.org/wiki/Beam_search#:~:text=In%20computer%20science%2C%20beam%20search,that%20reduces%20its%20memory%20requirements.)
    steps in.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你是一个[AI](https://en.wikipedia.org/wiki/Artificial_intelligence)语言模型，比如[ChatGPT](https://chat.openai.com/)，在完成一个句子时。你如何选择下一个词，使其不仅**语法正确**而且**上下文相关**？这就是[**Beam
    Search**](https://en.wikipedia.org/wiki/Beam_search#:~:text=In%20computer%20science%2C%20beam%20search,that%20reduces%20its%20memory%20requirements.)发挥作用的地方。
- en: By efficiently **exploring multiple possibilities** in parallel and maintaining
    top candidates at each step, Beam Search plays a crucial role in the task of predicting
    **subsequent elements**. Being an effective and powerful algorithm, it ensures
    output aligns with grammatical constraints and the context.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过高效**并行探索多个可能性**并在每一步保持最佳候选，Beam Search 在预测**后续元素**的任务中发挥着至关重要的作用。作为一种有效且强大的算法，它确保输出符合语法约束和上下文。
- en: To understand Beam Search's impact, think about all the applications requiring
    precise sequence generation, like **language translation**, **text completion**,
    and **chatbots**. In all these applications, Beam Search plays a critical role.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解 Beam Search 的影响，请考虑所有需要精确序列生成的应用，例如**语言翻译**、**文本补全**和**聊天机器人**。在所有这些应用中，Beam
    Search 都发挥着关键作用。
- en: In this article, I will introduce the theory and guide you through a practical
    step-by-step example of the Beam Search algorithm. I will also present several
    Beam Search variants, and detail all the pros and cons of this fundamental algorithm.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将介绍 Beam Search 算法的理论，并带你通过一个实际的逐步示例。我还将介绍几种 Beam Search 变体，并详细讲解这个基础算法的所有优缺点。
- en: Understanding Beam Search
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Beam Search
- en: 'Imagine you need to **translate the following sentence** from Spanish to English:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你需要将**以下句子**从西班牙语翻译成英语：
- en: Pablo estará en Nueva York la próxima semana.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Pablo 将于下周在纽约。
- en: We don’t only want to obtain a correct translation, we want to obtain **the
    best one**. For a language model, the best output coincides with the **most probable
    one**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅仅希望获得正确的翻译，我们还希望获得**最佳的翻译**。对于语言模型而言，最佳输出就是**最可能的输出**。
- en: To achieve this task, most [sequence-to-sequence](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)
    models employ Beam Search. It serves as an heuristic algorithm, systematically
    exploring multiple possibilities in parallel. At each step, a defined “beam width”
    maintains a fixed number of top candidates. This allows the algorithm to explore
    several candidates.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这项任务，大多数[序列到序列](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)模型使用Beam
    Search。它作为一种启发式算法，系统地并行探索多个可能性。在每一步中，定义的“beam width”保持固定数量的最佳候选项。这使得算法能够探索多个候选项。
- en: This approach **mimics decision-making** processes, with the model evaluating
    and selecting the most promising options.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法**模拟决策过程**，模型会评估并选择最有前景的选项。
- en: Beam Search Step-by-Step
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Beam Search逐步过程
- en: 'Consider a standard sequence-to-sequence model, represented by the simple network
    below:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个标准的序列到序列模型，下面是一个简单的网络表示：
- en: '![](../Images/f30ec7ec395dd7ba0d5daf116c16fa72.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f30ec7ec395dd7ba0d5daf116c16fa72.png)'
- en: Image by the author.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: At each timestep *t*, the model outputs a single word, used to compose the final
    sequence. The final sequence will be nothing other than the provided translated
    sentence.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间步*t*，模型输出一个单词，用于组成最终的序列。最终序列将是所提供的翻译句子。
- en: 'If you are not familiar with RNNs, I suggest to check the simple introduction
    I included in this article:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对RNN不太熟悉，我建议查看我在本文中包含的简单介绍：
- en: '[](/use-deep-learning-to-generate-fantasy-character-names-build-a-language-model-from-scratch-792b13629efa?source=post_page-----107d56b23556--------------------------------)
    [## Use Deep Learning to Generate Fantasy Names: Build a Language Model from Scratch'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 使用深度学习生成幻想名字：从零开始构建语言模型](/use-deep-learning-to-generate-fantasy-character-names-build-a-language-model-from-scratch-792b13629efa?source=post_page-----107d56b23556--------------------------------)'
- en: Can a language model invent unique fantasy character names? Let’s build it from
    scratch
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个语言模型能否发明独特的幻想角色名字？让我们从零开始构建它
- en: towardsdatascience.com](/use-deep-learning-to-generate-fantasy-character-names-build-a-language-model-from-scratch-792b13629efa?source=post_page-----107d56b23556--------------------------------)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何使用深度学习生成幻想角色名字：从零开始构建语言模型](/use-deep-learning-to-generate-fantasy-character-names-build-a-language-model-from-scratch-792b13629efa?source=post_page-----107d56b23556--------------------------------)'
- en: For text translation, we commonly use an [**encoder**](https://en.wikipedia.org/wiki/Autoencoder),
    which is a portion of the network dedicated to converting the input sequence into
    a vectorial form. In this case, the input sequence is the Spanish sentence to
    be translated. The encoder is followed by a [**decoder**](/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346)which,
    at each timestep, returns a piece of the output sequence.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本翻译，我们通常使用一个[**编码器**](https://en.wikipedia.org/wiki/Autoencoder)，它是网络的一部分，负责将输入序列转换为向量形式。在这种情况下，输入序列是要翻译的西班牙语句子。编码器后面跟着一个[**解码器**](/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346)，它在每个时间步返回输出序列的一部分。
- en: '![](../Images/c22140aaa9030a1b12bf7442f2ae743f.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c22140aaa9030a1b12bf7442f2ae743f.png)'
- en: Image by the author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Let’s check the first step out in detail.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细查看第一步。
- en: The encoder (green part) receives the Spanish sentence “*Pablo estará en Nueva
    York la próxima semana.*” and provides a vector form of it to the decoder (blue
    part).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器（绿色部分）接收西班牙语句子“*Pablo estará en Nueva York la próxima semana.*”并将其转换为向量形式提供给解码器（蓝色部分）。
- en: '![](../Images/813e02a670fadefd147d385a91780466.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/813e02a670fadefd147d385a91780466.png)'
- en: Image by the author.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'At timestep 1, the decoder will output the first word of the translation. The
    key question is:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间步1，解码器将输出翻译的第一个单词。关键问题是：
- en: How does the decoder choose the word?
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 解码器如何选择单词？
- en: The decoder chooses the most probable word, given the input sequence *x*. In
    other words, for each word in the dictionary, the model computes the corresponding
    probability to be the first word of the output sequence.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器根据输入序列*x*选择最可能的单词。换句话说，对于字典中的每个单词，模型计算其成为输出序列第一个单词的对应概率。
- en: '![](../Images/d29dfed795ada8b4109d9fa595966254.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d29dfed795ada8b4109d9fa595966254.png)'
- en: The one word that maximizes this probability is chosen.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 选择使得概率最大的那个单词。
- en: 'Here is where **Beam Search enters the game**: it introduces a parameter *B*,
    called **beam width**, which represents the number of words chosen by the model
    at each step.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是**Beam Search 进入游戏**的地方：它引入了一个参数 *B*，称为**beam width**，表示模型在每一步选择的单词数量。
- en: By setting, for instance, *B=3*, the model will return not only one but three
    candidate words.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，设置 *B=3*，模型将返回不仅是一个而是三个候选单词。
- en: Let’s suppose the most probable first words of the translation are “*Pablo*”,
    “*Next*”, and “*During*”.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 假设翻译中最可能的首个单词是“*Pablo*”、“*Next*”和“*During*”。
- en: '![](../Images/bdbd7809adab6b8f5451474fdd5113cc.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bdbd7809adab6b8f5451474fdd5113cc.png)'
- en: Image by the author.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: For each of these 3 candidate words, the model proceeds by guessing the second
    word *y²* in the English translation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这3个候选词中的每一个，模型通过猜测第二个单词 *y²* 在英文翻译中继续处理。
- en: '![](../Images/3dc070b8deac6b450540965ee725c72d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dc070b8deac6b450540965ee725c72d.png)'
- en: Image by the author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'As always, the model picks the words that maximize a given probability. In
    this case:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 与往常一样，模型选择最大化给定概率的单词。在这种情况下：
- en: '![](../Images/1044a9040734cae32188e67e621830c4.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1044a9040734cae32188e67e621830c4.png)'
- en: You can clearly see the reason for the name Beam Search now. Starting from a
    narrow set of 3 candidates, the algorithm will enlarge it at each step, considering
    the probabilities of all these combinations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以清楚地看到 Beam Search 名字的由来。从最初的3个候选集开始，算法将在每一步扩大它，考虑所有这些组合的概率。
- en: 'The output of step 2 consists of 9 candidate sequences: “*Pablo will*”, “*Pablo
    is*”, …, “*During next*”, and “*During one*”. The model associates each one of
    them with a probability. By setting the parameter *B=3*, the model will keep only
    the three candidate sequences with the higher probability.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 第2步的输出包括9个候选序列：“*Pablo will*”、“*Pablo is*”、……、“*During next*”和“*During one*”。模型将每一个与一个概率相关联。通过设置参数
    *B=3*，模型将仅保留三个概率较高的候选序列。
- en: Suppose that the candidates with higher probabilities are “*Pablo will*”, “*Pablo
    is*”, and “*Next week*”. During the 3-rd step, the decoder will guess 3 subsequent
    word for each candidate.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 假设概率较高的候选词是“*Pablo will*”、“*Pablo is*”和“*Next week*”。在第3步中，解码器将为每个候选词猜测3个后续单词。
- en: '![](../Images/f7347f2060245e60d484a2605eef72f0.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7347f2060245e60d484a2605eef72f0.png)'
- en: Image by the author.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: The same process is iterated all over again until the model predicts as the
    most likely word the **End of Sentence** token. The [EOS](https://forum.opennmt.net/t/end-and-start-tokens/4570)
    token states that the sequence reached its end and it is now considered complete.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的过程将重复进行，直到模型将**句子结束**标记预测为最可能的单词。[EOS](https://forum.opennmt.net/t/end-and-start-tokens/4570)标记表示序列已达到终点，现在被视为完成。
- en: Beam Search Variants
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Beam Search 变体
- en: 'Beam Search adaptability can be enhanced by several variants of the algorithm.
    They provide options that may be more or less adequate for diverse sequence generation
    tasks. The most common variants are:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Beam Search 的适应性可以通过算法的几种变体来增强。这些变体提供了适用于不同序列生成任务的更多或更少合适的选项。最常见的变体包括：
- en: '**Length-Normalized Beam Search**: It adjusts for sentence length disparities
    by normalizing the probability scores, mitigating biases towards shorter sequences.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Length-Normalized Beam Search**：它通过规范化概率分数来调整句子长度差异，减少对较短序列的偏见。'
- en: '**Diverse Beam Search**: It introduces diversity in candidate selection to
    prevent the algorithm from converging prematurely, promoting exploration of a
    broader solution space.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Diverse Beam Search**：它在候选选择中引入多样性，以防止算法过早收敛，促进对更广泛解决方案空间的探索。'
- en: '**Top-*k* Beam Search**: It restricts the number of candidates considered at
    each step to the top-*k* most probable, offering computational efficiency without
    compromising performance.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Top-*k* Beam Search**：它将每一步考虑的候选数量限制为前 *k* 个最可能的单词，提供了计算效率而不牺牲性能。'
- en: '**Alpha-Diverse Beam Search**: It controls the trade-off between diversity
    and optimization by introducing an alpha parameter, enabling fine-tuning based
    on specific task requirements.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Alpha-Diverse Beam Search**：它通过引入一个alpha参数来控制多样性和优化之间的权衡，从而能够根据特定任务要求进行微调。'
- en: '**Nucleus Sampling**: It defines a probability threshold (nucleus) and samples
    from the set of most probable candidates, enhancing the algorithm’s focus on high-quality
    sequences.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nucleus Sampling**：它定义了一个概率阈值（nucleus），并从最可能的候选集进行采样，提高算法对高质量序列的关注。'
- en: '![](../Images/25a6fb15f2f6331af55ee0af61654934.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25a6fb15f2f6331af55ee0af61654934.png)'
- en: 'Image source: [unsplash.com](https://unsplash.com/photos/multicolored-light-passage-in-dark-area-d3Zu34NBg7A).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：[unsplash.com](https://unsplash.com/photos/multicolored-light-passage-in-dark-area-d3Zu34NBg7A)。
- en: Conclusion
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In summary, in this post we understood why Beam Search is the **most used algorithm**
    in the field of sequence generation, particularly in the context of **language
    translation** models, but also for **chatbot responses**. Its systematic exploration
    of multiple possibilities in parallel, guided by a defined beam width, enhances
    the precision and the contextualize of the generated sequences.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在这篇帖子中我们理解了为什么 Beam Search 是**最常用的算法**，特别是在**语言翻译**模型的领域中，但也适用于**聊天机器人响应**。它通过定义的光束宽度系统地并行探索多个可能性，从而提高了生成序列的精准性和上下文相关性。
- en: I am confident that the step-by-step example I provided will make the abstract
    concept of Beam Search more concrete.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信我提供的逐步示例将使 Beam Search 的抽象概念变得更加具体。
- en: 'As I always do in my posts, I will now recap some pros and cons of Beam Search.
    The main advantages of this algorithm are:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在帖子中常做的那样，我现在将回顾一下 Beam Search 的一些优缺点。该算法的主要优点包括：
- en: '**Precision**: Beam Search excels in generating precise and contextually relevant
    sequences.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精准性**：Beam Search 在生成精确且具有上下文相关性的序列方面表现优异。'
- en: '**Flexibility**: Variants like Diverse Beam Search and Top-*k* Beam Search
    offer adaptability to diverse task requirements.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：像多样性 Beam Search 和 Top-*k* Beam Search 这样的变体提供了对多样任务需求的适应性。'
- en: '**Efficiency**: It efficiently explores a solution space, balancing computational
    complexity with performance.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：它高效地探索解决方案空间，平衡了计算复杂性和性能。'
- en: 'However, in Machine Learning there are **no free meals**. It is then important
    to clarify the drawbacks of each algorithm. In the case of Beam Search, I identified
    these possible issues:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在机器学习中**没有免费的午餐**。因此，澄清每种算法的缺点是很重要的。在 Beam Search 的情况下，我发现了这些可能的问题：
- en: '**Computational Cost**: The exhaustive exploration of possibilities can incur
    computational overhead.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算成本**：对所有可能性的详尽探索可能会带来计算开销。'
- en: '**Potential Convergence**: In standard configurations, Beam Search might converge
    prematurely to suboptimal solutions.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在收敛**：在标准配置下，Beam Search 可能会过早地收敛到次优解。'
- en: '![](../Images/2d758ea19408ece539193d8e6d922ae1.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d758ea19408ece539193d8e6d922ae1.png)'
- en: Image by the author.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: Finally, I invite you to explore the provided resources to get a deeper understanding
    of this algorithm.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我邀请你探索提供的资源，以更深入地了解这个算法。
- en: If you liked this story, consider following me to be notified of my upcoming
    projects and articles!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这个故事，考虑关注我，以便获得我即将发布的项目和文章的通知！
- en: References
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Deep Learning for Natural Language Processing, Brownlee, J. (2019)](https://oku.ozturkibrahim.com/docs_python/Deep_Learning_for_Natural_Language_Processing.pdf)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理的深度学习，Brownlee, J. (2019)](https://oku.ozturkibrahim.com/docs_python/Deep_Learning_for_Natural_Language_Processing.pdf)'
- en: '[Long short-term memory, Hochreiter, S., & Schmidhuber, J. (1997)](https://ieeexplore.ieee.org/abstract/document/6795963/)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[长短期记忆，Hochreiter, S., & Schmidhuber, J. (1997)](https://ieeexplore.ieee.org/abstract/document/6795963/)'
- en: '[Neural Turing Machines, Graves, A., et al. (2014)](https://arxiv.org/abs/1410.5401)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经图灵机，Graves, A., 等 (2014)](https://arxiv.org/abs/1410.5401)'
- en: '[A Diversity-Promoting Objective Function for Neural Conversation Models, Li,
    J., et al. (2016)](https://aclanthology.org/N16-1014)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[促进多样性的目标函数用于神经对话模型，Li, J., 等 (2016)](https://aclanthology.org/N16-1014)'
- en: '[Neural Machine Translation by Jointly Learning to Align and Translate, Bahdanau,
    D., et al. (2015)](https://arxiv.org/abs/1409.0473)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过联合学习对齐和翻译的神经机器翻译，Bahdanau, D., 等 (2015)](https://arxiv.org/abs/1409.0473)'
