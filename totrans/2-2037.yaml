- en: The Multi-Task Optimization Controversy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多任务优化争议
- en: 原文：[https://towardsdatascience.com/the-multi-task-optimization-controversy-793cbb431d98](https://towardsdatascience.com/the-multi-task-optimization-controversy-793cbb431d98)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-multi-task-optimization-controversy-793cbb431d98](https://towardsdatascience.com/the-multi-task-optimization-controversy-793cbb431d98)
- en: Do we need special algorithms to train models on multiple tasks at the same
    time?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们是否需要特殊的算法来同时训练多个任务的模型？
- en: '[](https://medium.com/@samuel.flender?source=post_page-----793cbb431d98--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----793cbb431d98--------------------------------)[](https://towardsdatascience.com/?source=post_page-----793cbb431d98--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----793cbb431d98--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----793cbb431d98--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samuel.flender?source=post_page-----793cbb431d98--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----793cbb431d98--------------------------------)[](https://towardsdatascience.com/?source=post_page-----793cbb431d98--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----793cbb431d98--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----793cbb431d98--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----793cbb431d98--------------------------------)
    ·6 min read·Sep 29, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----793cbb431d98--------------------------------)
    ·阅读时间6分钟·2023年9月29日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d49f4ff793f5ebba7bb708389b741416.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d49f4ff793f5ebba7bb708389b741416.png)'
- en: Photo by [Javier Allegue Barros](https://unsplash.com/@soymeraki?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Javier Allegue Barros](https://unsplash.com/@soymeraki?utm_source=medium&utm_medium=referral)在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)拍摄的照片
- en: The [multi-task learning paradigm](/multi-task-learning-in-recommender-systems-a-primer-508e661a2029#:~:text=Multi%2Dtask%20learning%20matters%20because,each%20other%20%E2%80%94%20creating%20negative%20transfer.)
    — that is, the ability to train models on multiple tasks at the same time — has
    been a blessing as much as a curse.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[多任务学习范式](/multi-task-learning-in-recommender-systems-a-primer-508e661a2029#:~:text=Multi%2Dtask%20learning%20matters%20because,each%20other%20%E2%80%94%20creating%20negative%20transfer.)
    —— 即同时训练多个任务的能力 —— 既是一种祝福，也是一种诅咒。'
- en: 'A blessing because it allows us to build a single model where previously we
    would have needed multiple. That makes live simpler: fewer models that need to
    be maintained, re-trained, tuned, and monitored.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个祝福，因为它使我们能够构建一个单一的模型，而之前我们需要多个模型。这使得生活更简单：减少需要维护、重新训练、调整和监控的模型数量。
- en: 'A curse because it opens up an entirely new pandora’s box of questions: which
    tasks should be learned together? Which tasks do we really need? What happens
    if tasks are competing with each other? How can we make make the model prioritize
    certain tasks over others? How can we avoid ‘task rot’, that is, the accumulation
    of task heads over time that eventually lead to degradation of model performance?'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个诅咒，因为它开启了一个全新的潘多拉盒子：哪些任务应该一起学习？我们真正需要哪些任务？如果任务之间存在竞争会发生什么？我们如何让模型优先考虑某些任务而不是其他任务？我们如何避免“任务腐蚀”，即任务头的积累最终导致模型性能的下降？
- en: It is questions like these that spawned a new subdomain of Machine Learning
    known as *multi-task optimization*, that is, the science of how to optimize a
    model on multiple, sometimes competing, tasks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正是这些问题催生了一个新的机器学习子领域，即*多任务优化*，也就是如何在多个有时相互竞争的任务上优化模型的科学。
- en: Scalarization
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标量化
- en: Scalarization is Mathematic’s answer to the multi-task optimization problem.
    In a multi-task model we are trying to learn K tasks, such as predicting “click”,
    “add-to-cart”, and “purchase” in an e-commerce recommender system. (In fact, modern
    recommender systems may include more than a dozen tasks!) In such a setting, we
    can define the solution as the one that minimizes
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 标量化是数学对多任务优化问题的回答。在多任务模型中，我们试图学习K个任务，例如在电子商务推荐系统中预测“点击”、“添加到购物车”和“购买”。（实际上，现代推荐系统可能包括十多个任务！）在这样的设置中，我们可以定义解决方案为最小化
- en: '![](../Images/12ec12c7f9f674d6244285cba72b20a2.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12ec12c7f9f674d6244285cba72b20a2.png)'
- en: …that is, the weighted sum of task-specific losses, where the weights are larger
    than 0 and sum up to 1.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: …也就是说，任务特定损失的加权和，其中权重大于 0 且总和为 1。
- en: This trick of reformulating a multi-task learning problem as single optimization
    problem is known as *scalarization*, and it’s borrowed from the broader discipline
    of mathematical optimization, which is covered in textbooks such as [Boyd & Vandenberghe](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 将多任务学习问题重新表述为单一优化问题的技巧被称为 *标量化*，它借鉴了更广泛的数学优化学科，该学科在诸如 [Boyd & Vandenberghe](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)
    等教科书中有详细介绍。
- en: 'An important definition in such a problem is that of *pareto optimality*: a
    solution θ is said to be pareto optimal if it achieves the lowest loss for all
    tasks, that is, there is no θ with a lower loss for any of the tasks. Usually,
    there is no single solution θ that’s pareto-optimal, but instead multiple, forming
    a high-dimensional curve in the loss space — the *pareto frontier*.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种问题中的一个重要定义是 *帕累托最优性*：如果一个解 θ 对所有任务都实现了最低损失，则称之为帕累托最优，即不存在一个 θ 对任何任务具有更低的损失。通常，没有一个单一的解
    θ 是帕累托最优的，而是多个解形成了损失空间中的高维曲线——即 *帕累托前沿*。
- en: '![](../Images/c668a8d2e5b137730c29002b982cd1c1.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c668a8d2e5b137730c29002b982cd1c1.png)'
- en: '(The Pareto frontier in a multi-task problem with 2 tasks. Image credit: [Xin
    et al 2022](https://arxiv.org/abs/2209.11379))'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: （具有 2 个任务的多任务问题中的帕累托前沿。图片来源：[Xin et al 2022](https://arxiv.org/abs/2209.11379)）
- en: 'Finally, here’s one of the most important results that can be derived within
    the context of mathematical optimization:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是在数学优化背景下可以推导出的最重要的结果之一：
- en: '**Mathematically, it can be shown that no matter which combinations of weights
    we pick, we always end up with a solution θ that’s sitting right on the pareto
    frontier. All we need to do in a practical application is to sweep over the possible
    weight combinations and pick the one that’s best aligned with the business objectives.**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**从数学上讲，可以证明无论我们选择哪种权重组合，我们总会得到一个恰好位于帕累托前沿的解 θ。在实际应用中，我们需要做的就是遍历可能的权重组合，并选择与业务目标最为一致的那个。**'
- en: Learnable loss weights
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可学习的损失权重
- en: The story of multi-task optimization could have ended in with scalarization
    and its guarantee of pareto-optimality. However, as so often in Machine Learning,
    practitioners ended up developing certain tricks that empirically turned out to
    work surprisingly well.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务优化的故事本可以通过标量化及其对帕累托最优性的保证来结束。然而，正如机器学习中的常见情况，实践者最终开发出一些在经验上效果出乎意料好的技巧。
- en: One such trick is ‘learnable loss weights’ (LLW), introduced in 2018 in a paper
    by researchers from the University of Cambridge ([Kendall et al 2018](https://arxiv.org/abs/1705.07115))
    in the context of computer vision. The key idea is to automatically assign task-specific
    loss weights that are inversely proportional to the model uncertainty for that
    datapoint’s prediction. The intuition is that if the model is wrong but uncertain
    we should assign a smaller loss compared to when the model is wrong and certain.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个技巧是“可学习的损失权重”（LLW），这是由剑桥大学的研究人员在 2018 年的一篇论文中提出的（[Kendall et al 2018](https://arxiv.org/abs/1705.07115)），主要应用于计算机视觉领域。其关键思想是自动分配与该数据点预测的模型不确定性成反比的任务特定损失权重。直观上，如果模型错误但不确定，我们应该分配较小的损失，而不是模型错误且确定时的损失。
- en: Mathematically, this means that we minimize
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，这意味着我们最小化
- en: '![](../Images/8f55e7c20bd2a66c7e874200a236f40f.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f55e7c20bd2a66c7e874200a236f40f.png)'
- en: where L_i is the loss for task i and σ_i is the uncertainty in the predictions
    for task i. The last term in the loss, which is simply adding the log of the uncertainties
    themselves, nudges the model to make predictions with high certainty instead of
    simply predicting every possible outcome with a small degree of certainty. For
    more than 2 tasks, we simply add more terms to this equation, one for each task’s
    loss.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 L_i 是任务 i 的损失，σ_i 是任务 i 预测中的不确定性。损失中的最后一项，简单地加上不确定性自身的对数，促使模型做出高确定性的预测，而不是仅仅以小的确定度预测每一种可能的结果。对于多于
    2 个任务的情况，我们只需在此方程中添加更多项，每项对应一个任务的损失。
- en: 'Practically, we can estimate the uncertainty σ by comparing the predictions
    to the ground truth and fitting a Gaussian distribution N where the mean is the
    prediction itself and the standard deviation is the model uncertainty:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们可以通过将预测结果与实际情况进行比较，并拟合一个均值为预测结果自身、标准差为模型不确定性的高斯分布 N 来估计不确定性 σ：
- en: '![](../Images/0193bc1e913ce5ca888aabf7f83e126b.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0193bc1e913ce5ca888aabf7f83e126b.png)'
- en: In the Cambridge paper, the authors apply learnable loss weights to a multi-task
    image segmentation problem, where the individual tasks are semantic segmentation,
    instance segmentation, and depth prediction. Compared to uniform weights (1/3,
    1/3, 1/3), with learnable loss weights (which turned out to be 0.89, 0.01, 0.1)
    the resulting segmentation has a 13% better IoU, proving the effectiveness of
    this approach.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在剑桥论文中，作者将可学习的损失权重应用于一个多任务图像分割问题，其中单个任务包括语义分割、实例分割和深度预测。与均匀权重（1/3, 1/3, 1/3）相比，使用可学习的损失权重（结果为0.89,
    0.01, 0.1）后，得到的分割结果的IoU提高了13%，证明了这种方法的有效性。
- en: Gradient manipulation
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度操控
- en: '![](../Images/73698e0f8ba9bb8cb6896da4c466b7af.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73698e0f8ba9bb8cb6896da4c466b7af.png)'
- en: '(Gradient “surgery”. Image credit: [Yu et al 2020](https://arxiv.org/pdf/2001.06782.pdf))'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: （梯度“手术”。图片来源：[Yu et al 2020](https://arxiv.org/pdf/2001.06782.pdf)）
- en: One problem in multi-task learning is that different gradients from different
    tasks may be conflicting with each other, causing the model to be pulled into
    multiple different directions at the same time. In scalarization, we solve this
    problem by simply tuning the loss weights (which directly impact the scale of
    the gradients) according to which task we deem most important. In LLW, instead
    of tuning these weights by hand, we try to learn them from the data. But why not
    manipulate the gradients directly, instead of the losses?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习中的一个问题是来自不同任务的不同梯度可能相互冲突，导致模型同时被拉向多个不同方向。在标量化中，我们通过根据认为最重要的任务来简单地调整损失权重（直接影响梯度的尺度）来解决这个问题。在LLW中，我们尝试从数据中学习这些权重，而不是手动调整。但为什么不直接操控梯度，而不是损失呢？
- en: 'This idea of direct gradient manipulation has spawned a number of research
    papers that claim to improve multi-task learning by scaling or re-aligning gradients
    in various ways:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 直接梯度操控的这个想法催生了一些研究论文，这些论文声称通过以各种方式缩放或重新对齐梯度来改进多任务学习：
- en: in [Gradient Surgery,](https://arxiv.org/pdf/2001.06782.pdf) we simply project
    a conflicting gradient onto the normal plane of the “anchor” gradient (that is,
    the gradient from the most important task we’re trying to predict),
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[Gradient Surgery](https://arxiv.org/pdf/2001.06782.pdf)中，我们简单地将一个冲突的梯度投影到“锚点”梯度的法向平面上（即，我们试图预测的最重要任务的梯度），
- en: in [GradNorm](https://arxiv.org/pdf/1711.02257.pdf), we normalize the scale
    of all gradients to be identical to the average gradient scale (averaged over
    all tasks) at that training iteration,
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[GradNorm](https://arxiv.org/pdf/1711.02257.pdf)中，我们将所有梯度的尺度标准化为该训练迭代中的平均梯度尺度（对所有任务进行平均），
- en: in [GradSimilarity](https://arxiv.org/abs/1812.02224), we only consider gradients
    of other tasks i that have a positive cosine with respect to the anchor gradient,
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[GradSimilarity](https://arxiv.org/abs/1812.02224)中，我们仅考虑与锚点梯度有正余弦值的其他任务i的梯度，
- en: in [MetaBalance](https://arxiv.org/abs/2203.06801), we normalize the scale of
    all gradients to be identical to the scale of the anchor gradient (similar to
    [MTAdam](https://aclanthology.org/2021.emnlp-main.837.pdf)), and more.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[MetaBalance](https://arxiv.org/abs/2203.06801)中，我们将所有梯度的尺度标准化为与锚点梯度的尺度相同（类似于[MTAdam](https://aclanthology.org/2021.emnlp-main.837.pdf)），还有更多。
- en: Each of these papers claimed to solve the multi-task learning problem better
    than its successors, and more papers on gradient manipulation are still being
    published at the time of this writing in 2023\. Gradient manipulation is a rapidly
    growing research domain!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 每一篇论文声称比其后继论文更好地解决了多任务学习问题，并且在2023年撰写本文时，关于梯度操控的更多论文仍在不断发布。梯度操控是一个迅速增长的研究领域！
- en: The controversy
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 争议
- en: All that leads us to a weird conclusion. Mathematically it can be shown that
    all we need to do in a multi-task problem is apply scalarization and sweep over
    the loss weights in order to find a point that’s most aligned with business objectives
    — this is (provably!) pareto-optimal. The authors of Learnable Loss Weights claim
    that it’s better to learn the loss weights instead of hand-tuning them. That’s
    ok, but they would have probably found the same results with a fine-grained parameter
    sweep.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都导致了一个奇怪的结论。从数学上可以证明，我们在多任务问题中需要做的就是应用标量化并在损失权重上进行遍历，以找到最符合业务目标的点——这是（可以证明的！）帕累托最优的。《可学习的损失权重》的作者声称，学习损失权重比手动调整它们更好。这没问题，但他们可能通过精细的参数遍历也会发现相同的结果。
- en: 'What’s controversial is the claim of researchers working on direct gradient
    manipulation algorithms that it’s *not* enough to change the loss weights: we
    need to adapt the gradients directly to resolve conflicts during training. This
    claim contradicts scalarization theory!'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有争议的是，研究者在直接梯度操作算法上的主张，即改变损失权重*是不够*的：我们需要直接调整梯度以解决训练过程中的冲突。这一主张与标量化理论相矛盾！
- en: '![](../Images/39a1589a724889aa3d495db52ee1d5bd.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39a1589a724889aa3d495db52ee1d5bd.png)'
- en: 'Gradient manipulation algorithms don’t beat scalarization (blue curve). Image
    credit: [Xin et al 2022](https://arxiv.org/abs/2209.11379)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度操作算法不如标量化（蓝色曲线）。图片来源：[Xin et al 2022](https://arxiv.org/abs/2209.11379)
- en: So, who’s right? In their paper “Do Current Multi-Task Optimization Methods
    in Deep Learning Even Help?”, Derrick Xin et al compare the predictive performance
    of scalarization (combined with parameter sweeps over loss weights) against a
    selection of modern gradient manipulation algorithms, including Gradient Surgery
    and GradNorm. The result? None of them beat scalarization!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，谁对呢？在他们的论文《当前深度学习中的多任务优化方法真的有帮助吗？》中，Derrick Xin等人比较了标量化（结合损失权重的参数扫描）与一些现代梯度操作算法，包括梯度手术和GradNorm的预测性能。结果是？它们都不如标量化！
- en: 'The authors explain:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作者解释道：
- en: '*“Researchers can unknowingly create the illusion of significant performance
    gains by simply under-tuning the competing baselines.”*'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“研究人员可以通过简单地调整竞争基线，毫无察觉地创造出显著的性能提升错觉。”*'
- en: 'And this “illusion” highlights a problem in modern Machine Learning research:
    perhaps it is too easy to publish ML research papers. Perhaps it is too easy to
    show that a new algorithm works on a fixed dataset, simply by tuning that algorithm
    a little bit more and tuning the baselines a little bit less.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这种“错觉”突显了现代机器学习研究中的一个问题：也许发表机器学习研究论文太容易了。也许仅仅通过稍微调整算法并减少基线的调整，就可以轻松证明一种新算法在固定数据集上的有效性。
- en: Perhaps, then, one of the best thing we can do to advance ML research is to
    [develop better theories](/why-does-deep-learning-work-so-well-6550f3aa22c6).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 也许，那么，推进机器学习研究的最佳方法之一是[开发更好的理论](/why-does-deep-learning-work-so-well-6550f3aa22c6)。
