- en: Pro GPU System vs Consumer GPU System for Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专业级GPU系统 vs 消费级GPU系统用于深度学习
- en: 原文：[https://towardsdatascience.com/pro-gpu-system-vs-consumer-gpu-system-for-deep-learning-a62bec69f557](https://towardsdatascience.com/pro-gpu-system-vs-consumer-gpu-system-for-deep-learning-a62bec69f557)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pro-gpu-system-vs-consumer-gpu-system-for-deep-learning-a62bec69f557](https://towardsdatascience.com/pro-gpu-system-vs-consumer-gpu-system-for-deep-learning-a62bec69f557)
- en: Hardware
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件
- en: Why you might consider going pro
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么你可能会考虑使用专业级GPU
- en: '[](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)[![Mike
    Clayton](../Images/2d37746b13b7d2ff1c6515893914da97.png)](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)
    [Mike Clayton](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)[![Mike
    Clayton](../Images/2d37746b13b7d2ff1c6515893914da97.png)](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)
    [Mike Clayton](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)
    ·21 min read·Apr 19, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)
    ·阅读时间21分钟·2023年4月19日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f24ad59210450dc7f7fab7e6456b0d01.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f24ad59210450dc7f7fab7e6456b0d01.png)'
- en: '*The professional workstation that will be utilised in this article. Image
    via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文将使用的专业工作站。图片来源于* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *，授权给Michael Clayton*'
- en: '**Having a GPU (or graphics card) in your system is almost essential when it
    comes to training neural networks, especially deep neural networks. The difference
    in training speed of a fairly modest GPU is a night and day difference when compared
    to a CPU.**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**在训练神经网络，特别是深度神经网络时，系统中拥有一个GPU（或显卡）几乎是必需的。与CPU相比，即使是相当普通的GPU，其训练速度的差异也是天壤之别。**'
- en: '**….but at what point might you consider jumping into the realms of professional,
    rather than consumer, level GPUs? Is there a huge difference in training and inference
    speed? Or is it other factors that make the jump compelling?**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**……但你什么时候可能会考虑跳入专业级而非消费级GPU的领域？训练和推理速度有很大的差别吗？还是说其他因素使得转向专业级GPU更具吸引力？**'
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: The aim of this article is to give you an idea of the main differences between
    a GPU you might use as a normal consumer (or starting out in machine/deep learning),
    and those used in higher end systems. The type of systems that might be used in
    the development and/or inference of advanced deep learning models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目的是让你了解作为普通消费者（或刚开始从事机器学习/深度学习）的GPU与高端系统中使用的GPU之间的主要区别。这些系统可能用于开发和/或推理高级深度学习模型。
- en: Apart from being an interesting exercise in understanding the distinctions between
    cutting edge pro equipment and consumer level hardware in terms of pure processing
    speed, it will also highlight some of the other limitations that are present in
    consumer level GPUs, and associated systems, when dealing with cutting edge deep
    learning models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 除了作为一个有趣的练习来理解前沿专业设备和消费级硬件在纯处理速度上的区别外，它还将突出一些消费级GPU及其相关系统在处理前沿深度学习模型时存在的其他限制。
- en: Which GPUs are you referring to when you say “Pro” or “Consumer”?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你提到的“专业”或“消费级”GPU指的是哪些GPU？
- en: The “real world” differences will be covered in the rest of the article, but
    if you want a solid technical distinction, with example graphics cards and specifications,
    then this section should cover it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: “现实世界”的差异将在文章的其余部分中讨论，但如果你想要一个明确的技术区分，包括示例显卡和规格，那么这一部分应该能涵盖。
- en: As detailed in one of my [previous articles](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b),
    NVIDIA are the only sensible option when it comes to GPUs for deep learning and
    neural networks at the current time. This is mainly due to their more thorough
    integration into platforms such as TensorFlow and PyTorch.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在[之前的文章](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b)中详细说明的那样，NVIDIA
    是目前深度学习和神经网络 GPU 的唯一明智选择。这主要是由于它们与 TensorFlow 和 PyTorch 等平台的更全面集成。
- en: Making the distinction between professional and consumer, in terms of specifications
    from the manufacturer, is therefore relatively straight forward.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在制造商的规格方面区分专业级和消费级显卡是相对直接的。
- en: 'Anything from the following page is the current batch of NVIDIA’s consumer
    graphics cards:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从以下页面中了解当前的 NVIDIA 消费级显卡批次：
- en: '[](https://www.nvidia.com/en-gb/geforce/graphics-cards/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA GeForce Graphics Cards'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.nvidia.com/en-gb/geforce/graphics-cards/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA GeForce 显卡'
- en: Explore NVIDIA GeForce graphics cards. RTX 40 series, RTX 30 series, RTX 20
    series and GTX 16 series.
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索 NVIDIA GeForce 显卡。RTX 40 系列、RTX 30 系列、RTX 20 系列和 GTX 16 系列。
- en: www.nvidia.com](https://www.nvidia.com/en-gb/geforce/graphics-cards/?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.nvidia.com](https://www.nvidia.com/en-gb/geforce/graphics-cards/?source=post_page-----a62bec69f557--------------------------------)'
- en: '…and professional level GPUs:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: …以及专业级 GPU：
- en: '[](https://www.nvidia.com/en-us/design-visualization/desktop-graphics/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA RTX & Quadro Desktop Workstations'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.nvidia.com/en-us/design-visualization/desktop-graphics/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA RTX & Quadro 台式工作站'
- en: See how 3D artists, architects, and product designers are using the powerful
    features of NVIDIA RTX ™ and Omniverse ™…
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解 3D 艺术家、建筑师和产品设计师如何利用 NVIDIA RTX ™ 和 Omniverse ™ 的强大功能…
- en: www.nvidia.com](https://www.nvidia.com/en-us/design-visualization/desktop-graphics/?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.nvidia.com](https://www.nvidia.com/en-us/design-visualization/desktop-graphics/?source=post_page-----a62bec69f557--------------------------------)'
- en: 'There are also GPUs, mainly used in data centres, that go beyond even the pro
    level graphics cards listed above. The A100 is a good example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些 GPU，主要用于数据中心，超越了上述的专业级显卡。A100 是一个很好的例子：
- en: '[](https://www.nvidia.com/en-us/data-center/a100/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA A100 GPUs Power the Modern Data Center'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.nvidia.com/en-us/data-center/a100/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA A100 GPU 驱动现代数据中心'
- en: The NVIDIA EGX ™ platform includes optimized software that delivers accelerated
    computing across the infrastructure…
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NVIDIA EGX ™ 平台包括优化的软件，提供基础设施上的加速计算…
- en: www.nvidia.com](https://www.nvidia.com/en-us/data-center/a100/?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.nvidia.com](https://www.nvidia.com/en-us/data-center/a100/?source=post_page-----a62bec69f557--------------------------------)'
- en: 'You can also get an idea of the system specifications and GPUs being used in
    professional data centre and workstation systems certified by NVIDIA:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以了解 NVIDIA 认证的专业数据中心和工作站系统中使用的系统规格和 GPU：
- en: '[## NVIDIA-Certified Systems'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[## NVIDIA 认证系统'
- en: The NVIDIA-Certified Systems program has assembled the industry's most complete
    set of accelerated workload performance…
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NVIDIA 认证系统程序汇集了业界最完整的加速工作负载性能集合…
- en: docs.nvidia.com](https://docs.nvidia.com/ngc/ngc-deploy-on-premises/nvidia-certified-systems/index.html?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[docs.nvidia.com](https://docs.nvidia.com/ngc/ngc-deploy-on-premises/nvidia-certified-systems/index.html?source=post_page-----a62bec69f557--------------------------------)'
- en: The Plan
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计划
- en: I generally find that a real demonstration (or experiment) is the best way to
    illustrate a point, rather than just relying on specs and statistics provided
    by the manufacturers.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常认为实际演示（或实验）是说明一个观点的最佳方式，而不仅仅依赖于制造商提供的规格和统计数据。
- en: With that in mind, although the article will discuss the relevant statistics,
    it will also directly compare three different GPUs (pro and consumer), at differing
    levels of sophistication, on the same deep learning model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有鉴于此，虽然文章将讨论相关统计数据，但它还将直接比较三种不同的 GPU（专业级和消费级），在相同的深度学习模型上进行不同层次的比较。
- en: This should help to highlight what is important, and what isn’t, when considering
    whether a professional level GPU is for you.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该有助于突出在考虑是否需要专业级GPU时哪些因素重要，哪些因素不重要。
- en: The GPU Specs — A Summary
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU规格 — 概述
- en: '![](../Images/652e61b5741fc1ee64f48d026de6b88b.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/652e61b5741fc1ee64f48d026de6b88b.png)'
- en: Photo by [Ann H](https://www.pexels.com/photo/sand-sign-texture-writing-11022641/)
    on [Pexels](https://www.pexels.com/)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Ann H](https://www.pexels.com/photo/sand-sign-texture-writing-11022641/)
    提供，发布在 [Pexels](https://www.pexels.com/)
- en: 'For the experiment, there will be three different graphics cards, but four
    levels of comparison:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这项实验，将会有三种不同的显卡，但有四个比较级别：
- en: NVIDIA RTX 1070 (Basic)
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NVIDIA RTX 1070（基础）
- en: NVIDIA Tesla T4 (Mid range)
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NVIDIA Tesla T4（中端）
- en: NVIDIA RTX 6000 Ada (High end)
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NVIDIA RTX 6000 Ada（高端）
- en: 2 x NVIDIA RTX 6000 Ada (Double high end!)
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2 x NVIDIA RTX 6000 Ada（双高端！）
- en: So how do these different graphics cards compare in terms of raw specs?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这些不同的显卡在原始规格方面如何比较？
- en: '![](../Images/31ffd6303b1c9dc911b2332516c9b24a.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31ffd6303b1c9dc911b2332516c9b24a.png)'
- en: Comparison of different graphics cards — Table by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 不同显卡的比较 — 表格由作者提供
- en: '***Note:*** *I have included the RTX 4090 in the table above as it is the pinnacle
    of current consumer level graphics cards, and probably the best direct comparison
    to the RTX 6000 Ada. I will reference the 4090 throughout the article as a comparison
    point, although it will not feature in the benchmarks.*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意：*** *我在上面的表格中包含了RTX 4090，因为它是当前消费级显卡的巅峰，可能是与RTX 6000 Ada最直接的比较对象。我将在整篇文章中参考4090作为比较点，尽管它不会出现在基准测试中。*'
- en: 'If the table above is just a load of number with no meaning, then I recommend
    my previous article which goes over some of the jargon:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果上面的表格只是一些没有意义的数字，那么我推荐我的上一篇文章，它介绍了一些术语：
- en: '[](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b?source=post_page-----a62bec69f557--------------------------------)
    [## How to Pick the Best Graphics Card for Machine Learning'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b?source=post_page-----a62bec69f557--------------------------------)
    [## 如何选择最佳的机器学习显卡'
- en: Speed up your training, and iterate faster
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加快训练速度，迭代更快
- en: towardsdatascience.com](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b?source=post_page-----a62bec69f557--------------------------------)
- en: The Professional System
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专业系统
- en: '![](../Images/0df47511780765ce613b7afceb97a5cd.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0df47511780765ce613b7afceb97a5cd.png)'
- en: '*A view from all angles of the professional workstation utilised in this article.
    Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*从各个角度展示了本文使用的专业工作站。图片由* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *提供，授权给Michael Clayton*'
- en: One of the problems with producing an article like this is that you need access
    to a professional level system, and therefore one of the main hurdles is…cost.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 制作这样的文章的一个问题是，你需要访问专业级系统，因此主要障碍之一就是……成本。
- en: Fortunately, there are companies out there that will give access to their equipment
    for trial runs, to allow you to see if it fits your needs. In this particular
    case [Exxact](https://www.exxactcorp.com/) have been kind enough to allow remote
    access to one of their builds for a limited period so I can get the comparisons
    I need.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有些公司会提供设备试用机会，以便你可以查看它是否满足你的需求。在这个特定的案例中，[Exxact](https://www.exxactcorp.com/)
    足够友好地允许远程访问他们的一台设备，以便我可以进行所需的比较。
- en: …the workstation is worth in the region of USD 25,000
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: …工作站的价值大约为25,000美元
- en: To drive home my point about how much these systems can cost I estimate the
    workstation I have been given access to is worth in the region of **USD 25,000**.
    If you want to depress (or impress?) yourself further you can take a look at the
    [**configurator**](https://www.exxactcorp.com/VWS-148320247/configurator) and
    see what can realistically be achieved.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了强调这些系统可能的成本，我估计我所获得访问权限的工作站价值大约为**25,000美元**。如果你想更深刻（或者更惊讶？）了解这些内容，可以查看 [**配置器**](https://www.exxactcorp.com/VWS-148320247/configurator)，看看实际能达到什么水平。
- en: 'Incidentally, if you are seriously in the market for this level of hardware
    you can apply for a remote ‘‘test drive’’ too:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，如果您正在认真考虑这一水平的硬件，您也可以申请远程“试用”：
- en: '[## NVIDIA H100 Test Drive | Exxact'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[## NVIDIA H100 试用 | Exxact'
- en: Test Drive Your Application on the Latest NVIDIA TechnologySign up for remote
    access to our fully-equipped GPU servers…
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用最新 NVIDIA 技术试用您的应用程序，注册以远程访问我们设备齐全的 GPU 服务器……
- en: www.exxactcorp.com](https://www.exxactcorp.com/Services/Test-Drive?utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Test+Drive&source=post_page-----a62bec69f557--------------------------------)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.exxactcorp.com](https://www.exxactcorp.com/Services/Test-Drive?utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Test+Drive&source=post_page-----a62bec69f557--------------------------------)'
- en: 'These are the complete specs of the “professional” system for those that are
    interested:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于感兴趣的人，这些是“专业”系统的完整规格：
- en: '![](../Images/0ad06958c07074b8fa0fb9888eab08b5.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ad06958c07074b8fa0fb9888eab08b5.png)'
- en: Specification of the professional system — Table by author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 专业系统的规格 — 作者提供的表格
- en: '***Note:*** *Feel free to refer to any of the images in this article that included
    the two gold looking GPUs in a black computer case, as those are actual pictures
    of the system detailed above.*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意：*** *您可以参考本文中包含两张金色 GPU 的黑色计算机机箱的任何图片，因为这些是上述系统的实际照片。*'
- en: It is interesting to note that having a high end system is not just about stuffing
    the best graphics card you can get your hands on into your current system. Other
    components need to scale up too. System RAM, motherboard, CPU, cooling, and of
    course power.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，拥有高端系统不仅仅是将您能找到的最佳显卡装入当前系统中。其他组件也需要升级。系统 RAM、主板、CPU、冷却系统以及电源，当然还有电力。
- en: The Contenders
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 竞争者
- en: '![](../Images/afed16c91fe7b379c2ddad574b3321ed.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afed16c91fe7b379c2ddad574b3321ed.png)'
- en: The NVIDIA GeForce GTX 1070 FTW that will be used as the base in this article
    — Image by Author
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中将用作基准的 NVIDIA GeForce GTX 1070 FTW — 作者提供的图片
- en: NVIDIA GeForce GTX 1070
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NVIDIA GeForce GTX 1070
- en: At the bottom of the pack is the GTX 1070, which is readily available to most
    people, but is still ***significantly*** faster than a CPU. It also has a decent
    amount of GPU RAM at 8GB. A good simple consumer level base.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在底部的是 GTX 1070，这对于大多数人来说很容易获得，但仍然***显著*** 比 CPU 更快。它还具有 8GB 的相当数量的 GPU RAM。一个不错的简单消费级基准。
- en: NVIDIA Tesla T4
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NVIDIA Tesla T4
- en: The Tesla T4 is maybe a strange addition, but there are a few reasons for this.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Tesla T4 可能是一个奇怪的补充，但有几个原因。
- en: The first thing to note is that the Tesla T4 is actually a professional graphics
    card, it is just a few generations old.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是，Tesla T4 实际上是一款专业显卡，只是几代之前的产品。
- en: In terms of processing speed it is roughly the equivalent of an RTX 2070, but
    it has double the GPU RAM at 16GB. This additional RAM puts it firmly in the mid
    range of this test. Current generation consumer cards tend to have RAM in this
    range (RTX 4070 [12GB] and RTX 4080 [16GB]), so it represents consumer graphics
    cards in terms of GPU RAM quite nicely.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从处理速度来看，它大致相当于 RTX 2070，但其 GPU RAM 是 16GB 的双倍。这额外的 RAM 使其在此测试中处于中端范围。目前一代的消费级显卡通常有这种范围的
    RAM（RTX 4070 [12GB] 和 RTX 4080 [16GB]），因此它在 GPU RAM 方面代表了消费级显卡。
- en: The final reason is that you can easily access one of these graphics cards for
    free in [Colab](https://colab.research.google.com/). That means anybody reading
    this article can get their hands dirty and run the code to see for themselves!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最终原因是您可以在 [Colab](https://colab.research.google.com/) 免费访问这些显卡。这意味着任何阅读本文的人都可以亲自动手运行代码以查看效果！
- en: The Pro GPU — NVIDIA RTX 6000 Ada
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专业 GPU — NVIDIA RTX 6000 Ada
- en: '![](../Images/17dfd95d7bee19fde31b3b39dd1f0fb1.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17dfd95d7bee19fde31b3b39dd1f0fb1.png)'
- en: '*A view of the two NVIDIA RTX 6000 Ada graphics cards installed in the professional
    workstation utilised in this article. Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*这张图片展示了在本文中使用的专业工作站中安装的两张 NVIDIA RTX 6000 Ada 显卡。图片来源于* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *，由 Michael Clayton 授权*'
- en: There is no doubt about it, the RTX 6000 Ada is an impressive graphics card
    both in terms of specs…and price. With an **MSRP of USD 6,800** it is definitely
    not a cheap graphics card. So why would you buy one (or more!?) if you can get
    an RTX 4090 for a mere USD 1599 (MSRP)?
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 毋庸置疑，RTX 6000 Ada 无论在规格还是价格上都是一款令人印象深刻的显卡。**MSRP 为 6800 美元**，绝对不是便宜的显卡。那么，如果你可以用仅仅
    1599 美元（MSRP）购买 RTX 4090，为什么还要买一张（或者更多！？）RTX 6000 Ada 呢？
- en: The RTX 4090 has half the RAM and uses 50% more power than the RTX 6000 Ada
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: RTX 4090 的 RAM 只有 RTX 6000 Ada 的一半，且功耗比 RTX 6000 Ada 高出 50%
- en: 'I slipped an RTX 4090 into the table to attempt to answer this question. It
    helps to demonstrate what tend to be the two most obvious differences between
    a consumer graphics card and a professional graphics card (at least from the specifications
    alone):'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我在桌子上放了一张 RTX 4090 来尝试回答这个问题。这有助于展示消费者显卡和专业显卡之间最明显的两个区别（至少从规格上来看）：
- en: the amount of GPU RAM available
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可用的 GPU RAM 数量
- en: the maximum power draw in use
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用中的最大功耗
- en: The RTX 4090 has **half the RAM** and **uses 50% more power** than the RTX 6000
    Ada. This is no accident, as will become evident as the article progresses.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: RTX 4090 的 **RAM 只有一半**，且 **功耗高出 50%** 比 RTX 6000 Ada。这绝非偶然，随着文章的深入将会显现出原因。
- en: Furthermore, considering the higher power draw of the RTX 4090, it is also worth
    noting that the RTX 6000 Ada is still roughly **10% faster.**
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑到 RTX 4090 更高的功耗，值得注意的是 RTX 6000 Ada 的速度仍然快了大约**10%**。
- en: Does this additional RAM and reduced power consumption really make a difference?
    Hopefully, the comparison will help to answer that later in the article.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这些额外的 RAM 和降低的功耗真的有区别吗？希望比较能在文章后面帮助回答这个问题。
- en: Any other less obvious advantages?
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有其他不太明显的优点吗？
- en: Well, yes. There are a few additional benefits to getting a professional level
    graphics card.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，获得专业级显卡确实有一些额外的好处。
- en: '***Reliability***'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '***可靠性***'
- en: '![](../Images/db2c37140746242f9b9fda939760a2d1.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db2c37140746242f9b9fda939760a2d1.png)'
- en: Image by [WikiImages](https://pixabay.com/users/wikiimages-1897/?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=62827)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=62827)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [WikiImages](https://pixabay.com/users/wikiimages-1897/?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=62827)，来自
    [Pixabay](https://pixabay.com//?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=62827)
- en: NVIDIA RTX professional graphics cards are certified with a broad range of professional
    applications, tested by leading independent software vendors (ISVs) and workstation
    manufacturers, and backed by a global team of support specialists.
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: NVIDIA RTX 专业显卡经过广泛的专业应用认证，经过领先的独立软件供应商（ISVs）和工作站制造商的测试，并由全球支持专家团队提供支持。
- en: ''
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: -[nvidia.com](https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/rtx-6000/proviz-print-rtx6000-datasheet-web-2504660.pdf)
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: -[nvidia.com](https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/rtx-6000/proviz-print-rtx6000-datasheet-web-2504660.pdf)
- en: In essence this means the graphics cards are likely to be more reliable and
    crash resistant, both on a software (drivers), and hardware level, and if you
    do have a problem, there is an extensive professional network available to solve
    the problem. These factors are obviously very important for enterprise applications
    where time is money.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，这意味着显卡在软件（驱动程序）和硬件层面上可能更可靠、更抗崩溃，如果遇到问题，还有一个广泛的专业网络可以解决问题。这些因素在企业应用中显然非常重要，因为时间就是金钱。
- en: Imagine running a complicated deep learning model for a few days and then losing
    the results due to a crash or bug. Then spending a significant amount more time
    potentially dealing with the problem. Not good!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下运行一个复杂的深度学习模型几天，然后由于崩溃或错误丢失结果。接着还需要花费更多的时间来解决问题。真是不妙！
- en: Is this peace of mind an additional reason to pay up? That really depends on
    your priorities, and scale...
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这种安心感是否成为额外的理由来支付更多的费用？这真的取决于你的优先级和规模...
- en: '***Scale***'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '***规模***'
- en: '![](../Images/d1bde7e0264bca185dd044513861d617.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1bde7e0264bca185dd044513861d617.png)'
- en: Photo by [Daniele Levis Pelusi](https://unsplash.com/@yogidan2012?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/4mpsEm3EGak?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Daniele Levis Pelusi](https://unsplash.com/@yogidan2012?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    在 [Unsplash](https://unsplash.com/photos/4mpsEm3EGak?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    上提供
- en: If you are designing a computer system to have optimal GPU processing power,
    then it may well be that you need more than one GPU. There will obviously be a
    limit on how many GPUs can fit in the system based primarily on the availability
    of motherboard slots, and physical space constraints in the case.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在设计一个具有最佳GPU处理能力的计算机系统，那么可能需要多个GPU。显然，系统中可容纳的GPU数量主要取决于主板插槽的数量以及机箱内的物理空间限制。
- en: However, there are other limiting factors directly related to the GPU itself,
    and this is where consumer GPUs and professional GPUs start to deviate in terms
    of design.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有其他直接与GPU相关的限制因素，这也是消费级GPU和专业GPU在设计上开始偏离的地方。
- en: Consider the fact that a professional motherboard may have availability for
    four dual slot GPUs (like the pro system in this article). So in theory you could
    fit 4 x RTX 6000 Ada GPUs into the system no problem at all. However, you would
    only be able to fit 2 x RTX 4090 on the same board. Why? Because the 4090 is a
    triple slot graphics card (~61mm thick), whereas the 6000 is a dual slot graphics
    card (~40mm thick).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到专业主板可能有四个双槽GPU的插槽（如本文中的专业系统）。理论上，你可以将4 x RTX 6000 Ada GPU装入系统中没有任何问题。然而，你只能在同一主板上装入2
    x RTX 4090。为什么？因为4090是三槽显卡（约61mm厚），而6000是双槽显卡（约40mm厚）。
- en: Consumer level GPUs are just not designed with the same constraints in mind
    (i.e. high density builds), and therefore start to be less useful as you scale
    up.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 消费级GPU的设计并没有考虑到相同的限制（即高密度构建），因此随着规模的扩大，它们的实用性开始下降。
- en: '***Cooling***'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '***冷却***'
- en: Following on from the potential sizing problem…even if the consumer graphics
    card was the same dual slot design, there are further issues.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接着讨论可能的尺寸问题……即使消费级显卡采用相同的双槽设计，还有其他问题。
- en: Pro level GPUs tend to be built with cooling systems (blower type) that are
    designed to draw air through the graphics cards from front to back with a sealed
    shroud to direct the air **straight out of the case** (i.e. no hot air recirculating
    through the case). This allows for pro GPUs to be stacked tightly into the case,
    and still be able to efficiently cool themselves. All with minimal impact on other
    components, or GPUs, in the rest of the case.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 专业级GPU通常配备有冷却系统（吹风机类型），这些系统设计用于从前到后通过显卡抽取空气，并且有封闭的罩子将空气**直接排出机箱**（即没有热空气在机箱内部循环）。这允许专业GPU紧密堆叠在机箱内，同时仍能高效地进行自我冷却，对机箱内其他组件或GPU的影响最小。
- en: '![](../Images/9b7183e130e50d9105f71d7289223a3f.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b7183e130e50d9105f71d7289223a3f.png)'
- en: Two graphics cards one utilising a ‘blower’ cooling system and the other a more
    common fan cooling system. Photo by [Nana Dua](https://www.pexels.com/photo/black-and-silver-car-wheel-4581613/)
    on [Pexels](https://www.pexels.com/). Annotations by author.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 两张显卡，一张采用‘吹风机’冷却系统，另一张采用更常见的风扇冷却系统。图片由[Nana Dua](https://www.pexels.com/photo/black-and-silver-car-wheel-4581613/)拍摄，发布在[Pexels](https://www.pexels.com/)上。注释由作者提供。
- en: Consumer GPUs, on the whole, tend to use fan cooling from above/below. This
    inevitably means hot air from the GPU will recirculate in the case to some degree,
    necessitating excellent case ventilation.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 消费级GPU通常使用从上/下方的风扇冷却。这不可避免地意味着GPU的热空气在机箱内会有一定程度的循环，因此需要优秀的机箱通风。
- en: However, in cases with multiple GPUs, the close proximity of the other graphics
    cards would make fan cooling very ineffective, and will inevitably lead to sub-optimal
    temperatures for both the GPUs, and other components in close proximity.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在多个GPU的机箱中，其他显卡的紧密接近会使风扇冷却变得非常无效，并且不可避免地导致GPU和其他接近组件的温度不理想。
- en: All-in-all professional graphics cards are designed to be tightly and efficiently
    packed into systems, whilst also staying cool and self contained.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，专业显卡设计为紧凑高效地打包到系统中，同时保持冷却和自我封闭。
- en: '***Accuracy***'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '***准确性***'
- en: '![](../Images/68d46195a35471852d50fa101bcc2036.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68d46195a35471852d50fa101bcc2036.png)'
- en: Photo by [Ricardo Arce](https://unsplash.com/@jrarce?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/cY_TCKr5bek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Ricardo Arce](https://unsplash.com/@jrarce?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，发布在[Unsplash](https://unsplash.com/photos/cY_TCKr5bek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)上。
- en: This really isn’t particularly relevant to deep learning specifically, but pro
    GPUs tend to have ECC (Error-Correcting Code) RAM. This would be useful where
    high precision (i.e. a low level of potential random errors from bit flips) is
    a must for whatever processes you are running through the graphics card.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上与深度学习并不特别相关，但专业级 GPU 通常具有 ECC（错误更正码）RAM。在需要高精度（即，位翻转的潜在随机错误低）的处理过程中，这将非常有用。
- en: However, deep learning models are sometimes tuned to be **less** numerically
    precise (half-precision 8-bit calculations), so this is not something that is
    likely to be of real concern for the calculations being run.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，深度学习模型有时会调优为**较少**的数值精度（半精度 8 位计算），因此这对正在运行的计算可能并不会造成实际问题。
- en: Although if those random bit flips happen to crash your model, then it may just
    be worth consideration too.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如果这些随机位翻转导致你的模型崩溃，那么这也可能值得考虑。
- en: The Deep Learning Model
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习模型
- en: '![](../Images/9cb88fa46938284cad845cb26ae8024c.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cb88fa46938284cad845cb26ae8024c.png)'
- en: Photo by [Pixabay](https://www.pexels.com/photo/adult-blur-books-close-up-261909/)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Pixabay](https://www.pexels.com/photo/adult-blur-books-close-up-261909/)
- en: For the deep learning model I wanted something that is advanced, industry leading,
    and demanding for the GPUs. It also has to be scalable in terms of difficulty
    as the GPUs on test have a wide range of capabilities.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于深度学习模型，我希望它既先进又领先行业，并对 GPU 具有较高要求。同时，它也必须在难度上具有可扩展性，因为测试中的 GPU 具有广泛的能力范围。
- en: A pro level model, for a pro level graphics card
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个专业级模型，适用于专业级显卡
- en: For the model to be industry standard rules out building a model from scratch,
    so for this comparison an existing, tried and tested, model will be used by utilising
    transfer learning.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要使模型符合行业标准，就排除了从头开始构建模型的可能性，因此在此比较中，将利用迁移学习使用现有的、经过验证的模型。
- en: Heavy data
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大数据
- en: To ensure the input data is heavy, the analysis will be image based, specifically
    image classification.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保输入数据的重量，分析将基于图像，特别是图像分类。
- en: Scalability
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性
- en: The final criteria is scalability, and there is a particular set of models out
    there that fits this criteria perfectly…
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最终标准是可扩展性，有一组特定的模型完全符合这一标准……
- en: EfficientNet
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EfficientNet
- en: '[EfficientNet](https://keras.io/api/applications/efficientnet/) consists of
    a family of image classification models (B0 to B7). Each model gets progressively
    more complicated (and accurate). It also has a different expected input shape
    for the images that you feed in as you progress through the family of models,
    which increases data input size.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[EfficientNet](https://keras.io/api/applications/efficientnet/) 由一系列图像分类模型（B0
    到 B7）组成。每个模型都变得越来越复杂（也更准确）。随着你在模型系列中的进展，它也有不同的预期输入形状，从而增加了数据输入大小。'
- en: '![](../Images/c161d9c0ab0fcf926c4bbb9aa17306c1.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c161d9c0ab0fcf926c4bbb9aa17306c1.png)'
- en: 'Comparison of the different EfficientNet models — Data from [EfficientNet:
    Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946.pdf)
    — Table by author'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '不同 EfficientNet 模型的比较——数据来源于[EfficientNet: Rethinking Model Scaling for Convolutional
    Neural Networks](https://arxiv.org/pdf/1905.11946.pdf)——表格由作者提供'
- en: 'This has a two fold effect:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这有两个方面的效果：
- en: as you progress through the different EfficientNet models, the model parameters
    will increase (i.e. a more complicated and demanding model for the GPUs to process)
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随着你在不同的 EfficientNet 模型中进展，模型参数会增加（即，对 GPU 处理要求更复杂、更高的模型）。
- en: the volume of raw data that needs to be processed will also increase (ranging
    from 224x224 pixels up to 600x600 pixels)
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要处理的原始数据量也会增加（从 224x224 像素到 600x600 像素不等）。
- en: Ultimately, this gives a large range of possibilities in terms of loading the
    GPUs both in terms of processing speed and GPU RAM requirements.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*最终*，这为加载 GPU 提供了广泛的可能性，包括处理速度和 GPU RAM 需求。'
- en: The Data
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: The [data](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)¹ utilised
    in this article is a set of images which depict the three possible combinations
    of hand position used in the game rock-paper-scissors.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的数据集是一组图像，描绘了游戏石头剪子布中手势的三种可能组合。[数据](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)¹。
- en: '![](../Images/36774ae755eb3b167772996581fd5ac3.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36774ae755eb3b167772996581fd5ac3.png)'
- en: Four examples from the three different categories of the [dataset](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors).
    Composite image by Author.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[数据集](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)的四个示例，分为三种不同的类别。合成图像由作者提供。
- en: Each image is of type PNG, and of dimensions 300(W) pixels x 200(H) pixels,
    in full colour.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 每张图片为 PNG 格式，尺寸为 300（宽）像素 x 200（高）像素，全彩色。
- en: The original dataset contains 2188 images in total, but for this article a smaller
    selection has been used, which comprises of precisely 2136 images (712 images
    for each category). This slight reduction in total images from the original has
    been done simply to balance the classes.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集总共包含 2188 张图片，但为了这篇文章使用了一个较小的选择，共包含 2136 张图片（每个类别 712 张）。从原始数据集中略微减少总图片数，是为了平衡类别。
- en: 'The balanced dataset that was used in this article is available here:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用的平衡数据集可以在这里找到：
- en: '[](https://github.com/thetestspecimen/notebooks/tree/main/datasets/rock_paper_scissors?source=post_page-----a62bec69f557--------------------------------)
    [## notebooks/datasets/rock_paper_scissors at main · thetestspecimen/notebooks'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[## notebooks/datasets/rock_paper_scissors at main · thetestspecimen/notebooks](https://github.com/thetestspecimen/notebooks/tree/main/datasets/rock_paper_scissors?source=post_page-----a62bec69f557--------------------------------)'
- en: These datasets are a selection of the original "rock paper scissors" dataset
    as detailed in the references section…
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这些数据集是原始“石头剪子布”数据集的一个选择，详细信息请见参考部分…
- en: github.com](https://github.com/thetestspecimen/notebooks/tree/main/datasets/rock_paper_scissors?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/thetestspecimen/notebooks/tree/main/datasets/rock_paper_scissors?source=post_page-----a62bec69f557--------------------------------)'
- en: The Test
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试
- en: '![](../Images/ce6041dc727b1d38f2fd19a3f8f4261a.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce6041dc727b1d38f2fd19a3f8f4261a.png)'
- en: Photo by [Kelly Sikkema](https://unsplash.com/@kellysikkema?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/4JxV3Gs42Ks?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[凯利·西克马](https://unsplash.com/@kellysikkema?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄于[Unsplash](https://unsplash.com/photos/4JxV3Gs42Ks?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: 'As mentioned previously, there are various levels of EfficientNet available,
    so for the purposes of testing, the following will be run on each GPU:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，EfficientNet 提供了各种不同的级别，因此为了测试，以下将在每个 GPU 上运行：
- en: '**EfficientNet B0** (simple)'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**EfficientNet B0**（简单）'
- en: '**EfficientNet B3** (intermediate)'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**EfficientNet B3**（中等）'
- en: '**EfficientNet B7** (intensive)'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**EfficientNet B7**（高强度）'
- en: This will test the graphics cards speed capabilities due to the difference in
    overall parameters of each model, but also a wide range of RAM requirements as
    the input image sizes will vary too.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这将测试显卡的速度能力，由于每个模型的总体参数不同，也会测试内存需求的范围，因为输入图像大小也会有所不同。
- en: The EfficientNet models will have all of their layers unlocked and allowed to
    learn.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: EfficientNet 模型将解锁所有层，并允许进行学习。
- en: 'The three final models:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 三个最终模型：
- en: '[PRE0]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Speed Test
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 速度测试
- en: The speed of the GPUs will be judged by how quickly they can complete an epoch.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 的速度将通过其完成一个周期的速度来评估。
- en: To be more specific, there will be a minimum of two epochs run on each graphics
    card, and the second epoch will be used to judge the processing speed. The first
    epoch generally has some additional loading time, so would not be a good reference
    for general execution time.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，每个显卡上将运行至少两个周期，第二个周期将用于判断处理速度。第一个周期通常会有额外的加载时间，因此不适合作为一般执行时间的参考。
- en: The time to run the first epoch will be listed only for reference.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个周期的运行时间仅供参考。
- en: GPU RAM Test
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 内存测试
- en: To test the limits of the GPU RAM, the batch size for each graphics card, and
    each EfficientNet model (i.e. B0, B3 or B7), has been tuned to be as close as
    possible to the limit for that particular graphics card (i.e. to fill the GPU
    RAM as much as possible).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试 GPU 内存的极限，每个显卡的批量大小和每个 EfficientNet 模型（即 B0、B3 或 B7）已调整到尽可能接近该显卡的极限（即尽可能填满
    GPU 内存）。
- en: The actual peak GPU RAM utilisation for the run will also be disclosed for comparison.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的峰值 GPU 内存使用情况也会披露，以便进行比较。
- en: The Code
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码
- en: '![](../Images/58a7cdf931b08f72018c64ec24fa5128.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58a7cdf931b08f72018c64ec24fa5128.png)'
- en: Photo by [Oskar Yildiz](https://unsplash.com/@oskaryil?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/cOkpTiJMGzA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[奥斯卡·伊尔迪兹](https://unsplash.com/@oskaryil?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄于[Unsplash](https://unsplash.com/photos/cOkpTiJMGzA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: 'As ever, I have made all the python scripts (GTX 1070 and RTX 6000 Ada) and
    notebooks (Tesla T4) available on GitHub:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我将所有的 Python 脚本（GTX 1070 和 RTX 6000 Ada）以及笔记本（Tesla T4）都提供在 GitHub 上：
- en: '[](https://github.com/thetestspecimen/notebooks/tree/main/pro-vs-consumer-graphics-card?source=post_page-----a62bec69f557--------------------------------)
    [## notebooks/pro-vs-consumer-graphics-card at main · thetestspecimen/notebooks'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/thetestspecimen/notebooks/tree/main/pro-vs-consumer-graphics-card?source=post_page-----a62bec69f557--------------------------------)
    [## notebooks/pro-vs-consumer-graphics-card at main · thetestspecimen/notebooks'
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab or…
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你现在无法执行该操作。你在另一个标签或窗口中登录了。你在另一个标签中登出了…
- en: github.com](https://github.com/thetestspecimen/notebooks/tree/main/pro-vs-consumer-graphics-card?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/thetestspecimen/notebooks/tree/main/pro-vs-consumer-graphics-card?source=post_page-----a62bec69f557--------------------------------)
- en: 'You can also access the notebooks for the Tesla T4 directly on Colab if you
    so wish:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，也可以直接在 Colab 上访问 Tesla T4 的笔记本：
- en: 'EfficientNetB0:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: EfficientNetB0：
- en: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B0.ipynb)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B0.ipynb)'
- en: 'EfficientNetB3:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: EfficientNetB3：
- en: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B3.ipynb)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B3.ipynb)'
- en: 'EfficientNetB7:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: EfficientNetB7：
- en: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B7.ipynb)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B7.ipynb)'
- en: The Results
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: '![](../Images/07b2b58f8ce44db7d0d0703e05a3e93f.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07b2b58f8ce44db7d0d0703e05a3e93f.png)'
- en: Photo by [Pixabay](https://www.pexels.com/photo/business-commerce-computer-delivery-263194/)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Pixabay](https://www.pexels.com/photo/business-commerce-computer-delivery-263194/)
- en: EfficientNet B0
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EfficientNet B0
- en: '![](../Images/777a63908da503045aeb462939760cba.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/777a63908da503045aeb462939760cba.png)'
- en: EfficientNet B3
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EfficientNet B3
- en: '![](../Images/06c1457350384a0f6731185373fefbff.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06c1457350384a0f6731185373fefbff.png)'
- en: EfficientNet B7
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EfficientNet B7
- en: '![](../Images/7a6c34f8712e1ac26d7e22315665111d.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a6c34f8712e1ac26d7e22315665111d.png)'
- en: '***Note:*** *for the first epoch I have listed a number of seconds in brackets.
    This is the time difference between the first and second epoch.*'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意：*** *在第一轮训练中，我列出了括号中的秒数。这是第一轮和第二轮训练之间的时间差。*'
- en: Discussion — Execution Speed
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论 — 执行速度
- en: '![](../Images/ef885c6083787cb3235968f4817c2f8f.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef885c6083787cb3235968f4817c2f8f.png)'
- en: Image by [Arek Socha](https://pixabay.com/users/qimono-1962238/?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=1249610)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=1249610)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Arek Socha](https://pixabay.com/users/qimono-1962238/?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=1249610)
    提供，来自 [Pixabay](https://pixabay.com//?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=1249610)
- en: The first item to look at is execution speed.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个要查看的项是执行速度。
- en: EfficientNet B0 doesn’t cause much of a challenge for any of the graphics cards
    with this particular dataset, with all completing an epoch in a matter of seconds.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个特定的数据集，EfficientNet B0 对任何显卡都没有造成太大的挑战，所有显卡都在几秒钟内完成了一轮训练。
- en: However, it is important to remember that the dataset utilised in this article
    is small, and in reality the two RTX 6000 Ada graphics cards are approximately
    **17 times faster** that the GTX 1070 (and Tesla T4) in terms of execution speed.
    The story is pretty much the same for EfficientNet B3 (8x faster) and B7 (11x
    faster).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要记住的是，本文章使用的数据集很小，实际上，两块 RTX 6000 Ada 显卡在执行速度上大约比 GTX 1070（和 Tesla T4）快**17倍**。对于
    EfficientNet B3（快 8 倍）和 B7（快 11 倍），情况也基本相同。
- en: The difference is that this slow down in speed, when viewed as execution time,
    starts to become more of a hindrance the more complicated the model gets.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 区别在于，当将其视为执行时间时，这种速度的减慢会随着模型的复杂性增加而变得更具障碍。
- en: For example, to execute a single epoch, on this very small dataset, using EfficientNet
    B7 with a GTX 1070 takes approximately 15 mins. Compare that to just over 1 minute
    with a pair of RTX 6000 Ada.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在这个非常小的数据集上，使用GTX 1070执行一个周期大约需要15分钟。与一对RTX 6000 Ada的1分钟多一点相比。
- en: …and it gets worse.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: …情况更糟。
- en: Scaling up
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展规模
- en: Let’s be realistic. No model is going to converge in one epoch. Four hundred
    might be a more reasonable number for a model like EfficientNet.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现实一点。没有模型会在一个周期内收敛。对于像EfficientNet这样的模型，四百可能是一个更合理的数字。
- en: That would be the difference between **4 days** on a GPU like the GTX 1070,
    and only a few hours (6.5 to be precise) on a dual RTX 6000 Ada setup. Then consider
    that a real dataset doesn’t have only 2188 images, it could have millions (for
    reference [ImageNet](https://www.image-net.org/) has just over **14 million images**).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是使用像GTX 1070这样的GPU需要**4天**的差距，而在双RTX 6000 Ada设置下仅需几个小时（准确地说是6.5小时）。然后考虑到实际数据集不只有2188张图片，它可能有数百万张（作为参考，[ImageNet](https://www.image-net.org/)有刚刚超过**1400万张图片**）。
- en: Industry progress
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行业进展
- en: Another thing to bear in mind is progress in industry. EfficientNet is a few
    years old now, and things have moved on.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要记住的是行业进展。EfficientNet已经有几年历史了，情况已经发生了变化。
- en: 'As a small example take [NoisyStudent](https://arxiv.org/pdf/1911.04252v4.pdf),
    which builds on the standard EfficientNets with a variation called EfficientNet-L2
    and states:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 举个小例子，[NoisyStudent](https://arxiv.org/pdf/1911.04252v4.pdf)在标准EfficientNets的基础上增加了一种叫做EfficientNet-L2的变体，并表示：
- en: Due to the large model size, the training time of EfficientNet-L2 is approximately
    five times the training time of EfficientNet-B7
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于模型大小较大，EfficientNet-L2的训练时间大约是EfficientNet-B7的五倍。
- en: ''
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: -[Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/pdf/1911.04252v4.pdf)
  id: totrans-210
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: -[自我训练与Noisy Student改进ImageNet分类](https://arxiv.org/pdf/1911.04252v4.pdf)
- en: …so speed really does matter if you need to stay at the cutting edge.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: …所以如果你需要保持在前沿，速度确实很重要。
- en: What does that mean for pro vs consumer graphics cards then?
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么这对专业图形卡与消费者图形卡意味着什么呢？
- en: The truth is that if you **only** look at speed of execution there is very little
    difference between professional and consumer GPUs if you compare like for like.
    An RTX 4090 is near as makes no difference the same speed as an RTX 6000 Ada.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 事实是，如果你**仅仅**看执行速度，专业和消费者GPU之间几乎没有区别，如果你对比相同条件下的产品。RTX 4090的速度几乎和RTX 6000 Ada一样。
- en: An RTX 4090 is near as makes no difference the same speed as an RTX 6000 Ada.
  id: totrans-214
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: RTX 4090的速度几乎和RTX 6000 Ada一样。
- en: All this little experiment has illustrated so far is that speed is very important,
    as industry standard models are progressing in complexity quite quickly. Older
    generation graphics cards are noticeably slower already. To keep up requires **at
    least** staying on the cutting edge of hardware.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止，这个小实验仅仅说明了速度非常重要，因为行业标准模型的复杂性发展很快。老一代图形卡已经明显较慢。要跟上，就需要**至少**保持在硬件的前沿。
- en: …scale matters a great deal when answering this question.
  id: totrans-216
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: …规模在回答这个问题时确实很重要。
- en: …but with the speed of progression (just look at the rapid accent of GTP-3 and
    GTP-4) it also appears that if you want to stay at the cutting edge, one GPU,
    even at the level of the RTX 4090 or RTX 6000 Ada, is unlikely to be enough. If
    that is the case, then the superior cooling, less power draw and more compact
    size of the professional level graphics cards are a significant advantage when
    building a system.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: …但随着进展速度的加快（只需看看GTP-3和GTP-4的迅速发展），如果你想保持在前沿，即使是RTX 4090或RTX 6000 Ada级别的单个GPU也可能不够。如果是这样的话，专业级图形卡在构建系统时优越的散热、较低的功耗和更紧凑的尺寸就是一个显著的优势。
- en: Essentially, scale matters a great deal when answering this question.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，规模在回答这个问题时非常重要。
- en: However, speed is only one facet. Now let’s move on to the GPU RAM, where things
    get a little more interesting…
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，速度只是一个方面。现在让我们转到GPU RAM，这里情况会有些更有趣…
- en: Discussion — GPU RAM
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论 — GPU RAM
- en: GPU RAM is a significant consideration in some situations, and can be a literal
    limiting factor as to whether certain models, or datasets, can be utilised at
    all.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: GPU RAM在某些情况下是一个重要的考虑因素，甚至可能是是否可以使用某些模型或数据集的实际限制因素。
- en: 'Let’s see the pair of RTX 6000 Ada in full flow:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一对RTX 6000 Ada的全面表现：
- en: '![](../Images/d888542c0d46ff23fd76e6d112f96c4c.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d888542c0d46ff23fd76e6d112f96c4c.png)'
- en: The two RTX 6000 Ada GPUs running a deep learning model. Image by Author
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 两张 RTX 6000 Ada GPU 正在运行深度学习模型。图片由作者提供
- en: 'You may notice in the image above that the GPU RAM is at 100% for both GPUs.
    However, the this is not the real usage:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到上面的图片中两个 GPU 的 GPU RAM 都达到了 100%。然而，这并不是真实的使用情况：
- en: By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject
    to `[*CUDA_VISIBLE_DEVICES*](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)`)
    visible to the process. This is done to more efficiently use the relatively precious
    GPU memory resources on the devices by reducing memory fragmentation.
  id: totrans-226
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 默认情况下，TensorFlow 会映射几乎所有 GPU 的 GPU 内存（受 `[*CUDA_VISIBLE_DEVICES*](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)`）到进程中。这是为了通过减少内存碎片来更有效地利用设备上相对宝贵的
    GPU 内存资源。
- en: ''
  id: totrans-227
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[-tensorflow.org](https://www.tensorflow.org/guide/gpu)'
  id: totrans-228
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[-tensorflow.org](https://www.tensorflow.org/guide/gpu)'
- en: The limits
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: The absolute limit is brought home quite starkly by the fact that the GTX 1070
    (which has 8GB of GPU RAM) is only capable of running EfficientNet B7 with a batch
    size of 1 (i.e. it can process 1 image at a time before having to update the model
    parameters and load the next image into the GPU RAM).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对的限制被 GTX 1070（它有 8GB GPU RAM）所凸显，它只能以批量大小为 1 运行 EfficientNet B7（即它每次只能处理 1
    张图片，然后更新模型参数并将下一张图片加载到 GPU RAM 中）。
- en: 'This causes two problems:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这会引发两个问题：
- en: You lose speed of execution due to frequent parameter updates in addition to
    loading in fresh data to the GPU RAM more regularly (i.e. larger batch sizes are
    inherently quicker.)
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于频繁的参数更新和更频繁地将新数据加载到 GPU RAM 中（即更大的批量大小本质上更快），你会失去执行速度。
- en: If the input image size gets any larger, the model will not be able to run at
    all, as it won’t fit one single image into the GPU RAM
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果输入图像尺寸再大一点，模型将无法运行，因为它无法将单张图像放入 GPU RAM 中。
- en: Even the Tesla T4 which has a not too shabby 16GB of GPU memory only manages
    a batch size of 2 on EfficientNet B7.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是 Tesla T4，它拥有不算差的 16GB GPU 内存，在 EfficientNet B7 上也只能处理批量大小为 2 的任务。
- en: As detailed earlier, 16GB of GPU RAM is a good representation of the majority
    of current generation consumer GPUs, with only the RTX 4090 having more at 24GB.
    So this is a fairly significant downfall for consumer GPUs if you are dealing
    with memory heavy raw data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，16GB 的 GPU RAM 是大多数当前一代消费级 GPU 的良好代表，只有 RTX 4090 拥有 24GB。因此，如果你处理的是内存密集型原始数据，这对消费级
    GPU 来说是一个相当显著的缺点。
- en: At this point it suddenly becomes clear why all the professional GPUs are so
    RAM heavy when compared to their consumer equivalents. As mentioned in the discussion
    for the speed of execution, EfficientNet is no longer at the bleeding edge, so
    the reality today is probably even more demanding than outlined in the tests for
    this article.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，为什么所有专业 GPU 相比于消费级 GPU 拥有如此大量的 RAM 突然变得清晰。正如执行速度讨论中提到的，EfficientNet 已经不再处于前沿，因此今天的现实可能比这篇文章中的测试所述还要苛刻。
- en: System density
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统密度
- en: Another consideration in regard to GPU RAM is system density.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 GPU RAM 的另一个考虑因素是系统密度。
- en: 'For example, the system I have been given access to has a motherboard that
    can take 4 double height GPUs (I have also seen systems with up to 8 GPUs). This
    means that if GPU RAM is a priority in your system, then professional GPUs are
    a no brainer:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我可以访问的系统有一个可以容纳 4 张双高显卡的主板（我也见过最多可安装 8 张显卡的系统）。这意味着如果你的系统对 GPU RAM 有优先需求，那么专业
    GPU 就是不二选择：
- en: 4 x RTX 6000 Ada = 192GB GPU RAM and 1200W of power draw
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 4 x RTX 6000 Ada = 192GB GPU RAM 和 1200W 功耗
- en: 4 x RTX 4090 = 96GB GPU RAM and 1800W of power draw
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 4 x RTX 4090 = 96GB GPU RAM 和 1800W 功耗
- en: (…and as I have already mentioned earlier in the article the RTX 4090 is a triple
    slot GPU so this isn’t even realistic. In reality only two RTX 4090 graphics cards
    would actually fit, but for the sake of easy comparison let’s assume it would
    work.)
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: （……正如我在文章前面提到的，RTX 4090 是一款三槽 GPU，所以这甚至不切实际。实际上，只有两张 RTX 4090 显卡才能实际适配，但为了方便比较，我们假设它是可行的。）
- en: That is no small difference. To match the RTX 6000 Ada system in terms of GPU
    RAM you would need two separate systems drawing at least **three times the power**.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个小差异。要匹配 RTX 6000 Ada 系统的 GPU RAM，你将需要两个分别消耗至少 **三倍功率** 的系统。
- en: To match the RTX 6000 Ada system in terms of RAM you would need two separate
    systems drawing at least three times the power.
  id: totrans-244
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要匹配 RTX 6000 Ada 系统的 RAM，你将需要两个分别消耗至少三倍功率的系统。
- en: Don’t forget that as you would need two separate systems, you would have to
    fork out for additional CPUs, power supplies, motherboards, cooling, cases etc.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了，因为你需要两个独立的系统，你还需要额外支付 CPU、电源、主板、冷却、机箱等费用。
- en: A side note on system RAM…
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于系统 RAM 的一个附注…
- en: '![](../Images/ffbcf362988e23943cc958ed6a9f0a7b.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ffbcf362988e23943cc958ed6a9f0a7b.png)'
- en: '*Did you notice 8 sticks of 64GB system RAM above and below the CPU in the
    professional system? Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '*你是否注意到在专业系统中，CPU 上下各有 8 根 64GB 的系统 RAM？图片来自* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *，由 Michael Clayton 授权使用*'
- en: It is also worth pointing out, that it is not just the GPU RAM that matters.
    As the GPU RAM scales up you need to increase the system RAM in parallel.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得指出的是，重要的并不仅仅是 GPU RAM。随着 GPU RAM 的增加，你需要同步增加系统 RAM。
- en: 'You may note in the Jupyter notebooks for the Tesla T4 that I have commented
    out the following optimisations:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，在 Tesla T4 的 Jupyter notebooks 中，我已注释掉了以下优化：
- en: '[PRE1]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is because, for EfficientNet B7, the training will crash if they are enabled.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为，对于 EfficientNet B7，如果启用这些设置，训练将崩溃。
- en: Why?
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么？
- en: 'Because the “.cache()” optimisation keeps the data in system memory to feed
    it efficiently to the GPU, and the Colab instance only has 12GB of system memory.
    Which is not enough, even though the GPU RAM peaks at 9.9GB:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 因为“.cache()”优化将数据保留在系统内存中，以便有效地传递给 GPU，而 Colab 实例只有 12GB 的系统内存。这还不够，即使 GPU RAM
    峰值为 9.9GB：
- en: This [.cache()] will save some operations (like file opening and data reading)
    from being executed during each epoch.
  id: totrans-255
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个 [.cache()] 会将一些操作（如文件打开和数据读取）从每个训练周期中省略。
- en: ''
  id: totrans-256
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: -[tensorflow.org](https://www.tensorflow.org/guide/data_performance)
  id: totrans-257
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: -[tensorflow.org](https://www.tensorflow.org/guide/data_performance)
- en: However, the professional system has 8 sticks of 64GB system RAM, for a total
    of 512GB of system RAM. So even though the two RTX 6000 Ada GPUs combined have
    96GB of GPU RAM, there is still plenty of overhead in the system RAM to deal with
    heavy caching.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，专业系统有 8 根 64GB 的系统 RAM，总计 512GB 的系统 RAM。所以即使两张 RTX 6000 Ada GPU 合计有 96GB
    的 GPU RAM，系统 RAM 仍有足够的余量来处理大量缓存。
- en: Conclusion
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: '![](../Images/921383d94b40284165c0c98bef51c2b2.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/921383d94b40284165c0c98bef51c2b2.png)'
- en: '*Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '*图片来自* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *，由 Michael Clayton 授权使用*'
- en: So, are professional level graphics cards better than consumer cards for deep
    learning?
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，专业级显卡在深度学习中是否优于消费级显卡？
- en: Money no object. Yes, they are.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果钱不是问题，那么是的，它们更好。
- en: Does that mean that you should discard considering consumer level graphics cards
    for deep learning?
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着你应该放弃考虑用于深度学习的消费级显卡？
- en: No, it doesn’t.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 不，并不是。
- en: It all comes down to specific requirements, and more often than not scale.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这完全取决于具体的需求，通常情况下，更是规模。
- en: Large datasets
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型数据集
- en: If you know that your workload is going to be RAM intensive (large language
    models, image, or video based analysis for example) then professional graphics
    cards of the same generation and processing speed tend to have roughly double
    the GPU RAM.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你知道你的工作负载将是内存密集型的（例如大型语言模型、图像或视频分析），那么同一代和处理速度的专业显卡通常拥有大约两倍的 GPU RAM。
- en: It all comes down to specific requirements, and scale.
  id: totrans-269
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这完全取决于具体的需求和规模。
- en: This is a significant advantage, especially considering there is no elevation
    in energy requirements to achieve this compared to a consumer graphics card.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个显著的优势，特别是考虑到与消费级显卡相比，实现这一点不需要额外增加能源需求。
- en: Smaller datasets
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 较小的数据集
- en: If you don’t have high RAM requirements, then the question is more nuanced and
    relies on whether reliability, compatibility, support, energy consumption, and
    that additional 10% in terms of speed are worth the quite significant hike in
    price.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的 RAM 需求不高，那么问题就更复杂了，涉及到可靠性、兼容性、支持、能源消耗，以及额外 10% 的速度是否值得那显著的价格上涨。
- en: Scale
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规模
- en: If you are about to invest in significant infrastructure, then reliability,
    energy consumption and system density may move from low priority to quite significant
    considerations. Areas that professional GPUs excel at.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算投资重大基础设施，那么可靠性、能源消耗和系统密度可能从低优先级变为相当重要的考虑因素。这些都是专业GPU擅长的领域。
- en: Conversely, if you need a smaller system, and high GPU RAM requirements aren’t
    important, then considering consumer level graphics cards may turn out to be beneficial.
    Factors associated with large scale, such as reliability and energy consumption
    will become less of an issue, and system density won’t matter at all.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果你需要一个较小的系统，并且高GPU内存需求并不重要，那么考虑消费者级别的显卡可能会有利。与大规模相关的因素，如可靠性和能源消耗将变得不那么重要，系统密度也不会成为问题。
- en: The final word
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终结论
- en: 'All in all it is a balancing act, but if I had to pick two items to summarise
    the most important factors in choosing between a consumer GPU and professional
    GPU it would be:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这是一个平衡的过程，但如果我必须选择两个因素来总结选择消费者级GPU与专业级GPU之间最重要的因素，那就是：
- en: GPU RAM
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU内存
- en: System scale
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统规模
- en: If you have **either** high GPU RAM requirements, or will need larger systems
    with multiple GPUs, then you need a professional level GPU/GPUs.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有**较高**的GPU内存需求，或需要配备多个GPU的大型系统，那么你需要一个专业级的GPU/多个GPU。
- en: Otherwise, most likely, consumer level will be a better deal.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，大多数情况下，消费者级别可能会是一个更好的选择。
- en: If you found this article interesting or useful, remember to follow me, or [sign
    up for my newsletter](https://medium.com/@maclayton/subscribe) for more content
    like this.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这篇文章有趣或有用，记得关注我，或[订阅我的通讯](https://medium.com/@maclayton/subscribe)以获取更多类似的内容。
- en: If you haven’t already, you could also consider [subscribing to Medium](https://medium.com/@maclayton/membership).
    Your membership fee directly supports, not just me, but other writers you read
    too. You’ll also get full unrestricted access to every story on Medium.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有，可以考虑[订阅Medium](https://medium.com/@maclayton/membership)。你的会员费不仅直接支持我，还支持你阅读的其他作者。你还将获得Medium上每一篇文章的完全无限制访问权限。
- en: Using my referral link to sign up will grant me a small kickback with zero effect
    on your membership, so thank you if you choose to do so.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我的推荐链接注册将为我带来少量佣金，但不会影响你的会员资格，所以如果你选择这样做，谢谢你。
- en: '[](https://medium.com/@maclayton/membership?source=post_page-----a62bec69f557--------------------------------)
    [## Join Medium with my referral link - Mike Clayton'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maclayton/membership?source=post_page-----a62bec69f557--------------------------------)
    [## 通过我的推荐链接加入Medium - Mike Clayton'
- en: Read every story from Mike Clayton (and thousands of other writers on Medium).
    Your membership fee directly supports…
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读Mike Clayton的每一篇文章（以及Medium上的其他成千上万的作者）。你的会员费直接支持…
- en: medium.com](https://medium.com/@maclayton/membership?source=post_page-----a62bec69f557--------------------------------)
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@maclayton/membership?source=post_page-----a62bec69f557--------------------------------)
- en: References
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Julien de la Bruère-Terreault, [Rock-Paper-Scissors Images](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)
    (2018), Kaggle, License: [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Julien de la Bruère-Terreault, [石头剪子布图像](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)
    (2018), Kaggle, 许可协议：[CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)'
