- en: AudioGPT — A Glimpse into the Future of Creating Music
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AudioGPT — 探索未来音乐创作的前景
- en: 原文：[https://towardsdatascience.com/audiogpt-a-glimpse-into-the-future-of-creating-music-9e8e0c65069e](https://towardsdatascience.com/audiogpt-a-glimpse-into-the-future-of-creating-music-9e8e0c65069e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/audiogpt-a-glimpse-into-the-future-of-creating-music-9e8e0c65069e](https://towardsdatascience.com/audiogpt-a-glimpse-into-the-future-of-creating-music-9e8e0c65069e)
- en: Research paper analyzed and explained
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研究论文分析和解释
- en: '[](https://medium.com/@maxhilsdorf?source=post_page-----9e8e0c65069e--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----9e8e0c65069e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e8e0c65069e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e8e0c65069e--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----9e8e0c65069e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maxhilsdorf?source=post_page-----9e8e0c65069e--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----9e8e0c65069e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e8e0c65069e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e8e0c65069e--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----9e8e0c65069e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e8e0c65069e--------------------------------)
    ·10 min read·May 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e8e0c65069e--------------------------------)
    ·阅读时间 10 分钟·2023 年 5 月 2 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7c61267fd6c17c0ecfb42939253873df.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c61267fd6c17c0ecfb42939253873df.png)'
- en: Image from [Pixabay](https://www.pexels.com/de-de/foto/low-angle-view-von-beleuchtungsgeraten-im-regal-257904/).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Pixabay](https://www.pexels.com/de-de/foto/low-angle-view-von-beleuchtungsgeraten-im-regal-257904/)。
- en: 'With [MusicLM](https://google-research.github.io/seanet/musiclm/examples/)
    released in January 2023, it became clear to musicians and data scientists alike:
    AI is here to disrupt the way we make music. Only a few days ago, the next big
    audio AI model was published. In this post, we will explore why I think **this
    model may be the foundation of a major technological disruption in music production**.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 [MusicLM](https://google-research.github.io/seanet/musiclm/examples/) 于 2023
    年 1 月发布，音乐家和数据科学家都清楚了：AI 正在颠覆我们制作音乐的方式。就在几天前，下一代大型音频 AI 模型发布了。在这篇文章中，我们将探讨为什么我认为
    **这个模型可能是音乐制作重大技术变革的基础**。
- en: 'This post addresses the following questions:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文解决了以下问题：
- en: What is AudioGPT?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 AudioGPT？
- en: How does it work?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: What are its capabilities & limitations?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的能力和限制是什么？
- en: What does this mean for the future of making music?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这对未来的音乐制作意味着什么？
- en: What is AudioGPT?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 AudioGPT？
- en: AudioGPT is a research project by a group of Chinese and U.S. researchers published
    in April 2023 **[1]**. But what does it actually do and how does it relate to
    GPT models? Well, let’s ask it!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: AudioGPT 是由一群中美研究人员于 2023 年 4 月发布的研究项目 **[1]**。但它实际做了什么，它与 GPT 模型有什么关系？好吧，让我们问问它吧！
- en: '![](../Images/e7bbdf3f190c060c8b60a5e39a454a8a.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7bbdf3f190c060c8b60a5e39a454a8a.png)'
- en: 'AudioGPT answers the question: “What is AudioGPT?”. Image by the author.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: AudioGPT 回答了“什么是 AudioGPT？”的问题。图像由作者提供。
- en: AudioGPT is a dialogue assistant
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AudioGPT 是一个对话助手
- en: As you can see from the screenshot, AudioGPT can be used in a chatbot interface
    similar to something like ChatGPT. In fact, it works just like ChatGPT for most
    conversational applications. One unique feature of AudioGPT is that, aside from
    text, the chatbot can handle speech as an input by transcribing the audio to text,
    first. Hence, this is a real dialogue assistant that you can talk to or write
    to, depending on your needs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从截图中可以看出，AudioGPT 可以在类似于 ChatGPT 的聊天界面中使用。实际上，对于大多数对话应用，它的工作方式与 ChatGPT 完全相同。AudioGPT
    的一个独特功能是，除了文本外，聊天机器人还可以处理语音输入，先将音频转录为文本。因此，这是真正的对话助手，你可以根据需求与之对话或书写。
- en: AudioGPT can perform various audio tasks
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AudioGPT 能够执行各种音频任务
- en: 'AudioGPT’s dialogue capabilities are only a support function. Its true purpose
    is to provide a unified experience for solving a multitude of tasks in the realm
    of audio analysis and generation. Here’s a selection of some of the tasks it can
    handle:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: AudioGPT 的对话能力仅仅是一个支持功能。它的真正目的在于提供一个统一的体验来解决音频分析和生成领域中的多种任务。以下是它可以处理的一些任务的精选：
- en: '**Audio Captioning**: describe the content of an audio signal using text'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**音频标题：** 使用文本描述音频信号的内容'
- en: '**Source Separation:** split an audio signal into different events (voices,
    noises, …)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源分离：** 将音频信号拆分成不同的事件（声音、噪音等）'
- en: '**Image-to-audio:** generate audio that fits the content of an image'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像转音频：** 生成符合图像内容的音频'
- en: '**Score-to-audio:** generate a singing voice given text, notes, and note durations'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分数转音频：** 根据文本、音符和音符时值生成歌声'
- en: '**Many more tasks** that we will cover later!'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更多任务** 我们稍后会讨论！'
- en: The cool thing is that AudioGPT, in contrast to ChatGPT, is able to receive
    and send audio files. For example, when I asked AudioGPT to generate a specific
    sound for me, it created the sounds, exported it to a wav file, and sent me the
    location of the exported file.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，与 ChatGPT 相比，AudioGPT 能够接收和发送音频文件。例如，当我要求 AudioGPT 为我生成特定的声音时，它创建了这些声音，将其导出为
    wav 文件，并将导出文件的位置发送给我。
- en: '![](../Images/62aaf175cdf853d3ea775325c0371fce.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62aaf175cdf853d3ea775325c0371fce.png)'
- en: AudioGPT is asked to generate “the sound of a lion roaring with racing cars
    in the background”. Image by the author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: AudioGPT 被要求生成“狮子吼叫的声音，背景有赛车声”。图片由作者提供。
- en: Before we can understand the significance of this technology for the future
    of music creation, let me first show you how AudioGPT actually works and what
    its strengths and limitations are.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够理解这项技术对未来音乐创作的意义之前，让我首先向你展示 AudioGPT 实际上是如何工作的，以及它的优势和局限性。
- en: How was AudioGPT implemented?
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AudioGPT 是如何实现的？
- en: While AudioGPT might seem like a typical AI chatbot to the user, there is actually
    a lot more going on under the hood. In fact, the chatbot AI (ChatGPT) is only
    used as a translator between the user request and other AI models. Such approaches
    already exist for other domains like image ([TaskMatrix](https://github.com/microsoft/TaskMatrix))
    or text ([LangChain](https://github.com/hwchase17/langchain)). Let us look at
    the illustration of AudioGPTs workflow provided by the authors in their paper
    **[1]**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 AudioGPT 对用户来说可能像一个典型的 AI 聊天机器人，但实际上在幕后还有更多复杂的工作。事实上，聊天机器人 AI（ChatGPT）仅作为用户请求与其他
    AI 模型之间的翻译器。这种方法在图像（[TaskMatrix](https://github.com/microsoft/TaskMatrix)）或文本（[LangChain](https://github.com/hwchase17/langchain)）等其他领域已经存在。让我们看看作者在他们的论文中提供的
    AudioGPT 工作流程的插图 **[1]**。
- en: '![](../Images/1e2355352532863074311bf69920068d.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e2355352532863074311bf69920068d.png)'
- en: Internal workflow of AudioGPT. Image from Huang, Li, Yang, Shit et a. (2023)
    [1].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: AudioGPT 的内部工作流程。图片来源于 Huang, Li, Yang, Shit 等（2023）**[1]**。
- en: As you can see, the workflow is split into four different steps. Let us go through
    all of them, briefly.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，工作流程被分为四个不同的步骤。让我们简要地了解一下所有步骤。
- en: 'Step 1: Modality transformation'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：模态转换
- en: AudioGPT is built to handle speech and text input. Therefore, the first step
    is to check if the user is texting or speaking to the system. If the input is
    speech, it is transcribed and transformed to text by a speech recognition system
    similar to Alexa or Siri. To the user, this conversion step should feel seamless.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: AudioGPT 被设计用于处理语音和文本输入。因此，第一步是检查用户是通过文本还是语音与系统互动。如果输入是语音，则由类似于 Alexa 或 Siri
    的语音识别系统将其转录并转换为文本。对用户而言，这个转换步骤应该是无缝的。
- en: 'Step 2: Task analysis'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2：任务分析
- en: 'With this text input, ChatGPT takes over and tries to understand the user''s
    request. Whether you say “Generate a wav file of a thunder sound effect” or “Give
    me a thunder sound”: ChatGPT is great at understanding different formulations
    of the same problem and mapping the request to a specific task — In this case,
    text-to-audio sound generation.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个文本输入下，ChatGPT 接管并尝试理解用户的请求。无论你说“生成一个雷声效果的 wav 文件”还是“给我一个雷声”：ChatGPT 擅长理解相同问题的不同表述，并将请求映射到特定任务——在这种情况下是文本到音频的声音生成。
- en: 'Step 3: Model assignment'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3：模型分配
- en: Once ChatGPT has understood the request, it selects an appropriate AI model
    from a set of 17 models currently included in the system. Each of these 17 handles
    one specific task in a very specific way. It is therefore crucial that ChatGPT
    understands the request, finds the correct model, and presents the user request
    in a way that the model can process it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 ChatGPT 理解了请求，它会从系统中目前包含的 17 个模型中选择一个合适的模型。这 17 个模型中的每一个都以非常特定的方式处理特定任务。因此，ChatGPT
    理解请求、找到正确模型并以模型可以处理的方式呈现用户请求至关重要。
- en: 'Step 4: Response generation'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4：响应生成
- en: Once an appropriate model is found and run, it will generate an output. This
    output can have all sorts of different modalities (audio, text, image, video).
    That is where ChatGPT comes in, again. It collects the model output and presents
    it to the user in a way that they can understand and interpret it. For example,
    a text output may be directly passed on to the user, whereas an audio output will
    be exported and the user will receive a file path linking to the exported audio.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦找到并运行了合适的模型，它将生成一个输出。这个输出可以有各种不同的形式（音频、文本、图像、视频）。这时 ChatGPT 再次发挥作用。它收集模型输出并以用户可以理解和解释的方式展示给用户。例如，文本输出可能直接传递给用户，而音频输出将被导出，用户将收到一个指向导出音频的文件路径。
- en: Memory & Chat History
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存与聊天历史
- en: Solving one task is great. However, what really stands out about this chatbot
    approach, is that AudioGPT can look at the entire conversation history. This means
    that you can always reference requests, questions, or outputs from earlier in
    the conversation and ask AudioGPT to do something with them. In some sense, it
    feels just like ChatGPT, but with the capability to receive and send audio files.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 解决一个任务是很棒的。然而，这种聊天机器人方法真正突出的地方在于，AudioGPT 可以查看整个对话历史。这意味着你总是可以引用之前对话中的请求、问题或输出，并让
    AudioGPT 对其进行操作。在某种意义上，它感觉就像 ChatGPT，但具有接收和发送音频文件的能力。
- en: What can AudioGPT do?
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AudioGPT 能做些什么？
- en: In this section, I want to give you some examples from the paper of what AudioGPT
    can do. This is, of course, not a comprehensive list, but just some interesting
    highlights.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我想给你一些来自论文的例子，展示 AudioGPT 能做什么。当然，这不是一个全面的列表，而只是一些有趣的亮点。
- en: Image to audio generation
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像到音频生成
- en: '![](../Images/4272971c06721ab8d1fd67d09a2c5f73.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4272971c06721ab8d1fd67d09a2c5f73.png)'
- en: Image to Audio Generation Example from Huang, Li, Yang, Shit et a. (2023) [1].
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图像到音频生成示例来自 Huang, Li, Yang, Shit 等（2023）[1]。
- en: In this example, AudioGPT is asked to generate audio that fits the image of
    a cat. The system then responds with the location of an exported audio file and
    a visualization of the audio waveform. We cannot listen to this example from the
    paper, but the response is most likely a cat sound like a hiss or a purr. Under
    the hood, the image is first captioned and the image caption is then synthesized
    to an audio signal. This could be really helpful for musicians to create samples
    for their music by simply inputting an image of what they are looking for.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，AudioGPT 被要求生成与猫的图像相匹配的音频。系统随后会响应导出音频文件的位置和音频波形的可视化。我们不能听到这篇论文中的示例，但响应很可能是类似于猫的嘶嘶声或咕噜声。在后台，首先对图像进行描述，然后将图像描述合成成音频信号。这对于音乐家来说可能非常有帮助，只需输入他们所寻找的图像，就可以为音乐创建样本。
- en: Singing voice generation
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 歌唱声音生成
- en: '![](../Images/401d50f22b98b666f04bd771b834ca36.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/401d50f22b98b666f04bd771b834ca36.png)'
- en: Singing Voice Generation Example from Huang, Li, Yang, Shit et a. (2023) [1].
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 歌唱声音生成示例来自 Huang, Li, Yang, Shit 等（2023）[1]。
- en: Now, this one is relevant for musicians! If we give the model a text alongside
    information on notes and note durations, it synthesizes a singing voice and sends
    the audio back to you. Under the hood, state-of-the-art speech synthesis models
    (DiffSinger **[2]**, VISinger **[3])** are applied. It is easy to imagine how
    this kind of technology could be implemented directly in a DAW, for example, to
    create singing samples for hip-hop beats or even background vocals.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这对于音乐家来说非常相关！如果我们给模型提供文本以及音符和音符时长的信息，它会合成一个歌声并将音频发送给你。在后台，应用了最先进的语音合成模型（DiffSinger
    **[2]**，VISinger **[3]**）。很容易想象，这种技术可以直接应用在数字音频工作站（DAW）中，例如，为嘻哈节拍或甚至背景人声创建歌唱样本。
- en: Sound extraction
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 声音提取
- en: '![](../Images/aa8d99f0e2ebf1bfffe5c27bbfb46275.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa8d99f0e2ebf1bfffe5c27bbfb46275.png)'
- en: Sound Extraction Example from Huang, Li, Yang, Shit et a. (2023) [1].
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 声音提取示例来自 Huang, Li, Yang, Shit 等（2023）[1]。
- en: Based on a text prompt, AudioGPT identifies where a specific event occurs in
    an audio signal and cuts off the irrelevant part of the audio for the user. Cutting
    samples or sounds using nothing but verbal prompts could prove incredibly useful
    for musicians. We may not be far away from telling our DAW to “retrieve the most
    emotional part of this sample and cut it down to one bar” without doing any of
    the mechanical work ourselves.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 基于文本提示，AudioGPT识别音频信号中发生特定事件的位置，并为用户剪切掉无关的音频部分。仅使用语言提示来剪切样本或声音可能对音乐家极为有用。我们可能很快就能告诉我们的DAW“提取这个样本中最具情感的部分并将其剪切为一小节”，而无需自己做任何机械工作。
- en: Source separation
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 来源分离
- en: '![](../Images/118bac72ba99073edaac2653d83bc4fd.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/118bac72ba99073edaac2653d83bc4fd.png)'
- en: Source Separation Example from Huang, Li, Yang, Shit et a. (2023) [1].
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 来源分离示例来自Huang, Li, Yang, Shit等（2023）[1]。
- en: Here, AudioGPT is asked to separate two speakers in an audio signal and return
    both extracted speakers, separately. Currently, there is no music source separation
    tool included in this system. However, it is easy to imagine that we could soon
    extract specific instruments or instrument groups from an audio signal right inside
    our DAW through a chatbot interface.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，要求AudioGPT从音频信号中分离出两个说话者，并分别返回这两个提取出的说话者。目前，该系统中没有包括音乐源分离工具。然而，可以很容易地想象，我们可以通过聊天机器人界面在我们的DAW中直接提取特定的乐器或乐器组。
- en: What are AudioGPT’s limitations?
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AudioGPT的局限性是什么？
- en: While these examples showcase how AudioGPT could build the basis for breakthrough
    technologies in the future, it still has lots of limitations.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些例子展示了AudioGPT如何为未来的突破性技术奠定基础，但它仍然有很多局限性。
- en: It was not built for music
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它不是为音乐而构建的
- en: In the context of this post, it is important to note that AudioGPT is not a
    great tool for music analysis or generation, yet. The only real dedicated music
    model is the singing voice synthesis model. Some other models are able to produce
    musical sounds, but they are primarily built for speech and sounds, not for music.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本帖的背景下，需要注意的是，AudioGPT尚不是一个很好的音乐分析或生成工具。目前唯一真正专用的音乐模型是歌唱声音合成模型。其他一些模型能够产生音乐声音，但主要是为语音和声音而非音乐构建的。
- en: However, this is not a limitation of the system per se. Instead, this is primarily
    because the developers did not decide to include more dedicated music AI models
    in this tool. With the current state of AudioGPT as a foundation, it is feasible
    to include more and more audio models in this system or to build a separate, music-specific
    system.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是系统本身的局限性。而主要是因为开发人员没有决定在该工具中包含更多专用音乐AI模型。在当前AudioGPT作为基础的状态下，将更多音频模型纳入该系统或构建一个独立的音乐专用系统是可行的。
- en: It is a work-in-progress
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这是一个正在进行中的工作
- en: From my limited experience using AudioGPT, I can already tell that the task
    assignment process does not work as well as I would like. Oftentimes, my request
    is misunderstood and the wrong model is called, which leads to a completely useless
    output. It seems that there still needs to be some optimization done to make this
    system more and more competent at understanding the user's needs.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我使用AudioGPT的有限经验，我已经可以看出任务分配过程的效果不如我所希望的那样。许多时候，我的请求被误解，调用了错误的模型，导致完全无用的输出。似乎仍需要进行一些优化，以使该系统在理解用户需求方面越来越有能力。
- en: Additionally, the state of audio AI as a whole is still far behind the state
    of text AI, for example. Most of the 17 models included in AudioGPT work somewhat
    well but have obvious limitations. Hence, even if AudioGPT’s task assignment worked
    perfectly, the systems would still be limited by the capabilities of the underlying
    models.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，整体音频AI的现状仍远远落后于文本AI。例如，AudioGPT中包含的17个模型大多数运作尚可，但存在明显的局限性。因此，即使AudioGPT的任务分配完美，系统仍将受制于底层模型的能力。
- en: What does this mean for music?
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这对音乐意味着什么？
- en: AI composition/production assistants
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI作曲/制作助手
- en: 'For now, AudioGPT does not really affect the work and lives of musicians in
    any way. However, in my estimation, this will change in the near future. Here
    are the two steps that would need to be taken to make these kinds of systems truly
    transformative in this field:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，AudioGPT对音乐家的工作和生活并没有真正的影响。然而，我估计这种情况在不久的将来会发生变化。要使这些系统在这个领域真正具有变革性，需要采取以下两个步骤：
- en: Expand AudioGPT with music models (source separation, tagging, denoising, audio
    effects, etc) or build a separate MusicGPT model focused on these specific tasks.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展AudioGPT的音乐模型（源分离、标记、去噪、音频效果等）或构建一个专注于这些特定任务的独立MusicGPT模型。
- en: Develop plugins that allow musicians to access AudioGPT (or MusicGPT) through
    a chat interface within their DAW.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开发插件，使音乐家能够通过聊天界面在他们的DAW中访问AudioGPT（或MusicGPT）。
- en: Clearly, this is no easy task. Especially the second step could be a huge hurdle
    to overcome. However, implementing such a chatbot in a DAW could be an immense
    competitive advantage for companies like Apple (Logic), Ableton, or Image-Line
    (FL Studio). A fleshed-out, domain-specific, and well-integrated version of AudiGPT
    could increase the efficiency, creative freedom, and fun of creating music dramatically.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这不是一项容易的任务。特别是第二步可能是一个巨大的障碍。然而，在DAW中实现这样的聊天机器人可能是像苹果（Logic）、Ableton或Image-Line（FL
    Studio）这样的公司巨大的竞争优势。一个完善、领域特定且良好集成的AudiGPT版本可以显著提高创建音乐的效率、创造自由度和乐趣。
- en: If the system had all the audio and MIDI events in your current project stored
    in its memory, you could always move, edit, combine, delete, or enhance these
    events using simple speech or text commands. Further, some things in the creative
    process are easy to verbalize but hard to execute, manually. Say you want your
    song to sound more “laid back” and “chill”. Do you turn hundreds of knobs in your
    instrument selection, mixer, effect chain, and master settings? Or do you simply
    tell your AI assistant to turn the knobs for you? I am dreaming of a DAW plugin
    that allows us to generate sounds, apply effects, mix/master our tracks, separate
    instruments, analyze and tag our music, and much more, all within an intuitive
    chatbot interface. Such a system could undoubtedly make us all more productive
    and creative in our music-making workflow.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统将当前项目中的所有音频和MIDI事件都存储在内存中，你可以随时使用简单的语音或文本命令来移动、编辑、组合、删除或增强这些事件。此外，创作过程中的一些事情很容易用语言表达，但手动执行却很困难。假设你想让你的歌曲听起来更加“放松”和“悠闲”。你是调整乐器选择、混音器、效果链和母带设置中的数百个旋钮，还是简单地告诉你的AI助手为你调整旋钮？我梦想有一个DAW插件，它允许我们在一个直观的聊天机器人界面内生成声音、应用效果、混音/母带处理我们的曲目、分离乐器、分析和标记音乐，以及更多。这种系统无疑能使我们在音乐创作流程中更加高效和富有创造力。
- en: Enhancement, not replacement
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强，而非替代
- en: Over the last few months, generation models like MusicLM have provoked existential
    fear in many artists. While it is undisputed that AI will dramatically disrupt
    the music industry, I think AudioGPT is a great example of how these technologies
    can augment, not replace our work as musicians. A chatbot interface can be really
    helpful for creating, editing, and rearranging sounds, but it does not act as
    an autonomous agent. The creativity, intention, and emotion of the composer or
    producer are what give the final product its value and meaning.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几个月中，像MusicLM这样的生成模型引发了许多艺术家的生存恐惧。虽然无可争议的是AI将显著颠覆音乐产业，但我认为AudioGPT是一个很好的例子，说明这些技术可以增强而不是取代我们的音乐工作。聊天机器人界面对创建、编辑和重新安排声音非常有帮助，但它不作为一个自主的代理。作曲家或制作人的创造力、意图和情感才是赋予最终产品价值和意义的关键。
- en: In the long run, human-made music will always be of higher value to humans than
    AI-made music. This is simply because music is inherently social and a form of
    communication between people. To most of us, it does not matter if the music is
    “hand-made” in the sense of using only acoustical instruments. Instead, what really
    matters is that, whatever technologies were used in the creative process, it was
    a human who utilized these tools in a controlled manner and as a means of personal
    creative expression. In this light, expanding the functionalities of AudioGPT
    and integrating it into music-making tools allows us to profit from speed- or
    creativity-enhancing technology while maintaining our value and purpose as composers.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，人类创作的音乐总是比AI创作的音乐对人类更有价值。这是因为音乐本质上是社会性的，是人们之间的一种沟通方式。对我们大多数人来说，音乐是否是用仅仅是声学乐器“手工制作”的并不重要。真正重要的是，无论在创作过程中使用了什么技术，都是由人类以受控的方式和作为个人创意表达的手段来利用这些工具。从这个角度看，扩展AudioGPT的功能并将其集成到音乐创作工具中，让我们能够从加速或提升创意的技术中获益，同时保持作为作曲家的价值和目的。
- en: How can I use AudioGPT?
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我该如何使用AudioGPT？
- en: As a programmer
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作为程序员
- en: As a programmer, you can simply clone the [AudioGPT GitHub repository](https://github.com/AIGC-Audio/AudioGPT),
    install all of the models used, enter your OpenAI API key, and get started. This
    will allow to you use ALL of the features presented in the paper.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 作为程序员，你可以简单地克隆 [AudioGPT GitHub 仓库](https://github.com/AIGC-Audio/AudioGPT)，安装所有使用的模型，输入你的
    OpenAI API 密钥，然后开始使用。这将允许你使用论文中展示的所有功能。
- en: As a non-techie
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作为一个非技术人员
- en: If you are not a programmer, you can still use AudioGPT, although to a limited
    extent, in this [HuggingFace web app](https://huggingface.co/spaces/AIGC-Audio/AudioGPT).
    To use the system, you will need an OpenAI API key. [Here](https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/)
    is a tutorial on how to get it. Depending on OpenAI’s current terms of use, you
    may need to enter your credit card information to be able to use the token. This
    key is needed because AudioGPT uses ChatGPT in the background. Using ChatGPT is
    not very expensive (0.002$ cents per ~700 words as of April, 23\. See [documentation](https://openai.com/pricing)).
    Still, if you decide to use this key for AudioGPT, I recommend monitoring the
    costs invoked by the system in your OpenAI account.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不是程序员，你仍然可以在这个 [HuggingFace 网络应用](https://huggingface.co/spaces/AIGC-Audio/AudioGPT)中有限度地使用
    AudioGPT。要使用该系统，你需要一个 OpenAI API 密钥。[这里](https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/)
    是如何获取密钥的教程。根据 OpenAI 目前的使用条款，你可能需要输入你的信用卡信息才能使用该令牌。这个密钥是必需的，因为 AudioGPT 在后台使用
    ChatGPT。使用 ChatGPT 并不昂贵（截至 4 月 23 日，每 ~700 字约 0.002 美分。见 [文档](https://openai.com/pricing)）。不过，如果你决定将此密钥用于
    AudioGPT，建议在你的 OpenAI 账户中监控系统产生的费用。
- en: Unfortunately, this HuggingFace web app has not been working all that well,
    for me. When I upload files, there is usually an error. The audio outputs are
    sometimes completely wrong, although my request seems to have been understood…
    If you already have an OpenAI API key, you should definitely try it out. If not,
    I am not sure if this web app is worth going through the effort of creating the
    account and key.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这个 HuggingFace 网络应用对我来说一直运行不太好。当我上传文件时，通常会出现错误。音频输出有时完全错误，尽管我的请求似乎被理解了……如果你已经有了
    OpenAI API 密钥，绝对应该尝试一下。如果没有，我不确定这个网络应用是否值得你去创建账户和密钥的努力。
- en: References
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '**[1] Huang, Li, Yang, Shi et al. (2023)**. AudioGPT: Understanding and Generating
    Speech, Music, Sound, and Talking Head. [arXiv:2304.12995v1](https://arxiv.org/abs/2304.12995)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**[1] 黄、李、杨、石等（2023）**。《AudioGPT：理解与生成语音、音乐、声音和谈话头像》。[arXiv:2304.12995v1](https://arxiv.org/abs/2304.12995)'
- en: '**[2] Liu et al. (2021)**. DiffSinger: Singing Voice Synthesis via Shallow
    Diffusion Mechanism. [arXiv:2105.02446](https://arxiv.org/abs/2105.02446)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**[2] 刘等（2021）**。《DiffSinger：通过浅层扩散机制进行歌声合成》。[arXiv:2105.02446](https://arxiv.org/abs/2105.02446)'
- en: '**[3] Zhang et al. (2021)**. VISinger: Variational Inference with Adversarial
    Learning for End-to-End Singing Voice Synthesis. [arXiv:2110.08813](https://arxiv.org/abs/2110.08813)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**[3] 张等（2021）**。《VISinger：使用对抗学习进行端到端歌声合成的变分推断》。[arXiv:2110.08813](https://arxiv.org/abs/2110.08813)'
- en: 'If you liked this post, check out my article on MusicLM, Google’s breakthrough
    music generation model: [**MusicLM: Has Google Solved AI Music Generation?**](https://medium.com/towards-data-science/musiclm-has-google-solved-ai-music-generation-c6859e76bc3c)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，可以看看我关于 MusicLM 的文章，即 Google 的突破性音乐生成模型：[**MusicLM：Google 解决了 AI 音乐生成问题吗？**](https://medium.com/towards-data-science/musiclm-has-google-solved-ai-music-generation-c6859e76bc3c)
