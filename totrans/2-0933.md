# 从因果树到森林

> 原文：[https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481](https://towardsdatascience.com/from-causal-trees-to-forests-43c4536f1481)

## [因果数据科学](https://towardsdatascience.com/tagged/causal-data-science)

## *如何使用随机森林进行政策定位*

[](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[![Matteo Courthoud](../Images/d873eab35a0cf9fc696658c0bee16b33.png)](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------) [Matteo Courthoud](https://medium.com/@matteo.courthoud?source=post_page-----43c4536f1481--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43c4536f1481--------------------------------) ·13分钟阅读·2023年2月20日

--

![](../Images/2977138a8f4b861a47fb69dc54222ec5.png)

封面，图片由作者提供

在我[之前的博客文章](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)中，我们已经探讨了如何使用**因果树**来估计政策的异质性处理效应。如果你还没有阅读，我建议先阅读那篇文章，因为我们将以那篇文章的内容为基础，从那里开始。

为什么要关注异质性处理效应（HTE）？首先，异质性处理效应的估计使我们能够选择哪些用户（患者、用户、客户等）接受治疗（药物、广告、产品等），这取决于他们预期的结果（疾病、公司收入、客户满意度等）。换句话说，估计HTE使我们能够进行**定位**。实际上，正如我们在文章后面将看到的，一个治疗在平均情况下可能无效或甚至适得其反，但对某一子集的用户却带来积极的效果。相反的情况也可能成立：一种药物在平均情况下有效，但如果我们识别出有副作用的用户，其效果可能会得到改善。

在这篇文章中，我们将深入探讨因果树的扩展：因果森林。正如随机森林通过平均多个自助抽样的树来扩展回归树一样，因果森林扩展了因果树。主要的不同之处在于推断的角度，这并不那么直接。我们还将了解如何比较不同的HTE估计算法的输出，并如何将它们用于**政策定位**。

# 在线折扣

在文章的其余部分，我们继续使用[因果树文章](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)中的玩具示例：我们假设我们是一个**在线商店**，并且我们希望了解是否向新客户提供折扣会增加他们在商店中的支出。

![](../Images/ed7548888ecdeef65e055e84fdc01a30.png)

图片，由作者使用[NightCafé](https://creator.nightcafe.studio/)生成

为了了解折扣是否具有成本效益，我们进行了一项随机实验或**A/B测试**：每当新客户浏览我们的在线商店时，我们会随机分配其到一个处理条件。对于处理用户，我们提供折扣；对于对照用户，则不提供。我从`[src.dgp](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py)`导入数据生成过程`dgp_online_discounts()`。我还从`[src.utils](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)`导入了一些绘图函数和库。为了包含代码、数据和表格，我使用了[Deepnote](https://deepnote.com/)，这是一个类似Jupyter的基于网页的协作笔记本环境。

我们有关于100,000名在线商店访客的数据，我们观察他们访问网站的`时间`、使用的`设备`、他们的`浏览器`和他们的地理`区域`。我们还看到他们是否获得了`折扣`（我们的处理）以及他们的`支出`（我们关注的结果）。

由于处理是随机分配的，我们可以使用简单的**均值差异**估计量来估计处理效果。我们预计处理组和对照组在除`折扣`之外是相似的，因此我们可以将`支出`中的任何差异归因于`折扣`。

折扣似乎是有效的：在处理组中，平均支出增加了1.95美元。但是所有客户的影响是否相同？

为了回答这个问题，我们希望估计**异质性处理效果**，可能是在个体层面上。

## 因果森林

计算异质性处理效果有很多不同的选项。最简单的一种方法是将关注的结果与异质性维度交互。这个方法的问题在于选择哪个变量。有时我们有先验信息可以指导我们的行动；例如，我们可能知道`移动`用户的平均支出高于`桌面`用户。其他时候，我们可能出于商业原因对某个维度感兴趣；例如，我们可能希望在某个`区域`投资更多。然而，当我们没有额外信息时，我们希望这个过程是数据驱动的。

在[上一篇文章](https://medium.com/towards-data-science/understanding-causal-trees-920177462149)中，我们探讨了一种数据驱动的方法来估计异质治疗效果：**因果树**。我们将扩展到因果森林。然而，在开始之前，我们必须介绍一下它的非因果兄弟：随机森林。

![](../Images/a7c8260b130c889ad9e94c2e15171116.png)

图片，由作者使用[NightCafé](https://creator.nightcafe.studio/)生成

[**随机森林**](https://en.wikipedia.org/wiki/Random_forest)，顾名思义，是回归树的扩展，在其基础上增加了两个独立的随机性来源。具体而言，随机森林算法利用许多不同回归树的预测结果，每棵回归树都是在数据的自助样本上训练的，并将这些预测结果进行平均。这一过程通常被称为[**袋装法**](https://en.wikipedia.org/wiki/Bootstrap_aggregating)，自助聚合，并可以应用于任何预测算法，并非随机森林所特有。额外的随机性来源来自于特征选择，因为在每次分裂时，只考虑所有特征*X*的随机子集进行最优分裂。

这两个额外的随机性来源极为重要，有助于随机森林的优越性能。首先，袋装法使随机森林通过对多个离散预测进行平均，**产生更平滑**的预测。随机特征选择则允许随机森林**更深入地探索特征空间**，使其能发现比简单回归树更多的交互作用。事实上，变量之间可能存在单独来看预测能力不强（因此不会产生分裂），但一起来看却非常强大的交互作用。

因果森林是随机森林的等效方法，但用于估计异质治疗效果，正如因果树和回归树一样。与因果树一样，我们面临一个基本问题：我们感兴趣的是预测一个我们无法观察到的对象：个体治疗效果*τᵢ*。解决方案是创建一个辅助结果变量*Y**，其对每个观测值的期望值恰好就是治疗效果。

![](../Images/8c6ee904e46dcad7945f99fe47a9c19b.png)

辅助结果变量，由作者提供的图片

如果你想了解更多关于为什么这个变量对个体治疗效果是无偏的细节，可以查看我的[上一篇文章](/920177462149)，在其中我会详细讲解。简而言之，你可以将*Yᵢ**解释为单个观测值的均值差异估计量。

一旦我们有了结果变量，还有几件事需要做，以便使用随机森林来估计异质性处理效果。首先，我们需要构建在每个叶子中有相同数量的处理和对照单位的树。其次，我们需要使用不同的样本来构建和评估树，即计算每个叶子的平均结果。这个过程通常被称为**诚实树**，它对于推断非常有帮助，因为我们可以将每个叶子的样本视为与树结构独立。

在进入估计之前，我们首先为分类变量`device`、`browser`和`region`生成虚拟变量。

我们现在可以使用随机森林算法来估计异质性处理效果。幸运的是，我们不需要手动完成所有这些操作，微软的[EconML](https://econml.azurewebsites.net/)包中有一个很好的因果树和森林实现。我们将使用`CausalForestDML`函数。

与因果树不同，因果森林更难解释，因为我们不能可视化每一棵树。我们可以使用`SingleTreeCateInterpreter`函数来绘制因果森林算法的等效表示。

![](../Images/b8388c2ff1a8cbb3c211d77f83de704b.png)

因果森林模型表示，作者提供的图像

我们可以像解释因果树模型一样解释树状图。在顶部，我们可以看到数据中的平均$Y^*$，1.917$。从那里开始，数据根据每个节点顶部突出显示的规则被分成不同的分支。例如，第一个节点根据`time`是否晚于11.295$将数据分成两个组，分别为46,878$和53,122$。在底部，我们有最终的分区及预测值。例如，最左侧的叶子包含40,191$的观察，其中`time`早于11.295$且`browser`非Safari，我们预测支出为0.264$。节点颜色越深表示预测值越高。

这个表示的问题在于，与因果树的情况不同，它只是模型的一个解释。由于因果森林由许多自助抽样树组成，因此无法直接检查每棵决策树。理解哪个特征在决定树的分裂时最重要的一种方法是所谓的[特征重要性](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)。

![](../Images/4231943452c929d60065ca79cf577212.png)

显然，`time`是异质性的第一个维度，其次是`device`（特别是移动设备）和`browser`（特别是Safari）。其他维度不太重要。

现在让我们检查模型性能。

## 性能

通常，我们无法直接评估模型性能，因为与标准机器学习设置不同，我们无法观察到真实情况。因此，我们不能使用测试集来计算模型的准确性度量。然而，在我们的案例中，我们控制数据生成过程，因此可以访问真实情况。让我们从分析模型如何沿数据的**分类** **维度**（如`device`、`browser`和`region`）估计异质处理效果开始。

对于每个分类变量，我们绘制了实际和估计的平均处理效果。

![](../Images/cb17be601a029225777fc1fd7fd3ddd0.png)

每个分类值的真实和估计的处理效果，图片由作者提供

因果森林算法在预测与分类变量相关的处理效果方面非常有效。至于因果树，由于算法具有非常离散的特性，这种情况是预期中的。然而，与因果树不同的是，预测结果更为细致。

我们现在可以进行更相关的测试：算法在处理连续变量如`time`时表现如何？首先，让我们再次隔离`time`上的预测处理效果，忽略其他协变量。

现在我们可以复制之前的图，但应用于`time`维度。我们绘制了每天每个时段的真实和估计的处理效果的平均值。

![](../Images/8306233b0ad9f2190ffaae1ac541bc7d.png)

随时间维度的真实和估计的处理效果，图片由作者提供

我们现在可以完全理解因果树和森林之间的差异：在因果树的情况下，估计结果基本上是非常粗略的阶跃函数，而我们现在可以看到因果森林如何产生**更平滑的估计**。

我们现在已经探索了模型，是时候使用它了！

# 政策目标定位

假设我们考虑向访问我们在线商店的新客户提供4$的折扣。

折扣对哪些客户有效？我们估计了1.9492$的平均处理效果，这意味着折扣在平均情况下并不真的有利可图。然而，我们现在能够针对单个个体，只对来访客户的子集提供折扣。我们将探讨如何进行**政策目标定位**，并为了更好地理解定位的质量，我们将使用因果树模型作为参考点。

我们使用相同的`CausalForestDML`函数构建一个因果树，但将估算器数量和森林大小限制为1。

接下来，我们将数据集拆分为训练集和测试集。这个想法与[**交叉验证**](https://en.wikipedia.org/wiki/Cross-validation_(statistics))非常相似：我们使用训练集来训练模型——在我们的例子中是用于异质处理效应的估计器——并使用测试集来评估其质量。主要区别在于我们无法在测试数据集中观察到真实结果。但我们仍然可以使用训练-测试拆分来比较样本内预测与样本外预测。

我们将80%的所有观察值放入训练集中，将20%放入测试集中。

首先，让我们只在训练样本上重新训练模型。

现在我们可以决定一个目标政策，即决定向哪些客户提供折扣。答案似乎很简单：我们向所有我们预计治疗效应大于成本4美元的客户提供折扣。

一个允许我们理解处理效果及其方式的可视化工具是所谓的**处理操作特征（TOC）**曲线。这个名字让人联想到更著名的[接收者操作特征（ROC）](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)曲线，该曲线绘制了不同阈值下的真正例率与假正例率。其想法类似：我们绘制不同处理人口份额下的平均处理效应。在一个极端情况下，当所有客户都被处理时，曲线取值等于平均处理效应，而在另一个极端情况下，当仅一个客户被处理时，曲线取值等于最大处理效应。

现在让我们计算曲线。

现在我们可以绘制两个CATE估计器的处理操作特征曲线。

![](../Images/75492db64e02a7aaf8e5321873415718.png)

处理操作特征曲线，图像由作者提供

正如预期的那样，由于我们增加了处理客户的比例，TOC曲线对于两个估计器都是递减的。换句话说，我们在释放折扣时越有选择性，每个客户的优惠效果越高。我还绘制了一条与折扣成本水平相同的水平线，以便我们可以将TOC曲线下方且成本线以上的阴影区域解释为**预期利润**。

这两个算法预测的处理份额相似，约为20%，其中因果森林算法针对的客户稍多。然而，它们预测的利润却大相径庭。因果树算法预测了一个小且恒定的利润差距，而因果森林算法预测了一个更大且更陡的利润差距。哪个算法更准确？

为了比较这两者，我们可以在测试集上进行评估。我们使用在训练集上训练的模型来预测处理效应，并与在测试集上训练的模型的预测结果进行比较。请注意，与机器学习标准测试程序不同的是，在我们的案例中，我们无法将预测结果与真实值进行评估，因为处理效应没有被观测到。我们只能相互比较两个预测结果。

![](../Images/45afc1cc609a1662db0f68ac767314eb.png)

看起来因果树模型比因果森林模型表现更好，总净效应为8,386$$，而因果森林为4,948$$。从图中我们还可以理解差异的来源。因果森林算法趋向于更为严格，并且处理的客户较少，虽然没有假阳性，但也有很多假阴性。另一方面，因果树算法则更为宽松，将`折扣`分发给更多的新客户。这导致了更多的真正阳性，但也有假阳性。净效应似乎偏向于因果树算法。

通常情况下，我们会在这里停止，因为我们不能做更多的事情。然而，在我们的案例中，我们可以访问**真实数据生成过程**。因此，我们可以检查这两种算法的真实准确性。

首先，让我们从处理效应的预测误差方面进行比较。对于每种算法，我们计算处理效应的[均方误差](https://en.wikipedia.org/wiki/Mean_squared_error)。

随机森林模型更好地预测了平均处理效应，其均方误差为0.5555$，而不是0.9035$。

这是否意味着**更好的目标定位**？我们现在可以重复之前的条形图，以了解这两种算法在政策定位方面的表现。

![](../Images/5f0a129b28a67b7fd07b9cc3f8e6f972.png)

图形非常相似，但结果差异很大。实际上，因果森林算法现在的总效应为10,395$，而因果树算法为8,828$。为何会有这种突如其来的差异？

为了更好地理解差异的来源，让我们根据真实情况绘制TOC图。

![](../Images/db212fd08f5e3be45d93e17a4b364a10.png)

处理操作特征曲线，图片由作者提供

正如我们所见，TOC非常偏斜，并且存在一些具有非常高平均处理效应的客户。随机森林算法更能识别这些客户，因此总体上更有效，尽管其目标客户较少。

# 结论

在这篇文章中，我们看到了一种用于估计异质性处理效应的非常强大的算法：**因果森林**。因果森林建立在因果树的相同原理基础上，但受益于对参数空间的更深入探索和袋装方法。

我们还看到了如何利用异质治疗效应的估计来进行政策**定位**。通过识别具有最高治疗效应的用户，我们能够使本来无法获利的政策变得有利可图。我们还看到，政策定位的目标可能与异质治疗效应估计的目标不同，因为分布的尾部可能比平均值更相关。

## 参考文献

+   S. Athey, G. Imbens, [异质因果效应的递归分割](https://www.pnas.org/doi/abs/10.1073/pnas.1510489113) (2016), *美国国家科学院院刊*。

+   S. Wager, S. Athey, [使用随机森林估计和推断异质治疗效应](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839) (2018), *美国统计协会期刊*。

+   S. Athey, J. Tibshirani, S. Wager, [广义随机森林](https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-2/Generalized-random-forests/10.1214/18-AOS1709.full) (2019). *统计年鉴*。

+   M. Oprescu, V. Syrgkanis, Z. Wu, [因果推断的正交随机森林](http://proceedings.mlr.press/v97/oprescu19a.html?ref=https%3A%2F%2Fgithubhelp.com) (2019). *第36届国际机器学习会议论文集*。

## 相关文章

+   [DAGs 和控制变量](/b63dc69e3d8c)

+   [匹配、加权还是回归？](/99bf5cffa0d9)

+   [理解元学习器](/8a9c1e340832)

+   [理解 AIPW，双重稳健估计量](/ed4097dab27a)

+   [理解因果树](/920177462149)

## 代码

你可以在这里找到原始 Jupyter Notebook：

[https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/causal_forests.ipynb)

## 感谢阅读！

*我非常感激！* 🤗 *如果你喜欢这篇文章并希望看到更多，请考虑* [***关注我***](https://medium.com/@matteo.courthoud)*。我每周发布一次关于因果推断和数据分析的内容。我尽量使我的帖子既简单又准确，始终提供代码、示例和模拟。*

*另外，* ***免责声明****: 我写作是为了学习，因此错误是常有的事，尽管我尽力而为。如果你发现错误，请告诉我。我也欢迎对新话题的建议！*
