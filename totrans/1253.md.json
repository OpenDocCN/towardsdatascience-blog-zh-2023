["```py\n# Text manipulation libraries\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n# nltk.download('stopwords') <-- we run this command to download the stopwords in the project\n# nltk.download('punkt') <-- essential for tokenization\n\nstopwords.words(\"italian\")[:10]\n>>> ['ad', 'al', 'allo', 'ai', 'agli', 'all', 'agl', 'alla', 'alle', 'con']\n```", "```py\ndef preprocess_text(text: str, remove_stopwords: bool) -> str:\n    \"\"\"Function that cleans the input text by going to:\n    - remove links\n    - remove special characters\n    - remove numbers\n    - remove stopwords\n    - convert to lowercase\n    - remove excessive white spaces\n    Arguments:\n        text (str): text to clean\n        remove_stopwords (bool): whether to remove stopwords\n    Returns:\n        str: cleaned text\n    \"\"\"\n    # remove links\n    text = re.sub(r\"http\\S+\", \"\", text)\n    # remove numbers and special characters\n    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n    # remove stopwords\n    if remove_stopwords:\n        # 1\\. create tokens\n        tokens = nltk.word_tokenize(text)\n        # 2\\. check if it's a stopword\n        tokens = [w.lower().strip() for w in tokens if not w.lower() in stopwords.words(\"italian\")]\n        # return a list of cleaned tokens\n        return tokens\n```", "```py\ndf[\"cleaned\"] = df.article.apply(\n    lambda x: preprocess_text(x, remove_stopwords=True)\n  )\n```", "```py\ntexts = df.cleaned.tolist()\n```", "```py\nfrom gensim.models import Word2Vec\n\nmodel = Word2Vec(sentences=texts)\n```", "```py\ndef reduce_dimensions(model):\n    num_components = 2  # number of dimensions to keep after compression\n\n    # extract vocabulary from model and vectors in order to associate them in the graph\n    vectors = np.asarray(model.wv.vectors)\n    labels = np.asarray(model.wv.index_to_key)  \n\n    # apply TSNE \n    tsne = TSNE(n_components=num_components, random_state=0)\n    vectors = tsne.fit_transform(vectors)\n\n    x_vals = [v[0] for v in vectors]\n    y_vals = [v[1] for v in vectors]\n    return x_vals, y_vals, labels\n\ndef plot_embeddings(x_vals, y_vals, labels):\n    import plotly.graph_objs as go\n    fig = go.Figure()\n    trace = go.Scatter(x=x_vals, y=y_vals, mode='markers', text=labels)\n    fig.add_trace(trace)\n    fig.update_layout(title=\"Word2Vec - Visualizzazione embedding con TSNE\")\n    fig.show()\n    return fig\n\nx_vals, y_vals, labels = reduce_dimensions(model)\n\nplot = plot_embeddings(x_vals, y_vals, labels)\n```", "```py\nVECTOR_SIZE = 100\nMIN_COUNT = 5\nWINDOW = 3\nSG = 1\n\nnew_model = Word2Vec(\n    sentences=texts, \n    vector_size=VECTOR_SIZE, \n    min_count=MIN_COUNT, \n    sg=SG\n)\n\nx_vals, y_vals, labels = reduce_dimensions(new_model)\n\nplot = plot_embeddings(x_vals, y_vals, labels)\n```", "```py\nimport datapane as dp\n\napp = dp.App(\n    dp.Text(text='# Visualizzazione degli embedding creati con Word2Vec'),\n    dp.Divider(),\n    dp.Text(text='## Grafico a dispersione'),\n    dp.Group(\n        dp.Plot(plot),\n        columns=1,\n    ),\n)\napp.save(path=\"test.html\")\n```"]