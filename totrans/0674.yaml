- en: Dealing with Conversion Metrics? Consider Beta-Binomial Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/dealing-with-conversion-metrics-consider-beta-binomial-model-29733906ff38](https://towardsdatascience.com/dealing-with-conversion-metrics-consider-beta-binomial-model-29733906ff38)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/52c7b004ff37e2cbacac7625eaf7ab8d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Karim MANJRA](https://unsplash.com/@karim_manjra?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Learn a feature engineering technique to make conversion-based metrics such
    as CTR/CVR more representative and stable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@pararawendy19?source=post_page-----29733906ff38--------------------------------)[![Pararawendy
    Indarjo](../Images/afba0cb7f3af9554a187bbc7a3c00e60.png)](https://medium.com/@pararawendy19?source=post_page-----29733906ff38--------------------------------)[](https://towardsdatascience.com/?source=post_page-----29733906ff38--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----29733906ff38--------------------------------)
    [Pararawendy Indarjo](https://medium.com/@pararawendy19?source=post_page-----29733906ff38--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----29733906ff38--------------------------------)
    ¬∑10 min read¬∑Jul 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Conversion metrics are abundant in the industry. And oftentimes, we want to
    use them as a feature in our ML model. Say, the impression-to-click product detail
    click-through rate (CTR) of a product shown on the search page may be relevant
    after all to be used as one feature to model whether or not the product will be
    purchased in an e-commerce platform.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we will learn a feature engineering technique for such conversion
    metrics. To pursue this objective, the rest of the blog will be structured as
    follows.
  prefs: []
  type: TYPE_NORMAL
- en: An explanation on why we need to handle conversion features with caution (i.e.,
    we shouldn‚Äôt use these features in their raw forms).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The solution: Beta-Binomial Model to transform the raw conversion values into
    more stable/representative version'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The theoretical foundation of Beta-Binomial Model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A guide to tune the parameters of the Beta-prior distribution of the model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Python code to do the Beta-Binomial transformation (hint: it‚Äôs very simple!)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let‚Äôs dive in!
  prefs: []
  type: TYPE_NORMAL
- en: The drawbacks of using raw conversion values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose we are building a classification model to predict whether or not a
    product will be purchased on an e-commerce platform. As part of the data preprocessing,
    we extract two columns related to each product: the number of impressions and
    the number of clicks it receives. Because we‚Äôre awesome data scientist with strong
    domain knowledge, we derive a new feature called ‚Äúimpression-to-click conversion.‚Äù'
  prefs: []
  type: TYPE_NORMAL
- en: The rationale behind this feature engineering is that we believe a higher impression-to-click
    conversion indicates a better product quality. The logic is that if a product
    receives a higher percentage of clicks relative to the number of times it was
    displayed (impressions), it suggests that users find the product appealing, leading
    to a higher likelihood of it being purchased.
  prefs: []
  type: TYPE_NORMAL
- en: Now consider the following three product scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8ffe947c758c7a3392886be504e8ce3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Original conversion values (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: In the table, both Product A and Product B have an equal impression-to-click
    conversion of 70%. Does it mean that Product A and B have the same quality? Note
    that Product A achieved the 70% conversion rate after being impressed a significant
    number of times (1000 impressions), indicating a higher level of testing and stability.
    On the other hand, Product B claims the same conversion rate from a much smaller
    number of impressions (only 10 impressions), making it less reliable and more
    susceptible to fluctuations.
  prefs: []
  type: TYPE_NORMAL
- en: Given this difference in testing and stability, I think it‚Äôs more appropriate
    to assign a higher conversion score to Product A compared to Product B.
  prefs: []
  type: TYPE_NORMAL
- en: The issue in using raw conversion value gets more obvious when we consider Product
    C. It has 100% impression-to-click conversion after being impressed only 1 time.
    By using raw conversion value, it is implied that Product C is significantly better
    than the other products ‚Äî which is not necessarily true. Because it‚Äôs possible
    that Product C simply had ‚Äúbeginner‚Äôs luck‚Äù after all. The true/stable conversion
    rate of Product C is most likely less than 100% as it gathers more impressions
    from users.
  prefs: []
  type: TYPE_NORMAL
- en: Beta-Binomial Model to the rescue!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Is there a better way rather than using the raw conversion value?
  prefs: []
  type: TYPE_NORMAL
- en: There is, indeed! We can use the Beta-Binomial model to obtain more stable conversion
    values, which may better represent the feature. We can calculate a product‚Äôs click-propensity
    (a term we use to refer to the better /more stable version of impression-to-click
    conversion) using the Beta-Binomial model via the following transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db663f5da3e3dcf8966dc8216b469fca.png)'
  prefs: []
  type: TYPE_IMG
- en: Beta-binomial conversion formula (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Where Œ±, Œ≤ are some specified values.
  prefs: []
  type: TYPE_NORMAL
- en: For example, by using Œ± = Œ≤ = 10, we arrive at the following results for the
    same Product A, B, and C we considered before.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/220d4d6d080968076f26d64e2e2e5d10.png)'
  prefs: []
  type: TYPE_IMG
- en: Beta-Binomial Conversion (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Definitely better than using the raw conversion values, right? Product A now
    has the highest score of the three, which seems more fair given that it has been
    tested the most by users (many impressions). Furthermore, Product C now has the
    lowest score because we are unsure about the seemingly perfect conversion it has
    (i.e., more tests are required to prove its worth).
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical Foundation of Beta-Binomial Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Despite its simplicity, the transformation described above has a solid theoretical
    foundation, which will be discussed in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Practical readers can simply skip this more technical section and proceed to
    the section on ‚ÄúHow to choose Œ± and Œ≤‚Äù.
  prefs: []
  type: TYPE_NORMAL
- en: Binomial Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first relevant concept is Binomial distribution. Recall that it‚Äôs a probability
    distribution that models the number of successes (y) from a set of independent
    binary trials (n), each with success probability of pi (œÄ).
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we can use Binomial distribution to model the number of clicks
    a product receives (y) from the number of impressions the product being shown
    to users (n), assuming the product has click-propensity of pi (œÄ).
  prefs: []
  type: TYPE_NORMAL
- en: The probability mass function of Binomial distribution is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/40663a72b44520389666709dcd279882.png)'
  prefs: []
  type: TYPE_IMG
- en: Binomial PMF (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Using the above formula, we can compute (given n & œÄ) the probability of number
    of success equals to y. As a result, we can determine which value y has a higher
    probability of occurring than the others.
  prefs: []
  type: TYPE_NORMAL
- en: However, in our case, we are *not* interested in learning the optimal value
    of y (i.e., the number of obtained clicks with the highest probability). This
    is due to the fact that we have clicks and impressions data as inputs (that is,
    we can query how many impressions (n) and clicks (y) Product A has received from
    our tracking database).
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we want to infer the product‚Äôs click-propensity. That is, given n and
    y, what should the value œÄ be?
  prefs: []
  type: TYPE_NORMAL
- en: Answering this question requires flipping the probability mass function on its
    head to become as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/51f9c859f355e5bf6dd0d9f5f1063283.png)'
  prefs: []
  type: TYPE_IMG
- en: Likelihood function of Binomial distribution (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The function described above is known as the **likelihood function**. It is
    worth noting that in the function, œÄ is now treated as the variable of interest.
    While n and y are considered constants (their values are given upfront).
  prefs: []
  type: TYPE_NORMAL
- en: Beta Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Beta distribution is a probability distribution that models a random variable
    that can take values between 0 and 1\. Therefore, we can use it to model the click-propensity
    œÄ we‚Äôre interested before.
  prefs: []
  type: TYPE_NORMAL
- en: The probability density function of Beta distribution is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b6aec702742428ca3a5bcb04d63a969.png)'
  prefs: []
  type: TYPE_IMG
- en: Beta distribution PDF (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Where **Œì** is the Gamma function, Œ± and Œ≤ are distribution parameters. For
    more details, you can refer to Beta distribution‚Äôs [Wiki page](https://en.wikipedia.org/wiki/Beta_distribution).
  prefs: []
  type: TYPE_NORMAL
- en: The expected value (mean) of a random variable following Beta(Œ±, Œ≤) is.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/baa9cedc9630dfd449fd840f5ff667d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Beta distribution mean (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: This magnitude is crucial for our modeling effort since we will use it to define
    the best value of œÄ that we‚Äôre looking for.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Statistics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bayesian statistics is a statistical thinking regime in which we examine not
    only the observed data, but also our prior knowledge, to arrive at a conclusion
    from the data. We do this by weighing the observed data (evidence) with our initial
    assumption before seeing the data.
  prefs: []
  type: TYPE_NORMAL
- en: In Bayesian statistics, we begin with an initial belief, represented by a prior
    probability distribution, and combine it with the likelihood of the observed data
    to obtain a posterior probability distribution. This posterior distribution reflects
    our updated understanding of the phenomenon under study, incorporating both the
    available data and our initial assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e03ffe5ca77012de9493b3dd47721f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Posterior formula (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: In our context, we are interested in finding the best value to represent the
    click-propensity œÄ for a given product. To this end, we can use Beta distribution
    as our prior distribution of click-propensity œÄ without seeing any data. This
    prior is then combined with the likelihood of Binomial distribution given the
    observed data (number of impressions *n* and number of clicks *y*).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c12c5e540c354390a084825586e239f1.png)'
  prefs: []
  type: TYPE_IMG
- en: Beta-Binomial posterior derivation (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: By doing some algebra (we skip it here, interested readers can see the full
    derivation [here](https://www.bayesrulesbook.com/chapter-3.html)), it turns out
    that the posterior distribution of œÄ will be equal to Beta(Œ±+y, Œ≤+n-y). Remember
    that n and y are number of impressions and clicks, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the mean of this posterior distribution of œÄ is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a7649b66e499aa9a49ad52bf9de21112.png)'
  prefs: []
  type: TYPE_IMG
- en: Conversion formula derivation (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly the transformation formula we used in our example before.
  prefs: []
  type: TYPE_NORMAL
- en: How to choose alpha and beta?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let‚Äôs summarize what we have done. We used Beta(Œ±=10, Œ≤=10) as our prior distribution
    of click-propensity œÄ. This results in posterior distribution of Beta(Œ±+clicks,
    Œ≤+impressions-clicks). This posterior has mean value of (clicks+Œ±/impressions+Œ±+Œ≤),
    which we used to transform the original conversion values.
  prefs: []
  type: TYPE_NORMAL
- en: Where do these values of Œ± and Œ≤ come from?
  prefs: []
  type: TYPE_NORMAL
- en: To be clear, the posterior distribution (hence the Beta posterior mean formula)
    is simply an implication of the prior distribution chosen. As a result, selecting
    Œ± and Œ≤ and is really a problem of selecting the prior distribution. Specifically,
    what do we want as the distribution of click-propensity œÄ without observing any
    data (i.e. product with no impression yet)?
  prefs: []
  type: TYPE_NORMAL
- en: The key idea here is to comprehend the effect of Œ± and Œ≤ on the shape of the
    Beta distribution PDF (probability density function). To gain some intuition on
    the subject, several Beta PDFs with different Œ± and Œ≤ values are shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3249228419cc74db1a77bd818e6b83ae.png)'
  prefs: []
  type: TYPE_IMG
- en: Effect of Œ± and Œ≤ on Beta distribution shape (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: We can see from the graph that using Beta(Œ±=10, Œ≤=10) as our prior (orange curve)
    means that in the absence of data, we tend to believe that the click-propensity
    œÄ is centered around 0.5, with symmetric variations ranging between 0.2 and 0.8.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we believe the default click-propensity is likely to be around 0.7, we can
    use Beta(Œ±=7, Œ≤=3) as our prior (brown curve). Another example: what if we have
    no preference for the default click-propensity (i.e., any proportion value is
    equally likely)? We can use Beta(Œ±=1, Œ≤=1) as our prior (blue line) in this case
    since it resembles the uniform distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, astute readers might say, ‚ÄúI know both Beta(Œ±=10, Œ≤=10) and Beta(Œ±=2, Œ≤=2)
    result in a symmetrical distribution centered at 0.5\. Then, why did we choose
    the former over the latter‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: Answering this question requires an understanding of Œ± and Œ≤ effect on Beta
    distribution variance. The picture below demonstrates the matter neatly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dc8831ea3a5f02ba00bce9c75ccb615b.png)'
  prefs: []
  type: TYPE_IMG
- en: Effect of alpha and beta to variability (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: We can see from the graph that higher Œ± and Œ≤ values result in less variability
    on the distribution. Beta(Œ±=10, Œ≤=10) has a steeper PDF than Beta(Œ±=2, Œ≤=2). And
    Beta(Œ±=50, Œ≤=50) has less variability than Beta(Œ±=10, Œ≤=10), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Practically speaking, if we use greater Œ± and Œ≤ values, this means we put greater
    weight on the prior to influence the posterior (recall: posterior is derived from
    a balancing act between prior and observed data).'
  prefs: []
  type: TYPE_NORMAL
- en: To understand it better, let‚Äôs see how our Product A, B, and C respond to different
    Œ± and Œ≤ values (given the Beta prior mean/default conversion is the same at 0.5).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e4de21f39eac9744de45098adf83ccd2.png)'
  prefs: []
  type: TYPE_IMG
- en: Different effects of alpha and beta magnitudes (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs focus on Product B. When Œ±=2, Œ≤=2, beta posterior mean is 64% (shifted
    almost 15% from the prior mean). When we increase Œ±=10, Œ≤=10, the shift is shrunk
    to less than 7%. And when we use both Œ± and Œ≤ greater than 100, the Beta posterior
    mean is virtually not moving from the default conversion of 50%.
  prefs: []
  type: TYPE_NORMAL
- en: To put it loosely, using greater Œ± and Œ≤ means we set higher ‚Äústubborn-level‚Äù
    on the model. That is, we demand greater amount of data (evidence) before we can
    move the posterior meaningfully from our default belief.
  prefs: []
  type: TYPE_NORMAL
- en: Python Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, you can find the code to derive the beta-binomial conversion below.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Phew. That was a lengthy read. So, congratulations on making it this far! üéâ
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we learned a simple feature engineering technique that can be
    used to improve the representativeness and stability of conversion metrics. Despite
    its simplicity, the technique has an elegant foundation based on the Beta-Binomial
    Model of Bayesian statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Later in the article, we learned how to tune Œ± and Œ≤ to select the appropriate
    prior distribution. In a nutshell, higher Œ± and Œ≤ practically imply that we require
    more data to shift the resulting conversion score away from our initial/default
    conversion.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this article helps when you encounter a similar situation! All in all,
    thanks for reading, and let‚Äôs connect with me on [LinkedIn](https://www.linkedin.com/in/pararawendy-indarjo/)!
    üëã
  prefs: []
  type: TYPE_NORMAL
- en: '**Reference**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Johnson, Alicia A., Ott, Miles Q., Dogucu, Mine. (2021). Bayes Rules! An Introduction
    to Applied Bayesian Modeling. CRC Press.*'
  prefs: []
  type: TYPE_NORMAL
