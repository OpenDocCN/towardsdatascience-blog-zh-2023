["```py\nimport xmltodict\nimport requests\n\nr = requests.get(\"https://news.itsfoss.com/sitemap-posts.xml\")\nxml = r.text\nrss = xmltodict.parse(xml)\n\narticle_links = [entry[\"loc\"] for entry in rss[\"urlset\"][\"url\"]]\n```", "```py\nfrom bs4 import BeautifulSoup\nfrom tqdm.notebook import tqdm\n\ndef extract_content(url):\n    html = requests.get(url).text\n    soup = BeautifulSoup(html, features=\"html.parser\")\n\n    elements = [\n        soup.select_one(\".c-topper__headline\"),\n        soup.select_one(\".c-topper__standfirst\"),\n        soup.select_one(\".c-content\"),\n    ]\n\n    text = \"\".join([element.get_text() for element in elements])\n\n    return text\n\narticles = []\n# Limited the list of > 900 articles to 10 for this example\nfor url in tqdm(article_links[0:10], desc=\"Extracting article content\"):\n    articles.append({\"source\": url, \"content\": extract_content(url)})\n```", "```py\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nrec_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, \n                                              chunk_overlap=150)\n\nweb_docs, meta = [], []\n\nfor article in tqdm(articles, desc=\"Splitting articles into chunks\"):\n    splits = rec_splitter.split_text(article[\"content\"])\n    web_docs.extend(splits)\n    meta.extend([{\"source\": article[\"source\"]}] * len(splits))\n```", "```py\nimport os\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import FAISS\n\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\n\narticle_store = FAISS.from_texts(\n    texts=web_docs, embedding=OpenAIEmbeddings(), metadatas=meta\n)\n```", "```py\nfrom langchain.document_loaders import YoutubeLoader\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\n\nyt_ids = [\n    \"OtD8wVaFm6E\",  # XGBoost Part 1 (of 4): Regression\n    \"8b1JEDvenQU\",  # XGBoost Part 2 (of 4): Classification\n    \"ZVFeW798-2I\",  # XGBoost Part 3 (of 4): Mathematical Details\n    \"oRrKeUCEbq8\",  # XGBoost Part 4 (of 4): Crazy Cool Optimizations\n]\n\nyt_docs = []\n\nfor yt_id in tqdm(yt_ids, desc=\"Retrieving transcripts\"):\n    splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=150, \n                                     separator=\" \")\n    yt_loader = YoutubeLoader(yt_id, add_video_info=True)\n    yt_docs.extend(yt_loader.load_and_split(splitter))\n```", "```py\n# Manipulate / extend source attribute\nfor doc in yt_docs:\n    doc.metadata[\"source\"] = (\n        doc.metadata[\"title\"]\n        + \" [\"\n        + doc.metadata[\"author\"]\n        + \"] \"\n        + \"https://youtu.be/\"\n        + doc.metadata[\"source\"]\n    )\n\n# Vector store\nyt_store = FAISS.from_documents(yt_docs, OpenAIEmbeddings())\n```", "```py\n[\n {'text': \"gonna talk about XG boost part 1 we're\",\n  'start': 14.19,\n  'duration': 6.21},\n {'text': 'gonna talk about XG boost trees and how',\n  'start': 17.91,\n  'duration': 6.66},\n...\n]\n```", "```py\n# Create transcript df\ndef create_transcript_df(yt_transcript: list, yt_id: str):\n    return (\n        pd.DataFrame(yt_transcript)\n        .assign(start_dt=lambda x: pd.to_datetime(x[\"start\"], unit=\"s\"))\n        .set_index(\"start_dt\")\n        .resample(\"3min\")\n        .agg({\"text\": \" \".join})\n        .reset_index()\n        .assign(start_dt=lambda x: x[\"start_dt\"].dt.minute * 60)\n        .assign(\n            source=lambda x: \"https://youtu.be/\"\n            + yt_id\n            + \"&t=\"\n            + x[\"start_dt\"].astype(\"str\")\n        )\n        .drop(columns=[\"start_dt\"])\n    )\n```", "```py\nfrom youtube_transcript_api import YouTubeTranscriptApi\n\nyt_ids = [\n    \"OtD8wVaFm6E\",  # XGBoost Part 1 (of 4): Regression\n    \"8b1JEDvenQU\",  # XGBoost Part 2 (of 4): Classification\n    \"ZVFeW798-2I\",  # XGBoost Part 3 (of 4): Mathematical Details\n    \"oRrKeUCEbq8\",  # XGBoost Part 4 (of 4): Crazy Cool Optimizations\n]\ntranscript_dfs = []\nfor yt_id in tqdm(yt_ids, desc=\"Fetching transcription\"):\n    yt_transcript = YouTubeTranscriptApi.get_transcript(yt_id)\n    transcript_dfs.append(create_transcript_df(yt_transcript, yt_id))\n\ntranscripts_df = pd.concat(transcript_dfs).reset_index(drop=True)\n```", "```py\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\n\ntext_splitter = CharacterTextSplitter(separator=\" \", chunk_size=1500, \n                                      chunk_overlap=150)\n\nyt_docs, yt_meta = [], []\n\nfor index, row in tqdm(transcripts_df.iterrows(), total=len(transcripts_df)):\n    splits = text_splitter.split_text(row[\"text\"])\n    yt_docs.extend(splits)\n    yt_meta.extend([{\"source\": row[\"source\"]}] * len(splits))\n    print(f\"Split {row['source']} into {len(splits)} chunks\")\n\nyt_ts_store = FAISS.from_texts(yt_docs, OpenAIEmbeddings(), metadatas=yt_meta)\n```", "```py\nfrom langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory(\n    memory_key=\"chat_history\",\n    input_key=\"question\",\n    output_key=\"answer\",\n    return_messages=True,\n)\n```", "```py\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"You are a chatbot having a conversation with a human.\nGiven the following extracted parts of a long document and a question, \ncreate a final answer.\n{context}\n{chat_history}\nHuman: {question}\nChatbot:\"\"\"\n\nquestion_prompt = PromptTemplate(\n    input_variables=[\"chat_history\", \"question\", \"context\"], template=template\n)\n```", "```py\nfrom langchain.chains import RetrievalQAWithSourcesChain\n\narticle_chain = RetrievalQAWithSourcesChain.from_llm(\n    llm=OpenAI(temperature=0.0),\n    retriever=article_store.as_retriever(k=4),\n    memory=memory,\n    question_prompt=question_prompt,\n)\n\nresult = article_chain({\"question\": \"What is Skiff?\"}, \n                        return_only_outputs=True)\n```", "```py\n{'question': 'What is Skiff?',\n 'answer':   'Skiff is a privacy-focused email service with unique \n              functionalities such as the ability to manage multiple \n              sessions, appearance tweaks, dark mode, white theme, \n              two layouts, supporting imports from Gmail, Outlook, \n              Proton Mail, and more, creating and managing aliases, \n              and connecting a crypto wallet from Coinbase, BitKeep, \n              Brave, and others to send/receive email utilizing Web3\\. \n              It also includes Pages to create/store documents securely, \n              the ability to use Skiff's server or IPFS (decentralized \n              technology) for file storage, and Skiff Pages, \n              Encrypted Cloud Storage With IPFS Support.\\n',\n 'sources': 'https://news.itsfoss.com/skiff-mail-review/'}\n```", "```py\narticle_chain(\n    {\"question\": \"What are its functionalities?\"},\n    return_only_outputs=True,\n)\n```", "```py\n{\n'answer': \"Skiff offers a range of functionalities, \nincluding Web3 integration, IPFS decentralized storage, \ncreating and managing aliases, connecting crypto wallets, \ngetting credits to upgrade your account, importing from Gmail, \nOutlook, Proton Mail, and more, Pages to create/store documents securely, \nencrypted cloud storage with IPFS support, and the ability to use \nSkiff's server or IPFS (decentralized technology) for file storage.\\n\",\n 'sources': 'https://news.itsfoss.com/anytype-open-beta/, \n             https://news.itsfoss.com/skiff-mail-review/'\n}\n```", "```py\nfrom langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory(\n    memory_key=\"chat_history\",\n    input_key=\"question\",\n    output_key=\"answer\",\n    return_messages=True,\n)\n\ntemplate = \"\"\"You are a chatbot having a conversation with a human.\n    Given the following extracted parts of a long document and a question, \n    create a final answer.\n    {context}\n    {chat_history}\n    Human: {question}\n    Chatbot:\"\"\"\n\nquestion_prompt = PromptTemplate(\n    input_variables=[\"chat_history\", \"question\", \"context\"], template=template\n)\n```", "```py\n# Use yt_store for YouTube transcripts without timestamps or\n# yt_ts_store with timestamps as sources.\nyt_chain = RetrievalQAWithSourcesChain.from_llm(\n    llm=OpenAI(temperature=0.0),\n    retriever=yt_store.as_retriever(k=4),\n    memory=memory,\n    question_prompt=question_prompt,\n)\n```", "```py\nresult = yt_chain(\n    {\n        \"question\": \"What is the difference in building a tree for a \n                     regression case compared to a classification case?\"\n    },\n    return_only_outputs=True\n)\n```", "```py\n{'answer': ' The main difference between building a tree for a regression case \n              and a classification case is that in a regression case, the goal \n              is to predict a continuous value, while in a classification case,\n              the goal is to predict a discrete value. In a regression case, \n              the tree is built by splitting the data into subsets based on \n              the value of a certain feature, while in a classification case, \n              the tree is built by splitting the data into subsets based on \n              the value of a certain feature and the class label. \n              Additionally, in a regression case, \n              the weights are all equal to one, \n              while in a classification case, the weights are the previous \n              probability times one minus the previous probability.\\n',\n 'sources': 'XGBoost Part 2 (of 4): Classification [StatQuest with Josh Starmer] https://youtu.be/8b1JEDvenQU, \n             XGBoost Part 3 (of 4): Mathematical Details [StatQuest with Josh Starmer] https://youtu.be/ZVFeW798-2I, \n             XGBoost Part 4 (of 4): Crazy Cool Optimizations [StatQuest with Josh Starmer] https://youtu.be/oRrKeUCEbq8'\n}\n```", "```py\n{'answer': 'The difference in building a tree for a regression case compared \n            to a classification case is that in a regression case, the goal \n            is to predict a continuous value, while in a classification case, \n            the goal is to predict a probability that the drug will be \n            effective. Additionally, the numerator for classification is the \n            same as the numerator for regression, but the denominator \n            contains a regularization parameter. The denominator for \n            classification is different from the denominator for regression, \n            and is the sum for each observation of the previously predicted \n            probability times 1 minus the previously predicted probability. \n            The only difference between building a tree for a regression case \n            and a classification case is the loss function.\\n',\n 'sources': 'https://youtu.be/ZVFeW798-2I&t=0 \n             https://youtu.be/8b1JEDvenQU&t=180\n             https://youtu.be/OtD8wVaFm6E&t=0'\n}\n```"]