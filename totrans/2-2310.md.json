["```py\nclass WordVosk:\n    \"\"\"A class representing a word from the JSON format for Vosk speech recognition API.\"\"\"\n\n    def __init__(self, conf: float, start: float, end: float, word: str) -> None:\n        \"\"\"\n        Initialize a Word object.\n\n        Args:\n            conf (float): Degree of confidence, from 0 to 1.\n            start (float): Start time of pronouncing the word, in seconds.\n            end (float): End time of pronouncing the word, in seconds.\n            word (str): Recognized word.\n        \"\"\"\n        self.conf = conf\n        self.start = start\n        self.end = end\n        self.word = word\n\n    def to_dict(self) -> Dict[str, Union[float, str]]:\n        \"\"\"Return a dictionary representation of the Word object.\"\"\"\n        return {\n            \"conf\": self.conf,\n            \"start\": self.start,\n            \"end\": self.end,\n            \"word\": self.word,\n        }\n\n    def to_string(self) -> str:\n        \"\"\"Return a string describing this instance.\"\"\"\n        return \"{:20} from {:.2f} sec to {:.2f} sec, confidence is {:.2f}%\".format(\n            self.word, self.start, self.end, self.conf * 100\n        )\n\n    def to_json(self) -> str:\n        \"\"\"Return a JSON representation of the Word object.\"\"\"\n        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True)\n```", "```py\nclass Transcription:\n    def __init__(self, words: List[WordVosk]) -> None:\n        self.words = words\n\n    def to_dict(self) -> List[Dict[str, Union[float, str]]]:\n        \"\"\"Return a dictionary representation of the Transcription object.\"\"\"\n        return [word.to_dict() for word in self.words]\n\n    def to_raw_text(self) -> str:\n        \"\"\"Generate raw transcription text from the list of WordVosk objects.\"\"\"\n        return \" \".join(word.word for word in self.words)\n```", "```py\nclass ModelSpeechToText:\n    def __init__(self, audio_path: str, model_path: str) -> None:\n        self.audio_path = audio_path\n        self.wf = wave.open(self.audio_path)\n        self.model = Model(model_path)\n```", "```py\n def speech_to_text(self) -> List[Dict[str, Any]]:\n        \"\"\"Transcribe speech to text using the Vosk API.\"\"\"\n        rec = KaldiRecognizer(self.model, self.wf.getframerate())\n        rec.SetWords(True)\n\n        results = []\n        frames_per_second = 44100\n        i = 0\n        print(\"Starting transcription process...\")\n        while True:\n            data = self.wf.readframes(4000)\n            i += 4000\n            if len(data) == 0:\n                break\n            if rec.AcceptWaveform(data):\n                part_result = json.loads(rec.Result())\n                results.append(part_result)\n            if i % (frames_per_second * 60) == 0:\n                print(f\"{i / frames_per_second / 60} minutes processed\")\n        part_result = json.loads(rec.FinalResult())\n        results.append(part_result)\n        self.wf.close()\n        print(\"Transcription process completed.\")\n        return results\n```", "```py\n @staticmethod\n    def results_to_words(results: List[Dict[str, Any]]) -> List[WordVosk]:\n        \"\"\"Convert a list of Vosk API results to a list of words.\"\"\"\n        list_of_words = []\n        for sentence in results:\n            if len(sentence) == 1:\n                continue\n            for ind_res in sentence[\"result\"]:\n                word = WordVosk(\n                    conf=ind_res[\"conf\"],\n                    start=ind_res[\"start\"],\n                    end=ind_res[\"end\"],\n                    word=ind_res[\"word\"],\n                )\n\n                list_of_words.append(word)\n        return list_of_words\n```", "```py\ndef calculate_wer(\n    reference_transcriptions: List[str], hypothesis_transcriptions: List[str]\n) -> float:\n    \"\"\"Calculate the average Word Error Rate (WER) between reference and hypothesis transcriptions.\n\n    Args:\n        reference_transcriptions: List of reference transcriptions.\n        hypothesis_transcriptions: List of hypothesis transcriptions.\n\n    Returns:\n        The average Word Error Rate (WER).\n    \"\"\"\n    assert len(reference_transcriptions) == len(\n        hypothesis_transcriptions\n    ), \"Reference and hypothesis lists should have the same length\"\n    total_wer = 0\n    for ref, hyp in zip(reference_transcriptions, hypothesis_transcriptions):\n        total_wer += wer(ref, hyp)\n    return total_wer / len(reference_transcriptions)\n```", "```py\ndef evaluate_models(\n    models: List[ModelSpeechToText],\n    evaluation_dataset: List[Tuple[str, str]],\n) -> List[Tuple[float, float, float]]:\n    \"\"\"Evaluate multiple speech-to-text models using a given evaluation dataset.\n\n    Args:\n        models: A list of ModelSpeechToText instances.\n        evaluation_dataset: A list of tuples containing the paths of the WAV files and their transcriptions.\n\n    Returns:\n        A list of tuples containing WER, execution time, and RAM usage for each model.\n    \"\"\"\n    if not evaluation_dataset:\n        print(\"The evaluation dataset is empty. Please check the dataset processing.\")\n        return []\n\n    audio_files, reference_transcriptions = zip(*evaluation_dataset)\n\n    metrics = []\n    for model in models:\n        start_time = time.time()\n\n        hypothesis_transcriptions = transcribe_audio_files(model, audio_files)\n\n        memory = psutil.Process().memory_info().rss\n        elapsed_time = time.time() - start_time\n\n        wer = calculate_wer(reference_transcriptions, hypothesis_transcriptions)\n\n        metrics.append((wer, elapsed_time, memory / 1024 ** 3))\n\n        del model\n        gc.collect()\n\n    return metrics\n```"]