["```py\nfrom sklearn.datasets import fetch_openml\n\nX, y = fetch_openml('mnist_784', return_X_y=True, as_frame=False)\n```", "```py\nprint(X.shape)\n```", "```py\n(70000, 784)\n```", "```py\nfig, axes = plt.subplots(5, 10, figsize=(10, 5))\ni = 0\nfor ax in axes.flat:\n    ax.imshow(X[i].reshape(28, 28), cmap='binary')\n    ax.axis('off')    \n    i += 1\n```", "```py\nX = X / 255\n```", "```py\ntrain_size = 60000\nX_train, y_train = X[:train_size], y[:train_size]\nX_test, y_test = X[train_size:], y[train_size:]\n```", "```py\nfrom sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\n```", "```py\nConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n```", "```py\nclf = LogisticRegression(max_iter=1000)\nclf.fit(X_train, y_train)\n```", "```py\nprint(clf.n_iter_)\n```", "```py\n[795]\n```", "```py\nprint('Training set accuracy: ', np.round(clf.score(X_train, y_train), 4))\nprint('Test set accuracy:' , np.round(clf.score(X_test, y_test), 4))\n```", "```py\nTraining set accuracy: 0.9393\nTest set accuracy: 0.9256\n```", "```py\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ny_test_pred = clf.predict(X_test)\ncm = confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\ndisp.plot(cmap='Blues')\n```", "```py\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_test_pred))\n```", "```py\n precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96       980\n           1       0.96      0.98      0.97      1135\n           2       0.93      0.90      0.91      1032\n           3       0.90      0.92      0.91      1010\n           4       0.94      0.94      0.94       982\n           5       0.90      0.87      0.88       892\n           6       0.94      0.95      0.95       958\n           7       0.93      0.92      0.93      1028\n           8       0.88      0.88      0.88       974\n           9       0.91      0.92      0.91      1009\n\n    accuracy                           0.93     10000\n   macro avg       0.92      0.92      0.92     10000\nweighted avg       0.93      0.93      0.93     10000\n```", "```py\nprint(clf.coef_.shape)\n```", "```py\n(10, 784)\n```", "```py\nfig, axes = plt.subplots(2, 5, figsize=(15, 5))\n\ndigit = 0\nfor coef, ax in zip(clf.coef_, axes.flat):\n    im = ax.imshow(coef.reshape(28, 28), cmap='gray')\n    ax.axis('off')\n    ax.set_title(str(digit))\n    digit += 1\n\nfig.colorbar(im, ax=axes.flat)\n```"]