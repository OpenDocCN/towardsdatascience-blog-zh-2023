- en: 'Gradient Boosting: a Silver Bullet in Forecasting'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/gradient-boosting-a-silver-bullet-in-forecasting-5820ba7182fd](https://towardsdatascience.com/gradient-boosting-a-silver-bullet-in-forecasting-5820ba7182fd)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We show that gradient boosting is very powerful for timeseries forecasting and
    we try to explain why
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)[![Davide
    Burba](../Images/a1ca3cf59c2b933021fa0d978e1af522.png)](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)
    [Davide Burba](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)
    ·6 min read·Jul 20, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6df1867e40446de2efa71a90ee5550c2.png)'
  prefs: []
  type: TYPE_IMG
- en: “Gradient Boosting”, by [Giulia Roggia](https://www.instagram.com/giulia_roggia__/).
    Used with permission.
  prefs: []
  type: TYPE_NORMAL
- en: '[What is gradient boosting?](#e549)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gradient boosting as a silver bullet](#3d7d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why is gradient boosting so good?](#76cc)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A word of caution](#af1c)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Appendix: List of competitions and published solutions](#aca8)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time-series forecasting is a crucial task in many domains, including finance,
    sales, and weather prediction. While classical timeseries models and deep learning
    techniques have been widely used for this purpose, there’s growing evidence that
    gradient boosting often outshines other methods.
  prefs: []
  type: TYPE_NORMAL
- en: What is gradient boosting?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) is a machine
    learning technique that builds predictive models by combining an ensemble of weak
    learners in a sequential manner. It aims to create a strong learner by iteratively
    minimizing the errors made by the previous models. The core idea is to fit subsequent
    models to the residuals of the previous models, gradually improving predictions
    with each iteration.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0574a91103d1b19408d9912ebd17c86b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '[LightGBM](https://lightgbm.readthedocs.io/en/v3.3.2/) and [XGBoost](https://xgboost.readthedocs.io/en/stable/)
    are two prominent libraries that implement gradient boosting algorithms. They
    have gained popularity due to their efficiency, scalability, and exceptional performance.'
  prefs: []
  type: TYPE_NORMAL
- en: While gradient boosting was not designed specifically for time-series data,
    we can use it for forecasting via a feature engineering step. You can check [this
    article](https://medium.com/towards-data-science/why-backtesting-matters-and-how-to-do-it-right-731fb9624a)
    for a concrete example.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosting as a silver bullet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can examine the winning solutions of competitions to evaluate the most powerful
    models in a given domain. Winning solutions are sometimes criticised for being
    too complex and not easily reproducible in a production environment. However,
    when a particular model consistently emerges in the winning solutions across different
    competitions, it demonstrates its ability to tackle complex challenges effectively.
  prefs: []
  type: TYPE_NORMAL
- en: The most famous Data Science competition platform is [Kaggle](https://www.kaggle.com/).
    Let’s have a look at the monetary forecasting competitions that were played in
    the last 10 years (see picture below).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dba08f3ecb10bee2654931cad88b6179.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot from [Kaggle](https://www.kaggle.com/) made in May 2023.
  prefs: []
  type: TYPE_NORMAL
- en: 'Top solutions are often published in the Discussion section once a competition
    ends. In this analysis we considered the published solutions that made it to the
    top 10 (you can check the details in [Appendix](#aca8)). Across these, we see
    that:'
  prefs: []
  type: TYPE_NORMAL
- en: '**All competitions have top solutions using gradient boosting** (usually LightGBM)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we consider only the single top published solution for each competition,
    we see that **they are** **based on gradient boosting in 6 cases out of 8** (the
    other two are based on deep learning models, i.e. [*MLB*](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/274255)
    and [*Wikipedia*](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43795))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We had to discard the oldest two competitions due to the absence of published
    solutions, and “*M5 Uncertainty*” competition because some solutions were based
    on the “*M5 Accuracy*” (which were often based on LightGBM, including the [winning
    one](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163684)).
  prefs: []
  type: TYPE_NORMAL
- en: Why is gradient boosting so good?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several factors which make gradient boosting a powerful model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling Nonlinear Relationships**: Traditional timeseries models often struggle
    to capture nonlinear patterns in data. On the other hand, gradient boosting can
    automatically learn complex relationships between variables. In particular, the
    tree based structure allows to learn abrupt changes, which are typical in tabular
    data and harder to learn for deep learning models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Global model**: Gradient boosting allows to train global models, i.e. single
    models trained on multiple timeseries. This often leads to better prediction than
    using one model per timeseries, which is the approach used by traditional timeseries
    models. For more information about local vs global models, you can check [this
    article](https://medium.com/towards-data-science/local-vs-global-forecasting-what-you-need-to-know-1cc29e66cae0).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Categorical Features**: One of the advantages of LightGBM is its ability
    to handle categorical features without the need to one-hot encode, which often
    is not efficient, or not even feasible due to memory constraints.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Fine tuning**: Apart from feature engineering, there’s a wide range of options
    that we can fine-tune to improve gradient boosting based models, including the
    choice of a custom loss function and parameters to improve the robustness to non-informative
    features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Quick and Scalable**: LightGBM and XGBoost are designed with efficiency and
    scalability in mind. These libraries employ advanced optimization techniques and
    parallel processing, enabling to handle large-scale data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are several resources that benchmark and try to explain why gradient
    boosting is great for tabular data, and these generally also apply to time-series
    forecasting. Here are some of these resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Why do tree-based models still outperform deep learning on tabular data?](https://arxiv.org/abs/2207.08815)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Learning vs. Gradient Boosting: Benchmarking state-of-the-art machine
    learning algorithms for credit scoring](https://arxiv.org/abs/2205.10535#:~:text=The%20experiment%20has%20shown%20that,and%20choice%20for%20credit%20scoring.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tabular Data: Deep Learning is Not All You Need](https://arxiv.org/abs/2106.03253)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A word of caution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We saw that gradient boosting is a powerful model for timeseries forecasting.
    However, there are some cases in which a different model might be a better idea:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Small, regular data**: If the data is very small (e.g. a single timeseries
    with just a few samples) and smooth, a traditional approach like exponential smoothing
    or ARIMA might be preferred. The reason is that gradient boosting still needs
    a minimum amount of data to fit and to tune the hyper-parameters. On the other
    hand, traditional time series models have strong assumptions on the stochastic
    process generating the data, which makes the parameters estimation easier. In
    practice, this kind of data is rarely seen outside of toy problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Huge data**: Gradient boosting is quite scalable. However, if we are talking
    about billions of data samples, a deep learning approach might be preferred. Apart
    from the fact that deep learning models shine with big data, they can also be
    continuously trained, while gradient boosting models usually have to be trained
    from scratch. Furthermore, they provide even better scalability in terms of categorical
    features via embedding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extremely low signal-to-noise ratio**: Although gradient boosting is quite
    robust to noise, in some extreme cases (e.g. stock prices prediction) it might
    lead to overfit. If so, it may be worth to test also less powerful but more robust
    models (e.g. linear models).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Appendix: List of competitions and published solutions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here below you can find the list of competitions and top public solutions considered
    for this article.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/march-machine-learning-mania-2023?source=post_page-----5820ba7182fd--------------------------------)
    [## March Machine Learning Mania 2023'
  prefs: []
  type: TYPE_NORMAL
- en: Forecast the 2023 NCAA Basketball Tournaments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/march-machine-learning-mania-2023?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/399553)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, Ensemble including XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/401578)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/401641)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5th, XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/401382)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7th, Ensemble including XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/400116)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8th, Ensemble including LightGBM](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/400834)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9th, Ensemble including XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/400151)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/g-research-crypto-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## G-Research Crypto Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: Use your ML expertise to predict real crypto market data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/g-research-crypto-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[2nd, LightGBM](https://www.kaggle.com/competitions/g-research-crypto-forecasting/discussion/323098)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, LightGBM](https://www.kaggle.com/competitions/g-research-crypto-forecasting/discussion/323703)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7th, Transformers](https://www.kaggle.com/competitions/g-research-crypto-forecasting/discussion/323250)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## MLB Player Digital Engagement Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: Predict fan engagement with baseball player digital content
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, GRU](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/274255)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, LightGBM & XGBoost](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/274661)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, Ensemble including LightGBM](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/256620)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5th, Ensemble including LightGBM & CatBoost](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/271345)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6th, Ensemble including LightGBM & CatBoost](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/271890)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8th, LSTM](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/271683)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/m5-forecasting-accuracy?source=post_page-----5820ba7182fd--------------------------------)
    [## M5 Forecasting — Accuracy'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate the unit sales of Walmart retail goods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/m5-forecasting-accuracy?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163684)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/164599)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, Modified DeepAR](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/164374)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4th, LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163216)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/m5-forecasting-uncertainty?source=post_page-----5820ba7182fd--------------------------------)
    [## M5 Forecasting — Uncertainty'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate the uncertainty distribution of Walmart unit sales.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/m5-forecasting-uncertainty?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Skipped: solutions based on M5-accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Recruit Restaurant Visitor Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: Predict how many future visitors a restaurant will receive
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[7th, LightGBM](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting/discussion/49166)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Corporación Favorita Grocery Sales Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: Can you accurately predict sales for a large grocery chain?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, Wavenet](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47568)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47560)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4th, Seq2Seq](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47529)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5th, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47556)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6th, Lightgbm](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47575)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8th, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47564)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Web Traffic Time Series Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: Forecast future traffic to Wikipedia pages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, Seq2Seq](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43795)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, Ensemble including XGBoost](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/39370)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5th, Polynomial Regression](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43603)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6th, CNN](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/39370)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7th, Neural Nets](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43621)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8th, Kalman](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43727)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/rossmann-store-sales?source=post_page-----5820ba7182fd--------------------------------)
    [## Rossmann Store Sales'
  prefs: []
  type: TYPE_NORMAL
- en: Forecast sales using store, promotion, and competitor data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/rossmann-store-sales?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, XGBoost](https://www.kaggle.com/competitions/rossmann-store-sales/discussion/18024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, Neural Nets](https://www.kaggle.com/competitions/rossmann-store-sales/discussion/17974)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/genentech-flu-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Flu Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: Predict when, where and how strong the flu will be
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/genentech-flu-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The discussion page does not load.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/ams-2014-solar-energy-prediction-contest/overview?source=post_page-----5820ba7182fd--------------------------------)
    [## AMS 2013–2014 Solar Energy Prediction Contest'
  prefs: []
  type: TYPE_NORMAL
- en: Forecast daily solar energy with an ensemble of weather models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/ams-2014-solar-energy-prediction-contest/overview?source=post_page-----5820ba7182fd--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: No published solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '*Enjoyed this article?* [*Checkout my other ones*](https://medium.com/@davide.burba)
    *and follow me for more!* [*Click here*](https://medium.com/@davide.burba/membership)
    *to read unlimited articles and support me at no additional cost for you*❤️'
  prefs: []
  type: TYPE_NORMAL
