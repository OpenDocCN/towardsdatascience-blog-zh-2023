- en: 'Gradient Boosting: a Silver Bullet in Forecasting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升：预测中的银弹
- en: 原文：[https://towardsdatascience.com/gradient-boosting-a-silver-bullet-in-forecasting-5820ba7182fd](https://towardsdatascience.com/gradient-boosting-a-silver-bullet-in-forecasting-5820ba7182fd)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/gradient-boosting-a-silver-bullet-in-forecasting-5820ba7182fd](https://towardsdatascience.com/gradient-boosting-a-silver-bullet-in-forecasting-5820ba7182fd)
- en: We show that gradient boosting is very powerful for timeseries forecasting and
    we try to explain why
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们展示了梯度提升在时间序列预测中非常强大，并尝试解释原因
- en: '[](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)[![Davide
    Burba](../Images/a1ca3cf59c2b933021fa0d978e1af522.png)](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)
    [Davide Burba](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)[![Davide
    Burba](../Images/a1ca3cf59c2b933021fa0d978e1af522.png)](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)
    [Davide Burba](https://medium.com/@davide.burba?source=post_page-----5820ba7182fd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)
    ·6 min read·Jul 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5820ba7182fd--------------------------------)
    ·6分钟阅读·2023年7月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6df1867e40446de2efa71a90ee5550c2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6df1867e40446de2efa71a90ee5550c2.png)'
- en: “Gradient Boosting”, by [Giulia Roggia](https://www.instagram.com/giulia_roggia__/).
    Used with permission.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “梯度提升”，由 [Giulia Roggia](https://www.instagram.com/giulia_roggia__/)。经许可使用。
- en: '[What is gradient boosting?](#e549)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是梯度提升？](#e549)'
- en: '[Gradient boosting as a silver bullet](#3d7d)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梯度提升作为银弹](#3d7d)'
- en: '[Why is gradient boosting so good?](#76cc)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么梯度提升如此出色？](#76cc)'
- en: '[A word of caution](#af1c)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[注意事项](#af1c)'
- en: '[Appendix: List of competitions and published solutions](#aca8)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[附录：竞赛和发布解决方案列表](#aca8)'
- en: Time-series forecasting is a crucial task in many domains, including finance,
    sales, and weather prediction. While classical timeseries models and deep learning
    techniques have been widely used for this purpose, there’s growing evidence that
    gradient boosting often outshines other methods.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测在许多领域中都非常重要，包括金融、销售和天气预测。尽管经典的时间序列模型和深度学习技术已被广泛使用，但有越来越多的证据表明，梯度提升通常优于其他方法。
- en: What is gradient boosting?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是梯度提升？
- en: '[Gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) is a machine
    learning technique that builds predictive models by combining an ensemble of weak
    learners in a sequential manner. It aims to create a strong learner by iteratively
    minimizing the errors made by the previous models. The core idea is to fit subsequent
    models to the residuals of the previous models, gradually improving predictions
    with each iteration.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[梯度提升](https://en.wikipedia.org/wiki/Gradient_boosting) 是一种机器学习技术，通过按顺序组合一组弱学习者来构建预测模型。它旨在通过迭代最小化前一个模型的误差来创建一个强学习者。其核心思想是将后续模型拟合到前一个模型的残差上，通过每次迭代逐步提高预测精度。'
- en: '![](../Images/0574a91103d1b19408d9912ebd17c86b.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0574a91103d1b19408d9912ebd17c86b.png)'
- en: Image by author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '[LightGBM](https://lightgbm.readthedocs.io/en/v3.3.2/) and [XGBoost](https://xgboost.readthedocs.io/en/stable/)
    are two prominent libraries that implement gradient boosting algorithms. They
    have gained popularity due to their efficiency, scalability, and exceptional performance.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[LightGBM](https://lightgbm.readthedocs.io/en/v3.3.2/) 和 [XGBoost](https://xgboost.readthedocs.io/en/stable/)
    是两个著名的实现梯度提升算法的库。它们因高效、可扩展和卓越的性能而受到欢迎。'
- en: While gradient boosting was not designed specifically for time-series data,
    we can use it for forecasting via a feature engineering step. You can check [this
    article](https://medium.com/towards-data-science/why-backtesting-matters-and-how-to-do-it-right-731fb9624a)
    for a concrete example.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管梯度提升并非专门为时间序列数据设计，但我们可以通过特征工程步骤将其用于预测。你可以查看[这篇文章](https://medium.com/towards-data-science/why-backtesting-matters-and-how-to-do-it-right-731fb9624a)以获取具体的示例。
- en: Gradient boosting as a silver bullet
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升作为银弹
- en: We can examine the winning solutions of competitions to evaluate the most powerful
    models in a given domain. Winning solutions are sometimes criticised for being
    too complex and not easily reproducible in a production environment. However,
    when a particular model consistently emerges in the winning solutions across different
    competitions, it demonstrates its ability to tackle complex challenges effectively.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检视竞赛的获胜解决方案来评估某一领域内最强的模型。获胜的解决方案有时会因为过于复杂且难以在生产环境中复制而受到批评。然而，当某个特定模型在不同竞赛中
    consistently 出现于获胜解决方案中时，它展示了应对复杂挑战的能力。
- en: The most famous Data Science competition platform is [Kaggle](https://www.kaggle.com/).
    Let’s have a look at the monetary forecasting competitions that were played in
    the last 10 years (see picture below).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的数据科学竞赛平台是 [Kaggle](https://www.kaggle.com/)。让我们来看看过去 10 年中进行的货币预测竞赛（见下图）。
- en: '![](../Images/dba08f3ecb10bee2654931cad88b6179.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dba08f3ecb10bee2654931cad88b6179.png)'
- en: Screenshot from [Kaggle](https://www.kaggle.com/) made in May 2023.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从 [Kaggle](https://www.kaggle.com/) 截取的屏幕截图，拍摄于 2023 年 5 月。
- en: 'Top solutions are often published in the Discussion section once a competition
    ends. In this analysis we considered the published solutions that made it to the
    top 10 (you can check the details in [Appendix](#aca8)). Across these, we see
    that:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 顶级解决方案通常会在竞赛结束后发布在讨论区。在本分析中，我们考虑了那些进入前 10 的发布解决方案（你可以在[附录](#aca8)中查看详情）。在这些解决方案中，我们看到：
- en: '**All competitions have top solutions using gradient boosting** (usually LightGBM)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**所有竞赛都有使用梯度提升的顶级解决方案**（通常是 LightGBM）'
- en: If we consider only the single top published solution for each competition,
    we see that **they are** **based on gradient boosting in 6 cases out of 8** (the
    other two are based on deep learning models, i.e. [*MLB*](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/274255)
    and [*Wikipedia*](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43795))
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果我们只考虑每个竞赛的单一顶级发布解决方案，我们会发现**它们** **在 8 个案例中有 6 个是基于梯度提升的**（另外两个基于深度学习模型，即
    [*MLB*](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/274255)
    和 [*Wikipedia*](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43795)） '
- en: We had to discard the oldest two competitions due to the absence of published
    solutions, and “*M5 Uncertainty*” competition because some solutions were based
    on the “*M5 Accuracy*” (which were often based on LightGBM, including the [winning
    one](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163684)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不得不放弃最早的两个竞赛，因为没有发布解决方案，以及“*M5 不确定性*”竞赛，因为一些解决方案基于“*M5 准确性*”（这些解决方案通常基于 LightGBM，包括[获胜者](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163684)）。
- en: Why is gradient boosting so good?
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么梯度提升如此出色？
- en: 'There are several factors which make gradient boosting a powerful model:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个因素使得梯度提升成为一个强大的模型：
- en: '**Handling Nonlinear Relationships**: Traditional timeseries models often struggle
    to capture nonlinear patterns in data. On the other hand, gradient boosting can
    automatically learn complex relationships between variables. In particular, the
    tree based structure allows to learn abrupt changes, which are typical in tabular
    data and harder to learn for deep learning models.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理非线性关系**：传统的时间序列模型通常难以捕捉数据中的非线性模式。另一方面，梯度提升可以自动学习变量之间的复杂关系。特别是，基于树的结构能够学习突变，这在表格数据中很常见，并且对于深度学习模型而言更难以学习。'
- en: '**Global model**: Gradient boosting allows to train global models, i.e. single
    models trained on multiple timeseries. This often leads to better prediction than
    using one model per timeseries, which is the approach used by traditional timeseries
    models. For more information about local vs global models, you can check [this
    article](https://medium.com/towards-data-science/local-vs-global-forecasting-what-you-need-to-know-1cc29e66cae0).'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**全局模型**：梯度提升允许训练全局模型，即在多个时间序列上训练单个模型。这通常比使用每个时间序列一个模型的方式（传统时间序列模型使用的方式）能得到更好的预测效果。有关局部模型与全局模型的更多信息，你可以查看[这篇文章](https://medium.com/towards-data-science/local-vs-global-forecasting-what-you-need-to-know-1cc29e66cae0)。'
- en: '**Categorical Features**: One of the advantages of LightGBM is its ability
    to handle categorical features without the need to one-hot encode, which often
    is not efficient, or not even feasible due to memory constraints.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类特征**：LightGBM 的一个优点是能够处理分类特征，而无需进行 one-hot 编码，这通常效率不高，或者由于内存限制甚至不可行。'
- en: '**Fine tuning**: Apart from feature engineering, there’s a wide range of options
    that we can fine-tune to improve gradient boosting based models, including the
    choice of a custom loss function and parameters to improve the robustness to non-informative
    features.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**微调**：除了特征工程外，我们可以微调的选项范围很广，以改善基于梯度提升的模型，包括选择自定义损失函数和参数，以提高对无信息特征的鲁棒性。'
- en: '**Quick and Scalable**: LightGBM and XGBoost are designed with efficiency and
    scalability in mind. These libraries employ advanced optimization techniques and
    parallel processing, enabling to handle large-scale data.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**快速且可扩展**：LightGBM和XGBoost在设计时考虑了效率和可扩展性。这些库采用了先进的优化技术和并行处理，使得处理大规模数据成为可能。'
- en: 'There are several resources that benchmark and try to explain why gradient
    boosting is great for tabular data, and these generally also apply to time-series
    forecasting. Here are some of these resources:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个资源对梯度提升进行基准测试，并尝试解释为何梯度提升在表格数据上表现优异，这些资源通常也适用于时间序列预测。以下是一些这些资源：
- en: '[Why do tree-based models still outperform deep learning on tabular data?](https://arxiv.org/abs/2207.08815)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么基于树的模型在表格数据上仍优于深度学习？](https://arxiv.org/abs/2207.08815)'
- en: '[Deep Learning vs. Gradient Boosting: Benchmarking state-of-the-art machine
    learning algorithms for credit scoring](https://arxiv.org/abs/2205.10535#:~:text=The%20experiment%20has%20shown%20that,and%20choice%20for%20credit%20scoring.)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习 vs. 梯度提升：信用评分的前沿机器学习算法基准测试](https://arxiv.org/abs/2205.10535#:~:text=The%20experiment%20has%20shown%20that,and%20choice%20for%20credit%20scoring.)'
- en: '[Tabular Data: Deep Learning is Not All You Need](https://arxiv.org/abs/2106.03253)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[表格数据：深度学习并非唯一选择](https://arxiv.org/abs/2106.03253)'
- en: A word of caution
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警告
- en: 'We saw that gradient boosting is a powerful model for timeseries forecasting.
    However, there are some cases in which a different model might be a better idea:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到梯度提升是时间序列预测的强大模型。然而，有些情况下使用其他模型可能更为合适：
- en: '**Small, regular data**: If the data is very small (e.g. a single timeseries
    with just a few samples) and smooth, a traditional approach like exponential smoothing
    or ARIMA might be preferred. The reason is that gradient boosting still needs
    a minimum amount of data to fit and to tune the hyper-parameters. On the other
    hand, traditional time series models have strong assumptions on the stochastic
    process generating the data, which makes the parameters estimation easier. In
    practice, this kind of data is rarely seen outside of toy problems.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小而规则的数据**：如果数据非常小（例如仅有少数样本的单一时间序列）且平滑，传统方法如指数平滑或ARIMA可能更为合适。原因在于梯度提升仍需要最少量的数据来拟合和调整超参数。另一方面，传统时间序列模型对生成数据的随机过程有较强的假设，这使得参数估计更为容易。在实践中，这种数据在实际问题中很少见。'
- en: '**Huge data**: Gradient boosting is quite scalable. However, if we are talking
    about billions of data samples, a deep learning approach might be preferred. Apart
    from the fact that deep learning models shine with big data, they can also be
    continuously trained, while gradient boosting models usually have to be trained
    from scratch. Furthermore, they provide even better scalability in terms of categorical
    features via embedding.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大规模数据**：梯度提升相当可扩展。然而，如果我们谈论的是数十亿的数据样本，可能更倾向于使用深度学习方法。除了深度学习模型在大数据上表现优越外，它们还可以不断训练，而梯度提升模型通常需要从头开始训练。此外，它们在分类特征方面通过嵌入提供了更好的可扩展性。'
- en: '**Extremely low signal-to-noise ratio**: Although gradient boosting is quite
    robust to noise, in some extreme cases (e.g. stock prices prediction) it might
    lead to overfit. If so, it may be worth to test also less powerful but more robust
    models (e.g. linear models).'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**极低的信噪比**：虽然梯度提升对噪声相当鲁棒，但在一些极端情况下（例如股票价格预测），可能会导致过拟合。如果是这样，可能值得尝试一些较不强大但更为鲁棒的模型（例如线性模型）。'
- en: 'Appendix: List of competitions and published solutions'
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录：竞赛和已发布解决方案列表
- en: Here below you can find the list of competitions and top public solutions considered
    for this article.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以找到为本文考虑的竞赛列表和顶级公开解决方案。
- en: '[](https://www.kaggle.com/competitions/march-machine-learning-mania-2023?source=post_page-----5820ba7182fd--------------------------------)
    [## March Machine Learning Mania 2023'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/competitions/march-machine-learning-mania-2023?source=post_page-----5820ba7182fd--------------------------------)
    [## 2023年三月机器学习狂欢]'
- en: Forecast the 2023 NCAA Basketball Tournaments
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测2023年NCAA篮球锦标赛
- en: www.kaggle.com](https://www.kaggle.com/competitions/march-machine-learning-mania-2023?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/399553)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, Ensemble including XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/401578)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/401641)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5th, XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/401382)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7th, Ensemble including XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/400116)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8th, Ensemble including LightGBM](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/400834)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9th, Ensemble including XGBoost](https://www.kaggle.com/competitions/march-machine-learning-mania-2023/discussion/400151)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/g-research-crypto-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## G-Research Crypto Forecasting'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Use your ML expertise to predict real crypto market data
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/g-research-crypto-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[2nd, LightGBM](https://www.kaggle.com/competitions/g-research-crypto-forecasting/discussion/323098)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, LightGBM](https://www.kaggle.com/competitions/g-research-crypto-forecasting/discussion/323703)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7th, Transformers](https://www.kaggle.com/competitions/g-research-crypto-forecasting/discussion/323250)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## MLB Player Digital Engagement Forecasting'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Predict fan engagement with baseball player digital content
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, GRU](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/274255)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, LightGBM & XGBoost](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/274661)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, Ensemble including LightGBM](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/256620)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5th, Ensemble including LightGBM & CatBoost](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/271345)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6th, Ensemble including LightGBM & CatBoost](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/271890)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8th, LSTM](https://www.kaggle.com/competitions/mlb-player-digital-engagement-forecasting/discussion/271683)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/m5-forecasting-accuracy?source=post_page-----5820ba7182fd--------------------------------)
    [## M5 Forecasting — Accuracy'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Estimate the unit sales of Walmart retail goods
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 估计沃尔玛零售商品的单位销售
- en: www.kaggle.com](https://www.kaggle.com/competitions/m5-forecasting-accuracy?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: www.kaggle.com](https://www.kaggle.com/competitions/m5-forecasting-accuracy?source=post_page-----5820ba7182fd--------------------------------)
- en: '[1st, LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163684)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第1名，LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163684)'
- en: '[2nd, LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/164599)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第2名，LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/164599)'
- en: '[3rd, Modified DeepAR](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/164374)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3名，修改版 DeepAR](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/164374)'
- en: '[4th, LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163216)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第4名，LightGBM](https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/163216)'
- en: '[](https://www.kaggle.com/competitions/m5-forecasting-uncertainty?source=post_page-----5820ba7182fd--------------------------------)
    [## M5 Forecasting — Uncertainty'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/competitions/m5-forecasting-uncertainty?source=post_page-----5820ba7182fd--------------------------------)
    [## M5 预测 — 不确定性'
- en: Estimate the uncertainty distribution of Walmart unit sales.
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 估计沃尔玛单位销售的不确定性分布。
- en: www.kaggle.com](https://www.kaggle.com/competitions/m5-forecasting-uncertainty?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: www.kaggle.com](https://www.kaggle.com/competitions/m5-forecasting-uncertainty?source=post_page-----5820ba7182fd--------------------------------)
- en: 'Skipped: solutions based on M5-accuracy.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 跳过：基于 M5 准确性的解决方案。
- en: '[](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Recruit Restaurant Visitor Forecasting'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Recruit 餐厅访客预测'
- en: Predict how many future visitors a restaurant will receive
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测餐厅未来将接待多少访客
- en: www.kaggle.com](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: www.kaggle.com](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting?source=post_page-----5820ba7182fd--------------------------------)
- en: '[7th, LightGBM](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting/discussion/49166)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第7名，LightGBM](https://www.kaggle.com/competitions/recruit-restaurant-visitor-forecasting/discussion/49166)'
- en: '[](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Corporación Favorita Grocery Sales Forecasting'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Corporación Favorita 超市销售预测'
- en: Can you accurately predict sales for a large grocery chain?
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你能准确预测大型超市链的销售吗？
- en: www.kaggle.com](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: www.kaggle.com](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting?source=post_page-----5820ba7182fd--------------------------------)
- en: '[1st, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第1名，包含 LightGBM 的集成方法](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582)'
- en: '[2nd, Wavenet](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47568)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第2名，Wavenet](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47568)'
- en: '[3rd, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47560)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3名，包含 LightGBM 的集成方法](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47560)'
- en: '[4th, Seq2Seq](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47529)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第4名，Seq2Seq](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47529)'
- en: '[5th, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47556)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5名，包含 LightGBM 的集成方法](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47556)'
- en: '[6th, Lightgbm](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47575)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第6名，Lightgbm](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47575)'
- en: '[8th, Ensemble including LightGBM](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47564)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第8名，包含 LightGBM 的集成方法](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47564)'
- en: '[](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Web Traffic Time Series Forecasting'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## 网络流量时间序列预测'
- en: Forecast future traffic to Wikipedia pages
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测维基百科页面的未来流量
- en: www.kaggle.com](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, Seq2Seq](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43795)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2nd, Ensemble including XGBoost](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/39370)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5th, Polynomial Regression](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43603)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6th, CNN](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/39370)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7th, Neural Nets](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43621)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8th, Kalman](https://www.kaggle.com/competitions/web-traffic-time-series-forecasting/discussion/43727)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/rossmann-store-sales?source=post_page-----5820ba7182fd--------------------------------)
    [## Rossmann Store Sales'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Forecast sales using store, promotion, and competitor data
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/rossmann-store-sales?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[1st, XGBoost](https://www.kaggle.com/competitions/rossmann-store-sales/discussion/18024)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3rd, Neural Nets](https://www.kaggle.com/competitions/rossmann-store-sales/discussion/17974)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/genentech-flu-forecasting?source=post_page-----5820ba7182fd--------------------------------)
    [## Flu Forecasting'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Predict when, where and how strong the flu will be
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/genentech-flu-forecasting?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: The discussion page does not load.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/competitions/ams-2014-solar-energy-prediction-contest/overview?source=post_page-----5820ba7182fd--------------------------------)
    [## AMS 2013–2014 Solar Energy Prediction Contest'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Forecast daily solar energy with an ensemble of weather models
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/competitions/ams-2014-solar-energy-prediction-contest/overview?source=post_page-----5820ba7182fd--------------------------------)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: No published solutions.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '*Enjoyed this article?* [*Checkout my other ones*](https://medium.com/@davide.burba)
    *and follow me for more!* [*Click here*](https://medium.com/@davide.burba/membership)
    *to read unlimited articles and support me at no additional cost for you*❤️'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
