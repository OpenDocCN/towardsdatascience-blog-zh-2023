- en: Easily Estimate Your OpenAI API Costs with Tiktoken
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Tiktoken 轻松估算你的 OpenAI API 成本
- en: 原文：[https://towardsdatascience.com/easily-estimate-your-openai-api-costs-with-tiktoken-c17caf6d015e](https://towardsdatascience.com/easily-estimate-your-openai-api-costs-with-tiktoken-c17caf6d015e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/easily-estimate-your-openai-api-costs-with-tiktoken-c17caf6d015e](https://towardsdatascience.com/easily-estimate-your-openai-api-costs-with-tiktoken-c17caf6d015e)
- en: Count your tokens and avoid going bankrupt from using the OpenAI API
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算你的令牌，避免因为使用 OpenAI API 而破产
- en: '[](https://medium.com/@iamleonie?source=post_page-----c17caf6d015e--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page-----c17caf6d015e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c17caf6d015e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c17caf6d015e--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page-----c17caf6d015e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iamleonie?source=post_page-----c17caf6d015e--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page-----c17caf6d015e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c17caf6d015e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c17caf6d015e--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page-----c17caf6d015e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c17caf6d015e--------------------------------)
    ·6 min read·Aug 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c17caf6d015e--------------------------------)
    ·6 分钟阅读·2023年8月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/286da1233aab3f57c2e2d49f77d8d96e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/286da1233aab3f57c2e2d49f77d8d96e.png)'
- en: Fresh tokens! $0.0015 per kilo!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 新鲜的令牌！每千个$0.0015！
- en: Many people I know are interested in playing with OpenAI’s large language models
    (LLMs). But hosting LLMs is expensive, and thus, inference services like OpenAI’s
    application programming interface (API) are not free. But entering your payment
    information without knowing what inferencing costs will add up to can be a little
    intimidating.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我认识的许多人对使用 OpenAI 的大型语言模型（LLMs）感兴趣。但托管 LLMs 是昂贵的，因此像 OpenAI 的应用程序编程接口（API）这样的推理服务并不是免费的。但在不了解推理成本总额的情况下输入付款信息可能会有些令人担忧。
- en: Usually, I like to include a little indicator of the API costs of a walkthrough
    of my articles, so my readers know what to expect and can get a feeling for inferencing
    costs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我喜欢在文章的操作指南中包含一个 API 成本的小提示，以便读者知道可以预期什么，并对推理成本有一个感受。
- en: This article introduces you to the `tiktoken` library I use to estimate inferencing
    costs for OpenAI foundation models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了我用来估算 OpenAI 基础模型推理成本的 `tiktoken` 库。
- en: What is tiktoken?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 tiktoken？
- en: '`tiktoken`is an open-source byte pair encoding (BPE) tokenizer developed by
    OpenAI that is used for tokenizing text in their LLMs. It allows developers to
    count how many tokens are in a text before making calls to the OpenAI endpoint.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '`tiktoken` 是一个由 OpenAI 开发的开源字节对编码（BPE）分词器，用于在其 LLMs 中对文本进行分词。它允许开发者在调用 OpenAI
    端点之前计算文本中有多少个令牌。'
- en: It thus helps with estimating the associated costs of using the OpenAI API because
    its costs are **billed in units of 1,000 tokens** according to the [OpenAI’s pricing
    page](https://openai.com/pricing) [1].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，它有助于估算使用 OpenAI API 相关的成本，因为其费用是根据 [OpenAI 的定价页面](https://openai.com/pricing)
    **按每 1,000 个令牌计费** [1]。
- en: '[](https://github.com/openai/tiktoken?source=post_page-----c17caf6d015e--------------------------------)
    [## GitHub — openai/tiktoken: tiktoken is a fast BPE tokeniser for use with OpenAI’s
    models.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/openai/tiktoken?source=post_page-----c17caf6d015e--------------------------------)
    [## GitHub — openai/tiktoken: tiktoken 是一个快速的 BPE 分词器，用于 OpenAI 的模型。'
- en: 'tiktoken is a fast BPE tokeniser for use with OpenAI’s models. — GitHub — openai/tiktoken:
    tiktoken is a fast BPE…'
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'tiktoken 是一个快速的 BPE 分词器，用于 OpenAI 的模型。 — GitHub — openai/tiktoken: tiktoken
    是一个快速的 BPE…'
- en: github.com](https://github.com/openai/tiktoken?source=post_page-----c17caf6d015e--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/openai/tiktoken?source=post_page-----c17caf6d015e--------------------------------)
- en: Tokens and Tokenization
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 令牌与分词
- en: '**Tokens** are common sequences of characters in a text, and **tokenization**
    is when you split a text string into a list of tokens. A token can be equal to
    a word but usually a word consists of multiple tokens.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**令牌** 是文本中常见的字符序列，**分词** 是将文本字符串拆分为令牌列表的过程。一个令牌可以等于一个词，但通常一个词由多个令牌组成。'
- en: Natural language processing (NLP) models are trained on tokens and understand
    the relationships between them. Thus, the input text is tokenized before an NLP
    model processes it.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）模型是通过 tokens 进行训练的，并理解它们之间的关系。因此，输入文本在 NLP 模型处理之前会进行分词。
- en: But how words are tokenized exactly depends on the used tokenizer.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但词语如何被分词，具体取决于使用的分词器。
- en: Below you can see an example of how the text
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以看到文本的一个示例
- en: “Alice has a parrot.
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “Alice 有一只鹦鹉。
- en: ''
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What animal is Alice’s pet?
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Alice 的宠物是什么动物？
- en: ''
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Alice’s pet is a parrot.”
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Alice 的宠物是一只鹦鹉。”
- en: can be tokenized.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可以进行分词。
- en: '![](../Images/359f5ca1e40f9c09b26964db2d24217c.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/359f5ca1e40f9c09b26964db2d24217c.png)'
- en: You can see that the text is split into chunks of characters, including spaces
    and punctuation, and even line breaks. Then each token is encoded as an integer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到文本被分成字符块，包括空格和标点符号，甚至换行符。然后每个 token 被编码为一个整数。
- en: 'While some shorter words are equivalent to one token, longer words, e.g., the
    word “parrot”, are separated into multiple tokens, as shown below:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些较短的词等于一个 token，但较长的词，例如“parrot”，会被分成多个 tokens，如下所示：
- en: '![](../Images/15e5eb17092e773a3cf7c6b8bdd780fc.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15e5eb17092e773a3cf7c6b8bdd780fc.png)'
- en: Depending on the tokenizer, the same word may not be encoded as the same token.
    E.g., in this example, the word Alice is once tokenized as “Alice” and once as
    “ Alice” (with a leading space), depending on where in the text this word appeared.
    Thus, the tokens “Alice” and “ Alice” (with a leading space) have different token
    identifiers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据分词器的不同，相同的词可能不会被编码为相同的 token。例如，在这个例子中，词 Alice 在文本中出现的位置不同时，会被一次分词为“Alice”，一次分词为“
    Alice”（带有前导空格）。因此，tokens “Alice” 和 “ Alice”（带有前导空格）具有不同的 token 标识符。
- en: '![](../Images/392cfbd72426e0c8ad030a03997b4fb2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/392cfbd72426e0c8ad030a03997b4fb2.png)'
- en: OpenAI uses a tokenization technique called byte pair encoding (BPE), which
    replaces the most frequent pairs of bytes in a text with a single byte and thus
    helps NLP models understand grammar better [4].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 使用一种称为字节对编码（BPE）的分词技术，该技术用一个单一的字节替换文本中最常见的字节对，从而帮助 NLP 模型更好地理解语法 [4]。
- en: E.g., “ing” is a frequent substring of characters in the English language. Thus,
    BPE will split words ending in “ing” as, e.g., “walking” into “walk” and “ing”.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，“ing” 是英语中一个常见的字符子串。因此，BPE 将以“ing”结尾的词，如“walking”，分词为“walk”和“ing”。
- en: On average, each token corresponds to about 4 bytes or 4 characters for common
    English text in BPE, which roughly translates to 100 tokens for 75 words [2, 4].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 平均来说，每个 token 对应于大约 4 字节或 4 个字符的常见英语文本，在 BPE 中，这大致相当于 75 个词对应 100 个 tokens [2,
    4]。
- en: 'For an in-depth explanation of BPE, I recommend this article:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 BPE 的详细解释，我推荐这篇文章：
- en: '[](/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0?source=post_page-----c17caf6d015e--------------------------------)
    [## Byte-Pair Encoding: Subword-based tokenization algorithm'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0?source=post_page-----c17caf6d015e--------------------------------)
    [## 字节对编码：基于子词的分词算法'
- en: Understand subword-based tokenization algorithm used by state-of-the-art NLP
    models — Byte-Pair Encoding (BPE)
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解前沿 NLP 模型使用的基于子词的分词算法——字节对编码（BPE）
- en: towardsdatascience.com](/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0?source=post_page-----c17caf6d015e--------------------------------)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0?source=post_page-----c17caf6d015e--------------------------------)
- en: How To Use tiktoken To Estimate OpenAI API Costs
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用 tiktoken 估算 OpenAI API 成本
- en: 'Estimating the OpenAI API costs with `tiktoken` consist of the following four
    simple steps, which we will discuss in detail:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `tiktoken` 估算 OpenAI API 成本包括以下四个简单步骤，我们将详细讨论：
- en: '[Installation and setup](#6216)'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[安装和设置](#6216)'
- en: '[Define encoding](#39cb)'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[定义编码](#39cb)'
- en: '[Tokenize text](#3fc9)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[分词文本](#3fc9)'
- en: '[Estimate OpenAI API costs](#8a89)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[估算 OpenAI API 成本](#8a89)'
- en: 'Step 1: Installation and setup'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：安装和设置
- en: 'First, you need to install `tiktoken` as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要按照以下步骤安装 `tiktoken`：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then you import the library:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你导入库：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step 2: Define encoding'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步：定义编码
- en: 'Next, you need to define which encoding to use for tokenization because OpenAI
    models use different encodings [3]:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要定义用于分词的编码，因为 OpenAI 模型使用不同的编码 [3]：
- en: '`cl100k_base`: for `gpt-4`, `gpt-3.5-turbo`, and `text-embedding-ada-002`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cl100k_base`：用于 `gpt-4`、`gpt-3.5-turbo` 和 `text-embedding-ada-002`'
- en: '`p50k_base`: for codex models, `text-davinci-002`, `text-davinci-003`'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p50k_base`：用于 codex 模型，`text-davinci-002`、`text-davinci-003`'
- en: '`gpt2` (or `r50k_base`): for GPT-3 models like `davinci`'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gpt2`（或 `r50k_base`）：用于 GPT-3 模型，如 `davinci`'
- en: 'If you know the encoding of your model, you can define the encoding as shown
    below:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你知道你的模型的编码方式，可以如下面所示定义编码：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alternatively, you can define the encoding according to the used model:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，你可以根据使用的模型定义编码方式：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Step 3: Tokenize the text'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步：对文本进行分词
- en: Finally, you can tokenize any body of text with the `.encode()` method, which
    will return a list of integers that represent the tokens.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以使用`.encode()`方法对任何文本进行分词，这将返回一个表示令牌的整数列表。
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Step 4: Estimate OpenAI API costs'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四步：估算OpenAI API费用
- en: To estimate the OpenAI API costs, you can now count the number of tokens in
    your text and estimate the associated costs of the inferencing service according
    to the model you are using.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要估算OpenAI API的费用，你现在可以计算文本中的令牌数量，并根据你使用的模型估算推断服务的相关费用。
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you are using an **embedding model**, you are only charged for the number
    of tokens of the input text to embed. E.g., `text-embedding-ada-002` cost $0.0001
    for 1,000 tokens at the time of writing [1].
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是**嵌入模型**，你仅为要嵌入的输入文本的令牌数量付费。例如，`text-embedding-ada-002`在写作时的费用为每1,000个令牌$0.0001
    [1]。
- en: '![](../Images/626974f1844ef6d37e9b5348d37ac295.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/626974f1844ef6d37e9b5348d37ac295.png)'
- en: But note, if you are using a **conversational model**, you are charged both
    for the number of input tokens (number of tokens of your prompt) as well as for
    the number of output tokens (number of tokens of the returned completion). E.g.,
    the `gpt-3.5-turbo` (4K context) model costs $0.0015 for 1,000 input tokens and
    $0.002 for 1,000 output tokens at the time of writing [1].
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 但请注意，如果你使用的是**对话模型**，你将为输入令牌的数量（你的提示中的令牌数量）以及输出令牌的数量（返回的完成中的令牌数量）收费。例如，`gpt-3.5-turbo`（4K上下文）模型在写作时的费用为每1,000个输入令牌$0.0015，每1,000个输出令牌$0.002
    [1]。
- en: '![](../Images/382101a4f1e6f8778dbdbc1960c3f56d.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/382101a4f1e6f8778dbdbc1960c3f56d.png)'
- en: That’s why you need to control the number of output tokens in addition to managing
    the length of your input text to avoid unexpected costs. You can control the number
    of output tokens via the optional but highly recommended `max_tokens` parameter.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么你需要控制输出令牌的数量，除了管理输入文本的长度，以避免意外的费用。你可以通过可选但强烈推荐的`max_tokens`参数来控制输出令牌的数量。
- en: 'Optional step: Decode tokens'
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可选步骤：解码令牌
- en: 'Another advantage of BPE is that it is reversible. If you want to decode a
    list of tokens, you can use the `.decode_sigle_token_bytes()` method shown below:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: BPE 的另一个优点是它是可逆的。如果你想解码一个令牌列表，可以使用下面显示的`.decode_sigle_token_bytes()`方法：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Summary
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This article showed how you can easily calculate the number of tokens in your
    input text (text to embed or prompt) with the `tiktoken` library before calling
    the OpenAI API endpoint. By including this step in your coding practice, you will
    get a feeling for the resulting API costs. Additionally, we discussed that you
    should also use the `max_tokens` parameter when using an LLM that will output
    a completion to avoid unexpected costs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章展示了如何使用`tiktoken`库轻松计算输入文本（要嵌入或提示）的令牌数量，然后再调用OpenAI API端点。通过将此步骤纳入你的编码实践中，你将对API费用有一个感性认识。此外，我们讨论了在使用会输出完成的LLM时，你还应该使用`max_tokens`参数，以避免意外费用。
- en: Enjoyed This Story?
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 喜欢这个故事吗？
- en: '[*Subscribe for free*](https://medium.com/subscribe/@iamleonie) *to get notified
    when I publish a new story.*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[*免费订阅*](https://medium.com/subscribe/@iamleonie) *以便在我发布新故事时获得通知。*'
- en: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----c17caf6d015e--------------------------------)
    [## Get an email whenever Leonie Monigatti publishes.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----c17caf6d015e--------------------------------)
    [## 每当Leonie Monigatti发布新内容时获得邮件提醒。'
- en: Get an email whenever Leonie Monigatti publishes. By signing up, you will create
    a Medium account if you don’t already…
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每当Leonie Monigatti发布新内容时，你会收到一封邮件。通过注册，你将创建一个Medium账户（如果你还没有的话）…
- en: medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----c17caf6d015e--------------------------------)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----c17caf6d015e--------------------------------)'
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/804250ab/),[*Twitter*](https://twitter.com/helloiamleonie)*,
    and* [*Kaggle*](https://www.kaggle.com/iamleonie)*!*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/804250ab/)、[*Twitter*](https://twitter.com/helloiamleonie)
    *和* [*Kaggle*](https://www.kaggle.com/iamleonie) *上找到我！*'
- en: References
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Image References
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图片参考
- en: If not otherwise stated, all images are created by the author.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有另行说明，所有图片均由作者创建。
- en: Web & Literature
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络与文献
- en: '[1] OpenAI (2023). [Pricing](https://openai.com/pricing) (accessed July 31st,
    2023)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] OpenAI（2023）。[定价](https://openai.com/pricing)（访问日期：2023年7月31日）'
- en: '[2] OpenAI (2023). [Tokenizer](https://platform.openai.com/tokenizer) (accessed
    July 31st, 2023)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] OpenAI (2023)。 [Tokenizer](https://platform.openai.com/tokenizer)（访问于 2023
    年 7 月 31 日）'
- en: '[3] OpenAI on GitHub(2023). [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
    (accessed July 31st, 2023)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] OpenAI 在 GitHub(2023)。 [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)（访问于
    2023 年 7 月 31 日）'
- en: '[4] OpenAI on GitHub(2023). [tiktoken](https://github.com/openai/tiktoken)
    (accessed July 31st, 2023)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] OpenAI 在 GitHub(2023)。 [tiktoken](https://github.com/openai/tiktoken)（访问于
    2023 年 7 月 31 日）'
