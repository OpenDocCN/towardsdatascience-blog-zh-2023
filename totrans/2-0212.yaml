- en: A Performant Recommender System Without Cold Start Problem
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å†·å¯åŠ¨é—®é¢˜çš„é«˜æ•ˆæ¨èç³»ç»Ÿ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b](https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b](https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b)
- en: '[Recommendation System](https://medium.com/tag/recommendation-system)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[æ¨èç³»ç»Ÿ](https://medium.com/tag/recommendation-system)'
- en: When collaboration and content-based recommenders merge
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å½“ååŒè¿‡æ»¤å’ŒåŸºäºå†…å®¹çš„æ¨èç³»ç»Ÿåˆå¹¶æ—¶
- en: '[](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Dr.
    Robert KÃ¼bler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    [Dr. Robert KÃ¼bler](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Dr.
    Robert KÃ¼bler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    [Dr. Robert KÃ¼bler](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    Â·11 min readÂ·Jan 31, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    Â·é˜…è¯»æ—¶é—´11åˆ†é’ŸÂ·2023å¹´1æœˆ31æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c0e674a93dd06ef0ac51647be57bbd22.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0e674a93dd06ef0ac51647be57bbd22.png)'
- en: Photo by [Ivan Aleksic](https://unsplash.com/@ivalex?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Ivan Aleksic](https://unsplash.com/@ivalex?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Perhaps the most famous recommender system is the so-called **matrix factorization**.
    In this **collaborative** recommender, users and items are represented with an
    **embedding**, which is nothing more but a vector of numbers. The intuition is
    that the dot product of the user and the item embedding should result in the rating
    that the user would give this item.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸æœ€è‘—åçš„æ¨èç³»ç»Ÿæ˜¯æ‰€è°“çš„**çŸ©é˜µåˆ†è§£**ã€‚åœ¨è¿™ç§**ååŒè¿‡æ»¤**æ¨èç³»ç»Ÿä¸­ï¼Œç”¨æˆ·å’Œé¡¹ç›®éƒ½é€šè¿‡**åµŒå…¥**è¡¨ç¤ºï¼Œè¿™ä¸è¿‡æ˜¯ä¸€ä¸ªæ•°å­—å‘é‡ã€‚ç›´è§‚çš„ç†è§£æ˜¯ï¼Œç”¨æˆ·å’Œé¡¹ç›®åµŒå…¥çš„ç‚¹ç§¯åº”ç­‰äºç”¨æˆ·å¯¹è¯¥é¡¹ç›®çš„è¯„åˆ†ã€‚
- en: If you are not yet familiar with these concepts, I recommend (ğŸ˜‰) reading my
    other article before you proceed since I explain many concepts and code snippets
    there.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹è¿™äº›æ¦‚å¿µè¿˜ä¸ç†Ÿæ‚‰ï¼Œæˆ‘å»ºè®®ï¼ˆğŸ˜‰ï¼‰åœ¨ç»§ç»­ä¹‹å‰é˜…è¯»æˆ‘çš„å¦ä¸€ç¯‡æ–‡ç« ï¼Œå› ä¸ºæˆ‘åœ¨å…¶ä¸­è§£é‡Šäº†è®¸å¤šæ¦‚å¿µå’Œä»£ç ç‰‡æ®µã€‚
- en: '[](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## Introduction to Embedding-Based Recommender Systems'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## åµŒå…¥å¼æ¨èç³»ç»Ÿç®€ä»‹'
- en: Learn to build a simple recommender in TensorFlow
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å­¦ä¹ å¦‚ä½•åœ¨ TensorFlow ä¸­æ„å»ºä¸€ä¸ªç®€å•çš„æ¨èç³»ç»Ÿ
- en: towardsdatascience.com](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
- en: The Cold Start Problem
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å†·å¯åŠ¨é—®é¢˜
- en: Purely collaborative recommender systems such as matrix factorization have the
    advantage that you can usually immediately build them even without having too
    much data about your users and movies/articles/items you want to recommend. You
    only have to know who rated what and how; for example, user *B* gave movie *Y*
    a rating of 2 stars.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: çº¯ç²¹çš„ååŒè¿‡æ»¤æ¨èç³»ç»Ÿï¼Œå¦‚çŸ©é˜µåˆ†è§£ï¼Œæœ‰ä¸€ä¸ªä¼˜ç‚¹ï¼Œå³ä½¿æ²¡æœ‰å¤ªå¤šå…³äºç”¨æˆ·å’Œä½ æƒ³æ¨èçš„ç”µå½±/æ–‡ç« /é¡¹ç›®çš„æ•°æ®ï¼Œä½ ä¹Ÿé€šå¸¸å¯ä»¥ç«‹å³æ„å»ºå®ƒä»¬ã€‚ä½ åªéœ€è¦çŸ¥é“è°å¯¹ä»€ä¹ˆè¿›è¡Œäº†è¯„åˆ†ä»¥åŠè¯„åˆ†æƒ…å†µï¼›ä¾‹å¦‚ï¼Œç”¨æˆ·*B*å¯¹ç”µå½±*Y*çš„è¯„åˆ†ä¸º2æ˜Ÿã€‚
- en: '![](../Images/1445f7bebc146490dd07c4960680fa87.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1445f7bebc146490dd07c4960680fa87.png)'
- en: Image by the author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡ã€‚
- en: However, they fall short when you have **new** **users or items** that you want
    to make predictions for since the model had no possibility of learning anything
    for them, leaving you with basically random recommendations for them â€” the dreaded
    **cold start problem**. Let us assume that another user *E* registers, and we
    also add a new movie *W* to the database.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå½“ä½ æœ‰**æ–°**çš„**ç”¨æˆ·æˆ–é¡¹ç›®**æ—¶ï¼Œå®ƒä»¬å°±ä¸å¤Ÿç”¨äº†ï¼Œå› ä¸ºæ¨¡å‹æ²¡æœ‰æœºä¼šå­¦ä¹ è¿™äº›å†…å®¹ï¼Œä»è€ŒåŸºæœ¬ä¸Šä¸ºè¿™äº›ç”¨æˆ·æˆ–é¡¹ç›®æä¾›äº†éšæœºæ¨èâ€”â€”è¿™å°±æ˜¯ä»¤äººå¤´ç–¼çš„**å†·å¯åŠ¨é—®é¢˜**ã€‚å‡è®¾å¦ä¸€ä¸ªç”¨æˆ·*E*æ³¨å†Œäº†ï¼Œæˆ‘ä»¬è¿˜åœ¨æ•°æ®åº“ä¸­æ·»åŠ äº†ä¸€ä¸ªæ–°ç”µå½±*W*ã€‚
- en: '![](../Images/75385b2e5f953f3aa8c5b5e144ba238e.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75385b2e5f953f3aa8c5b5e144ba238e.png)'
- en: Image by the author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: In this article, I will show you a simple way to mitigate the cold start problem
    by incorporating more features about the users and items â€” this is the **content-based**
    component we will bake into our model. Using actual content data, such as user
    age or a movie genre, produces models that can deal with new users or movies in
    a better way.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å±•ç¤ºä¸€ç§é€šè¿‡ç»“åˆæ›´å¤šå…³äºç”¨æˆ·å’Œé¡¹ç›®çš„ç‰¹å¾æ¥ç¼“è§£å†·å¯åŠ¨é—®é¢˜çš„ç®€å•æ–¹æ³•â€”â€”è¿™å°±æ˜¯æˆ‘ä»¬å°†åŠ å…¥åˆ°æ¨¡å‹ä¸­çš„**åŸºäºå†…å®¹çš„**ç»„ä»¶ã€‚ä½¿ç”¨å®é™…å†…å®¹æ•°æ®ï¼Œå¦‚ç”¨æˆ·å¹´é¾„æˆ–ç”µå½±ç±»å‹ï¼Œç”Ÿæˆçš„æ¨¡å‹èƒ½æ›´å¥½åœ°å¤„ç†æ–°ç”¨æˆ·æˆ–æ–°ç”µå½±ã€‚
- en: Back to MovieLens
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å›åˆ° MovieLens
- en: As in my last article, I will use the [MovieLens](https://movielens.org/) dataset
    that provides us with user-movie ratings. Furthermore, it even contains some more
    user and movie features, and while we ignored these in the last article, we will
    use them today to build an even better model!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œæˆ‘ä¸Šä¸€ç¯‡æ–‡ç« ä¸€æ ·ï¼Œæˆ‘å°†ä½¿ç”¨ [MovieLens](https://movielens.org/) æ•°æ®é›†ï¼Œå®ƒæä¾›äº†ç”¨æˆ·-ç”µå½±è¯„åˆ†ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜åŒ…å«äº†ä¸€äº›ç”¨æˆ·å’Œç”µå½±ç‰¹å¾ï¼Œå°½ç®¡æˆ‘ä»¬åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­å¿½ç•¥äº†è¿™äº›ç‰¹å¾ï¼Œä½†ä»Šå¤©æˆ‘ä»¬å°†åˆ©ç”¨è¿™äº›ç‰¹å¾æ¥æ„å»ºæ›´å¥½çš„æ¨¡å‹ï¼
- en: '*You can find the code on* [*my Github*](https://github.com/Garve/Towards-Data-Science---Notebooks/blob/main/TDS%20-%20A%20Performant%20Recommender%20System%20Without%20Cold%20Start%C2%A0Problem.ipynb)*.*'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ä½ å¯ä»¥åœ¨* [*æˆ‘çš„ Github*](https://github.com/Garve/Towards-Data-Science---Notebooks/blob/main/TDS%20-%20A%20Performant%20Recommender%20System%20Without%20Cold%20Start%C2%A0Problem.ipynb)*æ‰¾åˆ°ä»£ç *ã€‚'
- en: Following the last article let us
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è·Ÿéšä¸Šä¸€ç¯‡æ–‡ç« è®©æˆ‘ä»¬
- en: grab the data using tensorflow-datasets
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ tensorflow-datasets è·å–æ•°æ®
- en: make a dataframe out of it and change some column types, and
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å…¶åˆ¶ä½œæˆæ•°æ®æ¡†å¹¶æ›´æ”¹ä¸€äº›åˆ—ç±»å‹ï¼Œç„¶å
- en: sort it according to the time to conduct a temporal train-test split
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‰æ—¶é—´æ’åºä»¥è¿›è¡Œæ—¶é—´ä¸Šçš„è®­ç»ƒ-æµ‹è¯•åˆ†å‰²
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `filtered_data` dataframe
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`filtered_data` æ•°æ®æ¡†'
- en: '![](../Images/b1d25ca050a152a9e1bba81fdee26380.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1d25ca050a152a9e1bba81fdee26380.png)'
- en: Image by the author.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: tells us that besides **user_id, movie_id** and the target **user_rating** we
    have the **user features**
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å‘Šè¯‰æˆ‘ä»¬é™¤äº†**user_idã€movie_id**å’Œç›®æ ‡**user_rating**ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜æœ‰**ç”¨æˆ·ç‰¹å¾**
- en: bucketized_user_age
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: bucketized_user_age
- en: user_gender
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_gender
- en: user_occupation_label
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_occupation_label
- en: user_occupation_text
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_occupation_text
- en: user_zip_code
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_zip_code
- en: and the **movie features**
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠ**ç”µå½±ç‰¹å¾**
- en: movie_genres
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: movie_genres
- en: movie_title
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: movie_title
- en: 'Using some stereotypes:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¸€äº›åˆ»æ¿å°è±¡ï¼š
- en: Intuitively, these features should help a lot since a model could learn things
    like â€œWomen like dramasâ€ or â€œYoung people dislike old moviesâ€.
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä»ç›´è§‚ä¸Šçœ‹ï¼Œè¿™äº›ç‰¹å¾åº”è¯¥éå¸¸æœ‰å¸®åŠ©ï¼Œå› ä¸ºæ¨¡å‹å¯ä»¥å­¦ä¹ â€œå¥³æ€§å–œæ¬¢æˆå‰§â€æˆ–â€œå¹´è½»äººä¸å–œæ¬¢è€ç”µå½±â€ä¹‹ç±»çš„å†…å®¹ã€‚
- en: We will now find out how to use all of these additional features via a simple
    network architecture called **LightFM**. The name was chosen by [Maciej Kula](https://www.linkedin.com/in/maciej-kula-57283147/)
    in his well-written paper **Metadata Embeddings for User and Item Cold-start Recommendations**
    [1]. Please give it a read!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å°†äº†è§£å¦‚ä½•é€šè¿‡ä¸€ä¸ªç®€å•çš„ç½‘ç»œæ¶æ„**LightFM**æ¥ä½¿ç”¨æ‰€æœ‰è¿™äº›é¢å¤–ç‰¹å¾ã€‚è¿™ä¸ªåå­—æ˜¯ç”± [Maciej Kula](https://www.linkedin.com/in/maciej-kula-57283147/)
    åœ¨ä»–å†™å¾—å¾ˆå¥½çš„è®ºæ–‡ **Metadata Embeddings for User and Item Cold-start Recommendations**
    [1] ä¸­é€‰æ‹©çš„ã€‚è¯·é˜…è¯»ä¸€ä¸‹ï¼
- en: LightFM is a hybrid of a collaborative as well as a content-based recommender
    since it uses ratings as well as user and item features.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LightFM æ˜¯ä¸€ç§æ··åˆå‹æ¨èç³»ç»Ÿï¼Œå› ä¸ºå®ƒä½¿ç”¨è¯„åˆ†ä»¥åŠç”¨æˆ·å’Œé¡¹ç›®ç‰¹å¾ã€‚
- en: The Simple Idea of LightFM
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LightFM çš„ç®€å•æƒ³æ³•
- en: Let us first recap what our simple matrix factorization looked like, omitting
    biases. In our old recommender, we used the **user_id** and **movie_id**, embedded
    both, and computed the dot product to calculate the rating.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é¦–å…ˆå›é¡¾ä¸€ä¸‹æˆ‘ä»¬ç®€å•çš„çŸ©é˜µåˆ†è§£æ˜¯æ€æ ·çš„ï¼Œçœç•¥åå·®ã€‚åœ¨æˆ‘ä»¬æ—§çš„æ¨èç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†**user_id**å’Œ**movie_id**ï¼Œå°†ä¸¤è€…è¿›è¡ŒåµŒå…¥ï¼Œç„¶åè®¡ç®—ç‚¹ç§¯æ¥è®¡ç®—è¯„åˆ†ã€‚
- en: '![](../Images/8e6ee1d11d43d46b20f23f4f6241ff41.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e6ee1d11d43d46b20f23f4f6241ff41.png)'
- en: Matrix factorization architecture, image by the author.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ©é˜µåˆ†è§£æ¶æ„ï¼Œå›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: 'For **LightFM**, it works like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº**LightFM**ï¼Œå®ƒæ˜¯è¿™æ ·å·¥ä½œçš„ï¼š
- en: We **embed all the features** that we have, user and movie features.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬**åµŒå…¥æ‰€æœ‰ç‰¹å¾**ï¼ŒåŒ…æ‹¬ç”¨æˆ·ç‰¹å¾å’Œç”µå½±ç‰¹å¾ã€‚
- en: The user (movie) embedding is the **sum of all these user (movie) feature embeddings**.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨æˆ·ï¼ˆç”µå½±ï¼‰åµŒå…¥æ˜¯**æ‰€æœ‰è¿™äº›ç”¨æˆ·ï¼ˆç”µå½±ï¼‰ç‰¹æ€§åµŒå…¥çš„æ€»å’Œ**ã€‚
- en: 'Thatâ€™s it already! For some subset of features, the network architecture could
    look like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼å¯¹äºæŸäº›ç‰¹å®šçš„ç‰¹æ€§ï¼Œç½‘ç»œæ¶æ„å¯èƒ½çœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: '![](../Images/1026153ed5733b5d7693965251cdd499.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1026153ed5733b5d7693965251cdd499.png)'
- en: LightFM architecture, image by the author.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: LightFM æ¶æ„ï¼Œå›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: Advantages
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼˜åŠ¿
- en: The good thing about this approach is that even if you get a new user or movie
    into the database, you can create meaningful embeddings as long as you know their
    features (*contents*). You will not know the embeddings for the IDs â€” the main
    problem in the matrix factorization approach â€” but we hope that the other embeddings
    make up for it. In a cold start setting, **user_id** or **movie_id** are unknown,
    but we can still give them some default embedding.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹æ³•çš„å¥½å¤„æ˜¯ï¼Œå³ä½¿ä½ å°†æ–°ç”¨æˆ·æˆ–ç”µå½±æ·»åŠ åˆ°æ•°æ®åº“ä¸­ï¼Œåªè¦çŸ¥é“å®ƒä»¬çš„ç‰¹æ€§ï¼ˆ*å†…å®¹*ï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥åˆ›å»ºæœ‰æ„ä¹‰çš„åµŒå…¥ã€‚ä½ ä¸ä¼šçŸ¥é“ ID çš„åµŒå…¥â€”â€”è¿™æ˜¯çŸ©é˜µåˆ†è§£æ–¹æ³•ä¸­çš„ä¸»è¦é—®é¢˜â€”â€”ä½†æˆ‘ä»¬å¸Œæœ›å…¶ä»–åµŒå…¥å¯ä»¥å¼¥è¡¥è¿™ä¸€ç‚¹ã€‚åœ¨å†·å¯åŠ¨è®¾ç½®ä¸­ï¼Œ**user_id**
    æˆ– **movie_id** æ˜¯æœªçŸ¥çš„ï¼Œä½†æˆ‘ä»¬ä»ç„¶å¯ä»¥ç»™å®ƒä»¬ä¸€äº›é»˜è®¤çš„åµŒå…¥ã€‚
- en: Implementation in TensorFlow
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨ TensorFlow ä¸­çš„å®ç°
- en: With only the two IDs as input, it is sufficient to explicitly type out an input,
    encoding, embedding, and bias. However, for our number of features, it makes sense
    to define some config first and then use loops.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä»…ç”¨ä¸¤ä¸ª ID ä½œä¸ºè¾“å…¥ï¼Œæ˜ç¡®æŒ‡å®šè¾“å…¥ã€ç¼–ç ã€åµŒå…¥å’Œåå·®å°±è¶³å¤Ÿäº†ã€‚ç„¶è€Œï¼Œå¯¹äºæˆ‘ä»¬çš„ç‰¹æ€§æ•°é‡ï¼Œå…ˆå®šä¹‰ä¸€äº›é…ç½®ç„¶åä½¿ç”¨å¾ªç¯æ˜¯æœ‰æ„ä¹‰çš„ã€‚
- en: '***Note:*** *We will omit* ***movie_title*** *and* ***movie_genres*** *since
    we have to treat them differently than the rest. However, I will tell you things
    you can do to incorporate these features as well.*'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***æ³¨æ„ï¼š*** *æˆ‘ä»¬å°†çœç•¥* ***movie_title*** *å’Œ* ***movie_genres*** *ï¼Œå› ä¸ºæˆ‘ä»¬å¿…é¡»ä»¥ä¸åŒäºå…¶ä»–ç‰¹æ€§çš„æ–¹å¼å¤„ç†å®ƒä»¬ã€‚ç„¶è€Œï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ å¦‚ä½•å°†è¿™äº›ç‰¹æ€§ä¹Ÿçº³å…¥å…¶ä¸­ã€‚*'
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We now have an extensive configuration dictionary that tells us about each feature
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨æœ‰ä¸€ä¸ªè¯¦ç»†çš„é…ç½®å­—å…¸ï¼Œå®ƒå‘Šè¯‰æˆ‘ä»¬æ¯ä¸ªç‰¹æ€§çš„ä¿¡æ¯ã€‚
- en: which input *dtype* the input layer needs,
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾“å…¥å±‚éœ€è¦çš„*dtype*ï¼Œ
- en: if the features belong to the movie or user features,
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹æ€§æ˜¯å¦å±äºç”µå½±æˆ–ç”¨æˆ·ç‰¹æ€§ï¼Œ
- en: which lookup layer is needed, i.e. `IntegerLookup` for integer features and
    `StringLookup` for string features,
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éœ€è¦å“ªä¸ªæŸ¥æ‰¾å±‚ï¼Œå³`IntegerLookup`ç”¨äºæ•´æ•°ç‰¹æ€§ï¼Œ`StringLookup`ç”¨äºå­—ç¬¦ä¸²ç‰¹æ€§ï¼Œ
- en: and the vocabulary, i.e., the unique classes per feature.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥åŠè¯æ±‡è¡¨ï¼Œå³æ¯ä¸ªç‰¹æ€§çš„å”¯ä¸€ç±»ã€‚
- en: 'Then, we can define a TensorFlow model that does what we have seen in the LightFM
    architecture image:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ª TensorFlow æ¨¡å‹æ¥å®ç°æˆ‘ä»¬åœ¨ LightFM æ¶æ„å›¾ä¸­çœ‹åˆ°çš„å†…å®¹ï¼š
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I know this is quite hefty. But there should be no big surprises if you also
    read my other article about embedding-based recommenders. We are ready to train
    the model!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çŸ¥é“è¿™å¾ˆç¹é‡ã€‚ä½†å¦‚æœä½ ä¹Ÿé˜…è¯»äº†æˆ‘å…³äºåŸºäºåµŒå…¥çš„æ¨èç³»ç»Ÿçš„å…¶ä»–æ–‡ç« ï¼Œåº”è¯¥æ²¡æœ‰å¤§æƒŠå°æ€ªçš„åœ°æ–¹ã€‚æˆ‘ä»¬å‡†å¤‡å¥½è®­ç»ƒæ¨¡å‹äº†ï¼
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The performance on the test set:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æµ‹è¯•é›†ä¸Šçš„è¡¨ç°ï¼š
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can also try out the matrix factorization in this setting; you only have
    to change the `features_config` dictionary to
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥å°è¯•åœ¨è¿™ç§è®¾ç½®ä¸­è¿›è¡ŒçŸ©é˜µåˆ†è§£ï¼›ä½ åªéœ€å°†`features_config`å­—å…¸æ›´æ”¹ä¸º
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: by deleting some rows and then executing the rest of the code. The results,
    in this case, are a test MSE of 1.322 and an MAE of 0.953, which is much worse
    than the LightFM results. This looks great!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ é™¤ä¸€äº›è¡Œï¼Œç„¶åæ‰§è¡Œå‰©ä½™çš„ä»£ç ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç»“æœæ˜¯æµ‹è¯• MSE ä¸º 1.322 å’Œ MAE ä¸º 0.953ï¼Œè¿™æ¯” LightFM ç»“æœå·®å¾—å¤šã€‚è¿™çœ‹èµ·æ¥å¾ˆæ£’ï¼
- en: Dealing With The Movie Genre
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤„ç†ç”µå½±ç±»å‹
- en: So far, we have ignored the perhaps extremely informative column **movie_genres**
    because it is a bit harder to handle than the categorical variables since here
    we have a list of integers instead of just one integer. So, we have to make up
    some logic to deal with this.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¿½ç•¥äº†å¯èƒ½æå…·ä¿¡æ¯é‡çš„åˆ—**movie_genres**ï¼Œå› ä¸ºå®ƒæ¯”åˆ†ç±»å˜é‡æ›´éš¾å¤„ç†ï¼Œå› ä¸ºè¿™é‡Œæˆ‘ä»¬æœ‰ä¸€ä¸ªæ•´æ•°åˆ—è¡¨è€Œä¸æ˜¯å•ä¸ªæ•´æ•°ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å¿…é¡»åˆ¶å®šä¸€äº›é€»è¾‘æ¥å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚
- en: '![](../Images/c13e6726a3bb9b84eab7d7aa1cf3504c.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c13e6726a3bb9b84eab7d7aa1cf3504c.png)'
- en: Image by the author.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: The easiest thing to do with this is to make an embedding for each genre and
    then take the mean of them. You can use the `GlobalAveragePooling1D` layer for
    this.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†è¿™ä¸ªæœ€ç®€å•çš„æ–¹æ³•æ˜¯ä¸ºæ¯ä¸ªç±»å‹åˆ›å»ºä¸€ä¸ªåµŒå…¥ï¼Œç„¶åå–å®ƒä»¬çš„å‡å€¼ã€‚ä½ å¯ä»¥ä½¿ç”¨`GlobalAveragePooling1D`å±‚æ¥å®ç°è¿™ä¸€ç‚¹ã€‚
- en: 'In order to realize this idea in code, do the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åœ¨ä»£ç ä¸­å®ç°è¿™ä¸ªæƒ³æ³•ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The rest stays the same. You only have to add the feature **movie_genres** to
    the model during fit, evaluation, and testing as well. The shape of the genres
    is a bit difficult since the lists donâ€™t have the same length, so TensorFlow has
    trouble turning this into a regular tensor. Luckily, TensorFlow still got us covered
    by providing **ragged tensors** via `tf.ragged.constant` that can handle these
    variable-size tensors.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä½™éƒ¨åˆ†ä¿æŒä¸å˜ã€‚åœ¨æ‹Ÿåˆã€è¯„ä¼°å’Œæµ‹è¯•æ¨¡å‹æ—¶ï¼Œä½ åªéœ€å°†ç‰¹å¾**movie_genres**æ·»åŠ åˆ°æ¨¡å‹ä¸­ã€‚ç”±äºç±»å‹çš„å½¢çŠ¶æœ‰ç‚¹å›°éš¾ï¼Œå› ä¸ºåˆ—è¡¨çš„é•¿åº¦ä¸åŒï¼Œæ‰€ä»¥TensorFlowåœ¨å°†å…¶è½¬æ¢ä¸ºå¸¸è§„å¼ é‡æ—¶é‡åˆ°é—®é¢˜ã€‚å¹¸è¿çš„æ˜¯ï¼ŒTensorFlowé€šè¿‡æä¾›**ragged
    tensors**ï¼ˆé€šè¿‡`tf.ragged.constant`ï¼‰æ¥å¤„ç†è¿™äº›å¯å˜å¤§å°çš„å¼ é‡ã€‚
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Fitting and evaluating the model on the test set shows yet another improvement,
    although smaller than expected. The MSE is about 1.0, and MAE is about 0.807.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æµ‹è¯•é›†ä¸Šæ‹Ÿåˆå’Œè¯„ä¼°æ¨¡å‹æ˜¾ç¤ºäº†å¦ä¸€ä¸ªæ”¹è¿›ï¼Œå°½ç®¡å°äºé¢„æœŸã€‚MSEçº¦ä¸º1.0ï¼ŒMAEçº¦ä¸º0.807ã€‚
- en: '![](../Images/60f1b2ab0d69716a5356a9344c469ac5.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60f1b2ab0d69716a5356a9344c469ac5.png)'
- en: All of my results combined. Image by the author.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰ç»“æœçš„ç»¼åˆã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: Dealing with the Movie Title
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤„ç†ç”µå½±æ ‡é¢˜
- en: Another interesting feature we have ignored so far since it contains information
    about the movie franchise. With this information, we could make it easy for the
    model to learn that some users like all the Batman movies a lot, for example.
    *Coding this is homework for you, though.* One way to do this is to split the
    title strings into a list of words and then proceed as we did with the genres.
    You can even use sentence encoders, transformer-like architecture, LSTMs, or anything
    else to turn a text into an embedding.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæœ‰è¶£çš„ç‰¹å¾æ˜¯æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢å¿½ç•¥çš„ï¼Œå› ä¸ºå®ƒåŒ…å«å…³äºç”µå½±ç³»åˆ—çš„ä¿¡æ¯ã€‚æœ‰äº†è¿™äº›ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿æ¨¡å‹æ›´å®¹æ˜“å­¦ä¹ ä¸€äº›ç”¨æˆ·éå¸¸å–œæ¬¢æ‰€æœ‰çš„è™è ä¾ ç”µå½±ã€‚ä¾‹å¦‚ï¼Œ*ç¼–ç è¿™ä¸ªæ˜¯ä½ çš„ä½œä¸š*ã€‚ä¸€ç§æ–¹æ³•æ˜¯å°†æ ‡é¢˜å­—ç¬¦ä¸²åˆ†å‰²æˆå•è¯åˆ—è¡¨ï¼Œç„¶åæŒ‰ç…§æˆ‘ä»¬å¯¹å¾…ç±»å‹çš„æ–¹æ³•è¿›è¡Œå¤„ç†ã€‚ä½ ç”šè‡³å¯ä»¥ä½¿ç”¨å¥å­ç¼–ç å™¨ã€ç±»ä¼¼å˜æ¢å™¨çš„æ¶æ„ã€LSTMæˆ–å…¶ä»–ä»»ä½•æ–¹æ³•å°†æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥ã€‚
- en: Making Predictions
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿›è¡Œé¢„æµ‹
- en: 'You can make a prediction by providing all the necessary features like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥é€šè¿‡æä¾›æ‰€æœ‰å¿…è¦çš„ç‰¹å¾æ¥è¿›è¡Œé¢„æµ‹ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, you can see that some unknown user who is young, has gender 0, occupation
    label 12, living in the 65712 zip code area, and is a writer would probably like
    the movie with id 1 that belongs to the genres 1, 2, and 3.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥çœ‹åˆ°ä¸€ä¸ªå¹´è½»çš„æœªçŸ¥ç”¨æˆ·ï¼Œè¯¥ç”¨æˆ·æ€§åˆ«ä¸º0ï¼ŒèŒä¸šæ ‡ç­¾ä¸º12ï¼Œå±…ä½åœ¨65712é‚®æ”¿ç¼–ç åŒºåŸŸï¼Œä¸”æ˜¯ä¸€åä½œå®¶ï¼Œä»–å¯èƒ½ä¼šå–œæ¬¢IDä¸º1çš„ç”µå½±ï¼Œè¯¥ç”µå½±å±äº1ã€2å’Œ3è¿™äº›ç±»å‹ã€‚
- en: More Interesting Insights From The Paper
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¥è‡ªè®ºæ–‡çš„æ›´å¤šæœ‰è¶£è§è§£
- en: My small experiment showed that LightFM could increase the model performance,
    as also stated in [1]. This is great, although something you might have expected
    already since **LightFM is a generalized version of matrix factorization**.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„ä¸€ä¸ªå°å®éªŒè¡¨æ˜ï¼ŒLightFMå¯ä»¥æé«˜æ¨¡å‹æ€§èƒ½ï¼Œæ­£å¦‚[1]ä¸­æ‰€è¿°ã€‚è¿™å¾ˆæ£’ï¼Œå°½ç®¡è¿™å¯èƒ½æ˜¯ä½ å·²ç»é¢„æ–™åˆ°çš„ï¼Œå› ä¸º**LightFMæ˜¯çŸ©é˜µåˆ†è§£çš„ä¸€ä¸ªæ¨å¹¿ç‰ˆæœ¬**ã€‚
- en: 'In this regard, the paper author writes the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™æ–¹é¢ï¼Œè®ºæ–‡ä½œè€…å†™é“ï¼š
- en: â€œIn both cold-start and low-density scenarios, LightFM performs at least as
    well as pure content-based models, substantially outperforming them when either
    (1) collaborative information is available in the training set or (2) user features
    are included in the model.â€
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: â€œåœ¨å†·å¯åŠ¨å’Œä½å¯†åº¦åœºæ™¯ä¸‹ï¼ŒLightFMçš„è¡¨ç°è‡³å°‘ä¸çº¯å†…å®¹æ¨¡å‹ä¸€æ ·å¥½ï¼Œå½“ï¼ˆ1ï¼‰è®­ç»ƒé›†ä¸­æœ‰ååŒä¿¡æ¯æˆ–ï¼ˆ2ï¼‰æ¨¡å‹ä¸­åŒ…å«ç”¨æˆ·ç‰¹å¾æ—¶ï¼Œå®ƒçš„è¡¨ç°ä¼šå¤§å¹…è¶…è¶Šè¿™äº›æ¨¡å‹ã€‚â€
- en: â€œWhen collaborative data is abundant (warm-start, dense user-item matrix), LightFM
    performs at least as well as the MF model.â€
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: â€œå½“ååŒæ•°æ®ä¸°å¯Œï¼ˆçƒ­å¯åŠ¨ï¼Œå¯†é›†çš„ç”¨æˆ·-é¡¹ç›®çŸ©é˜µï¼‰æ—¶ï¼ŒLightFMçš„è¡¨ç°è‡³å°‘ä¸MFæ¨¡å‹ä¸€æ ·å¥½ã€‚â€
- en: â€œEmbeddings produced by LightFM encode important semantic information about
    features and can be used for related recommendation tasks such as tag recommendations.â€
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: â€œLightFMç”Ÿæˆçš„åµŒå…¥ç¼–ç äº†å…³äºç‰¹å¾çš„é‡è¦è¯­ä¹‰ä¿¡æ¯ï¼Œå¯ç”¨äºç›¸å…³çš„æ¨èä»»åŠ¡ï¼Œå¦‚æ ‡ç­¾æ¨èã€‚â€
- en: 'There is no proof of these statements, but he reached this conclusion by testing
    it on two datasets. Both datasets have **binary labels,** though, meaning that
    either the item was useful for the user or not. With binary labels, he chose the
    AUC as his evaluation metric and summarized his findings in this table:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›é™ˆè¿°æ²¡æœ‰è¯æ˜ï¼Œä½†ä»–é€šè¿‡åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šæµ‹è¯•å¾—å‡ºäº†è¿™ä¸ªç»“è®ºã€‚è¿™ä¸¤ä¸ªæ•°æ®é›†éƒ½æœ‰**äºŒè¿›åˆ¶æ ‡ç­¾ï¼Œ** æ„å‘³ç€è¯¥é¡¹ç›®å¯¹ç”¨æˆ·æœ‰ç”¨æˆ–æ— ç”¨ã€‚å¯¹äºäºŒè¿›åˆ¶æ ‡ç­¾ï¼Œä»–é€‰æ‹©äº†AUCä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶åœ¨æ­¤è¡¨æ ¼ä¸­æ€»ç»“äº†ä»–çš„å‘ç°ï¼š
- en: '![](../Images/c105fc4e74e6fa3f59a2c3392a8dfa3c.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c105fc4e74e6fa3f59a2c3392a8dfa3c.png)'
- en: From the paper, MF = Matrix Factorization. Higher numbers are better.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡ä¸­ï¼ŒMF = çŸ©é˜µåˆ†è§£ã€‚æ•°å­—è¶Šé«˜è¶Šå¥½ã€‚
- en: Here, we can also see that LightFM outperforms the other methods in the cold
    start and even the warm start setting. It is good to see that LightFM is not worse
    than MF in the warm start setting, but the main selling point is that **LightFM
    completely destroys MF in the cold setting**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ° LightFM åœ¨å†·å¯åŠ¨ç”šè‡³çƒ­å¯åŠ¨è®¾ç½®ä¸­è¶…è¶Šäº†å…¶ä»–æ–¹æ³•ã€‚å¾ˆé«˜å…´çœ‹åˆ° LightFM åœ¨çƒ­å¯åŠ¨è®¾ç½®ä¸­ä¸æ¯” MF å·®ï¼Œä½†ä¸»è¦çš„å–ç‚¹æ˜¯**LightFM
    åœ¨å†·å¯åŠ¨è®¾ç½®ä¸­å®Œå…¨å‡»è´¥äº† MF**ã€‚
- en: '***Remember:*** *An AUC of 0.5 means random guessing in the sense that the
    probability that a randomly picked* ***relevant item*** *for some user* ***scores
    higher******than a*** *randomly chosen* ***non-relevant item*** *for this user
    is* ***50%****.*'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***è®°ä½ï¼š*** *AUC ä¸º 0.5 æ„å‘³ç€éšæœºçŒœæµ‹ï¼Œå³æŸç”¨æˆ·éšæœºæŒ‘é€‰çš„* ***ç›¸å…³é¡¹ç›®*** *çš„è¯„åˆ†é«˜äºè¯¥ç”¨æˆ·çš„* ***éšæœºé€‰æ‹©çš„éç›¸å…³é¡¹ç›®***
    *çš„æ¦‚ç‡ä¸º* ***50%****ã€‚*'
- en: Conclusion
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this article, we have discussed how purely collaborative recommender systems,
    such as matrix factorization, have trouble when seeing new users or items, referred
    to as the cold start problem.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†çº¯ååŒæ¨èç³»ç»Ÿï¼ˆä¾‹å¦‚çŸ©é˜µåˆ†è§£ï¼‰åœ¨é¢å¯¹æ–°ç”¨æˆ·æˆ–æ–°é¡¹ç›®æ—¶é‡åˆ°çš„é—®é¢˜ï¼Œè¿™è¢«ç§°ä¸ºå†·å¯åŠ¨é—®é¢˜ã€‚
- en: We can mitigate this problem once we have more information about users and items
    since the model can learn some general patterns, such as that young people dislike
    old movies. So, if we have a new user and know they are young, a good model should
    score older movies lower than newer ones.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬è·å¾—æ›´å¤šå…³äºç”¨æˆ·å’Œé¡¹ç›®çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºæ¨¡å‹å¯ä»¥å­¦ä¹ ä¸€äº›ä¸€èˆ¬æ€§çš„æ¨¡å¼ï¼Œä¾‹å¦‚å¹´è½»äººä¸å–œæ¬¢è€ç”µå½±ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªæ–°ç”¨æˆ·ï¼Œå¹¶ä¸”çŸ¥é“ä»–ä»¬å¹´è½»ï¼Œå¥½çš„æ¨¡å‹åº”è¯¥å°†è€ç”µå½±çš„è¯„åˆ†ä½äºæ–°ç”µå½±ã€‚
- en: Still, if this new user keeps rating movies, the model can adjust and learn
    to display old movies like [Nosferatu](https://en.wikipedia.org/wiki/Nosferatu)
    if the userâ€™s behavior indicates that this might be a good fit.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œå¦‚æœè¿™ä¸ªæ–°ç”¨æˆ·ç»§ç»­è¯„åˆ†ï¼Œæ¨¡å‹å¯ä»¥è°ƒæ•´å¹¶å­¦ä¼šæ˜¾ç¤ºåƒ [è¯ºæ–¯è´¹æ‹‰å›¾](https://en.wikipedia.org/wiki/Nosferatu)
    è¿™æ ·çš„è€ç”µå½±ï¼Œå¦‚æœç”¨æˆ·çš„è¡Œä¸ºè¡¨æ˜è¿™å¯èƒ½æ˜¯ä¸€ä¸ªåˆé€‚çš„é€‰æ‹©ã€‚
- en: 'A model with these desirable properties feels a bit *Bayesian* to me:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰è¿™äº›ç†æƒ³ç‰¹æ€§çš„æ¨¡å‹å¯¹æˆ‘æ¥è¯´æ„Ÿè§‰æœ‰ç‚¹*è´å¶æ–¯*ï¼š
- en: The user and item feature embeddings serve as a kind of prior that has a great
    influence on the predictions as long as we donâ€™t have interaction data. As interactions
    come in, this prior gets changed.
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç”¨æˆ·å’Œé¡¹ç›®ç‰¹å¾åµŒå…¥ä½œä¸ºä¸€ç§å…ˆéªŒï¼Œå¯¹é¢„æµ‹å…·æœ‰å¾ˆå¤§çš„å½±å“ï¼Œåªè¦æˆ‘ä»¬æ²¡æœ‰äº’åŠ¨æ•°æ®ã€‚éšç€äº’åŠ¨æ•°æ®çš„åˆ°æ¥ï¼Œè¿™ç§å…ˆéªŒä¼šå‘ç”Ÿå˜åŒ–ã€‚
- en: However, it is an interesting question whether the user and item features lose
    their relevance once we have a **dense rating matrix**, e.g., if each user rated
    95% of all movies.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¸€ä¸ªæœ‰è¶£çš„é—®é¢˜æ˜¯ï¼Œä¸€æ—¦æˆ‘ä»¬æ‹¥æœ‰**å¯†é›†è¯„åˆ†çŸ©é˜µ**ï¼Œä¾‹å¦‚æ¯ä¸ªç”¨æˆ·è¯„åˆ†äº†95%çš„æ‰€æœ‰ç”µå½±ï¼Œç”¨æˆ·å’Œé¡¹ç›®ç‰¹å¾æ˜¯å¦å¤±å»ç›¸å…³æ€§ã€‚
- en: Anyway, LightFM is a good candidate for such a model, as indicated by my and
    the paper authorâ€™s experiments. LightFM beats MF, especially in the cold start
    setting on our selected datasets. If the cold start is not an issue, the improvements
    are minor and might even be just statistical noise.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ç®¡æ€æ ·ï¼ŒLightFM æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å€™é€‰æ¨¡å‹ï¼Œè¿™ä¸€ç‚¹ä»æˆ‘å’Œè®ºæ–‡ä½œè€…çš„å®éªŒä¸­å¯ä»¥çœ‹å‡ºã€‚LightFM åœ¨æˆ‘ä»¬çš„é€‰å®šæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äº MFï¼Œç‰¹åˆ«æ˜¯åœ¨å†·å¯åŠ¨è®¾ç½®ä¸­ã€‚å¦‚æœå†·å¯åŠ¨ä¸æ˜¯é—®é¢˜ï¼Œæ”¹è¿›æ˜¯å¾®å°çš„ï¼Œç”šè‡³å¯èƒ½åªæ˜¯ç»Ÿè®¡å™ªå£°ã€‚
- en: '**You can also try the paper** [**authorâ€™s implementation of LightFM**](https://github.com/lyst/lightfm)**.**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½ ä¹Ÿå¯ä»¥å°è¯•è®ºæ–‡** [**ä½œè€…å¯¹ LightFM çš„å®ç°**](https://github.com/lyst/lightfm)**ã€‚**'
- en: References
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] M. Kula, [Metadata Embeddings for User and Item Cold-start Recommendations](https://arxiv.org/abs/1507.08439)
    (2015), arXiv preprint arXiv:1507.08439'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] M. Kula, [ç”¨æˆ·å’Œé¡¹ç›®å†·å¯åŠ¨æ¨èçš„å…ƒæ•°æ®åµŒå…¥](https://arxiv.org/abs/1507.08439) (2015)ï¼ŒarXiv
    é¢„å°æœ¬ arXiv:1507.08439'
- en: I hope that you learned something new, interesting, and useful today. Thanks
    for reading!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ä½ ä»Šå¤©å­¦åˆ°äº†ä¸€äº›æ–°çš„ã€æœ‰è¶£çš„å’Œæœ‰ç”¨çš„ä¸œè¥¿ã€‚æ„Ÿè°¢é˜…è¯»ï¼
- en: '*If you have any questions, write me on* [*LinkedIn*](https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/)*!*'
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œå¯ä»¥åœ¨* [*LinkedIn*](https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/)*ä¸Šè”ç³»æˆ‘ï¼*'
- en: And if you want to dive deeper into the world of algorithms, give my new publication
    **All About Algorithms** a try! Iâ€™m still searching for writers!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³æ·±å…¥äº†è§£ç®—æ³•çš„ä¸–ç•Œï¼Œå¯ä»¥å°è¯•æˆ‘çš„æ–°å‡ºç‰ˆç‰©**å…³äºç®—æ³•çš„ä¸€åˆ‡**ï¼æˆ‘ä»åœ¨å¯»æ‰¾ä½œè€…ï¼
- en: '[](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## All About Algorithms'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## å…³äºç®—æ³•çš„ä¸€åˆ‡'
- en: From intuitive explanations to in-depth analysis, algorithms come to life with
    examples, code, and awesomeâ€¦
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»ç›´è§‚è§£é‡Šåˆ°æ·±å…¥åˆ†æï¼Œç®—æ³•é€šè¿‡ç¤ºä¾‹ã€ä»£ç å’Œç²¾å½©çš„æ–¹å¼å±•ç°å‡ºæ´»åŠ›â€¦â€¦
- en: medium.com](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
