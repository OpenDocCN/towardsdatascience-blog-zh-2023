- en: Improve tabular data prediction with Large Language Model through OpenAI API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/improve-tabular-data-prediction-with-large-language-model-through-openai-api-3eae3c5e52bc](https://towardsdatascience.com/improve-tabular-data-prediction-with-large-language-model-through-openai-api-3eae3c5e52bc)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Python implementation with machine learning classification, prompt engineering,
    feature engineering on text embedding and model explainability with OpenAI API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tonyzhangsky?source=post_page-----3eae3c5e52bc--------------------------------)[![Tony
    Zhang](../Images/a0551c7d670668297a15468d941672c1.png)](https://medium.com/@tonyzhangsky?source=post_page-----3eae3c5e52bc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3eae3c5e52bc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3eae3c5e52bc--------------------------------)
    [Tony Zhang](https://medium.com/@tonyzhangsky?source=post_page-----3eae3c5e52bc--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3eae3c5e52bc--------------------------------)
    ·11 min read·Jul 13, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46d4892886bd0e239397790eb79e98a9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: These days, large language models and the applications or tools are all over
    the news and social medium. The GitHub trending page showcases a substantial presence
    of repositories that extensively utilize large language models. We have seen the
    fantastic capabilities of large language models to create writing for marketing,
    summarize documents, compose music and generate code for software development.
  prefs: []
  type: TYPE_NORMAL
- en: Enterprises have the abundance of tabular data(one of the oldest and most ubiquitous
    formats of data that can be represented in a table with rows and columns) accumulated
    internally and online. Can we apply large language models on tabular data in the
    traditional machine learning lifecycle to improve model performance and add business
    value?
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, we will explore the following topic with full python implementation
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: Building generalized linear models and tree-base model on Kaggle [Heart Attack
    Analysis & Prediction Dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)
    public dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompt engineering to transform tabular data into text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zero-shot classification with OpenAI API (GPT-3.5 model: text-davinci-003)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boosting machine learning model performance with OpenAI embedding API— text-embedding-ada-002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prediction explainability with OpenAI API — gpt-3.5-turbo
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset description
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data is available on Kaggle’s website under license CC0 1.0 Universal (CC0
    1.0) Public Domain Dedication which is no copyright (you can copy, modify, distribute
    and perform the work, even for commercial purposes). Please refer to the below-mentioned
    link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset?source=post_page-----3eae3c5e52bc--------------------------------)
    [## Heart Attack Analysis & Prediction Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: A dataset for heart attack classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset?source=post_page-----3eae3c5e52bc--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'It contains demographics features, medical conditions and target. The columns
    are explained below:'
  prefs: []
  type: TYPE_NORMAL
- en: 'age: age of the applicant'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'sex: sex of the applicant'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'cp: chest pain type: value 1 is typical angina, value 2 is atypical angina,
    value 3 is non-anginal pain and value 4 is asymptomatic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'trtbps: resting blood pressure (in mm Hg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'chol: cholestoral in mg/dl fetched via BMI sensor'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'fbs: fasting blood sugar > 120 mg/dl, 1 = True, 0 = False'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'restecg: resting electrocardiographic results'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'thalachh: maximum heart rate achieved'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'exng: exercise induced angina (1 = yes; 0 = no)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'oldpeak: previous peak'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'slp: slope'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'caa: number of major vessels'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'thall: thal rate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'output: target variable, 0= less chance of heart attack, 1= more chance of
    heart attack'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Binary classification models are developed to predict the likelihood of having
    heart attack. This section will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pre-processing: missing value check, one-hot encoding, train test stratified
    split, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building 4 models including three generalized linear models and one tree-based
    model: Logistic Regression, Ridge, Lasso and Random Forest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model evaluation with AUC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, let’s import package, load data, pre-process and train test split.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s build the model object, fit the model, do the prediction on the test
    set and calculate AUC.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s visualize and compare the model performance(AUC).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e233acd8c858a891e609fb2aba537b7.png)'
  prefs: []
  type: TYPE_IMG
- en: By author
  prefs: []
  type: TYPE_NORMAL
- en: 'In this visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: Tree-based model (Random Forest) performs best with much higher AUC.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3 generalized linear models have similar level of performance and AUC is lower
    than tree based model which is expected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-shot classification with OpenAI API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will perform zero-shot classification on the tabular data with OpenAI API
    which is based on text-davinci-003 model. Before we deep dive into the python
    implementation, let’s understand a bit more about zero-shot classification. The
    [definition](https://huggingface.co/tasks/zero-shot-classification) from Hugging
    face is:'
  prefs: []
  type: TYPE_NORMAL
- en: Zero Shot Classification is the task of predicting a class that wasn’t seen
    by the model during training. This method, which leverages a pre-trained language
    model, can be thought of as an instance of [transfer learning](https://www.youtube.com/watch?v=BqqfQnyjmgg)
    which generally refers to using a model trained for one task in a different application
    than what it was originally trained for. This is particularly useful for situations
    where the amount of labelled data is small.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In zero-shot classification, a prompt and a sequence of text that describes
    what we want the model to do is provided to the model and without any example
    of expected behaviour. This section will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing of tabular data for prompt engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompting LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zero-shot prediction with GPT-3.5 API: text-davinci-003'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model evaluation with AUC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-processing of tabular data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s process the data before prompting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Prompting LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prompts are powerful tool to interact with large language models for a certain
    task. A prompt is a user-provided input to which the model is meant to respond.
    Prompts can be various forms, i.e., text, an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, the prompt includes instructions with expected JSON output
    format and the question itself. With the heart attack dataset, a text prompt can
    be as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e96a10dfc0cee55e136c9b67791e4b29.png)'
  prefs: []
  type: TYPE_IMG
- en: By author
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will define the prompt and API call function which constructs the prompt
    and gets the response from OpenAI-3.5 API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Get the API response — multiprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multiprocessing is utilized to speed up the API call. The code is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Zero-shot classification AUC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The AUC is 0.48 for zero-shot classification which suggests the predictions
    are worse than random chance and indicates that potentially there is no leakage
    in the GPT-3.5 text-davinci-003 model on this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Boost machine learning model performance with OpenAI embedding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LLM embedding is a endpoint of large language model(i.e., OpenAI API) that makes
    it easy to perform natural language and code tasks like semantic search, clustering,
    topic modelling and classification. With prompt engineering, the tabular data
    is transformed into natural language text which can be utilized to generate the
    embeddings. The embeddings have the potential to improve traditional machine learning
    model performance by enabling them to better understand the natural language and
    adapt context with small amount of labelled data. In short, it is one type of
    feature engineering in this context.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering is the process of transforming raw data into features that
    better represent the underlying problem to the predictive models, resulting in
    improved model accuracy on unseen data.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this section, you will see:'
  prefs: []
  type: TYPE_NORMAL
- en: How to get OpenAI embeddings through API call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model performance comparison — with vs without embedding features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, let’s define the function to get the embeddings through API and merge
    with raw dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar as pure machine learning models, we will also conduct stratified split
    and fit the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Model performance comparison — with vs without embedding features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By combining the models without embedding features, we have 8 models in total.
    The ROC curve on the test set is below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9abf86463bdc0bcb8c0003280738b129.png)'
  prefs: []
  type: TYPE_IMG
- en: By author
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, we observe:'
  prefs: []
  type: TYPE_NORMAL
- en: Embedding features are not significantly improving the generalized linear model
    performance(Logistic Regression, Ride and Lasso)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random Forest model with embedding features performs best and is slightly better
    than the random forest model without embedding features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We see the potential of large language models to be integrated into the traditional
    model training process and improve the quality of output. We may have the query,
    can large language models help explain the model decision? Let’s touch this in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Model explainability with OpenAI API — gpt-3.5-turbo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model explainability is one of the key topics in machine learning applications
    especially in areas such as insurance, healthcare, finance and law where users
    need to understand how a model makes a decision at local and global level. I have
    written an article related to [Deep Learning Model Interpretation Using SHAP](/deep-learning-model-interpretation-using-shap-a21786e91d16)
    if you’d like to know more about model interpretation on deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section covers:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing input for the OpenAI API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting reasoning through gpt-3.5-turbo model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, let’s prepare the input for the API call.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s get the reasoning by calling the gpt-3.5-turbo API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The response is quite impressive and the large language model shows strong reasoning
    capabilities along with reasonable explanations.
  prefs: []
  type: TYPE_NORMAL
- en: '{ “**decision**”: “less chance of heart attack”, “**reasoning**”: “Based on
    the information provided, the applicant has several factors that indicate a lower
    chance of having a heart attack. Firstly, the age of the applicant is 51, which
    is not considered young but also not in the high-risk range for heart attacks.
    Secondly, the applicant is male. While men generally have a higher risk than women
    for heart attacks, it is not the sole determining factor. Thirdly, the chest pain
    type reported by the applicant is atypical angina. **Atypical angina is characterized
    by chest pain that is less predictable and may have different patterns compared
    to typical angina**. This can indicate a lower risk of heart attack compared to
    typical angina.Fourthly, the resting blood pressure of the applicant is 125 mm
    Hg. **This falls within the normal range and does not indicate hypertension, which
    is a risk factor for heart attacks**.Fifthly, the cholesterol level of the applicant
    is 245 mg/dl. **While this is higher than the recommended level, it is not extremely
    high, and the applicant’s BMI is not provided, so we cannot determine if the cholesterol
    level is high due to obesity**.Sixthly, the applicant does not have fasting blood
    sugar level above 120 mg/dl, which indicates a lower risk of diabetes, another
    risk factor for heart attacks.Seventhly, the resting electrocardiographic results
    of the applicant are normal, which indicates normal heart function and reduces
    the risk of heart attack.**Eighthly, the maximum heart rate achieved by the applicant
    is 166, which is a good sign as it indicates a healthier cardiovascular system**.Ninthly,
    the applicant does not experience exercise-induced angina, which is another positive
    factor.Tenthly, the ST depression induced by exercise relative to rest is 2.4,
    which is within the normal range and does not indicate significant ischemia.**Eleventhly,
    the slope of the peak exercise ST segment is flat, which could be a normal finding
    or related to the atypical angina reported by the applicant**.Lastly, the applicant
    has no major vessels and a normal Thall, indicating a lower risk of coronary artery
    disease.**Considering all these factors, it is likely that the applicant has a
    lower chance of having a heart attack**. However, it is important to note that
    this evaluation is based solely on the provided information and further medical
    assessment may be necessary to make a definitive determination.” }'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large language models are powerful tool to solve a wide range of use cases in
    various industries. Creating LLM applications is easier and increasingly affordable.
    LLMs will definitely add real business value to the enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s stay in touch…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*I welcome you to* ***join me on an exciting and fruitful data science learning
    adventure****! Stay connected by* ***following my*** [***Medium***](https://medium.com/@tonyzhangsky)*page
    for a constant stream of captivating data science content. I will share more machine
    learning basic, NLP basic, end to end data science implementation in coming months.
    Cheers!*'
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://platform.openai.com/docs/guides/embeddings/what-are-embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://platform.openai.com/docs/models/overview](https://platform.openai.com/docs/models/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://huggingface.co/tasks/zero-shot-classification?source=post_page-----3eae3c5e52bc--------------------------------)
    [## What is Zero-Shot Classification? - Hugging Face'
  prefs: []
  type: TYPE_NORMAL
- en: Learn about Zero-Shot Classification using Machine Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'huggingface.co](https://huggingface.co/tasks/zero-shot-classification?source=post_page-----3eae3c5e52bc--------------------------------)
    [](https://developer.nvidia.com/blog/an-introduction-to-large-language-models-prompt-engineering-and-p-tuning/?source=post_page-----3eae3c5e52bc--------------------------------)
    [## An Introduction to Large Language Models: Prompt Engineering and P-Tuning
    | NVIDIA Technical Blog'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT has made quite an impression. Users are excited to use the AI chatbot
    to ask questions, write poems, imbue a…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: developer.nvidia.com](https://developer.nvidia.com/blog/an-introduction-to-large-language-models-prompt-engineering-and-p-tuning/?source=post_page-----3eae3c5e52bc--------------------------------)
    [](/deep-learning-model-interpretation-using-shap-a21786e91d16?source=post_page-----3eae3c5e52bc--------------------------------)
    [## Deep Learning Model Interpretation Using SHAP
  prefs: []
  type: TYPE_NORMAL
- en: Python implementation on image and tabular data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/deep-learning-model-interpretation-using-shap-a21786e91d16?source=post_page-----3eae3c5e52bc--------------------------------)
  prefs: []
  type: TYPE_NORMAL
