- en: Linear Regression — Occam’s Razor of Predictive Machine Learning Modeling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归 — 预测机器学习建模的奥卡姆剃刀
- en: 原文：[https://towardsdatascience.com/linear-regression-occams-razor-of-predictive-machine-learning-modeling-f2ba5b144a2b](https://towardsdatascience.com/linear-regression-occams-razor-of-predictive-machine-learning-modeling-f2ba5b144a2b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/linear-regression-occams-razor-of-predictive-machine-learning-modeling-f2ba5b144a2b](https://towardsdatascience.com/linear-regression-occams-razor-of-predictive-machine-learning-modeling-f2ba5b144a2b)
- en: Machine learning modeling using linear regression in Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 进行线性回归的机器学习建模
- en: '[](https://medium.com/@fmnobar?source=post_page-----f2ba5b144a2b--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----f2ba5b144a2b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f2ba5b144a2b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f2ba5b144a2b--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----f2ba5b144a2b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fmnobar?source=post_page-----f2ba5b144a2b--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----f2ba5b144a2b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f2ba5b144a2b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f2ba5b144a2b--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----f2ba5b144a2b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f2ba5b144a2b--------------------------------)
    ·16 min read·Jan 3, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f2ba5b144a2b--------------------------------)
    ·阅读时间 16 分钟·2023年1月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2494e60058d5a0eb46decef5f125cf20.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2494e60058d5a0eb46decef5f125cf20.png)'
- en: crystal ball, by [DALL.E 2](https://openai.com/dall-e-2/)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 水晶球，由 [DALL.E 2](https://openai.com/dall-e-2/)
- en: Are you familiar with Occam’s Razor? I remember a mention of it in the Big Bang
    Theory TV series! The idea behind Occam’s Razor is that all other things being
    equal, the simplest explanation for a phenomenon is more likely to be true than
    a more complex one (i.e. the simplest solution is almost always the best solution).
    I’d like to think that Occam’s Razor of predictive modeling in machine learning
    is linear regression, which is almost the simplest modeling methodology to use
    and can be the best solution for certain tasks. This post will cover an introduction
    and implementation of linear regression.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你熟悉奥卡姆剃刀吗？我记得在《生活大爆炸》电视剧中提到过它！奥卡姆剃刀的观点是，在其他条件相同的情况下，现象的最简单解释更可能是真实的，而不是更复杂的解释（即最简单的解决方案几乎总是最佳解决方案）。我认为机器学习预测建模中的奥卡姆剃刀就是线性回归，这几乎是使用的最简单建模方法，并且对于某些任务可能是最佳解决方案。本文将介绍线性回归的概念和实现。
- en: Similar to my other posts, learning will be achieved through practice questions
    and answers. I will include hints and explanations in the questions as needed
    to make the journey easier. Lastly, the notebook that I used to create this exercise
    is also linked in the bottom of the post, which you can download, run and follow
    along.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与我的其他帖子类似，通过实践问题和答案来实现学习。我会在问题中提供提示和解释，以便让过程更简单。最后，我使用的创建此练习的笔记本也链接在文章底部，你可以下载、运行并跟随学习。
- en: Let’s get started!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧！
- en: '*(All images, unless otherwise noted, are by the author.)*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*(除非另有说明，否则所有图片均由作者提供。)*'
- en: '[](https://medium.com/@fmnobar/membership?source=post_page-----f2ba5b144a2b--------------------------------)
    [## Join Medium with my referral link - Farzad Mahmoodinobar'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fmnobar/membership?source=post_page-----f2ba5b144a2b--------------------------------)
    [## 通过我的推荐链接加入 Medium - Farzad Mahmoodinobar'
- en: Read every story from Farzad (and other writers on Medium). Your membership
    fee directly supports Farzad and other…
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读 Farzad 的每一个故事（以及 Medium 上其他作者的故事）。你的会员费直接支持 Farzad 和其他人…
- en: medium.com](https://medium.com/@fmnobar/membership?source=post_page-----f2ba5b144a2b--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@fmnobar/membership?source=post_page-----f2ba5b144a2b--------------------------------)
- en: Data Set
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: In order to practice linear regression, we will use a data set of car prices
    from [UCI Machine Learning Repository](https://archive-beta.ics.uci.edu/dataset/10/automobile)
    (CC BY 4.0). I have cleaned up parts of the data for our use and it can be downloaded
    from [this link](https://gist.github.com/fmnobar/c9b4029e08e97978a9a53f4eb034b16f).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了练习线性回归，我们将使用来自 [UCI 机器学习库](https://archive-beta.ics.uci.edu/dataset/10/automobile)（CC
    BY 4.0）的汽车价格数据集。我已经清理了部分数据供我们使用，可以从 [这个链接](https://gist.github.com/fmnobar/c9b4029e08e97978a9a53f4eb034b16f)
    下载。
- en: I will explain some of the math behind the linear regression model we will be
    using in the exercise. Understanding the math is not required to be able to successfully
    understand the content of this post but I do recommend going through it to get
    a better sense of what is happening behind the scene, when we create a linear
    regression model.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我将解释我们在练习中使用的线性回归模型背后的数学。虽然理解这些数学内容不是成功理解本文内容的必要条件，但我建议你了解它，以便更好地理解创建线性回归模型时的幕后过程。
- en: Fundamentals of Linear Regression
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归基础
- en: 'Linear regression is when linear predictors (or independent variables) are
    used to predict a dependent variable. One simple example is the formula for a
    line:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是使用线性预测变量（或自变量）来预测因变量。一种简单的例子是直线公式：
- en: '![](../Images/681b884e40b7a6b0db5530abb337ed9b.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/681b884e40b7a6b0db5530abb337ed9b.png)'
- en: In this case, `y` is the dependent variable and `x` is the independent variable
    (`c` is a constant). The goal of a linear regression model is to determine the
    best coefficient (`a` in the example above) for `x` to most accurately predict
    `y`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`y` 是因变量，而 `x` 是自变量（`c` 是一个常数）。线性回归模型的目标是确定最佳系数（上例中的 `a`），以使 `x` 能最准确地预测
    `y`。
- en: Now let’s generalize that example, which is also known as mulitple linear regression.
    In a multiple linear regression model, the goal is to find the line of best fit
    that describes the relationship between the dependent variable and multiple independent
    variables.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这个例子推广到多元线性回归。在多元线性回归模型中，目标是找到描述因变量与多个自变量之间关系的最佳拟合线。
- en: '![](../Images/daebd57c67021726b1c7287621920276.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/daebd57c67021726b1c7287621920276.png)'
- en: In this case, we have multiple independent variables (or predictors) from `x_1`
    to `x_n` and each one is multiplied by its own coefficient to predict the dependent
    variable `y`. In a linear regression model, we will try to determine the values
    of coefficients `a_1` to `a_n` to have the best prediction for the dependent variable
    `y`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们有多个自变量（或预测变量），从 `x_1` 到 `x_n`，每个自变量都乘以它自己的系数，以预测因变量 `y`。在线性回归模型中，我们将尝试确定系数
    `a_1` 到 `a_n` 的值，以获得对因变量 `y` 的最佳预测。
- en: Now that we understand what a linear regression is, let’s move to Ordinary Least
    Squares (OLS) regression, which is a form of linear regression.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了线性回归的概念，让我们转向普通最小二乘（OLS）回归，这是一种线性回归形式。
- en: Ordinary Least Squares Regression
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 普通最小二乘回归
- en: Ordinary least squares regression model estimates the coefficients of a regression
    model by minimizing the sum of the squares of residuals. Residual is the vertical
    distance between the line (i.e. predicted values) vs. the actuals, as shown in
    the figure below. These residuals are squared so that errors do not cancel each
    other out (when one prediction is higher than actual and another prediction is
    lower than actual, these two are still errors and should not cancel each other
    out).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 普通最小二乘回归模型通过最小化残差平方和来估计回归模型的系数。残差是回归线（即预测值）与实际值之间的垂直距离，如下图所示。这些残差被平方，以便错误不会相互抵消（当一个预测值高于实际值，而另一个预测值低于实际值时，这两个仍然是错误，不应相互抵消）。
- en: '![](../Images/814567d23e6731a092e28fec2bdddb61.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/814567d23e6731a092e28fec2bdddb61.png)'
- en: Ordinary Least Squares Regression — Regression Line and Residuals
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 普通最小二乘回归——回归线和残差
- en: Now that we understand the underlying concepts, we will start with exploring
    the data and the variables (or features) that we may be able to use to predict
    the car prices. Then we will split the data into train and test sets to build
    the regression model. We will then look at the performance of the regression model
    and finally will plot the results.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了基本概念，我们将开始探索数据和我们可能用来预测汽车价格的变量（或特征）。然后，我们将数据分为训练集和测试集，以建立回归模型。接下来，我们将查看回归模型的性能，最后绘制结果。
- en: Let’s get started!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: 1\. Exploratory Analysis
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 探索性分析
- en: Let’s start by looking at the data, which can also be downloaded from [here](https://gist.github.com/fmnobar/c9b4029e08e97978a9a53f4eb034b16f).
    First we will import Pandas and NumPy. Then we will read the CSV file including
    our data set and look at the top five rows of the data set.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先查看数据，可以从[这里](https://gist.github.com/fmnobar/c9b4029e08e97978a9a53f4eb034b16f)下载。首先，我们将导入Pandas和NumPy。然后，我们将读取包含数据集的CSV文件，并查看数据集的前五行。
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Results:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/eb8ad12479cdd91d62cb8c73d320fd73.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb8ad12479cdd91d62cb8c73d320fd73.png)'
- en: Column names are mostly self-explanatory so I will add only the ones that were
    not immediately obvious to me. You can ignore these for now and just refer to
    them during the course of the exercise if you need the definition of a column
    name.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 列名大多是显而易见的，所以我只会添加那些对我不太明显的列名。你现在可以忽略这些，并在需要列名定义时参考它们。
- en: 'symboling: A value assigned by insurance companies according to the car’s perceived
    riskiness. A value of +3 indicates that the car is risky, -3 indicates that it
    is safe'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'symboling: 保险公司根据车辆的风险感知分配的值。+3表示车辆有风险，-3表示车辆安全'
- en: 'aspiration: Standard or turbo'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'aspiration: 标准或涡轮'
- en: 'drive-wheels: rwd for rear-wheel drive; fwd for front-wheel drive; 4wd for
    four-wheel drive'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'drive-wheels: rwd表示后驱；fwd表示前驱；4wd表示四轮驱动'
- en: 'wheel-base: The distance between the centres of the front and rear wheels in
    centimeters'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'wheel-base: 前后轮中心之间的距离，以厘米为单位'
- en: 'engine-type: dohc for Dual OverHead Cam; dohcv for Dual OverHead Cam and Valve;
    l for L engine; ohc for OverHead Cam; ohcf for OverHead Cam and Valve F engine;
    ohcv for OverHead Cam and Valve; rotor for Rotary engine'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'engine-type: dohc表示双顶置凸轮；dohcv表示双顶置凸轮和气门；l表示L型发动机；ohc表示顶置凸轮；ohcf表示顶置凸轮和气门F型发动机；ohcv表示顶置凸轮和气门；rotor表示旋转发动机'
- en: 'bore: Inner diameter of the cylinder in centimeters'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'bore: 汽缸的内径，以厘米为单位'
- en: 'stroke: Movement of the cylinder'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'stroke: 汽缸的运动'
- en: '**Question 1:**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 1：**'
- en: Are there any missing values in the dataframe?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框中是否有缺失值？
- en: '**Answer:**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**回答：**'
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Results:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/6d3e3b7d855ecea3cbdd3e6f348f436b.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d3e3b7d855ecea3cbdd3e6f348f436b.png)'
- en: As we can see, there are 25 columns (note column numbers start from 0 to 24)
    and 193 rows. There are no null values in the columns.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，共有25列（注意列编号从0到24）和193行。列中没有空值。
- en: 2\. Feature Selection
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 特征选择
- en: Feature selection is the process of identifying and selecting a subset of relevant
    features (also known as “predictors,” “inputs,” or “attributes”) for building
    a machine learning model. The goal of feature selection is to improve the model’s
    accuracy and interpretability by reducing the complexity of the model and eliminating
    irrelevant, redundant, or noisy features.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择是识别和选择一组相关特征（也称为“预测变量”、“输入”或“属性”）以构建机器学习模型的过程。特征选择的目标是通过减少模型的复杂性和消除不相关、冗余或噪声特征，从而提高模型的准确性和可解释性。
- en: '**Question 2:**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 2：**'
- en: Create a table showing the correlation among the columns in the dataframe.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个表格，显示数据框中列之间的相关性。
- en: '**Answer:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**回答：**'
- en: 'We are going to use `pandas.DataFrame.corr`, which calculates pairwise correlation
    of columns. There are two points to consider:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`pandas.DataFrame.corr`，它计算列之间的逐对相关性。需要考虑两个要点：
- en: '`pandas.DataFrame.corr` will exclude null values. We confirmed our data set
    does not include any null values but this might be important in exercises with
    null values.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pandas.DataFrame.corr`将排除空值。我们确认我们的数据集不包含任何空值，但在处理含有空值的练习中，这可能很重要。'
- en: We will be limiting the correlation to numerical values only and will discuss
    categorical values later in the exercise.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将仅限制数值的相关性，并将在后续练习中讨论分类值。
- en: As a refresher, let’s review what categorical and numerical variables are before
    we continue.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作为回顾，让我们在继续之前复习一下分类变量和数值变量是什么。
- en: In machine learning, categorical variables are variables that can take on a
    limited number of values. These values represent different categories and the
    values themselves have no inherent order or numerical meaning. Examples of categorical
    variables include gender (male or female), marital status (married, single, divorced,
    etc.).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，分类变量是可以取有限数量值的变量。这些值表示不同的类别，值本身没有固有的顺序或数值意义。分类变量的例子包括性别（男性或女性）、婚姻状况（已婚、单身、离婚等）。
- en: Numeric variables are variables that can take on any numerical value within
    a certain range. These variables can be either continuous (meaning they can take
    on any value within a certain range) or discrete (meaning they can only take on
    specific, predetermined values). Examples of numeric variables include age, height,
    weight, etc.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数值变量是可以在特定范围内取任意数值的变量。这些变量可以是连续的（意味着它们可以在特定范围内取任意值）或离散的（意味着它们只能取特定的、预定的值）。数值变量的例子包括年龄、身高、体重等。
- en: With those out of the way, let’s calculate the correlations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 处理完这些后，让我们计算相关性。
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Results:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/0b403d5f49deaa35f582b0961ea6feb2.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b403d5f49deaa35f582b0961ea6feb2.png)'
- en: '**Question 3:**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 3：**'
- en: There are a lot of correlation values generated in the last question. We care
    more about the correlation with the car prices. Show the correlation with the
    car prices and order that from the largest to the smallest.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一问题中生成了许多相关值。我们更关心与汽车价格的相关性。展示与汽车价格的相关性，并按从大到小的顺序排列。
- en: '**Answer:**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Results:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/e8d1690d750aa81648fbc0a35675b7eb.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8d1690d750aa81648fbc0a35675b7eb.png)'
- en: This is quite interesting. For example, “engine-size” seems to have the highest
    correlation with the price, which is expected, while “compression-ratio” does
    not seem to be as highly correlated with the price. On the other hand, “symboling”,
    which we recall is a measure of riskiness of the car, is negatively-correlated
    with the car price, which again makes intuitive sense.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常有趣。例如，“engine-size”似乎与价格的相关性最高，这在预期之中，而“compression-ratio”似乎与价格的相关性不那么高。另一方面，“symboling”，我们记得这是衡量汽车风险的指标，与汽车价格呈负相关，这也符合直觉。
- en: '**Question 4:**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 4：**'
- en: In order to focus more on the relevant features to build a car price model,
    filter out columns that have a weaker correlation with price, which we are going
    to define as any feature with correlation less than an absolute value of 0.2 (this
    is an arbitrarily-selected value for this exercise).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更专注于相关特征以构建汽车价格模型，筛选出与价格相关性较弱的列，我们将定义任何相关性绝对值小于0.2的特征（这是为了本练习而任意选择的值）。
- en: '**Answer:**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Results:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/aea2051e3164f7de810698a44ff777cd.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aea2051e3164f7de810698a44ff777cd.png)'
- en: We see that as a result of this, we are now left with 19 features (there are
    20 columns but one of them is the price itself so there are 19 features or predictors).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到由于这个原因，我们现在剩下19个特征（总共有20列，但其中一个是价格本身，所以剩下19个特征或预测变量）。
- en: '**Question 5:**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 5：**'
- en: Now that we have a more manageable number of features, take another look at
    them and see if we need to drop any of them.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了更可管理的特征数量，重新查看一下它们，看看是否需要删除其中任何一个。
- en: '***Hint:*** *Some features might be very similar and arguably redundant. And
    some might not really matter.*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '***提示：*** *一些特征可能非常相似，可能是冗余的。有些可能实际上并不重要。*'
- en: '**Answer:**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: Let’s look at the dataframe and then at the correlation among the features left.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看数据框，然后查看剩余特征之间的相关性。
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Results:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/00d5ea313f493625011f16024e2576ea.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00d5ea313f493625011f16024e2576ea.png)'
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Results:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/b5ac276e4dab731b663e69f57182034d.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5ac276e4dab731b663e69f57182034d.png)'
- en: “wheel-base” (distance between the front and rear wheels) and “length” (total
    lenght of the car) are highly-correlated and seem to convey the same information.
    Additionally, “city-mpg” and “highway-mpg” are highly-correlated, so we can consider
    dropping one of them. Let’s go ahead and drop “wheel-base” and “city-mpg” and
    then look at the top five rows of the dataframe again.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: “wheel-base”（前后轮之间的距离）和“length”（汽车的总长度）高度相关，似乎传达了相同的信息。此外，“city-mpg”和“highway-mpg”也高度相关，因此我们可以考虑删除其中一个。让我们继续删除“wheel-base”和“city-mpg”，然后再查看数据框的前五行。
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Results:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/d2eaea36a671a657462c276b6c803e81.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2eaea36a671a657462c276b6c803e81.png)'
- en: As we see above, the new dataframe is smaller and does not include the two columns
    that we just removed. Next, we will talk about categorical variables.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，新的数据框更小，不包括我们刚刚删除的两个列。接下来，我们将讨论分类变量。
- en: 2.1\. Dummy Coding
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1\. 虚拟编码
- en: Let’s look more closely at the values of columns “make” and “fuel-type”.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地查看“make”和“fuel-type”列的值。
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Results:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/7c5e9096f7d2a55e7c573d50e607d725.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c5e9096f7d2a55e7c573d50e607d725.png)'
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Results:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/2c920a9e96fd9e2516ccb31cc3eaff17.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c920a9e96fd9e2516ccb31cc3eaff17.png)'
- en: These two columns are categorical values (e.g. Toyota or Diesel), and not numerical.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这两列是分类值（例如丰田或柴油），而不是数值。
- en: In order to include these categorical variables in our regression model, we
    are going to create “dummy codes” for these categorical variables.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这些分类变量纳入我们的回归模型中，我们将为这些分类变量创建“虚拟编码”。
- en: 'Dummy coding is where the categorical variables (or predictors) in one column,
    are replaced by multiple binary columns. For example, let’s assume we had a categorical
    variable as shown in this table:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟编码是将一个列中的分类变量（或预测变量）替换为多个二进制列。例如，假设我们有一个如表中所示的分类变量：
- en: '![](../Images/be2d6ff2c74f37d7aa906bc1d8c006b4.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be2d6ff2c74f37d7aa906bc1d8c006b4.png)'
- en: Categorical Variable — Before Dummy Coding
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量 — 虚拟编码前
- en: 'As we see in the above table, “random_categorical_variable” can have three
    categorical values of A, B and C. We would like to transform the categorical variable
    into a format that we can more easily use in our regression model using dummy
    coding, which will transform it into three separate columns of A, B and C, with
    binary values, as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如上表所示，“random_categorical_variable”可以有 A、B 和 C 三个分类值。我们希望通过虚拟编码将分类变量转换为一种更易于在回归模型中使用的格式，这将把它转换为
    A、B 和 C 三个单独的列，并带有二进制值，如下所示：
- en: '![](../Images/745f3d431c3ab9d3debc858990d29472.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/745f3d431c3ab9d3debc858990d29472.png)'
- en: Categorical Variable — After Dummy Coding
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量 — 虚拟编码后
- en: Let’s see how dummy coding can be implemented in Python.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在 Python 中实现虚拟编码。
- en: '**Question 6:**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 6：**'
- en: Dummy code the categorical columns of our dataframe.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们数据框的分类列进行虚拟编码。
- en: 'Answer:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：
- en: Let’s first look at what the dataframe looks like before dummy coding.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看数据框在虚拟编码前的样子。
- en: '[PRE10]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Results:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/e06f558283eea02f5eacd756842ecd35.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e06f558283eea02f5eacd756842ecd35.png)'
- en: We know from the previous question that column “fuel-type” can take 2 distinct
    values (i.e. gas and diesel). Therefore, after dummy coding, we expect to replace
    “fuel-type” column with 2 separate columns. The same applies to other categorical
    columns, depending on how many unique values each has.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 从之前的问题我们知道，“fuel-type”列可以取 2 个不同的值（即汽油和柴油）。因此，在虚拟编码后，我们期望将“fuel-type”列替换为 2
    个单独的列。其他分类列也是如此，具体取决于每个列有多少个唯一值。
- en: Let’s first only dummy code the “fuel-type” column as an example and look at
    how the dataframe changes, then we can go ahead and dummy code other categorical
    columns.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们只对“fuel-type”列进行虚拟编码作为示例，并观察数据框的变化，然后我们可以继续对其他分类列进行虚拟编码。
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Results:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/0be5e2605762055a81e9e8b81816af61.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0be5e2605762055a81e9e8b81816af61.png)'
- en: As expected, we now have 2 columns for the original “fuel-type”, named “fuel-type_gas”
    and “fuel-type_diesel”.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们现在有两个原始的“fuel-type”列，分别命名为“fuel-type_gas”和“fuel-type_diesel”。
- en: Next, let’s identify all the categorical columns and dummy code them.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们识别所有分类列并对其进行虚拟编码。
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Results:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/477e0a07ebf3588fbfc63241c71f8ab6.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/477e0a07ebf3588fbfc63241c71f8ab6.png)'
- en: Note that the above snapshot does not cover all the columns after dummy coding,
    since now we have 63 columns, which would become too small to demonstrate in a
    snapshot.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，上述快照未覆盖虚拟编码后的所有列，因为现在我们有 63 列，这在快照中展示会显得太小。
- en: Lastly and now that we have created all these new columns, let’s recreate the
    correlation between price and all the other columns and sort them from the highest
    to the lowest.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，现在我们创建了所有这些新列，让我们重新创建价格与所有其他列之间的相关性，并从高到低进行排序。
- en: '[PRE13]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Results:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/9c7563699f6719c7abc2c85654efa98c.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c7563699f6719c7abc2c85654efa98c.png)'
- en: As we see above, some of the categorical variables have a high correlation with
    the price such as “drive-wheels” and “num-of-cylinders”.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，一些分类变量与价格有较高的相关性，例如“drive-wheels”和“num-of-cylinders”。
- en: At this point, we have familiarized ourselves with the data and cleaned up the
    data to a certain extent, now let’s continue with the main goal of creating a
    model to predict the price of the car, based on these attributes.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们已经对数据有所了解，并在一定程度上清理了数据，现在让我们继续进行创建模型以根据这些属性预测汽车价格的主要目标。
- en: 3\. Splitting the Data Into Train and Test Sets
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 将数据分割为训练集和测试集
- en: At this point, we are going to first break down the data into dependent and
    independent variables. Dependent variable or “y” is what we are going to predict,
    which is “price” in this exercise. It is called the dependent variable because
    its value depends on the values of the independent variables. Independent variables
    or “X” are all other variables or features that we have left in our data frame
    at this point, which includes “engine-size”, “horsepower”, etc.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们将首先将数据拆分为因变量和自变量。因变量或“y”是我们要预测的内容，在这个练习中是“价格”。它被称为因变量，因为它的值依赖于自变量的值。自变量或“X”是目前数据框中所有其他变量或特征，包括“发动机尺寸”、“马力”等。
- en: Next, we will break down the data into Train and Test sets. As the names suggest,
    Train data set will be used to train our regression model and then we will test
    the performance of the model using the Test set. We split the data to ensure that
    model does not see the Test set during its training process so that the Test set
    can be a good representative of how well the model performs. It is important to
    split the data into a training set and a test set because using the same data
    to fit the model and evaluate its performance can lead to overfitting. Overfitting
    occurs when the model is too complex and has learned the noise and random fluctuations
    in the data, rather than the underlying pattern. As a result, the model may perform
    well on the training data but poorly on new, unseen data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将数据拆分为训练集和测试集。顾名思义，训练数据集将用于训练回归模型，然后我们将使用测试集来测试模型的性能。我们拆分数据是为了确保模型在训练过程中看不到测试集，从而使测试集能够很好地代表模型的性能。将数据拆分为训练集和测试集很重要，因为使用相同的数据来拟合模型和评估其性能可能导致过拟合。过拟合发生在模型过于复杂时，它学习了数据中的噪声和随机波动，而不是潜在的模式。因此，模型可能在训练数据上表现良好，但在新见数据上表现不佳。
- en: '**Question 7:**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 7：**'
- en: Assign the dependent variable (target) to y and the independent variables (or
    features) to X.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 将因变量（目标）分配给 y，将自变量（或特征）分配给 X。
- en: '**Answer:**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Question 8:**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 8：**'
- en: Break down the data into a train and test set. Use 30% of the data for the test
    set, and use a `random_state` of 1234.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集。使用 30% 的数据作为测试集，并使用 `random_state` 为 1234。
- en: '**Answer:**'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE15]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Question 9:**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 9：**'
- en: Train a linear regression model using the training set.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练集训练线性回归模型。
- en: '**Answer:**'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Results:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/f621a2e7175b2d4c43945becfb948c12.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f621a2e7175b2d4c43945becfb948c12.png)'
- en: We will discuss what happened here, but let’s first look at how we can evaluate
    a machine learning model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论这里发生了什么，但首先让我们看看如何评估机器学习模型。
- en: 4\. Model Evaluation
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 模型评估
- en: 4.1\. R²
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1\. R²
- en: '**Question 10:**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 10：**'
- en: What is the score of the trained model?
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型的得分是多少？
- en: '**Answer:**'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'For this purpose, we can use LinearRegression’s “score()”, that returns the
    coefficient of determination of the prediction, or R²$, which is calculated as
    follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们可以使用 LinearRegression 的 “score()” 方法，它返回预测的决定系数或 R²$，计算如下：
- en: '![](../Images/6dc564ec022cd3d147dcff7c4bdea2bc.png)![](../Images/11dffd9b28f0fd2a5421f3642d067a80.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6dc564ec022cd3d147dcff7c4bdea2bc.png)![](../Images/11dffd9b28f0fd2a5421f3642d067a80.png)'
- en: The best possible score is 1.0\. A constant model that always predicts the expected
    value of “y”, regardless of the input features, would get R² score of 0.0.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的得分是 1.0\. 一个始终预测“y”期望值的常数模型，无论输入特征如何，都将得到 R² 分数 0.0。
- en: With that knowledge, let’s look at the implementation.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些知识后，我们来看看实现过程。
- en: '[PRE17]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Results:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/24e8597820edac349384c602fbe2d4f3.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24e8597820edac349384c602fbe2d4f3.png)'
- en: '**Question 11:**'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 11：**'
- en: Predict the values of the test set and then evaluate the performance of the
    trained model on the test set.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 预测测试集的值，然后评估训练模型在测试集上的表现。
- en: '**Answer:**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE18]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Results:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/6e762acf16b46983385cf997279802de.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e762acf16b46983385cf997279802de.png)'
- en: 4.2\. Mean Squared Error
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2\. 均方误差
- en: 'Mean Squared Error (MSE) is the average of the squared errors and is calculated
    as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差（Mean Squared Error, MSE）是平方误差的平均值，计算如下：
- en: '![](../Images/80dbaace5ecde5a193981630d22b1075.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80dbaace5ecde5a193981630d22b1075.png)'
- en: '**Question 12:**'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 12：**'
- en: Calculate the Mean Squared Error and R² for the predicted results of the test
    sets.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 计算测试集预测结果的均方误差（Mean Squared Error）和决定系数（R²）。
- en: '**Answer:**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE19]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Results:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/38284a52fe093e63223b6a7b1948926b.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38284a52fe093e63223b6a7b1948926b.png)'
- en: '**Question 13:**'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 13：**'
- en: How do you interpret the results of the previous question? What are your recommendations
    for the next steps?
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何解读前一个问题的结果？对下一步有什么建议？
- en: '**Answer:**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: R² is relatively high but the MSE is pretty high too, which can suggest the
    error may be too high — note this really depends on the business needs and what
    this model is being used for. There might be a case where R² of 90.6% is good
    enough for the business needs and there might be cases where this number is just
    not good enough. This performance level can be driven by some features that are
    not strong predictors of price. Let’s see if we can identify which ones are not
    strong predictors and eliminate them. Then we can retrain and look at the scores
    again to see if we were able to make improvements to our model.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: R² 相对较高，但均方误差（MSE）也很高，这可能表明误差可能过大——注意这实际上取决于业务需求以及模型的用途。在某些情况下，90.6% 的 R² 可能足够满足业务需求，而在其他情况下，这个数字可能还不够好。这种性能水平可能受到一些不是强预测价格的特征的影响。让我们看看能否识别出哪些特征不是强预测因子并将其删除。然后我们可以重新训练并再次查看评分，以查看是否能够改善我们的模型。
- en: For this step and in order to try something new, we are going to use the ordinary
    least squares (OLS) from statsmodels library. The steps of training and then predicting
    the values of the test set is the same as before.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尝试一些新的方法，我们将使用 statsmodels 库中的普通最小二乘法（OLS）。训练和预测测试集值的步骤与之前相同。
- en: '[PRE20]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Results:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/072aed0efd18d7c8f0abafb182807484.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/072aed0efd18d7c8f0abafb182807484.png)'
- en: This one provides a nice presentation of the features and a measurement of p-value
    for that specific feature’s significance. For example, if we use a 0.05 or 5%
    significance level (or 95% confidence level), we can eliminate the features where
    “P > |t|” is larger than 0.05.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法提供了特征的良好展示和该特征显著性的 p 值测量。例如，如果我们使用 0.05 或 5% 的显著性水平（或 95% 的置信水平），我们可以排除那些“P
    > |t|”大于 0.05 的特征。
- en: '[PRE21]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Results:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '[PRE22]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There are 43 such columns. Let’s drop these columns and see if the results improve.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 共有 43 列这样的数据。让我们删除这些列，看看结果是否有所改善。
- en: '[PRE23]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Results:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/8ec99628d8067f6c8c8e04199dadefb4.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ec99628d8067f6c8c8e04199dadefb4.png)'
- en: The overall performance, as judged by the R-squared value, improved from 0.967
    to 0.972 and we reduced the number of columns, which makes our model and analysis
    more efficient.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 R 平方值判断，整体性能从 0.967 提升至 0.972，并且我们减少了列数，这使得我们的模型和分析更加高效。
- en: 5\. Plot of the Predictions vs. Actuals
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 预测值与实际值的图
- en: '**Question 14:**'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 14：**'
- en: Create a scatter plot of predictions vs. actuals. We would expect all the points
    to lay across a straight line such as `f(x) = x` if all the predictions matched
    the actuals. Add such a straight line in red for comparison.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 创建预测值与实际值的散点图。如果所有预测值都与实际值相匹配，我们会期望所有点都沿着一条直线如 `f(x) = x` 分布。为比较添加一条红色的直线。
- en: '**Answer:**'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE24]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Results:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/bcee29cf4f4b942a17d73866cf3a019a.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bcee29cf4f4b942a17d73866cf3a019a.png)'
- en: Scatter Plot of the Trained Model’s Predictions vs. Actuals
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型的预测值与实际值的散点图
- en: As we expected, the values are scattered around the straight line, demonstrating
    a good level of prediction generatd by the model. Where the dots are to the right
    side of the red line, it means that the model predicted a larger price compared
    to the actual, while the dots in the left side of the red line indicate the reverse.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们预期的那样，值围绕直线散布，显示出模型产生了较好的预测水平。点在红线的右侧，意味着模型预测的价格高于实际价格，而在红线左侧的点则表示相反的情况。
- en: Notebook with Practice Questions
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有练习问题的笔记本
- en: Below is the notebook with both questions and answers that you can download
    and practice.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是包含问题和答案的笔记本，您可以下载并进行练习。
- en: Conclusion
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this post, we talked about how in some cases the simplest solution can be
    the most appropriate solution and introduced and implemented Linear Regression
    as such a solution in predictive machine learning tasks. We started by learning
    about the math behind linear regression and then implemented a model to predict
    car prices based on existing car attributes. We then measured the model’s performance
    and took certain measures to improve our model’s performance and finally visualized
    the comparison of the trained model’s predictions to the actuals using a scatterplot.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们讨论了在某些情况下，最简单的解决方案可能是最合适的解决方案，并介绍了如何将线性回归作为预测机器学习任务中的一种解决方案进行实现。我们首先学习了线性回归背后的数学原理，然后实现了一个模型来根据现有的汽车属性预测汽车价格。接着，我们测量了模型的性能，并采取了某些措施以提高模型的性能，最后通过散点图可视化了训练模型预测值与实际值的比较。
- en: Thanks for Reading!
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you found this post helpful, please [follow me on Medium](https://medium.com/@fmnobar)
    and subscribe to receive my latest posts!
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这篇文章对你有帮助，请 [关注我的 Medium](https://medium.com/@fmnobar) 并订阅以接收我的最新文章！
