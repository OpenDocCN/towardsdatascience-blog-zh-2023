["```py\nloss.backward()\nfor name, param in model.named_parameters():\n  param.grad *= guidance_mask[name]\noptimizer.step()\n```"]