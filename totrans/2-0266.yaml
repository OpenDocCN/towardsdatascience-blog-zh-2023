- en: 'Advances in Deep Learning for Time Series Forecasting and Classification: Winter
    2023 Edition'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/advances-in-deep-learning-for-time-series-forecasting-and-classification-winter-2023-edition-6617c203c1d1](https://towardsdatascience.com/advances-in-deep-learning-for-time-series-forecasting-and-classification-winter-2023-edition-6617c203c1d1)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The downfall of transformers for time series forecasting and the rise of time
    series embedding methods. Plus advances in anomaly detection, classification,
    and optimal (t) interventions.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://igodfried.medium.com/?source=post_page-----6617c203c1d1--------------------------------)[![Isaac
    Godfried](../Images/302c9b76bc1e293698ffa1479825e326.png)](https://igodfried.medium.com/?source=post_page-----6617c203c1d1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6617c203c1d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6617c203c1d1--------------------------------)
    [Isaac Godfried](https://igodfried.medium.com/?source=post_page-----6617c203c1d1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6617c203c1d1--------------------------------)
    ·16 min read·Jan 10, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7af7bc73ed4069181cec96d796eced4a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo from myself (Great Sand Dunes NP at sunset)
  prefs: []
  type: TYPE_NORMAL
- en: '*Note you can find an [updated 2024 issue of this article in DDS](https://medium.com/deep-data-science/advances-in-deep-learning-for-time-series-forecasting-classification-winter-2024-a3fd31b875b0).'
  prefs: []
  type: TYPE_NORMAL
- en: It has been quite sometime since I’ve written an update on the state of deep
    learning for time series. Several conferences have come and gone and the field
    as a whole has advanced in several different ways. Here I will attempt to cover
    some of the more promising as well as critical papers that have come out in the
    last year or so as well as updates to the [Flow Forecast](https://github.com/AIStream-Peelout/flow-forecast)
    framework [FF].
  prefs: []
  type: TYPE_NORMAL
- en: '[Flow Forecast Framework](https://github.com/AIStream-Peelout/flow-forecast)
    updates:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Over the last year we have made major strides in the architecture and documentation
    of FF. Just recently we rolled out full support for time series classification
    and supervised anomaly detection. Additionally, we have added several more [tutorial
    notebooks](https://github.com/AIStream-Peelout/flow_tutorials) and expanded our
    unit-test coverage to more than 77%.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also added a vanilla GRU model that you can use for time series forecasting,
    classification and anomaly detection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I presented some of my recent research at PyData NYC this past November (they
    still have not posted videos online unfortunately). I also coded up a [tutorial
    on Avocado Price Forecasting.](https://medium.com/towards-data-science/deep-time-series-forecasting-with-flow-forecast-part-1-avocado-prices-276a59eb454f)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are using GitHub discussions! Be sure to check out our [discussions](https://github.com/AIStream-Peelout/flow-forecast/discussions)
    or start a new one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s jump into some field updates.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transformer Related Research: Autoformer, Pyraformer, Fedformer, etc, their
    effectiveness and problems**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/58fe2668eb77396951ea8062579fe752.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure from page 3 of [Are Transformers Really Effective for Time Series Forecasting?](https://arxiv.org/pdf/2205.13504.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: '***Summary***: The transformer family of time series forecasting architectures
    has continued to grow with models such as the Autoformer (Neurips 2021), [Pyraformer](https://openreview.net/forum?id=0EXmFzUn5I)(ICLR
    2022), [Fedformer (ICML 2022)](https://arxiv.org/abs/2201.12740), [EarthFormer](https://arxiv.org/abs/2207.05833)
    (Neurips 2022), and [Non-Stationary Transformer](https://openreview.net/forum?id=ucNDIDRNjjv)
    (Neurips 2022). However, the ability of these models to accurately forecast data
    and outperform existing methods remains in question particularly in light of new
    research (which we will discuss on its in a bit).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Autoformer](https://arxiv.org/abs/2106.13008):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eace1323199ab2c9f6c2840be036809d.png)'
  prefs: []
  type: TYPE_IMG
- en: Architecture of the Autoformer model (Neurips 2021). The model features a seasonal
    decomposition mechanism which aims to create seasonal and cyclical representations
    of the temporal data. The decoder ingests three items . The decoder outputs a
    seasonal part and trend part that then get added together into a prediction. Figure
    from page 2 of Autoformer paper.
  prefs: []
  type: TYPE_NORMAL
- en: Autoformer expands and improves the performance of the Informer model. Autoformer
    features an auto-correlation mechanism which enables the model to better learn
    temporal dependencies than standard attention. It aims to accurately decompose
    the the trend and seasonal components of temporal data. You can find full code
    for the paper [here.](https://github.com/thuml/Autoformer)
  prefs: []
  type: TYPE_NORMAL
- en: 'Pyraformer: In this paper the authors introduce “pyramidal attention module
    (PAM) in which the inter-scale tree structure summarizes features at different
    resolutions and the intra-scale neighboring connections model the temporal dependencies
    of different ranges.”'
  prefs: []
  type: TYPE_NORMAL
- en: '[Fedformer:](https://arxiv.org/abs/2201.12740) This model focuses on capturing
    the global trend in the time series data. The authors, propose a seasonal trend
    decomposition module that aims to capture the global character of the time series.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Earthformer: Perhaps the most unique of this “set” of papers, the earthformer
    specifically focuses on forecasting earth systems such as weather, climate, and
    agriculture. This paper features a new earth cuboid attention mechanism. I’m hopeful
    of the potential this paper has for my research on stream and flash flood forecasting,
    where many of the classic transformers have failed.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Non-Stationary Transformer](https://openreview.net/forum?id=ucNDIDRNjjv):
    This is the most recent publication in the group of transformer for forecasting
    papers. The authors aim to better adapt transformers for handling non-stationary
    time series. They employ two mechanisms: de-stationary attention and a series
    stationarization mechanism. These mechanisms can be plugged into any existing
    transformer model and the authors test plugging them into the Informer, Autoformer,
    and the Vanilla Transformer where they all boost performance (in the appendix
    they also show it boosts Fedformer performance).'
  prefs: []
  type: TYPE_NORMAL
- en: '***Discussion/Evaluation***: Similar to the Informer all these models (with
    the exception of Earthformer) were evaluated on the electrical (ETTh), traffic,
    exchange and weather datasets. These models primarily evaluate based on Mean Squared
    Error (MSE) and the Mean Absolute Error (MAE) metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/061d793a5ba3b5ef1a31597a09fc38ed.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting results from Non-Stationary Transformers compared to other models.
    From page 7 of [Non-Stationary Transformers](https://openreview.net/pdf?id=ucNDIDRNjjv).
  prefs: []
  type: TYPE_NORMAL
- en: In the future I hope that all authors of transformer papers compare their model
    to simpler methods like D-Linear (which will talk about later) and even a basic
    LSTM/GRU. Also they should go beyond some of these standard datasets as I haven’t
    seen good performance on other time series related datasets. For instance, I had
    immense problems getting the Informer to accurately forecast river flows and it
    generally performed poorly compared to a LSTM or a even a vanilla transformer
    model. Since unlike with computer vision where image dimensions at least stay
    constant, time series data can differ immensely in terms of length, periodicity,
    trend, and seasonality a larger range of datasets is needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the [comments on OpenReview for the Non-Stationary Transformer one of the
    reviewers echoed these concerns](https://openreview.net/forum?id=ucNDIDRNjjv),
    however it was unfortunately shot-down in the final meta-review:'
  prefs: []
  type: TYPE_NORMAL
- en: “As the model is in the Transformer space, and transformers have previously
    been shown to be state of the art on a number of tasks, I do not find it necessary
    to compare against other ‘families’ of methods.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I personally think this is an extremely problematic argument and has led to
    the lack of applicability of research in the real-world. If certain models perform
    well in NLP we are supposed to just assume that they will perform well in time
    series? Also, if there is an incorrect evaluation protocol but it was the standard
    in previous publications then it should be repeated? As someone who has valued
    state of the art approaches and innovative models in practice, this is the exact
    type of thing that will make me look like a complete idiot when I spend months
    trying to get a supposedly “good” model to work only to be out performed by linear
    regression.
  prefs: []
  type: TYPE_NORMAL
- en: That said I don’t necessarily think this paper should’ve been rejected or singled
    out as all the transformer papers are equally guilty of limited evaluation. Rather
    we should from the start require more rigorous comparisons and clear illuminations
    of shortcomings. A complex model “family” might not always outperform simple models
    initially but that needs to be clearly noted in the paper and not glossed over
    or simply assumed not to be case because it has previously performed well in other
    domains.
  prefs: []
  type: TYPE_NORMAL
- en: On another happier note I was somewhat impressed with the evaluation of Earthformer.
    Earthformer was evaluated on the moving the “MovingMNIST dataset and a newly proposed
    chaotic N-body MNIST dataset” which the authors used to verify the effectiveness
    of the cuboid attention. They then evaluated it for precipitation now-casting
    and el/nino cycle forecasting. I think that this is a good example integrating
    physical knowledge into a model architecture with the cuboid attention and then
    designing good sub-tests.
  prefs: []
  type: TYPE_NORMAL
- en: '***Flow Forecast integration***: Since many of these models follow the same
    basic format of Informer the work to port them to FF is not that extensive. However,
    at certain point we have to wonder how much better these newer transformer models
    are on real-world data. Code consolidation is another area for myself and other
    maintainers to think about. Previously we have copied large swathes of code from
    authors implementations and tried to preserve that as much as possible (so as
    not to introduce new errors). That said we will likely add several of the models
    over the next couple of months (Fedformer, Non-Stationary Transformer).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Are Transformers Effective for Time Series Forecasting (2022)?**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ecd3a72e2c9d6405caad0a4b48cebe3f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [Are Transformers Effective for Time Series Forecasting](https://arxiv.org/pdf/2205.13504.pdf)
    page. 2\. TLDR is basically simple models outperform pretty much every transformer
    model up-to the Fedformer model (Non-stationary transformer was a later work though
    simple model would’ve likely out performed it as well. Possibly Non-Stationary
    Transformer + Fedformer might beat simple models in certain cases but that is
    a very big model compared to a simple one).
  prefs: []
  type: TYPE_NORMAL
- en: 'This paper explores the ability of transformer to forecast data versus baseline
    methods. The results somewhat reaffirm what I have seen in many of my own experiments
    that transformers often perform worse than simpler models and are difficult to
    tune. A couple interesting points within the paper include:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors gradually replace self-attention with basic linear layers and find:
    “Surprisingly, the performance of Informer grows with the gradual simplification,
    indicating the unnecessary of the self-attention scheme and other complex modules
    at least for existing LTSF benchmarks”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The authors also investigate whether increasing the look-back window improves
    the transformer performance and find that: “the performance of the SOTA Transformers
    drops slightly, indicating these models only capture similar temporal information
    from the adjacent time series sequence.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authors also explored whether positional embedding really capture the temporal
    order of the time series well. They do this by randomly shuffling the input sequence
    into the transformer. They found on several datasets this shuffling did not impact
    results (which is obviously quite troubling).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Discussion:*** Over the last several years I have run countless time-series
    experiments with transformer models and in the vast majority of cases the results
    were not great. For the longest time I assumed I must be doing something wrong
    or missing some small implementation detail. After-all these were supposed the
    next SOTA model just like in NLP. So it is nice to see some research that shows
    my experiments weren’t flawed (at least not entirely). However, it still leaves
    a load of lasting questions such as where to head next? If a simple model outperforms
    transformers should we continue to use them? Are all transformers inherently flawed
    or is it just the current mechanism? Should we return back to architectures like
    LSTMs, GRUs or simple feed forward models? These are questions I do not know the
    answer to and it remains to be seen the overall impact of the paper. As of now
    I think that the answer might be to take a step back and focus on learning effective
    time series representations. After-all initially BERT in the NLP context succeeded
    by forming good representations.'
  prefs: []
  type: TYPE_NORMAL
- en: That said I don’t think we should view tranformers for time-series as entirely
    dead. The Fedformer did perform quite close to the simple model benchmarks and
    did better with the various ablation shuffling tasks. I’ve also seen anecdotally
    that while transformers often struggle with forecasting in many cases their internal
    representations of the data can be quite good. I think more is needed to see the
    disconnect between the internal representation and the actual forecasting output.
    Also, as the authors suggest improving the positional embeddings could play a
    key role in improving overall performance. Finally, as we will see below there
    was a recent transformer based model that performed very well on a wide array
    of anomaly detection datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '***Flow Forecast integration:*** The paper did introduce a number of simpler
    models that serve as good benchmarks against complicated transformer methods.
    Since the models are simple they shouldn’t require that much effort to add to
    our framework. We will likely add these to FF over the next couple months. In
    the meantime you can find full code for the paper here.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Anomaly Transformer (ICLR Spolight 2022)**](https://arxiv.org/abs/2110.02642)**:**
    As evidenced above quite a bit of research has focused on applying the transformers
    to forecasting, however there has been comparatively little research anomaly detection.
    This paper introduces a (unsupervised) transformer to detect anomalies. The model
    utilizes specially constructed anomaly attention mechanism in conjunction with
    a minmax strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/838ba8e2f228d04a6f09a13de071eb6c.png)'
  prefs: []
  type: TYPE_IMG
- en: The authors develop a special form of attention specifically for anomaly detection.
    From Anomaly Transformer paper page 4.
  prefs: []
  type: TYPE_NORMAL
- en: '*Evaluation*: This paper evaluates the performance of the model on five real
    world datasets including Server Machine Dataset, Pooled Server Metrics, Soil Moisture
    Active Passive, and NeurIPS-TS (which itself consists of five different datasets).
    While one might be tempted to view this model skeptically particularly with respect
    to the above mentioned transformers, this evaluation was fairly rigorous. Neurips-TS
    was a recent dataset that was specifically created to provide a more rigorous
    evaluation of anomaly detection models (see more in the datasets section below).
    Therefore it does seem that this model actually improves performance versus simpler
    anomaly detection models.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Discussion*: Here the authors present a unique unsupervised transformer that
    performs well on a plethora of anomaly detection datasets. To me it was one of
    the more promising papers in the time series transformer space over the last couple
    years.'
  prefs: []
  type: TYPE_NORMAL
- en: In many ways it seems to make sense to first create models to effectively classify
    and detect anomalies in the temporal space and only later to focus on forecasting
    data. In my general experience forecasting is more challenging to than classification
    and even anomaly detection as you are trying to predict a huge possible range
    of values multiple time steps into the future. I’m kind of surprised so much research
    has focused on forecasts and ignored classification or anomaly detection given
    they seem to be a more natural first step with transformers.
  prefs: []
  type: TYPE_NORMAL
- en: '*FF Integration:* Definitely in the future I hope to add the model to FF as
    right now we have very limited anomaly detection models. However, adding the paper
    will likely entail writing a separate data-loader as the model is unsupervised
    and possibly adding additional checks to our main training loop (FF training loop
    assume both an X, Y value will be returned by the data-loader). You can however
    see the full code implementation for the model here.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**WaveBound: Dynamic Error Bounds for Stable Time Series Forecasting**](https://openreview.net/forum?id=vsNQkquutZk)
    **(Neurips 2022):**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary: This paper introduces a new form of regularization that aims to improve
    training of deep time series forecasting models (particularly the above mentioned
    transformers).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation: The authors evaluate their model in conjunction by plugging into
    existing transformer models + LSTNet. They find that it significantly improves
    performance in most cases. Though they only test models through the Autoformer
    and not more recent models like Fedformer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Discussion: New forms of regularization or loss functions are always useful
    as they can often plug-in to any existing time-series model to improve performance.
    Also I’m beginning to think that maybe if you combined Fedformer + Non-Stationary
    Mechanism + Wavebound you might be able to beat the simple D-Linear in performance
    :). Not great but it is a start but hey it might mean transformers aren’t completely
    dead with sufficient boosting.'
  prefs: []
  type: TYPE_NORMAL
- en: 'FF Integration: The authors do provide an implementation of the code. I like
    the fact that it can work with both RNNs and Transformers (since our code-base
    contains both). However, we probably won’t get around to adding it for awhile
    as a number of the other models are higher priority. But we will add it to our
    roadmap. If you have time You also can always open a PR yourself!'
  prefs: []
  type: TYPE_NORMAL
- en: Time Series Representations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the news might seem somewhat bleak with respect to transformers and forecasting,
    there have been a number of advances in creating useful time series representations.
    Some of these developments overlap and parallel the transformer related research
    but they have the added benefit of being primarily focused on the representations
    and not the final forecasting result. Altogether I think this is an impressive
    new area in the field of deep learning for time series that should be explored
    in more depth.
  prefs: []
  type: TYPE_NORMAL
- en: '[**TS2Vec: Towards Universal Representation of Time Series (AAAI 2022)**](https://arxiv.org/abs/2106.10466)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary: TS2Vec is a universal framework for learning time series representations/embeddings.
    The paper itself is already somewhat dated, however it really started this trend
    of time series representation learning papers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Discussion/Evaluation: Evaluation is done both for using the representations
    for forecasting and anomaly detection. The model outperforms many models such
    as the Informer and Log Transformer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'FF Integration: We do plan on adding this paper as a baseline time-series embedding
    method likely within the next two months. Although it has been out performed by
    more recent papers its simplicity and adaptability is still nice.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Learning Latent Seasonal-Trend Representations for Time Series Forecasting**](https://openreview.net/forum?id=C9yUwd72yy)
    **(Neurips 2022):**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dc231c643dc095d958ce202c213e4db2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image of the proposed LaST architecture (page 3). The model utilizes both a
    trend and seasonal encoder + decoder which create two separate representations
    that then get fed into a simple MLP predictors for the forecasting tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '*Summary*: The authors create a model (LAST) to create disentangled representations
    of both the seasonality and trends using variational inference.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation: The authors evaluate their model on down-stream forecasting tasks
    similar to the Informer, Autformer, and other models etc. They do this by adding
    a predictor (see B in figure above) on to the representations. They also provide
    interesting plots that show visualizations of the representations. The model outperforms
    the Autoformer at several forecasting tasks as well as TS2Vec and CoST at pretty
    much all of them. It also looks like on some of the forecasting tasks it may out-perform
    the D-Linear model mentioned above.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/51a8117521e4588c208d9fd21a9b5c92.png)'
  prefs: []
  type: TYPE_IMG
- en: An interesting diagram from the paper pg 9\. We can see the differences in learned
    visualized representations of the seasonality/trend.
  prefs: []
  type: TYPE_NORMAL
- en: '*Discussion*: Though at the moment I remain somewhat skeptical of models that
    only evaluate on the standard forecasting tasks, I do like that this model focuses
    on the representations rather than the forecasting task itself. If we look at
    some of the diagrams shown in the paper we can see that the model does seem to
    learn to distinguish between the seasonality and trend. It would be interesting
    to see the visualizations of representations of different datasets also embedded
    into the same space and if they show substantial differences.'
  prefs: []
  type: TYPE_NORMAL
- en: '*FF implementation*: In all likelihood we will add TS2Vec and before adding
    this model as that model is simpler. However, I hope to add this model at some
    point down the line as it does provide two good separate representations of the
    different temporal components. I’d guess we will probably add the model within
    the next two months.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations
    for Time Series Forecasting**](https://openreview.net/forum?id=PilZY3omXV2) **(ICLR
    2022):**'
  prefs: []
  type: TYPE_NORMAL
- en: This was a paper that appeared earlier in 2022 at ICLR that is quite similar
    to LaST in learning seasonal and trend representations. As LaST for the most part
    has already superseded it in performance I will not go into that much description.
    But the link is above for those that want to read it.
  prefs: []
  type: TYPE_NORMAL
- en: Other interesting papers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[**Domain Adaptation for Time Series Forecasting via Attention Sharing**](https://arxiv.org/abs/2102.06828)
    **(ICML 2022):**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8a86171077203a5b061e73efe88f6d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure from: Domain Adaptation for Time Series Forecasting Via Attention Sharing
    paper page 3.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary: Forecasting is challenging for DNNs when there is a lack of training
    data. I remember when I worked on COVID-19 forecasting the lack of temporal history
    initially made forecasting very difficult. Therefore I’m hopeful to see more papers
    start to address time series transfer learning scenarios. This paper utilizes
    shared attention layers for domains with rich data and then individual modules
    for the target domain(s).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation: The proposed model is evaluated with both synthetic and real datasets.
    In the synthetic setting they test both cold-start learning and few-shot learning
    and find their model outperforms a vanilla transformer and DeepAR. For the real
    word datasets they take a subset of the Kaggle retail dataset and electric datasets.
    The model greatly outperforms the baselines in these experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Discussion: Cold start, few shot and limited learning are extremely important
    topics yet few papers address with respect to time series. This model provides
    an important step in addressing some of these problems. That said I think they
    could have evaluated on more different limited real world datasets and compared
    against more benchmark models. Also it would be nice if the model was more easily
    to “plug-in” into existing architectures. Something nice about fine-tuning or
    regularization is that you can do it with any architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: 'FF Implementation: We already have some functionality in FF for transfer learning
    which greatly aided us when providing early insights into COVID. Adding this model
    could help provide a more, however the overhead looks high and the model can not
    easily plug into existing models in our ecosystem.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**When to Intervene: Learning Optimal Intervention Policies for Critical Events**](https://openreview.net/pdf?id=rP9xfRSF4F)
    **(Neurips 2022):**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Summary*: While not a “typical” time series paper I choose to include it on
    this list because at the of end of the day most companies are not looking to just
    forecast values or detect anomalies but to “respond” in someway. This article
    focuses on finding the optimal time to intervene before a machine fails. This
    is referred to as OTI or optimally timed intervention. The author'
  prefs: []
  type: TYPE_NORMAL
- en: 'Eval: Of course one of the problems with evaluating OTI is the problem is the
    accuracy of the underlying survival analysis (if it is incorrect the eval will
    also be incorrect). The authors evaluate their model against two static thresholds
    and find that it performs well. They plot the expected performance of different
    policies and the hit to miss ratio.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Discussion: This is an interesting problem and the authors propose a novel
    solution, however to me the evaluation was a little lacking. One of the reviwers
    notes that “I think that the experiments could be a lot more compelling if there
    were a plot showing the trade-off between the probability of failure and the expected
    time to intervene so that one could see visually what shape this trade-off curve
    takes”'
  prefs: []
  type: TYPE_NORMAL
- en: 'FF Integration: Both OTI and reinforcement learning on temporal data are interesting
    future potential directions to support in Flow Forecast. Unfortunately at the
    moment they are not a high priority as we are trying to make the framework rock-solid
    at forecasting, anomaly detection, and classification first. However, I definitely
    think in the future we could look into creating a more “actionable” framework
    to better support decision making.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**FiLM: Frequency improved Legendre Memory Model for Long-term Time Series
    Forecasting**](https://openreview.net/forum?id=zTQdHSQUQWc) **(Neurips 2022):**
    C[ode](https://github.com/tianzhou2011/FiLM/).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Adjusting for Autocorrelated Errors in Neural Networks for Time Series (Neurips
    2021)**: Code here.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Dynamic Sparse Network for Time Series Classification: Learning What to
    “See”**](https://openreview.net/forum?id=ZxOO5jfqSYw) **(Neurips 2022):**'
  prefs: []
  type: TYPE_NORMAL
- en: (Fairly) Recent Datasets/Benchmarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[**Monash Time Series Forecasting Archive**](https://forecastingdata.org/)
    **(Neurips 2021):** Lately we have seen many deep time series all evaluated on
    the same datasets. While this is okay for basic benchmarking they often do not
    hold up on differing temporal tasks. This archive aims to form a “master list”
    of different time series datasets and provide a more authoritative benchmark.
    The repository contains over 20 different datasets spanning across a wide variety
    of industries including health, retail, ride-share, demographic, and many-more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Subseasonal Forecasting Microsoft**](https://www.microsoft.com/en-us/research/project/subseasonal-climate-forecasting/)
    **(2021):** This is a publicly released dataset by Microsoft that aims to facilitate
    the use of machine learning to improve subseasonal forecasting (e.g. two to six
    weeks in the future). Subseasonal forecasting helps government agencies better
    prepare for weather events as well as farmer’s decisions. Microsoft included several
    benchmark models for the task and in general deep learning models performed quite
    poorly compared to other methods. The best DL model turned out to be a simple
    feed-forward model and the Informer performed awfully.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Revisiting Time Series Outlier Detection: Definitions and Benchmarks**](https://openreview.net/forum?id=r8IvOsnHchr)This
    paper critiques many existing anomaly/outlier detection datasets and proposes
    35 new synthetic datasets and 4 real world datasets for bench-marking purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A lot has happened in the past two years in the deep-learning for time series
    space. We have seen the rise and possibly the fall of transformers for time series
    forecasting. We have seen the rise of the time series embedding methods and additional
    breakthroughs in anomaly detection as well as classification. Flow Forecast has
    continued to grow as a framework and we hope to continue to incorporate the latest
    ground-breaking research.
  prefs: []
  type: TYPE_NORMAL
- en: We hope to add more interpretability, visualization, and benchmark methods so
    researchers and industry data-scientists alike can see where their model performs
    and where exactly the model breaks-down in performance. Additionally, we hope
    to add more forms of regularization, preprocessing, and transfer learning to boost
    performance. Maybe transformers are good for time series forecasting or maybe
    they aren’t but we will continue to support both them and their alternatives!
    As always feel free to leave any questions or insights below. Thank you for reading
    until the end.
  prefs: []
  type: TYPE_NORMAL
