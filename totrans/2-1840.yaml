- en: SHAP for Binary and Multiclass Target Variables
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二元和多类目标变量的 SHAP
- en: 原文：[https://towardsdatascience.com/shap-for-binary-and-multiclass-target-variables-ff2f43de0cf4](https://towardsdatascience.com/shap-for-binary-and-multiclass-target-variables-ff2f43de0cf4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/shap-for-binary-and-multiclass-target-variables-ff2f43de0cf4](https://towardsdatascience.com/shap-for-binary-and-multiclass-target-variables-ff2f43de0cf4)
- en: A guide to the code and interpreting SHAP plots when your model predicts a categorical
    target variable
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提供一个指南，讲解当模型预测分类目标变量时如何编写代码和解读 SHAP 图
- en: '[](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page-----ff2f43de0cf4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)
    ·9 min read·Sep 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ff2f43de0cf4--------------------------------)
    ·9 分钟阅读·2023年9月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b06abc866e3a7134fc4fddbaa12d53a3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b06abc866e3a7134fc4fddbaa12d53a3.png)'
- en: Photo by [Nika Benedictova](https://unsplash.com/@nika_benedictova?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Nika Benedictova](https://unsplash.com/@nika_benedictova?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'SHAP values give the contribution of a model feature to a prediction. This
    is also true when we use SHAP for classification. Except, for **binary target
    variables,** we interpret these values in terms of **log odds**. For **multiclass
    targets**, we use **softmax**. We will:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 值展示了模型特征对预测的贡献。这在我们使用 SHAP 进行分类时也同样适用。不同的是，对于**二元目标变量**，我们用**对数几率**来解释这些值。对于**多类目标**，我们使用**softmax**。我们将：
- en: Discuss these interpretations in more depth
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更深入地讨论这些解释
- en: Give the code for displaying SHAP plots for classification problems
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供用于显示分类问题的 SHAP 图的代码
- en: Explore new ways of aggregating SHAP values for multiclass targets
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索聚合 SHAP 值的新方法以适应多类目标
- en: 'You can also watch this video on the topic:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以观看关于该主题的视频：
- en: Previous SHAP tutorial
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 之前的 SHAP 教程
- en: We continue on from a previous [SHAP tutorial](/introduction-to-shap-with-python-d27edc23c454).
    It goes into depth on SHAP plots for a continuous target variable. You will see
    that these plots and their insights are similar for categorical target variables.
    You can also find the full project on [GitHub](https://github.com/conorosully/SHAP-tutorial).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续之前的 [SHAP 教程](/introduction-to-shap-with-python-d27edc23c454)。它深入探讨了连续目标变量的
    SHAP 图。你将发现这些图及其见解对于分类目标变量也是类似的。你还可以在 [GitHub](https://github.com/conorosully/SHAP-tutorial)
    上找到完整的项目。
- en: '[](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----ff2f43de0cf4--------------------------------)
    [## Introduction to SHAP with Python'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----ff2f43de0cf4--------------------------------)
    [## 使用 Python 进行 SHAP 介绍'
- en: 'How to create and interpret SHAP plots: waterfall, force, mean SHAP, beeswarm
    and dependence'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何创建和解读 SHAP 图：瀑布图、力图、均值 SHAP、蜜蜂散点图和依赖图
- en: towardsdatascience.com](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----ff2f43de0cf4--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/introduction-to-shap-with-python-d27edc23c454?source=post_page-----ff2f43de0cf4--------------------------------)
- en: To summarise, we used SHAP to explain a model built using the [abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone).
    This has **4,177** instances and you can see examples of the features below. We
    use the **8** features to predict y — the number of **rings** in the abalone’s
    shell. The rings are related to the age of the abalone. In this tutorial, we will
    bin y into different groups to create binary and multiclass target variables.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们使用SHAP解释了基于[海螺数据集](https://archive.ics.uci.edu/ml/datasets/abalone)构建的模型。该数据集包含**4,177**个实例，下面可以看到特征的示例。我们使用**8**个特征来预测y——海螺壳上的**环数**。环数与海螺的年龄有关。在本教程中，我们将y分成不同的组，以创建二元和多类目标变量。
- en: '![](../Images/4799522c7ec972bf1d1bb49fa9d3bcd5.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4799522c7ec972bf1d1bb49fa9d3bcd5.png)'
- en: 'X feature matrix (source: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/abalone))
    (licence: CC0: Public Domain)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: X特征矩阵（来源：[UCI机器学习库](https://archive.ics.uci.edu/ml/datasets/abalone)）（许可证：CC0：公共领域）
- en: Binary target variable
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二元目标变量
- en: For the continuous target variable, we saw that each instance had 8 SHAP values
    — one for every model feature. As seen in **Figure 1**, if we sum these and the
    average prediction **E[f(x)]** we get the prediction for that instance **f(x)**.
    For binary target variables, we have the same property. The difference is we interpret
    the values in terms of log odds of a *positive* prediction.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于连续目标变量，我们发现每个实例都有8个SHAP值——每个模型特征一个。如**图1**所示，如果我们将这些值与平均预测值**E[f(x)]**相加，我们就得到了该实例的预测值**f(x)**。对于二元目标变量，我们也有相同的性质。区别在于我们将值解释为*正*预测的对数几率。
- en: '![](../Images/1cbd2c5718130eba5887e9d805533d6b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cbd2c5718130eba5887e9d805533d6b.png)'
- en: 'Figure 1: interpreting SHAP values in terms of log-odds (source: author)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：根据对数几率解释SHAP值（来源：作者）
- en: 'To understand this let’s dive into a SHAP plot. We start by creating a binary
    target variable (line 2). We create two groups based on y:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，让我们深入研究SHAP图。我们从创建一个二元目标变量（第2行）开始。我们基于y创建了两个组：
- en: '**1** if the abalone has an above-average number of rings'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1** 如果海螺的环数高于平均水平'
- en: '**0** otherwise'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**0** 否则'
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We use this target variable and the 8 features to train an **XGBoost classifier**
    (lines 2–3). This model had an accuracy of **96.6%.**
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个目标变量和8个特征来训练一个**XGBoost分类器**（第2-3行）。该模型的准确率为**96.6%。**
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We now calculate the SHAP values (lines 2–3). We output the shape of this object
    (line 5) which gives **(4177, 8)**. So, just like the continuous target, we have
    one SHAP value per prediction and feature. Later, we will see how this is different
    for a multiclass target.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在计算SHAP值（第2-3行）。我们输出这个对象的形状（第5行），得到**(4177, 8)**。因此，与连续目标变量一样，我们每个预测和特征都有一个SHAP值。稍后，我们将看到这对于多类目标变量是如何不同的。
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We display a waterfall plot for the first instance (line 6). We can see the
    result in **Figure 2**. Notice the code is the same as for the continuous variable.
    Except for the numbers, the waterfall plot also looks similar.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为第一个实例显示了一个瀑布图（第6行）。我们可以在**图2**中看到结果。注意，代码与连续变量的代码相同。除了数字外，瀑布图也看起来类似。
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now **E[f(x)] = -0.789** gives the average predicted log odds across all 4,177
    abalones. That is the log odds of a positive (1) prediction. For this specific
    abalone, the model predicted a probability of **0.3958** that it had an above-average
    number of rings (i.e. **P = 0.3958**). This gives us a predicted log odds of **f(x)
    = ln(0.3958/(1–0.3958)) = -0.423.**
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在**E[f(x)] = -0.789** 给出了所有4,177个海螺的平均预测对数几率。这是正预测（1）的对数几率。对于这个特定的海螺，模型预测其有**0.3958**的概率具有高于平均水平的环数（即**P
    = 0.3958**）。这给出了预测的对数几率**f(x) = ln(0.3958/(1–0.3958)) = -0.423**。
- en: '![](../Images/544e0423a692d47a2dae1d6122db6b84.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/544e0423a692d47a2dae1d6122db6b84.png)'
- en: 'Figure 2: waterfall plot with a binary target variable (source: author)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：带有二元目标变量的瀑布图（来源：作者）
- en: So, the SHAP values give the difference between the predicted log odds and the
    average predicted log odds. Positive SHAP values increase the log odds. For example,
    shucked weight increased the log odds by **1.32**. In other words, this feature
    has increased the probability that the model will predict an above-average number
    of rings. Similarly, negative values decrease the log odds.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，SHAP值表示预测对数几率与平均预测对数几率之间的差异。正的SHAP值增加对数几率。例如，剥壳重量增加了**1.32**的对数几率。换句话说，这个特征增加了模型预测环数高于平均水平的概率。类似地，负值则减少对数几率。
- en: We can also aggregate these values in the same way as before. The good news
    is the interpretations of the plots like the beeswarm or mean SHAP will be the
    same. Just remember that we are dealing with log odds. Now let’s see how this
    interpretation changes for multiclass target variables.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以以之前相同的方式聚合这些值。好消息是，像蜜蜂散点图或均值 SHAP 这样的图形解释将保持不变。只需记住，我们处理的是对数赔率。现在让我们看看这种解释如何在多类别目标变量中发生变化。
- en: Multiclass target variable
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类别目标变量
- en: We start by creating a new target variable (**y_cat**) with 3 categories — young
    (0), medium (1) and old (2). As before, we train an XGBoost classifier to predict
    this target variable (lines 5–6).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过创建一个新的目标变量 (**y_cat**) 来开始，该变量有 3 个类别——年轻（0）、中等（1）和老（2）。如前所述，我们训练了一个 XGBoost
    分类器来预测这个目标变量（第 5–6 行）。
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For this model, we can no longer talk about a “positive prediction”. We can
    see this if we output the predicted probability for the first instance (line 2).
    This gives us **[0.2562, 0.1571, 0.5866]**. In this case, the 3rd probability
    is the highest and so the abalone is predicted to be old (2). What this means
    for SHAP, is we can no longer only consider values for the positive class.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个模型，我们不能再谈论“正预测”。如果我们输出第一个实例的预测概率（第 2 行），我们可以看到这一点。这给我们 **[0.2562, 0.1571,
    0.5866]**。在这种情况下，第三个概率最高，因此海洋蜗牛被预测为老（2）。这对 SHAP 意味着我们不能再只考虑正类的值。
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We can see this when we calculate the SHAP values (lines 2–3). The code is the
    same as for the binary model. Yet, when we output the shape (line 5) we get **(4177,
    8, 3)**. We now have one SHAP value for every instance, feature and *class*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们计算 SHAP 值时可以看到这一点（第 2–3 行）。代码与二分类模型相同。然而，当我们输出形状（第 5 行）时，我们得到 **(4177, 8,
    3)**。现在我们为每个实例、特征和*类别*都有一个 SHAP 值。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As a result, we have to display the SHAP values for each class in separate waterfall
    plots. We do this for the first instance in the code below.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们必须在单独的瀑布图中显示每个类别的 SHAP 值。我们在下面的代码中为第一个实例执行此操作。
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Figure 3** gives the waterfall plot for class 0\. The values explain how
    each feature has contributed to the model prediction *for this class*. That is
    compared to the average prediction for this class. We saw that the probability
    for this class was relatively low (i.e. **0.2562**). We can see that the shucked
    weight feature has made the most significant contribution to this low probability.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3** 给出了类别 0 的瀑布图。该图解释了每个特征如何对模型预测*为此类别*做出贡献。也就是说，与该类别的平均预测相比。我们看到该类别的概率相对较低（即
    **0.2562**）。我们可以看到，去壳重量特征对这一低概率做出了最显著的贡献。'
- en: '![](../Images/121bedc604cfe7ada1261f23304a1dbd.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/121bedc604cfe7ada1261f23304a1dbd.png)'
- en: 'Figure 3: waterfall plot for class 0 (source: author)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：类别 0 的瀑布图（来源：作者）
- en: '**Figure 4** gives the output for the other classes. You will notice that **f(x)
    = 1.211** is the largest for class 2\. This makes sense as we saw the probability
    for this class was also the largest (**0.5866)**. When analysing the SHAP values
    for this instance, it may make sense to focus on this waterfall plot. It is the
    class prediction for this abalone.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4** 给出了其他类别的输出。你会注意到 **f(x) = 1.211** 在类别 2 中是最大的。这是有道理的，因为我们看到这个类别的概率也是最大的（**0.5866**）。在分析该实例的
    SHAP 值时，可能要重点关注这个瀑布图。这是该海洋蜗牛的类别预测。'
- en: '![](../Images/037fb033008728d69202eb3cde2651c0.png)![](../Images/c3444e802e8381e160d964070139bbd5.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/037fb033008728d69202eb3cde2651c0.png)![](../Images/c3444e802e8381e160d964070139bbd5.png)'
- en: 'Figure 4: waterfall plot for classes 1 and 2 (source: author)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：类别 1 和 2 的瀑布图（来源：作者）
- en: Interpreting values with Softmax
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Softmax 解释值
- en: As we are now dealing with multiple classes, **f(x)** is given in terms of softmax.
    We can convert softmax values to probability using the function below. **fx**
    gives the three f(x) values in the above waterfall plots. The result is **[0.2562,
    0.1571, 0.5866]**. The same predicted probabilities we saw for instance 0!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在处理的是多个类别，**f(x)** 是以 softmax 形式给出的。我们可以使用下面的函数将 softmax 值转换为概率。**fx**
    给出了上述瀑布图中的三个 f(x) 值。结果是 **[0.2562, 0.1571, 0.5866]**。这就是我们看到的实例 0 的预测概率！
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Aggregating multiclass SHAP values
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合多类别 SHAP 值
- en: These SHAP values can be aggregated using any of the SHAP plots. However, like
    the waterfall, there will be individual plots for each class. Analysing these
    can be tedious. Especially if you have many categories in your target variable.
    So we’ll end by discussing some other approaches to aggregation.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些SHAP值可以使用任何SHAP图进行汇总。然而，像瀑布图一样，每个类别都会有单独的图。分析这些可能会很繁琐，尤其是当目标变量中有很多类别时。因此，我们将讨论一些其他的汇总方法。
- en: The first is a version of the mean SHAP plot. We calculate the absolute mean
    of the shap values for each class separately (lines 2–4). We then create a bar
    chart with one bar for each class and feature.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是平均SHAP图的一个版本。我们分别计算每个类别的SHAP值的绝对平均值（第2–4行）。然后我们创建一个条形图，每个类别和特征都有一个条形。
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can see the output in **Figure 5**. One thing to mention is that each bar
    gives the average over all the predictions. Yet, the actual predicted class will
    be different in each case. So, you may end up skewing the means with SHAP values
    that do not explain the predicted class. This is potentially why we are seeing
    smaller means for the medium class.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在**图5**中看到输出。有一点需要提到的是，每个条形图显示的是所有预测的平均值。然而，实际的预测类别在每种情况下都会有所不同。因此，您可能会因为SHAP值不能解释预测类别而使均值产生偏差。这可能是我们看到中等类别均值较小的原因。
- en: '![](../Images/b45c9a3d850d68a1e192e1fd0dcb13f0.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b45c9a3d850d68a1e192e1fd0dcb13f0.png)'
- en: 'Figure 5: mean SHAP for each class in a multiclass target variable (source:
    author)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：多分类目标变量中每个类别的平均SHAP值（来源：作者）
- en: To get around this, we can focus on the SHAP values for the predicted class.
    We start by getting the predicted class for each instance (line 2). We create
    a new set of shap values (**new_shap_values**). This is done by looping over the
    original values and only selecting the set that corresponds to the prediction
    for that instance (lines 5–7).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这个问题，我们可以集中在预测类别的SHAP值上。我们首先获取每个实例的预测类别（第2行）。我们创建一组新的SHAP值（**new_shap_values**）。这是通过遍历原始值并仅选择与该实例预测相对应的那一组值来完成的（第5–7行）。
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We then replace the SHAP values in the original object (line 2). Now, if we
    output the shape we get (4177, 8). In other words, we are back to one set of SHAP
    values per instance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将原始对象中的SHAP值替换掉（第2行）。现在，如果我们输出形状，得到的是(4177, 8)。换句话说，我们回到了每个实例一组SHAP值的情况。
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: A benefit of this approach is it is easy to use the built-in SHAP plots. For
    example, the mean SHAP plot in **Figure 6**. We can interpret these values as
    the average contribution of a feature to the predicted class.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个好处是可以轻松使用内置的SHAP图。例如，**图6**中的平均SHAP图。我们可以将这些值解读为特征对预测类别的平均贡献。
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/37bebcf87340eb6d41798e45371d8fbf.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37bebcf87340eb6d41798e45371d8fbf.png)'
- en: 'Figure 6: mean SHAP for predicted class in a multiclass target variable (source:
    author)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：多分类目标变量中预测类别的平均SHAP值（来源：作者）
- en: We can also use the beeswarm. Yet, notice we do not see a clear relationship
    between the SHAP values and feature values. This is because the features will
    have different relationships depending on the predicted class. Older abalone will
    be bigger. So, for example, large shell weights will lead to a higher probability
    of an old (2) prediction. The opposite is true for young (0) predictions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用beeswarm图。然而，注意到我们没有看到SHAP值与特征值之间的明确关系。这是因为特征的关系会根据预测类别而有所不同。年长的鲍鱼体型会更大。例如，大的壳重会导致老年（2）预测的概率更高。年轻（0）预测则相反。
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/2194302f628562be28ab5e4cb04c7681.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2194302f628562be28ab5e4cb04c7681.png)'
- en: 'Figure 6: beeswarm for multiclass target variable (source: author)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：多分类目标变量的beeswarm图（来源：作者）
- en: So hopefully is clear how to interpret SHAP values for binary and multiclass
    target variables. Yet, you may be wondering why they are given in terms of log
    odds and softmax. It may make more sense to interpret them both in terms of probabilities.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 希望现在清楚如何解读二分类和多分类目标变量的SHAP值。然而，您可能会想知道为什么它们以对数几率和softmax的形式给出。将它们解释为概率可能更有意义。
- en: This comes from the way SHAP values are calculated. That is simultaneously by
    a linear model. If we had to predict a binary or multiclass variable with a linear
    model we would use logistic or softmax regression respectively. These link functions
    are differentiable and they allow us to formulate model predictions as a linear
    equation of parameters and features. Likewise, these properties are used to estimate
    SHAP values efficiently.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这源于 SHAP 值的计算方式。即同时通过线性模型进行计算。如果我们需要用线性模型预测一个二元或多类变量，我们会分别使用逻辑回归或 Softmax 回归。这些连接函数是可微的，并允许我们将模型预测公式化为参数和特征的线性方程。同样，这些特性用于高效地估计
    SHAP 值。
- en: 'Learn more about shap:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 了解更多关于 SHAP 的信息：
- en: '[](/new-shap-plots-violin-and-heatmap-20f647313b64?source=post_page-----ff2f43de0cf4--------------------------------)
    [## New SHAP Plots: Violin and Heatmap'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/new-shap-plots-violin-and-heatmap-20f647313b64?source=post_page-----ff2f43de0cf4--------------------------------)
    [## 新的 SHAP 图：小提琴图和热图'
- en: What the plots in SHAP version 0.42.1 can tell you about your model
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SHAP 版本 0.42.1 中的图可以告诉你关于你的模型的哪些信息
- en: towardsdatascience.com](/new-shap-plots-violin-and-heatmap-20f647313b64?source=post_page-----ff2f43de0cf4--------------------------------)
    [](/the-limitations-of-shap-703f34061d86?source=post_page-----ff2f43de0cf4--------------------------------)
    [## The Limitations of SHAP
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/new-shap-plots-violin-and-heatmap-20f647313b64?source=post_page-----ff2f43de0cf4--------------------------------)
    [](/the-limitations-of-shap-703f34061d86?source=post_page-----ff2f43de0cf4--------------------------------)
    [## SHAP 的局限性'
- en: How SHAP is impacted by feature dependencies, causal inference and human biases
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SHAP 如何受到特征依赖性、因果推断和人为偏差的影响
- en: towardsdatascience.com](/the-limitations-of-shap-703f34061d86?source=post_page-----ff2f43de0cf4--------------------------------)
    [](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----ff2f43de0cf4--------------------------------)
    [## Using SHAP to Debug a PyTorch Image Regression Model
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/the-limitations-of-shap-703f34061d86?source=post_page-----ff2f43de0cf4--------------------------------)
    [](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----ff2f43de0cf4--------------------------------)
    [## 使用 SHAP 调试 PyTorch 图像回归模型'
- en: Using DeepShap to understand and improve the model powering an autonomous car
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 DeepShap 来理解和改进支持自动驾驶汽车的模型
- en: towardsdatascience.com](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----ff2f43de0cf4--------------------------------)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----ff2f43de0cf4--------------------------------)'
- en: I hope you enjoyed this article! You can support me by becoming one of my [**referred
    members**](https://conorosullyds.medium.com/membership) **:)**
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你喜欢这篇文章！你可以通过成为我的 [**推荐会员**](https://conorosullyds.medium.com/membership)
    来支持我 **:)**
- en: '[](https://conorosullyds.medium.com/membership?source=post_page-----ff2f43de0cf4--------------------------------)
    [## Join Medium with my referral link — Conor O’Sullivan'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://conorosullyds.medium.com/membership?source=post_page-----ff2f43de0cf4--------------------------------)
    [## 通过我的推荐链接加入 Medium — Conor O’Sullivan'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为 Medium 会员，你的会员费用的一部分将分配给你阅读的作者，并且你可以完全访问每个故事……
- en: conorosullyds.medium.com](https://conorosullyds.medium.com/membership?source=post_page-----ff2f43de0cf4--------------------------------)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[conorosullyds.medium.com](https://conorosullyds.medium.com/membership?source=post_page-----ff2f43de0cf4--------------------------------)'
- en: '| [Twitter](https://twitter.com/conorosullyDS) | [YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w)
    | [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup) — sign up for FREE access
    to a [Python SHAP course](https://adataodyssey.com/courses/shap-with-python/)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '| [Twitter](https://twitter.com/conorosullyDS) | [YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w)
    | [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup) — 免费注册获取 [Python SHAP 课程](https://adataodyssey.com/courses/shap-with-python/)'
- en: References
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Stackoverflow **How to interpret base_value of multi-class classification problem
    when using SHAP?**[https://stackoverflow.com/questions/65029216/how-to-interpret-base-value-of-multi-class-classification-problem-when-using-sha/65034362#65034362](https://stackoverflow.com/questions/65029216/how-to-interpret-base-value-of-multi-class-classification-problem-when-using-sha/65034362#65034362)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Stackoverflow **如何解释多类分类问题的 base_value，当使用 SHAP 时？**[https://stackoverflow.com/questions/65029216/how-to-interpret-base-value-of-multi-class-classification-problem-when-using-sha/65034362#65034362](https://stackoverflow.com/questions/65029216/how-to-interpret-base-value-of-multi-class-classification-problem-when-using-sha/65034362#65034362)
