["```py\nimport os\nfrom query_index import DocSearch\nimport logging\nimport re\nfrom utils.parse_tools import remove_tabbed_lines\nlogging.disable(logging.INFO)\n\ndef set_global_logging_level(level=logging.ERROR, prefices=[\"\"]):\n    \"\"\"\n    Override logging levels of different modules based on their name as a prefix.\n    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n\n    Args:\n        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n          Default is `[\"\"]` to match all active loggers.\n          The match is a case-sensitive `module_name.startswith(prefix)`\n    \"\"\"\n    prefix_re = re.compile(fr'^(?:{ \"|\".join(prefices) })')\n    for name in logging.root.manager.loggerDict:\n        if re.match(prefix_re, name):\n            logging.getLogger(name).setLevel(level)\n\ndef main(\n    query,\n    embedder = \"instructor\",\n    top_k = None, \n    block_types = None, \n    score = False, \n    open_url = True,\n    print_output = True\n    ):\n\n    # Set up query\n    query_machine = DocSearch(\n        embedder=embedder,\n        top_k=top_k,\n        block_types=block_types,\n        score=score,\n        open_url=open_url,\n        print_output=print_output\n    )\n\n    query_output = query_machine(query)\n\n    # Generate prompt\n    prompt = f\"\"\"\nBelow is an relevant documentation and a query. Write a response that appropriately completes the query based on the relevant documentation provided.\n\nRelevant documentation: {remove_tabbed_lines(query_output)}\n\nQuery: {query}\n\nResponse: Here's the answer to your query:\"\"\"\n\n    print(prompt)\n    return prompt\n\nif __name__ == '__main__':\n    set_global_logging_level(logging.ERROR, [\"transformers\", \"nlp\", \"torch\", \"tensorflow\", \"tensorboard\", \"wandb\"])\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--query', type=str, default=None)\n    parser.add_argument('--top_k', type=int, default=5)\n    parser.add_argument('--block_types', type=str, default='text')\n    parser.add_argument('--score', type=bool, default=False)\n    parser.add_argument('--open_url', type=bool, default=False)\n    parser.add_argument('--embedder', type=str, default='instructor')\n    parser.add_argument('--print_output', type=bool, default=False)\n    args = parser.parse_args()\n    main(**vars(args))\n```", "```py\n#!/bin/bash\n\n# Get the query from the command-line argument\nquery=\"$1\"\n\n# Launch prompt generation script with argument --query\nif ! prompt=$(python src/query_llm.py --query \"$query\" --top_k 1); then\n    echo \"Error running query_llm.py\"\n    exit 1\nfi\n\n# Run the terminal command\n<PATH_TO_LLAMA.CPP>/main \\\n    -t 8 \\\n    -m <PATH_TO_LLAMA.CPP>/models/Wizard-Vicuna-13B-Uncensored.ggmlv3.q4_0.bin \\\n    --color \\\n    -c 4000 \\\n    --temp 0.1 \\\n    --repeat_penalty 1.1 \\\n    -n -1 \\\n    -p \"$prompt\" \\\n    -ngl 1 \n```"]