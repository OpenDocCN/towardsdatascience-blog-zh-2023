- en: 'Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered
    Applications'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c](https://towardsdatascience.com/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A LangChain tutorial to build anything with large language models in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@iamleonie?source=post_page-----95fc8898732c--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page-----95fc8898732c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----95fc8898732c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----95fc8898732c--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page-----95fc8898732c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----95fc8898732c--------------------------------)
    ·11 min read·Apr 25, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ba0a0432f474352f0aac6ee6c0e9eeea.png)'
  prefs: []
  type: TYPE_IMG
- en: “What did the stochastic parrot say to the other?” (Image drawn by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the release of ChatGPT, large language models (LLMs) have gained a lot
    of popularity. Although you probably don’t have enough money and computational
    resources to train an LLM from scratch in your basement, you can still use pre-trained
    LLMs to build something cool, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Personal assistants](https://python.langchain.com/en/latest/use_cases/personal_assistants.html)
    that can interact with the outside world based on your data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chatbots](https://python.langchain.com/en/latest/use_cases/chatbots.html)
    customized for your purpose'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Analysis](https://python.langchain.com/en/latest/use_cases/question_answering.html)
    or [summarization](https://python.langchain.com/en/latest/use_cases/summarization.html)
    of your documents or [code](https://python.langchain.com/en/latest/use_cases/code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are changing how we build AI-powered products
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With their weird APIs and prompt engineering, LLMs are changing how we build
    AI-powered products. That’s why new developer tools are emerging everywhere under
    the term [“LLMOps”](https://wandb.ai/iamleonie/Articles/reports/Understanding-LLMOps-Large-Language-Model-Operations--Vmlldzo0MDgyMDc2).
  prefs: []
  type: TYPE_NORMAL
- en: One of these new tools is [LangChain](https://github.com/hwchase17/langchain).
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/hwchase17/langchain?source=post_page-----95fc8898732c--------------------------------)
    [## GitHub - hwchase17/langchain: ⚡ Building applications with LLMs through composability
    ⚡'
  prefs: []
  type: TYPE_NORMAL
- en: '⚡ Building applications with LLMs through composability ⚡ Production Support:
    As you move your LangChains into…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/hwchase17/langchain?source=post_page-----95fc8898732c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: What is LangChain?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'LangChain is a framework built to help you build LLM-powered applications more
    easily by providing you with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: a generic interface to a variety of different foundation models (see [Models](#bd03)),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a framework to help you manage your prompts (see [Prompts](#b1a5)), and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a central interface to long-term memory (see [Memory](#3bc6)), external data
    (see [Indexes](#806f)), other LLMs (see [Chains](#fcac)), and other agents for
    tasks an LLM is not able to handle (e.g., calculations or search) (see [Agents](#b842)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is an open-source project ([GitHub repository](https://github.com/hwchase17/langchain))
    created by [Harrison Chase](https://twitter.com/hwchase17).
  prefs: []
  type: TYPE_NORMAL
- en: Because LangChain has a lot of different functionalities, it may be challenging
    to understand what it does at first. That’s why we will go over the (currently)
    six key modules of LangChain in this article to give you a better understanding
    of its capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To follow along in this tutorial, you will need to have the `langchain` Python
    package installed and all relevant API keys ready to use.
  prefs: []
  type: TYPE_NORMAL
- en: Installing LangChain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before installing the `langchain` package, ensure you have a Python version
    of ≥ 3.8.1 and <4.0.
  prefs: []
  type: TYPE_NORMAL
- en: To install the `langchain` Python package, you can `pip` install it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this tutorial, we are using version 0.0.147\. The [GitHub repository](https://github.com/hwchase17/langchain)
    is very active; thus, ensure you have a current version.
  prefs: []
  type: TYPE_NORMAL
- en: Once you are all setup, import the `langchain` Python package.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: API keys
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Building an application with LLMs requires API keys for some services you want
    to use, and some APIs have associated costs.
  prefs: []
  type: TYPE_NORMAL
- en: '**LLM provider (required)** — You will first need an API key for the LLM provider
    you want to use. We are currently experiencing [“AI’s Linux moment](https://hazyresearch.stanford.edu/blog/2023-01-30-ai-linux)”
    where developers must **choose between proprietary or open-source foundation models**
    based on a trade-off mainly between performance and cost.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/00b94afaccb89deaf33f4d10262f2f94.png)'
  prefs: []
  type: TYPE_IMG
- en: 'LLM Providers: Proprietary and open-source foundation models (Image by the
    author, inspired by [Fiddler.ai](https://www.fiddler.ai/blog/the-missing-link-in-generative-ai),
    first published on [W&B’s blog](https://wandb.ai/iamleonie/Articles/reports/Understanding-LLMOps-Large-Language-Model-Operations--Vmlldzo0MDgyMDc2))'
  prefs: []
  type: TYPE_NORMAL
- en: '**Proprietary models** are closed-source foundation models owned by companies
    with large expert teams and big AI budgets. They usually are larger than open-source
    models and thus have better performance, but they also have expensive APIs. Examples
    of proprietary model providers are [OpenAI](https://python.langchain.com/en/latest/modules/models/llms/integrations/openai.html),
    [co:here](https://python.langchain.com/en/latest/modules/models/llms/integrations/cohere.html),
    [AI21 Labs](https://python.langchain.com/en/latest/modules/models/llms/integrations/ai21.html),
    or [Anthropic](https://python.langchain.com/en/latest/modules/models/llms/integrations/anthropic_example.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Most available LangChain tutorials use OpenAI but note that [the OpenAI API
    (is not expensive for experimentation but it) is not free](https://openai.com/pricing).
    To obtain an OpenAI API Key, you need an OpenAI account and then “Create new secret
    key” under [API keys](https://platform.openai.com/account/api-keys).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Open-source models** are usually smaller models with lower capabilities than
    proprietary models, but they are more cost-effective than proprietary ones. Examples
    of open-source models are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[BLOOM](https://huggingface.co/bigscience/bloom) by BigScience'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LLaMA](https://huggingface.co/docs/transformers/main/en/model_doc/llama) by
    Meta AI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Flan-T5](https://huggingface.co/google/flan-t5-xl) by Google'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT-J](https://huggingface.co/EleutherAI/gpt-j-6b) by Eleuther AI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many open-source models are organized and hosted on [Hugging Face](https://huggingface.co/)
    as a community hub. To obtain a Hugging Face API Key, you need a Hugging Face
    account and create a “New token” under [Access Tokens](https://huggingface.co/settings/tokens).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can use [Hugging Face](https://huggingface.co/) for free for open-source
    LLMs, but you will be limited to smaller LLMs with less performance.
  prefs: []
  type: TYPE_NORMAL
- en: '***A personal note —*** *Let’s be honest here for a second: Of course, you
    can experiment with open-source foundation models here. I tried to make this tutorial
    only with open-source models hosted on Hugging Face available with a regular account
    (google/flan-t5-xl and sentence-transformers/all-MiniLM-L6-v2). It works for most
    examples, but it is also a pain to get some examples to work. Finally, I pulled
    the trigger and set up a paid account for OpenAI as most examples for LangChain
    seem to be optimized for OpenAI’s API. Overall running a few experiments for this
    tutorial cost me about $1.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Vector Database (optional)** — If you want to use a specific vector database
    such as [Pinecone](https://www.pinecone.io/), [Weaviate](https://weaviate.io/),
    or [Milvus](https://milvus.io/), you need to register with them to obtain an API
    key and check their pricing. In this tutorial, we are using [Faiss](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/),
    which requires no sign-up.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tools (optional)** — Depending on the [tools](https://python.langchain.com/en/latest/modules/agents/tools.html)
    you want the LLM to interact with such as OpenWeatherMap or SerpAPI, you may need
    to register with them to obtain an API key and check their pricing. In this tutorial,
    we only use tools requiring no API key.'
  prefs: []
  type: TYPE_NORMAL
- en: What can you do with LangChain?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The package provides a generic interface to many foundation models, enables
    prompt management, and acts as a central interface to other components like prompt
    templates, other LLMs, external data, and other tools via agents.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, LangChain (version 0.0.147) covers six modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Models: Choosing from different LLMs and embedding models](#bd03)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Prompts: Managing LLM inputs](#b1a5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chains: Combining LLMs with other components](#fcac)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Indexes: Accessing external data](#806f)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Memory: Remembering previous conversations](#3bc6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Agents: Accessing other tools](#b842)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code examples in the following sections are copied and modified from the
    [LangChain documentation](https://python.langchain.com/en/latest/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Models: Choosing from different LLMs and embedding models'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Currently, many different LLMs are emerging. LangChain offers integrations to
    a wide range of models and a streamlined interface to all of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'LangChain differentiates between three types of models that differ in their
    inputs and outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**LLMs** take a string as an input (prompt) and output a string (completion).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6f7c12ec849f0405cc0b12cdc130e129.png)'
  prefs: []
  type: TYPE_IMG
- en: LLM models (Image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: '**Chat models** are similar to LLMs. They take a list of chat messages as input
    and return a chat message.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text embedding models** take text input and return a list of floats (embeddings),
    which are the numerical representation of the input text. Embeddings help extract
    information from a text. This information can then be later used, e.g., for calculating
    similarities between texts (e.g., movie summaries).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0759e970e3b04f43b057231e5e2aec43.png)'
  prefs: []
  type: TYPE_IMG
- en: Text embedding models (Image by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompts: Managing LLM inputs'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs have weird APIs. Although inputting prompts to LLMs in natural language
    should feel intuitive, it takes quite a bit of tweaking of the prompt until you
    get the desired output from an LLM. This process is called *prompt engineering*.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have a good prompt, you may want to use it as a template for other
    purposes. Thus, LangChain provides you with so-called `PromptTemplates`, which
    help you construct prompts from multiple components.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The above prompt can be viewed as a **zero-shot problem setting**, where you
    hope the LLM was trained on enough relevant data to provide a satisfactory response.
  prefs: []
  type: TYPE_NORMAL
- en: Another trick to improve the LLM’s output is to add a few examples in the prompt
    and make it a **few-shot problem setting**.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The above code will generate a prompt template and compose the following prompt
    based on the provided examples and input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Chains: Combining LLMs with other components'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Chaining in LangChain simply describes the process of combining LLMs with other
    components to create an application. Some examples are:'
  prefs: []
  type: TYPE_NORMAL
- en: Combining LLMs with prompt templates (see this section)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining multiple LLMs sequentially by taking the first LLM’s output as the
    input for the second LLM (see this section)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining LLMs with external data, e.g., for question answering (see [Indexes](#806f))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining LLMs with long-term memory, e.g., for chat history (see [Memory](#3bc6))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the previous section, we created a prompt template. When we want to use
    it with our LLM, we can use an `LLMChain` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to use the output of this first LLM as the input for a second LLM,
    we can use a `SimpleSequentialChain`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a19959a0c2a5d4f0c48c9aee7cb979a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of a SimpleSequentialChain using PromptTemplates and LLMs in LangChain
    (Screenshot by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Indexes: Accessing external data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One limitation of LLMs is their lack of contextual information (e.g., access
    to some specific documents or emails). You can combat this by giving LLMs access
    to the specific external data.
  prefs: []
  type: TYPE_NORMAL
- en: For this, you first need to load the external data with a document loader. LangChain
    provides a variety of loaders for different types of documents ranging from PDFs
    and emails to websites and YouTube videos.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s load some external data from a YouTube video. You can refer to the official
    documentation if you want to [load a large text document and split it with a](https://python.langchain.com/en/latest/modules/indexes/getting_started.html)
    [Text Splitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have your external data ready to go as `documents` , you can index
    it with a **text embedding model** (see [Models](#bd03)) in a vector database
    — a **VectorStore.** Popular vector databases include [Pinecone](https://www.pinecone.io/),
    [Weaviate](https://weaviate.io/), and [Milvus](https://milvus.io/). In this article,
    we are using Faiss because it doesn’t require an API key.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Your document (in this case, a video) is now stored as embeddings in a vector
    store.
  prefs: []
  type: TYPE_NORMAL
- en: Now you can do a variety of things with this external data. Let’s use it for
    a question-answering task with an information **retriever:**
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e9499bbce4053fff99174903e5578c71.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of the RetrievalQA (Screenshot by the author)
  prefs: []
  type: TYPE_NORMAL
- en: Wait a minute — Did you just get rickrolled? Yes, you did.
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory: Remembering previous conversations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For applications like chatbots, it is essential that they can remember previous
    conversations. But by default, LLMs don’t have any long-term memory unless you
    input the chat history.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/13683d095100fa5d71506adbe571435a.png)'
  prefs: []
  type: TYPE_IMG
- en: Chat with and without conversational memory (Image by the author made with [ifaketextmessage.com](https://ifaketextmessage.com/),
    inspired by [Pinecone](https://www.pinecone.io/learn/langchain-conversational-memory))
  prefs: []
  type: TYPE_NORMAL
- en: 'LangChain solves this problem by providing several different options for dealing
    with chat history :'
  prefs: []
  type: TYPE_NORMAL
- en: keep all conversations,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: keep the latest k conversations,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: summarize the conversation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this example, we will use a `ConversationChain` to give this application
    conversational memory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This will result in the right-hand conversation in the above image. Without
    the `ConversationChain` to keep a conversational memory, the conversation will
    look like the one on the left-hand side in the above image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Agents: Accessing other tools'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite being quite powerful, LLMs have some limitations: they lack contextual
    information (e.g., access to specific knowledge not contained in training data),
    they can become outdated quickly (e.g., GPT-4 was [trained on data before September
    2021](https://openai.com/research/gpt-4)), and they are bad at math.'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are bad at math
  prefs: []
  type: TYPE_NORMAL
- en: Because LLMs can hallucinate on tasks they can’t accomplish on their own, we
    need to give them access to supplementary **tools** such as search (e.g., [Google
    Search](https://python.langchain.com/en/latest/modules/agents/tools/examples/google_search.html)),
    calculators (e.g., [Python REPL](https://python.langchain.com/en/latest/modules/agents/tools/examples/python.html)
    or [Wolfram Alpha](https://python.langchain.com/en/latest/modules/agents/tools/examples/wolfram_alpha.html)),
    and lookups (e.g., [Wikipedia](https://python.langchain.com/en/latest/modules/agents/tools/examples/wikipedia.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we need agents that make decisions about which tools to use to
    accomplish a task based on the LLM’s output.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note that some LLMs such as* `[*google/flan-t5-xl*](https://github.com/hwchase17/langchain/issues/1358)`
    [*won’t be suitable for the following examples as they do not follow the*](https://github.com/hwchase17/langchain/issues/1358)
    `[*conversational-react-description*](https://github.com/hwchase17/langchain/issues/1358)`
    [*template.*](https://github.com/hwchase17/langchain/issues/1358) *For me, this
    was the point where I set up a paid account on OpenAI and switched to the OpenAI
    API.*'
  prefs: []
  type: TYPE_NORMAL
- en: Below is an example in which the agent first looks up the date of Barack Obama’s
    birth with Wikipedia and then calculates his age in 2022 with a calculator.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4b0008eae6eb77df7210741f368d43b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of the LLM agent (Screenshot by the author)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just a few months ago, we all (or at least most of us) were impressed by ChatGPT's
    capabilities. Now, new developer tools like LangChain enable us to build similarly
    impressive prototypes on our laptops within a few hours — these are some truly
    exciting times!
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is an open-source Python library that enables anyone who can write
    code to build LLM-powered applications. The package provides a generic interface
    to many foundation models, enables prompt management, and acts as a central interface
    to other components like prompt templates, other LLMs, external data, and other
    tools via agents — at the time of writing.
  prefs: []
  type: TYPE_NORMAL
- en: The library offers many more features than mentioned in this article. With the
    current speed of developments, this article could also be potentially outdated
    in a month.
  prefs: []
  type: TYPE_NORMAL
- en: While working on this article, I noticed that the library and documentation
    are centered around OpenAI’s API. Although many examples work with the open-source
    foundation model `[google/flan-t5-xl](https://github.com/hwchase17/langchain/issues/1358)`,
    I switched to the OpenAI API in between. Despite not being free, experimenting
    with the OpenAI API in this article cost me only about $1.
  prefs: []
  type: TYPE_NORMAL
- en: Enjoyed This Story?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Subscribe for free*](https://medium.com/subscribe/@iamleonie) *to get notified
    when I publish a new story.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----95fc8898732c--------------------------------)
    [## Get an email whenever Leonie Monigatti publishes.'
  prefs: []
  type: TYPE_NORMAL
- en: Get an email whenever Leonie Monigatti publishes. By signing up, you will create
    a Medium account if you don’t already…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----95fc8898732c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/804250ab/),[*Twitter*](https://twitter.com/helloiamleonie)*,
    and* [*Kaggle*](https://www.kaggle.com/iamleonie)*!*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Harrison Chase (2023). [LangChain documentation](https://python.langchain.com/en/latest/index.html)
    (accessed April 23rd, 2023)'
  prefs: []
  type: TYPE_NORMAL
