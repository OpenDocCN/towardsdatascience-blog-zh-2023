["```py\nprompt = \"My name is Andrea\"\nresponse = chatgpt_call(prompt)\nprint(response)\n\n# Output: Nice to meet you, Andrea! How can I assist you today?\n```", "```py\nprompt = \"Do you remember my name?\"\nresponse = chatgpt_call(prompt)\nprint(response)\n\n# Output: I'm sorry, as an AI language model, I don't have the ability \n# to remember specific information about individual users.\n```", "```py\npip install langchain\n```", "```py\n# Loads OpenAI key from the environment\nfrom langchain.llms import OpenAI\nchatgpt = OpenAI()\n```", "```py\nfrom langchain.chains import ConversationChain\nconversation = ConversationChain(llm=chatgpt)\n```", "```py\nconversation.predict(input=\"Hello, we are ForCode'Sake! A Medium publication with the objective of democratizing the knowledge of data!\")\n```", "```py\nconversation.predict(input=\"Do you remember our name?\")\n\n# Output: \" Hi there! It's great to meet you. \n# I'm an AI that specializes in data analysis. \n# I'm excited to hear more about your mission in democratizing data knowledge.\n# What inspired you to do this?\"\n```", "```py\nfrom langchain.memory import ConversationBufferMemory\nmemory=ConversationBufferMemory()\n```", "```py\nmemory.save_context({\"input\": \"Hi\"},\n                    {\"output\": \"What's up\"})\nmemory.save_context({\"input\": \"Not much, just hanging\"},\n                    {\"output\": \"Cool\"})\n```", "```py\n# OpenAI key from environment\nfrom langchain.llms import OpenAI\nllm = OpenAI()\n```", "```py\nfrom langchain.memory import ConversationBufferWindowMemory\nmemory = ConversationBufferWindowMemory(k=1)\n```", "```py\nmemory.save_context({\"input\": \"Hi\"},\n                    {\"output\": \"What's up\"})\nmemory.save_context({\"input\": \"Not much, just hanging\"},\n                    {\"output\": \"Cool\"})\n```", "```py\nmemory.load_memory_variables({})\n\n# Output: {'history': 'Human: Not much, just hanging\\nAI: Cool'}\n```", "```py\nconversation.predict(input=\"Can you tell me a joke?\")\n```", "```py\nfrom langchain.memory import ConversationSummaryBufferMemory\n```", "```py\nschedule = \"There is a meeting at 8am with your product team. \\\nYou will need your powerpoint presentation prepared. \\\n9am-12pm have time to work on your LangChain \\\nproject which will go quickly because Langchain is such a powerful tool. \\\nAt Noon, lunch at the Italian restaurant with a customer who is driving \\\nfrom over an hour away to meet you to understand the latest in AI. \\\nBe sure to bring your laptop to show the latest LLM demo.\"\n\nmemory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\nmemory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\nmemory.save_context({\"input\": \"Not much, just hanging\"},\n                    {\"output\": \"Cool\"})\nmemory.save_context({\"input\": \"What is on the schedule today?\"}, \n                    {\"output\": f\"{schedule}\"})\n```", "```py\n{\n  'history': 'System: \n  \\nThe human greets the AI and asks what is on the schedule for the day. \n  The AI responds with \"Cool\".\\n\n  AI: There is a meeting at 8am with your product team. \n  You will need your powerpoint presentation prepared. \n  9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. \n  At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. \n  Be sure to bring your laptop to show the latest LLM demo.'\n}\n```", "```py\nllm = OpenAI()\n\nconversation = ConversationChain(\n    llm=llm, \n    memory = memory,\n    verbose=True\n)\n```"]