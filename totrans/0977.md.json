["```py\npip install jax\n```", "```py\nimport pandas as pd\nimport jax.numpy as jnp\nfrom jax import grad\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('/kaggle/input/mobile-price-classification/train.csv')\ndf = df.iloc[:, 10:]\ndf = df.loc[df['price_range'] <= 1]\ndf.head()\n```", "```py\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    stratify=y)\n\nX_train, X_test, y_train, Y_test = jnp.array(X_train), jnp.array(X_test), \\\n                                   jnp.array(y_train), jnp.array(y_test)\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n```", "```py\ndef activation(r):\n    return 1 / (1 + jnp.exp(-r))\n\ndef loss(c, w, X, y, lmbd=0.1):\n    p = activation(jnp.dot(X, w) + c)\n    loss = jnp.sum(y * jnp.log(p) + (1 - y) * jnp.log(1 - p)) / y.size\n    reg = 0.5 * lmbd * (jnp.dot(w, w) + c * c) \n    return - loss + reg \n```", "```py\nn_iter, eta = 100, 1e-1\nw = 1.0e-5 * jnp.ones(X.shape[1])\nc = 1.0\nhistory = [float(loss(c, w, X_train, y_train))]\nfor i in range(n_iter):\n    c_current = c\n    c -= eta * grad(loss, argnums=0)(c_current, w, X_train, y_train)\n    w -= eta * grad(loss, argnums=1)(c_current, w, X_train, y_train)\n    history.append(float(loss(c, w, X_train, y_train)))\n```", "```py\ny_pred = jnp.array(activation(jnp.dot(X_test, w) + c))\ny_pred = jnp.where(y_pred > 0.5, 1, 0) \nprint(classification_report(y_test, y_pred))\n```"]