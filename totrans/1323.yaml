- en: Improving Diffusers Package for High-Quality Image Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4](https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overcoming token size limitations, custom model loading, LoRa support, textual
    inversion support, and more
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Andrew
    Zhu (Shudong Zhu)](../Images/46f07a875a42bcc4e0c262aea5e2a504.png)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    [Andrew Zhu (Shudong Zhu)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    ·15 min read·Apr 5, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec28506deb9273669dd315b83ff91aec.png)'
  prefs: []
  type: TYPE_IMG
- en: Goodbye Babel, generated by Andrew Zhu using Diffusers in pure Python
  prefs: []
  type: TYPE_NORMAL
- en: '[Stable Diffusion WebUI from AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
    has proven to be a powerful tool for generating high-quality images using the
    Diffusion model. However, while the WebUI is easy to use, data scientists, machine
    learning engineers, and researchers often require more control over the image
    generation process. This is where the [diffusers](https://github.com/huggingface/diffusers)
    package from huggingface comes in, providing a way to run the Diffusion model
    in Python and allowing users to customize their models and prompts to generate
    images to their specific needs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite its potential, the Diffusers package has several limitations that prevent
    it from generating images as good as those produced by the Stable Diffusion WebUI.
    The most significant of these limitations include:'
  prefs: []
  type: TYPE_NORMAL
- en: The inability to use custom models in the `.safetensor` file format;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The 77 prompt token limitation;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lack of LoRA support;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And the absence of image scale-up functionality (also known as HighRes in Stable
    Diffusion WebUI);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Low performance and high VRAM usage by default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This article aims to address these limitations and enable the Diffusers package
    to generate high-quality images comparable to those produced by the Stable Diffusion
    WebUI. With the enhancement solutions provided, data scientists, machine learning
    engineers, and researchers can enjoy greater control and flexibility in their
    image generation processes while also achieving exceptional results. In the following
    sections, we will explore the various strategies and techniques that can be used
    to overcome these limitations and unlock the full potential of the Diffusers package.
  prefs: []
  type: TYPE_NORMAL
- en: Note that please follow this link to install all required CUDA and Python packages
    if it is your first time running Stable Diffusion.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)
    [## Installation'
  prefs: []
  type: TYPE_NORMAL
- en: Install 🤗 Diffusers for whichever deep learning library you're working with.
    🤗 Diffusers is tested on Python 3.7+…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: huggingface.co](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Load Up Local Model files in .safetensor Format
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Users can easily spin up diffusers to generate an image like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You may not satisfy with either the output image or the performance. Let’s
    deal with the problems one by one. First, let’s load up a custom model in `.safetensor`
    format located anywhere on your machine. you **can’t** just load the model file
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the detailed steps to covert `.safetensor` file to diffusers format:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1**. Pull all diffusers code from GitHub'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2**. Under the `scripts` folder locate the [file](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py):
    `convert_original_stable_diffusion_to_diffusers.py`'
  prefs: []
  type: TYPE_NORMAL
- en: In your terminal, run this command to convert `.safetensor` file to Diffusers
    format. Remember to change the `— checkpoint_path` value to represent your case.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3**. Now you can load up the pipeline using the newly converted model
    file, here is the complete code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You should be able to convert and use any models you download from huggingface
    or civitai.com.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a205baa885ec1cb4bb289043bcc75c7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Cat playing piano generated by the above code
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Boost the Performance of Diffusers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generating high-quality images can be a time-consuming process even for the
    latest 3xxx and 4xxx Nvidia RTX GPUs. By default, Diffuers package comes with
    non-optimized settings. Two solutions can be applied to greatly boost performance.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the interaction speed before applying the following solution, only about
    2.x iterations per second in RTX 3070 TI 8G RAM to generate a 512x512 image
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/523fd850a9008a5879b938236e13116f.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Use Half Precision Weights**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first solution is to use half precision weights. Half precision weights
    use 16-bit floating-point numbers instead of the traditional 32-bit numbers. This
    reduces the memory required for storing weights and speeds up computation, which
    can significantly improve the performance of the Diffusers package.
  prefs: []
  type: TYPE_NORMAL
- en: According to this [video](https://www.youtube.com/watch?v=9tpLJpqxdE8&ab_channel=NVIDIADeveloper),
    reducing float precision from FP32 to FP16 will also enable the Tensor Cores.
  prefs: []
  type: TYPE_NORMAL
- en: I had another article to test out how fast GPU Tensor cores can boost the computation
    speed.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
    [## How Fast GPU Computation Can Be'
  prefs: []
  type: TYPE_NORMAL
- en: A comparison of matrix arithmetic calculation in CPU and GPU with Python and
    PyTorch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Here is how to enable FP16 in diffusers, Just adding two lines of code will
    boost the performance by 500%, with almost no image quality impacts.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now the iteration speed boosts to 10.x iteration per second. A **5x times faster**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e365ff233687b79a64d433c7508b776d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Use Xformers**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Xformers](https://github.com/facebookresearch/xformers) is an open-source
    library that provides a set of high-performance transformers for various natural
    language processing (NLP) tasks. It is built on top of PyTorch and aims to provide
    efficient and scalable transformer models that can be easily integrated into existing
    NLP pipelines. (Nowadays, are there any models that don’t use Transformer? :P)'
  prefs: []
  type: TYPE_NORMAL
- en: Install Xformers by `pip install xformers` , then we can easily switch diffusers
    to use xformers by one line code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This one-line code boosts performance by another 20%.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d31f5865af53b4ed32364192c78b7d52.png)'
  prefs: []
  type: TYPE_IMG
- en: 3\. Remove the 77 prompt tokens limitation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the current version of Diffusers, there is a limitation of 77 prompt tokens
    that can be used in the generation of images.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, there is a solution to this problem. By using the “`lpw_stable_diffusion`”
    pipeline provided by the community, you can unlock the 77 prompt token limitation
    and generate high-quality images with longer prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the “`lpw_stable_diffusion`” pipeline, you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this code, we are initializing a new DiffusionPipeline object using the “`from_pretrained`”
    method. We are specifying the path to the pre-trained model and setting the “`custom_pipeline`”
    argument to “`lpw_stable_diffusion`”. This tells Diffusers to use the “`lpw_stable_diffusion`”
    pipeline, which unlocks the 77 prompt token limitation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s use a long prompt string to test it out. Here is the complete code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'And you will get an image like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7b1e72d61d933d3acdae9a6b8ceb0da2.png)'
  prefs: []
  type: TYPE_IMG
- en: Goodby Babel, generated by Andrew Zhu using diffusers
  prefs: []
  type: TYPE_NORMAL
- en: 'If you still see a warning message like: `Token indices sequence length is
    longer than the specified maximum sequence length for this model ( *** > 77 )
    . Running this sequence through the model will result in indexing errors.` It
    is normal, you can just ignore it.'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Use Custom LoRA with Diffusers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the claims of [LoRA support](https://huggingface.co/docs/diffusers/training/lora)
    in Diffusers, users still face limitations when it comes to loading local LoRA
    files in the `.safetensor` file format. This can be a significant obstacle for
    users to use the LoRA from the community.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome this limitation, I have created a function that allows users to
    load LoRA files with weighted numbers in real time. This function can be used
    to load LoRA files and their corresponding weights to a Diffusers model, enabling
    the generation of high-quality images with LoRA data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the function body:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The logic is extracted from the [convert_lora_safetensor_to_diffusers.py](https://github.com/huggingface/diffusers/blob/main/scripts/convert_lora_safetensor_to_diffusers.py)
    of the diffusers git repo.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take one of the famous [LoRA:MoXin](https://civitai.com/models/12597/moxin)
    for example. you can use the `__load_lora` function like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The prompt will generate an image like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0c2db814c9d57b74bd9cdcf193ee1ce4.png)'
  prefs: []
  type: TYPE_IMG
- en: a branch of flower, generated by Andrew Zhu using diffusers
  prefs: []
  type: TYPE_NORMAL
- en: You can call multiple times of `__load_lora()` to load several LoRAs for one
    generation.
  prefs: []
  type: TYPE_NORMAL
- en: With this function, you can now load LoRA files with weighted numbers in real
    time and use them to generate high-quality images with Diffusers. The LoRA loading
    is pretty fast, usually taking only 1–2 seconds, way better than converting and
    using(which will generate another model file in GB size).
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Use Custom Textural Inversions with Diffusers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using custom Texture Inversions with Diffusers package can be a powerful way
    to generate high-quality images. However, the [official documentation of Diffusers](https://huggingface.co/docs/diffusers/training/text_inversion)
    suggests that users need to train their own Textual Inversions which can take
    up to an hour on a V100 GPU. This may not be practical for many users who want
    to generate images quickly.
  prefs: []
  type: TYPE_NORMAL
- en: So I investigated it and found a solution that can enable diffusers to use a
    textual inversion just like in Stable Diffusion WebUI. Below is the function I
    created to load a custom Textual Inversion.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `load_textual_inversion()` function, you need to provide the following
    arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`learned_embeds_path`: Path to the pre-trained textual inversion model file
    in .pt or .bin format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_encoder`: Text encoder object obtained from the Diffusion Pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tokenizer`: Tokenizer object obtained from the Diffusion Pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`token`: Optional argument specifying the prompt token. By default, it is set
    to None. it is the keyword that will trigger the textual inversion in your prompt'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`weight`: Optional argument specifying the weight of the textual inversion.
    By default, I set it to 0.5\. you can change to other value as needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can now use the function with a diffusers pipeline like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here is the result of applying an [Empire Style](https://civitai.com/models/2032/empire-style)
    Textual Inversion.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2f7296d2aa833114ac96d08f3556338.png)'
  prefs: []
  type: TYPE_IMG
- en: The left’s modern street turns to an old London style.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Upscale Images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Diffusers package is great for generating high-quality images, but image upscaling
    is not its primary function. However, the Stable-Diffusion-WebUI offers a feature
    called HighRes, which allows users to upscale their generated images to 2x or
    4x. It would be great if Diffusers users could enjoy the same feature. After some
    research and testing, I found that the SwinRI model is an excellent option for
    image upscaling, and it can easily upscale images to 2x or 4x after they are generated.
  prefs: []
  type: TYPE_NORMAL
- en: To use the SwinRI model for image upscaling, we can use the code from the GitHub
    repository of [JingyunLiang/SwinIR](https://github.com/JingyunLiang/SwinIR). If
    you just want codes, downloading `models/network_swinir.py`, `utils/util_calculate_psnr_ssim.py`
    and `main_test_swinir.py` is enough. Following the readme guideline, you can upscale
    images like magic.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a sample of how well SwinRI can scale up an image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b977daec46ca853876ed6c25563a0159.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Left: original image, Right: 4x SwinRI upscaled image'
  prefs: []
  type: TYPE_NORMAL
- en: Many other open-source solutions can be used to improve image quality. Here
    list three other models that I tried that return wonderful results.
  prefs: []
  type: TYPE_NORMAL
- en: '**RealSR**: [https://github.com/jixiaozhong/RealSR](https://github.com/jixiaozhong/RealSR)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RealSR can scale up an image 4 times almost as good as SwinRI, and its execution
    performance is the fastest, instead of invoking PyTorch and CUDA. The author compiles
    the code and CUDA usage to binary directly. My observations reveal that the RealSR
    can upscale a mage in about just 2–4 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: '**CodeFormer**: [https://github.com/sczhou/CodeFormer](https://github.com/sczhou/CodeFormer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CodeFormer is good at restoring blurred or broken faces, it can also remove
    noise and enhance background details. This solution and algorithm is widely used
    in other applications, including Stable-Diffusion-WebUI
  prefs: []
  type: TYPE_NORMAL
- en: '**GFPGAN:** [https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another powerful open-source solution that archives amazing results of face
    restoration, and it is fast too. GFPGAN is also integrated into Stable-Diffusion-WebUI.
  prefs: []
  type: TYPE_NORMAL
- en: '[Updated by April 19, 2023]'
  prefs: []
  type: TYPE_NORMAL
- en: Found that the SD 1.5 and all extended models can’t handle well with generating
    a high-resolution image by simply using the text2img pipeline. In practice, I
    found that the Diffusers text2img pipeline will easily generate twisted and broken
    images even at 1920x1080, the same settings and prompt can generate good images
    at 800x600.
  prefs: []
  type: TYPE_NORMAL
- en: 'I found Diffusers’ img2img pipeline can function as a great image high-resolution
    fix solution. here are the overall steps to implement img2img pipeline as an image
    high-resolution fix solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a low-resolution image using the text2img pipeline
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upsize the image to whatever resolution you want (max size depends on your VRAM
    size). `img = img.resize((width,height))` . The test shows that my 8G VRAM RTX
    3070 Ti can handle upscaling a 800x600 3 times to 2400x1800\. Note that at this
    step, no image upscaling or fixing happening, just upsize the image to the size
    you want.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then feed the new manually upsized `img` to the img2img pipeline with the same
    prompt, negative prompt, and additional setting: `strength` into the call, you
    will see the input get upscaled like magic.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The img2img will slightly change the image content, take a face as an example,
    it will not only upscale the image and somewhat change the face a little bit.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7527d699ce47ca6f85c6b30f975efb7e.png)'
  prefs: []
  type: TYPE_IMG
- en: Face HighRes upscale using Diffuses img2img pipeline, image generated by the
    author
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Optimize Diffusers CUDA Memory Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When using Diffusers to generate images, it’s important to consider the CUDA
    memory usage, especially when you want to load other models to further process
    the generated images. If you try to load another model like SwinIR to upscale
    images, you might encounter a `RuntimeError: CUDA out of memory` due to the Diffuser
    model still occupying the CUDA memory.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To mitigate this issue, there are several solutions to optimize CUDA memory
    usage. The following two solutions I found work the best:'
  prefs: []
  type: TYPE_NORMAL
- en: Sliced Attention for Additional Memory Savings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sliced attention is a technique that reduces the memory usage of self-attention
    mechanisms in transformers. By partitioning the attention matrix into smaller
    blocks, the memory requirements are reduced. This technique can be used with the
    Diffusers package to reduce the memory footprint of the Diffuser model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use it in Diffusers, simply one line code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Model offloading to CPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, you won’t have two models running at the same time, the idea is to
    offload the model data to the CPU memory temporarily and free up CUA memory space
    for other models, and only load up to VRAM when you start using the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use dynamically offload data to CPU memory in Diffusers, use this line code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: After applying this, whenever Diffusers finish the image generation task, the
    model data will be offloaded to CPU memory automatically until the next time calling.
  prefs: []
  type: TYPE_NORMAL
- en: For more performance and VRAM optimization for Diffusers with PyTorch 2.0, please
    check out this article I wrote up as a supplement to this article.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
    [## Performance Testing Note of Diffusers With PyTorch 2.0'
  prefs: []
  type: TYPE_NORMAL
- en: Test various methods to boost Stable Diffusion package Diffusers' performance
    and lower VRAM usage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: betterprogramming.pub](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The article discusses how to improve the performance and capabilities of the
    Diffusers package, The article covers several solutions to common issues faced
    by Diffusers users, including loading local `.safetensor` models, boosting performance,
    removing the 77 prompt tokens limitation, using custom LoRA and Textual Inversion,
    upscaling images, and optimizing CUDA memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: By applying these solutions, Diffusers users can generate high-quality images
    with better performance and more control over the process. The article also includes
    code snippets and detailed explanations for each solution.
  prefs: []
  type: TYPE_NORMAL
- en: If you can successfully apply these solutions and code in your case, there could
    be an additional benefit, which I benefit a lot, is that you may implement your
    own solutions by reading the Diffusers source code and understand better how Stable
    Diffusion works. To me, learning, finding, and implementing these solutions is
    a fun journey. Hope these solutions can also help you and wish you enjoy with
    Stable Diffusion and diffusers package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here provide the prompt that generates the heading image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Size: **600 * 800**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Seed: **3977059881**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scheduler (or Sampling method): **DPMSolverMultistepScheduler**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sampling steps: **25**'
  prefs: []
  type: TYPE_NORMAL
- en: 'CFG Scale (or Guidance Scale): **7.5** SwinRI model: **003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth**'
  prefs: []
  type: TYPE_NORMAL
- en: License and Code Reuse
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The solutions provided in this article were achieved through extensive source
    reading, later night testing, and logical design. It is important to note that
    at the time of writing (April 2023), loading LoRA and Textual Inversion solutions
    and code included in this article are the only working versions across the internet.
  prefs: []
  type: TYPE_NORMAL
- en: If you find the code presented in this article useful and want to reuse it in
    your project, paper, or article, please reference back to this Medium article.
    The code presented here is licensed under the MIT license, which permits you to
    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
    of the software, subject to the conditions of the license.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the solutions presented in this article may not be the optimal
    or most efficient way to achieve the desired results, and are subject to change
    as new developments and improvements are made. It is always recommended to thoroughly
    test and validate any code before implementing it in a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Book: Using Stable Diffusion with Python'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The article provided a glimpse into the potential of Stable Diffusion controlling
    using Python. Delving deeper into this interdisciplinary field requires a comprehensive
    guide that not only explains the theory but also demonstrates practical applications
    through Python programming.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, I am thrilled to announce the release of my book, “[Using Stable Diffusion
    with Python](https://www.amazon.com/Using-Stable-Diffusion-Python-Generation/dp/1835086373).”
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d86f8ba31c642e1d9042ef8d70ed379f.png)'
  prefs: []
  type: TYPE_IMG
- en: Using Stable Diffusion with Python
  prefs: []
  type: TYPE_NORMAL
- en: This book is a culmination of the latest research, experimentation, and dedication
    to making complex AI concepts accessible to everyone (using Python). Whether you
    are a beginner programmer intrigued by the power of Python, a seasoned engineer
    looking to expand your toolkit, or a scientist eager to delve into mathematical
    modeling, this book is designed to cater to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Within its pages, you will find detailed explanations of the mathematical foundations
    of Stable Diffusion, coupled with clear, step-by-step tutorials on how to use
    these models withPython. From setting up your Python environment to running the
    Diffusion models, visualizing results, every aspect is covered with meticulous
    attention to detail.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you like it.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[diffusers github repository](https://github.com/huggingface/diffusers)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Issue: Overcoming the 77 token limit in diffusers](https://github.com/huggingface/diffusers/issues/2136)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Diffusers memory and speed](https://huggingface.co/docs/diffusers/optimization/fp16)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deliberate model download](https://civitai.com/models/4823/deliberate)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
