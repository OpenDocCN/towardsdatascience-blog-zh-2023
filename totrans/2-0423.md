# 使用LangChain和GPT-3构建一个透明的文档问答机器人

> 原文：[https://towardsdatascience.com/build-a-transparent-question-answering-bot-for-your-documents-with-langchain-and-gpt-3-7f6a71f379f8](https://towardsdatascience.com/build-a-transparent-question-answering-bot-for-your-documents-with-langchain-and-gpt-3-7f6a71f379f8)

## 开发一个信息丰富的问答机器人指南，并显示所使用的来源

[](https://konstantin-rink.medium.com/?source=post_page-----7f6a71f379f8--------------------------------)[![Konstantin Rink](../Images/41bfc069d7382a0fd56f081eea7eb2d9.png)](https://konstantin-rink.medium.com/?source=post_page-----7f6a71f379f8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f6a71f379f8--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f6a71f379f8--------------------------------) [Konstantin Rink](https://konstantin-rink.medium.com/?source=post_page-----7f6a71f379f8--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f6a71f379f8--------------------------------) ·阅读时间11分钟·2023年7月22日

--

![](../Images/c24d8ab8c013ee7e02974a92cc9beff8.png)

图片由[Justin Ha](https://unsplash.com/@mekanizm?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，来源于[Unsplash](https://unsplash.com/de/fotos/XNn3SpMhiNE?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)。

问答系统在分析大量数据或文档时可以大有帮助。然而，模型用来生成答案的来源（即文档的部分内容）通常不会在最终答案中显示。

理解回应的背景和来源不仅对寻求准确信息的用户有价值，也对希望持续改进其QA机器人（问答机器人的开发者）有帮助。通过回答中包含的来源，开发者可以深入了解模型的决策过程，从而促进迭代改进和微调。

**本文展示了如何使用LangChain和GPT-3（text-davinci-003）创建一个透明的问答机器人，通过两个示例展示了生成答案时所使用的来源。**

在第一个示例中，你将学习如何创建一个透明的QA机器人，利用你的网站内容回答问题。在第二个示例中，我们将探讨使用来自不同YouTube视频的转录文本，包括带有和不带有时间戳的文本。

# 处理数据并创建向量存储

在我们能够利用像GPT-3这样的语言模型的能力之前，我们需要将文档（例如网站内容或YouTube转录文本）以正确的格式（首先分块，然后生成嵌入）处理，并将其存储在向量存储中。下图1展示了从左到右的处理流程。

![](../Images/aa6564c71496116719665fdfbd9b4f15.png)

图1\. 数据处理和向量存储创建的流程图（图像来源于作者）。

## 网站内容示例

在这个示例中，我们将处理网络门户[*It’s FOSS*](https://itsfoss.com/)的内容，该门户专注于开源技术，特别是Linux。

首先，我们需要获取一个**所有待处理的文章列表**并存储在我们的向量存储中。下面的代码读取了*sitemap-posts.xml*文件，该文件包含了所有文章的链接列表。

[PRE0]

在本文撰写时，列表中包含了超过969个文章链接。

有了链接列表，我们现在可以编写一个小的**辅助函数**，称为`extract_content`，它使用`BeautifulSoup`从文章页面中提取包含相关内容的特定元素。

[PRE1]

最后一步，我们遍历链接列表，并将我们的辅助函数`extract_content`应用于每个URL。为了演示目的，我将列表限制为10个元素。如果你想爬取所有文章，只需从`article_links[0:10]`中删除`[0:10]`。

`articles`列表现在包含每篇文章的字典，字典中包括`"source"`（文章链接）和`"content"`（文章内容）。文章的链接将在最终答案中作为来源显示。

由于GPT-3有一个**令牌限制**（4,096个令牌），因此将长文章分成**块**是有意义的。这些块将被组合在一起并发送给GPT-3。

下面的代码将文章内容拆分成几个块。

[PRE2]

我们在这里使用`RecursiveCharacterTextSplitter`，因为它旨在尽可能长时间地**将语义相关的内容保持在一起**。

一旦完成，我们只需执行以下命令，将文章及其来源存储到我们的向量存储中。

[PRE3]

在这个示例中，我们使用[FAISS](https://github.com/facebookresearch/faiss)作为**向量存储**，并使用`OpenAIEmbeddings`作为我们的嵌入模型。当然，也可以探索其他向量存储选项，例如[Chroma](https://github.com/chroma-core/chroma)，并尝试Hugging Face的嵌入模型解决方案。

> **注意**：你还可以通过运行`article_store.save_local("your_name")`来保存你的向量存储，这样你就不必每次使用时都重新创建它。更多详情见[这里](https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss#saving-and-loading)。

如果你**不想处理YouTube转录内容**，你可以**跳过下面的部分**并**继续到下一节**“运行透明问答”。

## YouTube转录示例

转录内容可以通过两种不同且独立的方式处理。**第一个选项**演示了如何处理YouTube转录内容，同时**保留视频链接**作为来源（例如，[https://youtu.be/XYZ](https://youtu.be/XYZ)。）。

**第二部分**做了同样的事情，但说明了如何**保留链接**，**包括时间戳**（例如，`https://youtu.be/XYZ&t=60`）以获取更详细的信息。

对于这两种方法，使用了来自频道[StatQuest](https://www.youtube.com/@statquest/featured)的以下YouTube视频的转录：

+   [XGBoost 第1部分（共4部分）：回归](https://youtu.be/OtD8wVaFm6E)

+   [XGBoost 第2部分（共4部分）：分类](https://youtu.be/8b1JEDvenQU)

+   [XGBoost 第3部分（共4部分）：数学细节](https://www.youtube.com/watch?v=ZVFeW798-2I)

+   [XGBoost 第4部分（共4部分）：疯狂酷炫的优化](https://youtu.be/oRrKeUCEbq8)

## **YouTube 转录示例（不带时间戳）**

第一部分非常直接。下面的代码利用了 LangChain 的 DocumentLoader `YoutubeLoader`，它集成了[youtube-transcript-api](https://pypi.org/project/youtube-transcript-api/)和[pytube](https://pytube.io/en/latest/)。

[PRE4]

为了避免与令牌限制发生冲突，我们使用`CharacterTextSplitter`将数据拆分为几个块。`add_video_info`设置为*True*，以**接收视频的标题和作者信息**。

返回的分块转录是[文档](https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html?highlight=document#langchain.schema.document.Document)对象。在创建嵌入并将其存储在向量存储中之前，我们通过添加有关*标题*、*作者*和*视频链接*的信息来操作或扩展它们的元数据。

[PRE5]

## YouTube 转录示例（带时间戳）

第二种方法稍微**复杂一些**。在这里，我们使用名为[youtube-transcript-api](https://pypi.org/project/youtube-transcript-api/)的不同包来检索转录。输出是一个包含文本、开始时间和持续时间的字典列表。我们需要切换到不同的包，因为`YoutubeLoader`包不返回时间戳。

示例可以在这里看到：

[PRE6]

从每个文本条目创建文档对象没有多大意义，因为条目**太短**（例如，上述示例中每个条目只有8个单词），不便于后续使用。在向量存储中搜索时，只返回有限数量的匹配文档（例如，4个），信息内容不足。

因此，我们需要首先将文本条目聚合或合并成适当的文本块。下面的代码片段包含一个自定义助手函数。

[PRE7]

该助手应用**重采样**来调整时间**维度为3分钟步长**。换句话说，它**将转录合并为3分钟的文本部分**。有了这个功能，我们现在可以开始获取和处理转录。

[PRE8]

结果的摘录可以在下图中看到。

![](../Images/9b617d92c19e8202d6e68ff670ca554d.png)

图2. 转录数据框的摘录（图片由作者提供）。

由于合并的 3 分钟部分现在可能会导致令牌限制问题，我们需要在生成嵌入并将其存储在向量存储中之前，使用**分割器**再次处理它们。

[PRE9]

# 运行透明问答

有了填充的向量存储后，我们现在可以专注于**透明问答**。下面的图给出了该过程的概述。

![](../Images/011b144a50c651d7977825ab220ddd86.png)

图 3\. 透明问答过程概述（图片由作者提供）。

我们首先**定义一个问题**，然后由嵌入模型或API**转换**为嵌入。向量存储利用这个问题嵌入来搜索存储中的’n’（默认：4）**相似文档或片段**。随后，将**每个文档或片段的内容与提示组合**并发送到GPT-3。

GPT-3 返回的结果然后**与另一个提示组合**，在**最后一步再次发送回 GPT-3**以获取最终答案，包括来源。

## 网站内容示例

在使用`RetrievalQAWithSourcesChain`之前，我们确保通过实施记忆使我们的机器人**记住**之前的对话。这增强了与用户的上下文相关互动。

[PRE10]

为了将之前的聊天记录整合到使用的提示中，我们需要修改现有的模板。

[PRE11]

之后，我们可以利用 `RetrievalQAWithSourcesChain` 来提问。在这个示例中，我们设置**k=4**，这意味着我们将查询向量存储以获取4个最相似的文档。

[PRE12]

结果以字典形式返回：

[PRE13]

我们可以观察到，结果包含了回答给定问题所用的来源。为了生成这个最终答案，API 被调用了**5次**：4次提取最相似的4个片段中的相关信息，额外1次生成最终答案。

我们还可以提出引用**之前问题**的问题。

[PRE14]

结果将如下所示。

[PRE15]

**请记住，对于这些问题，API 也被调用了5次。**

## YouTube 转录示例（有时间戳和没有时间戳）

YouTube 转录示例的代码与网站的代码非常相似。首先，我们初始化 ConversationBufferMemory，并创建一个自定义问题提示模板。

[PRE16]

然后我们创建带有来源的 QA 链。

[PRE17]

让我们问一个问题。

[PRE18]

不带时间戳的示例结果：

[PRE19]

带时间戳的示例结果：

[PRE20]

# 结论

LangChain 的 RetrievalQAWithSourcesChain 和 GPT-3 的结合非常适合提高问答的透明度。正如过程图所示（图 3），获取最终答案需要**多次调用** OpenAI。

根据你使用服务的情况和需要处理的类似文档数量，调用次数可能会增加，**导致更高的费用**。这确实值得关注。不过，对于你的爱好项目来说，这不应该太关键。为了更好地关注费用和发送的提示，可以考虑使用 [Promptlayer](https://promptlayer.com/home) 或 [TruLens](https://medium.com/towards-artificial-intelligence/evaluate-and-monitor-the-experiments-with-your-llm-app-df391c0f51c9)。

Colab 笔记本可以在这里找到：

+   [网站示例](https://github.com/darinkist/Medium-Article-Transparent-Question-Answering-Bot/blob/main/CodeForArticleWebsiteExample.ipynb)

+   [YouTube 示例](https://github.com/darinkist/Medium-Article-Transparent-Question-Answering-Bot/blob/main/CodeForArticleYouTubeExample.ipynb)

# 资料来源

+   **LangChain RetrievalQAWithSourcesChain API 文档** [https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html)

*所有者或创作者已经提前询问是否允许我将他们的内容/数据用作本文的示例。*

+   It’s FOSS., “It’s FOSS”, [https://itsfoss.com/](https://itsfoss.com/)

+   StatQuest. “XGBoost 第1部分（共4部分）：回归” *YouTube,* Joshua Starmer, 2019年12月16日, [https://youtu.be/OtD8wVaFm6E](https://youtu.be/OtD8wVaFm6E)。

+   StatQuest. “XGBoost 第2部分（共4部分）：分类” *YouTube,* Joshua Starmer, 2020年1月13日, [https://youtu.be/8b1JEDvenQU](https://youtu.be/8b1JEDvenQU)。

+   StatQuest. “XGBoost 第3部分（共4部分）：数学细节” *YouTube,* Joshua Starmer, 2020年2月10日, [https://youtu.be/ZVFeW798-2I](https://youtu.be/ZVFeW798-2I)。

+   StatQuest. “XGBoost 第4部分（共4部分）：疯狂炫酷的优化” *YouTube,* Joshua Starmer, 2020年3月2日, [https://youtu.be/oRrKeUCEbq8](https://youtu.be/oRrKeUCEbq8)。
