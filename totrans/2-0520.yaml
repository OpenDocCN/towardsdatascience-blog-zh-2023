- en: 'Cognitive Biases in Data Science: The Category-Size Bias'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/cognitive-biases-in-data-science-the-category-size-bias-8dbd851608c3](https://towardsdatascience.com/cognitive-biases-in-data-science-the-category-size-bias-8dbd851608c3)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[DATA BIAS HACKERS](https://towardsdatascience.com/tagged/data-cognitive-bias)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A data scientist’s guide to outsmarting biases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)[![Maham
    Haroon](../Images/5a9ac82369ecbf7719b765ec160a70ef.png)](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)
    [Maham Haroon](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)
    ·8 min read·Nov 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eee2dc275bfeecb4dd134047e6cab03f.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Andy Li](https://unsplash.com/@andylid0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/man-in-white-dress-shirt-standing-in-front-of-brown-wooden-shelf-RndRFJ1v1kk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you find yourself in a quaint neighborhood with two bakeries. The first
    is a small, family-owned bakery, warmly nestled on the corner street. The second,
    however, is a grand three-story establishment, with a sign that showcases its
    extensive selection and state-of-the-art ovens.
  prefs: []
  type: TYPE_NORMAL
- en: As you embark on your quest for the perfect loaf of bread, you are drawn to
    the towering bakery. The sheer size and grandeur of the building make an immediate
    impression, making the assumption that the larger bakery must surely produce the
    finest bread.
  prefs: []
  type: TYPE_NORMAL
- en: Here, in this scenario, you’re unknowingly succumbing to a mental tendency known
    as category size bias. The bias leads you to believe that the larger bakery is
    more likely to offer superior bread.
  prefs: []
  type: TYPE_NORMAL
- en: In reality, the size of the bakery doesn’t necessarily correlate with the quality
    of its bread. The smaller, family-owned bakery may have a closely guarded secret
    recipe, perfected over generations, while the larger bakery might focus on quantity
    over artisanal craftsmanship.
  prefs: []
  type: TYPE_NORMAL
- en: This bias echoes our inclination to associate larger categories with better
    outcomes, even when the specific characteristics within those categories may not
    align with our assumptions. This phenomenon is called category size bias.
  prefs: []
  type: TYPE_NORMAL
- en: Category size bias refers to our inclination to perceive outcomes as more probable
    when they belong to a larger category as opposed to a smaller one, even when the
    likelihood of each outcome is equal.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Despite the bias being grounded in experimentally validated studies, there
    is ongoing variability in the interpretation of the evidence.](https://thedecisionlab.com/biases/category-size-bias)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the realm of Data Science, category size bias may manifest via specific
    assumptions. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assumption 1: Larger more complex models always provide better predictions
    compared to smaller models.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within the context of category size bias, the tendency is to believe that the
    performance of a Neural Network or an ML model improves with its size or complexity.
    Consequently, regardless of whether the data or task aligns with the model’s characteristics,
    there’s often a focus on complex models. This inclination is akin to the [bandwagon
    effect](https://thedecisionlab.com/biases/bandwagon-effect), where newer, more
    intricate, and renowned algorithms are presumed to be cutting-edge, even for tasks
    they are not well-suited for. Consider, for instance, using large language models
    (LLMs) for relatively simple tasks.
  prefs: []
  type: TYPE_NORMAL
- en: For example, adding extra layers to a Neural Network, even when they don’t really
    make the model much better, as most tasks can be handled well with just two layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/714b2e09674794c09c497f79cdd11841.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Caveat:** It’s important to note that the assumption of larger, more complex
    models yielding better predictions holds true in many cases, especially when dealing
    with complex tasks that require a high level of precision or problems involving
    vast and diverse datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trade-off:** The trade-off in such scenarios encompasses both performance
    and resource consumption. While complex or larger models demand more resources,
    the increased resource consumption doesn’t automatically translate to superior
    model performance. Although this may not always be necessary or impactful, in
    critical problems, making such considerations can indeed make a significant difference.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assumption 2: Overlooking Class Imbalance by Relying Solely on Higher Accuracy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This problem is a more widely acknowledged one. When utilizing a metric such
    as accuracy, there is a heightened risk of overlooking an underlying bias. To
    illustrate, consider a dataset with 5 instances of a disease among 1000 patients.
    If a model achieves 99.5% accuracy by consistently classifying almost all instances
    as negative (given the majority of instances are negative), the assumption might
    be that the model performs well. However, in reality, the model would be performing
    inadequately by not classifying any instances as positive.
  prefs: []
  type: TYPE_NORMAL
- en: 'To explain further, let’s look at a basic example. We’ll create 100 random
    numbers between 0 and 1\. If a number is over 0.92, we call it positive; otherwise,
    it’s negative. We’ll use logistic regression as our model. The code snippet below
    demonstrates this scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Although the model achieves a respectable accuracy of 0.92, an examination of
    other metrics like recall and f1-score reveals a far inferior performance. In
    the plotted chart on the left, it becomes clear that none of the positive instances
    have been correctly classified as positive.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3327d6d5722a6ce1b4638fdb362ea840.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Caveat:** While accuracy is usually a good measure, there are cases where
    prioritizing higher accuracy makes sense. In cases where class imbalances are
    minimal, and the cost of misclassification is relatively low, prioritizing accuracy
    can be a reasonable choice.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trade-off:** The trade-off in this scenario revolves around performance itself,
    with considerable stakes. However, in instances of minor imbalances or data previously
    processed, this concern may not be as consequential.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assumption 3: Equating Larger Datasets with Improved Performance'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While it’s often the case that larger datasets bring about more features, additional
    information, and an enhanced likelihood of realistic predictions, this holds true
    only up to a point. The amount of data needed depends on the specific problem.
    For example, in classification tasks, scenarios with a smaller number of classes
    or a many informative features might do well with smaller datasets. Similarly,
    tasks involving lower-order function approximation might be content with a more
    modest dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s understand this with an example. First, we make fake data with half of
    it being useful, 5 categories, and around 20,000 samples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Subsequently, we employ Support Vector Classification (SVC) for class separation
    on a subset of the data, specifically 9,000 instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'When measuring the time taken for this task, we observe 6.9590 seconds with
    an accuracy of 0.8430\. Subsequently, we utilize the entire dataset for training
    the SVC, comprising approximately 16,000 instances for training and 4,000 instances
    for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This time, the algorithm takes 20.4149 seconds, about 3x the previous time,
    yielding an accuracy of 0.8452 — remarkably close despite almost double the data.
    A comparison of ROC curves for both models reveals nearly identical results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a3de088294ad99b83d639441dc7a8256.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Caveat:** Complex tasks often need more data, but there’s a point where more
    data doesn’t necessarily mean better results.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trade-off:** While additional data rarely harms the model, the trade-off
    lies not in performance but in computational cost. This cost can be substantial
    when irrelevant information is added to the model, emphasizing the importance
    of data pre-processing and cleaning, particularly in complex tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assumption 4: Equating Longer, More Complex Algorithms with Superior Performance'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While not always true, there exists a notion that longer, complex algorithms
    hold superiority over their shorter, simpler counterparts. Sometimes, a more intricate
    algorithm is favored even when a simpler one perfectly accomplishes the task.
    While this notion is not always unfounded, the issue lies in the underlying rationale
    for such a belief. If complexity and length are genuinely warranted by the algorithm,
    then there’s no harm in their application.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this assumption, let’s compare two code blocks. The first function
    appears quite straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the second function seems to involve more work, evident
    in both time and space complexity. However, the ultimate goal of both functions
    is exactly the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: I intentionally kept this example simple, but the idea applies to more complicated
    code that might focus too much on a specific problem or do different things.
  prefs: []
  type: TYPE_NORMAL
- en: '**Caveat:** This doesn’t apply to adding unit tests, comments, or improvements
    that genuinely make the code better. Furthermore, the belief that longer and more
    complex algorithms are superior is not unfounded in certain contexts. For tasks
    that inherently require nuanced decision boundaries or involve complex relationships,
    a more sophisticated algorithm might indeed be necessary.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trade-off:** The cost of this bias often manifests in terms of computational
    resources. While it might not significantly impact simpler tasks, the expense
    becomes more pronounced for more complex tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Avoiding Category-Size Bias: Strategies for Awareness and Mitigation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While category-size bias may not be the most detrimental bias, it can lead to
    resource drainage.
  prefs: []
  type: TYPE_NORMAL
- en: '***It’s better to break things down to simpler and smaller tasks and start
    there when possible for clearer understanding of the underlying problem.***'
  prefs: []
  type: TYPE_NORMAL
- en: Being aware of our subconscious inclination towards favoring one option over
    another is a key to avoid succumbing to the bias. A valuable approach is to challenge
    assumptions, utilizing the Socratic questioning technique.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.verywellmind.com/socratic-questioning-8350838?source=post_page-----8dbd851608c3--------------------------------)
    [## Understanding Socratic Questioning: A Comprehensive Guide'
  prefs: []
  type: TYPE_NORMAL
- en: Socratic questioning encourages people to think more deeply about an issue,
    stepping outside their own perspective…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.verywellmind.com](https://www.verywellmind.com/socratic-questioning-8350838?source=post_page-----8dbd851608c3--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '***Another approach is attempting to prove the hypothesis opposite to the initially
    favored one.***'
  prefs: []
  type: TYPE_NORMAL
- en: Taking the time to individually assess data and treat each problem distinctly
    can provide valuable insights.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In conclusion, this post highlighted the influence of category-size bias in
    the realm of data science. The key takeaway is, to stay mindful of the bias and
    consistently take the context of the problem into account.
  prefs: []
  type: TYPE_NORMAL
- en: Coming up on the horizon…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our analyses often don’t rely only on algorithms and models, but are heavily
    influenced by the deeply embedded cognitive biases. This post explored the Category-Size
    Bias and its impact on decision-making in data science. However, this is just
    the start. In upcoming posts of this series, I’d focus on uncovering more cognitive
    biases and their impact on data research and analytics. From assumptions about
    causation to the appeal of anecdotal evidence, from confirmation bias to the bandwagon
    effect, the posts will explore the intersection of human biases and data science.
  prefs: []
  type: TYPE_NORMAL
- en: It’s my goal to present more in-depth examination of biases that could affect
    our analytical pursuits, and promote a more nuanced and bias-aware data science
    practice.
  prefs: []
  type: TYPE_NORMAL
- en: I add some additional resources or further exploration.
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](https://thedecisionlab.com/biases?source=post_page-----8dbd851608c3--------------------------------)
    [## List of Cognitive Biases and Heuristics - The Decision Lab'
  prefs: []
  type: TYPE_NORMAL
- en: Below is a list of the most important cognitive biases and heuristics in the
    field of behavioural science.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'thedecisionlab.com](https://thedecisionlab.com/biases?source=post_page-----8dbd851608c3--------------------------------)
    [](https://www.teachthought.com/critical-thinking/cognitive-biases/?source=post_page-----8dbd851608c3--------------------------------)
    [## The Cognitive Biases List: A Visual Of 180+ Heuristics'
  prefs: []
  type: TYPE_NORMAL
- en: Cognitive biases are tendencies to selectively search for or interpret data
    in a way that confirms one's existing…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.teachthought.com](https://www.teachthought.com/critical-thinking/cognitive-biases/?source=post_page-----8dbd851608c3--------------------------------)
    [](https://www.mindtools.com/aipz4vt/the-ladder-of-inference?source=post_page-----8dbd851608c3--------------------------------)
    [## The Ladder of Inference - How to Avoid Jumping to Conclusions
  prefs: []
  type: TYPE_NORMAL
- en: Use the Ladder of Inference to explore the seven steps we take in our thinking
    to get from a fact to a decision or…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.mindtools.com](https://www.mindtools.com/aipz4vt/the-ladder-of-inference?source=post_page-----8dbd851608c3--------------------------------)
  prefs: []
  type: TYPE_NORMAL
