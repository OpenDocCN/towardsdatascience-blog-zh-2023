["```py\nn_samples = 100\nX = np.random.rand(n_samples, 1) - 0.5\ny = 5 * X[:, 0] ** 2 + 0.1 * np.random.randn(n_samples)\n\nplt.scatter(X, y, s=20)\n```", "```py\nh1 = DecisionTreeRegressor(max_depth=2)\nh1.fit(X, y)\n```", "```py\nF1 = [h1]  # ensemble of one tree\nF1_pred = h1.predict(X)\nprint(f'R2 score of F1: {r2_score(y, F1_pred):.4f}')\n```", "```py\nR2 score of F1: 0.7819\n```", "```py\nh2 = DecisionTreeRegressor(max_depth=2)\ny2 = y - F1_pred\nh2.fit(X, y2)\n```", "```py\nF2 = [h1, h2] # ensemble of two trees\nF2_pred = sum(h.predict(X) for h in F2)\nprint(f'R2 score of F2: {r2_score(y, F2_pred):.4f}')\n```", "```py\nR2 score of F2: 0.8802\n```", "```py\nh3 = DecisionTreeRegressor(max_depth=2)\ny3 = y - F2_pred\nh3.fit(X, y3)\n\nF3 = [h1, h2, h3] # ensemble of three trees\nF3_pred = sum(h.predict(X) for h in F3)\nprint(f'R2 score of F3: {r2_score(y, F3_pred):.4f}')\n```", "```py\nR2 score of F3: 0.9124\n```", "```py\nfig, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(12, 7))\nX_test = np.linspace(-0.5, 0.5, 500).reshape(-1, 1)\n\nfor i, h, residuals in zip([0, 1, 2], [h1, h2, h3], [y, y2, y3]):\n    ax = axes[0, i]\n    y_test_pred = h.predict(X_test)\n    ax.scatter(X, residuals, c='k', s=20, marker='x', label='Residuals')\n    ax.plot(X_test, y_test_pred, 'r', linewidth=2)\n    ax.set_title(f'$h_{i + 1}(x)$')\n    ax.legend(loc='upper center')\n\nfor i, ensemble in enumerate([F1, F2, F3]):\n    ax = axes[1, i]\n    y_test_pred = sum(h.predict(X_test) for h in ensemble)\n    ax.scatter(X, y, s=20, label='Training set')\n    ax.plot(X_test, y_test_pred, 'm', linewidth=2)\n    ax.set_title(f'$F_{i + 1}(x)$')\n    ax.legend(loc='upper center')\n```"]