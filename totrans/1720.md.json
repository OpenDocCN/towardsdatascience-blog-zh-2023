["```py\n# dictcomp_pipeline.py\n\nfrom pathlib import Path\nfrom collections.abc import Sequence\n\nfrom typing import Any, Optional\n\n# Type aliases\nPaths = Sequence[Path]\nKeywordArgs = Optional[dict[str, Any]]\n\ndef read_text(path: Path) -> str:\n    \"\"\"Read text from path and return a string.\"\"\"\n    return path.read_text()\n\ndef parse_text(text: str, word: str) -> bool:\n    \"\"\"Parse text from string and return a bool value.\"\"\"\n    return word.lower() in text.lower()\n\ndef run_dictcomp_pipeline(\n    documents: Any,\n    read_text_kwargs: KeywordArgs = None,\n    parse_text_kwargs: KeywordArgs = None) -> dict[str, bool]:\n    read_text_kwargs = read_text_kwargs or {}\n    parse_text_kwargs = parse_text_kwargs or {}\n\n    texts = {\n        doc: read_text(doc, **read_text_kwargs)\n        for doc in documents\n    }\n    return {\n        str(doc): parse_text(text, **parse_text_kwargs)\n        for doc, text in texts.items()\n    }\n```", "```py\n# test_dictcomp_pipeline.py\n\nimport pathlib\nimport pytest\n\nfrom dictcomp_pipeline import get_dictcomp_pipeline\n\n@pytest.fixture\ndef files():\n    n_files = 11\n    paths = [pathlib.Path(\".\") / f\"txt_file_{i}.txt\"\n             for i in range(n_files)]\n    for i, path in enumerate(paths):\n        text = \"Shout Bamalama!\\nI'm an elephant, and so what?\\n\\n\"\n        if i % 2 == 0:\n            text = f\"{text}Python\"\n        path.write_text(text)\n    yield paths\n    for path in paths:\n        path.unlink()\n\ndef test_get_dictcomp_pipeline(files):\n    isPython = get_dictcomp_pipeline(\n        files,\n        parse_text_kwargs={\"word\": \"Python\"}\n    )\n    assert isPython == {\n        'txt_file_0.txt': True,\n        'txt_file_1.txt': False,\n        'txt_file_2.txt': True,\n        'txt_file_3.txt': False,\n        'txt_file_4.txt': True,\n        'txt_file_5.txt': False,\n        'txt_file_6.txt': True,\n        'txt_file_7.txt': False,\n        'txt_file_8.txt': True,\n        'txt_file_9.txt': False,\n        'txt_file_10.txt': True\n        }\n```", "```py\n# dictcomp_pipeline.py\n\nfrom pathlib import Path\nfrom collections.abc import Sequence\n\nfrom typing import Any, Optional\n\n# Type aliases\nPaths = Sequence[Path]\nKeywordArgs = Optional[dict[str, Any]]\n\ndef read_text(path: Path) -> str:\n    \"\"\"Read text from path and return a string.\n\n    You can rewrite this function to read from another source.\n    The function must return a string, but it can take any\n    number of keyword arguments. The first argument must\n    work as positional, and it must represent a document\n    from the `documents` sequences from `run_dictcomp_pipeline()`.\n    \"\"\"\n    return path.read_text()\n\ndef parse_text(text: str, word: str) -> bool:\n    \"\"\"Parse text from string and return a bool value.\n\n    You can rewrite this function to use different\n    parsing logic. The function must return a bool,\n    but it can take any number of keyword arguments.\n    The first argument must remain unchanged, and must\n    work as a positional argument.\n    \"\"\"\n    return word.lower() in text.lower()\n\ndef run_dictcomp_pipeline(\n    documents: Any,\n    read_text_kwargs: KeywordArgs = None,\n    parse_text_kwargs: KeywordArgs = None) -> dict[str, bool]:\n    \"\"\"Run dictcomp pipeline.\n\n    The function does not handle exceptions: if anything goes\n    wrong, the pipeline breaks and the corresponding exception\n    is raised.\n\n    Args:\n        paths (Paths): sequence with paths to files with\n            documents to read\n        word (str): word to look for in documents\n        read_text_kwargs (KeywordArgs, optional): dictionary with\n            keyword arguments to be used in a call to `read_text()`,\n            if needed. Defaults to None, meaning that no arguments\n            are passed.\n        parse_text_kwargs (KeywordArgs, optional): dictionary with\n            keyword arguments to be used in a call to `parse_text()`,\n            if needed. Defaults to None, meaning that no arguments\n            are passed.\n\n    Returns:\n        dict[Path, bool]: dictionary with the output of\n            the pipeline; its result represent the parsing logic\n            used in the documents\n    \"\"\"\n    read_text_kwargs = read_text_kwargs or {}\n    parse_text_kwargs = parse_text_kwargs or {}\n\n    texts = {\n        doc: read_text(doc, **read_text_kwargs)\n        for doc in documents\n    }\n    return {\n        str(doc): parse_text(text, **parse_text_kwargs)\n        for doc, text in texts.items()\n    }\n```", "```py\n# optionalbool_dictcomp_pipeline.py\n\nfrom pathlib import Path\nfrom collections.abc import Sequence\n\nfrom typing import Any, Optional\n\nfrom optionalbool import OptionalBool\n\n# Type aliases\nPaths = Sequence[Path]\nKeywordArgs = Optional[dict[str, Any]]\n\ndef read_text(path: Path) -> str:\n    \"\"\"Read text from path and return a string.\"\"\"\n    return path.read_text()\n\ndef parse_text(text: str,\n               word: str,\n               standards_phrases: Sequence[str]\n               ) -> OptionalBool:\n    \"\"\"Parse text from string and return a bool value.\"\"\"\n    if not any(phrase.lower() in text.lower() for phrase in standards_phrases):\n        return OptionalBool(None)\n    return OptionalBool(word.lower() in text.lower())\n\ndef run_dictcomp_pipeline(\n    documents: Any,\n    read_text_kwargs: KeywordArgs = None,\n    parse_text_kwargs: KeywordArgs = None\n    ) -> dict[str, OptionalBool]:\n    read_text_kwargs = read_text_kwargs or {}\n    parse_text_kwargs = parse_text_kwargs or {}\n\n    texts = {\n        doc: read_text(doc, **read_text_kwargs)\n        for doc in documents\n    }\n    return {\n        str(doc): parse_text(text, **parse_text_kwargs)\n        for doc, text in texts.items()\n    }\n```", "```py\n# test_optionalbool_dictcomp_pipeline.py\n\nimport pathlib\nimport pytest\n\nfrom optionalbool_dictcomp_pipeline import run_dictcomp_pipeline\n\nfrom optionalbool import OptionalBool\n\n@pytest.fixture\ndef files():\n    n_files = 11\n    paths = [pathlib.Path(\".\") / f\"doc_file_{i}.txt\"\n             for i in range(n_files)]\n    for i, path in enumerate(paths):\n        text = \"Shout Bamalama!\\nI'm an elephant, and so what?\\n\\n\"\n        if i % 2 == 0:\n            text = f\"{text}Python\"\n        if i % 3 != 0:\n            text = (\n                \"This is a Standard Operating Procedure\\n\"\n                f\"{text}\"\n            )\n        path.write_text(text)\n    yield paths\n    for path in paths:\n        path.unlink()\n\ndef test_get_dictcomp_pipeline(files):\n    standards_phrases = [\"Standard Operating Procedure\", \"SOP\",]\n    isPython = run_dictcomp_pipeline(\n        files,\n        parse_text_kwargs={\"word\": \"Python\",\n                           \"standards_phrases\": standards_phrases}\n    )\n    for v in isPython.values():\n        assert isinstance(v, OptionalBool)\n    assert isPython == {\n        'doc_file_0.txt': None,\n        'doc_file_1.txt': False,\n        'doc_file_2.txt': True,\n        'doc_file_3.txt': None,\n        'doc_file_4.txt': True,\n        'doc_file_5.txt': False,\n        'doc_file_6.txt': None,\n        'doc_file_7.txt': False,\n        'doc_file_8.txt': True,\n        'doc_file_9.txt': None,\n        'doc_file_10.txt': True\n    }\n```"]