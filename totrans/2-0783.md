# 边缘情感识别：通过实时语音分析提升人机互动

> 原文：[https://towardsdatascience.com/edge-emotion-recognition-enhancing-human-machine-interaction-through-real-time-speech-analysis-235ee97cc5f6](https://towardsdatascience.com/edge-emotion-recognition-enhancing-human-machine-interaction-through-real-time-speech-analysis-235ee97cc5f6)

[](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)[![Rüdiger Buchkremer, PhD](../Images/c116ab76808a3b5c892e2917f1a679d7.png)](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------) [Rüdiger Buchkremer, PhD](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------) ·13分钟阅读·2023年7月23日

--

在现代世界中，我们与计算机的对话增长了指数级。但可惜的是，这些技术奇迹对我们的情感毫无察觉，这可能会带来不便。在这篇文章中，我将尝试揭示通过先进技术手段检测情感的有趣方法。不仅如此，我还将给你讲述一个我们创新大学研究所开发的突破性程序的故事，该程序可以在没有网络连接的情况下操作。所以，请系好安全带，准备好被情感识别技术的奇迹所吸引吧！

![](../Images/79d8f4540c56db0ace654d9785a3fcfe.png)

来源：作者，图像由人工智能生成（leonardo.ai）

## **背景故事**

人们通过不仅仅是他们说的话来表达感情。他们的声音语调、说话速度，甚至是之间的沉默都能提供**幸福、悲伤、愤怒、恐惧、厌恶和惊讶**的线索。

*但标准计算机对这些含义一无所知。它们只是处理基本的语音声音。*

最近，我越来越多地需要与计算机沟通，要么由人类中介提供指导，要么直接回应我的询问。**这让我烦恼**的是，这些计算机似乎完全没有意识到这种互动对我产生的情感影响，因为它们始终以冷漠和客观的方式回应，这只会加剧我的挫败感。

为了解决这个问题，我们研究所的研究人员开展了一项合作研究，结果由Dominik和我在一篇科学文章中发表，这篇文章相当冗长且技术性强。然而，我很高兴地通知您，我们原始的24页科学论文，最近在《计算机科学研究期刊》上发表，链接可以在当前文章的末尾找到。

## **当前技术背景**

随着机器在我们日常生活中集成的不断推进，对这些机器能够理解人类情感的需求也在增长。当我们与计算机、机器人和AI助手互动时，我们通过语调变化、面部表情和手势等多种方式表达情感是自然的。然而，值得注意的是，**大多数现有技术缺乏对这些情感信号的全面理解。**

研究人员已经开发出能够有效识别一个人声音中情感的系统，以解决这个问题。类似于人类如何从语音模式的变化中获取意义，这些机器正逐步获得解释暂停、音调、音量、节奏及其他细微差别的能力，旨在识别如快乐、悲伤、愤怒等情感。

**一种特别的方法涉及利用机器学习技术对大量情感语音样本进行算法训练**。通过揭示与各种情感状态相关的**声学模式**，这些系统可以以约70%的准确率对基本情感进行分类。

**其他研究人员将语音转换为称为频谱图的视觉表示**，频谱图是表示声波模式的彩色图像。

## **研究里程碑**

在2000年代初，云计算作为一项革命性里程碑出现，改变了商业模式并引发了全球创新。**然而，云计算的统治正面临黄昏，** 一种称为边缘计算的新范式正在抢占风头，这一变化受到不断发展的需求和要求的驱动。

边缘计算具有满足低延迟、增强数据安全性、无缝移动支持和实时处理的能力，使其成为对抗云计算的强大竞争者。

边缘计算领域主要有三个子领域：雾计算、云端计算和移动边缘计算（MEC）。虽然雾计算和云端计算在实际应用中仍显得难以普及，但MEC已成为明星技术。

**想象一下：** MEC站点就在或位于接近终端设备内部，确保日常使用这项尖端技术。MEC意味着数据处理会立即发生，在终端设备上完成。

我们还有移动云计算（MCC），其中终端设备执行处理，仅将结果发送回MEC或MCC服务器。**结合云计算和边缘计算技术提供了令人眼花缭乱的可能性**，满足各种用例，并充分发挥其独特的优势。

现在，让我们转向另一个引人入胜的话题：语音情感识别（SER）以及特征提取和模式识别的迷人世界。当代研究正热烈讨论SER，其中连续和光谱语音特征成为焦点，以惊人的准确性捕捉情感的本质。

情感识别的旅程依赖于主要语音频率、响度、时间比率、停顿以及像梅尔频率倒谱系数（MFCC）和所谓的梅尔谱图等光谱特征的表现。

**梅尔谱图**

在迷人的音频和语音处理领域，一颗迷人的明星已经崭露头角——梅尔谱图（mel 代表旋律）。这个令人着迷的可视化工具已经成为焦点，吸引了研究人员和爱好者。其卓越之处在于能够以一种独特的方式描绘声音信号随时间的频率内容。

通过利用梅尔尺度，这一尺度反映了我们对音高的感知，梅尔谱图捕捉了在语音和音频分析中具有重要意义的不同频带的本质。这种卓越的方法提供了丰富的洞察力，揭示了信号的声学特征，使其在诸多应用中成为不可或缺的伙伴，包括语音识别和音乐处理。

从本质上讲，梅尔谱图作为一个仁慈的向导，揭示了声音的奥秘，照亮了频率与时间之间的微妙舞蹈，并滋养了我们对迷人音频世界的理解。

![](../Images/fdacca4b3da99b8121a03c33fa23584a.png)

来源：作者；图片升级自Estevez de Andrade & Buchkremer，《计算机科学研究杂志》（2023）

## **机器学习技术**

在追求分类卓越的过程中，诸多技术相继登场，从经典的高斯混合模型（GMM）和隐马尔可夫模型（HMM）组合到迷人的支持向量机（SVM），以及神经网络的迷人世界。

*迷人的魅力并未止步于此；我们完全被递归神经网络（RNN）如长短期记忆（LSTM）的迷人潜力所吸引。但请等一下，现在的聚光灯照在了卷积神经网络（CNN）上，例如AlexNet、VGG16、ResNet和MobileNetV2，这些网络凭借其卓越的资源和记忆效率占据了领先地位。这就像目睹了一场盛大的变革——MFCC和梅尔谱图与CNN相结合，以及迁移学习和多任务学习的神秘艺术放大了其魅力。*

# **想象一下：在小型计算机上运行所有这些的美妙前景，完全摆脱了大型供应商的束缚。**

这不仅为我们提供了提升数据隐私的宝贵礼物，还赋予了我们新的独立感。

凭借这一非凡组合，我们可以蓬勃发展，打破束缚我们的链条，迎接一个自主无限的世界。因此，让我们陶醉于这种赋权的可能性中，隐私与自我依赖交织在一起，抓住机会规划我们的数字命运。

## **通过参数集提取正确的数据**

每一个优秀的识别性能都源于巧妙提取的特征。这项技艺涉及从多样化的集合中仔细选择。备受青睐的机器学习魔术师是迷人的开源框架——大空间提取的语音和音乐解释（openSMILE）。这个出色的框架包含了扩展的日内瓦简约声学参数集（eGeMAPS）和ComParE数据集，在这个宏伟的演出中扮演了重要角色。在深度学习中，聚光灯转向CNN，它们优雅地担任特征提取的角色，既可以作为分类器，也可以将接力棒交给SVM，以其多才多艺迷住观众。

在这激动人心的情感分类过程中，各种情感展现出来，每种情感都包含独特的情感数量。观众沉浸在从五种到惊人的二十种情感中。在众多情感中，Ekman的经典情感格外引人注目：**快乐、悲伤、愤怒、恐惧、厌恶和惊讶**，以及神秘的第七种情感，中立。

**随着边缘计算的崭露头角和神经网络的魔力释放，情感识别的未来充满了无限可能。**

## **我们的做法**

我们探索了语音中的情感识别，利用标注的情感语音数据进行原型实现。为了确保数据集的健壮性，我们寻找了长度在一到二十秒之间的音频文件。我们主要关注那些，正如之前提到的，情感数据库中常见的六种基本情感。然而，我们在工作中并未考虑唤醒度和情感价值维度，因此在数据采集过程中忽略了这些标准。

**在人类语音中，情感通常会在单个句子中出现。** 因此，选择的音频长度在一到二十秒之间主观上较为合适，能够涵盖大多数口语句子。

*所选音频文件需要排除唱歌、噪声或类似干扰，以保持清晰和相关性。虽然说话者的母语不是选择标准，但我们确保在获取的数据库中男性和女性口语句子的表现是平衡的。通道数量或采样率等因素在数据采集阶段也没有意义，因为这些参数在训练过程中会被标准化。*

最后，为了可访问性和清晰性，音频文件和数据库需要是自由获取的，并且由适当的标签标识。

以这些质量标准为基础，我们选择了符合我们标准的以下音频数据库：

**1)** 瑞尔森情感语音与歌曲视听数据库 (RAVDESS)

**2)** 柏林情感语音数据库 (Emo-DB)

**3)** 多伦多情感语音集 (TESS)

**4)** EMOVO

**5)** eNTERFACE’05

在我们的研究中，机器学习和深度学习技术相结合，深入探索情感识别的神秘世界。探寻始于共享的数据语料库，依据现有文献中精心列出的预定义标准进行挑选。不包含口语的句子被排除在外，因为原型专注于语音情感识别（SER）。仅允许纯语音文件，即使一些音乐作品包含带有乐器的口语段落。

说到背景噪声，它在这段旋律之旅中是不可忽视的。现实生活中的交流常发生在嘈杂的环境中，因此带有背景噪声的音频数据对于丰富研究至关重要。但不要把它与音乐中的背景噪声混淆，音乐背景噪声在与语音相关的场景中扮演着不同的角色。

**音频文件中使用的母语也没有限制。** 德语、英语、意大利语、土耳其语、丹麦语或中文——所有语言都欢迎加入这个引人入胜的舞台。为什么？因为达尔文和艾克曼描述的六种基本情感在不同文化中以相似的方式表达，超越了语言障碍。

**对标记数据的开放获取是我们神秘冒险的另一个关键。**

没有它，整个旅程将充满神秘，使得其他人无法重现结果。毕竟，监督式机器学习算法依赖于标记数据。

现在，让我们谈谈这场表演的明星——超参数！

*超参数是深度学习和机器学习中的关键元素，像旋钮一样控制模型的学习过程和性能。它们在训练前设定，影响模型的结构和复杂性。*

*在机器学习中，常见的超参数包括学习率，它决定了模型在训练过程中调整参数的程度，以及隐藏层的数量，这影响了模型的深度和学习复杂模式的能力。*

*在深度学习中，由于深度神经网络的复杂性，超参数变得尤为重要。具体的超参数包括丢弃率、激活函数、优化算法和权重初始化，它们在模型性能中扮演着至关重要的角色。*

深度学习拥有明确的超参数，而机器学习则寻求基于预定义标准找到最优值。这两种方法之间的较量展开，每种方法都争夺着焦点。

随着研究的推进，我们遇到了一些基础模型——MobileNetV2、CNN ResNet50和SqueezeNet——它们都渴望展示各自的独特优势。但请记住，通向伟大的道路并非没有挑战。过拟合和欠拟合为故事增添了一丝戏剧性，让我们保持高度关注。

情节更加复杂！这项研究中开发的原型设备专为配备麦克风的设备量身定制，使其成为智能音响和电视的完美伴侣。它们已经准备好踏上伟大的冒险，将情感识别带入日常生活。

由于实时能力的需求，机器学习方法的速度优势成为关键因素。随着时间的流逝，毫秒的差距决定了比赛的结果。

但等一下，还有更多！这项研究为未来的实时SER和边缘计算的调查开辟了无尽的可能性。谁知道情感识别中还隐藏着哪些未解之谜？

## **结论**

在我们开创性的研究中，前沿的语音情感识别（SER）系统成为焦点，展示了它们在许多实际应用中的潜力。

(i) 通用应用：SER应用展示了它们的多功能性，广泛应用于呼叫中心、广播、电台、播客和电视节目。可不仅如此！想象一下一个智能音响，能在你家中检测到声音活动和情绪，根据你的感受提供个性化的产品和服务。或者如何在体育比赛中实现自动化亮点，量身定制以匹配当时的情绪？可能性无穷，甚至可以扩展到像Twitch或Netflix这样的互联网广播。

(ii) 实时观众情绪捕捉：准备好实时情绪追踪吧！想象一下拥有一个可以随时评估观众情绪的工具。政治演讲、产品介绍——没有任何场合是这个尖端技术无法涉足的。演讲者现在可以即时获得他们激发的情感反馈，彻底改变了在实体、虚拟或混合环境中沟通的艺术。

(iii) 以个人为中心的应用：情感识别变得更加个性化，迎合个人用户及其情感需求。想象一下一个智能音响或汽车根据你的情绪调整音乐或照明。在游戏中，当算法检测到愤怒时可以提供缓解。而且，准备好在社交媒体或电子商务平台上看到根据你的情感状态动态变化的个性化广告吧。这就像拥有一个专属的情感管家！

那么，我们是如何来到这里的呢？这项研究通过系统的文献综述，开发了两个使用机器学习和深度学习的原型，并通过一个包含五个音频数据库的大型数据语料库进行了严格的模型训练。

在机器学习方法中，openSMILE框架施展其魔力，提取特征，然后对这些特征进行标准化并用于分类。支持向量机（SVM）是主要的分类器，能够识别不同的声音和语音文件中的七种不同情感。该原型在1000毫秒内提供结果，以其速度和准确性令人着迷。

不过，还有更多惊喜！深度学习模型引入了Mel谱图，解锁了情感识别的新维度。在TensorFlow的忠实伴随下，卷积神经网络（CNN）成为焦点，精通特征提取和分类。笔记本电脑和Raspberry Pi也加入了这个派对，展示了模型的便携性和效率。

随着研究的展开，我们见证了SER系统在增强人机交互方面的激动人心的潜力。想象一下一个我们的设备能够理解我们情感的世界，提供更类似人类和直观的响应。这是对未来沟通的瞥见！

但故事并未就此结束。这项研究让我们渴望更多，暗示了未来研究的方向。情感超越了主要的六种，探索唤醒和效价维度，调查基于识别情感的机器行为——可能性是巨大的。还有不同的模型训练超参数和新颖的迁移学习技术呢？对更深层次理解和改进性能的追求才刚刚开始。

## **伦理问题**

这次旅程中的一个重大伦理问题是知情同意和隐私。**我们的情感是否应该在我们不知情的情况下被审视？** 这就像是在未经允许的情况下窥探我们的情感日记。透明性和获得我们分析情感的许可是关键的检查点。

现在，让我们谈谈令人兴奋的操控和剥削的前景。权力越大，责任越大，实时观众情绪捕捉也不免受到滥用的风险。想象一下政治家或广告商利用你的情感状态为自己谋取利益。这就像幕后有提线木偶操控情感。我们需要保护措施和规定来确保这项技术受到控制。

算法可能是狡猾的家伙，会拾取我们世界中的现有偏见。如果这些偏见渗透到技术中，**我们就会面临伦理雷区**。我们必须确保公平对待每个人，无论种族、性别或背景如何。

那么情感健康如何呢？在我们不知道的情况下持续监测可能会影响我们的心理。感觉像大哥在监视你的每一个情感，并不是一个令人安慰的想法。我们需要在这次旅程中保护我们的心理和情感健康。

当然，别忘了准确性和可靠性——这是我们旅程中的关键检查点。

情感识别并不完美，将其用于决定生活中的重大事项就像信任一个缺少螺栓的过山车。我们需要确保这项技术不会因错误的读数让我们悬挂在半空中。

为个人利益操控情感听起来像科幻末日，而不是我们理想的主题公园。我们的选择和决定应该是我们的，而不是被狡猾的情感追踪者操控。

文化敏感性是必须的！情感在不同文化中各异，就像全球自助餐中的各种风味。我们不能强加一种适合所有人的情感规范；那就像把花生酱涂在所有食物上一样。

既然我们提到这个话题，**让我们谈谈算法透明度**。这就像被困在一个不知道如何运作的过山车上。我们需要明确解释这项技术如何得出结论，这样我们就不会陷入伦理的回旋圈。

我们需要知道谁掌握了我们的情感数据以及他们如何处理这些数据。这就像把我们情感王国的钥匙交给别人；我们最好了解是谁在掌舵。

通过适当的预防措施，我们可以确保这项技术实现它所承诺的奇迹，而不会让我们面临令人不安的伦理问题。

## **关于这个话题的个人备注**

我们为成功在像树莓派这样的微型计算机上实现情感识别技术感到非常自豪。

然而，必须认识到这一技术可能带来的潜在负面影响。虽然我会很高兴如果我互动的计算机能够更好地感知我的情感，但我也担心在我不希望透露情感时被意外检测到。因此，我们必须考虑这个研究背景中的伦理隐患。

鉴于这些考虑，研究项目的伦理方面变得尤为重要。通过我们的努力，我真诚希望能照亮一个令人振奋的话题，并激发有意义的讨论。我们在一起探索这个迷人的话题时，期待你的反馈。

**进一步阅读的科学文章**

*Andrade, D.E. De; Buchkremer, R. 提升人机互动：通过语音分析进行实时情感识别。计算机科学研究杂志* ***2023****, 5, 22–45, doi:10.30564/jcsr.v5i3.5768.*

**如果你觉得这很有趣：**

*你可以查看我的其他文章，也可以通过*[***LinkedIn***](https://www.linkedin.com/in/buchkremer/)***与我联系或找到我。***
