- en: 'Backpropagation: Step-By-Step Derivation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/backpropagation-step-by-step-derivation-99ac8fbdcc28](https://towardsdatascience.com/backpropagation-step-by-step-derivation-99ac8fbdcc28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A complete guide to the algorithm used to train neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@roiyeho?source=post_page-----99ac8fbdcc28--------------------------------)[![Dr.
    Roi Yehoshua](../Images/905a512ffc8879069403a87dbcbeb4db.png)](https://medium.com/@roiyeho?source=post_page-----99ac8fbdcc28--------------------------------)[](https://towardsdatascience.com/?source=post_page-----99ac8fbdcc28--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----99ac8fbdcc28--------------------------------)
    [Dr. Roi Yehoshua](https://medium.com/@roiyeho?source=post_page-----99ac8fbdcc28--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----99ac8fbdcc28--------------------------------)
    ·11 min read·Apr 10, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e828233e39b8fb6f6f3bf155056673e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [DeepMind](https://unsplash.com/@deepmind?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/8heReYC6Zt0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: In the [previous article](https://medium.com/@roiyeho/multi-layer-perceptrons-8d76972afa2b)
    we talked about multi-layer perceptrons (MLPs) as the first neural network model
    that could solve non-linear and complex problems.
  prefs: []
  type: TYPE_NORMAL
- en: For a long time it was not clear how to train these networks on a given data
    set. While single-layer perceptrons had a simple learning rule that was guaranteed
    to converge to a solution, it could not be extended to networks with more than
    one layer. The AI community has struggled with this problem for more than 30 years
    (in a period known as the “AI winter”), when eventually in 1986 Rumelhart et al.
    introduced the **backpropagation algorithm** in their groundbreaking paper [1].
  prefs: []
  type: TYPE_NORMAL
- en: In this article we will discuss the backpropagation algorithm in detail and
    derive its mathematical formulation step-by-step. Since this is the main algorithm
    used to train neural networks of all kinds (including the deep networks we have
    today), I believe it would be beneficial to anyone working with neural networks
    to know the details of this algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although you can find descriptions of this algorithm in many textbooks and
    online sources, in writing this article I have tried to keep the following principles
    in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Use clear and consistent notations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain every step of the mathematical derivation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Derive the algorithm for the most general case, i.e., for networks with any
    number of layers and any activation or loss functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After deriving the backpropagation equations, a complete pseudocode for the
    algorithm is given and then illustrated on a numerical example.
  prefs: []
  type: TYPE_NORMAL
- en: Before reading the article, I recommend that you refresh your calculus knowledge,
    specifically in the area of derivatives (including [partial derivatives](https://en.wikipedia.org/wiki/Partial_derivative)
    and the [chain rule of derivatives](https://en.wikipedia.org/wiki/Chain_rule)).
  prefs: []
  type: TYPE_NORMAL
- en: Now grab a cup of coffee and let’s dive in :)
  prefs: []
  type: TYPE_NORMAL
- en: The Three Phases of the Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The backpropagation algorithm consists of three phases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Forward pass**. In this phase we feed the inputs through the network, make
    a prediction and measure its error with respect to the true label.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Backward pass.** We propagate the gradients of the error with respect to
    each one of the weights backward from the output layer to the input layer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Gradient descent step**. We slightly tweak the connection weights in the
    network by taking a step in the opposite direction of the error gradients.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will now go over each one of these phases in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Forward Pass
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the forward pass, we propagate the inputs in a forward direction, layer-by-layer,
    until the output is generated. The activation of neuron *i* in layer *l* is computed
    using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e047a8af35d57800a95e155af0189bf.png)'
  prefs: []
  type: TYPE_IMG
- en: The forward pass equation
  prefs: []
  type: TYPE_NORMAL
- en: where *f* is the activation function, *zᵢˡ* is the net input of neuron *i* in
    layer *l*, *wᵢⱼˡ* is the connection weight between neuron *j* in layer *l* — 1
    and neuron *i* in layer *l*, and *bᵢˡ* is the bias of neuron *i* in layer *l*.
    For more details on the notations and the derivation of this equation see my [previous
    article](https://medium.com/@roiyeho/multi-layer-perceptrons-8d76972afa2b).
  prefs: []
  type: TYPE_NORMAL
- en: 'To simplify the derivation of the learning algorithm, we will treat the bias
    as if it were the weight *w*₀ of an input neuron *x*₀ that has a constant value
    of 1\. This enables us to write the above equation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8d660784aa002a8d9e09340051323e73.png)'
  prefs: []
  type: TYPE_IMG
- en: Backward Pass
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the backward pass we propagate the gradients of the error from the output
    layer back to the input layer.
  prefs: []
  type: TYPE_NORMAL
- en: Definition of the Error and Loss Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We first define the error of the network on the training set with respect to
    its weights. Let’s denote by **w** the vector that contains all the weights of
    the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assume that we have *n* training samples {(**x***ᵢ, yᵢ*)}, *i* = 1,…,*n*, and
    the output of the network on sample *i* is *oᵢ*. Then the error of the network
    with respect to **w** is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/508f02875ea0f634d6db4a6580d48141.png)'
  prefs: []
  type: TYPE_IMG
- en: The error function
  prefs: []
  type: TYPE_NORMAL
- en: 'where *J*(*y*, *o*) is the **loss function.** The specific loss function that
    we use depends on the task the network is trying to accomplish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For regression problems, we use the **squared loss** function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/0e4f8824ade135f76abe47d4754fffe7.png)'
  prefs: []
  type: TYPE_IMG
- en: '2\. For binary classification problems, we use **log loss** (also known as
    the **binary cross-entropy loss**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6aeb6075d5e97275dac0b0b8ad1f83d2.png)'
  prefs: []
  type: TYPE_IMG
- en: '3\. For multi-class classification problems, we use the **cross-entropy loss**
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1642774222b5fdf2522fd0b4e9423922.png)'
  prefs: []
  type: TYPE_IMG
- en: where *k* is the number of classes.
  prefs: []
  type: TYPE_NORMAL
- en: The reason why we use these specific loss functions is explained in detail in
    [this article](/loss-functions-in-machine-learning-9977e810ac02).
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal is to find the weights **w** that minimize *E*(**w**). Unfortunately,
    this function is non-convex because of the non-linear activations of the hidden
    neurons. This means that it may have multiple local minima:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa359faad562fcdba72eb2d2f6ae8d8a.png)'
  prefs: []
  type: TYPE_IMG
- en: There are various techniques that can be used to prevent gradient descent from
    getting stuck in a local minimum, such as momentum. These techniques will be covered
    in future articles.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Gradients of the Error
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to use gradient descent, we need to compute the partial derivatives
    of *E*(**w**) with respect to each one of the weights in the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9e4c8524d699d0015e1c58263d0e6abe.png)'
  prefs: []
  type: TYPE_IMG
- en: The partial derivative of the error with respect to a given weight
  prefs: []
  type: TYPE_NORMAL
- en: 'To simplify the mathematical derivation, we will assume that we have only one
    training example and find the partial derivatives of the error with respect to
    that example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c05fc19990455b4a2a3ab40ce562e57.png)'
  prefs: []
  type: TYPE_IMG
- en: where *y* is the label of this example and *o* is the output of the network
    for that example. The extension to *n* training samples is straightforward, since
    the derivative of the sum of functions is just the sum of their derivatives.
  prefs: []
  type: TYPE_NORMAL
- en: The computation of the partial derivatives of the weights in the hidden layers
    is not trivial, since those weights don’t affect directly the output (and hence
    the error). To address this problem, we will use the [chain rule of derivatives](https://en.wikipedia.org/wiki/Chain_rule)
    to establish a relationship between the gradients of the error in a given layer
    and the gradients in the subsequent layer.
  prefs: []
  type: TYPE_NORMAL
- en: The Delta Terms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We first note that *E* depends on the weight *wᵢⱼˡ* only via the net input
    *zᵢˡ* of neuron *i* in layer *l*. Therefore, we can apply the chain rule of derivatives
    to the gradient of *E* with respect to this weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5b2ebf3062fc48256cf9d5146224dd12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second derivative on the right side of the equation is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e8e99aca22b26d661e5640ff3dc844d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68874ddc5d32f9fca152070c597203d3.png)'
  prefs: []
  type: TYPE_IMG
- en: The variable *δᵢ* is called the **delta term** of neuron *i* or **delta** for
    short.
  prefs: []
  type: TYPE_NORMAL
- en: The Delta Rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **delta rule** establishes the relationship between the delta terms in layer
    *l* and the delta terms in layer *l* + 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'To derive the delta rule, we again use the chain rule of derivatives. The loss
    function depends on the net input of neuron *i* only via the net inputs of all
    the neurons it is connected to in layer *l* + 1\. Therefore we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/421c4f1e5008d314de094bae9af2e17a.png)'
  prefs: []
  type: TYPE_IMG
- en: where the index *j* in the sum goes over all the neurons in layer *l* + 1 that
    neuron *i* in layer *l* is connected to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once again we use the chain rule to decompose the second partial derivative
    inside the brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ebf1c7d004137a813191fd54d96e6961.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first partial derivative inside the brackets is just the delta of neuron
    *j* in layer *l* + 1, therefore we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/22b181fe642ab9ebc72be2739664c2b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second partial derivative is easy to compute:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/81f8b1fe1633ba453a4a8a76e8f8424a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d4d3213dd5842cc476c077fb52e5a192.png)'
  prefs: []
  type: TYPE_IMG
- en: But *aᵢˡ* = *f*(*zᵢˡ*), where *f* is the activation function. Hence, the partial
    derivative outside the sum is just the derivative of the activation function *f*’(*x*)
    for *x* = *zᵢˡ*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07713282e31ac44c9ffb0e23b5d9ee93.png)'
  prefs: []
  type: TYPE_IMG
- en: The delta rule
  prefs: []
  type: TYPE_NORMAL
- en: This equation, known as the **delta rule**,shows the relationship between the
    deltas in layer *l* and the deltas in layer *l* + 1\. More specifically, each
    delta in layer *l* is a linear combination of the deltas in layer *l* + 1, where
    the coefficients of the combination are the connection weights between these layers.
    The delta rule allows us to compute all the delta terms (and thus all the gradients
    of the error) recursively, starting from the deltas in the output layer and going
    back layer-by-layer until we reach the input layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the flow of the error information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a9e6b7b137ce99e203f2bed43ec8ac46.png)'
  prefs: []
  type: TYPE_IMG
- en: The calculation of the delta of neuron *i* in layer *l* by backpropagation of
    the deltas from those neurons in layer *l*+1 to which it is connected. The black
    arrows indicate the direction of flow during forward propagation, and the red
    arrows indicate the backward propagation of the error.
  prefs: []
  type: TYPE_NORMAL
- en: 'For specific activation functions, we can derive more explicit equations for
    the delta rule. For example, if we use the sigmoid function then:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8b893ba60884b9ad140623c200ea35fb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The derivative of the sigmoid function has a simple form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a5d3aa3f91f489200ba6d0f4f967e6f4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Hence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aead0691125e71e5da4843d16e29c10e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then the delta rule for the sigmoid function gets the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cdfe6a79624599e9c7bce25decf19d8c.png)'
  prefs: []
  type: TYPE_IMG
- en: The delta rule for the sigmoid function
  prefs: []
  type: TYPE_NORMAL
- en: The Deltas in the Output Layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final piece of the puzzle are the delta terms in the output layer, which
    are the first ones that we need to compute.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deltas in the output layer depend both on the loss function and the activation
    function used in the output neurons:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/778baeef0a413fde2d9b5241c73a89e1.png)'
  prefs: []
  type: TYPE_IMG
- en: where *f* is the activation function used to compute the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now derive more specific delta terms for each type of learning task:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In regression problems, the activation function we use in the output is the
    identity function *f*(*x*) = *x*, whose derivative is 1, and the loss function
    is the squared loss. Therefore the delta is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/0094fabb2ef5c498e15edab58a3e227d.png)'
  prefs: []
  type: TYPE_IMG
- en: '2\. In binary classification problems, the activation function we use is sigmoid
    and the loss function is log loss, therefore we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6c2385c98268f5167973370f65c25b0.png)'
  prefs: []
  type: TYPE_IMG
- en: In other words, the delta is simply the difference between the network’s output
    and the label.
  prefs: []
  type: TYPE_NORMAL
- en: '3\. In multiclass classification problems, we have *k* output neurons (where
    *k* is the number of classes) and we use softmax activation and the cross-entropy
    log loss. Similar to the previous case, the delta term of the *i*th output neuron
    is surprisingly simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2444f2275ef23dc9691796e68adba5e7.png)'
  prefs: []
  type: TYPE_IMG
- en: where *oᵢ* is the *i*-th component of the network’s prediction and *yᵢ* is the
    *i*-th component of the label. The proof is somewhat longer, and you can find
    it in [this article](https://medium.com/towards-data-science/deep-dive-into-softmax-regression-62deea103cb8).
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we finish computing all the delta terms, we can use gradient descent to
    update the weights. In gradient descent, we take small steps in the opposite direction
    of the gradient (i.e., in the direction of the steepest descent) in order to get
    closer to the minimum error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4136bc6fed46169ab4b42672f6dd2f1e.png)'
  prefs: []
  type: TYPE_IMG
- en: Gradient descent
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that the partial derivative of the error function with respect to
    each weight is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0bfefb241373b5f35b9224adc6443737.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, we can write the gradient descent update rule as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cc43d67db8ae41c2bff5c1ab29fb4d29.png)'
  prefs: []
  type: TYPE_IMG
- en: The gradient descent update rule
  prefs: []
  type: TYPE_NORMAL
- en: where *α* is a learning rate that controls the step size (0 < *α* < 1). In other
    words, we subtract from the weight between neuron *j* in layer *l* — 1 and neuron
    *i* in layer *l* the delta of neuron *i* multiplied by the activation of neuron
    *j* (scaled by the learning rate).
  prefs: []
  type: TYPE_NORMAL
- en: 'Gradient descent can be applied in one of the following modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Batch gradient descent** — the weights are updated after we compute the error
    on the entire training set.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Stochastic gradient descent (SGD)** — a gradient descent step is performed
    after every training example. Typically converges faster than batch gradient descent
    but is less stable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mini-batch gradient descent** — a middle way between batch gradient descent
    and SGD. We use small batches of random training samples (normally between 10
    to 1,000 examples) for the gradient updates. This reduces the noise in SGD but
    is still more efficient than full-batch updates, and it is the most common form
    to train neural networks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Backpropagation: The Complete Algorithm'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are now ready to present the entire algorithm in its full glory:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3204b2cb18d638732a189438bc17be67.png)'
  prefs: []
  type: TYPE_IMG
- en: As an exercise, try to implement this algorithm in Python (or your favorite
    programming language).
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine that we have a binary classification problem with two binary inputs
    and a single binary output. Our neural network has two hidden layers with the
    following weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/81bd7b7f409c34c0265ce16269b3abe1.png)'
  prefs: []
  type: TYPE_IMG
- en: The activation function in the hidden layers and in the output unit is the sigmoid
    function, and the learning rate is *α* = 0.5*.*
  prefs: []
  type: TYPE_NORMAL
- en: The network is presented with a training example with the inputs *x*₁ = 1 and
    *x*₂ = 0, and the target label is *y* = 1\. Let’s perform one iteration of the
    backpropagation algorithm to update the weights.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with forward propagation of the inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bb8913aebebd7590cac08e28fd9c0c1f.png)'
  prefs: []
  type: TYPE_IMG
- en: The forward pass
  prefs: []
  type: TYPE_NORMAL
- en: The output of the network is 0.6718 while the true label is 1, hence we need
    to update the weights in order to increase the network’s output and make it closer
    to the label.
  prefs: []
  type: TYPE_NORMAL
- en: We first compute the delta at the output node. Since this is a binary classification
    problem we use the log loss function, and the delta at the output is *o* — *y*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/761010e4ff07308e08093f7ffb1b798e.png)'
  prefs: []
  type: TYPE_IMG
- en: The delta at the output neuron
  prefs: []
  type: TYPE_NORMAL
- en: 'We now propagate the deltas from the output neuron back to the input layer
    using the delta rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5110588ec02922b78970946605f32e93.png)'
  prefs: []
  type: TYPE_IMG
- en: The backward pass
  prefs: []
  type: TYPE_NORMAL
- en: Note how the deltas become increasingly smaller as we go back in the layers,
    causing the early layers in the network to train very slowly. This phenomenon,
    known as the **vanishing gradients**, was one of the main reasons why backpropagation
    was not successful in training deep networks and a main motivation for the emergence
    of deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we perform one step of gradient descent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8d0580a985d8dc5a4baed318a9a97ca.png)'
  prefs: []
  type: TYPE_IMG
- en: Gradient descent step
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do another forward pass to see if the network’s output became closer
    to the target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/973181d89d535b17a94eeeeaa99f1c2d.png)'
  prefs: []
  type: TYPE_IMG
- en: Another forward pass
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, the output has increased from 0.6718 to 0.6981!
  prefs: []
  type: TYPE_NORMAL
- en: '**Final Notes**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All images unless otherwise noted are by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. “Learning
    representations by back-propagating errors.” *nature* 323.6088 (1986): 533–536.'
  prefs: []
  type: TYPE_NORMAL
