- en: 'Building an AI-Powered Language Learning App: Learning From Two AI Chatting'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd](https://towardsdatascience.com/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A step-by-step tutorial on creating a dual-chatbot language learning app with
    Langchain, OpenAI, gTTS, and Streamlit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)
    ¬∑25 min read¬∑Jun 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6b56edb9154ae8825ea55581c2ab5ee9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'DALL-E Prompt: two friendly robots talking with each other.'
  prefs: []
  type: TYPE_NORMAL
- en: When I first began learning a new language, I like to buy those ‚Äúconversational
    dialogues‚Äù books. I find those books very useful as they help me understand how
    the language worked ‚Äî not just the grammar and vocabulary, but also how people
    really used it in day-to-day life.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now with the rise of large language models (LLMs), a thought occurred to me:
    could I replicate these language-learning books in a more interactive, dynamic,
    and scalable format? Could I utilize LLM to create a tool that generates fresh,
    on-demand conversations for language learners?'
  prefs: []
  type: TYPE_NORMAL
- en: This thought inspired the project I would like to share with you today ‚Äî an
    AI-powered language learning app, where learners can observe and learn from two
    AI chatbots engaged in either a user-defined **conversation** or a **debate**.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the employed tech stack, I have used Langchain, OpenAI API, gTTS,
    and Streamlit to create the application where users can define the roles, scenarios,
    or debate topics, and let the AI generate the content.
  prefs: []
  type: TYPE_NORMAL
- en: Demo for the developed language learning app. (Video by author)
  prefs: []
  type: TYPE_NORMAL
- en: If you‚Äôre curious about how it all works, then join me as I walk you through
    the journey of building this interactive dual-chatbot system, step by step üó∫Ô∏èüìçüö∂‚Äç‚ôÄÔ∏è.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the complete source code [here](https://github.com/ShuaiGuo16/language_learning_app)*üíª*.
    In this blog, we will also go through the key code snippets to explain the ideas.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With that in mind, let‚Äôs get started!
  prefs: []
  type: TYPE_NORMAL
- en: '**Table of Content**'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑ [1\. Project Overview](#209d)
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑ [2\. Prerequisites](#9115)
  prefs: []
  type: TYPE_NORMAL
- en: ‚àò [2.1 LangChain](#0dee)
  prefs: []
  type: TYPE_NORMAL
- en: ‚àò [2.2 ConversationChain](#3988)
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑ [3\. Project Design](#d70e)
  prefs: []
  type: TYPE_NORMAL
- en: ‚àò [3.1 Developing a single chatbot](#c790)
  prefs: []
  type: TYPE_NORMAL
- en: ‚àò [3.2 Developing a dual-chatbot system](#5a8a)
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑ [4\. App Interface Design with Streamlit](#2557)
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑ [5\. Learnings and Future Extensions](#cffe)
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑ [6\. Conclusion](#954a)
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Project Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, our goal is to create a unique language-learning app powered
    by two conversational AI or chatbots. The innovative aspect of this app lies in
    having these chatbots interact with each other, creating realistic dialogues in
    the target language. Users can observe these AI-driven conversations, use them
    as language-learning resources, and understand the practical usage of their chosen
    language.
  prefs: []
  type: TYPE_NORMAL
- en: In our app, users should have the flexibility to customize their learning experience
    according to their needs. They can adjust several settings including target language,
    learning mode, session length, and proficiency level.
  prefs: []
  type: TYPE_NORMAL
- en: '**Target Language** üî§'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Users can choose the language they wish to learn. This choice guides the language
    used by the chatbots during their interactions. For the moment, I have included
    support for English ‚Äî ‚Äòen‚Äô, German ‚Äî ‚Äòde‚Äô, Spanish ‚Äî ‚Äòes‚Äô, and French ‚Äî ‚Äòfr‚Äô,
    but it is trivial to add more languages as long as the GPT model has sufficient
    knowledge about them.
  prefs: []
  type: TYPE_NORMAL
- en: Learning mode üìñ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This setting lets users select the style of conversation between the chatbots.
    In the **‚Äúconversation‚Äù** mode, users can define the **roles** (e.g., customer
    and waitstaff) and **actions** (ordering food and taking an order)for each bot
    and specify a **scenario** (at a restaurant), upon which the bots will simulate
    a realistic conversation. In the **‚Äúdebate‚Äù** mode, users are prompted to input
    a debate **topic** (Should we adopt nuclear energy?). The bots then engage in
    a lively debate on the provided topic.
  prefs: []
  type: TYPE_NORMAL
- en: The app‚Äôs interface should be responsive and dynamically adjusts based on the
    learning mode selected by the user, providing a seamless user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Session Length ‚è∞
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The session length setting gives users control over the duration of each chatbot
    conversation or debate. This means they can have short, quick dialogues or longer,
    more in-depth discussions, depending on their preference.
  prefs: []
  type: TYPE_NORMAL
- en: Proficiency Level üèÜ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This setting tailors the complexity of the chatbot conversation to the user‚Äôs
    language skill level. Beginners might prefer simpler conversations, while more
    advanced learners can handle intricate debates or discussions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the users specify those settings, they can initiate the session and watch
    as the AI chatbots spring into action, carrying out dynamic and interactive dialogues
    in accordance with the user‚Äôs preferences. Our overall workflow can be illustrated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5c17a979a507a63f4be9b4f03e15b7fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Workflow overview. The user-specified settings will be used to configure the
    prompt, which will be fed to the chatbots to generate conversations. The obtained
    script (together with user settings) will be used to populate the app interface.
    (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Prerequisites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into the development of our app, let‚Äôs familiarize ourselves
    with the tools that we will be using. In this section, we‚Äôll briefly introduce
    the LangChain library, specifically the `ConversationChain` module, which serves
    as the backbone of our app.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 LangChain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Building an application powered by Large Language Models (LLMs) involves many
    complexities. You need to interface with language model providers through API
    calls, connect these models to various data sources, handle the history of user
    interactions, and design pipelines for executing complex tasks. This is where
    the LangChain library comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: '[**LangChain**](https://python.langchain.com/docs/get_started/introduction)is
    a framework dedicated to streamlining the development of LLM-powered applications.
    It offers a wide array of components that address the common pain points listed
    above. Whether it‚Äôs managing interactions with the language model providers, orchestrating
    data connections, maintaining memory for historical interactions, or defining
    intricate task pipelines, LangChain has it covered.'
  prefs: []
  type: TYPE_NORMAL
- en: A key concept introduced by LangChain is the ‚Äú**Chain**‚Äù. In essence, chains
    allow us to combine multiple components together to create a single, coherent
    application. For example, a fundamental chain type in LangChain is the `LLMChain.`
    It creates a pipeline that first formats the prompt template using the user-provided
    input key values, then passes the formatted instructions to LLM, and finally returns
    the LLM output.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain hosts a variety of chain types, including `RetrievalQAChain,` for
    question-answering over documents, `SummarizationChain,` for summarizing multiple
    documents, and of course, our focus for today, the `ConversationChain.`
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 ConversationChain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ConversationChain`is used to facilitate interactive conversations by providing
    a framework for exchanging messages and storing conversation history. Here‚Äôs a
    sample code snippet to illustrate its usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the `ConversationChain` takes three inputs, *memory*, a LangChain
    component that holds the interaction history; *prompt*, the input to the LLM;
    and *llm*, the core large language model (e.g., GPT-3.5-Turbo, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: Once the`ConversationChain` object is instantiated, we can simply call `conversation.predict()`
    with the user input to get LLM‚Äôs response. The convenience with `ConversationChain`
    is that we can actually call `conversation.predict()` multiple times, and it automatically
    records the message history under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we‚Äôll harness the power of `ConversationChain`to create
    our chatbots and delve into how the memory, prompt template, and LLM are defined
    and utilized.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to learn more about LangChain, take a look at their [official
    documentation](https://python.langchain.com/docs/get_started/introduction.html).
    In addition, this [YouTube playlist](https://youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)
    also offers a comprehensive, hands-on introduction.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 3\. Project Design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a clear understanding of what we want to build and the tools
    to build it, it‚Äôs time to roll up our sleeves and dive into the code! In this
    section, we‚Äôre going to focus on the nuts and bolts of creating our dual-chatbot
    interaction. First, we‚Äôll explore the class definition for a single chatbot and
    then expand on this to create a dual-chatbot class, enabling our two chatbots
    to interact. We‚Äôll save the design of the app interface using Streamlit for Section
    4.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Developing a single chatbot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this subsection, we will develop a single chatbot together, which will later
    be integrated into the dual-chatbot system. Let‚Äôs start with the overall class
    design, then shift our attention to prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: üèóÔ∏è **Class Design**
  prefs: []
  type: TYPE_NORMAL
- en: Our chatbot class should enable the management of an individual chatbot. This
    involves instantiating a chatbot with a user-specified LLM as its backbone, providing
    instructions based on the user‚Äôs intent, and facilitating interactive multi-round
    conversations. With that in mind, let‚Äôs start coding.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the class constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Currently, you can only choose to use the native OpenAI API. Nevertheless, adding
    more backend LLMs is straightforward since LangChain supports various types (e.g.,
    Azure OpenAI endpoint, Anthropic chat models, PaLM API on Google Vertex AI, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: Besides LLM, another important component we need to instantiate is *memory*,
    which tracks the conversation history. Here, we use `ConversationBufferMemory`
    for this purpose, which simply prepends the last few inputs/outputs to the current
    input of the chatbot. This is the simplest memory type offered in LangChain and
    it‚Äôs sufficient for our current purpose.
  prefs: []
  type: TYPE_NORMAL
- en: For a complete overview of other types of memory, please refer to the [official
    docs](https://python.langchain.com/docs/modules/memory/).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Moving on, we need to have a class method that allows us to give instructions
    to the chatbot and make conversations with it. This is what `self.instruct()`
    for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**We define a couple of settings to allow users to customize their learning
    experience.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to what has been mentioned in ‚ÄúSection 1 Project Overview‚Äù, we
    have four new attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`self.role/self.oppo_role:` this attribute takes the form of a dictionary that
    records the role name and corresponding actions. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`self.oppo_role` represents the role taken by the other chatbot engaged in
    the conversation with the current chatbot. It‚Äôs essential because the current
    chatbot needs to understand who it is communicating with, providing necessary
    contextual information.'
  prefs: []
  type: TYPE_NORMAL
- en: '`self.scenario` sets the stage for the conversation. For ‚Äúconversation‚Äù learning
    mode, `self.scenario`represents the place where the conversation'
  prefs: []
  type: TYPE_NORMAL
- en: is happening; for ‚Äúdebate‚Äù mode, `self.scenario`represents the debating topic.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `self.starter` is just a boolean flag to indicate if the current chatbot
    will initiate the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: '**We structure the prompt for the chatbot.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In OpenAI, a chat model generally takes a list of messages as input and returns
    a model-generated message as output. LangChain supports `SystemMessage`,`AIMessage`,
    `HumanMessage`: `SystemMessage` helps set the behavior of the chatbot, `AIMessage`
    stores previous chatbot responses, and `HumanMessage` provides requests or comments
    for the chatbot to respond to.'
  prefs: []
  type: TYPE_NORMAL
- en: LangChain conveniently offers `PromptTemplate` to streamline prompt generation
    and ingestion. For a chatbot application, we need to specify the `PromptTemplate`
    for all three message types. The most critical piece is setting the `SystemMessage`,
    which controls the chatbot‚Äôs behavior. We have a separate method, `self._specify_system_message()`,
    to handle this, which we‚Äôll discuss in detail later.
  prefs: []
  type: TYPE_NORMAL
- en: '**Finally, we bring all the pieces together and construct a** `ConversationChain.`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: üñãÔ∏è **Prompt Design**
  prefs: []
  type: TYPE_NORMAL
- en: 'Our focus now turns to guiding the chatbot in participating in the conversation
    as desired by the user. To this end, we have the `self._specify_system_message()`
    method. The signature of this method is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Essentially, this method compiles a string, which will then be fed into the
    `SystemMessagePromptTemplate.from_template()` to instruct the chatbot, as demonstrated
    in the definition of the `self.instruct()` method above. We‚Äôll dissect this ‚Äúlong
    string‚Äù in the following to understand how each language learning requirement
    is incorporated into the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 1Ô∏è‚É£ Session length
  prefs: []
  type: TYPE_NORMAL
- en: The session length is controlled by directly specifying the maximum number of
    exchanges that can happen within one session. Those numbers are hard-coded for
    the time being.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 2Ô∏è‚É£ Number of sentences the chatbot can say in one exchange
  prefs: []
  type: TYPE_NORMAL
- en: Apart from limiting the total number of allowed exchanges, it‚Äôs also beneficial
    to restrict how much a chatbot can say within one exchange, or equivalently, the
    number of sentences.
  prefs: []
  type: TYPE_NORMAL
- en: In my experiments, there is usually no need to constrain this in ‚Äúconversation‚Äù
    mode, as the chatbot mimics a real-life dialogue and tends to speak at a reasonable
    length. However, in ‚Äúdebate‚Äù mode, it‚Äôs necessary to impose a limit. Otherwise,
    the chatbot may continue speaking, eventually generating an ‚Äúessay‚Äù üòÜ.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to limiting the session length, the numbers that restrict the speech
    length are also hard-coded and correspond with the user‚Äôs proficiency level in
    the target language:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 3Ô∏è‚É£ Determine speech complexity
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we regulate the complexity level of the language the chatbot can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 4Ô∏è‚É£ Put everything together!
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs what the instruction looks like for different learning modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 5Ô∏è‚É£ Who speaks first?
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we instruct the chatbot whether it should speak first or wait for
    the response from the opponent AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have completed the prompt design üéâ As a quick summary, this is what
    we have developed so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c9261f866e1940098eee750f07557ee.png)'
  prefs: []
  type: TYPE_IMG
- en: The single chatbot class. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Developing a dual-chatbot system
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we arrive at the exciting part! In this subsection, we will develop a dual-chatbot
    class to let two chatbots interact with each other üí¨üí¨
  prefs: []
  type: TYPE_NORMAL
- en: üèóÔ∏è **Class Design**
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to the previously developed single Chatbot class, we can effortlessly
    instantiate two chatbots in the class constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `self.chatbots` is a dictionary designed to store information related to
    both bots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `self._reset_conversation_history` serves to initiate a fresh conversation
    history and provide the initial instructions to the chatbots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To facilitate interaction between the two chatbots, we employ `self.step()`
    method. This method allows for one round of interaction between the two bots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we have embedded a method called `self.translate()`. The purpose
    of this method is to translate the script into English. This functionality could
    be useful for language learners as they can understand the meaning of the conversation
    generated in the target language.
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve the translation functionality, we can employ the basic `LLMChain`,
    which requires a backend LLM model and a prompt for instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, it could be beneficial for language learners to have a summary of
    the key language learning points of the generated conversation script, be it key
    vocabulary, grammar points, or function phrases. For that, we can include a `self.summary()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Similar to the `self.translate()` method, we employed a basic `LLMChain` to
    perform the desired task. Note that we explicitly ask the language model to summarize
    key language learning points based on the user‚Äôs proficiency level.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, we have completed the development of the dual-chatbot class ü•Ç As
    a quick summary, this is what we have developed so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/faa19b5a62676515982824900850cc7b.png)'
  prefs: []
  type: TYPE_IMG
- en: The single chatbot & Dual-chatbot class. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 4\. App Interface Design with Streamlit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now ready to develop the user interface üñ•Ô∏è For this project, we will
    use the Streamlit library to construct the frontend.
  prefs: []
  type: TYPE_NORMAL
- en: If you‚Äôre unfamiliar, Streamlit is an open-source Python library for creating
    interactive web applications focused on data science and machine learning. It
    simplifies the process of building and deploying apps by providing an easy-to-use
    API, live code reloading for instant updates, interactive widgets for user input,
    support for data visualization libraries, and the ability to incorporate rich
    media.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs initiate with a new Python script app.py, and import the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Alongside the main `streamlit`library, we also import the `streamlit_chat` library,
    a community-built Streamlit component specifically designed for creating chatbot
    UIs. Our previously-developed `DualChatbot` class is stored in the *chatbot.py*
    file, so we need to import that as well. Lastly, we import `gTTS`, which stands
    for *Google Text-to-Speech,* to add audio to the bot-generated conversation script
    in this project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we configure the Streamlit interface, let‚Äôs first define the language
    learning settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `AVATAR_SEED` is used for generating different avatar icons for different
    chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by setting up the basic layout of the user interface and establishing
    options for the user to select:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note the introduction of a `time_delay`variable. It‚Äôs used for specifying the
    waiting time between displaying two consecutive messages. If this delay is set
    to zero, the exchanges generated between two chatbots will appear in the app swiftly
    (limited only by OpenAI‚Äôs response time). However, for user experience, it could
    be beneficial to allow enough time for the user to read the generated message
    before the next exchange appears.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we initialize the Streamlit session state to store user-specific session
    data in the Streamlit app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we answer two questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 1Ô∏è‚É£ First of all, why do we need ‚Äúsession_state‚Äù?
  prefs: []
  type: TYPE_NORMAL
- en: In Streamlit, every time the user interacts with the app, Streamlit reruns the
    entire script from top to bottom, updating the app‚Äôs output accordingly. However,
    this reactive nature of Streamlit can pose a challenge when you want to maintain
    user-specific data or preserve state across different interactions or pages within
    the app. Since Streamlit reloads the script on every user interaction, regular
    Python variables would lose their values, and the app would reset to its initial
    state.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the session_state comes in. Session state in Streamlit provides
    a way to store and retrieve data that persists throughout the user‚Äôs session,
    even when the app is reloaded or the user navigates between different components
    or pages. It allows you to maintain stateful information and preserve the app‚Äôs
    context for each user.
  prefs: []
  type: TYPE_NORMAL
- en: 2Ô∏è‚É£ Secondly, what are those variables stored in the session_state?
  prefs: []
  type: TYPE_NORMAL
- en: '‚Äú**bot1_mesg**‚Äù is a list, where each element of the list is a dictionary that
    holds the messages spoken by the first chatbot. It has the following keys: ‚Äúrole‚Äù,
    ‚Äúcontent‚Äù, and ‚Äútranslation‚Äù. The same definition applies to the ‚Äú**bot2_mesg**‚Äù.'
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äú**batch_flag**‚Äù is a boolean flag to indicate whether the conversation exchanges
    are shown all at once or with a time delay. In the current design, the chats between
    two bots will appear with a time delay when their conversation is generated for
    the first time. Afterward, the user may want to see the translations of or add
    audio to the generated conversation, the stored conversation messages (in ‚Äú**bot1_mesg**‚Äù
    and ‚Äú**bot2_mesg**‚Äù) will be shown all at once. This is beneficial as we don‚Äôt
    need to call OpenAI API again to reduce cost and latency.
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äú**translate_flag**‚Äù and ‚Äú**audio_flag**‚Äù are used to indicate if the translation
    and/or audio will be shown next to the original conversation.
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äú**message_counter**‚Äù is a counter that adds one whenever a message from chabot
    is displayed. The idea is to assign the message ID with this counter, as Streamlit
    requires that each UI component needs to have a unique ID.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can introduce the logic of letting two chatbots interact and generate
    conversations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Upon running the script for the first time, there will be no ‚Äú**dual_chatbots**‚Äù
    key stored in the session_state (as the dual-chatbot has not been created yet).
    As a result, the code snippet shown above will be executed when the user hits
    the ‚Äú**Generate**‚Äù button on the sidebar. The two chatbots will chat back and
    forth a given number of times, and all the conversation messages are recorded
    in the session_state. The `show_message()`function is a helper function designed
    to be the sole interface to style the message display. We will go back to it at
    the end of this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if the user interacts with the app and changes some settings, Streamlit
    will rerun the entire script from the top. Since we have already generated the
    desired conversation script, there is no need to invoke OpenAI API again. Instead,
    we can simply retrieve the stored information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note that there is another flag called ‚Äú**first_time_exec**‚Äù in the session
    state. This is used to indicate if the originally generated script has already
    been shown on the app. If we remove this check, the same messages will appear
    twice when running the app for the first time.
  prefs: []
  type: TYPE_NORMAL
- en: The only thing left is the inclusion of the summary of key learning points in
    the UI. For that, we can use `st.expander`. In Streamlit, `st.expander` is useful
    when we have a large amount of content or information that we want to present
    in a condensed form, initially hidden from view. When the user clicks the expander,
    the content within it will expand or collapse, thus revealing or hiding the additional
    details.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Since the summary of key learning points is also generated by calling OpenAI
    API, we can save the generated summary to the session_state so that the content
    can be retrieved if the script is run a second time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let‚Äôs complete the Streamlit UI design with the helper function `show_message`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'A few points warrant further explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: 1Ô∏è‚É£ The `message()` object
  prefs: []
  type: TYPE_NORMAL
- en: 'This is part of the `streamlit_chat` library and is used to display messages.
    In its simplest form, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3a8358fe3d3a897bcdca1aa15caa5e79.png)'
  prefs: []
  type: TYPE_IMG
- en: (Image from streamlit_chat [GitHub repository](https://github.com/AI-Yash/st-chat))
  prefs: []
  type: TYPE_NORMAL
- en: where the argument `is_user` determines if the message should be left-aligned
    or right-aligned. In our code snippet for `show_message`, we have also specified
    `avatar_style` and `seed` to set the avatar icons for two chatbots. The `key`
    argument is merely for assigning a unique ID for each message, as required by
    the Streamlit.
  prefs: []
  type: TYPE_NORMAL
- en: 2Ô∏è‚É£ Text-to-speech
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we use gTTS library to create audio speech in the target language based
    on the generated script. This library is straightforward to use, but it does have
    a limitation: you can only have one voice. After the audio object is generated,
    we can use`st.audio` to create an audio player for each message in the app.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! We have now completed the UI design :) Type the following command in
    your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: You should see the app in your browser and be able to interact with it. Great
    job!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/039cdf24564a65d3616a9dcf5c2ab365.png)'
  prefs: []
  type: TYPE_IMG
- en: The interface of the developed language learning app. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Learnings and Future Extensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we finish, I want to share with you some key learnings from this project
    and potential directions for future enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: 1Ô∏è‚É£ How to stop the conversation?
  prefs: []
  type: TYPE_NORMAL
- en: 'This problem is actually harder than it looks if you want to do it right. Ideally,
    we would like the conversation to end naturally. However, in some of my experiments,
    I noticed that the chatbots will just keep saying ‚Äúthank you‚Äù or ‚Äúgoodbye‚Äù to
    each other toward the end of the conversation, which unnecessarily elongated the
    conversation. A few potential solutions to this issue include:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hard Limiting of Exchange Rounds: This is perhaps the easiest solution and
    it‚Äôs also what we have adopted in this project. However, it might not always be
    ideal as it can lead to prematurely terminated conversations. As a workaround,
    we‚Äôve instructed the bot in the `SystemMessage`to finish the conversation within
    a set number of exchanges.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use of ‚ÄúSignal Words‚Äù: The chatbot could be programmed to say specific ‚Äòsignal
    words‚Äô (e.g., ‚ÄòConversation over‚Äô) when it deems the conversation to have naturally
    ended. A logic could then be implemented to spot these ‚Äòsignal words‚Äô and end
    the loop accordingly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Post-Processing of the Conversation: Once the chatbots have generated the conversation,
    another LLM could be deployed as an ‚Äúeditor‚Äù to prune the conversation. This could
    be an effective approach. However, its drawbacks may include designing an additional
    prompt, incurring extra costs from calling the OpenAI API again, and increasing
    latency.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2Ô∏è‚É£ How to control language complexity?
  prefs: []
  type: TYPE_NORMAL
- en: 'In my experience, the developed chatbots seemed to have difficulty following
    the instructions regarding the language complexity used in the chat: sometimes
    ‚Äúintermediate‚Äù level of language usage will appear even though the proficiency
    level is set to be ‚Äúbeginner‚Äù. One reason may be the current prompt design is
    not sufficient for specifying the nuance between different complexity levels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a couple of ways to address this issue: to begin with, we can perform
    *in-context learning*. That is to say, we provide examples to the chatbots and
    show them what kind of language usage we desire for different complexity levels.
    Another way forward is similar to what we have discussed above: we could use another
    LLM to adjust the complexity of the conversation. Essentially, this extra LLM
    can use the generated script as a starting point and rewrite a new script to match
    the desired proficiency level of the user.'
  prefs: []
  type: TYPE_NORMAL
- en: 3Ô∏è‚É£ Better text-to-speech library?
  prefs: []
  type: TYPE_NORMAL
- en: 'The current project only utilized the simple gTTS library to synthesize voices,
    there‚Äôs room for improvement. More advanced libraries offer multilingual support,
    multiple-speaker support, and more natural-sounding speech. To name a few: [*pyttsx3*](https://github.com/nateshmbhat/pyttsx3),
    *Amazon Polly*, *IBM Watson TTS*, *Microsoft Azure Cognitive Services TTS*, [*Coqui.ai-TTS*](https://github.com/coqui-ai/TTS),
    as well as a recent release from Meta, [*Voicebox*](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/).'
  prefs: []
  type: TYPE_NORMAL
- en: 4Ô∏è‚É£ More tests with different scenarios?
  prefs: []
  type: TYPE_NORMAL
- en: Due to time constraints, I tested only a few scenarios to ascertain whether
    the chatbots can generate meaningful conversations. These tests identified issues
    in my initial prompt design, providing opportunities for refinement. Additional
    scenario tests would likely reveal overlooked areas and suggest ways to enhance
    the prompt. I‚Äôve compiled a [comprehensive list](https://github.com/ShuaiGuo16/language_learning_app/blob/main/Scenario_ideas.pdf)
    of typical ‚Äúconversation‚Äù scenarios and ‚Äúdebate‚Äù topics. Feel free to try them
    out and assess the performance of the current prompt design.
  prefs: []
  type: TYPE_NORMAL
- en: 5Ô∏è‚É£ Include other forms of Generative AI?
  prefs: []
  type: TYPE_NORMAL
- en: This project primarily explored text-to-text (chatbot) and text-to-speech generative
    AI techniques. We could enhance the user experience further by leveraging other
    forms of generative AI, such as **text-to-image** or **text-to-video**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Text-to-Image**: For every user-inputted scenario, we could use text-to-image
    models to create corresponding figures. Displaying these figures alongside the
    generated conversation can provide visual context and enhance language learning
    engagement. Models like *StableDiffusion*, *Midjourney*, and *DALL-E* could be
    used for this purpose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text-to-Video**: To make the app more multimedia-focused, we could generate
    videos based on input scenarios. A tool like [*RunwayML*](https://runwayml.com/)could
    help with this. Furthermore, we might even attempt to create digital humans to
    present the conversation, which could dramatically enhance user experience if
    executed correctly. [*Synthesia*](https://www.synthesia.io/tools/digital-human?utm_term=digital+avatar&utm_campaign=Basic+Search&utm_source=google&utm_medium=cpc&hsa_acc=5132031546&hsa_cam=17790491238&hsa_grp=142067774834&hsa_ad=611252817304&hsa_src=g&hsa_tgt=aud-2090130405830%3Akwd-625911181570&hsa_kw=digital+avatar&hsa_mt=p&hsa_net=adwords&hsa_ver=3&gclid=Cj0KCQjw4s-kBhDqARIsAN-ipH35DgWBi1zs_i0xDB5FBPvzMRgKLYsLvuN2d8MEAdKbw9jFL1TYB2saAsy-EALw_wcB)might
    be a suitable tool for this purpose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6Ô∏è‚É£ More language learning settings?
  prefs: []
  type: TYPE_NORMAL
- en: At present, our app mainly focuses on ‚Äúconversation‚Äù and ‚Äúdebate‚Äù learning modes.
    However, the potential for growth is substantial. For instance, we could introduce
    other learning modes such as ‚Äústorytelling‚Äù and ‚Äúcultural learning.‚Äù Additionally,
    we could expand the chatbots‚Äô interaction to cater to more professional and technical
    scenarios. These might include settings like meetings, negotiations, or sectors
    like sales and marketing, law, engineering, and more. Such a feature could be
    helpful for language learners aiming to bolster their *professional* language
    proficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Wow, what a journey! Thanks a lot for sticking with me so far :) From designing
    prompts to creating chatbots, we‚Äôve certainly covered a lot of ground. Using LangChain
    and Streamlit, we‚Äôve built a functional dual-chatbot system that can be used for
    learning language, not bad!
  prefs: []
  type: TYPE_NORMAL
- en: If you find my content useful, you could buy me a coffee [here](https://www.buymeacoffee.com/Shuaiguo09f)
    ü§ó Thank you very much for your support!
  prefs: []
  type: TYPE_NORMAL
