- en: 'Finding Temporal Patterns in Twitter Posts: Exploratory Data Analysis with
    Python (Part 2)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Twitter 帖子中发现时间模式：使用 Python 进行探索性数据分析（第二部分）
- en: 原文：[https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-part-2-8eec19431c23](https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-part-2-8eec19431c23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-part-2-8eec19431c23](https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-part-2-8eec19431c23)
- en: Users behavior analysis with Python and Pandas
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 和 Pandas 进行用户行为分析
- en: '[](https://dmitryelj.medium.com/?source=post_page-----8eec19431c23--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----8eec19431c23--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8eec19431c23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8eec19431c23--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----8eec19431c23--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page-----8eec19431c23--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----8eec19431c23--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8eec19431c23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8eec19431c23--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----8eec19431c23--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8eec19431c23--------------------------------)
    ·15 min read·Jun 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8eec19431c23--------------------------------)
    ·阅读时间 15 分钟·2023年6月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8cd91f7aa34d2b4468cca5c4eda1c113.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cd91f7aa34d2b4468cca5c4eda1c113.png)'
- en: User timelines example, Image by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 用户时间线示例，图片由作者提供
- en: In the [first part](/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699)
    of this article, I analyzed the timestamps of about 70,000 Twitter posts and got
    some interesting results; for example, it was possible to detect bots or users
    posting messages from clone accounts. But I was not able to get accurate message
    time; at least for a free account, the Twitter API response does not have a time
    zone, and all messages have UTC time. Millions of people are using social networks
    nowadays, and analysis of users' behavior is not only interesting but may also
    be important for sociological or psychological studies. For example, it can be
    interesting to figure out if people are posting more messages in the evening,
    at night, or during the day, but without having a proper time, it is impossible
    to know. Finally, I was able to find a workaround that works well, even with the
    limitations of a free API.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章的[第一部分](/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699)中，我分析了大约
    70,000 条 Twitter 帖子的时间戳，并获得了一些有趣的结果；例如，可以检测到机器人或从克隆账户发布消息的用户。但我未能获取准确的消息时间；至少对于免费账户，Twitter
    API 响应没有时区，所有消息都有 UTC 时间。现在，数以百万计的人使用社交网络，对用户行为的分析不仅有趣，而且可能对社会学或心理学研究重要。例如，了解人们是在晚上、夜间还是白天发布更多消息是有趣的，但没有准确的时间就无法知道。最后，我找到了一种即使在免费
    API 限制下也能很好工作的解决方法。
- en: In this article, I will show the full workflow, from collecting the data to
    the analysis using Python and Pandas.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将展示从数据收集到使用 Python 和 Pandas 进行分析的完整工作流程。
- en: Methodology
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法论
- en: 'Our data processing flow will consist of several steps:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据处理流程将包括几个步骤：
- en: Collecting the data using the [Tweepy library](https://github.com/tweepy/tweepy).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [Tweepy 库](https://github.com/tweepy/tweepy) 收集数据。
- en: Loading the data and getting basic insights.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据并获取基本见解。
- en: Data transformation. We will group data by user and find specific metrics useful
    for analysis.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据转换。我们将按用户对数据进行分组，并寻找对分析有用的特定指标。
- en: Analyzing the results.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析结果。
- en: Let’s get started.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 1\. Collecting the data
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 收集数据
- en: 'As was written in the previous part, we cannot get a proper timezone for Twitter
    messages; all messages returned by the Twitter API have the UTC time. As a workaround,
    I decided to test three approaches:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一部分所述，我们无法获取 Twitter 消息的正确时区；所有由 Twitter API 返回的消息都具有 UTC 时间。作为一种变通方法，我决定测试三种方法：
- en: I tried to get **all messages** using the “*” mask and analyze the “location”
    field of every message. Not every user specified the location on Twitter, but
    a pretty large number did. The idea was good, but practically, it did not work.
    Twitter is a large social network; it generates a huge amount of data, and collecting
    all tweets even for a week is unrealistic. The number of thousands of messages
    per second is not only too large for processing on an ordinary PC, but it will
    also be beyond the limitations of the free Twitter developer account.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我尝试使用“*”掩码获取**所有消息**并分析每条消息的“位置”字段。并非每个用户在Twitter上都指定了位置，但相当大一部分用户指定了。这个想法很好，但实际上没有效果。Twitter是一个大型社交网络；它生成大量数据，收集一周内的所有推文是不现实的。每秒数千条消息的数量不仅对普通PC处理来说过大，而且也超出了免费的Twitter开发者账户的限制。
- en: I can use a **city name** as a request; for example, I can search all tweets
    with the hashtag “#Berlin”. Then it would be easy to filter users who have “Germany”
    as a location, and for Germany, we know the time zone. This idea works, but the
    problem is that the results may be biased. For example, messages with the hashtag
    “#Berlin” may be posted by people interested in politics or by sports fans. But
    in general, this approach is interesting; with different search queries, it may
    be possible to reach different types of audiences.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以使用**城市名称**作为请求；例如，我可以搜索所有带有“#Berlin”标签的推文。然后很容易筛选出位置为“德国”的用户，对于德国，我们知道其时区。这个想法是可行的，但问题是结果可能会有偏差。例如，带有“#Berlin”标签的消息可能是由对政治感兴趣的人或体育迷发布的。但总体来说，这种方法很有趣；通过不同的搜索查询，可能能够接触到不同类型的受众。
- en: Finally, I’ve found a solution that works well for me. I decided to get **all**
    **messages in a specific language** by specifying the “*” mask and a language
    code. This obviously will not work for English, but there are many countries in
    the world that are geographically small enough to easily determine the time zone
    of their citizens. I selected the Dutch language because the number of Dutch speakers
    in the world is not so big; this language is mostly used in the Netherlands and
    in Belgium, and both countries have the same time zone. Some people may live abroad,
    and there are also native Dutch speakers in Suriname and Curaçao, but those numbers
    are not that big.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，我找到了一种对我有效的解决方案。我决定通过指定“*”掩码和语言代码来获取**特定语言**的**所有**消息。这显然对英语不起作用，但世界上有许多地理面积足够小的国家，可以轻松确定其公民的时区。我选择了荷兰语，因为世界上荷兰语使用者的数量并不大；这种语言主要在荷兰和比利时使用，这两个国家有相同的时区。虽然有些人可能居住在国外，也有一些荷兰语母语者在苏里南和库拉索，但这些数字也不多。
- en: Collecting the data itself is straightforward. The code was already used in
    [the first part](/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699);
    I only specified “*” as a query mask and “nl” as a language code. A free Twitter
    API has a 7-day limitation for getting historical data. But practically, it turned
    out that the pagination has a limit of about 100,000 messages. Is it a lot? Actually,
    not. Most people probably never realize how many messages are posted on social
    media. There are only about 25 million Dutch-speaking people in the world. And
    100,000 is the number of messages that these people are posting on Twitter within
    only 3 hours! Practically, I needed to run the code at least every 2 hours to
    get all the tweets.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 收集数据本身是简单的。代码已经在[第一部分](/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699)中使用过；我只指定了“*”作为查询掩码和“nl”作为语言代码。一个免费的Twitter
    API对获取历史数据有7天的限制。但实际上，分页的限制大约为100,000条消息。这算多吗？实际上，不算。大多数人可能从未意识到社交媒体上发布了多少消息。全世界只有大约2500万荷兰语使用者。而100,000是这些人在仅仅3小时内在Twitter上发布的消息数量！实际上，我需要每隔至少2小时运行一次代码才能获取所有的推文。
- en: 'Collecting the data every two hours is not a problem; it can be easily done
    in the cloud, but as a free solution, I just took my Raspberry Pi:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每两小时收集一次数据并不成问题；这可以轻松在云端完成，但作为一个免费的解决方案，我就使用了我的Raspberry Pi：
- en: '![](../Images/ce6a9db86f97e75932f04bdbce1a7f9b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce6a9db86f97e75932f04bdbce1a7f9b.png)'
- en: Raspberry Pi 4, Image source [https://en.wikipedia.org/wiki/Raspberry_Pi](https://en.wikipedia.org/wiki/Raspberry_Pi)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Raspberry Pi 4，图片来源 [https://en.wikipedia.org/wiki/Raspberry_Pi](https://en.wikipedia.org/wiki/Raspberry_Pi)
- en: The Raspberry Pi is a small credit-card-size Linux computer with 1–8 GB of RAM
    and a 1–2 GHz CPU. Those specs are absolutely enough for our task, and it is also
    nice that the Raspberry Pi has no coolers, produces no noise, and has only 2–5
    W of power consumption. So, it’s a perfect choice to run a code for a week or
    two.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'I slightly modified the Python script so it could make requests every 2 hours,
    and I also added a timestamp to the name of each CSV file. After doing the SSH
    login into the Raspberry Pi, I could run this script in the background by using
    the Linux “nohup” command:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: By default, “nohup” saves the console output to the “*nohup.out*” file. This
    file can be large, so I use forwarding to “/dev/null” to prevent this. Another
    solution like Cron can also be used, but this simple command is enough for this
    task.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'The process is running in the background, so we see nothing on the screen,
    but we can watch the log in realtime by using the “tail” command (here “20230601220000”
    is the name of the current file):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Getting tweets in the console looks like this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dca1a1a12cdf242222e3245ed9d81f8c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: Collecting Twitter messages, Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'When needed, we can copy new logs from the Raspberry Pi by using the “scp”
    command:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, “/home/pi/Documents/…” is a remote path on the Raspberry Pi, and “.” is
    the current folder on a desktop PC, where CSV files should be copied.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: In my case, I kept the Raspberry Pi running for about 10 days, which was enough
    to collect some data. But in general, the longer, the better. During the data
    preparation for the previous part of the article, I saw enough users who were
    making Twitter posts only once per week; obviously, longer intervals will be needed
    to see patterns in those users’ behavior.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Loading the data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Python script was getting new Twitter messages every 2 hours, and as an
    output, a lot of CSV files were generated. We can load all files in Pandas and
    combine them into one dataset:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The code is straightforward. I load each file into the dataframe, then I combine
    all the data frames using *pd.concat*. The time intervals overlap each other;
    to avoid having duplicate records, I use the *drop_duplicates* method.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see what kind of data we have:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result looks like this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0981303a124e6ad914fe40eda96318d6.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: Dataframe with all messages, Image by author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The text and message ids are actually not important; for the analysis, we will
    need only the “created_at” field. To make further processing easier, let’s extract
    the date, time, and hour of the day as separate columns. We can also add a timezone
    offset to all records:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result looks like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/16d4de6f0f53c8fcb21d846588615476.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: Dataframe with added columns, Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: The data load is ready. Let’s see what the data looks like.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 3\. General Insights
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This article aims to analyze the patterns in the “time” domain. As a warm-up,
    let’s see **all messages on a single timeline**. To draw all the graphs in the
    article, I will be using the [Bokeh](https://github.com/bokeh/bokeh) library:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this method,I group all messages by date and time. The timestamps I created
    before have the “HH:MM” format. The number of messages per minute is not a convenient
    metric, so I divided all values by 60 to get the number of messages per second.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'The result looks like this:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/221349f61742428091900f8c39724dba.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: All Twitter messages, Image by author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'The code had been running for about 10 days on the Raspberry Pi. As a result,
    6,487,433 Twitter messages made by 1,515,139 unique users were collected. But
    in the image, we can see some problems. Some intervals are missing; probably there
    was no Internet access at this time. Another day is partially missing, and I don’t
    know what caused this issue; probably a free Twitter account has the lowest priority
    compared to all other requests. Anyway, we cannot complain about the free API,
    and my goal was to collect the data at least for a week, and I have enough information
    for that. I can just delete the corrupted intervals at the end:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'By the way, another point on the timeline caught my attention; the peak happened
    on the 4th of June when the number of messages per second literally doubled. I
    became curious about what it was. We can easily filter the dataframe:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The result looks like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2f91a351212c228bd5fe0c4f462058fe.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Tweets posted during the peak interval, Image by author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'It turned out that popular football player Zlatan Ibrahimovic from AC Milan
    announced his retirement at the age of 41, and this message caused a lot of Twitter
    reposts:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b7a70f4110ac34b53cb3cae2b9e62897.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
- en: Twitter messages timeline, Image by author
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the duration of the peak was about an hour; maybe it could be
    longer, but it was late; according to the timeline, the announcement was made
    at 23:35.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'But let’s return to Pandas. For further time analysis, let’s create two helper
    methods to draw all **messages, grouped by the time of the day**:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will allow us to see all messages on a single 24-hour timeline:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The optional “df_filtered” parameter will be used later. The result looks like
    this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b876abd01eff3f41c1e26763f72816c6.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
- en: Messages per day, Image by author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: We can clearly see a day/night difference, so my assumption that most of the
    messages in Dutch were made from the same time zone was correct.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also draw a **timeline for a single user**. I already used this method
    in the previous part. For the convenience of readers who may use this article
    as a tutorial, I’ll place the code here as well:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The result looks like this:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e671c39ad58bc5bf519c90c0a3905841.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: Messages timeline for a single user, Image by author
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Data transformation
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous step, we got a “raw” dataframe of messages made by all users.
    We are going to find daily patterns, so as input data, let’s get the number of
    messages grouped by an hour and calculated for each user:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步中，我们获得了所有用户消息的“原始”数据框。我们将找到每日模式，因此作为输入数据，让我们获取按小时分组并计算的每用户消息数量：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The result looks like this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![](../Images/11c64fca0b1a07aacd864c18fec3938c.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11c64fca0b1a07aacd864c18fec3938c.png)'
- en: As a reminder, I was using 7-day data. In this example, we can see that during
    this interval, the user posted 4 messages at 7 a.m., 1 message at 8 a.m., 3 messages
    at 5 p.m., and so on.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，我使用了7天的数据。在这个例子中，我们可以看到在此时间段内，用户在早上7点发布了4条消息，在早上8点发布了1条消息，在下午5点发布了3条消息，等等。
- en: 'For analysis, I decided to use three metrics:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分析，我决定使用三个指标：
- en: The total number of “busy hours” per day when the user was making Twitter posts
    (in the last example, the number is 5).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户每天进行Twitter发布的“繁忙小时”总数（在上一个示例中，数量是5）。
- en: The total number of messages per user (in the last example, the number is 20).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个用户的消息总数（在上一个示例中，数量是20）。
- en: An array of 24 numbers, representing the number of messages grouped by hour.
    As an important step, I will also normalize the array sum to 100%.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含24个数字的数组，表示按小时分组的消息数量。作为一个重要步骤，我还会将数组和标准化为100%。
- en: 'The output will be a new dataframe, grouped by user names. This method does
    all the calculations:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是一个按用户名分组的新数据框。这个方法完成了所有的计算：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result looks like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![](../Images/66cc746a60ef45237a293e93f2c79d9d.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66cc746a60ef45237a293e93f2c79d9d.png)'
- en: Data metrics, grouped by user, Image by author
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 数据指标，按用户分组，作者提供的图片
- en: Now we have a dataframe with all the metrics, and we’re ready to have some fun
    with this data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个包含所有指标的数据框，准备开始处理这些数据。
- en: 5\. Analysis
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 分析
- en: 'In the last step, we transformed a “raw” dataframe with all Twitter messages
    into the data, grouped by user. This dataframe is actually much more useful. As
    a warm-up, let’s start with something simple. Let’s get the **number of messages**
    **per user**. The dataframe is already sorted, and we can easily see the “Top
    5” of users who posted the maximum number of messages:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步中，我们将包含所有Twitter消息的“原始”数据框转换为按用户分组的数据。这个数据框实际上更有用。作为热身，让我们从简单的开始。让我们获取**每个用户的消息数量**。数据框已经排序，我们可以轻松看到发布最大数量消息的“前5名”用户：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/0cb79b187e76b2b18c111c4bdf9daa26.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cb79b187e76b2b18c111c4bdf9daa26.png)'
- en: Metrics dataframe, grouped by user, Image by author
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 指标数据框，按用户分组，作者提供的图片
- en: 'Let’s also **find percentiles**:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还**找到百分位数**：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The result is interesting. This data was collected within 7 days. There are
    1,198,067 unique users in the dataframe who posted at least one message during
    this period. And the 90th percentile is only 4, which means that 90% of all users
    posted only 4 messages during this week. A big difference, compared to the top
    users, who posted more than 5000 tweets! But as was discussed in the first part,
    some of the “top users” are probably bots. Well, we can easily verify this by
    using the **number of messages per hour**. I already have a number of messages,
    grouped by hour and normalized to 100%. Let’s find users who are posting messages
    continuously, without any delays. To do this, we only need to filter users who
    were posting 100/24 = 4% of their messages every hour:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 结果很有趣。这些数据是在7天内收集的。数据框中有1,198,067个唯一用户在此期间发布了至少一条消息。而90百分位数仅为4，这意味着90%的用户在这一周内仅发布了4条消息。与发布超过5000条推文的顶级用户相比，差异很大！但正如在第一部分讨论的那样，一些“顶级用户”可能是机器人。我们可以通过使用**每小时消息数量**轻松验证这一点。我已经有了按小时分组并标准化到100%的消息数量。让我们找出连续发布消息而没有任何延迟的用户。为此，我们只需筛选出每小时发布100/24
    = 4%消息的用户：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The number may not be exactly 4%, so I used 2..5% as a filter range. As a result,
    28 “users” were found who were posting the same number of messages every hour:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数字可能不完全是4%，因此我使用了2..5%作为筛选范围。结果发现有28个“用户”每小时发布相同数量的消息：
- en: '![](../Images/74660a9de6e7c408f3b61eda66d67302.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74660a9de6e7c408f3b61eda66d67302.png)'
- en: “Users”, posting messages with equal intervals, Image by author
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 发布等间隔消息的“用户”，作者提供的图片
- en: In the previous part, I had already detected some bots using the clustering
    algorithm. Here we can see that even with a much more simple approach, we can
    get similar results.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分，我已经使用聚类算法检测到了一些机器人。在这里，我们可以看到即使使用更简单的方法，我们也可以获得类似的结果。
- en: 'Let’s go to a more fun part and **group users by their activity time**. Because
    the total amount of messages per hour is normalized to 100%, it''s possible to
    make pretty complex requests. For example, let’s add new columns “morning”, “day”,
    “evening”, and “night”:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For the analysis, I will use only those users who posted more than 10 messages:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Of course, 10 is not a statistically significant number. This is only a proof
    of concept, and for real research, collecting data at longer intervals is recommended.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, the results are interesting. For example, we can find **users who posted
    most of their** **messages in the morning**, using only one line of code. We can
    also get all these messages and draw them on the timeline:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The result looks like this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8ab28c9f870705a57d781925b53f674f.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Users posting tweets in the morning, Image by author
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'Interestingly, this number is only about 3%. As a comparison, 46% of active
    users send more than 50% of their **messages during the day**:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/19e0eec4bb497452b59a1b5e4af24421.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: Users posting tweets during the day, Image by author
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'We can make other requests; for example, let’s find users who are making **80%
    of their messages in the evening**:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The result looks like this:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/62cebcc5864fc080a9ec447d7c450db8.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: Users posting tweets in the evening, Image by author
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also display the timeline of some users to verify the results:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output looks like this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bbfe34c9683b5f414b2b55b76e69ca7b.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
- en: Timeline of selected users, Image by author
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Results can be interesting; for example, the user “rhod***” was posting almost
    all the messages at the same time after 19.00.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Again, I must repeat that these results are not final. I analyzed only more
    or less active users who posted more than 10 tweets within a week. But a significant
    number of users posted fewer messages, and to gather more insights about them,
    data should be collected within several weeks or even months.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this article, we were able to get all Twitter messages posted in a specific
    language — in our example, Dutch. This language is mostly used in the Netherlands
    and Belgium, which are located close to each other. This allows us to know the
    user’s timezone, which, alas, I was not able to obtain from the Twitter API, at
    least using the free account. By doing an analysis of message timestamps, we can
    get a lot of interesting information; for example, it is possible to find out
    if more users are active in the morning, during working hours, or in the evening.
    Finding temporal patterns in users’ behavior can be useful for psychology, cultural
    anthropology, or even medicine. Millions of people are using social networks,
    and it is interesting to know how it affects our lives, the rhythm of work, or
    sleep. And as was shown in the article, analyzing this behavior can be done using
    simple requests, which are actually not more difficult than school math.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: It was also interesting to see how much data social networks can store. I suppose
    most people never think about how many messages are posted. Even for a relatively
    small Dutch-speaking community (about 25 million native speakers in the world),
    more than 10 tweets per second can be generated. For this article, 6,487,433 Twitter
    messages from 1,515,139 users were analyzed, and these were only messages posted
    within 10 days! For larger countries like Germany, getting all the messages will
    probably be beyond the limitations of a free Twitter development account. In that
    case, it may be possible to combine different request queries with filtering by
    user location.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 看到社交网络可以存储如此大量的数据也很有趣。我想大多数人从未考虑过发布了多少消息。即使是相对较小的荷兰语社区（全球约2500万母语者），每秒钟也能生成超过10条推文。对于这篇文章，分析了来自1,515,139用户的6,487,433条Twitter消息，这些消息仅仅是10天内发布的！对于像德国这样的大国来说，获取所有消息可能会超出免费的Twitter开发账户的限制。在这种情况下，可以考虑结合不同的请求查询，并按用户位置进行过滤。
- en: Anyway, social networks are an interesting source of information *about us*,
    and I wish readers good luck with their own experiments. Those who are interested
    are also welcome to read the [first part](/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699)
    about using the K-Means algorithm for clustering Twitter users. And as another
    approach, the [NLP analysis](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906)
    of Twitter posts was also explained.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，社交网络是一个*关于我们*的有趣信息来源，我祝愿读者在自己的实验中好运。那些感兴趣的人也欢迎阅读关于使用K-Means算法对Twitter用户进行聚类的[第一部分](/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699)。另外，Twitter帖子也进行了[NLP分析](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906)。
- en: If you enjoyed this story, feel free [to subscribe](https://medium.com/@dmitryelj/membership)
    to Medium, and you will get notifications when my new articles will be published,
    as well as full access to thousands of stories from other authors.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这个故事，可以[订阅](https://medium.com/@dmitryelj/membership)Medium，这样你将收到我新文章发布的通知，并可以全面访问其他作者的数千个故事。
- en: Thanks for reading.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
