["```py\nimport os\nimport tensorflow.keras.backend as K\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import MaxPooling2D\n```", "```py\n def create_pairs(images, labels):\n  imagePairs = []\n  labelPairs = []\n\n  #Getting the indices of each class\n  numclasses = len(np.unique(labels))\n  idx = [np.where(labels ==i)[0] for i in range(numclasses)]\n\n  for ind in range(len(images)):\n    #Getting current image with index\n    currImage = images[ind]\n    #getting the label of the image from labels.\n    label = labels[ind]\n\n    #Randomly choosing another labels from the same class\n    indB = np.random.choice(idx[label])\n    #corresponding image for this randomly selected label\n    indImage = images[indB]\n\n    imagePairs.append([currImage, indImage])\n\n    labelPairs.append([1])\n\n    #Getting a label where label is different than the current image\n    diss_idx = np.where(labels != label)[0]\n\n    #finding an image for this label\n    diss_image = images[np.random.choice(diss_idx)]\n\n    imagePairs.append([currImage, diss_image])\n    labelPairs.append([0])\n\n  return (np.array(imagePairs), np.array(labelPairs))\n```", "```py\ndef euclidean_distance(vecs):\n  (imgA, imgB) = vecs\n  ss = K.sum(K.square(imgA - imgB), axis = 1, keepdims=True)\n  return K.sqrt(K.maximum(ss, K.epsilon()))\n```", "```py\n def siamese_model(input_shape, embeddingDim = 48):\n  inputs = Input(input_shape)\n  x = Conv2D(128, (2, 2), padding = \"same\", activation = \"relu\")(inputs)\n  x = MaxPooling2D(pool_size=(2, 2))(x)\n  x = Dropout(0.4)(x)\n\n  x = Conv2D(128, (2, 2), padding = \"same\", activation = \"relu\")(inputs)\n  x = MaxPooling2D(pool_size=(2, 2))(x)\n  x = Dropout(0.4)(x)\n\n  pooling = GlobalAveragePooling2D()(x)\n  outputs = Dense(embeddingDim)(pooling)\n  model = Model(inputs, outputs)\n\n  return model\n```", "```py\ndef contrastiveLoss(y, y_preds, margin=1):\n y = tf.cast(y, y_preds.dtype)\n y_preds_squared = K.square(y_preds)\n margin_squared = K.square(K.maximum(margin - y_preds, 0))\n loss = K.mean(y * y_preds_squared + (1 - y) * margin_squared)\n return loss\n```", "```py\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.datasets import fashion_mnist\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n```", "```py\nx_train = x_train/255.0\nx_test = x_test/255.0\n\nx_train = np.expand_dims(x_train, axis = -1)\nx_test = np.expand_dims(x_test, axis=-1)\n\n(training_pairs, training_labels) = create_pairs(x_train, y_train)\n(test_pairs, test_labels) = create_pairs(x_test, y_test)\n```", "```py\nimage_shape = (28, 28, 1)\n# specify the batch size and number of epochs\nbatch_size = 64\nepochs = 70\n\nimageA = Input(shape = image_shape)\nimageB = Input(shape = image_shape)\n\nmodel_build = siamese_model(image_shape)\nmodelA = model_build(imageA)\nmodelB = model_build(imageB)\n\ndistance = Lambda(euclidean_distance)([modelA, modelB])\nmodel = Model(inputs=[imageA, imageB], outputs=distance)\n```", "```py\nmodel.compile(loss = contrastiveLoss, optimizer=\"adam\")\nhistory = model.fit(\n    [training_pairs[:, 0], training_pairs[:, 1]], training_labels[:],\n    validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels[:]),\n    batch_size = batch_size,\n    epochs = epochs\n```", "```py\nEpoch 1/70\n1875/1875 [==============================] - 24s 7ms/step - loss: 0.1808 - val_loss: 0.1618\nEpoch 2/70\n1875/1875 [==============================] - 15s 8ms/step - loss: 0.1615 - val_loss: 0.1572\nEpoch 3/70\n1875/1875 [==============================] - 14s 7ms/step - loss: 0.1588 - val_loss: 0.1551\nEpoch 4/70\n1875/1875 [==============================] - 14s 8ms/step - loss: 0.1566 - val_loss: 0.1529\nEpoch 5/70\n1875/1875 [==============================] - 14s 7ms/step - loss: 0.1552 - val_loss: 0.1520\n.\n.\n.\n.\nEpoch 67/70\n1875/1875 [==============================] - 14s 7ms/step - loss: 0.1486 - val_loss: 0.1447\nEpoch 68/70\n1875/1875 [==============================] - 14s 7ms/step - loss: 0.1487 - val_loss: 0.1443\nEpoch 69/70\n1875/1875 [==============================] - 14s 7ms/step - loss: 0.1484 - val_loss: 0.1447\nEpoch 70/70\n1875/1875 [==============================] - 14s 7ms/step - loss: 0.1490 - val_loss: 0.1446\n```", "```py\nimport cv2\npairs = np.random.choice(len(test_pairs), size=4)\n\nfor i in pairs:\n  imageA = test_pairs[i][0]\n  imageB = test_pairs[i][1]\n\n  baseA = imageA.copy()\n  baseB = imageB.copy()\n\n  imageA = np.expand_dims(imageA, axis=-1)\n  imageB = np.expand_dims(imageB, axis=-1)\n\n  imageA = np.expand_dims(imageA, axis=0)\n  imageB = np.expand_dims(imageB, axis =0)\n\n  imageA = imageA/255.0\n  imageB = imageB / 255.0\n\n  predicts = model.predict([imageA, imageB])\n\n  proba = predicts[0][0]\n\n  fig = plt.figure(\"Pair #{}\".format(i+1), figsize=(4,2))\n  plt.suptitle(\"Distance: {}:.2f\".format(proba))\n\n  ax = fig.add_subplot(1, 2, 1)\n  plt.imshow(baseA, cmap=plt.cm.gray)\n  plt.axis(\"off\")\n\n  ax = fig.add_subplot(1, 2, 2)\n  plt.imshow(baseB, cmap=plt.cm.gray)\n  plt.axis(\"off\")\n\n  plt.show()\n```"]