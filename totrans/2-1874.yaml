- en: 'Sklearn Pipelines for the Modern ML Engineer: 9 Techniques You Can’t Ignore'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/sklearn-pipelines-for-the-modern-ml-engineer-9-techniques-you-cant-ignore-637788f05df5](https://towardsdatascience.com/sklearn-pipelines-for-the-modern-ml-engineer-9-techniques-you-cant-ignore-637788f05df5)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are so many ways you can build them…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ibexorigin.medium.com/?source=post_page-----637788f05df5--------------------------------)[![Bex
    T.](../Images/516496f32596e8ad56bf07f178a643c6.png)](https://ibexorigin.medium.com/?source=post_page-----637788f05df5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----637788f05df5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----637788f05df5--------------------------------)
    [Bex T.](https://ibexorigin.medium.com/?source=post_page-----637788f05df5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----637788f05df5--------------------------------)
    ·10 min read·May 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d48b62f54a1b0bf20e303b7d4db6b1d8.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Image by me with Midjourney**'
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Today, this is what I am selling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`awesome_pipeline` may look just like another variable, but here is what it
    does to poor `X` and `y` under the hood:'
  prefs: []
  type: TYPE_NORMAL
- en: Automatically isolates numerical and categorical features of `X`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Imputes missing values in numeric features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log-transforms skewed features while normalizing the rest.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Imputes missing values in categorical features and one-hot encodes them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Normalizes the target array `y` for good measure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apart from collapsing almost 100 lines worth of unreadable code into a single
    line, `awesome_pipeline` can now be inserted into cross-validators or hyperparameter
    tuners, guarding your code from data leakage and making everything reproducible,
    modular, and headache-free.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how to build the thing.
  prefs: []
  type: TYPE_NORMAL
- en: 0\. Estimators vs transformers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s get the terminology out of the way.
  prefs: []
  type: TYPE_NORMAL
- en: A transformer in Sklearn is any class or function that accepts features of a
    dataset, applies transformations, and returns them. It has `fit_transform` and
    `transform` methods.
  prefs: []
  type: TYPE_NORMAL
- en: An example is the `QuantileTransformer`, which takes numeric input(s) and makes
    them normally distributed. It is especially useful for features with [outliers](/how-to-perform-outlier-detection-in-python-in-easy-steps-for-machine-learning-1-8f9a3e6c88b5).
  prefs: []
  type: TYPE_NORMAL
- en: Transformers inherit from the `TransformerMixin` base class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: On the other hand, an estimator is any class that usually generates predictions
    on a dataset. Estimators often have names ending with words like `Regressor` or
    `Classifier`.
  prefs: []
  type: TYPE_NORMAL
- en: Estimators inherit from the `BaseEstimator` class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 1\. Vanilla pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A vanilla pipeline in Sklearn always consists of one or more transformers of
    the same type and one final estimator. It chains the transformers to perform a
    series of operations on the feature array (`X`), eliminating the need to call
    `fit_transform` for each transformer and feed the final output to the estimator.
    All of this is done in a single line of code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To build a vanilla pipeline, you can use the `make_pipeline` function and pass
    the transformers and the estimator. The order of the transformers matters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The above example showcases a **numeric pipeline**, which can only be fitted
    to a dataset with numeric features. There is also a **categorical pipeline**,
    designed for datasets with only categorical features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Each item passed into `make_pipeline` is referred to as a step in the pipeline,
    as depicted in the output below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `make_pipeline` function automatically assigns names to each step in the
    pipeline, but these names can be lengthy and explicit.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to provide custom step names, you need to use the `Pipeline` class
    directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `steps` argument accepts a list of tuples with two items:'
  prefs: []
  type: TYPE_NORMAL
- en: Step name as a string.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The transformer or the estimator for that step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The significance of properly naming steps will become evident in the upcoming
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. A milkshake of transformers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, you will rarely use vanilla transformers on their own because real-world
    datasets often consist of a mixture of numeric and categorical features.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, you need a way to combine different categories of transformers into
    a single object while also specifying which transformer should be applied to which
    columns in the dataset `X`.
  prefs: []
  type: TYPE_NORMAL
- en: This functionality is elegantly implemented in the `ColumnTransformer` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'In step 0, you need to define the numeric and categorical features separately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In step 1, define two transformer-only pipelines for both numeric and categorical
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can create an instance of a `ColumnTransformer` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `transformers` argument of `ColumnTransformer` accepts a list of three-item
    tuples:'
  prefs: []
  type: TYPE_NORMAL
- en: The name of the step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The transformer or a pipeline of transformers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The name of the columns to which the transformers should be applied.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you use the `transformers` object, it will apply two types of operations
    on both numeric and categorical features independently and then combine the results
    to return a single matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, a `ColumnTransformer` represents a more complex pipeline that does
    not include a final estimator. To complete the pipeline, let's add one.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. A milkshake with a watermelon on top
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Right now, our semi-pipeline only *transforms* the dataset `X`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The only thing missing from it is an estimator. This is easily fixable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Depending on the machine learning task, you need to chain either a Regressor
    or a Classifier estimator as the final step in the pipeline. The resulting pipeline
    will have both a `fit` and a `predict` method, depending on the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 4\. Choosing columns with style
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While defining the `ColumnTransformer`, we specified the numeric and categorical
    features manually, one by one. Like a caveman.
  prefs: []
  type: TYPE_NORMAL
- en: But fear not! Sklearn provides a cool way of doing it more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`make_column_selector` is a handy function that allows you to automatically
    isolate columns from dataframes in various ways. In the example above, we used
    it to filter columns based on their data type. However, you can also utilize the
    `pattern` parameter to specify a regular expression (RegEx) pattern for filtering
    column names.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The provided example captures columns that start with either `word1` or `word2`.
  prefs: []
  type: TYPE_NORMAL
- en: This function is particularly useful when constructing `ColumnTransformer` objects.
    It eliminates the need to manually list down each and every column name, which
    can become challenging, if not impossible, when dealing with datasets containing
    numerous columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `make_column_transformer` function is a shorthand function, similar to `make_pipeline`,
    that allows you to build `ColumnTransformer` objects without explicitly specifying
    step names. By combining it with `make_column_selector`, you can significantly
    shorten your code.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Visual pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you print a complex pipeline, such as `full_pipeline_clf`, the output can
    become an unreadable mess in your Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this issue, you can set the `display` option to `diagram` using
    the `set_config` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when you print or return the pipeline, an HTML diagram will be displayed,
    providing a visual representation of the pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a29f80ad9a88d5961d7854e2d8e1eb0f.png)'
  prefs: []
  type: TYPE_IMG
- en: This visual representation is extremely helpful for debugging and diagnostics.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the HTML representation is the default in the latest versions
    of Sklearn (1.0.0 onwards).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6\. Pipeline cache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once your pipeline is ready, you’ll likely want to run it 24/7\. However, since
    the pipeline includes multiple transformers that manipulate the data, rerunning
    the same operations can be time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this issue, Sklearn provides a `memory` argument that allows you
    to cache the output of transformers within the pipeline. This caching mechanism
    helps avoid unnecessary recomputation of transformer outputs. Here''s how you
    can use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: To enable caching, you need to create a temporary directory using the `mkdtemp`
    function. Then, you can pass this directory path to the `memory` argument of the
    `Pipeline` object.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, make sure to include `rmtree(cache_dir)` at the end of your script
    or notebook to remove the cache directory and its contents.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are some caveats to using the cache (although nothing serious).
    You can read more about them [here](https://scikit-learn.org/stable/modules/compose.html#caching-transformers-avoid-repeated-computation).
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Inside other objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Even though a pipeline contains a variety of transformers, at the end of the
    day, it is an estimator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This means it can be used anywhere a typical stand-alone estimator could be
    used. For example, pipelines are often inserted into cross-validators to guard
    the machine learning model from data leakage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Or into hyperparameter tuners such as `[HalvingGridSearch](/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232ed0160155)`
    (for the same reasons):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, I want to draw your attention to the definition of the parameter
    grid. Take a look at how it is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The first parameter, `with_mean`, of `StandardScaler` serves as an example
    of a nested parameter. It is preceded by two specifiers: `preprocessor` and `numeric`,
    separated by double underscores.'
  prefs: []
  type: TYPE_NORMAL
- en: Nested parameters follow the `<step_name>__<parameter>` syntax. In this case,
    `with_mean` is a parameter of a transformer that is two levels deep. The inner
    pipeline's name is `numeric`, and the outer one's name is `preprocessor`, resulting
    in `preprocessor__numeric__with_mean`.
  prefs: []
  type: TYPE_NORMAL
- en: By writing nested parameters in this syntax, you can optimize not only for the
    parameters of the model but also for the parameters of the inner transformers
    themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Custom transformers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What if you want to perform a custom transformation on the data that is not
    implemented in the `sklearn.preprocessing` module? Do you have to abandon Sklearn
    pipelines and all the benefits they bring?
  prefs: []
  type: TYPE_NORMAL
- en: 'Absolutely not! With the `FunctionTransformer` class, you can transform any
    Python function into a transformer that can be integrated into pipelines. For
    instance, consider the following function that adds a column representing the
    number of missing values in each row of a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To convert it into a transformer, you just have to wrap it with `FunctionTransformer`
    and pass it into pipelines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'There may also be cases where simple functions are not sufficient to create
    custom transformations. In such cases, you can create your own classes that inherit
    from the `TransformerMixin` class. I won''t go into the details here, but I recommend
    checking out a comprehensive article I wrote on the topic last year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://ibexorigin.medium.com/in-depth-guide-to-building-custom-sklearn-transformers-for-any-data-preprocessing-scenario-33450f8b35ff?source=post_page-----637788f05df5--------------------------------)
    [## In-Depth Guide to Building Custom Sklearn Transformers for any Data Preprocessing
    Scenario'
  prefs: []
  type: TYPE_NORMAL
- en: Edit description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ibexorigin.medium.com](https://ibexorigin.medium.com/in-depth-guide-to-building-custom-sklearn-transformers-for-any-data-preprocessing-scenario-33450f8b35ff?source=post_page-----637788f05df5--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 9\. Target transformations with a pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the most part, the transformers in your pipeline focus on the feature array
    `X`. However, there are cases where the target array `y` requires some preprocessing
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: A common scenario in regression is to make the target normally distributed to
    improve the fit of linear models. If you perform the normalization outside a pipeline,
    there is a chance you might introduce data leakage to your training set.
  prefs: []
  type: TYPE_NORMAL
- en: To address this issue and simplify the process, Sklearn provides the `TransformedTargetRegressor`
    class. With this class, you can include target array transformations directly
    in your pipeline, ensuring data integrity and reducing boilerplate code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: After defining the pipeline that ends with a regression model like `LinearRegression`,
    you can pass it into the `regressor` argument of the `TransformedTargetRegressor`
    class. Additionally, you need to specify the transformer for the target array
    `y` using the `transformer` argument.
  prefs: []
  type: TYPE_NORMAL
- en: For more information about this class and its usage, you can refer to the [Sklearn
    documentation](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html#sklearn.compose.TransformedTargetRegressor).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I believe this article is one of my most detailed yet on Sklearn, unless you
    count maybe these two:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/19-hidden-sklearn-features-you-were-supposed-to-learn-the-hard-way-5293e6ff149?source=post_page-----637788f05df5--------------------------------)
    [## 19 Hidden Sklearn Features You Were Supposed to Learn The Hard Way'
  prefs: []
  type: TYPE_NORMAL
- en: Edit description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/19-hidden-sklearn-features-you-were-supposed-to-learn-the-hard-way-5293e6ff149?source=post_page-----637788f05df5--------------------------------)
    [](/10-sklearn-gems-buried-in-the-docs-waiting-to-be-found-ad95a8fabdfd?source=post_page-----637788f05df5--------------------------------)
    [## 10 Sklearn Gems Buried In the Docs Waiting To Be Found
  prefs: []
  type: TYPE_NORMAL
- en: Edit description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/10-sklearn-gems-buried-in-the-docs-waiting-to-be-found-ad95a8fabdfd?source=post_page-----637788f05df5--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Anyway, Sklearn pipelines are one of the primary reasons why I keep coming back
    to this favorite library of mine. They bring harmony to the chaotic world of machine
    learning workflows, turning raw data into gold with elegance and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: With pipelines, you can orchestrate a symphony of transformers, estimators,
    and column transformers, effortlessly taming even the wildest datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading!
  prefs: []
  type: TYPE_NORMAL
- en: Loved this article and, let’s face it, its bizarre writing style? Imagine having
    access to dozens more just like it, all written by a brilliant, charming, witty
    author (that’s me, by the way :).
  prefs: []
  type: TYPE_NORMAL
- en: For only 4.99$ membership, you will get access to not just my stories, but a
    treasure trove of knowledge from the best and brightest minds on Medium. And if
    you use [my referral link](https://ibexorigin.medium.com/membership), you will
    earn my supernova of gratitude and a virtual high-five for supporting my work.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://ibexorigin.medium.com/membership?source=post_page-----637788f05df5--------------------------------)
    [## Join Medium with my referral link - Bex T.'
  prefs: []
  type: TYPE_NORMAL
- en: Get exclusive access to all my ⚡premium⚡ content and all over Medium without
    limits. Support my work by buying me a…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ibexorigin.medium.com](https://ibexorigin.medium.com/membership?source=post_page-----637788f05df5--------------------------------)
    ![](../Images/ecb20212397d966ec82b2333cf9ec8f5.png)
  prefs: []
  type: TYPE_NORMAL
- en: Image by me with Midjourney
  prefs: []
  type: TYPE_NORMAL
