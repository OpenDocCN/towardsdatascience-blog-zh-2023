- en: Differential Equations as a Pytorch Neural Network Layer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作为 Pytorch 神经网络层的微分方程
- en: 原文：[https://towardsdatascience.com/differential-equations-as-a-pytorch-neural-network-layer-7614ba6d587f](https://towardsdatascience.com/differential-equations-as-a-pytorch-neural-network-layer-7614ba6d587f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/differential-equations-as-a-pytorch-neural-network-layer-7614ba6d587f](https://towardsdatascience.com/differential-equations-as-a-pytorch-neural-network-layer-7614ba6d587f)
- en: How to use differential equations layers in pytorch
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何在 pytorch 中使用微分方程层
- en: '[](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)[![Kevin
    Hannay](../Images/6dfcf0384e2a8aac0dd27a216ed2d92c.png)](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------)
    [Kevin Hannay](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)[![Kevin
    Hannay](../Images/6dfcf0384e2a8aac0dd27a216ed2d92c.png)](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------)
    [Kevin Hannay](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------)
    ·17 min read·Apr 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------)
    ·阅读时间 17 分钟·2023 年 4 月 26 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Differential equations are the mathematical foundation for most of modern science.
    They describe the state of a system using an equation for the rate of change (differential).
    It is remarkable how many systems can be well described by equations of this form.
    For example, the physical laws describing motion, electromagnetism and quantum
    mechanics all take this form. More broadly, differential equations describe chemical
    reaction rates through the law of mass action, neuronal firing and disease spread
    through the SIR model.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 微分方程是现代科学的大多数数学基础。它们通过描述变化率（微分）的方程来描述系统的状态。许多系统都可以通过这种形式的方程很好地描述。例如，描述运动、电磁学和量子力学的物理定律都采用这种形式。更广泛地说，微分方程通过质量作用定律描述化学反应速率，通过
    SIR 模型描述神经元放电和疾病传播。
- en: The deep learning revolution has brought with it a new set of tools for performing
    large scale optimizations over enormous datasets. In this post, we will see how
    you can use these tools to fit the parameters of a custom differential equation
    layer in pytorch.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习革命带来了新一套工具，用于在巨大的数据集上进行大规模优化。在这篇文章中，我们将探讨如何使用这些工具来拟合 pytorch 中自定义微分方程层的参数。
- en: What is the problem we are trying to solve?
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们要解决的问题是什么？
- en: Let’s say we have some time series data y(t) that we want to model with a differential
    equation. The data takes the form of a set of observations yᵢ at times tᵢ. Based
    on some domain knowledge of the underlying system we can write down a differential
    equation to approximate the system.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一些时间序列数据 y(t)，我们希望用微分方程对其建模。数据表现为在时间 tᵢ 上的一组观察值 yᵢ。基于对基础系统的某些领域知识，我们可以写出一个微分方程来近似该系统。
- en: 'In the most general form this takes the form:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在最一般的形式下，这表现为：
- en: '![](../Images/a40c428710be4c634489d22e95a37020.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a40c428710be4c634489d22e95a37020.png)'
- en: General ordinary differential equation system
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一般常微分方程系统
- en: where y is the state of the system, t is time, and θ are the parameters of the
    model. In this post we will assume that the parameters θ are unknown and we want
    to learn them from the data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 y 是系统的状态，t 是时间，而 θ 是模型的参数。在这篇文章中，我们将假设参数 θ 是未知的，我们希望从数据中学习这些参数。
- en: All of the code for this post is available on [github](https://github.com/khannay/paramfittorchdemo)
    or as a [colab notebook](https://colab.research.google.com/github/khannay/paramfittorchdemo/blob/main/nbs/00_training.ipynb),
    so no need to try and copy and paste if you want to follow along.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的所有代码可在 [github](https://github.com/khannay/paramfittorchdemo) 或 [colab notebook](https://colab.research.google.com/github/khannay/paramfittorchdemo/blob/main/nbs/00_training.ipynb)
    上找到，所以如果你想跟随学习，无需尝试复制粘贴。
- en: Let’s import the libraries we will need for this post. The only non standard
    machine learning library we will use the [torchdiffeq](https://github.com/rtqichen/torchdiffeq)
    library to solve the differential equations. This library implements numerical
    differential equation solvers in pytorch.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们导入本帖所需的库。我们将使用的唯一非标准机器学习库是 [torchdiffeq](https://github.com/rtqichen/torchdiffeq)
    库来解决微分方程。该库在 pytorch 中实现了数值微分方程求解器。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Models
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: The first step of our modeling process is to define the model. For differential
    equations this means we must choose a form for the function f(y,t;θ) and a way
    to represent the parameters θ. We also need to do this in a way that is compatible
    with pytorch.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建模过程的第一步是定义模型。对于微分方程，这意味着我们必须选择函数 f(y,t;θ) 的形式和表示参数 θ 的方式。我们还需要以与 pytorch
    兼容的方式完成这项工作。
- en: This means we need to encode our function as a *torch.nn.Module* class. As you
    will see this is pretty easy and only requires defining two methods. Lets get
    started with the first of out three example models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们需要将我们的函数编码为 *torch.nn.Module* 类。正如你所看到的，这非常简单，只需要定义两个方法。让我们从三个示例模型中的第一个开始。
- en: van Der Pol Oscillator (VDP)
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: van Der Pol 振荡器 (VDP)
- en: We can define a differential equation system using the *torch.nn.Module* class
    where the parameters are created using the *torch.nn.Parameter* declaration. This
    lets pytorch know that we want to accumulate gradients for those parameters. We
    can also include fixed parameters (parameters that we don’t want to fit) by just
    not wrapping them with this declaration.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 *torch.nn.Module* 类来定义一个微分方程系统，其中参数通过 *torch.nn.Parameter* 声明创建。这让 pytorch
    知道我们希望为这些参数累积梯度。我们还可以通过不使用此声明来包含固定参数（我们不想调整的参数）。
- en: 'The first example we will use is the classic VDP oscillator which is a nonlinear
    oscillator with a single parameter μ. The differential equations for this system
    are:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的第一个示例是经典的 VDP 振荡器，它是一个具有单个参数 μ 的非线性振荡器。该系统的微分方程是：
- en: '![](../Images/f984c8771b0c62531721fc143d1f7dc6.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f984c8771b0c62531721fc143d1f7dc6.png)'
- en: VDP oscillator equations
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: VDP 振荡器方程
- en: 'where **x** and **y** are the state variables. The VDP model is used to model
    everything from electronic circuits to cardiac arrhythmias and circadian rhythms.
    We can define this system in pytorch as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 **x** 和 **y** 是状态变量。VDP 模型用于模拟从电子电路到心律失常和昼夜节律的一切。我们可以在 pytorch 中定义此系统如下：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You only need to define the *__init__* method (**init**) and the forward method.
    I added a string method __*repr__* to pretty print the parameter. The key point
    here is how we can translate from the differential equation to torch code in the
    forward method. This method needs to define the right-hand side of the differential
    equation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要定义 *__init__* 方法 (**init**) 和 forward 方法。我添加了一个字符串方法 __*repr__* 来美观地打印参数。关键点在于我们如何在
    forward 方法中将微分方程转换为 torch 代码。此方法需要定义微分方程的右侧。
- en: 'Let’s see how we can integrate this model using the odeint method from torchdiffeq:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用来自 torchdiffeq 的 odeint 方法来集成这个模型：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/38e234bbc82a1b9c30dc4b550479214c.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38e234bbc82a1b9c30dc4b550479214c.png)'
- en: Here is a phase plane plot of the solution (a phase plane plot of a parametric
    plot of the dynamical state).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是解的相平面图（动态状态的参数图的相平面图）。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/a58bc70d4e871b67c22c583f19227709.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a58bc70d4e871b67c22c583f19227709.png)'
- en: The colors indicate the 30 separate trajectories in our batch. The solution
    comes back as a torch tensor with dimensions (time_points, batch number, dynamical_dimension).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色表示我们批次中的 30 条独立轨迹。解返回为具有 (time_points, batch number, dynamical_dimension)
    维度的 torch 张量。
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lotka Volterra Predator Prey equations
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lotka-Volterra 捕食者-猎物方程
- en: 'As another example we create a module for the Lotka-Volterra predator-prey
    equations. In the Lotka-Volterra (LV) predator-prey model, there are two primary
    variables: the population of prey (x) and the population of predators (y). The
    model is defined by the following equations:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个示例，我们创建一个 Lotka-Volterra 捕食者-猎物方程的模块。在 Lotka-Volterra (LV) 捕食者-猎物模型中，有两个主要变量：猎物的种群
    (x) 和捕食者的种群 (y)。该模型由以下方程定义：
- en: '![](../Images/4861c4876c104ce423e07b60b0ffdc04.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4861c4876c104ce423e07b60b0ffdc04.png)'
- en: Lotka-Volterra equations for predator prey dynamics
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 捕食者-猎物动态的 Lotka-Volterra 方程
- en: 'In addition to the primary variables, there are also four parameters that are
    used to describe various ecological factors in the model:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 除了主要变量，还有四个参数用于描述模型中的各种生态因素：
- en: α represents the intrinsic growth rate of the prey population in the absence
    of predators. β represents the predation rate of the predators on the prey. γ
    represents the death rate of the predator population in the absence of prey. δ
    represents the efficiency with which the predators convert the consumed prey into
    new predator biomass.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: α 表示在没有捕食者情况下猎物种群的内在增长率。β 表示捕食者对猎物的捕食率。γ 表示在没有猎物情况下捕食者种群的死亡率。δ 表示捕食者将消耗的猎物转化为新捕食者生物量的效率。
- en: 'Together, these variables and parameters describe the dynamics of predator-prey
    interactions in an ecosystem and are used to mathematically model the changes
    in the populations of prey and predators over time. Here is this system as a *torch.nn.Module*:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变量和参数共同描述了生态系统中捕食者与猎物之间的相互作用动态，并用于数学建模猎物和捕食者种群随时间的变化。这里是这个系统作为 *torch.nn.Module*
    的实现：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This follows the same pattern as the first example, the main difference is that
    we now have four parameters and store them as a *model_params* tensor. Here is
    the integration and plotting code for the predator-prey equations.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这遵循了与第一个示例相同的模式，主要区别在于我们现在有四个参数，并将它们存储为 *model_params* 张量。以下是捕食者-猎物方程的积分和绘图代码。
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/58bdcdc8b3ec9b84c3af02856148c2c9.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58bdcdc8b3ec9b84c3af02856148c2c9.png)'
- en: 'Now a phase plane plot of the system:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是系统的相平面图：
- en: '![](../Images/d7ae7a0eda4a514d6111b301033a2e53.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7ae7a0eda4a514d6111b301033a2e53.png)'
- en: Lorenz system
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 洛伦兹系统
- en: 'The last example we will use is the Lorenz equations which are famous for their
    beautiful plots illustrating chaotic dynamics. They originally came from a reduced
    model for fluid dynamics and take the form:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的最后一个示例是洛伦兹方程，这些方程因其美丽的混沌动态图而闻名。它们最初来源于流体动力学的简化模型，并呈现以下形式：
- en: '![](../Images/0dcaffefdc1eba6471cc753f3d0a3faa.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dcaffefdc1eba6471cc753f3d0a3faa.png)'
- en: where x, y, and z are the state variables, and σ, ρ, and β are the system parameters.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 x、y 和 z 是状态变量，σ、ρ 和 β 是系统参数。
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This shows how to integrate this system and plot the results. This system (at
    these parameter values) shows chaotic dynamics so initial conditions that start
    off close together diverge from one another exponentially.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了如何集成这个系统并绘制结果。该系统（在这些参数值下）显示了混沌动态，因此起始条件虽然很接近，但会指数级地彼此发散。
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/7984eecf06eb3fd53899755e48f5964d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7984eecf06eb3fd53899755e48f5964d.png)'
- en: Here we show the famous butterfly plot (phase plane plot) for the first set
    of initial conditions in the batch.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了第一组初始条件的著名蝴蝶图（相平面图）。
- en: '![](../Images/58e4336da5ee47b8d7bcaf8666994410.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58e4336da5ee47b8d7bcaf8666994410.png)'
- en: The Lorenz equations show chaotic dynamics and trace out a beautiful strange
    attractor.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 洛伦兹方程展示了混沌动态，并描绘出一个美丽的奇异吸引子。
- en: Data
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据
- en: Now that we can define the differential equation models in pytorch we need to
    create some data to be used in training. This is where things start to get really
    neat as we see our first glimpse of being able to hijack deep learning machinery
    for fitting the parameters. Really we could just use tensor of data directly,
    but this is a nice way to organize the data. It will also be useful if you have
    some experimental data that you want to use.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在 pytorch 中定义微分方程模型了，我们需要创建一些数据用于训练。这是事情变得真正有趣的地方，因为我们首次看到了能够利用深度学习机制来拟合参数的可能性。实际上，我们可以直接使用数据张量，但这是一种很好的组织数据的方式。如果你有一些实验数据需要使用，它也会很有用。
- en: Torch provides the *Dataset* class for loading in data. To use it you just need
    to create a subclass and define two methods. The *__len__* function that returns
    the number of data points and a *__getitem__* function that returns the data point
    at a given index. If you are wondering these methods are what underly the *len(array)*
    and *array[0]* subscript access in python lists.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Torch 提供了 *Dataset* 类用于加载数据。要使用它，你只需创建一个子类并定义两个方法。一个是返回数据点数量的 *__len__* 函数，另一个是返回给定索引处数据点的
    *__getitem__* 函数。如果你想知道这些方法是如何在 python 列表中支持 *len(array)* 和 *array[0]* 下标访问的。
- en: The rest of boilerplate code needed in defined in the parent class *torch.utils.data.Dataset*.
    We will see the power of these method when we go to define a training loop.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的样板代码在父类 *torch.utils.data.Dataset* 中定义。我们将在定义训练循环时看到这些方法的强大功能。
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Next let’s create a quick generator function to generate some simulated data
    to test the algorithms on. In a real use case the data would be loaded from a
    file or database- but for this example we will just generate some data. In fact,
    I recommend that you always start with generated data to make sure your code is
    working before you try to load real data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个快速生成器函数来生成一些模拟数据以测试算法。在实际使用中，数据将从文件或数据库中加载，但在这个例子中，我们将仅生成一些数据。实际上，我建议你总是从生成的数据开始，以确保你的代码在尝试加载真实数据之前正常工作。
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This just takes in a differential equation model with some initial states and
    generates some time-series data from it (and adds in some gaussian noise). This
    data is then passed into our custom dataset container.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是输入一个带有一些初始状态的微分方程模型，并从中生成一些时间序列数据（并添加一些高斯噪声）。然后这些数据被传入我们的自定义数据集容器中。
- en: Training Loop
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练循环
- en: Next we will create a wrapper function for a pytorch training loop. Training
    means we want to update the model parameters to increase the alignment with the
    data (or decrease the cost function).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将为pytorch训练循环创建一个包装函数。训练意味着我们想要更新模型参数以增加与数据的对齐度（或减少成本函数）。
- en: One of the tricks for this from deep learning is to not use all the data before
    taking a gradient step. Part of this is necessity for using enormous datasets
    as you can’t fit all of that data inside a GPU’s memory, but this also can help
    the gradient descent algorithm avoid getting stuck in local minima.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中的一个技巧是不要在进行梯度步骤之前使用所有数据。这部分是因为在使用巨大数据集时，你不能将所有数据放入GPU的内存中，但这也可以帮助梯度下降算法避免陷入局部最小值。
- en: 'The training loop in words:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 训练循环的文字描述：
- en: Divide the dataset into mini-batches, these are subsets of your entire data
    set. Usually want to choose these randomly.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集分割成小批量，这些是你整个数据集的子集。通常要随机选择这些小批量。
- en: Iterate through the mini-batches
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代小批量
- en: Generate the predictions using the current model parameters
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用当前模型参数生成预测
- en: Calculate the loss (here we will use the mean squared error)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算损失（这里我们将使用均方误差）
- en: Calculate the gradients, using backpropagation.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用反向传播计算梯度。
- en: Update the parameters using a gradient descent step. Here we use the Adam optimizer.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用梯度下降步骤更新参数。这里我们使用Adam优化器。
- en: Each full pass through the dataset is called an epoch.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整遍历数据集的过程称为一个周期（epoch）。
- en: 'Okay here is the code:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这里是代码：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Examples
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: Fitting the VDP Oscillator
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拟合VDP振荡器
- en: Let’s use this training loop to recover the parameters from simulated VDP oscillator
    data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个训练循环从模拟的VDP振荡器数据中恢复参数。
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let’s create a model with the wrong parameter value and visualize the starting
    point.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个参数值错误的模型并可视化起始点。
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/9a3ae99f6b8944ff0d86a7e00c724c7d.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a3ae99f6b8944ff0d86a7e00c724c7d.png)'
- en: Now, we will use the training loop to fit the parameters of the VDP oscillator
    to the simulated data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用训练循环来拟合VDP振荡器的参数到模拟数据中。
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Not to bad! Let’s see how the plot looks now…
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 不错！让我们看看图现在是什么样子的……
- en: '![](../Images/ec1504367018a9ece345f7546705af24.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec1504367018a9ece345f7546705af24.png)'
- en: The plot confirms that we almost perfectly recovered the parameter. One more
    quick plot, where we plot the dynamics of the system in the phase plane (a parametric
    plot of the state variables).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图示确认我们几乎完全恢复了参数。再绘制一个图，我们绘制系统在相平面上的动态（状态变量的参数化图）。
- en: '![](../Images/e6d29331b53d0080c8a5f6428375fff5.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6d29331b53d0080c8a5f6428375fff5.png)'
- en: 'Here is a visual of the training process for this model:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该模型的训练过程的可视化：
- en: '![](../Images/3bfaaa91a33776ca1bccbda8d804ec88.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3bfaaa91a33776ca1bccbda8d804ec88.png)'
- en: Video of the training process for the VDP model
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: VDP模型的训练过程视频
- en: Lotka Voltera Equations
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 洛特卡-沃尔泰拉方程
- en: Now lets adapt our methods to fit simulated data from the Lotka-Volterra equations.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们调整方法以拟合来自洛特卡-沃尔泰拉方程的模拟数据。
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here is the initial fits for the starting parameters, then we will fit as before
    and take a look at the results.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这是初始参数的拟合，然后我们将像之前一样拟合并查看结果。
- en: '![](../Images/c324d4f631cb1479f069a7c2471ec736.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c324d4f631cb1479f069a7c2471ec736.png)'
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'First a time-series plot of the fitted system:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是拟合系统的时间序列图：
- en: '![](../Images/1cad34d577e24b2bbae6a39ef6e8ea27.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cad34d577e24b2bbae6a39ef6e8ea27.png)'
- en: Now let’s visualize the results using a phase plane plot.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用相平面图来可视化结果。
- en: '![](../Images/c5bb7d6259f550bd7f5dc28330476a55.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5bb7d6259f550bd7f5dc28330476a55.png)'
- en: Here is a visual of the fitting process….
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是拟合过程的可视化……
- en: '![](../Images/7b71c438cc820ad955e4595c1cd1131d.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b71c438cc820ad955e4595c1cd1131d.png)'
- en: Lorenz Equations
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 洛伦兹方程
- en: Finally, let’s try to fit the Lorenz equations.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们尝试拟合洛伦兹方程。
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here is the initial fits, then we will call our training loop.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是初始拟合，然后我们将调用训练循环。
- en: '![](../Images/fc271257498a7efd4a21da9c71d16e56.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc271257498a7efd4a21da9c71d16e56.png)'
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here are the training results:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这是训练结果：
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Let’s look at the fitted model. Starting with a full plot of the dynamics.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看拟合的模型。从完整的动态图开始。
- en: '![](../Images/68ad27e421cc95d203aa338507deb0f6.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68ad27e421cc95d203aa338507deb0f6.png)'
- en: Let’s zoom in on the bulk of the data and see how the fit looks.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们放大数据的主体部分，看看拟合效果如何。
- en: '![](../Images/3ff8fb66cb7d20e91b8dacb8082d7844.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ff8fb66cb7d20e91b8dacb8082d7844.png)'
- en: You can see the model is very close to the true model for the data range, and
    generalizes well for t < 16 for the unseen data. Now the phase plane plot (zoomed
    in).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到模型在数据范围内非常接近真实模型，并且对于 t < 16 的未见数据具有良好的泛化能力。现在是相位平面图（放大）。
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/2876da4f6595ae6470eb1b40a816366b.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2876da4f6595ae6470eb1b40a816366b.png)'
- en: You can see that our fitted model performs well for t in [0,16] and then starts
    to diverge.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们拟合的模型在 t ∈ [0,16] 范围内表现良好，但随后开始发散。
- en: Intro to Neural Differential Equations
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经微分方程简介
- en: This procedure works great for the situation where we know the form of the equations
    on the right-hand-side, but what if we don’t? Can we use this procedure to discover
    the model equations?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在我们知道右侧方程形式的情况下效果很好，但如果我们不知道呢？我们可以使用这个方法来发现模型方程吗？
- en: This is much too big of a subject to fully cover in this post, but one of the
    biggest advantages of moving our differential equations models into the torch
    framework is that we can mix and match them with artificial neural network layers.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个主题过于庞大，无法在这篇文章中完全覆盖，但将我们的微分方程模型迁移到 torch 框架的最大优势之一是我们可以将其与人工神经网络层混合搭配。
- en: The simplest thing we can do is to replace the right-hand-side f(y,t; θ) with
    a neural network layer. These types of equations have been called a neural differential
    equations and it can be viewed as [generalization of a recurrent neural network](https://dl.acm.org/doi/10.5555/3327757.3327764).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做的最简单的事情是用神经网络层替换方程右侧的 f(y,t; θ)。这类方程被称为神经微分方程，可以看作是[递归神经网络的推广](https://dl.acm.org/doi/10.5555/3327757.3327764)。
- en: '![](../Images/29598e77aeefc86671eadc34c6e77e7f.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29598e77aeefc86671eadc34c6e77e7f.png)'
- en: Neural differential equations replace the right-hand-side of the equations with
    a artificial neural network
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 神经微分方程将方程的右侧替换为人工神经网络
- en: As a first example, let’s do this for the our simple VDP oscillator system.
    To begin we will remake the simulated data, you will notice that I am creating
    longer time-series of the data and more samples. Fitting a neural differential
    equation takes much more data and more computational power since we have many
    more parameters that need to be determined.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一个例子，让我们对我们简单的 VDP 振荡器系统进行操作。首先，我们将重新生成模拟数据，你会注意到我正在创建更长的时间序列数据和更多的样本。拟合神经微分方程需要更多的数据和计算能力，因为我们有许多需要确定的参数。
- en: '[PRE23]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now I define a simple feedforward neural network layer to fill in the right-hand-side
    of the equation.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我定义一个简单的前馈神经网络层来填充方程的右侧。
- en: '[PRE24]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here is a plot of the system before fitting:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是拟合前系统的图：
- en: '[PRE25]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](../Images/ebf03ab9b520dde7236de0dfa8249652.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebf03ab9b520dde7236de0dfa8249652.png)'
- en: You can see we start very far away for the correct solution, but then again
    we are injecting much less information into our model. Let’s see if we can fit
    the model to get better results.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们一开始离正确解很远，但我们注入到模型中的信息却少得多。让我们看看能否通过拟合模型得到更好的结果。
- en: '[PRE26]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Visualizing the results, we can see that the model is able to fit the data and
    even extrapolate to the future (although it is not as good or fast as the specified
    model).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 通过可视化结果，我们可以看到模型能够拟合数据，甚至可以外推到未来（尽管它的效果和速度不如指定模型）。
- en: '![](../Images/2a9b06cf98c1563ef2aa13728286f085.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a9b06cf98c1563ef2aa13728286f085.png)'
- en: Now the phase plane plot of our neural differential equation model.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是我们神经微分方程模型的相位平面图。
- en: '![](../Images/1c04104e67e37c75340ecd6da5e55c6d.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c04104e67e37c75340ecd6da5e55c6d.png)'
- en: These models take a long time to train and more data to converge on a good fit.
    This makes sense since we are both trying to learn the model and the parameters
    at the same time.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型需要很长时间才能训练，并且需要更多数据才能获得良好的拟合。这是有道理的，因为我们同时试图学习模型和参数。
- en: '![](../Images/f3e1eda9f5826ff5860298d228175c6b.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f3e1eda9f5826ff5860298d228175c6b.png)'
- en: Video of the fitting process for a NDE.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: NDE拟合过程的视频。
- en: Conclusions and Wrap-Up
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论与总结
- en: 'In this article I have demonstrated how we can use differential equation models
    within the pytorch ecosytem using the torchdiffeq package. The code from this
    article is available on [github](https://github.com/khannay/paramfittorchdemo)
    and can be opened directly to [google colab](https://colab.research.google.com/github/khannay/paramfittorchdemo/blob/main/nbs/00_training.ipynb)
    for experimentation. You can also install the code from this article using pip:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我展示了如何在pytorch生态系统中使用torchdiffeq包应用微分方程模型。这篇文章中的代码可以在[github](https://github.com/khannay/paramfittorchdemo)上找到，并且可以直接在[google
    colab](https://colab.research.google.com/github/khannay/paramfittorchdemo/blob/main/nbs/00_training.ipynb)中打开进行实验。你也可以通过pip安装这篇文章中的代码：
- en: '[PRE28]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This post is an introduction in the future I will be writing more about the
    following topics:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章是一个介绍，未来我将写更多关于以下主题的内容：
- en: How to blend some mechanistic knowledge of the dynamics with deep learning.
    These have been called [universal differential equations](https://arxiv.org/abs/2001.04385)
    as they enable us to combine scientific knowledge with deep learning. This basically
    blends the two approaches together.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将一些动力学的机制知识与深度学习相结合。这些被称为[通用微分方程](https://arxiv.org/abs/2001.04385)，因为它们使我们能够将科学知识与深度学习结合起来。这基本上将两种方法融合在一起。
- en: How to combine differential equation layers with other deep learning layers.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将微分方程层与其他深度学习层结合。
- en: 'Model discovery: Can we recover the actual model equations from data? This
    uses tools like [SINDy](https://www.pnas.org/doi/10.1073/pnas.1906995116) to extract
    the model equations from data.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型发现：我们能否从数据中恢复实际的模型方程？这使用[SINDy](https://www.pnas.org/doi/10.1073/pnas.1906995116)等工具从数据中提取模型方程。
- en: MLOps tools for managing the training of these models. This includes tools like
    [MLFlow](https://mlflow.org/) , [Weights and Biases](https://wandb.ai/home) ,
    and [Tensorboard](https://pytorch.org/docs/stable/tensorboard.html) .
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于管理这些模型训练的MLOps工具。这包括[MLFlow](https://mlflow.org/)、[Weights and Biases](https://wandb.ai/home)和[Tensorboard](https://pytorch.org/docs/stable/tensorboard.html)等工具。
- en: Anything else I hear back about from you!
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何其他我从你那里听到的反馈！
- en: If you liked this post, be sure to follow me and connect on l[inked-in](https://www.linkedin.com/in/kevin-hannay-7a6049198/).
    All images unless otherwise noted are by the author.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，确保关注我并在[lLinked-in](https://www.linkedin.com/in/kevin-hannay-7a6049198/)上与我联系。除非另有说明，否则所有图片均由作者提供。
