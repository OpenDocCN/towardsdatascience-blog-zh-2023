- en: How to Use Chat-GPT and Python to Build a Knowledge Graph in Neo4j Based on
    Your Own Articles
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用Chat-GPT和Python在Neo4j中基于你自己的文章构建知识图谱
- en: 原文：[https://towardsdatascience.com/how-to-use-chat-gpt-and-python-to-build-a-knowledge-graph-in-neo4j-based-on-your-own-articles-c622bc4e2eaa](https://towardsdatascience.com/how-to-use-chat-gpt-and-python-to-build-a-knowledge-graph-in-neo4j-based-on-your-own-articles-c622bc4e2eaa)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-use-chat-gpt-and-python-to-build-a-knowledge-graph-in-neo4j-based-on-your-own-articles-c622bc4e2eaa](https://towardsdatascience.com/how-to-use-chat-gpt-and-python-to-build-a-knowledge-graph-in-neo4j-based-on-your-own-articles-c622bc4e2eaa)
- en: A graph containing structured knowledge from more than 120 articles on mathematics
    and data science
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个包含120多篇关于数学和数据科学的文章结构化知识的图形
- en: '[](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)[![Kasper
    Müller](../Images/336cad595544ba68e3376a038d44df62.png)](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)
    [Kasper Müller](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)[![Kasper
    Müller](../Images/336cad595544ba68e3376a038d44df62.png)](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)
    [Kasper Müller](https://kaspermuller.medium.com/?source=post_page-----c622bc4e2eaa--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)
    ·8 min read·Aug 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c622bc4e2eaa--------------------------------)
    ·8分钟阅读·2023年8月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c43ea8409a8a04894916f41afe7075dc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c43ea8409a8a04894916f41afe7075dc.png)'
- en: Screenshot by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: In this article, I will show how you can structure and explore the content of
    your own articles using graph technology and some programming.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将展示如何利用图形技术和一些编程来结构化和探索你自己的文章内容。
- en: The idea of using NLP techniques for structuring unstructured data is not new,
    however, the latest progress in LLMs (Large Language Models) has sparked countless
    opportunities for doing just that. The accessibility for amateurs through the
    booming technology Chat-GPT has created a lot of attention towards LLMs and generator
    models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NLP技术来结构化非结构化数据的想法并不新鲜，然而，最新的大型语言模型（LLMs）的进展激发了无数机会。Chat-GPT的普及技术使得业余爱好者对LLMs和生成模型产生了很多关注。
- en: In fact, generative AI is on the agenda in many companies already!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，生成式AI已经成为许多公司议程中的一部分！
- en: The way we will work with the technology in this article is through the programming
    language Python using OpenAI’s developer API. We will work on data from Medium
    (meta huh?) and build a knowledge graph. That may sound like a mouthful, but it
    is actually surprisingly easy to get started with.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将通过编程语言Python使用OpenAI的开发者API来处理技术。我们将处理来自Medium的数据（哈哈，元数据？），并构建一个知识图谱。听起来可能有些复杂，但实际上开始时非常简单。
- en: Getting started
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始
- en: First things first. The plan of attack is the following.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，攻击计划如下。
- en: Get the API to work and access it through Python.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使API正常工作并通过Python访问它。
- en: Use a sample text to do prompt engineering ensuring that the GPT-4 model understands
    what you want from it.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用示例文本进行提示工程，以确保GPT-4模型理解你的需求。
- en: Download your articles from Medium (you can of course use other pieces of text
    if you want) and pre-process the data.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Medium下载你的文章（如果你愿意，也可以使用其他文本），并对数据进行预处理。
- en: Extract and collect output from Chat-GPT.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取和收集Chat-GPT的输出。
- en: Post-process the output from Chat-GPT
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对Chat-GPT的输出进行后处理
- en: Write code to structure the data further into a graph using the Cypher query
    language.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写代码使用Cypher查询语言进一步将数据结构化为图形。
- en: Play around with your new best friend and explore your articles.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 玩弄你的新伙伴并探索你的文章。
- en: Without further ado, let’s get started by quickly setting up the basic tech.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 话不多说，让我们通过快速设置基础技术来开始吧。
- en: Setup
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置
- en: We need to have the programming language Python and the graph database Neo4j
    installed on our local computer.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在本地计算机上安装编程语言Python和图形数据库Neo4j。
- en: The first thing to do is to ensure that you have a plus account at OpenAI so
    that you can use GPT-4\. The second thing you should make sure of is that you
    have [signed up](https://platform.openai.com/account/billing/overview) for the
    API use. Once that is in place, you need to generate an [API key](https://platform.openai.com/account/api-keys).
    Then you need to *pip install openai*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要确保你在 OpenAI 有一个付费账户，以便可以使用 GPT-4。其次，你应该确保你已[注册](https://platform.openai.com/account/billing/overview)
    API 使用。一旦准备好，你需要生成一个[API 密钥](https://platform.openai.com/account/api-keys)。然后你需要
    *pip install openai*。
- en: Before connecting to ChatGPT, let’s go to the browser and try to find the right
    way to ask about this task. This is called prompt engineering and it is very important
    to get right. By trying out different ways to ask using a random article of mine
    as an example, I found that the right way to ask was to provide a detailed and
    guided prescript before giving it the actual text.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在连接 ChatGPT 之前，让我们去浏览器中尝试找到询问此任务的正确方式。这被称为提示工程，正确处理非常重要。通过使用我的一篇随机文章作为示例，尝试不同的询问方式，我发现正确的方法是提供一个详细且有指导性的预设，然后再给出实际文本。
- en: 'I ended up with the following prescript:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我最终得到了以下的预设：
- en: '![](../Images/3cd99f403e3ce9c9fa0eb1603461a774.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cd99f403e3ce9c9fa0eb1603461a774.png)'
- en: Screenshot by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: 'As an example, I gave it a snippet from the article about the Gamma function
    that I wrote a long time ago:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，我给它了一段关于 Gamma 函数的文章摘录，这篇文章是我很久以前写的：
- en: '![](../Images/6140a54366f5d59cf2039d4ff217bca2.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6140a54366f5d59cf2039d4ff217bca2.png)'
- en: Screenshot by Author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: 'What it came up with was the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 它得出的结果是：
- en: '![](../Images/890fb9f93a7201446ed9faf280133be8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/890fb9f93a7201446ed9faf280133be8.png)'
- en: Screenshot by Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: Even though it clearly didn’t really understand the task, it did okay, especially
    with the format. However, sometimes it creates duplicates, and note that it hallucinated
    some entities and relationships even though we asked it not to. Annoying disobedient
    machine! We will deal with this later.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它显然并没有真正理解任务，但它做得还不错，特别是在格式上。然而，有时它会创建重复项，并且注意到它有时会虚构一些实体和关系，尽管我们要求它不要这样做。恼人的不听话的机器！我们稍后会处理这个问题。
- en: For future uses, we will store this prescript in a Python file called *prompt_input.py*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将来使用，我们将把这个预设存储在一个名为 *prompt_input.py* 的 Python 文件中。
- en: Now that the basic setup is in place, let’s test if it actually works.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在基础设置已经就绪，让我们测试一下它是否真的有效。
- en: If the code is only for you and only on your local machine, you can hardcode
    the API key in the Python file, otherwise you can set it as an environment variable
    or place it in a config file that you don’t push anywhere!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果代码仅供你自己使用，并且只在本地机器上，你可以将 API 密钥硬编码到 Python 文件中，否则，你可以将其设置为环境变量或放在一个你不会推送的配置文件中！
- en: Let’s test if this setup works. We create a file called *connect.py* containing
    the basic connection to ChatGPT from Python.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下这个设置是否有效。我们创建一个名为 *connect.py* 的文件，包含从 Python 连接 ChatGPT 的基本代码。
- en: We verify that this works!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们验证这个是否有效！
- en: Data
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: I need to fetch articles from my Medium account. At the time of writing, I have
    published 123 articles, but the download feature from Medium returns 259 files!
    This is because it classifies comments and drafts as posts too. We only want the
    published articles, but that is not the only problem. The files are HTML files!
    That is of course great if you want to read them in a browser, but not if you
    want to work with the pure text.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要从我的 Medium 账户中提取文章。在写作时，我已经发布了 123 篇文章，但从 Medium 下载功能返回了 259 个文件！这是因为它也将评论和草稿分类为帖子。我们只想要已发布的文章，但这还不是唯一的问题。这些文件是
    HTML 文件！如果你想在浏览器中阅读当然没问题，但如果你想处理纯文本就不太适用了。
- en: Well, nice try, Medium, but that can’t stop a data scientist armed with programming
    languages and dirty tricks!
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 好吧，中等水平，你做得不错，但这不能阻止一个装备了编程语言和各种窍门的数据科学家！
- en: We also note that the file names of the downloaded files are quite messy. A
    standard name is for example “*2020–12–11_The-Most-Beautiful-Equation-in-the-World-5ab6e49c363.html*”
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到下载文件的文件名相当混乱。一个标准名称的例子是“*2020–12–11_The-Most-Beautiful-Equation-in-the-World-5ab6e49c363.html*”
- en: Let’s store these files in a folder called *raw*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些文件存储在一个名为 *raw* 的文件夹中。
- en: 'We write a small module called *extract_text_from_html.py* with some functionality
    to extract the text from these files:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写一个名为 *extract_text_from_html.py* 的小模块，功能是从这些文件中提取文本：
- en: 'Before we can use it to actually get results from ChatGPT, we need to be able
    to split the text up into batches. The reason is that GPT-4 has a token limit.
    Luckily, this is easy. In a file called *preprocess.py*, we write:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够实际从 ChatGPT 获取结果之前，我们需要能够将文本拆分成批次。原因是 GPT-4 有一个令牌限制。幸运的是，这很简单。在名为*preprocess.py*的文件中，我们编写：
- en: Now we are ready to actually get some data from ChatGPT.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备实际从 ChatGPT 获取一些数据。
- en: We write a file called *process_articels.py* where **loop** through the articles,
    retrieve the **titles** from the frightening file names, extract the actual **text**
    from the HTML files, run each batch of text through **ChatGPT**, **collect** the
    results from the files, and **save** the outputs from the model in new files that
    we store in a folder called *data*. We also save the actual texts in a folder
    called **cleaned** for later use.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写一个名为*process_articels.py*的文件，在其中**循环**处理文章，从令人恐惧的文件名中检索**标题**，从 HTML 文件中提取实际的**文本**，将每批文本通过**ChatGPT**处理，从文件中**收集**结果，并将模型的输出**保存**到一个名为*data*的文件夹中。我们还将实际的文本保存在一个名为**cleaned**的文件夹中，以便以后使用。
- en: Phew!! that was a lot. But actually, the code is simple because we have already
    done some of the work in other files.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 呼！！那真是一大堆工作。但实际上，代码很简单，因为我们已经在其他文件中完成了一些工作。
- en: The above code might take a while to execute as the GPT-4 model is relatively
    slow compared to the other sub-performing models available. We make sure to use
    a cashing setup so that if the program crashes, then we don’t start all over,
    we just start where we left off.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码可能需要一段时间来执行，因为 GPT-4 模型相对较慢，与其他表现较差的模型相比。我们确保使用缓存设置，这样如果程序崩溃，我们不会从头开始，而是从中断的地方继续。
- en: Now (several hours in agony later) we have a structured dataset of results from
    GPT-4\. Perfect. Now we “just” need to build a graph from it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在（经过几个小时的痛苦之后），我们有了一个结构化的 GPT-4 结果数据集。完美。现在我们“只”需要从中构建图谱。
- en: Building the knowledge graph
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建知识图谱
- en: We will merge the preprocess and graph creation process into one single function.
    This is normally not very advisable (separation of concerns and all), but because
    we need to look at a “relationship and entity” — level in the preprocessing anyway,
    we might as well create the nodes and relationships in the graph while we have
    our hands dirty.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将预处理和图谱创建过程合并为一个单独的函数。这通常不是很明智（关注点分离），但由于我们在预处理阶段需要查看“关系和实体”层级，我们可以在双手沾满污垢时创建图谱中的节点和关系。
- en: Let us create a small API containing a driver so we can talk to our graph.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个小型 API，包含一个驱动程序，以便我们可以与图形进行交互。
- en: We need to **loop** over the results, make sure that the entities are **not**
    too long, **clean** the results, and define the **nodes** and **relationships**
    in the output from the gpt-model, we **don’t** want to call the graph with the
    same query multiple times, we want the entities to be connected to the original
    **articles**, and then we need to make sure that each entity and relationship
    cooked up by Chat-GPT is actually **in** the text so we don’t build a graph of
    **machine dreams**!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要**循环**处理结果，确保实体**不**太长，**清理**结果，并定义 gpt 模型输出中的**节点**和**关系**，我们**不**希望用相同的查询多次调用图形，我们希望实体与原始**文章**相关联，然后我们需要确保
    Chat-GPT 提出的每个实体和关系实际**存在**于文本中，以免我们构建一个**机器梦**的图谱！
- en: The last of the above requirements is to raise the probability that we can trust
    the graph even though it is not fool proof if you think about it.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 上述要求的最后一点是提高我们信任图形的概率，即使它不是万无一失的，考虑到这一点。
- en: 'No biggie! We write the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 没问题！我们写下以下内容：
- en: There are of course many ways to create a schema for a knowledge graph. It is
    not always easy to see what should be nodes and what should be relationships but
    since we don’t want relationships between relationships, we went for the above.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有很多方法可以为知识图谱创建模式。不是总能容易看出什么应该是节点，什么应该是关系，但由于我们不希望关系之间有关系，所以我们选择了上述方法。
- en: Moreover, I chose a minimalistic approach for this article. Normally, we would
    enrich the nodes and relationships with more properties.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我为这篇文章选择了简约的方法。通常，我们会用更多的属性来丰富节点和关系。
- en: Now we just need a main point of entry.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需要一个主要入口点。
- en: That is it. Now we have ourselves a knowledge graph containing information from
    my articles on Medium. In fact, we have about 2000 nodes and 4500 relationships.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。现在我们有了一个包含 Medium 上我文章信息的知识图谱。事实上，我们有大约 2000 个节点和 4500 个关系。
- en: Exploring the graph
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索图谱
- en: So what can we do with this thing? What should we ask of it?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们可以用这个做什么？我们应该问它什么？
- en: 'Let’s try to find out how many articles the different persons were found in.
    We have the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试找出不同的人出现在多少篇文章中。我们有如下结果：
- en: '![](../Images/3f012b4855bea74d20b5a06362b50949.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f012b4855bea74d20b5a06362b50949.png)'
- en: Screenshot by author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: Not surprisingly, Euler tops the list but I am surprised that Ramanujan and
    Newton were found in 4 of my articles. I could of course find the titles of the
    articles if I wanted but let’s move on. Okay, so this was fun but you don’t need
    a graph to figure this out.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，欧拉排在榜首，但我惊讶于拉马努jan和牛顿出现在我的4篇文章中。当然，我可以找到这些文章的标题，但让我们继续。好吧，这很有趣，但你不需要一个图表就能搞清楚这一点。
- en: Let’s try something else. Let’s see how many articles mention both Riemann and
    Euler.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再试试别的。让我们看看有多少篇文章同时提到瑞曼和欧拉。
- en: '![](../Images/3f0ef614507164a3ad4b347c3cda3e10.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f0ef614507164a3ad4b347c3cda3e10.png)'
- en: Screenshot by author
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: Let’s see how many of Euler’s discoveries my articles mention.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我的文章提到了多少欧拉的发现。
- en: '![](../Images/504694e28a228ec117657e1761a49456.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/504694e28a228ec117657e1761a49456.png)'
- en: Screenshot by author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: Hmm no Euler line? I have to write an article about that.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，没有欧拉线？我得写一篇关于这个的文章。
- en: Let’s find out how many articles shared some mathematical keyword with the article
    *Group Theory*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们找出有多少篇文章与文章*群论*共享了一些数学关键词。
- en: '![](../Images/e817643569064a6b1e3bc802326559dd.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e817643569064a6b1e3bc802326559dd.png)'
- en: Screenshot by author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: The result is displayed here as 27 other articles connected by the non-orange
    nodes in the above image. Even though this is merely a toy example, one could
    imagine how this could just as well show how business-related documents are related
    by various sensitive keywords important within some disciplines such as GDPR or
    Audit.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在这里，与上图中非橙色节点连接的27篇其他文章。尽管这只是一个玩具示例，但可以想象它同样可以显示业务相关文档如何通过一些在某些学科（如GDPR或审计）中重要的敏感关键词相互关联。
- en: Takeaways
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收获
- en: Obviously, this work should be seen as what we call a “proof of concept”. We
    can’t use my articles for anything really, but if this had been texts from a company
    containing information about their customers and employees from emails to word
    files, pdfs, and so on, this could be used to map out how customers are related
    and which employees work closely together.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这项工作应该被视为我们所谓的“概念验证”。我们不能真正地利用我的文章，但如果这些文本来自一个公司，包含关于他们的客户和员工的信息，从电子邮件到Word文档、PDF等等，这可以用来绘制客户之间的关系以及哪些员工密切合作。
- en: This in turn would give us a 360 view of how data flows through the organization
    as a whole, who is the most important person for a specific type of information
    flow, who is the right one to reach out to if you want to know about a specific
    topic or document, the client we contacted in our department was once contacted
    by another department, etc.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们能够360度了解数据如何在整个组织中流动，谁是特定信息流的最重要人物，谁是了解特定主题或文档的合适人选，我们部门联系的客户曾被另一个部门联系过，等等。
- en: Extremely valuable information. Of course, we can’t use ChatGPT for this because
    we don’t know what happens to the data we send it. Therefore it is not a good
    idea to ask it about sensitive or business-critical information. What we need
    to do is to download another LLM (large language model) that only lives on our
    laptop. A local LLM. We can even fine-tune it on our own data. This is done as
    we speak by many companies already for building chatbots, assistants, and so on.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 极其宝贵的信息。当然，我们不能用ChatGPT来做这个，因为我们不知道我们发送的数据会发生什么。因此，询问它关于敏感或业务关键的信息不是一个好主意。我们需要做的是下载另一个仅存在于我们笔记本电脑上的LLM（大型语言模型）。一个本地LLM。我们甚至可以在自己的数据上进行微调。目前许多公司已经在进行这种操作，用于构建聊天机器人、助手等。
- en: But using it to build a knowledge graph over your unstructured data is next-level
    if you ask me and I think I have shown that it is more than doable!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你问我，用它来构建一个关于你非结构化数据的知识图谱是更高层次的工作，我认为我已经展示了这完全是可行的！
- en: If your company wants to know how we can use your data to weave a spiderweb
    of possibilities for your business, then please reach out to [me](https://www.linkedin.com/in/kasper-m%C3%BCller-96ba95169/)
    or my colleague [Kenneth Nielsen](https://www.linkedin.com/in/kenneth-h-m-nielsen-phd/).
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你的公司想知道我们如何利用你的数据为你的业务编织可能性网络，请联系[我](https://www.linkedin.com/in/kasper-m%C3%BCller-96ba95169/)或我的同事[Kenneth
    Nielsen](https://www.linkedin.com/in/kenneth-h-m-nielsen-phd/)。
- en: Thank you for reading.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你的阅读。
- en: '*If you like to read articles like this one on Medium, you can* [*get a membership*](https://kaspermuller.medium.com/membership)
    *for full access. To join the community, simply click* [*here*](https://kaspermuller.medium.com/membership)*.*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢在 Medium 上阅读像这样的一些文章，你可以* [*获取会员资格*](https://kaspermuller.medium.com/membership)
    *以获得全部访问权限。要加入社区，只需点击* [*这里*](https://kaspermuller.medium.com/membership)*。*'
