# 深入探讨统计期望的科学

> 原文：[https://towardsdatascience.com/a-deep-dive-into-the-science-of-statistical-expectation-9dc0f80bd26](https://towardsdatascience.com/a-deep-dive-into-the-science-of-statistical-expectation-9dc0f80bd26)

![](../Images/3eff4d617150c08e1c79642593c4821e.png)

[多佛白崖](https://commons.wikimedia.org/wiki/File:White_Cliffs_of_Dover_02.JPG) ([CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/deed.en))

## 我们如何形成对某件事的期望，这种期望的含义，以及产生这种含义的数学原理。

[](https://timeseriesreasoning.medium.com/?source=post_page-----9dc0f80bd26--------------------------------)[![Sachin Date](../Images/bd023298b414caf88f79b00ef032d065.png)](https://timeseriesreasoning.medium.com/?source=post_page-----9dc0f80bd26--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9dc0f80bd26--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9dc0f80bd26--------------------------------) [Sachin Date](https://timeseriesreasoning.medium.com/?source=post_page-----9dc0f80bd26--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----9dc0f80bd26--------------------------------) ·29分钟阅读·2023年6月17日

--

这是1988年的夏天，我第一次踏上了船。这是一艘从英格兰多佛出发、驶往法国加来乘客渡轮。我当时并不知道，但我正赶上了渡轮穿越英吉利海峡的黄金时代的尾声。这正是在廉价航空公司和英吉利海峡隧道[几乎终结](https://journals.openedition.org/rhcf/2452)我仍认为的最佳旅行方式之前。

我曾期望渡轮看起来像我在儿童书籍中看到的许多船只之一。然而，实际看到的是一座异常庞大、闪闪发光的白色摩天大楼，带有小小的方形窗户。而且，这座摩天大楼似乎由于某种令人困惑的原因横着放置。从码头的视角来看，我看不到船体和烟囱。我看到的只是它长而平坦、带窗户的外观。我看到的是一座横向的摩天大楼。

![](../Images/a46e80475dce15950d57dcd307629a60.png)

照片由[Martin](https://unsplash.com/es/@martinostsee?utm_source=medium&utm_medium=referral)提供，[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

回想起来，用统计学的语言来重新审视我的经历是颇为有趣的。我的大脑从我看到的船只图片的数据样本中计算出了**期望的渡轮形状**。但我的样本对于整体而言毫无代表性，这使得样本均值同样不代表总体均值。我是在用一个严重偏颇的样本均值来解码现实。

# 晕船

这次跨越英吉利海峡的旅行也是我第一次晕船。人们说，当你晕船时，应该走到甲板上，呼吸新鲜凉爽的海风，盯着地平线。对我来说唯一有效的办法是坐下来，闭上眼睛，喝着我最喜欢的汽水，直到我的思绪慢慢从搅动我胃部的痛苦恶心中脱离。顺便说一下，我*并没有*慢慢脱离本文的主题。我会很快进入统计学的内容。在此期间，让我解释一下你为什么会在船上生病的原因，以便你能看到与当前主题的联系。

在你大多数的生活日子里，你不会在船上摇晃。在陆地上，当你将身体倾斜到一侧时，你的内耳和身体的每一块肌肉都会告诉你的大脑你在倾斜。是的，你的肌肉也在和你的大脑沟通！你的眼睛热切地支持所有这些反馈，你也就安然无恙。然而在船上，眼睛和耳朵之间这段和谐的契约被打破了。

在船上，当海洋使船倾斜、摇晃、摆动、滚动、漂移、起伏或其他任何情况时，你的眼睛告诉大脑的东西可能会与肌肉和内耳告诉大脑的东西大相径庭。你的内耳可能会说：“小心！你在向左倾斜。你应该调整你对世界的**预期**。”但你的眼睛则说：“胡说！我坐着的桌子在我看来是完全水平的，桌子上的食物盘也是如此。墙上的那幅呐喊的画看起来也很直很水平。*不要*听内耳的。”

![](../Images/80c9fa9c4be9e7621e99eddee08fe456.png)

[呐喊](https://commons.wikimedia.org/wiki/File:Edvard_Munch_-_The_Scream_-_Google_Art_Project.jpg)（公共领域）

你的眼睛可能向大脑报告更令人困惑的事情，比如“是的，你确实在倾斜。但这个倾斜的程度或速度并不像你那过于热心的内耳可能让你相信的那样严重。”

**就好像你的眼睛和内耳各自要求你的大脑创建两个不同的预期，关于你的世界将如何改变**。你的大脑显然做不到这一点。它感到困惑。而由于进化的原因，你的胃表达出强烈的欲望想要排空其内容。

让我们尝试通过统计推理的框架来解释这个令人痛苦的情况。这次，我们将使用一点数学来帮助解释。

## 你应该预期会晕船吗？深入统计学研究晕船问题

让我们定义一个 [**随机变量**](https://medium.com/towards-data-science/the-aspiring-statisticans-introduction-to-random-variables-7b26a057a89a) **X**，它有两个取值：0 和 1。如果你眼睛的信号**不**与内耳的信号一致，则**X**为0。如果信号**一致**，则**X**为1：

![](../Images/f74a9705ed2619d01a6d72cecee0ebd4.png)

随机变量 **X** （作者提供的图片）

理论上，**X** 的每个值都应该具有一定的概率 P(**X**=x)。概率 P(**X**=0) 和 P(**X**=1) 共同构成了 **X** 的 [**概率质量函数**](https://medium.com/towards-data-science/the-aspiring-statisticans-introduction-to-random-variables-7b26a057a89a)。我们如下表述：

![](../Images/92aeea6f530ff74e1464d4a901681056.png)

X 的概率质量函数（图片来源于作者）

在绝大多数情况下，你的眼睛所接收到的信号会与内耳的信号一致。因此，p 几乎等于 1，(1 — p) 是一个非常非常小的数字。

让我们对 (1 — p) 的值做一个大胆的猜测。我们将使用以下推理来得出一个估计值：根据联合国的数据，2023 年出生时人类的平均预期寿命大约是 [73 年](https://population.un.org/wpp/Graphs/Probabilistic/EX/BothSexes/900)。换算成秒，这大约是 2302128000 秒（约 23 亿）。假设一个普通人在其一生中经历 16 小时的晕船，即 28800 秒。现在，让我们不要对这 16 小时斤斤计较。这只是一个大胆的猜测，记住吗？所以，28800 秒给出了 (1 — p) 的一个工作估计值为 28000/2302128000 = 0.0000121626，而 p=(1 —0.0000121626) = 0.9999878374。因此，在一个普通人的一生中的任何一秒中，他们经历晕船的**无条件概率**仅为 0.0000121626。

根据这些概率，我们将进行一个持续 10 亿秒的模拟，模拟一个名叫 John Doe 的人的一生。这大约是 JD 模拟寿命的 50%。JD 更喜欢大部分时间待在坚实的地面上。他偶尔会进行海上巡游，并经常感到晕船。我们将模拟 JD 是否会在模拟的每一秒中经历晕船。为此，我们将进行 10 亿次[**伯努利随机变量**](https://en.wikipedia.org/wiki/Bernoulli_distribution)的试验，其概率为 p 和 (1 — p)。每次试验的结果将是 1（如果 JD 晕船），或者 0（如果 JD 不晕船）。进行实验后，我们将得到 10 亿个结果。你也可以使用以下 Python 代码运行这个模拟：

[PRE0]

让我们计算结果为 1（即未晕船）和 0（即晕船）的次数：

[PRE1]

我们将打印这些计数。当我打印它们时，我得到以下值。你每次运行模拟时可能会得到稍有不同的结果：

[PRE2]

现在我们可以计算 JD 是否**预计**在这些 10 亿秒中的任何一秒中感到晕船。

**期望值是两个可能结果的加权平均**：即 1 和 0，加权是两个结果的频率。因此，让我们进行这个计算：

![](../Images/c3267f02e1258237aa5e3bd71a672581.png)

结果的期望值（图片来源于作者）

期望结果是 0.999987794，这实际上接近 1.0。数学告诉我们，在 JD 模拟的 10 亿秒中的任何随机选择的一秒钟内，JD 应该*不会*预期感到晕船。数据似乎几乎不允许这种情况发生。

现在让我们对上述公式稍作调整。我们将按如下方式重新排列它：

![](../Images/4a0311fd355fe26c31fc51889a96f642.png)

结果的期望值（图像由作者提供）

当以这种方式重新排列时，我们看到一个令人愉快的子结构逐渐显现出来。两个括号中的比率表示与两个结果相关的概率，具体来说是从我们 10 亿强数据样本中得出的**样本概率**，而不是**总体概率**。它们是**样本概率**，因为我们使用了来自我们 10 亿强数据样本的数据进行计算。话虽如此，0.999987794 和 0.000012206 这两个值应与总体值 p 和 (1 — p) 非常接近。

通过插入概率，我们可以将期望公式重新表述如下：

![](../Images/1cd96f7bb541dc8654287b7d1322f435.png)

**X** 的期望值（图像由作者提供）

注意到我们使用了期望的符号，即 E()。由于**X** 是一个 Bernoulli(p) 随机变量，上述公式还告诉我们如何计算**Bernoulli 随机变量的期望值**。**X** ~ Bernoulli(p) 的期望值就是 p。

# 关于样本均值、总体均值，以及一个让你听起来很酷的词

E(**X**) 也被称为**总体均值**，用 μ 表示，因为它使用了概率 p 和 (1 — p)，这些是**总体**层面的概率值。这些是你如果能访问到全部数据总体时将观察到的‘真实’概率，但实际上几乎不可能做到。统计学家在提到这些和类似的测量时使用了“**渐近**”这个词。它们被称为渐近的，因为它们的意义仅在样本大小趋近于无穷大或整个总体的大小时才具有显著性。现在问题来了：我认为人们就是喜欢说‘渐近’。我也认为这是掩盖一个麻烦的真相，即你永远无法精确测量任何事物的值。

从积极的一面来看，无法接触到总体是统计科学领域的‘伟大平衡者’。无论你是新近毕业的学生还是诺贝尔经济学奖得主，这扇通往‘总体’的门对你始终紧闭。作为统计学家，你只能使用样本来工作，你必须默默忍受其缺陷。但情况实际上并没有听起来那么糟糕。想象一下，如果你能知道所有事物的确切值会发生什么。如果你可以接触到总体。如果你能够精确地计算均值、中位数和方差。如果你能够以精确的预测未来。那时就不再需要估计任何东西。统计学的许多分支将会消失。世界将需要减少成千上万的*统计学家*，更不用说数据科学家了。想象一下对失业、世界经济和世界和平的影响……

但我岔开话题了。我的观点是，如果**X**是伯努利分布（p），那么要计算E(**X**)，你不能使用实际的p和（1 — p）值。相反，你必须使用p和（1 — p）的**估计值**。这些估计值，你将使用一个适中规模的数据样本来计算，而不是整个总体——没有机会做到这一点。因此，我很遗憾地告诉你，你所能做的最好的是得到随机变量**X**的**期望值的估计**。按照惯例，我们将p的估计值表示为p_hat（带小帽的p），将估计的期望值表示为E_cap(**X**）。

![](../Images/8085cd782b6db1f0f4937721685cef46.png)

X的估计期望（图源作者）

由于E_cap(**X**)使用**样本概率**，因此称为**样本均值**。它用x̄或‘x bar’表示，就是在x上方加一条横杠。

**总体均值**和**样本均值**是统计学中的蝙蝠侠和罗宾。

*统计学的大部分内容都致力于计算样本均值，并将样本均值作为总体均值的估计值。*

这就是它——用一句话概括了统计学的广阔领域。😉

# 深入期望的深渊

我们对伯努利随机变量的思维实验在某种程度上揭示了期望的本质。**伯努利变量**是**二元变量**，它的操作非常简单。然而，我们经常使用的随机变量可能取多种不同的值。幸运的是，我们可以轻松地将期望的概念和公式扩展到多值随机变量。让我们通过另一个例子来说明。

## 多值离散随机变量的期望值

下表显示了205辆汽车的数据子集。具体来说，表中展示了每辆车引擎中的气缸数量。

![](../Images/a7430cfb4cc664b136f8df6f90671c86.png)

汽车的气缸数（数据来源：[UCI机器学习数据集库](https://archive-beta.ics.uci.edu/dataset/10/automobile)，许可证：CC BY 4.0）（图片来自作者）

设**Y**为一个随机变量，包含了从该数据集中随机选择的车辆的气缸数。我们知道数据集中包含气缸数为2、3、4、5、6、8或12的车辆。因此，**Y**的范围是集合E=[2, 3, 4, 5, 6, 8, 12]。

我们将数据行按气缸数分组。下表显示了分组计数。最后一列表示每个计数的**样本**出现概率。该概率是通过将组大小除以205计算得出的：

![](../Images/f6073ac7c1be9bcda8410805d6ff14f9.png)

气缸数的频率分布

使用样本概率，我们可以构建**概率质量函数** P(**Y**) 来表示**Y**。如果我们将其与**Y**进行绘图，效果如下：

![](../Images/98bd65ac868aea5d6e05c3d2a22cc208.png)

**Y**的PMF（图片来自作者）

如果一辆随机选择的车辆在你面前驶过，你会**期望**它的气缸数是多少？仅通过查看PMF，你会想猜测4个气缸。然而，这个猜测背后有严谨的数学支持。类似于伯努利**X**，你可以按如下方式计算**Y**的期望值：

![](../Images/35afce78379cd7db6a6866dbcd56a407.png)

**Y**的期望值（图片来自作者）

如果你计算这个和，它的结果是4.38049，这与你猜测的4个气缸非常接近。

由于**Y**的范围是集合**E=**[2,3,4,5,6,8,12]，我们可以将此和式表示为对E的求和，如下所示：

![](../Images/2d2d71058987c8bbb924c7e4703cd814.png)

离散随机变量**Y**的期望值公式（图片来自作者）

你可以使用上述公式来计算任何[**离散随机变量**](https://medium.com/towards-data-science/the-aspiring-statisticans-introduction-to-random-variables-7b26a057a89a)的期望值，其范围是集合**E**。

## 连续随机变量的期望值

如果你处理的是连续随机变量，情况会有所不同，如下所述。

让我们回到我们的车辆数据集。具体来说，让我们查看车辆的长度：

![](../Images/cb6db24d821ca585035b737ca9ab9a18.png)

汽车长度（数据来源：[UCI机器学习数据集库](https://archive-beta.ics.uci.edu/dataset/10/automobile)，许可证：CC BY 4.0）（图片来自作者）

假设**Z**表示随机选取的车辆的长度（单位：英寸）。**Z**的范围不再是离散的值集合，而是实数集合**ℝ**的一个子集。由于长度总是正数，因此它是所有正实数的集合，记作**ℝ**>0。

由于所有正实数的集合具有（不可数）无限多个值，因此将概率分配给**Z**的某个特定值是没有意义的。如果你不相信我，可以考虑一个简单的思想实验：想象一下给**Z**的每一个可能值分配一个正概率。你会发现这些概率的和会趋向于无穷大，这显然是不合理的。因此，概率P(**Z**=z)根本不存在。相反，你必须使用**概率密度函数** f(**Z**=z)，它为不同的**Z**值分配一个**概率密度**。

我们之前讨论了如何使用概率质量函数计算离散随机变量的期望值。

![](../Images/2d2d71058987c8bbb924c7e4703cd814.png)

离散随机变量**Y**期望值的公式（图片由作者提供）

我们可以将这个公式用于连续随机变量吗？答案是可以的。要了解如何进行，想象一下你拿着一台电子显微镜。

拿起那台显微镜，聚焦在**Z**的范围内，即所有正实数的集合（**ℝ**>0）。现在，放大到一个极其微小的区间(z, z+δz]。在这个微观尺度下，你可能会观察到，*从实际角度来看*（现在，*这*不是一个有用的术语），概率密度 f(**Z**=z) 在 δz 上是常量。因此，f(**Z**=z)和 δz 的乘积可以近似为随机选择的车辆长度落在开闭区间(z, z+δz]内的**概率**。

拥有这个近似概率后，你可以将**Z**的期望值近似如下：

![](../Images/0ba4c1d7a434b139c2b79d518fc16508.png)

当**Z**是连续的时，E(**Z**)的近似评估（图片由作者提供）

注意我们是如何从E(**Y**)的公式跳跃到这个近似公式的。要从E(**Y**)得到E(**Z**)，我们做了以下工作：

+   我们将离散的y_i替换为实值的z_i。

+   我们将**Y**的PMF P(**Y**=y)替换为**Z**的近似概率 f(**Z**=z)δz，它表示在微观区间(z, z+δz]中找到z的概率。

+   我们不再对**E**的离散有限范围**Y**求和，而是对**ℝ**>0的连续无限范围**Z**求和。

+   最后，我们将等号替换为近似符号。罪行就在这里。我们作弊了。我们偷偷使用了概率 f(**Z**=z)δz，它是对精确概率 P(**Z**=z) 的近似。我们作弊的原因是，精确概率 P(**Z**=z) 对于连续**Z**而言是不存在的。我们必须为这个罪过做出补偿，这正是我们接下来要做的。

我们现在进行我们的绝技，我们的拿手好戏，并在这样做中救赎自己。

由于 **ℝ**>0 是正实数的集合，在 **ℝ**>0 中有无限多个大小为 δz 的微小区间。因此，对 **ℝ**>0 的求和是对无限多个项的求和。这一事实为我们提供了一个绝佳的机会，可以用*精确积分*来替代近似求和，如下所示：

![](../Images/60118e6dce3a418709f15c705a54055d.png)

**Z** 的期望值（作者提供的图片）

一般来说，如果 **Z** 的范围是实数区间 [a, b]，我们将定积分的上下限设置为 a 和 b，而不是 0 和 ∞。

如果你知道 **Z** 的概率密度函数（PDF），并且在 [a, b] 区间内 z 乘以 f(**Z**=z) 的积分存在，你将解出上述积分，从而得到 **E**(**Z**)。

如果 **Z** 在区间 [a, b] 上均匀分布，其 PDF 如下：

![](../Images/5248effc78a35c7b8d92cdafa7e1c75e.png)

PDF of Z ~ Uniform(a, b)（作者提供的图片）

如果你设置 a=1 和 b=5，

f(**Z**=z) = 1/(5–1) = 0.25。

概率密度在 **Z**=1 到 **Z**=5 的区间内为常数 0.25，而其他地方为零。**Z** 的 PDF 如下所示：

![](../Images/253cf2bb7bbae91430351e189bcfa41f.png)

PDF of Z ~ Uniform(1, 5)（作者提供的图片）

基本上，它是从 (1,0.25) 到 (5,0.25) 的一条连续平坦的水平线，其他地方的值为零。

一般来说，如果 **Z** 的概率密度在区间 [a, b] 上是均匀分布的，**Z** 的 PDF 在 [a, b] 上是 1/(b-a)，其他地方为零。你可以使用以下过程计算 **E**(**Z**):

![](../Images/6732f0ffcefb8c7ab9c2a9d45ce2c7eb.png)

计算均匀分布在区间 [a, b] 上的连续随机变量的期望值的过程（作者提供的图片）

如果 a=1 且 b=5，**Z** ~ Uniform(1, 5) 的均值就是 (1+5)/2 = 3。这与我们的直觉一致。如果在 1 和 5 之间的每一个无限多的值都是同样可能的，我们会期望均值等于 1 和 5 的简单平均值。

现在我不想打击你的积极性，但实际上，你更可能在前院看到双彩虹，而不是遇到需要用积分法来计算其期望值的连续随机变量。

![](../Images/1b6c6056ea185c5e8d5fa0e45459990a.png)

[双彩虹](https://commons.wikimedia.org/wiki/File:Double_rainbow_Hertfordshire_England.jpg) ([CC BY-SA 2.0](https://creativecommons.org/licenses/by-sa/2.0/deed.en))

你会发现，看似精美的概率密度函数（PDF）通常会被嵌入到大学教科书的章节末尾练习中。它们就像家猫一样，不“出门”。但作为一个实践中的统计学家，“外面”就是你生活的地方。在外面，你会发现自己面对着连续值的数据样本，比如车辆的长度。为了对这些真实世界的随机变量进行建模，你很可能会使用一些著名的连续函数，例如正态分布、对数正态分布、卡方分布、指数分布、威布尔分布等等，或者混合分布，即最适合你数据的模型。

这里有几个这样的分布：

![](../Images/115e6d34afe08ba1592a0b673c2f4488.png)

正态分布和卡方分布的连续随机变量的PDF和期望值（图片由作者提供）

对于许多常用的PDF，已经有人花费心力通过积分（x 乘以 f(x)）来推导分布的均值，就像我们对均匀分布所做的那样。这里有几个这样的分布：

![](../Images/2024cd655ed11336435e62e2eadbfe2f.png)

指数分布和伽马分布的连续随机变量的PDF和期望值

最后，在一些情况下，实际上是许多情况下，现实生活中的数据集表现出过于复杂的模式，无法用任何一个分布来建模。这就像你感染了一种病毒，带来了一堆症状。为了帮助你克服这些症状，你的医生会给你开一系列药物，每种药物的强度、剂量和作用机制都不同。当你面对的数据展现出许多复杂的模式时，你必须动用一小支概率分布的“军队”来进行建模。这种不同分布的组合被称为[**混合分布**](https://en.wikipedia.org/wiki/Mixture_model)。一种常用的混合分布是强大的[**高斯混合模型**](https://en.wikipedia.org/wiki/Mixture_model)，它是多个正态分布随机变量的几个概率密度函数的加权和，每个随机变量具有不同的均值和方差组合。

给定一个真实值数据的样本，你可能会发现自己在做一些非常简单的事情：你将计算连续值数据列的平均值，并将其称为样本均值。例如，如果你计算汽车数据集中汽车的平均长度，它会是174.04927英寸，仅此而已。就这么完成了。但是，这还不是全部，你还有一个问题需要回答。

# 你的样本均值有多准确？感受它的准确性

你如何知道样本均值对总体均值的估计有多准确？在收集数据时，你可能运气不好，或者懒惰，或者‘数据受限’（这通常是懒惰的一个极好的委婉说法）。无论哪种方式，你都在面对一个**非随机的**样本。它没有按比例代表总体的不同特征。以汽车数据集为例：你可能收集了大量中型车的数据，而大型车的数据则太少。而且伸缩豪华轿车可能完全没有出现在你的样本中。结果，你计算的平均长度将严重偏向于总体中仅中型车的平均长度。无论你是否喜欢，你现在都在以几乎每个人都开中型车为信念进行工作。

## 对自己要诚实

如果你收集了一个严重偏倚的样本，而你不知道或者不在意，那么愿上天保佑你在你选择的职业道路上。然而，如果你愿意考虑*偏倚的可能性*，并且你有一些线索关于你可能遗漏了哪些数据（例如跑车），那么统计学将通过[**强有力的机制来帮助你估计这种偏倚**](https://medium.com/towards-data-science/what-happens-when-you-omit-important-variables-from-your-regression-model-966830590d53)。

不幸的是，无论你多么努力，你永远也无法收集到一个完美平衡的样本。它*总是*包含偏倚，因为总体中各种元素的确切比例对你来说永远无法访问。记住那扇通向总体的门吗？记得门上的标志上总是写着‘CLOSED’吗？

你最有效的行动方案是收集一个大致包含总体中所有事物的相同比例的样本——即所谓的**良好平衡样本**。这个良好平衡样本的均值是你可以出发的最佳样本均值。

但是自然法则并不总是让统计学家的风帆黯然失色。自然界有一个宏伟的特性，体现在一个被称为**中心极限定理**（CLT）的定理中。你可以使用 CLT 来确定你的样本均值估计总体均值的效果如何。

CLT 并不是应对严重偏倚样本的灵丹妙药。如果你的样本主要由中型车组成，你实际上已经重新定义了你对总体的概念。如果你是*有意*只研究中型车，那么你就免责了。在这种情况下，尽管使用 CLT。它将帮助你估计你的样本均值与*中型车*的总体均值有多接近。

另一方面，如果你的存在目的在于研究所有生产的车辆，但你的样本主要是中型车，那么你遇到了问题。对于统计学的学生，让我用稍微不同的词重述一下。如果你的大学论文是关于宠物打哈欠的频率，但你的样本是20只猫和你邻居的贵宾犬，那么无论中心极限定理是否适用，再多的统计技巧也无法帮助你评估样本均值的准确性。

## 中心极限定理的要点

对于中心极限定理（CLT）的全面理解是另一个话题，但其要点如下：

如果你从总体中随机抽取数据点，并计算样本均值，然后重复这个过程多次，你将得到……许多不同的样本均值。嗯，显然如此！但接下来会发生一些令人惊讶的事情。如果你绘制所有这些样本均值的频率分布，你会发现它们 *总是* 正态分布的。更重要的是，这种正态分布的均值总是你正在研究的总体均值。这种我们宇宙个性中诡异而迷人的方面正是中心极限定理用（还有什么？）数学语言描述的。

![](../Images/0f1242dd21de974c56c4c15dc71bb9b2.png)

标记为 174.04927 英寸的样本均值长度在一个假设总体均值为 180 英寸的正态分布 **Z** 上（图由作者提供）

让我们来看看如何使用中心极限定理。我们将按以下步骤进行：

使用仅从一个样本得出的样本均值 **Z**_bar，我们将说总体均值 μ 落在区间 [μ_low, μ_high] 内的概率是 (1 — α)：

![](../Images/8ea79e6ade108b268bdac4f94671a1a7.png)

总体均值的下限和上限置信区间（图由作者提供）

你可以将 α 设置为 0 到 1 之间的任何值。例如，如果你将 α 设置为 0.05，你将得到 (1 — α) 为 0.95，即 95%。

要使这种概率 (1 — α) 成立，应该按如下方式计算下界 μ_low 和上界 μ_high：

![](../Images/831c3bb8cce18e67a2eea48eac6f9e89.png)

总体均值的下限和上限（图由作者提供）

在上述公式中，我们知道 **Z**_bar、α、μ_low 和 μ_high。其余的符号需要一些解释。

变量 s 是数据 *样本* 的标准差。

N 是样本量。

现在我们来讨论 z_α/2。

z_α/2 是你在标准正态分布的概率密度函数（PDF）的 X 轴上读出的值。标准正态分布是一个均值为零，标准差为一的正态分布连续随机变量的 PDF。z_α/2 是该分布 X 轴上使得 PDF 曲线左侧面积为 (1 — α/2) 的值。这一区域当你设置 α 为 0.05 时的样子如下：

![](../Images/2639cdecfcb11717eb8bd76ff72c91a4.png)

在 X 轴上某个值 X 左侧的 PDF 区域。在这种情况下，x=1.96（图由作者提供）

蓝色区域计算为 (1 — 0.05/2) = 0.975。请记住，任何 PDF 曲线下的总面积始终为 1.0。

总结一下，一旦你从一个样本中计算出均值 (**Z**_bar)，你可以围绕这个均值建立界限，使得总体均值落在这些界限内的概率是你选择的值。

让我们重新检查估计这些界限的公式：

![](../Images/831c3bb8cce18e67a2eea48eac6f9e89.png)

总体均值的下界和上界（图像来源于作者）

这些公式给我们一些关于样本均值性质的见解：

1.  随着样本方差 s 的增加，下界 (μ_low) 的值会降低，而上界 (μ_high) 的值会增加。这会有效地使 μ_low 和 μ_high 彼此远离，并远离样本均值。相反，随着样本方差的减少，μ_low 从下方更接近**Z**_bar，μ_high 从上方更接近**Z**_bar。区间界限本质上从两侧趋向于样本均值。实际上，区间 [μ_low, μ_high] 与样本方差成正比。如果样本在均值周围分布得很广泛（或紧密），则较大的（或较小的）分散会降低（或增加）样本均值作为总体均值估计的可靠性。

1.  注意，区间的宽度与样本大小 (N) 成反比。在两个方差相似的样本之间，较大的样本会产生围绕其均值的更紧密区间，而较小的样本则不会。

让我们看看如何计算汽车数据集的这个区间。我们将计算 [μ_low, μ_high]，以便有 95% 的概率使总体均值 μ 落在这些范围内。

为了获得 95% 的概率，我们应该将 α 设置为 0.05，这样 (1 — α) = 0.95。

我们知道 **Z**_bar 为 174.04927 英寸。

N 为 205 辆车辆。

[样本标准差](https://en.wikipedia.org/wiki/Standard_deviation)可以很容易地计算出来。它为 12.33729 英寸。

接下来，我们将处理 z_α/2。由于 α 为 0.05，α/2 为 0.025。我们需要找到 z_α/2 的值，即 z_0.025。这是在标准正态随机变量的 PDF 曲线的 X 轴上的值，其中曲线下的区域是 (1 — α/2) = (1 — 0.025) = 0.975。通过查阅 [标准正态分布表](https://en.wikipedia.org/wiki/Standard_normal_table#Cumulative_from_minus_infinity_to_Z)，我们发现这个值对应于**X**=1.96 的左侧区域。

![](../Images/97037ab018de01202f7f06d89ae8d8c7.png)

包含标准正态分布 CDF 值的表格。包含不同 **X** 值的 P(**X** ≤ x)（来源：[维基百科](https://en.wikipedia.org/wiki/Standard_normal_table#Cumulative_from_minus_infinity_to_Z)）

插入这些值，我们得到以下界限：

μ_low = Z_bar — ( z_α/2 · s/√N) = 174.04927 — (1.96 · 12.33729/205) = 173.93131

μ_high = Z_bar + ( z_α/2 · s/√N) = 174.04927 + (1.96 · 12.33729/205) = 174.16723

因此，[μ_low, μ_high] = [173.93131英寸, 174.16723英寸]

有95%的概率人口均值位于这个区间内。看看这个区间有多紧凑。它的宽度仅为0.23592英寸。在这个狭小的间隙中包含了样本均值174.04927英寸。尽管样本中可能存在各种偏差，我们的分析表明，样本均值174.04927英寸是对未知人口均值的*极其*良好的估计。

# 超越第一维度：多维样本空间中的期望

目前，我们关于期望的讨论仅限于一维，但它不一定非得如此。我们可以轻松地将期望的概念扩展到二维、三维或更高维度。要计算多维空间中的期望，我们只需要一个定义在N维空间上的**联合概率质量函数（或密度函数）**。联合PMF或PDF以多个随机变量作为参数，返回这些值同时出现的概率。

在文章前面，我们定义了一个随机变量**Y**，表示从汽车数据集中随机选择的车辆中的气缸数量。**Y**是你的典型一维离散随机变量，它的期望值由以下公式给出：

![](../Images/2d2d71058987c8bbb924c7e4703cd814.png)

单维离散随机变量的期望值（图像由作者提供）

让我们引入一个新的离散随机变量**X**。**X**和**Y**的**联合概率质量函数**用P(**X**=x_i, **Y**=y_j)表示，或简写为P(**X**, **Y**)。这个联合PMF将我们从**Y**所处的舒适一维空间中带出，带入到一个更有趣的二维空间。在这个二维空间中，一个数据点或结果由元组(x_i, y_i)表示。如果**X**的范围包含‘p’个结果，**Y**的范围包含‘q’个结果，则二维空间将具有(p x q)个联合结果。我们用元组(x_i, y_i)来表示这些联合结果中的每一个。要计算这个二维空间中的E(**Y**)，我们必须将E(**Y** )的公式适应如下：

![](../Images/7e3b49c7038d4d68e6b873648451968c.png)

离散随机变量**Y**在二维空间中的期望值（图像由作者提供）

请注意，我们正在对二维空间中所有可能的元组(x_i, y_i)进行求和。让我们将这个求和拆解成嵌套求和如下：

![](../Images/c2c6ceebae66298f720c09b455417590.png)

离散随机变量**Y**在二维空间中的期望值（图像由作者提供）

在嵌套求和中，内层求和计算y_j和P(**X**=x_i, **Y**=y_j)在所有y_j值上的乘积。然后，外层求和对每个x_i值重复内层求和。之后，它将所有这些单独的和收集起来并加总，以计算E(**Y** )。

我们可以通过将求和嵌套在彼此之间，将上述公式扩展到任意数量的维度。你需要的只是一个在N维空间上定义的联合PMF。例如，以下是如何将公式扩展到4维空间：

![](../Images/b8c1e2e20439a681bed53b49d457d5e3.png)

离散随机变量**Y**在4维空间上的期望值（图片由作者提供）

注意我们总是将**Y**的求和放在最深层次。你可以按任何顺序安排其余的求和——你将得到相同的E(**Y**)结果。

你可能会问，为什么要定义一个联合PMF并为所有这些嵌套求和而发狂？在N维空间上计算的E(**Y**)是什么意思？

理解多维空间中期望值含义的最佳方式是用实际的多维数据来说明其使用。

我们将使用的数据来自一艘特定的船，它与我渡过英吉利海峡的船不同，不幸的是没能到达另一边。

![](../Images/d74c510d6e19ccb84cbabe7d7e4d52b8.png)

[RMS泰坦尼克号](https://en.wikipedia.org/wiki/RMS_Titanic)于1912年4月10日从南安普顿出发（公有领域）

下图展示了887名乘客在RMS泰坦尼克号上的数据集中的一些行：

![](../Images/46c3115e711687c5e917c79bdc1423a2.png)

[泰坦尼克号数据集](https://www.kaggle.com/datasets/brendan45774/test-file) ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))

**Pclass**列表示乘客的舱位级别，整数值为1、2或3。**Siblings/Spouses Aboard**和**Parents/Children Aboard**变量是二元（0/1）变量，表示乘客是否有兄弟姐妹、配偶、父母或子女在船上。在统计学中，我们常常有些残酷地称这些**二元指示变量**为**虚拟变量**。它们并没有什么愚蠢的地方以至于配得上这样的贬义称呼。

从表中可以看出，有8个变量共同标识数据集中的每个乘客。每一个这8个变量都是一个随机变量。我们面临的任务有三方面：

1.  我们希望在这些随机变量的一个子集上定义一个联合概率质量函数，并且，

1.  使用这个联合PMF，我们希望说明如何在这个多维PMF上计算这些变量的期望值，并且，

1.  我们希望理解如何解读这个期望值。

为了简化问题，我们将**Age**变量分成5年为一个区间，并将这些区间标记为5、10、15、20、…、80。例如，20岁区间意味着乘客的实际年龄在（15，20]年区间内。我们将这个分箱后的随机变量称为**Age_Range**。

一旦**Age**被分箱，我们将按**Pclass**和**Age_Range**对数据进行分组。以下是分组计数：

![](../Images/9e30b445ff081d3de104d89ff4ce6ff7.png)

按乘客的舱位和（分组的）年龄的频率分布（作者提供的图像）

上表包含了每个**群体**（组）的泰坦尼克号乘客数量，这些群体是由**Pclass**和**Age_Range**的特征定义的。顺便提一下，*群体*也是统计学家非常崇拜的另一个词（以及[渐进](https://en.wikipedia.org/wiki/Asymptotic_analysis)）。这里有个小提示：每当你想说“组”时，直接说“群体”。我向你保证，无论你本来打算说什么，瞬间都会显得十倍重要。例如：“八个不同的**群体**的酒精爱好者（请原谅，[酒类鉴赏家](https://en.wikipedia.org/wiki/Oenophilia)）喝了假酒，他们的反应被记录下来。”明白了吗？

说实话，“群体”确实有“组”没有的精准[含义](https://en.wikipedia.org/wiki/Cohort_(statistics))。尽管如此，偶尔说一遍“群体”，观察听众脸上的尊敬感是有启发性的。

无论如何，我们将向频率表中添加另一列。这一新列将保存观察到特定**Pclass**和**Age_Range**组合的概率。这个概率P(**Pclass**, **Age_Range**)是频率（即**Name**列中的数量）与数据集中乘客总数（即887）的比率。

![](../Images/e46b8e99bfb76ce84c55a3a167e52413.png)

按乘客的舱位和（分组的）年龄的频率分布（作者提供的图像）

概率P(**Pclass**, **Age_Range**)是随机变量**Pclass**和**Age_Range**的**联合概率质量函数**。它给出了观察到被特定**Pclass**和**Age_Range**组合描述的乘客的概率。例如，查看**Pclass**为3且**Age_Range**为25的行。相应的联合概率为0.116122。这个数字告诉我们，大约12%的泰坦尼克号3等舱乘客年龄在20到25岁之间。

与一维PMF类似，当对其所有组成随机变量的值组合进行评估时，联合PMF也会加和为完美的1.0。如果你的联合PMF没有加和为1.0，你应该仔细检查一下定义。可能在公式中存在错误，或者更糟糕的是实验设计中有问题。

在上面的数据集中，联合PMF确实加和为1.0。相信我吧！

要直观感受联合PMF P(**Pclass**, **Age_Range**)，你可以在3维中绘制它。在3-D图中，将X和Y轴分别设置为**Pclass**和**Age_Range**，将Z轴设置为概率P(**Pclass**, **Age_Range**)。你会看到一个引人入胜的3-D图表。

![](../Images/a20b2a052e080bc06a7b572bc06640f3.png)

**Pclass**和**Age_Range**的联合PMF的3-D图（作者提供的图像）

如果你仔细观察，你会注意到联合PMF包含三个平行的图，分别对应于泰坦尼克号上的每一个船舱等级。三维图展示了不幸海轮上的一些人口统计数据。例如，在所有三个舱等级中，15到40岁的乘客占据了大部分。

现在让我们计算在这个二维空间上的E(**Age_Range**)。E(**Age_Range**)由下式给出：

![](../Images/2f1d0f42a523e477f3863faadcb5f2d4.png)

**Age_Range**的期望值（图片来源：作者）

我们对所有**Age_Range**的值进行内部求和：5,10,15,…,80。我们对所有**Pclass**的值进行外部求和：[1, 2, 3]。对于每一个(**Pclass**, **Age_Range**)的组合，我们从表中选择联合概率。**Age_Range**的期望值是31.48252537岁，这对应于35的分箱值。我们可以预期，泰坦尼克号上的“平均”乘客年龄在30到35岁之间。

如果你取泰坦尼克号数据集中**Age_Range**列的平均值，你将得到完全相同的数值：31.48252537岁。那么为什么不直接取**Age_Range**列的平均值来得到E(**Age_Range**)? 为什么要构建一个嵌套求和的鲁布·戈德堡机器来计算同样的值呢？

![](../Images/97471fe67495593c6cf73036a637e3c3.png)

[鲁布·戈德堡的“自动操作餐巾纸”机器](https://commons.wikimedia.org/wiki/File:Self-operating_napkin_(Rube_Goldberg_cartoon_with_caption).jpg)（公共领域）

这是因为在某些情况下，你所拥有的只是联合PMF和随机变量的范围。在这种情况下，如果你只有P(**Pclass, Age_Range**)且知道**Pclass**的范围是[1,2,3]，以及Age_Range的范围是[5,10,15,20,…,80]，你仍然可以使用嵌套求和技术来计算E(**Pclass**) **或** E(**Age_Range**)。

如果随机变量是连续的，那么可以使用多重积分在多维空间中找到期望值。例如，如果**X**、**Y**和**Z**是连续随机变量，并且f(**X**,**Y**,**Z**)是定义在三维连续空间（x, y, z）的联合概率密度函数，则**Y**在该三维空间中的期望值如图所示：

![](../Images/3a6fe3f347a8d63bfc35eaaa04139ac1.png)

连续随机变量**Y**在连续三维空间中的期望值（图片来源：作者）

就像在离散情况下，你首先对你想计算其期望值的变量进行积分，然后对其他变量进行积分。

一个著名的例子展示了用于计算期望值的多重积分方法，其规模小到人眼无法感知。我指的是**量子力学**中的**波函数**。波函数在笛卡尔坐标中表示为Ψ(x, y, z, t)，在极坐标中表示为Ψ(r, θ, ɸ, t)。它用于描述那些喜欢待在极其狭小空间里的微小物体的性质，例如原子中的电子。波函数Ψ返回一个形式为A + jB的复数，其中A代表实部，B代表虚部。我们可以将Ψ的绝对值平方解释为定义在四维空间（x, y, z, t）或（r, θ, ɸ, t）上的**联合概率密度函数**。特别是对于氢原子中的电子，我们可以将|Ψ|²解释为在时间t时电子在（x, y, z）或（r, θ, ɸ）周围一个极其微小的空间体积中的大致概率。通过知道|Ψ|²，我们可以在x, y, z和t上进行四重积分，以计算电子在时间t沿X、Y或Z轴（或其极坐标等效轴）的**期望位置**。

# 结束语

我以自己对晕船的经历开始这篇文章。如果你对用伯努利随机变量来建模这一非常复杂且尚未完全理解的人类困境感到不满，我也不会怪你。我的目的是说明期望如何从生物学层面实际影响我们。一种解释这一困境的方法是使用随机变量的酷炫且舒缓的语言。

从看似简单的伯努利变量开始，我们将我们的插图画笔从统计画布扫到量子波函数的宏伟多维复杂性。在整个过程中，我们力求理解期望如何在离散和连续尺度、单维和多维、以及微观尺度上运作。

还有一个领域，期望发挥了巨大的影响。这个领域是**条件概率**，其中计算随机变量**X**取值‘x’的概率，假设某些其他随机变量**A**、**B**、**C**等已经取值‘a’、‘b’、‘c’。**X**在**A**、**B**和**C**的条件下的概率表示为P(**X**=x|**A**=a,**B**=b,**C**=c)，或简写为P(**X**|**A**、**B**、**C**)。在我们见过的所有期望公式中，如果将概率（或概率密度）替换为同一条件版本，得到的就是**条件期望**的相应公式。它表示为E(**X**=x|**A**=a,**B**=b,**C**=c)，它位于回归分析和估计的广泛领域的核心。这是未来文章的素材！

# 引用和版权

## 数据集

汽车数据集下载自[加州大学欧文分校机器学习库](https://archive-beta.ics.uci.edu/dataset/10/automobile)，根据[知识共享署名4.0国际](https://creativecommons.org/licenses/by/4.0/legalcode)（CC BY 4.0）许可协议使用。

泰坦尼克号数据集下载自[Kaggle](https://www.kaggle.com/datasets/brendan45774/test-file)，根据[CC0许可](https://creativecommons.org/publicdomain/zero/1.0/)使用。

## 图片

本文中的所有图片版权归[Sachin Date](https://www.linkedin.com/in/sachindate/)所有，采用[CC-BY-NC-SA](https://creativecommons.org/licenses/by-nc-sa/4.0/)许可，除非图片下方另有说明。

*如果你喜欢这篇文章，请关注我，访问* [***Sachin Date***](https://timeseriesreasoning.medium.com) *以获取关于回归、时间序列分析和预测主题的提示、操作指南和编程建议。*
