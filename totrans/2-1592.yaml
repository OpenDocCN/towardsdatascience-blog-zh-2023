- en: Okay, You’ve Trained the Best Machine Learning Model. What’s Next?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 好的，你已经训练了最好的机器学习模型。接下来做什么？
- en: 原文：[https://towardsdatascience.com/okay-youve-trained-the-best-machine-learning-model-what-s-next-e7b8f167006e](https://towardsdatascience.com/okay-youve-trained-the-best-machine-learning-model-what-s-next-e7b8f167006e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/okay-youve-trained-the-best-machine-learning-model-what-s-next-e7b8f167006e](https://towardsdatascience.com/okay-youve-trained-the-best-machine-learning-model-what-s-next-e7b8f167006e)
- en: Data Science
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学
- en: An MLOps project beyond modeling in Jupyter Notebook
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个超越 Jupyter Notebook 建模的 MLOps 项目
- en: '[](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)[![Albers
    Uzila](../Images/64f95bb182d878579e23ed4aaec1aafb.png)](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7b8f167006e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7b8f167006e--------------------------------)
    [Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)[![Albers
    Uzila](../Images/64f95bb182d878579e23ed4aaec1aafb.png)](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7b8f167006e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7b8f167006e--------------------------------)
    [Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7b8f167006e--------------------------------)
    ·18 min read·Jun 4, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7b8f167006e--------------------------------)
    ·阅读时间 18 分钟·2023 年 6 月 4 日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a4f723cf7bf28815d9d27a97fd601e83.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4f723cf7bf28815d9d27a97fd601e83.png)'
- en: Photo by [Elena Mozhvilo](https://unsplash.com/@miracleday?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Elena Mozhvilo](https://unsplash.com/@miracleday?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Let’s say you’re building a data science project, maybe for work, college, portfolio,
    hobby, or whatever it is. You’ve spent your days solving a problem statement and
    experimenting with Jupyter notebooks. Now, you’re wondering, “How do I deploy
    my work as a useful product?”.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在构建一个数据科学项目，可能是为了工作、大学、作品集、爱好或其他任何目的。你已经花费了很多时间来解决问题陈述，并在 Jupyter notebooks
    中进行实验。现在，你在想，“我怎么将我的工作部署成一个有用的产品？”。
- en: To be concrete, assume you have a website that hosts forums. Users can add tags
    to a thread in a forum to ease navigating between forums with different topics.
    You want to better the user experience by suggesting predefined tags hence giving
    context to what the discussion is about.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，假设你有一个托管论坛的网站。用户可以给论坛中的线程添加标签，以方便在不同主题的论坛之间导航。你希望通过建议预定义的标签来改善用户体验，从而为讨论提供背景。
- en: The forum can be anything, so let’s be more specific; it always starts with
    a *post* explaining a math problem, followed by thoughts, questions, hints, or
    answers around it. Below is what a thread looks like and its 3 tags, i.e. **induction**,
    **combinatorics unsolved**, and **combinatorics**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 论坛可以是任何形式的，因此让我们更具体一点；它通常以一个 *帖子* 开始，解释一个数学问题，接着是围绕这个问题的想法、问题、提示或答案。以下是一个线程的样子及其三个标签，即
    **induction**、**combinatorics unsolved** 和 **combinatorics**。
- en: '![](../Images/5dd6880d744be717451c45c98d3fbcbe.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5dd6880d744be717451c45c98d3fbcbe.png)'
- en: An example of a thread in a forum | Image by [author](http://dwiuzila.medium.com/membership)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 论坛中的一个帖子示例 | 图片由 [author](http://dwiuzila.medium.com/membership) 提供
- en: At this point, you’ve done everything in your notebooks, from understanding
    the problem statement, defining metrics, querying data, cleaning it, preprocessing,
    EDA, building a model, to evaluating and optimizing the model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你已经在你的 notebooks 中完成了所有工作，从理解问题陈述、定义指标、查询数据、清理数据、预处理、EDA、构建模型到评估和优化模型。
- en: You notice there are [so many posts](https://medium.com/towards-data-science/multilabel-text-classification-done-right-using-scikit-learn-and-stacked-generalization-f5df2defc3b5)
    with a huge total number of tags. So to simplify, you filter only 10 tags. The
    models you develop are simple [linear classifiers](/understanding-3-classical-machine-learning-models-once-and-for-all-part-1-32a1ac52c0fd)
    (SVM, logistic regression, etc.) preceded by [TF-IDF vectorization](/all-you-need-to-know-about-bag-of-words-and-word2vec-text-feature-extraction-e386d9ed84aa),
    and you train them with [Stochastic Gradient Descent](https://medium.com/towards-data-science/complete-step-by-step-gradient-descent-algorithm-from-scratch-acba013e8420)
    (SGD).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df8459514d52d33342616cba2be61e1b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: First 30 frequent tag count | Image by [author](http://dwiuzila.medium.com/membership)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fdf51bf531d6380432968037ab2c7f51.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: Final tag distribution. Notice that geometry is the most common one | Image
    by [author](http://dwiuzila.medium.com/membership)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: While notebooks are great and can help you conduct experiments very fast, they’re
    not production-ready and are sometimes hard to maintain. So, you need to migrate
    your codes into individual Python files, and then step-by-step add other utilities
    while collaborating with your team members.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'This story will guide you to do exactly that with bite-sized simple steps.
    Before that, you might want to refresh your mind about linear models, TF-IDF,
    and SGD:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[](/understanding-3-classical-machine-learning-models-once-and-for-all-part-1-32a1ac52c0fd?source=post_page-----e7b8f167006e--------------------------------)
    [## Linear Regression, Logistic Regression, and SVM in 10 Minutes'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: How does linear regression relate to logistic regression and Support Vector
    Machine?
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/understanding-3-classical-machine-learning-models-once-and-for-all-part-1-32a1ac52c0fd?source=post_page-----e7b8f167006e--------------------------------)
    [](/all-you-need-to-know-about-bag-of-words-and-word2vec-text-feature-extraction-e386d9ed84aa?source=post_page-----e7b8f167006e--------------------------------)
    [## All You Need to Know About Bag of Words and Word2Vec — Text Feature Extraction
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Why Word2Vec is better, and why it’s not good enough
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/all-you-need-to-know-about-bag-of-words-and-word2vec-text-feature-extraction-e386d9ed84aa?source=post_page-----e7b8f167006e--------------------------------)
    [](/complete-step-by-step-gradient-descent-algorithm-from-scratch-acba013e8420?source=post_page-----e7b8f167006e--------------------------------)
    [## Complete Step-by-Step Gradient Descent Algorithm from Scratch
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: And its implementation for constant learning rate and line search
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/complete-step-by-step-gradient-descent-algorithm-from-scratch-acba013e8420?source=post_page-----e7b8f167006e--------------------------------)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Initialize a Repository
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, let’s create a new repo on [GitHub](https://github.com/new) called [tagolym-ml](https://github.com/dwiuzila/tagolym-ml/tree/main),
    complete with `README.md`, `.gitignore`, and `LICENSE`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们在[GitHub](https://github.com/new)上创建一个名为[tagolym-ml](https://github.com/dwiuzila/tagolym-ml/tree/main)的新仓库，并配有`README.md`、`.gitignore`和`LICENSE`。
- en: '![](../Images/ca7476cb2277feb398c1c8acea14c958.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca7476cb2277feb398c1c8acea14c958.png)'
- en: Creating a new GitHub repository | Image by [author](http://dwiuzila.medium.com/membership)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 创建新的GitHub仓库 | 图片来源 [author](http://dwiuzila.medium.com/membership)
- en: 'To work with the repo, do these steps:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这个代码库，请执行以下步骤：
- en: Clone the repo and a folder named `tagolym-ml` will be created.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆代码库，将创建一个名为`tagolym-ml`的文件夹。
- en: Change the working directory into this folder.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将工作目录更改为此文件夹。
- en: Build a virtual environment called `venv`.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`venv`的虚拟环境。
- en: Activate the environment.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活环境。
- en: Upgrade `pip`.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级`pip`。
- en: Optionally, you can check the packages currently installed in your environment
    using `pip list`, there will be `pip` and `setuptools`.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，你可以使用`pip list`检查当前环境中已安装的包，其中会有`pip`和`setuptools`。
- en: Create a new git branch called `code_migration` and switch to it.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`code_migration`的新git分支并切换到它。
- en: Create a file `setup.py`.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`setup.py`文件。
- en: Make some new folders named `config`, `tagolym`, and `credentials`.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一些名为`config`、`tagolym`和`credentials`的新文件夹。
- en: Create files `config.py` and `args.json` inside the `config` folder.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`config`文件夹内创建`config.py`和`args.json`文件。
- en: Create files `main.py`, `utils.py`, `data.py`, `train.py`, `evaluate.py`, and
    `predict.py` inside the `tagolym` folder.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`tagolym`文件夹内创建`main.py`、`utils.py`、`data.py`、`train.py`、`evaluate.py`和`predict.py`文件。
- en: 'If you don’t understand how to do those, don’t worry. Here are all the commands
    you need that you can run on your favorite terminal:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道如何做这些，不用担心。这里是你可以在喜欢的终端上运行的所有命令：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You now have a git repo in your local connected to the remote repo in GitHub.
    The local repo directories will look like this.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在有一个本地git仓库，已连接到GitHub上的远程仓库。当地仓库的目录将如下所示。
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Almost all of these files are empty for now. You’ll fill them in one by one,
    starting with the folder `config`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 目前几乎所有这些文件都是空的。你将一个一个地填写它们，从`config`文件夹开始。
- en: Migrate Your Codebase
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移你的代码库
- en: There are two main folders within your project, i.e. `config` and `tagolym`.
    You want to copy the necessary codes from your notebooks into files inside these
    folders. Let’s do it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你的项目中有两个主要文件夹，即`config`和`tagolym`。你需要将笔记本中的必要代码复制到这些文件夹中的文件中。我们来做吧。
- en: config/config.py
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: config/config.py
- en: Here, you define global variables related to seeds, directories, experiment
    tracking, preprocessing, and label names.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你定义了与种子、目录、实验跟踪、预处理和标签名称相关的全局变量。
- en: 'When this file is imported somewhere in your code, it will make two new folders
    if not yet created:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当这个文件在你的代码中被导入时，如果尚未创建，它将创建两个新文件夹：
- en: '`data`, in which you store labeled data for the project,'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`data`，用于存储项目的标记数据，'
- en: '`stores/model`, in which you store the model registry,'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`stores/model`，用于存储模型注册，'
- en: and then connect `stores/model` to a tracking URI for experiment tracking with
    MLflow.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将`stores/model`连接到用于实验跟踪的MLflow跟踪URI。
- en: You also define stopwords and additional command words here. The stopwords will
    be the default from `nltk` package, while command words are `["prove", "let",
    "find", "show", "given"]`, which often come up in the post but don’t give any
    useful signals.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你还在这里定义了停用词和额外的命令词。停用词将默认为`nltk`包中的词汇，而命令词为`["prove", "let", "find", "show",
    "given"]`，这些词经常出现在帖子中，但不提供任何有用的信号。
- en: Regex patterns are used for preprocessing. They look intimidating, but you don’t
    need to understand them. What they basically do is catch any [mathematical expressions](https://www.overleaf.com/learn/latex/Mathematical_expressions)
    and [asymptote syntax](https://asymptote.sourceforge.io/) in LaTeX, which are
    the bread and butter in a math problem post.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式用于预处理。它们看起来很吓人，但你不需要理解它们。它们的基本功能是捕捉任何[数学表达式](https://www.overleaf.com/learn/latex/Mathematical_expressions)和[渐近线语法](https://asymptote.sourceforge.io/)的LaTeX，这些在数学问题的帖子中是基础和核心。
- en: Lastly, remember you selected only 10 shortlisted labels to work with? You list
    all of them in this file. Some tags have a similar meaning to your labels (e.g.
    “inequalities” → “inequality”), so you also have 10 partial labels to catch these
    tags and replace them with appropriate labels. See `tagolym/data.py` below for
    how you do this.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，记住你只选择了10个入围标签进行处理？你在这个文件中列出了所有这些标签。一些标签与您的标签有类似的含义（例如“inequalities” → “inequality”），因此你也有10个部分标签来捕获这些标签并用适当的标签替换它们。请参见下面的`tagolym/data.py`，了解如何操作。
- en: config/args.json
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: config/args.json
- en: This is where you store all *initial* arguments for the entire process. They
    are coming from different parts of the pipeline.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你存储整个过程的*初始*参数的地方。它们来自管道的不同部分。
- en: What do they mean?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它们是什么意思？
- en: '`nocommand` and `stem` — booleans for preprocessing the posts, whether to exclude
    command words and to implement [word stemming](https://en.wikipedia.org/wiki/Stemming).'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`nocommand` 和 `stem` —— 处理帖子时的布尔值，是否排除命令词和实现[词干提取](https://en.wikipedia.org/wiki/Stemming)。'
- en: '`ngram_max_range` — the upper boundary of the range of *n* values for different
    *n*-grams to be extracted during [TF-IDF vectorization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ngram_max_range` —— 在[TF-IDF向量化](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)过程中提取不同*n*-gram的*n*值范围的上限。'
- en: '`loss`, `l1_ratio`, `alpha`, `learning_rate`, `eta0`, `power_t` — hyperparameters
    for models using the [SGD classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html).'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`loss`、`l1_ratio`、`alpha`、`learning_rate`、`eta0`、`power_t` —— 用于[SGD分类器](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)的模型的超参数。'
- en: tagolym/utils.py
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tagolym/utils.py
- en: 'The pipeline is a bit convoluted, so you need some utility functions and Python
    classes to streamline your codes. This file contains those:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线有些复杂，因此你需要一些实用函数和Python类来简化代码。这个文件包含了这些：
- en: '`load_dict` and `save_dict` — to load a dictionary from a JSON file and, the
    other way around, dump a dictionary into a JSON file.'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`load_dict` 和 `save_dict` —— 从JSON文件中加载字典，或将字典转储到JSON文件中。'
- en: '`NumpyEncoder` — to encode objects with Numpy instances into Python built-in
    instances, used in `save_dict`.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NumpyEncoder` —— 将包含Numpy实例的对象编码为Python内置实例，用于`save_dict`。'
- en: '`IterativeStratification` — when you’re dealing with multilabel classification
    like this project, the vanilla [train-test-split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
    method is not ideal for the data. In return, you need what we call [iterative
    stratification](http://scikit.ml/stratification.html), which aims to provide well-balanced
    distribution of evidence of label relations up to a given order. In this project,
    the order is set to 2.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`IterativeStratification` —— 当你处理像这个项目这样的多标签分类时，普通的[训练-测试划分](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)方法对于数据并不理想。相反，你需要我们所说的[迭代分层](http://scikit.ml/stratification.html)，它旨在提供在给定阶数下标签关系证据的良好平衡分布。在这个项目中，阶数设置为2。'
- en: tagolym/data.py
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tagolym/data.py
- en: All functions regarding data are written in this file, including data split,
    preprocessing, and transformation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据相关的所有函数都写在这个文件中，包括数据分割、预处理和转换。
- en: '`preprocess` — creates a mapping from tags containing partial labels to one
    of the 10 labels defined in `config/config.py`, then does text processing on all
    posts and labels. This function also drops all samples with an empty post after
    text processing.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`preprocess` —— 从包含部分标签的标签创建映射到`config/config.py`中定义的10个标签之一，然后对所有帖子和标签进行文本处理。这个函数还会在文本处理后删除所有空帖子样本。'
- en: '`binarize` — based on model requirements, you may want to binarize your labels
    if you’re working on a multilabel classification problem. This function converts
    labels into a binary matrix of size (#samples × #labels) indicating the presence
    of a tag in the labels. For example, the label containing two tags `["algebra",
    "inequality"]` will be transformed into `[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]`. Besides
    returning the transformed labels, it also returns the `[MultiLabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html)`
    object used later, especially for converting the matrix back to labels.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`binarize` — 根据模型要求，如果你正在处理多标签分类问题，你可能需要对标签进行二值化。此函数将标签转换为一个大小为（#样本 × #标签）的二进制矩阵，指示标签中标签的存在。例如，包含两个标签`["algebra",
    "inequality"]`的标签将被转换为`[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]`。除了返回转换后的标签，它还返回稍后使用的`[MultiLabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html)`对象，特别是在将矩阵转换回标签时。'
- en: '`split_data` — using `IterativeStratification` from `tagolym/utils.py`, this
    function splits the posts and labels into 3 parts with 70/15/15 proportions, each
    respectively for model training, validation, and testing.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`split_data` — 使用`tagolym/utils.py`中的`IterativeStratification`，此函数将帖子和标签拆分为3部分，比例为70/15/15，分别用于模型训练、验证和测试。'
- en: tagolym/train.py
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tagolym/train.py
- en: It’s a best practice to have separate files for model training, validation,
    and testing. As the file name suggests, you do all the training here. Since you
    want users to use the model’s tag recommendations confidently, you want to have
    low false positives.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践是将模型训练、验证和测试放在不同的文件中。正如文件名所示，你在这里进行所有的训练。由于你希望用户能自信地使用模型的标签推荐，你需要降低假阳性率。
- en: 'On the other hand, false negatives are not your top priority for now. To see
    why, let’s take an extreme example: the model predicts all 10 labels as negatives,
    hence no tags are recommended and you have a high number of false negatives. But
    then, the users can just create their own tags without hesitation. No big deal.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，目前假阴性并不是你的首要任务。为了说明这一点，我们来看看一个极端的例子：模型将所有10个标签预测为负值，因此没有推荐标签，你会有大量的假阴性。但用户可以毫不犹豫地创建自己的标签。这没什么大不了的。
- en: So, your objective will be to have a model with high precision.
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以，你的目标是拥有一个高精度的模型。
- en: 'Now, let’s discuss what this file has to offer:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下这个文件的内容：
- en: '`train` — preprocess the data, binarize the labels, and split the data using
    functions from `tagolym/data.py`. Then, initialize a model, train it, predict
    the labels on all three splits using the trained model, and evaluate the predictions.
    This function accepts `args` which contains all arguments in `config/args.json`,
    to which an additional argument `threshold` may be added before being returned.
    Basically, `threshold` is a list of the best threshold for every label calculated
    by `tune_threshold`.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`train` — 预处理数据，将标签二值化，并使用`tagolym/data.py`中的函数拆分数据。然后，初始化一个模型，训练它，使用训练好的模型对所有三个数据拆分进行标签预测，并评估预测结果。这个函数接受`args`，其中包含`config/args.json`中的所有参数，返回时可能会添加一个额外的参数`threshold`。基本上，`threshold`是通过`tune_threshold`计算出的每个标签的最佳阈值列表。'
- en: '`objective` — f1 score is a metric chosen to be optimized in [hyperparameter
    tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization). Using an `args`
    chosen in a trial, this function trains the model and returns the f1 score of
    the validation split. It also sets additional attributes to the trial, including
    precision, recall, and the f1 score of all three splits.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`objective` — f1分数是[超参数调整](https://en.wikipedia.org/wiki/Hyperparameter_optimization)中选择的优化指标。使用试验中选择的`args`，此函数训练模型并返回验证集的f1分数。它还为试验设置了额外的属性，包括所有三个数据拆分的精确度、召回率和f1分数。'
- en: '`tune_threshold` — the default decision boundary for a binary classification
    problem is 0.5, which may not be optimal depending on the problem. So, besides
    tuning `args`, you also tune the threshold for every label while optimizing the
    f1 score. What it does is try all possible values of the threshold from a grid
    of 0 to 1 and pick the one that has the maximum f1 score.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tune_threshold` — 二分类问题的默认决策边界是0.5，但这可能并不是最优的，具体取决于问题。因此，除了调整`args`，你还需要在优化f1分数时调整每个标签的阈值。它的作用是尝试从0到1的网格中所有可能的阈值，并选择具有最大f1分数的阈值。'
- en: tagolym/predict.py
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tagolym/predict.py
- en: 'What next after model training? Predict! There are two functions in this file:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练之后该做什么？预测！这个文件中有两个函数：
- en: '`custom_predict` — if the model has `predict_proba` attribute, this function
    will predict the probability of each label being a tag. Otherwise, it predicts
    the tag directly using 0.5 threshold. In the former case, if the true labels are
    given, the function will use them to tune the threshold using `tune_threshold`
    from `tagolym/train.py`.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`custom_predict` — 如果模型具有 `predict_proba` 属性，则此函数将预测每个标签作为标签的概率。否则，使用 0.5 阈值直接预测标签。在前一种情况下，如果提供了真实标签，函数将使用
    `tagolym/train.py` 中的 `tune_threshold` 来调整阈值。'
- en: '`predict` — load `args`, the label binarizer, and the trained model. Then,
    preprocess given texts and do predictions on them using `custom_predict`. After
    that, transform the prediction matrix back into tags.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`predict` — 加载 `args`、标签二值化器和训练好的模型。然后，预处理给定的文本，并使用 `custom_predict` 对其进行预测。之后，将预测矩阵转换回标签。'
- en: tagolym/evaluate.py
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tagolym/evaluate.py
- en: 'Given prediction and true label matrices, the purpose of this file is to calculate
    the precision, recall, f1 score, and number of samples. The performance is computed
    on the overall samples, per-class samples, and per-slice samples. There are 8
    slices you consider:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 给定预测和真实标签矩阵，本文件的目的是计算精度、召回率、F1 分数和样本数量。性能是根据总体样本、每类样本和每个切片样本计算的。你考虑了 8 个切片：
- en: short posts, i.e. those that have less than 5 words after preprocessed,
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 短帖，即经过预处理后少于 5 个单词的帖子，
- en: six slices in which the posts are tagged as a subtopic but not tagged as the
    bigger topic covering the subtopic, and
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 六个切片，其中帖子被标记为子主题但未标记为覆盖子主题的更大主题，以及
- en: posts that don’t have frequent four-letter-or-more words.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不包含频繁出现的四字或更多字的帖子。
- en: tagolym/main.py
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tagolym/main.py
- en: 'This is the main file that runs everything end-to-end. Here are 5 functions
    you have in this file and what instructions you should write in them:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是运行所有任务的主要文件。这里有 5 个函数和你需要在其中编写的指令：
- en: '`elt_data` — query labeled data and save it to `data` folder in JSON format.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`elt_data` — 查询标记数据并以 JSON 格式保存到`data`文件夹中。'
- en: '`train_model` — load labeled data from `data` folder and train your model.
    Don’t forget to log the metrics, artifacts, and parameters using MLflow. Save
    also MLflow `run_id` and metrics to the `config` folder.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`train_model` — 从`data`文件夹加载标记数据并训练模型。不要忘记使用 MLflow 记录指标、工件和参数。还要将 MLflow `run_id`和指标保存到`config`文件夹中。'
- en: '`optimize` — load labeled data from `data` folder and optimize given arguments.
    For search efficiency, the optimization is done in two steps: a) hyperparameters
    in preprocessing, vectorization, and modeling; and b) hyperparameters in the learning
    algorithm. Save also the best arguments based on the objective to the `config`
    folder, name it as `args_opt.json`.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`optimize` — 从`data`文件夹加载标记数据并优化给定的参数。为了提高搜索效率，优化分为两个步骤：a) 预处理、向量化和建模中的超参数；b)
    学习算法中的超参数。还要根据目标将最佳参数保存到`config`文件夹中，命名为`args_opt.json`。'
- en: '`load_artifacts` — load the artifacts of a specific `run_id` into memory, including
    arguments, metrics, model, and label binarizer.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`load_artifacts` — 将特定 `run_id` 的工件加载到内存中，包括参数、指标、模型和标签二值化器。'
- en: '`predict_tag` — given a specific `run_id`, predict the tags of every text it
    receives using preloaded artifacts.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`predict_tag` — 给定特定的 `run_id`，使用预加载的工件预测接收到的每个文本的标签。'
- en: Phew! You just did all migration needed. Now, how do you use these codes?
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 唷！你刚刚完成了所有迁移工作。现在，如何使用这些代码？
- en: '![](../Images/cee12848735f6ab48433c40563e4fd78.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cee12848735f6ab48433c40563e4fd78.png)'
- en: Photo by [Jason Strull](https://unsplash.com/@jasonstrull?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Jason Strull](https://unsplash.com/@jasonstrull?utm_source=medium&utm_medium=referral)
    提供的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Package Your Codebase
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 打包你的代码库
- en: When you used notebooks, you had a preloaded set of packages for experimentation.
    To reproduce it locally and deploy it to production, you want to define your environment
    explicitly instead.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用笔记本时，你有一个预加载的包集合用于实验。为了在本地重现并部署到生产环境，你希望明确地定义你的环境。
- en: You import many open-source packages in this project but only have `pip` and
    `setuptools` in your environment. So, before running the pipeline, you need to
    install those packages too.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这个项目中导入了许多开源包，但你的环境中只有`pip`和`setuptools`。因此，在运行管道之前，你需要安装这些包。
- en: Below is a handy command to do that. Notice I added `[pip-chill](https://pypi.org/project/pip-chill/)`
    at the end to clean up the generation of the package requirements file later.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个方便的命令来实现这一点。注意，我在最后添加了 `[pip-chill](https://pypi.org/project/pip-chill/)`
    以便于后续清理生成的包要求文件。
- en: '[PRE3]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: What’s cool about `pip-chill` is that it lets you generate a requirements file
    without any packages that depend on other packages in the file, making the requirements
    file clean and accurate. Let’s just run it.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip-chill` 的一个很酷的特点是，它可以生成一个不包含文件中依赖于其他包的包的要求文件，使得要求文件干净且准确。让我们运行一下。'
- en: '[PRE4]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This will create a file `requirements.txt` containing all packages you actually
    need. Note that there are no `pandas`, `scikit-learn`, `regex`, and several other
    packages since these are dependencies of packages already listed in the file.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个 `requirements.txt` 文件，包含你实际需要的所有包。请注意，因为这些包是已经列在文件中的包的依赖项，所以文件中没有 `pandas`、`scikit-learn`、`regex`
    以及其他几个包。
- en: Now you’ll use `setup.py` to package your codebase, wrapping up all dependencies.
    Inside this file, load all libraries you have in `requirements.txt`, and define
    your package using the `setup` function from `setuptools`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你将使用 `setup.py` 打包你的代码库，将所有依赖项打包在一起。在这个文件中，加载你在 `requirements.txt` 中的所有库，并使用
    `setuptools` 中的 `setup` 函数定义你的包。
- en: Your package name will be `tagolym`. You can see other details like its version
    and description in the code below. Libraries you load from `requirements.txt`
    will be used in the `install_requires` parameter and become dependencies of `tagolym`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 你的包名将是 `tagolym`。你可以在下面的代码中看到其他细节，如版本和描述。你从 `requirements.txt` 中加载的库将用于 `install_requires`
    参数，并成为 `tagolym` 的依赖项。
- en: You can then install `tagolym` using this command below. A new folder named
    `tagolym.egg-info` will be created which contains the project’s metadata.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以使用下面的命令安装 `tagolym`。这将创建一个名为 `tagolym.egg-info` 的新文件夹，包含项目的元数据。
- en: '[PRE5]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Notice the `-e` or `--editable` flag installs a package in editable mode from
    a local project path. In other words, if you use some functions in the current
    working directory, e.g. using `from tagolym import main`, then you make some changes
    to `tagolym/main.py`, you will able to use this updated version without re-installing
    your package using `pip install`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`-e` 或 `--editable` 标志会从本地项目路径以可编辑模式安装包。换句话说，如果你在当前工作目录中使用一些函数，例如使用 `from
    tagolym import main`，然后对 `tagolym/main.py` 进行一些更改，你将能够使用这个更新版本，而无需使用 `pip install`
    重新安装你的包。
- en: Setup Data Source Credential
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置数据源凭证
- en: There’s one small problem. The data used in this project is my own data which
    is available in my [BigQuery](https://cloud.google.com/bigquery). After creating
    and downloading a [service account key](https://console.cloud.google.com/iam-admin/serviceaccounts),
    I rename it to `bigquery-key.json`, and place it in the `credentials` folder.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个小问题。这些项目中使用的数据是我自己的数据，存储在我的 [BigQuery](https://cloud.google.com/bigquery)
    中。在创建并下载一个 [服务账户密钥](https://console.cloud.google.com/iam-admin/serviceaccounts)
    后，我将其重命名为 `bigquery-key.json`，并将其放置在 `credentials` 文件夹中。
- en: To access the data, you’d need my credential, which unfortunately is not to
    be shared. But worry not, I’ll provide samples for you to work with.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问数据，你需要我的凭证，但不幸的是，这些凭证不能共享。不过不用担心，我会提供样本供你使用。
- en: '![](../Images/5559db01c3de6704a8347306c22df26f.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5559db01c3de6704a8347306c22df26f.png)'
- en: Creating a service account key | Image by [author](http://dwiuzila.medium.com/membership)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 创建服务账户密钥 | 图片由 [作者](http://dwiuzila.medium.com/membership) 提供
- en: 'What you need to do is simple: download the samples `labeled_data.json` [**here**](https://gist.github.com/dwiuzila/74dc99fe6f6d3901dbd1695f77977865)
    and save the file in a folder named `data` in the working directory.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做的很简单：下载样本 `labeled_data.json` [**在这里**](https://gist.github.com/dwiuzila/74dc99fe6f6d3901dbd1695f77977865)
    并将文件保存在工作目录中名为 `data` 的文件夹里。
- en: Run Your Pipeline
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行你的管道
- en: Now you’re ready! Type `python3` command in the terminal and you’re good to
    run everything in Python. You’ll only use `tagolym/main.py` file.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你准备好了！在终端中输入 `python3` 命令，你就可以运行 Python 中的所有内容。你只需使用 `tagolym/main.py` 文件。
- en: First, I query the data using my credential and the `elt_data` function. When
    I see `✅ Saved data!`, I know that the process ran smoothly. As mentioned above,
    you can skip this step and manually put the samples I provided in the `data` folder.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我使用我的凭证和 `elt_data` 函数查询数据。当我看到 `✅ Saved data!` 时，我知道过程顺利完成。如上所述，你可以跳过这一步，手动将我提供的样本放入
    `data` 文件夹中。
- en: Then, you optimize the model using the `optimize` function by reading the initial
    arguments `config/args.json`. I set the number of trials to 10, but you can try
    something else. A new MLflow study will be created with 20 trials in total since
    you have a two-step optimization process. The best validation f1 score found is
    0.7730.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用 `optimize` 函数来优化模型，通过读取初始参数 `config/args.json`。我将试验次数设置为 10，但您可以尝试其他设置。由于您有一个两步优化过程，所以将创建一个新的
    MLflow 研究，总共 20 次试验。找到的最佳验证 f1 分数是 0.7730。
- en: With a set of optimized arguments `config/args_opt.json`, you train the model
    once again using the `train_model` function and do inference on a list of texts
    using the `predict_tag` function. You can see below that the predictions are spot
    on!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一组优化后的参数 `config/args_opt.json`，您可以再次使用 `train_model` 函数训练模型，并使用 `predict_tag`
    函数对文本列表进行推断。您可以看到下面的预测非常准确！
- en: '[PRE6]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can explore your experiments in a beautiful MLflow UI:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在美观的 MLflow UI 中查看您的实验：
- en: '[PRE7]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/32002dbbcf952c1651380ccb18fe5eb8.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32002dbbcf952c1651380ccb18fe5eb8.png)'
- en: MLflow user interface | Image by [author](http://dwiuzila.medium.com/membership)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 用户界面 | 图片由 [作者](http://dwiuzila.medium.com/membership) 提供
- en: Some of these processes create new files in the background, most are the outputs
    of model training. You can see the current project directory in the `README.md`
    file explained in the next section.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这些过程中的一些在后台创建了新的文件，大多数是模型训练的输出。您可以在下一节中解释的 `README.md` 文件中查看当前的项目目录。
- en: Miscellaneous
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 杂项
- en: The security of your project is of the utmost importance. So, credentials should
    only live in your local repo; you don’t want to push it to GitHub.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 您项目的安全性至关重要。因此，凭据应仅存在于本地仓库中；您不希望将其推送到 GitHub。
- en: As a precaution, add `credentials/` at the end of the `.gitignore` file. This
    will ignore any changes you make in the `credentials` folder when you develop
    your project.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 作为预防措施，在 `.gitignore` 文件末尾添加 `credentials/`。这将忽略您在开发项目时对 `credentials` 文件夹所做的任何更改。
- en: Other things you might want to add to `.gitignore` is `data/` and `stores/`
    since they may contain sensitive information or occupy large disk space. If you’re
    using macOS, add also `.DS_Store`. It’s a file that stores custom attributes of
    its containing folder, which isn’t useful for your project.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 其他您可能想要添加到 `.gitignore` 的内容包括 `data/` 和 `stores/`，因为它们可能包含敏感信息或占用大量磁盘空间。如果您使用的是
    macOS，还需添加 `.DS_Store`。这是一个存储其所在文件夹自定义属性的文件，对您的项目没有用处。
- en: After doing all these, optionally, you could update your project description
    in `README.md`. Just type in the high-level process you’ve done in this story
    so everyone could replicate your work easily. Here’s what it might look like.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有这些之后，您可以选择更新 `README.md` 中的项目描述。只需输入您在这个故事中完成的高层次过程，以便每个人都可以轻松复制您的工作。这可能看起来是这样的。
- en: Push Your Project to GitHub
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将您的项目推送到 GitHub
- en: Your project is cool and all, but is it useful for others? To answer this, you
    can open-source your project so everyone can benefit from it, give feedback, or
    even contribute. And it’s very simple to do so.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 您的项目很酷，但它对其他人有用吗？要回答这个问题，您可以开源您的项目，以便每个人都可以从中受益，提供反馈，甚至贡献。这样做非常简单。
- en: 'What you need is the three commands below:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要的是下面的三个命令：
- en: add every change you made to the Git index,
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您所做的每一项更改添加到 Git 索引中。
- en: commit changes in the index to the local repo, and
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将索引中的更改提交到本地仓库，并
- en: push the local repo to remote, this will create a new branch `code_migration`
    in the remote repo.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将本地仓库推送到远程，这将创建一个新的分支 `code_migration` 在远程仓库中。
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You can see the results [**here**](https://github.com/dwiuzila/tagolym-ml/tree/code_migration).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [**这里**](https://github.com/dwiuzila/tagolym-ml/tree/code_migration) 查看结果。
- en: 'Know more about Git:'
  id: totrans-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 了解更多关于 Git 的信息：
- en: '[](/a-real-world-case-study-of-using-git-commands-as-a-data-scientist-e7775cccb4ba?source=post_page-----e7b8f167006e--------------------------------)
    [## A Real-World Case Study of Using Git Commands as a Data Scientist'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-real-world-case-study-of-using-git-commands-as-a-data-scientist-e7775cccb4ba?source=post_page-----e7b8f167006e--------------------------------)
    [## 作为数据科学家使用 Git 命令的真实案例研究'
- en: Complete with Branch Illustration
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完成分支说明
- en: towardsdatascience.com](/a-real-world-case-study-of-using-git-commands-as-a-data-scientist-e7775cccb4ba?source=post_page-----e7b8f167006e--------------------------------)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-real-world-case-study-of-using-git-commands-as-a-data-scientist-e7775cccb4ba?source=post_page-----e7b8f167006e--------------------------------)
- en: Wrapping Up
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congratulations! 🍻 You’ve come to the end of this story. You learned how to
    translate your data science experimentation in Jupyter Notebook to a clean and
    maintainable project. Besides that, now you also know how to package your project,
    run your pipeline end-to-end, and work with GitHub and BiqQuery.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！🍻 你已经阅读完了这个故事。你学会了如何将你的数据科学实验从 Jupyter Notebook 转化为一个干净且可维护的项目。除此之外，你还知道了如何打包你的项目，运行整个数据管道，并使用
    GitHub 和 BigQuery。
- en: But, this is just the beginning of your MLOps journey. There’s still a long
    way to go. Stay tuned! 📻
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，这只是你 MLOps 旅程的开始。还有很长的路要走。敬请关注！📻
- en: '![](../Images/fcb1906b329c918a89549438fd041b55.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcb1906b329c918a89549438fd041b55.png)'
- en: Photo by [Matese Fields](https://unsplash.com/@tesecreates?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Matese Fields](https://unsplash.com/@tesecreates?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供
- en: '![](../Images/39d3928bb1b8338b76276e63c0b8b3f8.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39d3928bb1b8338b76276e63c0b8b3f8.png)'
- en: 🔥 *Hi there! If you enjoy this story and want to support me as a writer, consider*
    [***becoming a member***](https://dwiuzila.medium.com/membership)*. For only $5
    a month, you’ll get unlimited access to all stories on Medium. If you sign up
    using my link, I’ll earn a small commission.*
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 🔥 *你好！如果你喜欢这个故事并想支持我作为一个作家，可以考虑* [***成为会员***](https://dwiuzila.medium.com/membership)*。每月只需
    $5，你就可以无限制访问 Medium 上的所有故事。如果你通过我的链接注册，我将获得一小笔佣金。*
- en: 🔖 *Want to know more about how classical machine learning models work and how
    they optimize their parameters? Or an example of MLOps megaprojects? What about
    cherry-picked top-notch articles of all time? Continue reading:*
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 🔖 *想了解更多关于经典机器学习模型如何运作以及如何优化其参数的信息？或者 MLOps 大型项目的示例？还有精选的顶尖文章？继续阅读：*
- en: '![Albers Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![Albers Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
- en: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
- en: MLOps Megaproject - Part II
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps 大型项目 - 第二部分
- en: '[View list](https://dwiuzila.medium.com/list/mlops-megaproject-part-ii-0c6f23f2ddfa?source=post_page-----e7b8f167006e--------------------------------)3
    stories![](../Images/140d7ffae64707753b23e1c5e18dce62.png)![](../Images/1524ee6088d1c77d5bf77d99f6804cc2.png)![](../Images/43560f87b46b65c4bbce9154e5c2b731.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://dwiuzila.medium.com/list/mlops-megaproject-part-ii-0c6f23f2ddfa?source=post_page-----e7b8f167006e--------------------------------)3
    篇故事！[](../Images/140d7ffae64707753b23e1c5e18dce62.png)![](../Images/1524ee6088d1c77d5bf77d99f6804cc2.png)![](../Images/43560f87b46b65c4bbce9154e5c2b731.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
- en: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
- en: Machine Learning from Scratch
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从零开始的机器学习
- en: '[View list](https://dwiuzila.medium.com/list/machine-learning-from-scratch-b35db8650093?source=post_page-----e7b8f167006e--------------------------------)8
    stories![](../Images/4b97f3062e4883b24589972b2dc45d7e.png)![](../Images/ec855bb602dbe7a37aa8ef73fb3df3b7.png)![](../Images/72471337c5c7555442f0cc06985de74d.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://dwiuzila.medium.com/list/machine-learning-from-scratch-b35db8650093?source=post_page-----e7b8f167006e--------------------------------)8
    篇故事！[](../Images/4b97f3062e4883b24589972b2dc45d7e.png)![](../Images/ec855bb602dbe7a37aa8ef73fb3df3b7.png)![](../Images/72471337c5c7555442f0cc06985de74d.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
- en: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
- en: Advanced Optimization Methods
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级优化方法
- en: '[View list](https://dwiuzila.medium.com/list/advanced-optimization-methods-26e264a361e4?source=post_page-----e7b8f167006e--------------------------------)7
    stories![](../Images/99e5c4ac661c0a5c6f0f386ae7986984.png)![](../Images/f84958116968e333daead307a6b3684c.png)![](../Images/c491e53a229df0bc740a49349af2665c.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://dwiuzila.medium.com/list/advanced-optimization-methods-26e264a361e4?source=post_page-----e7b8f167006e--------------------------------)7
    篇故事！[](../Images/99e5c4ac661c0a5c6f0f386ae7986984.png)![](../Images/f84958116968e333daead307a6b3684c.png)![](../Images/c491e53a229df0bc740a49349af2665c.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
- en: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
- en: My Best Stories
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我的最佳故事
- en: '[View list](https://dwiuzila.medium.com/list/my-best-stories-d8243ae80aa0?source=post_page-----e7b8f167006e--------------------------------)10
    stories![](../Images/bff788cd6edf0f1d2e69a785ca11d1dc.png)![](../Images/0d3371edcb1483d694597eb934c27411.png)![](../Images/43560f87b46b65c4bbce9154e5c2b731.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://dwiuzila.medium.com/list/my-best-stories-d8243ae80aa0?source=post_page-----e7b8f167006e--------------------------------)10个故事![](../Images/bff788cd6edf0f1d2e69a785ca11d1dc.png)![](../Images/0d3371edcb1483d694597eb934c27411.png)![](../Images/43560f87b46b65c4bbce9154e5c2b731.png)![Albers
    Uzila](../Images/b4f51438d99b29f789091dd239d7cfa6.png)'
- en: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[Albers Uzila](https://dwiuzila.medium.com/?source=post_page-----e7b8f167006e--------------------------------)'
- en: Data Science in R
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: R中的数据科学
- en: '[View list](https://dwiuzila.medium.com/list/data-science-in-r-0a8179814b50?source=post_page-----e7b8f167006e--------------------------------)7
    stories![](../Images/bad098890d89ce5a89e723add9c14d98.png)![](../Images/5bf2373efc1c05f1939dc9a72c99d786.png)![](../Images/c7d3478ce4cf90499b3e953ba69cd90e.png)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://dwiuzila.medium.com/list/data-science-in-r-0a8179814b50?source=post_page-----e7b8f167006e--------------------------------)7个故事![](../Images/bad098890d89ce5a89e723add9c14d98.png)![](../Images/5bf2373efc1c05f1939dc9a72c99d786.png)![](../Images/c7d3478ce4cf90499b3e953ba69cd90e.png)'
