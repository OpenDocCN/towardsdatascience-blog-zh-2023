["```py\n***Table of Contents***\n**·** [**Initialize a Repository**](#546e)\n**·** [**Migrate Your Codebase**](#f64b)\n  ∘ [config/config.py](#fe43)\n  ∘ [config/args.json](#1d69)\n  ∘ [tagolym/utils.py](#8d40)\n  ∘ [tagolym/data.py](#65c3)\n  ∘ [tagolym/train.py](#e3ff)\n  ∘ [tagolym/predict.py](#358d)\n  ∘ [tagolym/evaluate.py](#4517)\n  ∘ [tagolym/main.py](#c70b)\n**·** [**Package Your Codebase**](#ea95) **·** [**Setup Data Source Credential**](#94ae) **·** [**Run Your Pipeline**](#53a6) **·** [**Miscellaneous**](#f95f) **·** [**Push Your Project to GitHub**](#4df4) **·** [**Wrapping Up**](#cf97)\n```", "```py\n$ git clone https://github.com/dwiuzila/tagolym-ml.git\n$ cd tagolym-ml\n$ python3 -m venv venv\n$ source venv/bin/activate\n$ python3 -m pip install --upgrade pip\n$ pip list\nPackage    Version\n---------- -------\npip        23.1.2\nsetuptools 58.0.4\n$ git checkout -b code_migration\n$ touch setup.py\n$ mkdir config tagolym credentials\n$ touch config/config.py config/args.json\n$ cd tagolym\n$ touch main.py utils.py data.py train.py evaluate.py predict.py\n$ cd ..\n```", "```py\nconfig/\n├── args.json        - preprocessing/training parameters\n└── config.py        - configuration setup\ncredentials/         - keys and passwords\ntagolym/\n├── data.py          - data processing components\n├── evaluate.py      - evaluation components\n├── main.py          - training/optimization pipelines\n├── predict.py       - inference components\n├── train.py         - training components\n└── utils.py         - supplementary utilities\nvenv/                - virtual environment\n.gitignore           - files/folders that git will ignore\nLICENSE              - project license\nREADME.md            - longform description of the project\nsetup.py             - code packaging\n```", "```py\n$ pip install mlflow nltk regex scikit-learn snorkel joblib optuna pandas google-cloud-bigquery google-auth numpy scipy pip-chill\n```", "```py\n$ pip-chill --no-chill > requirements.txt\n```", "```py\n$ python3 -m pip install -e .\n```", "```py\n$ python3\n>>> from pathlib import Path\n>>> from config import config\n>>> from tagolym import main\n>>>\n>>> # query data\n>>> key_path = \"credentials/bigquery-key.json\"\n>>> main.elt_data(key_path)\n✅ Saved data!\n>>>\n>>> # optimize model\n>>> args_fp = Path(config.CONFIG_DIR, \"args.json\")\n>>> main.optimize(args_fp, study_name=\"optimization\", num_trials=10)\n2023/06/03 17:42:12 INFO mlflow.tracking.fluent: Experiment with name 'optimization' does not exist. Creating a new experiment.\n[I 2023-06-03 17:41:45,657] A new study created in memory with name: optimization\n[I 2023-06-03 17:42:12,343] Trial 0 finished with value: 0.7519199358796977 and parameters: {'nocommand': False, 'stem': True, 'ngram_max': 2, 'loss': 'modified_huber', 'l1_ratio': 0.6011150117432088, 'alpha': 0.001331121608073689}. Best is trial 0 with value: 0.7519199358796977.\n[I 2023-06-03 17:42:38,441] Trial 1 finished with value: 0.7629559140596291 and parameters: {'nocommand': False, 'stem': True, 'ngram_max': 2, 'loss': 'modified_huber', 'l1_ratio': 0.43194501864211576, 'alpha': 7.476312062252303e-05}. Best is trial 1 with value: 0.7629559140596291.\n[I 2023-06-03 17:42:57,713] Trial 2 finished with value: 0.7511576441724478 and parameters: {'nocommand': True, 'stem': False, 'ngram_max': 3, 'loss': 'hinge', 'l1_ratio': 0.5924145688620425, 'alpha': 1.3783237455007187e-05}. Best is trial 1 with value: 0.7629559140596291.\n[I 2023-06-03 17:43:19,108] Trial 3 finished with value: 0.7106573336158825 and parameters: {'nocommand': True, 'stem': False, 'ngram_max': 4, 'loss': 'hinge', 'l1_ratio': 0.6842330265121569, 'alpha': 0.00020914981329035596}. Best is trial 1 with value: 0.7629559140596291.\n[I 2023-06-03 17:43:37,349] Trial 4 finished with value: 0.741392879377292 and parameters: {'nocommand': False, 'stem': False, 'ngram_max': 2, 'loss': 'hinge', 'l1_ratio': 0.5467102793432796, 'alpha': 3.585612610345396e-05}. Best is trial 1 with value: 0.7629559140596291.\n[I 2023-06-03 17:44:04,235] Trial 5 finished with value: 0.7426444422157734 and parameters: {'nocommand': True, 'stem': True, 'ngram_max': 3, 'loss': 'hinge', 'l1_ratio': 0.045227288910538066, 'alpha': 9.46217535646148e-05}. Best is trial 1 with value: 0.7629559140596291.\n[I 2023-06-03 17:44:30,104] Trial 6 finished with value: 0.7337258988967691 and parameters: {'nocommand': True, 'stem': True, 'ngram_max': 2, 'loss': 'modified_huber', 'l1_ratio': 0.07455064367977082, 'alpha': 0.009133995846860976}. Best is trial 1 with value: 0.7629559140596291.\n[I 2023-06-03 17:44:51,778] Trial 7 finished with value: 0.7700323704566581 and parameters: {'nocommand': True, 'stem': False, 'ngram_max': 4, 'loss': 'log_loss', 'l1_ratio': 0.3584657285442726, 'alpha': 2.2264204303769678e-05}. Best is trial 7 with value: 0.7700323704566581.\n[I 2023-06-03 17:45:18,125] Trial 8 finished with value: 0.7559495178348377 and parameters: {'nocommand': True, 'stem': True, 'ngram_max': 2, 'loss': 'log_loss', 'l1_ratio': 0.8872127425763265, 'alpha': 0.00026100256506134784}. Best is trial 7 with value: 0.7700323704566581.\n[I 2023-06-03 17:45:47,029] Trial 9 finished with value: 0.7730089901544794 and parameters: {'nocommand': False, 'stem': True, 'ngram_max': 4, 'loss': 'log_loss', 'l1_ratio': 0.02541912674409519, 'alpha': 2.1070472806578224e-05}. Best is trial 9 with value: 0.7730089901544794.\n[I 2023-06-03 17:45:47,056] A new study created in memory with name: optimization\n[I 2023-06-03 17:46:16,061] Trial 0 finished with value: 0.7730089901544794 and parameters: {'learning_rate': 'optimal'}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:46:48,008] Trial 1 finished with value: 0.7701884982320516 and parameters: {'learning_rate': 'adaptive', 'eta0': 0.15930522616241014}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:47:18,651] Trial 2 finished with value: 0.7331091235928242 and parameters: {'learning_rate': 'invscaling', 'eta0': 0.0265875439832727, 'power_t': 0.17272998688284025}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:47:49,429] Trial 3 finished with value: 0.7196639813595901 and parameters: {'learning_rate': 'invscaling', 'eta0': 0.038234752246751866, 'power_t': 0.34474115788895177}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:48:21,601] Trial 4 finished with value: 0.7727673901952036 and parameters: {'learning_rate': 'adaptive', 'eta0': 0.3718364180573207}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:48:51,330] Trial 5 finished with value: 0.7576010292654753 and parameters: {'learning_rate': 'invscaling', 'eta0': 0.16409286730647918, 'power_t': 0.16820964947491662}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:49:21,906] Trial 6 finished with value: 0.7428637006524251 and parameters: {'learning_rate': 'invscaling', 'eta0': 0.040665633135147955, 'power_t': 0.13906884560255356}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:49:52,034] Trial 7 finished with value: 0.746701310091385 and parameters: {'learning_rate': 'constant', 'eta0': 0.011715937392307063}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:50:21,383] Trial 8 finished with value: 0.7683160697730758 and parameters: {'learning_rate': 'constant', 'eta0': 0.10968217207529521}. Best is trial 0 with value: 0.7730089901544794.\n[I 2023-06-03 17:50:51,373] Trial 9 finished with value: 0.7338062675694838 and parameters: {'learning_rate': 'invscaling', 'eta0': 0.7568292060167615, 'power_t': 0.4579309401710595}. Best is trial 0 with value: 0.7730089901544794.\nBest value (f1): 0.7730089901544794\nBest hyperparameters: {\n  \"nocommand\": false,\n  \"stem\": true,\n  \"ngram_max\": 4,\n  \"loss\": \"log_loss\",\n  \"l1_ratio\": 0.02541912674409519,\n  \"alpha\": 2.1070472806578224e-05,\n  \"learning_rate\": \"invscaling\",\n  \"eta0\": 0.7568292060167615,\n  \"power_t\": 0.4579309401710595,\n  \"threshold\": [\n    0.59,\n    0.79,\n    0.55,\n    0.7000000000000001,\n    0.5,\n    0.72,\n    0.76,\n    0.63,\n    0.7000000000000001,\n    0.77\n  ]\n}\n>>>\n>>> # train model\n>>> args_fp = Path(config.CONFIG_DIR, \"args_opt.json\")\n>>> main.train_model(args_fp, experiment_name=\"baselines\", run_name=\"sgd\")\n2023/06/03 17:52:01 INFO mlflow.tracking.fluent: Experiment with name 'baselines' does not exist. Creating a new experiment.\nRun ID: fbdba0c7cab640bc853611ba6cd75cee\n>>> text = [\n...     \"Let $c,d \\geq 2$ be naturals. Let $\\{a_n\\}$ be the sequence satisfying $a_1 = c, a_{n+1} = a_n^d + c$ for $n = 1,2,\\cdots$.Prove that for any $n \\geq 2$, there exists a prime number $p$ such that $p|a_n$ and $p \\not | a_i$ for $i = 1,2,\\cdots n-1$.\",\n...     \"Let $ABC$ be a triangle with circumcircle $\\Gamma$ and incenter $I$ and let $M$ be the midpoint of $\\overline{BC}$. The points $D$, $E$, $F$ are selected on sides $\\overline{BC}$, $\\overline{CA}$, $\\overline{AB}$ such that $\\overline{ID} \\perp \\overline{BC}$, $\\overline{IE}\\perp \\overline{AI}$, and $\\overline{IF}\\perp \\overline{AI}$. Suppose that the circumcircle of $\\triangle AEF$ intersects $\\Gamma$ at a point $X$ other than $A$. Prove that lines $XD$ and $AM$ meet on $\\Gamma$.\",\n...     \"Find all functions $f:(0,\\infty)\\rightarrow (0,\\infty)$ such that for any $x,y\\in (0,\\infty)$, $$xf(x^2)f(f(y)) + f(yf(x)) = f(xy) \\left(f(f(x^2)) + f(f(y^2))\\right).$$\",\n...     \"Let $n$ be an even positive integer. We say that two different cells of a $n \\times n$ board are [b]neighboring[/b] if they have a common side. Find the minimal number of cells on the $n \\times n$ board that must be marked so that any cell (marked or not marked) has a marked neighboring cell.\"\n... ]\n>>> main.predict_tag(text=text)\n[\n  {\n    \"input_text\": \"Let $c,d \\\\geq 2$ be naturals. Let $\\\\{a_n\\\\}$ be the sequence satisfying $a_1 = c, a_{n+1} = a_n^d + c$ for $n = 1,2,\\\\cdots$.Prove that for any $n \\\\geq 2$, there exists a prime number $p$ such that $p|a_n$ and $p \\not | a_i$ for $i = 1,2,\\\\cdots n-1$.\",\n    \"predicted_tags\": [\n      \"number theory\"\n    ]\n  },\n  {\n    \"input_text\": \"Let $ABC$ be a triangle with circumcircle $\\\\Gamma$ and incenter $I$ and let $M$ be the midpoint of $\\\\overline{BC}$. The points $D$, $E$, $F$ are selected on sides $\\\\overline{BC}$, $\\\\overline{CA}$, $\\\\overline{AB}$ such that $\\\\overline{ID} \\\\perp \\\\overline{BC}$, $\\\\overline{IE}\\\\perp \\\\overline{AI}$, and $\\\\overline{IF}\\\\perp \\\\overline{AI}$. Suppose that the circumcircle of $\\triangle AEF$ intersects $\\\\Gamma$ at a point $X$ other than $A$. Prove that lines $XD$ and $AM$ meet on $\\\\Gamma$.\",\n    \"predicted_tags\": [\n      \"geometry\"\n    ]\n  },\n  {\n    \"input_text\": \"Find all functions $f:(0,\\\\infty)\\rightarrow (0,\\\\infty)$ such that for any $x,y\\\\in (0,\\\\infty)$, $$xf(x^2)f(f(y)) + f(yf(x)) = f(xy) \\\\left(f(f(x^2)) + f(f(y^2))\\right).$$\",\n    \"predicted_tags\": [\n      \"algebra\",\n      \"function\"\n    ]\n  },\n  {\n    \"input_text\": \"Let $n$ be an even positive integer. We say that two different cells of a $n \\times n$ board are [b]neighboring[/b] if they have a common side. Find the minimal number of cells on the $n \\times n$ board that must be marked so that any cell (marked or not marked) has a marked neighboring cell.\",\n    \"predicted_tags\": [\n      \"combinatorics\"\n    ]\n  }\n]\n>>> exit()\n```", "```py\n$ mlflow ui --backend-store-uri stores/model\n```", "```py\n$ git add .\n$ git commit -m \"Initial commit\"\n$ git push origin code_migration\n```"]