- en: How strongly associated are your variables?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-strongly-associated-are-your-variables-80493127b3a2](https://towardsdatascience.com/how-strongly-associated-are-your-variables-80493127b3a2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Use Cramer’s V test to check how strongly associated are two categorical variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://gustavorsantos.medium.com/?source=post_page-----80493127b3a2--------------------------------)[![Gustavo
    Santos](../Images/a19a9f4525cdeb6e7a76cd05246aa622.png)](https://gustavorsantos.medium.com/?source=post_page-----80493127b3a2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----80493127b3a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----80493127b3a2--------------------------------)
    [Gustavo Santos](https://gustavorsantos.medium.com/?source=post_page-----80493127b3a2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----80493127b3a2--------------------------------)
    ·7 min read·Feb 28, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f1fcc9151c3e67267cfaafc6bc6af713.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Susan Holt Simpson](https://unsplash.com/pt-br/@shs521?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/H7SCRwU1aiM?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Feature selection is an important step for any data science project. I can
    imagine you heard it a million times if you’re not new to the field, and I am
    sure you already heard it if you’re a newbie, but I will say it again: *If you
    feed your model with garbage, you will collect garbage as a result.*'
  prefs: []
  type: TYPE_NORMAL
- en: Ok, now that we took that our of our chest, let’s move on. There are a couple
    of good ways to select the best features for you model, like running a Random
    Forest model and then checking the `feature_importances_` attribute, using sklearn’s`SelectKBest`,
    performing statistical tests separately, and other techniques.
  prefs: []
  type: TYPE_NORMAL
- en: These automated tests from **sklearn** are very handy and excellent options
    for us to make our feature selection fastly. They are an automated way to use
    statistical tests like F-Test, correlation, chi squared and quickly perform hypothesis
    tests to choose variables based on the results.
  prefs: []
  type: TYPE_NORMAL
- en: When we’re talking about categorical variables, for example, if we run the `SelectKBest`,
    we’ll have to use the scoring function `chi2` to find out if the p-values are
    under the threshold for statistical significance of the dependency of the variables.
  prefs: []
  type: TYPE_NORMAL
- en: Ho = The variables are independent
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Ha = The variables are not independent
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A common significance level used is 0.05.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, the returned value is only the p-value and test statistic. This means
    that the tool aims for giving us only the quick result, such as a p-value under
    the threshold, confirming we have evidence to reject the null-hypothesis and pointing
    to both categorical variables being dependent. But it won’t tell you how strong
    is this association.
  prefs: []
  type: TYPE_NORMAL
- en: An easy workaround is to **perform the Cramer’s V test**, to be presented in
    this post.
  prefs: []
  type: TYPE_NORMAL
- en: Before we continue, let me present the dataset used for the examples in this
    post. It’s the *diamonds* dataset, an open sample data from the Seaborn package.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/bf4ffed1e594dc516b6140497de6e32a.png)'
  prefs: []
  type: TYPE_IMG
- en: Diamonds Dataset from seaborn. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: This dataset has observations of diamonds cuts, color, size, carat and prices.
    **Our intention is to check the association between the categorical variables**
    `**cut, color, clarity**` **and the** `**price**`.
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to import the packages to code along.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Using Select K Best
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ok, once we introduced the dataset and the test to be performed by the `SelectKBest`
    tool, let’s see how it works and the results from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, as we will check the association between two categorical variables,
    let’s make the `price` variable become categorical. For that, I will separate
    the prices of the diamonds in bins:'
  prefs: []
  type: TYPE_NORMAL
- en: '**cheaper**: From 0 to 20% under the average'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**on_average**: From Avg - 20% to the average'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**high_price**: From the Average to Avg + 20%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**expensive**: From Avg + 20% to the max value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This is how it will look like.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/088a0284000baa26199a2b3ea44a1430.png)'
  prefs: []
  type: TYPE_IMG
- en: price_bins variable added. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will have the data split in X (explanatory) and y (explained).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the sequence, we select the categorical variables and encode the values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With this, we’ll be ready to fit the data and extract the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The resulting data frame is in the next picture.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/adfae2866986197dfc1d6e164fd15ef0.png)'
  prefs: []
  type: TYPE_IMG
- en: Results of the `SelectKBest` tool. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: That is great! Now we can see that the 3 features are dependent on the prices
    with statistical significance of 95% (*p-values < 0.05; reject Ho*). But how can
    we make sure that those associations are strong or not?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s perform the Cramer’s V test and find out.
  prefs: []
  type: TYPE_NORMAL
- en: Cramer’s V test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we do a quick research, we will find out that:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cramer’s V** is a measure of association between two categorical variables
    that returns a value between 0 (weak) and 1 (strong).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To perform it in Python, we need `Pandas` to create a contingency table and
    `scipy` to run the Chi² test, that will lead to the final calculation of the V
    number.
  prefs: []
  type: TYPE_NORMAL
- en: Ok, so from our dataset, let’s create a contingency table between `cut` and
    our recently created variable `price_bins`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Next, is the resulting contingency table. This is nothing more than calculating
    how many observations are present in each pair of association. For example, there
    are 14,181 diamonds with an “Ideal” cut and “cheaper” price. 735 diamonds are
    “Premium” cut and have a price “on average”.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68aa5e79837398a3eb24e86aaf84ebd8.png)'
  prefs: []
  type: TYPE_IMG
- en: Contingency table Cut x Price Bins. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform the Chi² now, we will use the function`chi2_contingency` from `scipy`.
    So we pass the contingency table to the function. It returns a lot of interesting
    information: (1) Chi² statistic; (2) p-value; (3) Degrees of freedom; and(4) expected
    values. As we need only the Chi² for this test, we take the first index `chi_stat
    = X2[0]`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s calculate the Cramer’s V value. The formula for V is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/00d13b7aa3e62417c7dbb910a3365e30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'V formula: X² is the chi squared statistic; N is the sample size; k is the
    minimum number between the number of categories in rows and columns.'
  prefs: []
  type: TYPE_NORMAL
- en: In Python, the calculation is performed with the next code snippet.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Cramer’s V strength value for the association between the Cut and the Price
    bins is 0.099, or 9.9%, which can be understood as something between a small to
    medium effect (see the [table for values interpretation here](https://www.statology.org/interpret-cramers-v/))
    for 3 degrees of freedom (`minimum_dimension = 3`).
  prefs: []
  type: TYPE_NORMAL
- en: 'For `clarity` , here’s the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: For `clarity`, the number 0.18 is around the medium strength. For `color`, V
    = 0.115, also in the small effect range.
  prefs: []
  type: TYPE_NORMAL
- en: Before You Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This subject called my attention because, indeed, many times we just go for
    automated solutions like sklearn’s `SelectKBest` and we take for granted their
    p-value as the single criterium to decide which variable to use for our model.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you got to the end of this post, you have another statistical tool
    to select the best variables for a model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary:'
  prefs: []
  type: TYPE_NORMAL
- en: Select two categorical variables
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a contingency table with `pd.crosstab()`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `scs.chi2_contingency(contingency_table)` to collect the Chi² statistic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate Cramer’s V: `np.sqrt((chi_stat/N) / minimum_dimension)`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/gurezende/Studying/blob/master/Python/statistics/Cramers_V.ipynb?source=post_page-----80493127b3a2--------------------------------)
    [## Studying/Cramers_V.ipynb at master · gurezende/Studying'
  prefs: []
  type: TYPE_NORMAL
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab or…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/gurezende/Studying/blob/master/Python/statistics/Cramers_V.ipynb?source=post_page-----80493127b3a2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: If you liked this content, [follow my blog for more](http://gustavorsantos.medium.com/).
    Find me on [Linkedin](https://www.linkedin.com/in/gurezende/).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[## Cramér''s V - Wikipedia'
  prefs: []
  type: TYPE_NORMAL
- en: From Wikipedia, the free encyclopedia In statistics, Cramér's V (sometimes referred
    to as Cramér's phi and denoted as )…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: en.wikipedia.org](https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V?source=post_page-----80493127b3a2--------------------------------)
    [](https://www.statology.org/interpret-cramers-v/?source=post_page-----80493127b3a2--------------------------------)
    [## How to Interpret Cramer's V (With Examples) - Statology
  prefs: []
  type: TYPE_NORMAL
- en: 'It ranges from 0 to 1 where: 0 indicates no association between the two variables.
    1 indicates a perfect association…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.statology.org](https://www.statology.org/interpret-cramers-v/?source=post_page-----80493127b3a2--------------------------------)
    [](/contingency-tables-chi-squared-and-cramers-v-ada4f93ec3fd?source=post_page-----80493127b3a2--------------------------------)
    [## Contingency Tables, Chi-Squared and Cramer’s V
  prefs: []
  type: TYPE_NORMAL
- en: How to easily check for associations between categoricals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/contingency-tables-chi-squared-and-cramers-v-ada4f93ec3fd?source=post_page-----80493127b3a2--------------------------------)
    [](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html?source=post_page-----80493127b3a2--------------------------------)
    [## scipy.stats.chi2_contingency - SciPy v1.10.1 Manual
  prefs: []
  type: TYPE_NORMAL
- en: Chi-square test of independence of variables in a contingency table. This function
    computes the chi-square statistic…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: docs.scipy.org](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html?source=post_page-----80493127b3a2--------------------------------)
    [](https://www.statology.org/interpret-cramers-v/?source=post_page-----80493127b3a2--------------------------------)
    [## How to Interpret Cramer's V (With Examples) - Statology
  prefs: []
  type: TYPE_NORMAL
- en: 'It ranges from 0 to 1 where: 0 indicates no association between the two variables.
    1 indicates a perfect association…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.statology.org](https://www.statology.org/interpret-cramers-v/?source=post_page-----80493127b3a2--------------------------------)
    [](https://www.spss-tutorials.com/cramers-v-what-and-why/?source=post_page-----80493127b3a2--------------------------------)
    [## Cramér's V - Beginners Tutorial
  prefs: []
  type: TYPE_NORMAL
- en: Cramér's V is a number between 0 and 1 that indicates how strongly two categorical
    variables are associated. If we'd…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.spss-tutorials.com](https://www.spss-tutorials.com/cramers-v-what-and-why/?source=post_page-----80493127b3a2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
