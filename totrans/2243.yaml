- en: Unveiling the Precision@N and Recall@N in Recommender System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unveiling-the-precision-n-and-recall-n-in-recommender-system-7a4c6b69d060](https://towardsdatascience.com/unveiling-the-precision-n-and-recall-n-in-recommender-system-7a4c6b69d060)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Optimizing Recommender: Deeper Interpretation of Precision and Recall Use Case'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@christienatashia?source=post_page-----7a4c6b69d060--------------------------------)[![Christie
    Natashia](../Images/168aa61f8495c7f3a3eccb880c8a023c.png)](https://medium.com/@christienatashia?source=post_page-----7a4c6b69d060--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7a4c6b69d060--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7a4c6b69d060--------------------------------)
    [Christie Natashia](https://medium.com/@christienatashia?source=post_page-----7a4c6b69d060--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7a4c6b69d060--------------------------------)
    ·7 min read·Jun 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/82d0300f568aaadbebfc1c9e9808d001.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Norbert Braun](https://unsplash.com/@medion4you?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**The main topics for discussion are:**'
  prefs: []
  type: TYPE_NORMAL
- en: Precision and Recall in a Nutshell
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fitting Precision and Recall Definition to Recommendation Use Case
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Need for Binary Preference Transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Problem of Impractical Recall
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Solution of Impractical Recall: Top-N items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Illustrative Implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code Implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Introduction**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Accuracy Metrics are a useful metric for assessing the overall performance in
    machine learning, it represents the proportion of correctly classified instances
    within a dataset. Evaluation metrics in conjunction with accuracy such as precision
    and recall are used to gain a more comprehensive understanding of a model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: In general, Precision and Recall compare the predicted class to the actual class
    of the test set and calculate the ratio of correct predictions to the total number
    of predictions made.
  prefs: []
  type: TYPE_NORMAL
- en: Precision and Recall in a Classification Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a supervised classification problem, the target value (y value) must be binary
    (though classification problem is not limited to multi-binary value). *For instance,
    benign or malignant, good or bad, and spam or not spam.* These binary values allow
    the application of precision and recall to measure the correctness of the model
    to classify predicted values.
  prefs: []
  type: TYPE_NORMAL
- en: Precision measures the proportion of correctly predicted positive instances
    (true positives) out of all instances predicted as positive
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6b31b56671d0939745d298df0209680a.png)'
  prefs: []
  type: TYPE_IMG
- en: Recall measures the proportion of correctly predicted positive instances (true
    positives) out of all actual positive instances in the dataset
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/376d5d50e10f51c46cd2951b45ea3071.png)'
  prefs: []
  type: TYPE_IMG
- en: Both precision and recall provide complementary insights into a model’s performance.
    While precision focuses on the accuracy of positive predictions, recall focuses
    on the model’s ability to find all positive instances.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fitting Precision and Recall Definition to Recommendation Use Case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When constructing a recommender model, our expectation is the model can provide
    accurate item recommendations. Classification accuracy metrics measure the performance
    of a model by quantifying the percentage of correctly predicted instances out
    of the total number of instances in the dataset. However, In the context of recommendation
    systems, it is typical for the target value to be represented by rating scales,
    such as the 1–5 star rating for movies.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, to make precision and recall appropriately usable in the recommender task,
    it is necessary to convert the rating scale to binary preferences. This is commonly
    achieved by transforming the rating scale into a distinction between “relevant”
    and “irrelevant” items.
  prefs: []
  type: TYPE_NORMAL
- en: The Need for Binary Preference Transformation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this stage, it is important to establish a clear cutoff point. To do this,
    we assume that any rating above 4 is considered to relevant item, and any rating
    below 4 is deemed irrelevant (cut off of 4 is just a threshold value I choose,
    the value can vary depending on the requirements of each use cases)
  prefs: []
  type: TYPE_NORMAL
- en: At this point, this illustration can assist in gaining a comprehensive understanding
    of why transforming to binary preference can bring a sense of the accuracy metrics
    like precision and recall feasible in the recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc4ce4c893e1387afd8cf7244a02cfd5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image illustrated by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**The Problem of Impractical Recall**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: However, according to this [article](https://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf)
    [1],
  prefs: []
  type: TYPE_NORMAL
- en: R**ecall is almost always impractical to measure in a recommender system. In
    the pure sense, measuring recall requires knowing whether each item is relevant;
    for a movie recommender, this would involve asking many users to view all 5000
    movies (in the movie database) to measure how successfully we recommend each one
    to each user —** Herlocker et al. (2004)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To simplify the statement above, it is imposible, for instance, movie platforms
    like Netflix to ask all users to watch 5000 movies in order to measure the accuracy
    in recommending movies. Due to the vast difference between the number of items
    rated by each user and the total number of items in the dataset, the recall rate
    tends to be relatively low as well.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the **solution to the** statement above should focus on recommending
    the top-5/top-10 movie list to the user. Considering that it’s neither practical
    nor feasible to suggest all available movies in the database to each user.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Solution** of Impractical Recall: **Top-N items**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is where Top-N items can be an appropriate way to **make use of** precision
    and recall metrics for recommendation system. It should predict the top N items
    for **which users give rating**. Where N is an integer that corresponds to the
    top-N recommendation objective.
  prefs: []
  type: TYPE_NORMAL
- en: This can be done by splitting the dataset into train and test sets. The training
    set is used to train the algorithm, then in the next step, the test set will be
    used to make predictions of the top N items. To this end, **precision@N** and
    **recall@N** metrics are employed. This approach enables a more relevant and accurate
    evaluation of the system’s performance in recommending the most pertinent items
    to the user.
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision@N**: How many of the top N recommended items are relevant to the
    user. The 80% of precision@10 means model there were provided 10 recommended movies
    available, but only 8 are actually user’s preference'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`**Precision = (relavent_item_recommended in top-N) / (n_recommended_item)**`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Recall@K**: How many of the relevant items in the dataset were included in
    the top N recommended items by the system. The 60% of recall@10 means that 60%
    of the total number of the relevant items appear in the top-N results.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`**Recall = (relavent_item_recommended in top-N) / (relevant_item)**`'
  prefs: []
  type: TYPE_NORMAL
- en: By this stage, I hope you understand the definition of Relevant and Recommended
    definition (with the assumption of 4 stars is set as the cut-off)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b96d8368bcd2a7c8fa92657c95e132bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image illustrated by Author
  prefs: []
  type: TYPE_NORMAL
- en: An Illustrative Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As discussed above, here are the steps needed:'
  prefs: []
  type: TYPE_NORMAL
- en: Set the threshold cut-off (*if 4 stars is set as the cut-off, any rating above
    4 is considered to relevant item, and any rating below 4 is deemed irrelevant,
    and it applies the same to recommended/not recommended*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transform rating data into binary preferences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting the ’N’ for Precision@N and Recall@N
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate Individual Precision@N and Recall@N
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/c8052157ba1becf50dbb6b4ae57c8795.png)'
  prefs: []
  type: TYPE_IMG
- en: Image illustrated by Author
  prefs: []
  type: TYPE_NORMAL
- en: Code Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you wish to build a recommendation system from scratch, you can refer to
    my previous writing where you can gain an understanding of the mathematical concept
    behind the recommender system. However, if you are well exposed to recommender
    tasks, you can skip this one.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/recommendation-system-with-matrix-factorization-ebc4736869e4?source=post_page-----7a4c6b69d060--------------------------------)
    [## Recommendation System with Matrix Factorization'
  prefs: []
  type: TYPE_NORMAL
- en: The Concept Behind Matrix Factorization and Practical Implementation in Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/recommendation-system-with-matrix-factorization-ebc4736869e4?source=post_page-----7a4c6b69d060--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Back to daaa code!!
  prefs: []
  type: TYPE_NORMAL
- en: Here is the Python snippet for calculating Precision@N and Recall@N. Besides,
    you can access the whole notebook [here](https://github.com/christienatashiaarchie/Precision-N-and-Recall-N-Recommender-System/blob/main/Precision_and_Recall_of_Recomender_Systems_Final.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: 'The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/813fa9b47fd4e6a257043df8b760b4da.png)'
  prefs: []
  type: TYPE_IMG
- en: Output Snippet
  prefs: []
  type: TYPE_NORMAL
- en: Again, the recall value here can be relatively low due to the vast difference
    between the **relevant item that has been recommended by the model** versus **the
    number of items rated by each user** (Although we can onboard a dataset in which
    users have given quite a number of ratings to counter the relatively low recall
    that close to 0).
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, I would like to emphasize an **important** **note** regarding
    recall in recommendation system, which is also supported by the findings of Herlocker
    et al. (2004) [1] as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The recall@N metric should only be used in a comparative fashion on the same
    dataset; it should not be interpreted as an absolute measure
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That sum up my writing about the comprehensive interpretation of Precision@N
    and Recall@N. Aside from that, I have provided a list of valuable papers and articles
    in the reference section that have significantly contributed to my research.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] J.L. Herlocker, J.A. Konstan, L.G. Terveen, J.T. Riedl, Evaluating collaborative
    filtering recommender systems, ACM Trans Inform Syst, 22 (1) (2004), pp. 5–53\.
    Accessible here: [https://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf](https://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/recommendation-system-with-matrix-factorization-ebc4736869e4?source=post_page-----7a4c6b69d060--------------------------------)
    [## Recommendation System with Matrix Factorization'
  prefs: []
  type: TYPE_NORMAL
- en: The Concept Behind Matrix Factorization and Practical Implementation in Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/recommendation-system-with-matrix-factorization-ebc4736869e4?source=post_page-----7a4c6b69d060--------------------------------)
    [](https://github.com/christienatashiaarchie/Precision-N-and-Recall-N-Recommender-System/blob/main/Precision_and_Recall_of_Recomender_Systems_Final.ipynb?source=post_page-----7a4c6b69d060--------------------------------)
    [## Precision-N-and-Recall-N-Recommender-System/Precision_and_Recall_of_Recomender_Systems_Final.ipynb…
  prefs: []
  type: TYPE_NORMAL
- en: Precision@N and Recall@N in Recommender System. Contribute to…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/christienatashiaarchie/Precision-N-and-Recall-N-Recommender-System/blob/main/Precision_and_Recall_of_Recomender_Systems_Final.ipynb?source=post_page-----7a4c6b69d060--------------------------------)  [##
    FAQ - Surprise 1 documentation
  prefs: []
  type: TYPE_NORMAL
- en: You will find here the Frequently Asked Questions, as well as some other use-case
    examples that are not part of the…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: surprise.readthedocs.io](https://surprise.readthedocs.io/en/latest/FAQ.html?source=post_page-----7a4c6b69d060--------------------------------#how-to-compute-precision-k-and-recall-k)
    [](https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54?source=post_page-----7a4c6b69d060--------------------------------)
    [## Recall and Precision at k for Recommender Systems
  prefs: []
  type: TYPE_NORMAL
- en: Detailed Explanation with examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54?source=post_page-----7a4c6b69d060--------------------------------)
  prefs: []
  type: TYPE_NORMAL
