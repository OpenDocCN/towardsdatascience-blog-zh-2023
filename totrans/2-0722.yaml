- en: Deploying a TFLite Model on GCP Serverless
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨ GCP æ— æœåŠ¡å™¨æ¶æ„ä¸Šéƒ¨ç½² TFLite æ¨¡å‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/deploying-tflite-model-on-gcp-serverless-b4cd84f86de1](https://towardsdatascience.com/deploying-tflite-model-on-gcp-serverless-b4cd84f86de1)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/deploying-tflite-model-on-gcp-serverless-b4cd84f86de1](https://towardsdatascience.com/deploying-tflite-model-on-gcp-serverless-b4cd84f86de1)
- en: How to deploy a quantized model in a Serverless fashion
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä»¥æ— æœåŠ¡å™¨çš„æ–¹å¼éƒ¨ç½²é‡åŒ–æ¨¡å‹
- en: '[](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)[![Vishal
    Rajput](../Images/c43407d7df1f099832cbaa5381a0bb74.png)](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4cd84f86de1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4cd84f86de1--------------------------------)
    [Vishal Rajput](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)[![Vishal
    Rajput](../Images/c43407d7df1f099832cbaa5381a0bb74.png)](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4cd84f86de1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4cd84f86de1--------------------------------)
    [Vishal Rajput](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4cd84f86de1--------------------------------)
    Â·11 min readÂ·Jul 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4cd84f86de1--------------------------------)
    Â·é˜…è¯»æ—¶é•¿ 11 åˆ†é’ŸÂ·2023å¹´7æœˆ21æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Model deployment is tricky; with the continuously changing landscape of cloud
    platforms and other AI-related libraries updating almost weekly, back compatibility
    and finding the correct deployment method is a big challenge. In todayâ€™s blog
    post, we will see how to deploy a **tflite model** on the **Google Cloud Platform**
    in a **serverless** fashion.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹éƒ¨ç½²æ˜¯ä¸€ä¸ªæ£˜æ‰‹çš„é—®é¢˜ï¼›ç”±äºäº‘å¹³å°å’Œå…¶ä»–AIç›¸å…³åº“çš„ä¸æ–­å˜åŒ–ï¼Œå‡ ä¹æ¯å‘¨éƒ½æœ‰æ›´æ–°ï¼Œå› æ­¤å‘åå…¼å®¹æ€§å’Œæ‰¾åˆ°æ­£ç¡®çš„éƒ¨ç½²æ–¹æ³•æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚åœ¨ä»Šå¤©çš„åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•ä»¥**æ— æœåŠ¡å™¨**çš„æ–¹å¼åœ¨**Google
    Cloud Platform**ä¸Šéƒ¨ç½²**tfliteæ¨¡å‹**ã€‚
- en: 'This blog post is structured in the following way:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬åšå®¢æ–‡ç« çš„ç»“æ„å¦‚ä¸‹ï¼š
- en: Understanding Serverless and other ways of Deployment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç†è§£æ— æœåŠ¡å™¨æ¶æ„å’Œå…¶ä»–éƒ¨ç½²æ–¹å¼
- en: What is Quantization and TFLite?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯é‡åŒ–å’Œ TFLiteï¼Ÿ
- en: Deploying TFLite model using GCP Cloud Run API
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GCP Cloud Run API éƒ¨ç½² TFLite æ¨¡å‹
- en: '![](../Images/c1719de604d34543f57af5f33b0bf5ce.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1719de604d34543f57af5f33b0bf5ce.png)'
- en: 'Img Src: [https://pixabay.com/photos/man-pier-silhouette-sunrise-fog-8091933/](https://pixabay.com/photos/man-pier-silhouette-sunrise-fog-8091933/)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ç‰‡æ¥æº: [https://pixabay.com/photos/man-pier-silhouette-sunrise-fog-8091933/](https://pixabay.com/photos/man-pier-silhouette-sunrise-fog-8091933/)'
- en: Understanding Serverless and other ways of Deployment
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç†è§£æ— æœåŠ¡å™¨æ¶æ„å’Œå…¶ä»–éƒ¨ç½²æ–¹å¼
- en: '**Letâ€™s first understand what do we mean by serverless because serverless doesnâ€™t
    mean without a server.**'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**é¦–å…ˆè®©æˆ‘ä»¬äº†è§£ä»€ä¹ˆæ˜¯æ— æœåŠ¡å™¨æ¶æ„ï¼Œå› ä¸ºæ— æœåŠ¡å™¨å¹¶ä¸æ„å‘³ç€æ²¡æœ‰æœåŠ¡å™¨ã€‚**'
- en: An AI model, or any application for that matter can be deployed in several different
    ways with three major categorisations.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªAIæ¨¡å‹ï¼Œæˆ–ä»»ä½•åº”ç”¨ç¨‹åºï¼Œå®é™…ä¸Šå¯ä»¥é€šè¿‡å¤šç§ä¸åŒçš„æ–¹å¼è¿›è¡Œéƒ¨ç½²ï¼Œä¸»è¦æœ‰ä¸‰å¤§ç±»ã€‚
- en: '**Serverless:** In this case, the model is stored on the cloud container registry
    and only runs when a user makes a request. When a request is made, a server instance
    is automatically launched to fulfill the user request, which shuts down after
    a while. From starting, configuring, scaling, and shutting down, all of this is
    taken by the Cloud Run API provided by the Google Cloud platform. We have AWS
    Lambda and Azure Functions as alternatives in other clouds.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ— æœåŠ¡å™¨æ¶æ„ï¼š** åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹å­˜å‚¨åœ¨äº‘å®¹å™¨æ³¨å†Œè¡¨ä¸­ï¼Œåªæœ‰åœ¨ç”¨æˆ·å‘å‡ºè¯·æ±‚æ—¶æ‰ä¼šè¿è¡Œã€‚å½“è¯·æ±‚å‘å‡ºæ—¶ï¼Œä¼šè‡ªåŠ¨å¯åŠ¨ä¸€ä¸ªæœåŠ¡å™¨å®ä¾‹æ¥å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼Œå¹¶åœ¨ä¸€æ®µæ—¶é—´åå…³é—­ã€‚ä»å¯åŠ¨ã€é…ç½®ã€æ‰©å±•åˆ°å…³é—­ï¼Œè¿™ä¸€åˆ‡éƒ½ç”±
    Google Cloud å¹³å°æä¾›çš„ Cloud Run API å¤„ç†ã€‚åœ¨å…¶ä»–äº‘å¹³å°ä¸­ï¼Œæˆ‘ä»¬æœ‰ AWS Lambda å’Œ Azure Functions ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆã€‚'
- en: '**Serverless** has its own advantages and disadvantages.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ— æœåŠ¡å™¨æ¶æ„**æœ‰å…¶è‡ªèº«çš„ä¼˜ç¼ºç‚¹ã€‚'
- en: The biggest advantage is the **cost-saving**, if you donâ€™t have a large user
    base, most of the time, the server is sitting idle, and your money is just going
    for no reason. Another advantage is that we donâ€™t need to think about **scaling**
    the infrastructure, depending upon the load on the server, it can automatically
    replicate the number of instances and handle the traffic.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§çš„ä¼˜åŠ¿åœ¨äº**èŠ‚çœæˆæœ¬**ï¼Œå¦‚æœä½ æ²¡æœ‰å¤§é‡çš„ç”¨æˆ·åŸºç¡€ï¼Œå¤§éƒ¨åˆ†æ—¶é—´æœåŠ¡å™¨å¤„äºé—²ç½®çŠ¶æ€ï¼Œä½ çš„é’±åªæ˜¯ç™½ç™½èŠ±è´¹äº†ã€‚å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯æˆ‘ä»¬ä¸éœ€è¦è€ƒè™‘**æ‰©å±•**åŸºç¡€è®¾æ–½ï¼Œæ ¹æ®æœåŠ¡å™¨çš„è´Ÿè½½ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨å¤åˆ¶å®ä¾‹çš„æ•°é‡å¹¶å¤„ç†æµé‡ã€‚
- en: In the disadvantage column, there are three things to consider. It has a **small
    payload limit**, meaning it can be used to run a bigger model. Secondly, the server
    automatically shuts down after 15 min of idle time, thus when we make a request
    after a long time, the first requests take much longer time than the consecutive
    ones, this problem is called **Cold Start Problem**. And lastly, there are **no
    proper GPU-based instances** yet for serverless.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç¼ºç‚¹æ–¹é¢ï¼Œæœ‰ä¸‰ç‚¹éœ€è¦è€ƒè™‘ã€‚é¦–å…ˆæ˜¯**å°è´Ÿè½½é™åˆ¶**ï¼Œè¿™æ„å‘³ç€å®ƒä¸èƒ½ç”¨äºè¿è¡Œæ›´å¤§çš„æ¨¡å‹ã€‚å…¶æ¬¡ï¼ŒæœåŠ¡å™¨åœ¨ 15 åˆ†é’Ÿç©ºé—²åä¼šè‡ªåŠ¨å…³é—­ï¼Œå› æ­¤å½“æˆ‘ä»¬åœ¨å¾ˆé•¿æ—¶é—´åå‘å‡ºè¯·æ±‚æ—¶ï¼Œç¬¬ä¸€æ¬¡è¯·æ±‚æ¯”åç»­è¯·æ±‚èŠ±è´¹çš„æ—¶é—´è¦é•¿ï¼Œè¿™ä¸ªé—®é¢˜è¢«ç§°ä¸º**å†·å¯åŠ¨é—®é¢˜**ã€‚æœ€åï¼Œç›®å‰è¿˜æ²¡æœ‰**é€‚å½“çš„
    GPU åŸºäºå®ä¾‹**å¯ç”¨äºæ— æœåŠ¡å™¨è®¡ç®—ã€‚
- en: '**Server instances:** In this schema, the server is always up and you are always
    paying up the money even if no one requests our application. For applications
    with larger user bases, keeping the server up and running is important. In this
    strategy, we can deploy our apps in multiple ways, one way is to launch a single
    server instance that you scale manually every time the traffic increases. In practice,
    these servers are launched with the help of **Kubernetes** **clusters** which
    define the rule for scaling the infrastructure and do traffic management for us.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœåŠ¡å™¨å®ä¾‹ï¼š** åœ¨è¿™ç§æ¨¡å¼ä¸­ï¼ŒæœåŠ¡å™¨å§‹ç»ˆå¤„äºè¿è¡ŒçŠ¶æ€ï¼Œå³ä½¿æ²¡æœ‰äººè¯·æ±‚æˆ‘ä»¬çš„åº”ç”¨ï¼Œä½ ä¹Ÿæ€»æ˜¯éœ€è¦æ”¯ä»˜è´¹ç”¨ã€‚å¯¹äºç”¨æˆ·åŸºç¡€è¾ƒå¤§çš„åº”ç”¨æ¥è¯´ï¼Œä¿æŒæœåŠ¡å™¨æŒç»­è¿è¡Œæ˜¯å¾ˆé‡è¦çš„ã€‚åœ¨è¿™ç§ç­–ç•¥ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥å¤šç§æ–¹å¼éƒ¨ç½²åº”ç”¨ï¼Œå…¶ä¸­ä¸€ç§æ–¹å¼æ˜¯å¯åŠ¨ä¸€ä¸ªå•ä¸€çš„æœåŠ¡å™¨å®ä¾‹ï¼Œå¹¶åœ¨æµé‡å¢åŠ æ—¶æ‰‹åŠ¨æ‰©å±•ã€‚å®é™…ä¸Šï¼Œè¿™äº›æœåŠ¡å™¨æ˜¯å€ŸåŠ©**Kubernetes**
    **é›†ç¾¤**å¯åŠ¨çš„ï¼Œè¿™äº›é›†ç¾¤å®šä¹‰äº†æ‰©å±•åŸºç¡€è®¾æ–½çš„è§„åˆ™ï¼Œå¹¶ä¸ºæˆ‘ä»¬è¿›è¡Œæµé‡ç®¡ç†ã€‚'
- en: The biggest advantage is that we can work with the biggest-sized models and
    applications and get precise control over our resources, from GPU-based instances
    to regular instances. But managing and scaling these server instances properly
    is quite a big task and often requires a lot of fiddling. These can get super
    expensive for **GPU-based instances** since many AI models require GPU for faster
    inference.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§çš„ä¼˜åŠ¿åœ¨äºæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ€å¤§è§„æ¨¡çš„æ¨¡å‹å’Œåº”ç”¨ï¼Œå¹¶ç²¾ç¡®æ§åˆ¶æˆ‘ä»¬çš„èµ„æºï¼Œä»åŸºäº GPU çš„å®ä¾‹åˆ°å¸¸è§„å®ä¾‹ã€‚ä½†æ­£ç¡®ç®¡ç†å’Œæ‰©å±•è¿™äº›æœåŠ¡å™¨å®ä¾‹æ˜¯ä¸€é¡¹ç›¸å½“å¤§çš„ä»»åŠ¡ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„è°ƒæ•´ã€‚è¿™äº›å¯¹äº**åŸºäº
    GPU çš„å®ä¾‹**æ¥è¯´å¯èƒ½éå¸¸æ˜‚è´µï¼Œå› ä¸ºè®¸å¤š AI æ¨¡å‹éœ€è¦ GPU ä»¥å®ç°æ›´å¿«çš„æ¨ç†ã€‚
- en: 'Two great resources to understand Kubernetes and Docker:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£ Kubernetes å’Œ Docker çš„ä¸¤ä¸ªæå¥½çš„èµ„æºï¼š
- en: '[](https://medium.com/aiguys/docker-for-dummies-8e8edc8af0ea?source=post_page-----b4cd84f86de1--------------------------------)
    [## Docker for dummiesâ€¦ ğŸ³ ğŸ§ ğŸ’¡'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/aiguys/docker-for-dummies-8e8edc8af0ea?source=post_page-----b4cd84f86de1--------------------------------)
    [## Docker å…¥é—¨â€¦ ğŸ³ ğŸ§ ğŸ’¡'
- en: ğŸš€ Dockerize a hello-world node app with me, in 15 mins.
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ğŸš€ å’Œæˆ‘ä¸€èµ·åœ¨ 15 åˆ†é’Ÿå†…å°†ä¸€ä¸ª hello-world èŠ‚ç‚¹åº”ç”¨ç¨‹åº Docker åŒ–ã€‚
- en: 'medium.com](https://medium.com/aiguys/docker-for-dummies-8e8edc8af0ea?source=post_page-----b4cd84f86de1--------------------------------)
    [](https://medium.com/aiguys/kubernetes-101-introduction-to-container-orchestration-b88e60c04ed2?source=post_page-----b4cd84f86de1--------------------------------)
    [## Kubernetes 101: Introduction to Container Orchestration ğŸµ ğŸ³'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/aiguys/docker-for-dummies-8e8edc8af0ea?source=post_page-----b4cd84f86de1--------------------------------)
    [](https://medium.com/aiguys/kubernetes-101-introduction-to-container-orchestration-b88e60c04ed2?source=post_page-----b4cd84f86de1--------------------------------)
    [## Kubernetes 101ï¼šå®¹å™¨ç¼–æ’ä»‹ç» ğŸµ ğŸ³
- en: If you are reading this article, you most likely are to be familiar with the
    concept of containerization, images andâ€¦
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨é˜…è¯»è¿™ç¯‡æ–‡ç« ï¼Œä½ å¾ˆå¯èƒ½å¯¹å®¹å™¨åŒ–ã€é•œåƒç­‰æ¦‚å¿µéå¸¸ç†Ÿæ‚‰â€¦â€¦
- en: medium.com](https://medium.com/aiguys/kubernetes-101-introduction-to-container-orchestration-b88e60c04ed2?source=post_page-----b4cd84f86de1--------------------------------)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/aiguys/kubernetes-101-introduction-to-container-orchestration-b88e60c04ed2?source=post_page-----b4cd84f86de1--------------------------------)
- en: '**Edge Deployment:** When we need the fastest response in places without internet,
    we go with edge deployment. This deployment type is meant for **IoT devices**
    and other smaller devices that do not have large memory or connection with the
    internet. For instance, if we want AI in a drone, we want the AI module to be
    deployed in the drone itself, not on some cloud server.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¾¹ç¼˜éƒ¨ç½²ï¼š** å½“æˆ‘ä»¬éœ€è¦åœ¨æ²¡æœ‰äº’è”ç½‘çš„åœ°æ–¹è·å¾—æœ€å¿«å“åº”æ—¶ï¼Œæˆ‘ä»¬é€‰æ‹©è¾¹ç¼˜éƒ¨ç½²ã€‚è¿™ç§éƒ¨ç½²ç±»å‹é€‚ç”¨äº**IoT è®¾å¤‡**å’Œå…¶ä»–æ²¡æœ‰å¤§å†…å­˜æˆ–äº’è”ç½‘è¿æ¥çš„å°å‹è®¾å¤‡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›åœ¨æ— äººæœºä¸Šä½¿ç”¨
    AIï¼Œæˆ‘ä»¬å¸Œæœ› AI æ¨¡å—éƒ¨ç½²åœ¨æ— äººæœºæœ¬èº«ä¸Šï¼Œè€Œä¸æ˜¯æŸä¸ªäº‘æœåŠ¡å™¨ä¸Šã€‚'
- en: This deployment type can only handle a very small payload due to the devices'
    hardware-based limitation. In this deployment mode, there is zero cost because
    everything runs locally. Making models small enough to fit on an IoT device is
    quite challenging and requires a completely new set of strategies.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºè®¾å¤‡çš„ç¡¬ä»¶é™åˆ¶ï¼Œè¿™ç§éƒ¨ç½²ç±»å‹åªèƒ½å¤„ç†éå¸¸å°çš„è´Ÿè½½ã€‚åœ¨è¿™ç§éƒ¨ç½²æ¨¡å¼ä¸‹ï¼Œæ²¡æœ‰æˆæœ¬ï¼Œå› ä¸ºä¸€åˆ‡éƒ½åœ¨æœ¬åœ°è¿è¡Œã€‚ä½¿æ¨¡å‹å°åˆ°è¶³ä»¥é€‚åº” IoT è®¾å¤‡æ˜¯ç›¸å½“å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå¹¶ä¸”éœ€è¦å®Œå…¨ä¸åŒçš„ç­–ç•¥ã€‚
- en: Deployment strategies have a ton of things; covering in one blog is almost impossible.
    Hereâ€™s another good blog giving an overview of the entire MLOPS strategies.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: éƒ¨ç½²ç­–ç•¥æœ‰å¾ˆå¤šå†…å®¹ï¼›åœ¨ä¸€ä¸ªåšå®¢ä¸­å‡ ä¹ä¸å¯èƒ½è¦†ç›–æ‰€æœ‰å†…å®¹ã€‚è¿™é‡Œæœ‰å¦ä¸€ä¸ªå¾ˆå¥½çš„åšå®¢æä¾›äº†æ•´ä¸ª MLOPS ç­–ç•¥çš„æ¦‚è¿°ã€‚
- en: '[](https://medium.com/aiguys/mlops-deploying-and-managing-models-at-scale-9a51f8fc0406?source=post_page-----b4cd84f86de1--------------------------------)
    [## MLOps: Managing AI models at Scale'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/aiguys/mlops-deploying-and-managing-models-at-scale-9a51f8fc0406?source=post_page-----b4cd84f86de1--------------------------------)
    [## MLOpsï¼šå¤§è§„æ¨¡ç®¡ç† AI æ¨¡å‹'
- en: Model building is excellent, but if we canâ€™t deploy these models then it becomes
    useless. Unlike Deep learning, findingâ€¦
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ„å»ºå¾ˆå‡ºè‰²ï¼Œä½†å¦‚æœæˆ‘ä»¬ä¸èƒ½éƒ¨ç½²è¿™äº›æ¨¡å‹ï¼Œå®ƒä»¬å°±ä¼šå˜å¾—æ— ç”¨ã€‚ä¸æ·±åº¦å­¦ä¹ ä¸åŒï¼Œæ‰¾åˆ°â€¦â€¦
- en: medium.com](https://medium.com/aiguys/mlops-deploying-and-managing-models-at-scale-9a51f8fc0406?source=post_page-----b4cd84f86de1--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/aiguys/mlops-deploying-and-managing-models-at-scale-9a51f8fc0406?source=post_page-----b4cd84f86de1--------------------------------)
- en: What is Quantization and TFLite?
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯é‡åŒ–å’Œ TFLiteï¼Ÿ
- en: '**Quantization** is a model compression technique in which we convert our weights
    to lower precision to **reduce the size of the model** thus making our models
    smaller and faster at inference. Quantization can greatly improve **speed** and
    is often used for edge deployment. Deploying a quantized model in a serverless
    fashion can be great cost-saving as this makes the AI model small enough to be
    used in a serverless fashion.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**é‡åŒ–**æ˜¯ä¸€ç§æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼Œåœ¨è¿™ç§æŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬å°†æƒé‡è½¬æ¢ä¸ºè¾ƒä½çš„ç²¾åº¦ï¼Œä»¥**å‡å°æ¨¡å‹çš„å¤§å°**ï¼Œä»è€Œä½¿æ¨¡å‹åœ¨æ¨æ–­æ—¶æ›´å°ã€æ›´å¿«ã€‚é‡åŒ–å¯ä»¥æ˜¾è‘—æé«˜**é€Ÿåº¦**ï¼Œå¹¶ä¸”é€šå¸¸ç”¨äºè¾¹ç¼˜éƒ¨ç½²ã€‚åœ¨æ— æœåŠ¡å™¨æ¨¡å¼ä¸‹éƒ¨ç½²é‡åŒ–æ¨¡å‹å¯ä»¥å¤§å¤§èŠ‚çœæˆæœ¬ï¼Œå› ä¸ºè¿™ä½¿å¾—
    AI æ¨¡å‹å°åˆ°è¶³ä»¥åœ¨æ— æœåŠ¡å™¨æ¨¡å¼ä¸‹ä½¿ç”¨ã€‚'
- en: '**NOTE:** People often think they need GPU instances to serve the AI models
    as they used GPU instances to train them, but thatâ€™s not true. Most AI applications
    with CPU instances and proper deployment strategy can serve even a billion users.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** äººä»¬å¸¸å¸¸è®¤ä¸ºéœ€è¦ GPU å®ä¾‹æ¥æœåŠ¡ AI æ¨¡å‹ï¼Œå› ä¸ºä»–ä»¬ç”¨ GPU å®ä¾‹è®­ç»ƒäº†è¿™äº›æ¨¡å‹ï¼Œä½†è¿™å¹¶ä¸æ­£ç¡®ã€‚å¤§å¤šæ•° AI åº”ç”¨ç¨‹åºé€šè¿‡ CPU
    å®ä¾‹å’Œé€‚å½“çš„éƒ¨ç½²ç­–ç•¥å¯ä»¥æœåŠ¡ç”šè‡³åäº¿ç”¨æˆ·ã€‚'
- en: Quantization is one of many ways to compress model size, there are a lot of
    other methodologies like pruning, weight sharing, etc.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: é‡åŒ–æ˜¯å‹ç¼©æ¨¡å‹å¤§å°çš„ä¼—å¤šæ–¹æ³•ä¹‹ä¸€ï¼Œè¿˜æœ‰å¾ˆå¤šå…¶ä»–æ–¹æ³•ï¼Œå¦‚å‰ªæã€æƒé‡å…±äº«ç­‰ã€‚
- en: 'Hereâ€™s an article detailing all the **model compression techniques**:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ç¯‡æ–‡ç« è¯¦ç»†ä»‹ç»äº†æ‰€æœ‰çš„**æ¨¡å‹å‹ç¼©æŠ€æœ¯**ï¼š
- en: '[](https://medium.com/aiguys/reducing-deep-learning-size-16bed87cccff?source=post_page-----b4cd84f86de1--------------------------------)
    [## Deep learning model compression'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/aiguys/reducing-deep-learning-size-16bed87cccff?source=post_page-----b4cd84f86de1--------------------------------)
    [## æ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©'
- en: With each passing year, models are getting more complex and bigger. A lot of
    AI models developed in research labs neverâ€¦
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: éšç€æ¯å¹´æ¨¡å‹å˜å¾—è¶Šæ¥è¶Šå¤æ‚å’Œåºå¤§ã€‚å¾ˆå¤šåœ¨ç ”ç©¶å®éªŒå®¤å¼€å‘çš„ AI æ¨¡å‹ä»æœªâ€¦â€¦
- en: medium.com](https://medium.com/aiguys/reducing-deep-learning-size-16bed87cccff?source=post_page-----b4cd84f86de1--------------------------------)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/aiguys/reducing-deep-learning-size-16bed87cccff?source=post_page-----b4cd84f86de1--------------------------------)
- en: What is TFLite
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ TFLite
- en: According to the TensorFlow website, â€œTensorFlow Lite is a set of tools that
    enables on-device machine learning by helping developers run their models on mobile,
    embedded, and edge devices.â€
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ® TensorFlow ç½‘ç«™ï¼Œâ€œTensorFlow Lite æ˜¯ä¸€å¥—å·¥å…·ï¼Œé€šè¿‡å¸®åŠ©å¼€å‘è€…åœ¨ç§»åŠ¨è®¾å¤‡ã€åµŒå…¥å¼è®¾å¤‡å’Œè¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œæ¨¡å‹ï¼Œå®ç°è®¾å¤‡ä¸Šçš„æœºå™¨å­¦ä¹ ã€‚â€
- en: There are many ways to quantize AI models; two main categorizations are **post-training
    quantization and quantization-aware training**. In the prior one, we normally
    train our models. After the training is complete, quantization is applied to model
    weights, whereas for the latter, during the training itself, quantization is active.
    Usually, quantized-aware training performs better than post-training quantization.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: é‡åŒ– AI æ¨¡å‹çš„æ–¹æ³•æœ‰å¾ˆå¤šï¼›ä¸»è¦åˆ†ä¸º **è®­ç»ƒåé‡åŒ–å’Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒ** ä¸¤ç±»ã€‚åœ¨å‰è€…ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å…ˆè®­ç»ƒæ¨¡å‹ã€‚è®­ç»ƒå®Œæˆåï¼Œå¯¹æ¨¡å‹æƒé‡åº”ç”¨é‡åŒ–ï¼Œè€Œåœ¨åè€…ä¸­ï¼Œé‡åŒ–åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°±å·²ç»æ¿€æ´»ã€‚é€šå¸¸ï¼Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒçš„æ•ˆæœä¼˜äºè®­ç»ƒåé‡åŒ–ã€‚
- en: Letâ€™s directly jump into the code for quantization. We are using a post-training
    quantized image segmentation model for this blog. Given below image shows the
    architecture of our AI Pipeline.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç›´æ¥è·³åˆ°é‡åŒ–ä»£ç éƒ¨åˆ†ã€‚æˆ‘ä»¬åœ¨è¿™ä¸ªåšå®¢ä¸­ä½¿ç”¨çš„æ˜¯è®­ç»ƒåé‡åŒ–çš„å›¾åƒåˆ†å‰²æ¨¡å‹ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†æˆ‘ä»¬ AI ç®¡é“çš„æ¶æ„ã€‚
- en: '![](../Images/e7a7de87920f7d11c6a6c85a15be31e8.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7a7de87920f7d11c6a6c85a15be31e8.png)'
- en: 'AI Pipeline architecture (Img Src: Belongs to author)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: AI ç®¡é“æ¶æ„ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…æ‰€æœ‰ï¼‰
- en: 'Iâ€™m making the following assumptions here:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œåšå‡ºä»¥ä¸‹å‡è®¾ï¼š
- en: You already have an image segmentation model saved in .hdf5 or .h5 format.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å·²ç»æœ‰ä¸€ä¸ªä»¥ .hdf5 æˆ– .h5 æ ¼å¼ä¿å­˜çš„å›¾åƒåˆ†å‰²æ¨¡å‹ã€‚
- en: 'If not, follow this tutorial from Keras official website: [https://keras.io/examples/vision/oxford_pets_image_segmentation/](https://keras.io/examples/vision/oxford_pets_image_segmentation/)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸æ˜¯ï¼Œè¯·å‚é˜… Keras å®˜æ–¹ç½‘ç«™çš„æ•™ç¨‹ï¼š[https://keras.io/examples/vision/oxford_pets_image_segmentation/](https://keras.io/examples/vision/oxford_pets_image_segmentation/)
- en: You have a variable called ***train_input_img_paths*** storing paths to all
    the training images. Once again, you can follow the Keras official example link
    of Step 1.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨æœ‰ä¸€ä¸ªåä¸º ***train_input_img_paths*** çš„å˜é‡ï¼Œç”¨äºå­˜å‚¨æ‰€æœ‰è®­ç»ƒå›¾åƒçš„è·¯å¾„ã€‚æ‚¨å¯ä»¥å†æ¬¡å‚é˜… Keras å®˜æ–¹ç¤ºä¾‹é“¾æ¥çš„ç¬¬
    1 æ­¥ã€‚
- en: If you have your own custom data loaders, modify the ***represetative_dataset()***
    method.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰è‡ªå·±çš„è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨ï¼Œè¯·ä¿®æ”¹ ***represetative_dataset()*** æ–¹æ³•ã€‚
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now we are ready to deploy our TFLite model in a serverless fashion using Google
    Cloud Run API.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡ä½¿ç”¨ Google Cloud Run API ä»¥æ— æœåŠ¡å™¨çš„æ–¹å¼éƒ¨ç½²æˆ‘ä»¬çš„ TFLite æ¨¡å‹ã€‚
- en: Deploying TFLite model using GCP Cloud Run API
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GCP Cloud Run API éƒ¨ç½² TFLite æ¨¡å‹
- en: We need these resources and files to deploy our model and make predictions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦è¿™äº›èµ„æºå’Œæ–‡ä»¶æ¥éƒ¨ç½²æˆ‘ä»¬çš„æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹ã€‚
- en: Dockerfile
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dockerfile
- en: app.py
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: app.py
- en: client.py
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: client.py
- en: requirements.txt
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: requirements.txt
- en: quantized model
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡åŒ–æ¨¡å‹
- en: Letâ€™s first understand the flow of deployment first.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬æ¥ç†è§£éƒ¨ç½²çš„æµç¨‹ã€‚
- en: The serverless deployment flow starts with **containerizing** of our application
    app.py (we use docker here), then **pushing the docker image to a container registry**
    (Google container registry in our case); we need a container registry to ensure
    the versioning, availability, and security of our images. Then configuring and
    deploying it to a serverless platform (Google Cloud Run API), and then allowing
    the platform to handle the execution and scaling of our functions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ— æœåŠ¡å™¨éƒ¨ç½²æµç¨‹ä» **å®¹å™¨åŒ–** åº”ç”¨ç¨‹åº app.pyï¼ˆæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ Dockerï¼‰å¼€å§‹ï¼Œç„¶å **å°† Docker é•œåƒæ¨é€åˆ°å®¹å™¨æ³¨å†Œè¡¨**ï¼ˆåœ¨æˆ‘ä»¬è¿™é‡Œæ˜¯
    Google å®¹å™¨æ³¨å†Œè¡¨ï¼‰ï¼›æˆ‘ä»¬éœ€è¦å®¹å™¨æ³¨å†Œè¡¨æ¥ç¡®ä¿æˆ‘ä»¬é•œåƒçš„ç‰ˆæœ¬æ§åˆ¶ã€å¯ç”¨æ€§å’Œå®‰å…¨æ€§ã€‚æ¥ç€ï¼Œå°†å…¶é…ç½®å¹¶éƒ¨ç½²åˆ°æ— æœåŠ¡å™¨å¹³å°ï¼ˆGoogle Cloud Run
    APIï¼‰ï¼Œç„¶åè®©å¹³å°å¤„ç†æˆ‘ä»¬çš„å‡½æ•°çš„æ‰§è¡Œå’Œæ‰©å±•ã€‚
- en: The serverless mode of deployment abstracts away infrastructure management and
    provides automatic scaling, giving us more time to focus on developing and deploying
    our application code.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ— æœåŠ¡å™¨æ¨¡å¼çš„éƒ¨ç½²å°†åŸºç¡€è®¾æ–½ç®¡ç†æŠ½è±¡åŒ–ï¼Œå¹¶æä¾›è‡ªåŠ¨æ‰©å±•ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿæœ‰æ›´å¤šæ—¶é—´ä¸“æ³¨äºå¼€å‘å’Œéƒ¨ç½²åº”ç”¨ç¨‹åºä»£ç ã€‚
- en: '**Dockerfile**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dockerfile**'
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Overall, this Dockerfile sets up the necessary environment and dependencies
    for running the Flask application (`app.py`) inside a Docker container. It ensures
    that the required Python packages and the pre-trained model file are available
    within the container.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä½“è€Œè¨€ï¼Œè¿™ä¸ª Dockerfile è®¾ç½®äº†è¿è¡Œ Flask åº”ç”¨ç¨‹åºï¼ˆ`app.py`ï¼‰æ‰€éœ€çš„ç¯å¢ƒå’Œä¾èµ–é¡¹ã€‚å®ƒç¡®ä¿åœ¨å®¹å™¨å†…å¯ä»¥ä½¿ç”¨æ‰€éœ€çš„ Python
    åŒ…å’Œé¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ã€‚
- en: '**app.py**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**app.py**'
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**client.py**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**client.py**'
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Note:** When I trained my image segmentation model, I used BGR format (default
    mode of OpenCV); if you used RGB, remove ***line 30*** from the app.py.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** å½“æˆ‘è®­ç»ƒå›¾åƒåˆ†å‰²æ¨¡å‹æ—¶ï¼Œæˆ‘ä½¿ç”¨äº† BGR æ ¼å¼ï¼ˆOpenCV çš„é»˜è®¤æ¨¡å¼ï¼‰ï¼›å¦‚æœæ‚¨ä½¿ç”¨äº† RGBï¼Œè¯·ä» app.py ä¸­åˆ é™¤ ***ç¬¬
    30 è¡Œ***ã€‚'
- en: Also, put your own endpoint URL in client.py ***line 8,*** which you will get
    after successfully deploying the Google Cloud RUN API.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œè¯·åœ¨ client.py çš„ ***ç¬¬ 8 è¡Œ*** ä¸­å¡«å…¥æ‚¨åœ¨æˆåŠŸéƒ¨ç½² Google Cloud RUN API åè·å¾—çš„ç«¯ç‚¹ URLã€‚
- en: And latly, use the same version of Python in your Dockerfile and local environment
    to avoid breaking anything during the deployment.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œä¸ºäº†é¿å…åœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜ï¼Œè¯·åœ¨ Dockerfile å’Œæœ¬åœ°ç¯å¢ƒä¸­ä½¿ç”¨ç›¸åŒç‰ˆæœ¬çš„ Pythonã€‚
- en: '**requirements.txt**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**requirements.txt**'
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Quantized model**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**é‡åŒ–æ¨¡å‹**'
- en: And lastly, we need to keep our **model_quantized_float16.tflite** in the same
    folder as our app.py as we copy our quantized model in our docker image.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬éœ€è¦å°† **model_quantized_float16.tflite** ä¿å­˜åœ¨ä¸ app.py ç›¸åŒçš„æ–‡ä»¶å¤¹ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬å°†é‡åŒ–æ¨¡å‹å¤åˆ¶åˆ°
    Docker é•œåƒä¸­ã€‚
- en: 'This is how my directory looks after collecting all the resources:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘æ”¶é›†æ‰€æœ‰èµ„æºåç›®å½•çš„æ ·å­ï¼š
- en: '![](../Images/3c64d26ef869ef20b754722938704489.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c64d26ef869ef20b754722938704489.png)'
- en: 'Img Src: Belongs to author'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒæ¥æºï¼šå±äºä½œè€…
- en: Setting Up Serverless
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¾ç½®æ— æœåŠ¡å™¨ç¯å¢ƒ
- en: 'The first step is to get the gcloud CLI (Command Line Interface), I used Windows
    itâ€™s pretty straightforward: [https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install)'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥æ˜¯è·å– gcloud CLIï¼ˆå‘½ä»¤è¡Œæ¥å£ï¼‰ï¼Œæˆ‘ä½¿ç”¨äº† Windowsï¼Œæ“ä½œéå¸¸ç®€å•ï¼š[https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install)
- en: 2\. Navigate to your folder using the standard CLI command
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. ä½¿ç”¨æ ‡å‡† CLI å‘½ä»¤å¯¼èˆªåˆ°ä½ çš„æ–‡ä»¶å¤¹
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 3\. Login into gcloud CLI
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. ç™»å½• gcloud CLI
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This will open up a window in your browser and ask for a few permissions, allow
    that.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ä¸€ä¸ªçª—å£ï¼Œå¹¶è¦æ±‚æˆäºˆä¸€äº›æƒé™ï¼Œè¯·å…è®¸ã€‚
- en: 4\. Setup a project in gcloud, better use the GUI interface for this.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. åœ¨ gcloud ä¸­è®¾ç½®é¡¹ç›®ï¼Œæœ€å¥½ä½¿ç”¨ GUI ç•Œé¢ã€‚
- en: 'Hereâ€™s the link to create a GCP project:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯åˆ›å»º GCP é¡¹ç›®çš„é“¾æ¥ï¼š
- en: '[](https://developers.google.com/workspace/guides/create-project?source=post_page-----b4cd84f86de1--------------------------------)
    [## Create a Google Cloud project | Google Workspace | Google for Developers'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://developers.google.com/workspace/guides/create-project?source=post_page-----b4cd84f86de1--------------------------------)
    [## åˆ›å»º Google Cloud é¡¹ç›® | Google Workspace | Google å¼€å‘è€…'
- en: A Google Cloud project is required to use Google Workspace APIs and build Google
    Workspace add-ons or apps. Thisâ€¦
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Google Workspace API å’Œæ„å»º Google Workspace æ’ä»¶æˆ–åº”ç”¨ç¨‹åºéœ€è¦ä¸€ä¸ª Google Cloud é¡¹ç›®ã€‚è¿™...
- en: developers.google.com](https://developers.google.com/workspace/guides/create-project?source=post_page-----b4cd84f86de1--------------------------------)
    ![](../Images/d306e4ddae1d3bba879df811fc98a7fd.png)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: developers.google.com](https://developers.google.com/workspace/guides/create-project?source=post_page-----b4cd84f86de1--------------------------------)
    ![](../Images/d306e4ddae1d3bba879df811fc98a7fd.png)
- en: 'GCP project Dashboard (Img Src: Belongs to author)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: GCP é¡¹ç›®ä»ªè¡¨æ¿ï¼ˆå›¾åƒæ¥æºï¼šå±äºä½œè€…ï¼‰
- en: 5\. Setup project ID in gcloud CLI, you can see your project ID in your dashboard.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. åœ¨ gcloud CLI ä¸­è®¾ç½®é¡¹ç›® IDï¼Œä½ å¯ä»¥åœ¨ä»ªè¡¨æ¿ä¸­çœ‹åˆ°ä½ çš„é¡¹ç›® IDã€‚
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 6\. Build container in gcloud CLI. Replace <PROJECT_ID> everywhere.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. åœ¨ gcloud CLI ä¸­æ„å»ºå®¹å™¨ã€‚å°† <PROJECT_ID> æ›¿æ¢ä¸ºå®é™…é¡¹ç›® IDã€‚
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/52a2c7122581c08fe5dd3009d144c776.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52a2c7122581c08fe5dd3009d144c776.png)'
- en: 'Building container (Img Src: Belongs to author)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºå®¹å™¨ï¼ˆå›¾åƒæ¥æºï¼šå±äºä½œè€…ï¼‰
- en: 7\. Push Docker image to Container registry through gcloud CLI
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. é€šè¿‡ gcloud CLI å°† Docker é•œåƒæ¨é€åˆ°å®¹å™¨æ³¨å†Œè¡¨
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/08f5edf767b9bea3b1e51f7248bbd668.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08f5edf767b9bea3b1e51f7248bbd668.png)'
- en: 'Google Container registry (Img Src: Belongs to author)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Google å®¹å™¨æ³¨å†Œè¡¨ï¼ˆå›¾åƒæ¥æºï¼šå±äºä½œè€…ï¼‰
- en: 8\. Deploy the Coud RUN API through gcloud CLI. This will ask to choose server
    locations and some other authentications, allow all of them.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. é€šè¿‡ gcloud CLI éƒ¨ç½² Cloud RUN APIã€‚è¿™ä¼šè¦æ±‚é€‰æ‹©æœåŠ¡å™¨ä½ç½®å’Œä¸€äº›å…¶ä»–çš„èº«ä»½éªŒè¯ï¼Œå…è®¸æ‰€æœ‰è¿™äº›æ“ä½œã€‚
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/797936fcd94d0d2ef0284ffcb52f90a1.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/797936fcd94d0d2ef0284ffcb52f90a1.png)'
- en: 'Model Deployed (Img Src: Belongs to author)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹å·²éƒ¨ç½²ï¼ˆå›¾åƒæ¥æºï¼šå±äºä½œè€…ï¼‰
- en: If everything is successful, you will see a link in your gcloud CLI, that you
    need to paste into your client.py. Otherwise, go to logs and try to fix the errors.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸€åˆ‡é¡ºåˆ©ï¼Œä½ å°†åœ¨ gcloud CLI ä¸­çœ‹åˆ°ä¸€ä¸ªé“¾æ¥ï¼Œä½ éœ€è¦å°†å…¶ç²˜è´´åˆ° client.py ä¸­ã€‚å¦åˆ™ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—å¹¶å°è¯•ä¿®å¤é”™è¯¯ã€‚
- en: '![](../Images/d0b43da956b78aa1de4600633cebbd39.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d0b43da956b78aa1de4600633cebbd39.png)'
- en: 'Cloud Run API console (Img Src: Belongs to author)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Cloud Run API æ§åˆ¶å°ï¼ˆå›¾åƒæ¥æºï¼šå±äºä½œè€…ï¼‰
- en: '**Key things to Note here:**'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**éœ€è¦æ³¨æ„çš„å…³é”®ç‚¹ï¼š**'
- en: Itâ€™s almost guaranteed that something or other will break in this deployment;
    the biggest reason is version mismatch in packages.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ä¹å¯ä»¥ä¿è¯åœ¨è¿™ä¸ªéƒ¨ç½²è¿‡ç¨‹ä¸­ä¼šå‡ºç°ä¸€äº›é—®é¢˜ï¼›æœ€å¤§çš„é—®é¢˜æ˜¯åŒ…çš„ç‰ˆæœ¬ä¸åŒ¹é…ã€‚
- en: Use the exact same version in your requirements.txt and Dockerfile as you used
    to train the model and quantize the model. Remember GCP runs quite behind the
    TFâ€™s and Pythonâ€™s latest version. Itâ€™s better to use an older version.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ requirements.txt å’Œ Dockerfile ä¸­ä½¿ç”¨ä¸ä½ è®­ç»ƒæ¨¡å‹å’Œé‡åŒ–æ¨¡å‹æ—¶å®Œå…¨ç›¸åŒçš„ç‰ˆæœ¬ã€‚è®°ä½ GCP çš„ TF å’Œ Python
    ç‰ˆæœ¬é€šå¸¸è¾ƒæ—§ï¼Œæœ€å¥½ä½¿ç”¨è¾ƒæ—§çš„ç‰ˆæœ¬ã€‚
- en: I trained my model on Python 3.8.15; the rest are given in the requirements.txt.
    The errors in the logs are often unclear, so always use the exact same versions;
    if you canâ€™t find the required versions in GCP, change the version for your local
    environment.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨ Python 3.8.15 ä¸Šè®­ç»ƒäº†æˆ‘çš„æ¨¡å‹ï¼›å…¶ä½™çš„åœ¨ requirements.txt ä¸­ç»™å‡ºã€‚æ—¥å¿—ä¸­çš„é”™è¯¯é€šå¸¸ä¸æ˜ç¡®ï¼Œå› æ­¤è¯·å§‹ç»ˆä½¿ç”¨å®Œå…¨ç›¸åŒçš„ç‰ˆæœ¬ï¼›å¦‚æœåœ¨
    GCP ä¸­æ‰¾ä¸åˆ°æ‰€éœ€çš„ç‰ˆæœ¬ï¼Œè¯·ä¸ºæœ¬åœ°ç¯å¢ƒæ›´æ”¹ç‰ˆæœ¬ã€‚
- en: Next, the biggest reason for failed deployment is that you havenâ€™t activated
    the required APIs or you donâ€™t have the required permissions and IAM roles. Itâ€™s
    better to use the account as owner with all the permissions enabled if you use
    GCP for the first time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œéƒ¨ç½²å¤±è´¥çš„æœ€å¤§åŸå› æ˜¯ä½ æ²¡æœ‰æ¿€æ´»æ‰€éœ€çš„ API æˆ–è€…ä½ æ²¡æœ‰å¿…è¦çš„æƒé™å’Œ IAM è§’è‰²ã€‚å¦‚æœä½ ç¬¬ä¸€æ¬¡ä½¿ç”¨ GCPï¼Œæœ€å¥½ä½¿ç”¨æ‹¥æœ‰æ‰€æœ‰æƒé™çš„è´¦æˆ·ä½œä¸ºæ‰€æœ‰è€…ã€‚
- en: Making predictions
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿›è¡Œé¢„æµ‹
- en: Just run `client.py` in your gcloud CLI or your standard command prompt.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: åªéœ€åœ¨ä½ çš„ gcloud CLI æˆ–æ ‡å‡†å‘½ä»¤æç¤ºç¬¦ä¸‹è¿è¡Œ `client.py`ã€‚
- en: 'Hereâ€™s what my output looks like:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘çš„è¾“å‡ºç¤ºä¾‹ï¼š
- en: '![](../Images/11c8a54ffa4b58e442c58f79562e5f8c.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11c8a54ffa4b58e442c58f79562e5f8c.png)'
- en: 'Model prediction (Img Src: Belongs to author)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹é¢„æµ‹ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…æä¾›ï¼‰
- en: I trained a binary image segmentation model on some private data. Due to privacy,
    I can neither reveal the details of my model nor the data. But all the mentioned
    things should work with any image segmentation model.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨ä¸€äº›ç§äººæ•°æ®ä¸Šè®­ç»ƒäº†ä¸€ä¸ªäºŒåˆ†ç±»å›¾åƒåˆ†å‰²æ¨¡å‹ã€‚ç”±äºéšç§åŸå› ï¼Œæˆ‘ä¸èƒ½é€éœ²æˆ‘çš„æ¨¡å‹æˆ–æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ã€‚ä½†æ‰€æœ‰æåˆ°çš„å†…å®¹éƒ½åº”è¯¥é€‚ç”¨äºä»»ä½•å›¾åƒåˆ†å‰²æ¨¡å‹ã€‚
- en: Versioning
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‰ˆæœ¬æ§åˆ¶
- en: And lastly, if you need more resources from the start or want to minimize the
    cold start problem, we can create a new version of the same with just a few additional
    steps.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¦‚æœä½ éœ€è¦ä»ä¸€å¼€å§‹å°±è·å¾—æ›´å¤šèµ„æºï¼Œæˆ–æƒ³è¦æœ€å°åŒ–å†·å¯åŠ¨é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‡ ä¸ªé¢å¤–çš„æ­¥éª¤åˆ›å»ºåŒæ ·çš„æ–°ç‰ˆæœ¬ã€‚
- en: '**Go to your gcloud console in** **GUI > Search cloud run API > Select the
    deployed service > Click on edit and deploy new revision button**. And you will
    get the following options, choose according to your needs, save them, and automatically,
    a new version of your model will be set up for the next sets of requests.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**å‰å¾€ä½ çš„ gcloud æ§åˆ¶å°** **åœ¨ GUI > æœç´¢ cloud run API > é€‰æ‹©å·²éƒ¨ç½²çš„æœåŠ¡ > ç‚¹å‡»ç¼–è¾‘å¹¶éƒ¨ç½²æ–°ç‰ˆæœ¬æŒ‰é’®**ã€‚ä½ å°†çœ‹åˆ°ä»¥ä¸‹é€‰é¡¹ï¼Œæ ¹æ®ä½ çš„éœ€æ±‚è¿›è¡Œé€‰æ‹©ï¼Œä¿å­˜å®ƒä»¬ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä¸ºä¸‹ä¸€æ‰¹è¯·æ±‚è®¾ç½®æ¨¡å‹çš„æ–°ç‰ˆæœ¬ã€‚'
- en: '![](../Images/9ab775f6e179512f6bfe95c2d07eb9eb.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ab775f6e179512f6bfe95c2d07eb9eb.png)'
- en: 'Solving cold start problem (Img Src: Belongs to author)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³å†·å¯åŠ¨é—®é¢˜ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…æä¾›ï¼‰
- en: Conclusion
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Choosing the right strategy for deployment is crucial for cost saving.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€‰æ‹©æ­£ç¡®çš„éƒ¨ç½²ç­–ç•¥å¯¹èŠ‚çœæˆæœ¬è‡³å…³é‡è¦ã€‚
- en: We can make our models faster and smaller using the quantization techniques.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é‡åŒ–æŠ€æœ¯ä½¿æ¨¡å‹æ›´å¿«æ›´å°ã€‚
- en: Serverless deployment with quantized model is a great strategy and can easily
    serve many requests without using costly GPU instances.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é‡åŒ–æ¨¡å‹çš„æ— æœåŠ¡å™¨éƒ¨ç½²æ˜¯ä¸€ç§å¾ˆå¥½çš„ç­–ç•¥ï¼Œå¯ä»¥è½»æ¾å¤„ç†è®¸å¤šè¯·æ±‚è€Œä¸ä½¿ç”¨æ˜‚è´µçš„ GPU å®ä¾‹ã€‚
- en: Serverless takes away the hastle of scaling.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ— æœåŠ¡å™¨æ¶æ„æ¶ˆé™¤äº†æ‰©å±•çš„éº»çƒ¦ã€‚
- en: Thanks for your time and patience, happy learning â¤. Follow me for more of such
    awesome content.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢ä½ çš„æ—¶é—´å’Œè€å¿ƒï¼Œç¥å­¦ä¹ æ„‰å¿« â¤ã€‚å…³æ³¨æˆ‘ï¼Œè·å–æ›´å¤šè¿™æ ·çš„ç²¾å½©å†…å®¹ã€‚
- en: '**Hereâ€™s my reading list for MLOps, discussing several other key concepts and
    strategies:**'
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿™æ˜¯æˆ‘çš„ MLOps é˜…è¯»æ¸…å•ï¼Œè®¨è®ºäº†å‡ ä¸ªå…¶ä»–å…³é”®æ¦‚å¿µå’Œç­–ç•¥ï¼š**'
- en: '![Vishal Rajput](../Images/a96ad11c1783cef37c01eb5b36ffbe0d.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![Vishal Rajput](../Images/a96ad11c1783cef37c01eb5b36ffbe0d.png)'
- en: '[Vishal Rajput](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[Vishal Rajput](https://vishal-ai.medium.com/?source=post_page-----b4cd84f86de1--------------------------------)'
- en: MLOps
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps
- en: '[View list](https://vishal-ai.medium.com/list/mlops-ff7f2453a835?source=post_page-----b4cd84f86de1--------------------------------)10
    stories![](../Images/f43ac8226531c0d15a3fdd2c774f939c.png)![](../Images/f6516179d1713c465b1fff8a3017344f.png)![](../Images/65ceb6ecc46ce9f7e4159979b811b308.png)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://vishal-ai.medium.com/list/mlops-ff7f2453a835?source=post_page-----b4cd84f86de1--------------------------------)10
    ä¸ªæ•…äº‹![](../Images/f43ac8226531c0d15a3fdd2c774f939c.png)![](../Images/f6516179d1713c465b1fff8a3017344f.png)![](../Images/65ceb6ecc46ce9f7e4159979b811b308.png)'
