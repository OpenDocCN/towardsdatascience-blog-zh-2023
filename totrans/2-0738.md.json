["```py\n-- displaying dataset (case_sql.csv)\nSELECT * FROM case_sql;\n```", "```py\n# import python libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\n%matplotlib inline\ncolor = sns.color_palette()\nfrom pandas.plotting import table \nfrom datetime import datetime\n```", "```py\n# load the data set\ndf = pd.read_csv(\"case.csv\", sep=\";\")\n\n# number of observations and columns\ndf.shape\n(31507, 7)\n\n# display rows sample\ndf.sample(15)\n```", "```py\n# SHAPE\n# Create a function that prints the shape of the dataframe and some other basic info \n# --> number of observations, features, duplicates, missing values (True, False) datatypes and its proportion.\n\ndef shape_df(df):\n    print(f\"Number of observations: {df.shape[0]}\")\n    print(f\"Number of variables:    {df.shape[1]}\")\n    print(f\"Number of duplicates:   {df.duplicated().sum()}\")\n    print(f\"Are there any missing values? {df.isnull().values.any()}\\n-----\")\n    print(f\"{df.dtypes.sort_values(ascending=True)}\\n-----\")\n    print(f\"Datatypes' proportion:\\n{df.dtypes.value_counts(ascending=True)}\")\n\n# calling the function\nshape_df(df)\n\nNumber of observations: 31507\nNumber of variables:    7\nNumber of duplicates:   4083\nAre there any missing values? False\n-----\ndate                         int64\nusers                        int64\nsessions                     int64\nbounces                      int64\nbrand                       object\ndevice_category             object\ndefault_channel_grouping    object\ndtype: object\n------\nDatatypes proportion:\nobject    3\nint64     4\ndtype: int64\n```", "```py\n# lowering columns' capital letters for easy typing\ndf.columns = map(str.lower, df.columns)\n\n# remove spaces in columns name\ndf.columns = df.columns.str.replace(' ','_')\n```", "```py\n# make string version of original column 'date', call it 'date_'\ndf['date_'] = df['date'].astype(str)\n\n# create the new columns using string indexing\ndf['year'] = df['date_'].str[0:4]\ndf['month'] = df['date_'].str[4:6]\ndf['day'] = df['date_'].str[6:]\n\n# concatenate 'year', 'month' and 'day'\ndf[\"date\"] = df[\"year\"] + \"-\" + df[\"month\"] + \"-\" + df[\"day\"]\n\n# convert to datetime\ndf[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\")\n```", "```py\n# extract 'year', 'month' and 'weekday'\ndf[\"year\"] = df[\"date\"].dt.year\ndf[\"month\"] = df[\"date\"].dt.month\ndf[\"weekday\"] = df[\"date\"].dt.dayofweek.map({0 : \"Mon\", 1 : \"Tue\", 2 : \"Wed\", 3: \"Thu\", 4 : \"Fri\", 5 : \"Sat\", 6 : \"Sun\"})\n```", "```py\n# select columns to perform exploratory data analysis\ncols = \"date year month weekday brand device_category  default_channel_grouping  users  sessions  bounces\".split()\ndf = df[cols].copy()\n\n# display final dataset\ndf.head(10)\n```", "```py\n-- Device distribution\nSELECT \n    device_category, -- select the device_category column\n    ROUND(COUNT(users) / (SELECT \n                    COUNT(users)\n                FROM\n                    case_sql) * 100,\n            1) AS percent -- calculate the percentage of users in each category\nFROM\n    case_sql -- select data from the case_sql table\nGROUP BY 1 -- group the result by device_category\nORDER BY 1; -- order the result by device_category in ascending order\n```", "```py\n# device distribution\n# counts the number of occurrences of each unique device category in the device_category column of the DataFrame df, including missing values (if any).\ndf.device_category.value_counts(dropna=False).plot(kind='pie', figsize=(8,4),\n                                              explode = (0.02, 0.02, 0.02),\n                                              autopct='%1.1f%%',\n                                              startangle=150);\n# Params\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.title(\"Device distribution\", fontsize=10, loc=\"right\");\n```", "```py\n-- Brand distribution\nSELECT \n    brand, -- select the brand column\n    COUNT(users) AS users, -- count the number of users for each unique brand and alias the result as \"users\"\n    ROUND(COUNT(users) / (SELECT \n                    COUNT(users)\n                FROM\n                    case_sql) * 100,\n            2) AS percent -- calculate the percentage of users for each brand out of the total number of users in the case_sql table and alias the result as \"percent\"\nFROM\n    case_sql -- select data from the case_sql table\nGROUP BY 1; -- group the result by the first column (brand)\n```", "```py\n# Brand distribution\nabsolut = df[\"brand\"].value_counts().to_frame()\n\n# Pie chart\nabsolut.plot(kind='pie', subplots=True, autopct='%1.2f%%', \n             explode= (0.05, 0.05), startangle=20, \n             legend=False, fontsize=12, figsize=(8,4))\n\n# Params\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.title(\"Brand's distribution\", fontsize=10, loc=\"right\");\n\ndisplay(absolut) # Table\n```", "```py\nSELECT \n    date, -- select the date column\n    DAYNAME(date) AS day_name, -- calculate the day name corresponding to each date\n    SUM(users) AS users -- sum the number of users for each unique date where the brand is 'Brand 1'\nFROM\n    case_sql -- select data from the case_sql table\nWHERE\n    brand = 'Brand 1' -- filter rows where the brand is 'Brand 1'\nGROUP BY 1 -- group the result by date\nORDER BY 3 DESC -- order the result by users in descending order\nLIMIT 1; -- select only the first row of the result (the row with the highest number of users)\n```", "```py\n# filter users that arrived at 'Brand 1' only, assign it 'brand_1'\nbrand_1 = df[df[\"brand\"] == \"Brand 1\"].copy()\n\n''' sum total users that came from all \"channelgrouping\" for the same date, \nassign it 'brandgroup' no matter the type of device '''\n\nbrandgroup = brand_1.groupby([\"date\",\"weekday\"])[[\"default_channel_grouping\",\"users\"]].sum()\n\n# filter the date by maximum users, assign it 'users'\nusers = brandgroup[brandgroup[\"users\"] == brandgroup.users.max()].copy()\n\n# reseat index\nusers.reset_index([\"date\"], inplace=True)\nusers.reset_index([\"weekday\"], inplace=True)\n\n# results\nprint(f\"\"\"Date: {users.date} \\n\\nTotal users: {users.users} \\n\\nDay of week: {users.weekday}\"\"\")\n\nDate: 0   2019-11-22\nName: date, dtype: datetime64[ns] \n\nTotal users: 0    885\nName: users, dtype: int64 \n\nDay of week: 0    Fri\nName: weekday, dtype: object\n\n# calling the variable\nusers\n```", "```py\nSELECT \n    DATE(date) AS date, -- Select the date from the 'date' column and convert it to a date data type\n    DAYNAME(date) AS dayofweek, -- Select the day of the week from the 'date' column\n    SUM(CASE\n        WHEN brand = 'Brand 1' THEN users -- Sum the 'users' column for Brand 1\n        ELSE NULL\n    END) AS b1_users,\n    SUM(CASE\n        WHEN brand = 'Brand 2' THEN users -- Sum the 'users' column for Brand 2\n        ELSE NULL\n    END) AS b2_users\nFROM\n    case_sql -- From the 'case_sql' table\nGROUP BY 1, 2 -- Group the results by the first and second columns (date and dayofweek)\nORDER BY 3 DESC -- Order the results by b1_users in descending order\nLIMIT 1; -- Limit the results to only the highest total number of Brand 1 users\n```", "```py\n# filter users that arrived at 'Brand 2', assign it 'brand_2'\nbrand_2 = df[df[\"brand\"] == \"Brand 2\"].copy()\n\n# rename the 'users' column from previous (above) Python code\nbrandgroup.rename(columns = {'users':'brand1_users'}, inplace = True)\n\n# include a new column with the filtered users from 'Brand_2'\nbrandgroup[\"brand2_users\"] = brand_2.groupby([\"date\",\"weekday\"])[[\"default_channel_grouping\",\"users\"]].sum()\n\n# filter the new column (brand2_users) by maximum users\nusers2 = brandgroup[brandgroup[\"brand2_users\"] == brandgroup.brand2_users.max()].copy()\n```", "```py\nSELECT \n    default_channel_grouping AS channels,\n    SUM(users) AS total_users,\n    ROUND(SUM(users) / (SELECT \n                    SUM(users)\n                FROM\n                    case_sql) * 100,\n            1) AS percent -- calculate the percentage of users for each channel\nFROM\n    case_sql\nGROUP BY 1\nORDER BY 2 DESC;\n```", "```py\n# sum users by all channel groups and plot bar chart \nax = df.groupby(\"default_channel_grouping\")[\"users\"].sum().sort_values(ascending=True)\\\n.plot(kind=\"bar\", figsize=(9,6), fontsize=12, linewidth=2, \n      color=sns.color_palette(\"rocket\"), grid=False, table=False)\n\n# show data labels\nfor p in ax.patches:\n    ax.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', xytext=(0, 7), textcoords='offset points')\n\n# params\nplt.xlabel(\"Channel groups\", fontsize=10)\nplt.xticks(rotation=90, horizontalalignment=\"center\")\nplt.ylabel(\"Absolute values\", fontsize=10)\nplt.title(\"Best channel group (highest number of users)\", fontsize=10, loc=\"right\");\n```", "```py\nSELECT \n    default_channel_grouping AS channels,\n    SUM(CASE -- sum users by brand and map to new columns\n        WHEN brand = 'brand 1' THEN users -- if brand = 'brand 1', sum users and store in 'Brand_1' column\n        ELSE NULL -- if not 'brand 1', set value to null\n    END) AS Brand_1, -- create column for Brand 1 users\n    SUM(CASE \n        WHEN brand = 'brand 2' THEN users \n        ELSE NULL \n    END) AS Brand_2 \nFROM\n    case_sql\nGROUP BY 1 -- group by channel\nORDER BY 3 DESC; -- order by Brand 2 users in descending order\n```", "```py\n# create pivot_table\n# sum all users for each brand by channels\ntype_pivot = df.pivot_table(\n    columns=\"brand\",\n    index=\"default_channel_grouping\",\n    values=\"users\", aggfunc=sum)\n\ndisplay(type_pivot)\n\n#Display pivot_table with a bar chart\ntype_pivot.sort_values(by=[\"Brand 2\"], ascending=True).plot(kind=\"bar\", figsize=(12,8) ,fontsize = 15)\nplt.xlabel(\"Channel groups\", fontsize=10)\nplt.xticks(rotation=90, horizontalalignment=\"center\")\nplt.ylabel(\"Absolute values\", fontsize=10)\nplt.title(\"Channel groups by brand (highest number of users)\", fontsize=10, loc=\"right\");\n```", "```py\nSELECT \n    brand,\n    default_channel_grouping AS channels,\n    ROUND(SUM(sessions) / (SELECT \n                    SUM(sessions)\n                FROM\n                    case_sql) * 100,\n            1) AS percent\nFROM\n    case_sql\nWHERE\n    default_channel_grouping IN ('Paid Search' , 'Paid Social', 'Display', 'Other Advertising') -- include only rows with these values\n        AND date < '2020-01-01' -- only date before '2020-01-01' will be included.\nGROUP BY 1 , 2\nHAVING percent > 5 -- filters the groups to only include values greater than 5%.\nORDER BY 1 , 3 DESC\n```", "```py\n# groupby dataframe by selected cols\ndf = df.groupby([\"date\",\"brand\",\"default_channel_grouping\"])[\"sessions\"].sum().to_frame().copy()\n\n# calculate percentages (new column)\ndf[\"percent\"] = (df.apply(lambda x: x/x.sum())*100).round(2)\n\n# reset index\ndf = df.reset_index().copy()\n\n# display a 5 rows sample\ndf.sample(5)\n```", "```py\n# filter paid channels using lambda function\npaid = df.apply(lambda row: row[df['default_channel_grouping'].isin(['Display','Paid Search','Paid Social','Other Advertising'])])\n\n# filter year 2019\npaid = paid[paid['date'] < '2020-01-01']\n\n# groupby channels by brand\npaid = paid.groupby([\"brand\",\"default_channel_grouping\"])[[\"sessions\",\"percent\"]].sum()\n\n# filter sessions higher than 5%\npaid[paid[\"percent\"] >5]\n```", "```py\nSELECT \n    brand,\n    SUM(CASE\n        WHEN device_category = 'Desktop' THEN users\n        ELSE NULL\n    END) AS desktop,\n    SUM(CASE\n        WHEN device_category = 'Mobile' THEN users\n        ELSE NULL\n    END) AS mobile,\n    SUM(CASE\n        WHEN device_category = 'Tablet' THEN users\n        ELSE NULL\n    END) AS tablet\nFROM\n    case_sql\nGROUP BY 1\nORDER BY 1;\n```", "```py\n# pivot_table\ntype_pivot = df.pivot_table(\n    columns=\"device_category\",\n    index=\"brand\",\n    values=\"users\", aggfunc=sum)\n\ndisplay(type_pivot)\n\n# display pivot_table (chart)\nax = type_pivot.sort_values(by=[\"brand\"], ascending=False).plot(kind=\"bar\", figsize=(12,8) ,fontsize = 15);\n\n# adding data labels\nfor p in ax.patches:\n    ax.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 7), textcoords='offset points')\n\nplt.xlabel(\"Brands\", fontsize=10)\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.ylabel(\"Absolute values\", fontsize=10)\nplt.title(\"Brand by type of device\", fontsize=10, loc=\"right\")\nplt.legend([\"Desktop\",\"Mobile\",\"Tablet\"]);\n```", "```py\nSELECT \n    default_channel_grouping,\n    AVG(CASE\n        WHEN device_category = 'Desktop' THEN users\n        ELSE NULL\n    END) AS desktop,\n    AVG(CASE\n        WHEN device_category = 'Mobile' THEN users\n        ELSE NULL\n    END) AS mobile,\n    AVG(CASE\n        WHEN device_category = 'Tablet' THEN users\n        ELSE NULL\n    END) AS tablet\nFROM\n    case_sql\nGROUP BY 1\nORDER BY 1;\n```", "```py\n# pivot_table\ntype_pivot = df.pivot_table(\n    columns=\"device_category\",\n    index=\"default_channel_grouping\",\n    values=\"users\", aggfunc=np.mean)\n\ndisplay(type_pivot)\n```", "```py\n# display pivot_table\ntype_pivot.sort_values(by=[\"default_channel_grouping\"], ascending=False).plot(kind=\"bar\", figsize=(12,8) ,fontsize = 15);\n\nplt.xlabel(\"Date\", fontsize=10)\nplt.xticks(rotation=90, horizontalalignment=\"center\")\nplt.ylabel(\"Absolute values\", fontsize=10)\nplt.title(\"Average use of device types by channel grouping\", fontsize=10, loc=\"right\")\nplt.legend([\"Desktop\",\"Mobile\",\"Tablet\"]);\n```", "```py\nSELECT \n    default_channel_grouping,\n    SUM(sessions) AS sessions,\n    SUM(bounces) AS bounces,\n    ROUND(SUM(bounces) / SUM(sessions) * 100, 2) AS bounces_r\nFROM\n    case_sql\nGROUP BY 1\nORDER BY 4 DESC;\n```", "```py\nSELECT \n    SUM(sessions) AS sessions,\n    SUM(bounces) AS bounces,\n    ROUND(SUM(bounces) / SUM(sessions) * 100, 2) AS bounces_r,\n    AVG(ROUND(bounces/sessions*100, 2)) AS avg_bounces_r\nFROM\n    case_sql;\n```", "```py\n# group individual channels by sum of users\ndfbounce = df.groupby(\"default_channel_grouping\")[\"users\"].sum().to_frame()\n\n# group individual channels by sum of sessions\ndfbounce[\"sessions\"] = df.groupby(\"default_channel_grouping\")[\"sessions\"].sum()\n\n# group individual channels by sum of bounces\ndfbounce[\"bounces\"] = df.groupby(\"default_channel_grouping\")[\"bounces\"].sum()\n\n# calculus of bounce rate for each individual channel\ndfbounce[\"bounces_r\"] = dfbounce.apply(lambda x: 0.0 if x[\"sessions\"] == 0.0 else (x[\"bounces\"] / x[\"sessions\"])*100, axis=1).round(2)\n\ndff = dfbounce.copy()\n\ndfbounce.drop([\"users\"],axis=1,inplace=True)\n\n# sort values by rate\ndfbounce.sort_values(by=\"bounces_r\", ascending=False)\n```", "```py\n# display bar chart with the bounce rate for each channel\nax = dfbounce.groupby(\"default_channel_grouping\")[\"bounces_r\"].sum().sort_values(ascending=True)\\\n.plot(kind=\"bar\", figsize=(9,6), fontsize=12, linewidth=2, color=sns.color_palette(\"rocket\"), grid=False, table=False)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha='center', va='center', xytext=(0, 7), textcoords='offset points')\n\nplt.axhline(dfbounce.groupby(\"default_channel_grouping\")[\"bounces_r\"].mean().mean(), linewidth=1, color =\"r\")\nplt.xlabel(\"channel groups\", fontsize=10)\nplt.xticks(rotation=90, horizontalalignment=\"center\")\nplt.ylabel(\"Absolute values\", fontsize=10)\nplt.title(\"Bounce rate by channelGrouping\", fontsize=10, loc=\"right\");\n```", "```py\nSELECT \n    YEAR(date) AS year, -- extract year\n    MONTH(date) AS month,  -- extract month \n    DATE_FORMAT(date, '%b') AS month_,   -- format the date column to display month name\n    ROUND(SUM(bounces) / SUM(sessions) * 100, 2) AS bounces_r  -- calculate bounce rate\n    case_sql                        \nGROUP BY 1 , 2 , 3                  \nORDER BY 1 , 2 , 3; \n```", "```py\n df_date = df.groupby(\"date\")[['sessions','bounces']].sum()\n\n''' create function to assess the bounce rate, assign it as 'bounce_r'\nReturn 0 if session's value is 0, else divide the bounces by sessions \nfor each date and multiply it by 100 to get the percentage '''\n\ndef div(bounces, sessions):\n    return lambda row: 0.0 if row[sessions] == 0.0 else float((row[bounces]/(row[sessions])))*100\n\n# create column 'bounce_r' with the function results\ndf_date[\"bounce_r\"] = (df_date.apply(div('bounces', 'sessions'), axis=1)).round(1)\n\n# drop unnecessary columns\ndf_date.drop([\"sessions\",\"bounces\"], axis=1, inplace=True)\n\n# sum all bounces over time and plot chart\nax = df_date.plot(kind=\"line\", figsize=(14,6), fontsize=12, linewidth=2)\n\nplt.xlabel(\"Date\", fontsize=10)\nplt.xticks(rotation=90, horizontalalignment=\"center\")\nplt.ylabel(\"Rate\", fontsize=10)\nplt.title(\"Evolution of the bounce rate over time\", fontsize=10, loc=\"right\");\n```", "```py\n# Smoothing the line with a step of 15 days interval\nresampled = df_date[\"bounce_r\"].resample(\"m\").mean() \n\nplt.figure(figsize = (12,6))\nax = sns.lineplot(data = resampled)\nplt.title(\"Evolution of the bounce rate over time (smooth)\", fontsize=10, loc=\"right\")\nplt.xlabel(\"Date\", fontsize=10)\nplt.xticks(rotation=0, horizontalalignment=\"center\")\nplt.ylabel(\"Rate\", fontsize=10);\n```", "```py\n# filter by brand\nb1 = df[df[\"brand\"] == \"Brand 1\"]\nb2 = df[df[\"brand\"] == \"Brand 2\"]\n\n# ** brand 1 **\n\n# group individual channels by sum of sessions for brand 1\ndfbrand = b1.groupby(\"default_channel_grouping\")[\"sessions\"].sum().to_frame()\ndfbrand.rename(columns={\"sessions\":\"sessions1\"}, inplace=True)\n\n# group individual channels by sum of bounces for brand 1\ndfbrand[\"bounces1\"] = b1.groupby(\"default_channel_grouping\")[\"bounces\"].sum()\n\n# calculus of bounce rate for each individual channel for brand 1\ndfbrand[\"1bounces_r\"] = dfbrand.apply(lambda x: 0.0 if x[\"sessions1\"] == 0.0 else (x[\"bounces1\"] / x[\"sessions1\"]*100), axis=1).round(2)\n\n# ** brand 2 **\n\n# group individual channels by sum of bounces for brand 2\ndfbrand[\"sessions2\"] = b2.groupby(\"default_channel_grouping\")[\"sessions\"].sum()\n\n# group individual channels by sum of bounces for brand 2\ndfbrand[\"bounces2\"] = b2.groupby(\"default_channel_grouping\")[\"bounces\"].sum()\n\n# calculus of bounce rate for each individual channel for brand 2\ndfbrand[\"2bounces_r\"] = dfbrand.apply(lambda x: 0.0 if x[\"sessions2\"] == 0.0 else (x[\"bounces2\"] / x[\"sessions2\"]*100), axis=1).round(2)\n\n# sort values by rate\ndfbrand.sort_values(by=\"1bounces_r\", ascending=False)\n```", "```py\n# clean dataframe\ndfchannels = dfbrand.copy()\ndfbrand_chart = dfbrand.copy()\ndfbrand_chart.drop([\"sessions1\",\"sessions2\",\"bounces1\",\"bounces2\"], axis=1, inplace=True)\n\n# display bar chart with the average bounce rate for each channel\nax = dfbrand_chart.plot(kind=\"bar\", figsize=(13,6), fontsize=12, linewidth=2, color=sns.color_palette(\"BrBG\"), grid=False, table=False)\n\nfor p in ax.patches:\n    ax.annotate(\"%.1f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 7), textcoords='offset points')\n\nplt.xlabel(\"channel groups\", fontsize=10)\nplt.xticks(rotation=90, horizontalalignment=\"center\")\nplt.ylabel(\"Absolute values\", fontsize=10)\nplt.title(\"Bounce rate by channelGrouping and by brand\", fontsize=10, loc=\"right\")\nplt.legend([\"Brand 1\",\"Brand 2\"]);\n```", "```py\nSELECT \n    brand,\n    CASE\n        WHEN\n            default_channel_grouping IN ('Paid Search', \n                'Paid Social',\n                'Display',\n                'Other Advertising')\n        THEN\n            'Paid'\n        WHEN\n            default_channel_grouping IN ('Direct',\n                'Native',\n                'Organic Search',\n                'Referral',\n                'Social',\n                'Email',\n                '(Other)')\n        THEN\n            'Organic'\n        ELSE NULL\n    END AS media,\n    ROUND(SUM(bounces) / SUM(sessions) * 100, 2) AS bounce_r\nFROM\n    case_sql\nGROUP BY brand , media\nORDER BY 1;\n```", "```py\n# create dictionary\nmedia_dict = \n{\n    'Display': 'paid',\n    'Paid Search': 'paid',\n    'Paid Social': 'paid',\n    'Other Advertising': 'paid',\n    'Direct': 'organic',\n    'Native': 'organic',\n    'Organic Search': 'organic',\n    'Referral': 'organic',\n    'Social': 'organic',\n    'Email': 'organic',\n    '(Other)': 'organic'\n}\n\n# mapping the dict into a new column\ndf['media'] = df['default_channel_grouping'].map(media_dict)\n\n# define cols position in dataframe\ncols = ['brand','media','sessions','bounces']\n\n# reindex columns order\ndf = df.reindex(columns = cols)\n\n# groupby dataframe by selected cols\ndf = df.groupby([\"brand\",\"media\"])[[\"sessions\",\"bounces\"]].sum()\n\n# bounce rate by channel\ndf[\"bounces_r\"] = df.apply(lambda x: 0.0 if x[\"sessions\"] == 0.0 else (x[\"bounces\"] / x[\"sessions\"])*100, axis=1).round(2)\n```"]