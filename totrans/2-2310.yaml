- en: 'Vosk for Efficient Enterprise-Grade Speech Recognition: An Evaluation and Implementation
    Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vosk：高效企业级语音识别的评估与实施指南
- en: 原文：[https://towardsdatascience.com/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c](https://towardsdatascience.com/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c](https://towardsdatascience.com/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c)
- en: A comprehensive walkthrough of implementing and assessing Vosk-based speech
    recognition systems
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对实现和评估基于Vosk的语音识别系统的全面指南
- en: '[](https://medium.com/@luisroque?source=post_page-----87a599217a6c--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----87a599217a6c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----87a599217a6c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----87a599217a6c--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----87a599217a6c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisroque?source=post_page-----87a599217a6c--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----87a599217a6c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----87a599217a6c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----87a599217a6c--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----87a599217a6c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----87a599217a6c--------------------------------)
    ·9 min read·May 15, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----87a599217a6c--------------------------------)
    ·9分钟阅读·2023年5月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In our latest articles, we have been working extensively with different models
    and approaches to perform speech recognition. The open-source community has been
    developing solutions in this space for the last few years, giving us many options
    to select from. We have tried Whisper, WhisperX, and Whisper-JAX. All of them
    are based on the Whisper model trained and open-sourced by OpenAI recently. It
    is an Automatic Speech Recognition (ASR) system trained on multilingual and multiple
    tasks, making it general-purpose for speech and even language tasks.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们最新的文章中，我们广泛地使用了不同的模型和方法来进行语音识别。开源社区在过去几年中一直在开发这方面的解决方案，给我们提供了许多选择。我们尝试了Whisper、WhisperX和Whisper-JAX。它们都基于最近由OpenAI训练并开源的Whisper模型。它是一个在多语言和多任务上训练的自动语音识别（ASR）系统，使其在语音甚至语言任务中都具有通用性。
- en: One of the downsides of Whisper is the resources it takes to run it, especially
    in terms of execution time for longer audio files. In this article, we guide you
    through developing your enterprise-grade speech recognition model using Vosk,
    an open-source offline speech recognition toolkit. These models are significantly
    faster, which, in a significant number of use cases, is a decisive factor.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Whisper的一个缺点是运行所需的资源，特别是在较长音频文件的执行时间方面。在本文中，我们将引导你通过使用Vosk，一个开源离线语音识别工具包，来开发企业级语音识别模型。这些模型显著更快，在许多使用案例中，这是一个决定性因素。
- en: We dive into the performance of four Vosk speech recognition models, highlighting
    their strengths and weaknesses in terms of accuracy, execution time, and model
    size. Our findings reveal interesting insights, such as the 20% improvement in
    accuracy when transitioning from the smaller models to bigger ones. We also shed
    light on the trade-offs between speed and accuracy.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深入探讨了四个Vosk语音识别模型的性能，突出了它们在准确性、执行时间和模型大小方面的优缺点。我们的发现揭示了有趣的见解，比如从较小的模型过渡到更大的模型时准确性提高了20%。我们还揭示了速度和准确性之间的权衡。
- en: '![](../Images/7ff0f43043ccd4bbccc7d9dc24eee0a2.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ff0f43043ccd4bbccc7d9dc24eee0a2.png)'
- en: 'Figure 1: Speech to text is getting us closer to the machines ([source](https://unsplash.com/photos/zoG585VYsV8))'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：语音转文本使我们更接近机器（[来源](https://unsplash.com/photos/zoG585VYsV8)）
- en: 'This article belongs to “Large Language Models Chronicles: Navigating the NLP
    Frontier”, a new weekly series of articles that will explore how to leverage the
    power of large models for various NLP tasks. By diving into these cutting-edge
    technologies, we aim to empower developers, researchers, and enthusiasts to harness
    the potential of NLP and unlock new possibilities.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'Articles published so far:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[Summarizing the latest Spotify releases with ChatGPT](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Master Semantic Search at Scale: Index Millions of Documents with Lightning-Fast
    Inference Times using FAISS and Sentence Transformers](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Unlock the Power of Audio Data: Advanced Transcription and Diarization with
    Whisper, WhisperX, and PyAnnotate](https://medium.com/towards-data-science/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281)'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Whisper JAX vs PyTorch: Uncovering the Truth about ASR Performance on GPUs](https://medium.com/towards-data-science/whisper-jax-vs-pytorch-uncovering-the-truth-about-asr-performance-on-gpus-8794ba7a42f5)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As always, the code is available on my [Github](https://github.com/luisroque/large_laguage_models).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Speech Recognition
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Speech recognition is the technology that enables computers and other devices
    to understand and process human speech, converting spoken language into written
    text. There are several steps in how these systems learn to convert speech to
    text. They automatically extract the raw audio waveform, essentially the audio
    signal’s acoustic features. Then, they map those features to phonemes and, using
    a language model, map the phonemes to words. More advanced systems also incorporate
    contextual information and semantic understanding to refine the transcript.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Speech recognition faces numerous challenges due to the complexity of human
    speech and the factors that introduce variability and ambiguity. Some challenges
    include speaker variability, background noise, disfluencies and filler words,
    and homophones and coarticulation. Speaker variability originates from different
    speakers’ unique accents, speaking styles, and pronunciations. Background noise,
    such as that found in noisy environments, interferes with the clarity of the speech
    signal, posing a challenge for accurate recognition. Disfluencies and filler words
    present another hurdle, as hesitations, repetitions, and filler words (e.g., “uh”
    and “um”) commonly occur in natural speech. Lastly, homophones and coarticulation
    create additional obstacles. Some words sound identical but have different meanings
    (homophones). The pronunciation of others can change depending on their position
    in a sentence (coarticulation). All these factors introduce ambiguity to the recognition
    task and make it harder for our models to perform accurately in certain tasks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别面临着许多挑战，因为人类语音的复杂性以及引入变异性和模糊性的因素。一些挑战包括说话人变异、背景噪声、言语流畅性问题和填充词、以及同音词和共鸣现象。说话人变异源于不同说话人的独特口音、说话风格和发音。背景噪声，如嘈杂环境中的噪音，会干扰语音信号的清晰度，对准确识别构成挑战。言语流畅性问题和填充词是另一个障碍，因为在自然语言中常出现犹豫、重复和填充词（例如“呃”和“嗯”）。最后，同音词和共鸣现象带来额外的障碍。一些单词发音相同但含义不同（同音词）。另一些单词的发音可能会根据其在句子中的位置而改变（共鸣现象）。所有这些因素都为识别任务引入了模糊性，使得我们的模型在某些任务中更难准确执行。
- en: A Practical Guide to Building an Enterprise-Grade Speech Recognition Model with
    Vosk
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《构建企业级语音识别模型的实用指南》
- en: We leverage the power of Vosk, an open-source offline speech recognition toolkit,
    to build a custom speech recognition system. Vosk offers a flexible and efficient
    solution for implementing speech recognition on various platforms, including Android,
    iOS, Windows, Linux, and Raspberry Pi. Its key features include support for multiple
    languages, speaker identification, compatibility with small-footprint devices,
    and large-scale server deployments.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用 Vosk 的强大功能，这是一个开源的离线语音识别工具包，用于构建自定义语音识别系统。Vosk 提供了一个灵活高效的解决方案，能够在包括 Android、iOS、Windows、Linux
    和 Raspberry Pi 等各种平台上实现语音识别。其关键特性包括支持多种语言、说话人识别、与小型设备兼容以及大规模服务器部署。
- en: In the following sections, we guide you through creating your speech recognition
    system using Vosk. We discuss popular frameworks and libraries, outline the steps
    for data collection, preprocessing, and model training, and provide tips for fine-tuning
    the model for specific use cases.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将指导您如何使用 Vosk 创建语音识别系统。我们将讨论流行的框架和库，概述数据收集、预处理和模型训练的步骤，并提供针对特定用例的模型微调技巧。
- en: Data Collection
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集
- en: To evaluate different models, we will use the [LibriSpeech](https://www.openslr.org/12)
    ASR corpus dataset (CC BY 4.0). The dataset comprises recordings of LibriSpeech
    is a corpus of approximately 1000 hours of read English speech. The dataset is
    ideal for benchmarking speech recognition models as it provides various accents,
    speaking styles, pronunciations and background noises. As we discussed previously,
    these are often large obstacles for these models to perform well. We are interested
    in testing if Vosk is capable to work in these challenging environments.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估不同的模型，我们将使用 [LibriSpeech](https://www.openslr.org/12) ASR 语料库数据集（CC BY 4.0）。该数据集包括大约
    1000 小时的朗读英语语音录音。LibriSpeech 数据集非常适合用来评估语音识别模型，因为它提供了多种口音、说话风格、发音和背景噪声。正如我们之前讨论的，这些因素通常会对模型的表现产生重大影响。我们希望测试
    Vosk 是否能够在这些具有挑战性的环境中有效工作。
- en: Transcription and Word Representation
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转录与单词表示
- en: 'The Vosk API is quite rich; we have access to several attributes for each word
    transcribed. It returns the following attributes:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Vosk API 非常丰富；我们可以访问每个转录单词的几个属性。它返回以下属性：
- en: '`conf`: Degree of confidence for the recognized word, ranging from 0 to 1.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conf`：识别单词的置信度，范围从 0 到 1。'
- en: '`start`: Start time of pronouncing the word, in seconds.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start`：发音开始时间，以秒为单位。'
- en: '`end`: End time of pronouncing the word, in seconds.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end`：发音结束时间，以秒为单位。'
- en: '`word`: The recognized word.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word`：识别出的单词。'
- en: 'To streamline our process, we create a `WordVosk` class that represents each
    word returned by the Vosk API:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化我们的过程，我们创建了一个 `WordVosk` 类，用于表示 Vosk API 返回的每个单词：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As our primary interest lies in obtaining transcriptions, we create a `Transcription`
    class that takes a list of `WordVosk` objects. The `to_raw_text` method generates
    the final raw transcription:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These classes help manage the output from the Vosk speech recognition API more
    efficiently, allowing for easier manipulation of the transcription results.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the Main Model Class
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `ModelSpeechToText` class is designed to handle speech-to-text conversion
    using the Vosk API. It takes an audio file and a Vosk model as input, and it returns
    a list of transcribed words.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `speech_to_text` method transcribes speech to text using the Vosk API. It
    reads the audio file in chunks and processes each chunk using the `KaldiRecognizer`.
    The transcription results are collected in the `results` list.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `results_to_words` method takes the transcription results and converts them
    into a list of `WordVosk` objects. This method allows us to easily manipulate
    and process the transcribed words.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `ModelSpeechToText` is the final abstraction that we needed to efficiently
    use the Vosk API. It allows us to transcribe audio files and obtain a list of
    transcribed words, which are represented as `WordVosk` objects.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating Speech-to-Text Models Using Word Error Rate
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To evaluate speech-to-text models, we can use the Word Error Rate (WER) metric.
    It is the average number of insertions, deletions, and substitutions needed to
    transform the hypothesis transcription into the reference transcription, divided
    by the total number of words in the reference transcription. Lower WER values
    indicate better performance.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The `calculate_wer` function computes the average WER between reference and
    hypothesis transcriptions:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `evaluate_models` function evaluates multiple speech-to-text models using
    a given evaluation dataset:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Evaluating Vosk Speech-to-Text Models: Accuracy, Execution Time, and Memory
    Consumption'
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let’s introduce the four models that we are testing. These models vary
    in size and complexity, which can potentially affect their performance. We compared
    them in terms of accuracy, execution time, and memory consumption. The models
    and their respective sizes are as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'vosk-model-small-en-us-0.15 (Size: 40M)'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'vosk-model-en-us-0.22 (Size: 1.8G)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'vosk-model-en-us-0.22-lgraph (Size: 128M)'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'vosk-model-en-us-0.42-gigaspeech (Size: 2.3G)'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Comparing Model Performance
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After evaluating the four Vosk models on a dataset rich in accents and complex
    sentences, we observed noticeable differences in their performance. The best models
    in terms of accuracy were the 0.42-gigaspeech and 0.22, with the latter showing
    an improvement of about 20% compared to the smaller 0.15 and 0.22-lgraph models.
    This improvement can be attributed to the larger size of the 0.42-gigaspeech and
    0.22 models, which allows them to better handle diverse accents and complex language
    structures.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/048b43887c8668fc1c459b4fbf12e5e7.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Word error rate (WER) for each model tested (image by author)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：每个测试模型的词错误率（WER）（图片由作者提供）
- en: In terms of execution time, the 0.22 and 0.15 models were the best performers,
    taking around 150 seconds to complete the transcription process. On the other
    hand, the 0.22-lgraph model took considerably longer, at over 750 seconds. This
    highlights an interesting trade-off between accuracy and speed, with the 0.22
    model emerging as an appealing option that achieves a good balance between performance
    and accuracy.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行时间方面，0.22和0.15模型表现最佳，完成转录过程大约需要150秒。另一方面，0.22-lgraph模型所需时间较长，超过750秒。这突显了准确性和速度之间的有趣权衡，0.22模型作为一个吸引人的选择，在性能和准确性之间达到了良好的平衡。
- en: '![](../Images/63b105fd85b3c54fda538f17b0ccec6a.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63b105fd85b3c54fda538f17b0ccec6a.png)'
- en: 'Figure 3: Execution time for each model tested (image by author)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：每个测试模型的执行时间（图片由作者提供）
- en: Considering the results, the 0.22 model offers a promising combination of accuracy
    and efficiency, making it suitable for a wide range of applications.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到结果，0.22模型提供了准确性和效率的有希望的组合，使其适用于广泛的应用场景。
- en: Conclusion
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we evaluated four different Vosk speech recognition models
    to compare their performance in terms of accuracy and execution time. We observed
    that the 0.42-gigaspeech and 0.22 models exhibited superior accuracy, with the
    0.22 model demonstrating a 20% improvement over the smaller 0.15 and 0.22-lgraph
    models. This improvement can be attributed to the larger size of the 0.42-gigaspeech
    and 0.22 models, allowing them to handle diverse accents and complex language
    structures better.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们评估了四种不同的Vosk语音识别模型，以比较它们在准确性和执行时间方面的表现。我们观察到，0.42-gigaspeech和0.22模型的准确性优越，其中0.22模型比较小的0.15和0.22-lgraph模型表现出20%的改进。这一改进归因于0.42-gigaspeech和0.22模型的更大尺寸，使它们能够更好地处理不同的口音和复杂的语言结构。
- en: When considering execution time, the 0.22 and 0.15 models emerged as the best
    performers. The 0.22 model, in particular, stands out as an appealing option that
    achieves a good balance between performance and accuracy. It is important to note
    that the choice of the optimal model depends on the specific requirements of each
    project. Always consider the trade-offs between speed and accuracy.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑执行时间时，0.22和0.15模型表现最佳。特别是0.22模型，作为一个吸引人的选择，它在性能和准确性之间达到了良好的平衡。需要注意的是，选择最佳模型取决于每个项目的具体要求。始终考虑速度和准确性之间的权衡。
- en: 'Keep in touch: [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 保持联系：[LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
