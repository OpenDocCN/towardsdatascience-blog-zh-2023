- en: Training of Robotic Manipulators on the Obstacle Avoidance task through Reinforcement
    Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过强化学习训练机器人操控器在避障任务上的应用
- en: 原文：[https://towardsdatascience.com/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning-ea2a3404883f](https://towardsdatascience.com/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning-ea2a3404883f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning-ea2a3404883f](https://towardsdatascience.com/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning-ea2a3404883f)
- en: Easily train a Robotic Manipulator to avoid obstacles by using the **robotic-maninpulator-rloa**
    framework
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过使用**robotic-manipulator-rloa**框架，轻松训练机器人操控器避开障碍物。
- en: '[](https://medium.com/@JavierMtz5?source=post_page-----ea2a3404883f--------------------------------)[![Javier
    Martínez Ojeda](../Images/5b5df4220fa64c13232c29de9b4177af.png)](https://medium.com/@JavierMtz5?source=post_page-----ea2a3404883f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea2a3404883f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea2a3404883f--------------------------------)
    [Javier Martínez Ojeda](https://medium.com/@JavierMtz5?source=post_page-----ea2a3404883f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@JavierMtz5?source=post_page-----ea2a3404883f--------------------------------)[![Javier
    Martínez Ojeda](../Images/5b5df4220fa64c13232c29de9b4177af.png)](https://medium.com/@JavierMtz5?source=post_page-----ea2a3404883f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea2a3404883f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea2a3404883f--------------------------------)
    [Javier Martínez Ojeda](https://medium.com/@JavierMtz5?source=post_page-----ea2a3404883f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea2a3404883f--------------------------------)
    ·7 min read·Mar 15, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----ea2a3404883f--------------------------------)
    ·7分钟阅读·2023年3月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3d857dfac9d0b252ac6b3ded3ae4c6d7.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d857dfac9d0b252ac6b3ded3ae4c6d7.png)'
- en: Photo by [David Levêque](https://unsplash.com/ko/@davidleveque?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[David Levêque](https://unsplash.com/ko/@davidleveque?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。
- en: If you want to read this article without a Premium Medium account, you can do
    it from this friend link :)
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你想阅读这篇文章而没有高级Medium账户，可以通过这个朋友链接访问 :)
- en: '[https://www.learnml.wiki/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning/](https://www.learnml.wiki/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning/)'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://www.learnml.wiki/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning/](https://www.learnml.wiki/training-of-robotic-manipulators-on-the-obstacle-avoidance-task-through-reinforcement-learning/)'
- en: The purpose of this article, beyond explaining how to train a manipulator in
    the obstacle avoidance task, is to introduce the open-source framework **robotic-manipulator-rloa**
    and to explain how it works and how to use it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目的是，除了讲解如何训练操控器以完成避障任务外，还介绍开源框架**robotic-manipulator-rloa**，并解释其工作原理和使用方法。
- en: In short, the **robotic-manipulator-rloa** framework allows the user to load
    a URDF or SDF model of a Robotic Manipulator (URDF or SDF files are XML file formats
    used to describe all elements of a robot) in a simulation environment, which will
    be used to train the manipulator to avoid hitting an obstacle while trying to
    reach a specific point in space. In order to make the training customizable, the
    user can configure the basic components of the environment, as well as the hyperparameters
    of the NAF algorithm, which is the algorithm used for training.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，**robotic-manipulator-rloa**框架允许用户在模拟环境中加载URDF或SDF格式的机器人模型（URDF或SDF文件是用于描述机器人所有元素的XML文件格式），并用来训练操控器在尝试到达空间中特定点时避开障碍物。为了使训练过程可定制，用户可以配置环境的基本组件，以及用于训练的NAF算法的超参数。
- en: 'The NAF algorithm was previously explained at a theoretical level in this article:
    [Applied Reinforcement Learning V: Normalized Advantage Function (NAF) for Continuous
    Control](https://medium.com/towards-data-science/applied-reinforcement-learning-v-normalized-advantage-function-naf-for-continuous-control-62ad143d3095)'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: NAF算法在这篇文章中以理论层面进行了讲解：[应用强化学习 V：连续控制的归一化优势函数 (NAF)](https://medium.com/towards-data-science/applied-reinforcement-learning-v-normalized-advantage-function-naf-for-continuous-control-62ad143d3095)
- en: '[](/applied-reinforcement-learning-v-normalized-advantage-function-naf-for-continuous-control-62ad143d3095?source=post_page-----ea2a3404883f--------------------------------)
    [## Applied Reinforcement Learning V: Normalized Advantage Function (NAF) for
    Continuous Control'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 应用强化学习 V: 用于连续控制的标准化优势函数 (NAF)](/applied-reinforcement-learning-v-normalized-advantage-function-naf-for-continuous-control-62ad143d3095?source=post_page-----ea2a3404883f--------------------------------)'
- en: Introduction and explanation of the NAF algorithm, widely used in continuous
    control tasks
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NAF 算法的介绍和解释，该算法广泛用于连续控制任务
- en: towardsdatascience.com](/applied-reinforcement-learning-v-normalized-advantage-function-naf-for-continuous-control-62ad143d3095?source=post_page-----ea2a3404883f--------------------------------)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/applied-reinforcement-learning-v-normalized-advantage-function-naf-for-continuous-control-62ad143d3095?source=post_page-----ea2a3404883f--------------------------------)'
- en: Install the robotic-manipulator-rloa framework via PyPI
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 PyPI 安装 robotic-manipulator-rloa 框架
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The installation of the PyPi package will install the following packages as
    dependencies:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 PyPi 包将会安装以下依赖包：
- en: '**torch:** PyTorch is used to contruct the neural networks required for the
    NAF algorithm.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**torch:** PyTorch 用于构建 NAF 算法所需的神经网络。'
- en: '**numpy:** NumPy is used to work with numbers and arrays in an optimized way.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**numpy:** NumPy 用于以优化的方式处理数字和数组。'
- en: '**pybullet:** PyBullet is used to create the simulation of the training environment,
    and to interact with and obtain information from it.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pybullet:** PyBullet 用于创建训练环境的模拟，并与其交互和获取信息。'
- en: '**matplotlib:** Matplotlib is used to visualize the rewards obtained by the
    agent along the training process.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**matplotlib:** Matplotlib 用于可视化训练过程中智能体获得的奖励。'
- en: Once the framework has been installed, a training and evaluation of the agent
    can be configured and executed in **5** **steps**, which are presented in the
    following sections.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 安装框架后，可以在 **5** **步** 中配置和执行智能体的训练和评估，这些步骤在以下部分中介绍。
- en: 1\. Initialize ManipulatorFramework
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 初始化 ManipulatorFramework
- en: Create an object of the **ManipulatorFramework** class.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 **ManipulatorFramework** 类的对象。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The constructor of the ManipulatorFramework class initializes the hyperparameters
    of the NAF algorithm with the default values:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ManipulatorFramework 类的构造函数使用默认值初始化 NAF 算法的超参数：
- en: '**Buffer Size** defaults to 100000.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓冲区大小** 默认为 100000。'
- en: '**Batch Size** defaults to 128.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量大小** 默认为 128。'
- en: '**Gamma** defaults to 0.99.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Gamma** 默认为 0.99。'
- en: '**Tau** defaults to 0.001,'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tau** 默认为 0.001，'
- en: '**Learning Rate** defaults to 0.001,'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习率** 默认为 0.001，'
- en: '**Update Frequency** defaults to 1.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更新频率** 默认为 1。'
- en: '**Number of Updates** defaults to 1.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更新次数** 默认为 1。'
- en: In case you want to configure any of the hyperparameters of the NAF algorithm,
    the ManipulatorFramework class has a **set_hyperparameter()** method, which receives
    as parameters the name of the hyperparameter to be modified and the new value
    to be set, as shown below.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想配置 NAF 算法的任何超参数，ManipulatorFramework 类有一个 **set_hyperparameter()** 方法，该方法接收要修改的超参数名称和要设置的新值，如下所示。
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 2\. Initialize the Environment
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 初始化环境
- en: 'The **Environment** needs some information from the user to configure the training
    simulation. More specifically, the fields required in the initialization of the
    Environment class are:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**Environment** 需要一些来自用户的信息来配置训练模拟。具体来说，初始化 Environment 类时需要的字段包括：'
- en: '**manipulator_file**: path to the manipulator’s URDF or SDF file.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**manipulator_file**: 操纵器 URDF 或 SDF 文件的路径。'
- en: '**endeffector_index**: index of the manipulator’s end-effector.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**endeffector_index**: 操纵器末端执行器的索引。'
- en: '**fixed_joints**: list containing the indices of every joint not involved in
    the training (joints that will be static during training).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**fixed_joints**: 包含所有未参与训练的关节的索引的列表（在训练过程中将保持静态的关节）。'
- en: '**involved_joints**: list containing the indices of every joint involved in
    the training.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**involved_joints**: 包含所有参与训练的关节索引的列表。'
- en: '**target_position**: list containing the position of the target object, as
    3D Cartesian coordinates.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**target_position**: 包含目标对象位置的列表，使用 3D 笛卡尔坐标表示。'
- en: '**obstacle_position**: list containing the position of the obstacle, as 3D
    Cartesian coordinates.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**obstacle_position**: 包含障碍物位置的列表，使用 3D 笛卡尔坐标表示。'
- en: '**initial_joint_positions**: list containing as many items as the number of
    joints of the manipulator. Each item in the list corresponds to the initial position
    wanted for the joint with that same index.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**initial_joint_positions**: 包含与操纵器关节数量相同项数的列表。列表中的每个项对应于希望的关节初始位置。'
- en: '**initial_positions_variation_range**: list containing as many items as the
    number of joints of the manipulator. Each item in the list corresponds to the
    variation range (initial_pos-range, initial_pos+range) wanted for the joint with
    that same index.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**initial_positions_variation_range**: 列表中包含的项数与操控器的关节数相同。列表中的每一项对应于所需关节的变动范围（initial_pos-range,
    initial_pos+range）。'
- en: '**max_force**:maximum force to be applied on the joints.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**max_force**: 施加在关节上的最大力量。'
- en: '**visualize**: boolean indicating whether or not to visualize the simulated
    environment during training.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**visualize**: 布尔值，指示是否在训练期间可视化模拟环境。'
- en: 'Taking into account these parameters, the initialization of the environment
    would be carried out by calling the **initialize_environment()** method as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些参数，环境的初始化将通过以下方式调用**initialize_environment()**方法：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 3\. Initialize NAF Agent
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 初始化NAF Agent
- en: The NAF Agent is initialized in a very simple way, since most of the parameters
    it needs are taken from the previously configured Environment and from the hyperparameters
    initialized and configured in **Step 1**.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: NAF Agent的初始化非常简单，因为它需要的大多数参数都是从之前配置的环境和**步骤1**中初始化和配置的超参数中获取的。
- en: In fact, the only parameter received by the **initialize_naf_agent()** method,
    which is used to initialize the NAF Agent, is **checkpoint_frequency**, which
    determines how often the training status will be saved. This parameter defaults
    to 500.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，**initialize_naf_agent()**方法唯一接收的参数是**checkpoint_frequency**，它决定了训练状态保存的频率。默认值为500。
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 4\. Run training
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 运行训练
- en: 'Once the **Environment** and **NAF Agent** have been configured and initialized,
    training can proceed. This step is carried out by means of the **run_training()**
    method, which receives three parameters:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦**环境**和**NAF Agent**配置并初始化完毕，训练可以继续进行。这一步通过**run_training()**方法进行，该方法接收三个参数：
- en: '**episodes**: maximum number of episodes to execute for the training.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**episodes**: 训练执行的最大集数。'
- en: '**frames**: maximum number of timesteps to execute per episode.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**frames**: 每集要执行的最大时间步数。'
- en: '**verbose**: boolean indicating whether the verbose mode is activated or not.
    If verbose mode in on, information of each timestep will be printed on terminal.
    It is recommended to use this mode only in debug and development phases, as in
    the context of a normal training it adds too much information and prevents to
    see the training status in a clear way.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**verbose**: 布尔值，指示是否激活详细模式。如果详细模式开启，终端将打印每个时间步的信息。建议仅在调试和开发阶段使用此模式，因为在正常训练过程中，它会添加过多的信息，导致无法清晰地看到训练状态。'
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 5\. Run testing
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 运行测试
- en: 'Once the training has finished, it will be possible to test the agent to evaluate
    if it has managed to learn the task. To do this, use is made of the **test_trained_model()**
    method, which receives 2 parameters as for the **run_training()** method: the
    number of episodes and timesteps per episode that you want to run in the test.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，可以测试代理以评估其是否成功学会了任务。为此，使用**test_trained_model()**方法，该方法接收与**run_training()**方法相同的两个参数：测试中要运行的集数和每集的时间步数。
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The test process can also be carried out without having previously executed
    a training session, by loading the trained weights from a previous training session.
    These trained weights can be obtained from the checkpoints that the framework
    generates throughout the training, or from the *‘model.p’* file that is generated
    at the end of a training session. To execute a test on weights trained in a previous
    training, it will be also necessary to initialize the Environment and the NAF
    Agent in the same way that it was done when those weights were trained.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 测试过程也可以在未先前执行训练会话的情况下进行，通过加载先前训练会话中的训练权重。这些训练权重可以从框架在整个训练过程中生成的检查点中获取，也可以从训练会话结束时生成的*‘model.p’*文件中获取。要对以前训练的权重进行测试，还需要以与训练权重时相同的方式初始化环境和NAF
    Agent。
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It is important to note that when the trained weights are loaded from one of
    the checkpoints, it will be necessary to pass as a parameter the episode from
    which the weights are to be obtained. As an example, the code above gets the weights
    of the checkpoint generated for episode 2000.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，当从一个检查点加载训练后的权重时，需要作为参数传递要获取权重的集数。例如，上面的代码获取了为第2000集生成的检查点的权重。
- en: Training Execution Information
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练执行信息
- en: This section explains how the information about the training is displayed during
    the execution of a training session.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了在训练会话执行期间如何显示训练信息。
- en: If **visualize** is set to True when initializing the Environment
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果**visualize**在初始化Environment时设置为True
- en: If the **visualize** parameter is set to True during the initialization of the
    **Environment**, then during the execution of the training the manipulator will
    be visualized, as shown in *Figure 1*. While this mode allows you to see that
    the manipulator movements are good and that the training is proceeding as expected,
    visualization slows down the execution of the program, so it should be used in
    development and not in the execution of a training with many episodes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在初始化**Environment**时将**visualize**参数设置为True，则在训练执行期间将可视化 manipulator，如*图1*所示。虽然这种模式可以让你看到
    manipulator 的运动是否良好以及训练是否按预期进行，但可视化会减慢程序的执行速度，因此应在开发中使用，而不是在进行大量回合的训练时使用。
- en: '![](../Images/fc4265da15bf81a0644df1a7ab80ec79.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc4265da15bf81a0644df1a7ab80ec79.png)'
- en: '**Figure 1**. Visualization of the training. Image by author'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1**。训练的可视化。图片由作者提供'
- en: If verbose is set to True when initializing the Training
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果在初始化训练时将verbose设置为True
- en: If the **verbose** parameter is set to True during the **Environment** initialization,
    then information about each of the timesteps of each episode will be displayed,
    as shown in *Figure 2*. Considering that a normal training can last more than
    1000 episodes, and that each episode can consist of 500 timesteps, displaying
    the information for each timestep floods the terminal stdout, which can make it
    difficult to access certain information, and can be counterproductive in the context
    of a long training.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在**Environment**初始化时将**verbose**参数设置为True，则每个训练回合的每个时间步的信息将会显示，如*图2*所示。考虑到正常的训练可能持续超过1000个回合，并且每个回合可能包含500个时间步，显示每个时间步的信息会淹没终端stdout，这可能会使得某些信息难以获取，并且在长期训练的情况下可能适得其反。
- en: '![](../Images/1e50d880ca03796cb76527ec0e6fd143.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e50d880ca03796cb76527ec0e6fd143.png)'
- en: '**Figure 2**. Terminal logs of a training when verbose is True. Image by author'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2**。verbose为True时的训练终端日志。图片由作者提供'
- en: If verbose is set to False when initializing the Training
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果在初始化训练时将verbose设置为False
- en: If the **verbose** parameter is set to False during the **Environment** initialization,
    then only information about each episode will be displayed, as shown in *Figure
    3*. This type of execution is much more recommendable for a long training, since
    it allows to easily obtain the information of each one of the episodes completed
    during the training.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在**Environment**初始化时将**verbose**参数设置为False，则只会显示每个回合的信息，如*图3*所示。这种执行模式更适合长期训练，因为它可以轻松获取训练过程中每个回合完成的信息。
- en: '![](../Images/f8f893eaf26d43f7808c1343b5fddbef.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8f893eaf26d43f7808c1343b5fddbef.png)'
- en: '**Figure 3**. Terminal logs of a training when verbose is False. Image by author'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3**。verbose为False时的训练终端日志。图片由作者提供'
- en: '**Demo Training and Testing**'
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**演示训练与测试**'
- en: The **robotic-manipulator-rloa** package allows running training and testing
    demos for [*KUKA IIWA*](https://www.kuka.com/es-es/productos-servicios/sistemas-de-robot/robot-industrial/lbr-iiwa)
    and [*Xarm6*](https://www.ufactory.cc/product-page/ufactory-xarm-6) robot manipulators,
    in order to show the user the necessary steps to run and evaluate a training with
    two different environment configurations. These trainings and tests are executed
    as shown below.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**robotic-manipulator-rloa**包允许运行[**KUKA IIWA**](https://www.kuka.com/es-es/productos-servicios/sistemas-de-robot/robot-industrial/lbr-iiwa)和[**Xarm6**](https://www.ufactory.cc/product-page/ufactory-xarm-6)机器人
    manipulator 的训练和测试演示，以展示用户在两个不同环境配置下运行和评估训练所需的步骤。这些训练和测试如下所示。'
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: More information about the package
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 包的更多信息
- en: More information about the **robotic-manipulator-rloa** package can be found
    in the documentation, or from the project page on PyPI. As for the code, it can
    be found in my GitHub repository, so if anyone has any improvements and proposals
    for the project, feel free to let me know.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关于**robotic-manipulator-rloa**包的更多信息可以在文档中找到，或在PyPI的项目页面上查看。至于代码，可以在我的GitHub仓库中找到，因此如果有人对项目有任何改进建议，请随时告诉我。
- en: '**Documentation**: [https://javiermtz5.github.io/robotic_manipulator_rloa/](https://javiermtz5.github.io/robotic_manipulator_rloa/)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档**：[https://javiermtz5.github.io/robotic_manipulator_rloa/](https://javiermtz5.github.io/robotic_manipulator_rloa/)'
- en: '**PyPI page**: [https://pypi.org/project/robotic-manipulator-rloa/](https://pypi.org/project/robotic-manipulator-rloa/)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyPI 页面**: [https://pypi.org/project/robotic-manipulator-rloa/](https://pypi.org/project/robotic-manipulator-rloa/)'
- en: '**GitHub repository**: [https://github.com/JavierMtz5/robotic_manipulator_rloa](https://github.com/JavierMtz5/robotic_manipulator_rloa)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GitHub 仓库**: [https://github.com/JavierMtz5/robotic_manipulator_rloa](https://github.com/JavierMtz5/robotic_manipulator_rloa)'
- en: I hope that the framework is helpful, easy to use and that it manages to train
    with good results the different manipulator robots that are going to be loaded.
    If this has been the case, or if anyone runs into any problems or unexpected behavior,
    I would really appreciate it if you would let me know on the [GitHub repository](https://github.com/JavierMtz5/robotic_manipulator_rloa),
    either by starring the project or by opening an issue with the problem found.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个框架对你有所帮助，易于使用，并且能够有效地训练即将加载的不同操控机器人。如果情况如此，或者如果有人遇到任何问题或意外行为，我将非常感激您能在[GitHub
    仓库](https://github.com/JavierMtz5/robotic_manipulator_rloa)上告知我，无论是通过给项目加星，还是通过报告发现的问题。
