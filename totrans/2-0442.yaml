- en: 'Building an AI-Powered Language Learning App: Learning From Two AI Chatting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ª AI é©±åŠ¨çš„è¯­è¨€å­¦ä¹ åº”ç”¨ï¼šä»ä¸¤ä¸ª AI èŠå¤©ä¸­å­¦ä¹ 
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd](https://towardsdatascience.com/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd](https://towardsdatascience.com/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)
- en: A step-by-step tutorial on creating a dual-chatbot language learning app with
    Langchain, OpenAI, gTTS, and Streamlit
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªåŒèŠå¤©æœºå™¨äººè¯­è¨€å­¦ä¹ åº”ç”¨çš„é€æ­¥æ•™ç¨‹ï¼Œä½¿ç”¨ Langchainã€OpenAIã€gTTS å’Œ Streamlit
- en: '[](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----6db7f9b0d7cd--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)
    Â·25 min readÂ·Jun 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6db7f9b0d7cd--------------------------------)
    Â·25 åˆ†é’Ÿé˜…è¯»Â·2023å¹´6æœˆ26æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6b56edb9154ae8825ea55581c2ab5ee9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b56edb9154ae8825ea55581c2ab5ee9.png)'
- en: 'DALL-E Prompt: two friendly robots talking with each other.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E æç¤ºï¼šä¸¤ä¸ªå‹å¥½çš„æœºå™¨äººç›¸äº’äº¤è°ˆã€‚
- en: When I first began learning a new language, I like to buy those â€œconversational
    dialoguesâ€ books. I find those books very useful as they help me understand how
    the language worked â€” not just the grammar and vocabulary, but also how people
    really used it in day-to-day life.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ç¬¬ä¸€æ¬¡å¼€å§‹å­¦ä¹ ä¸€é—¨æ–°è¯­è¨€æ—¶ï¼Œæˆ‘å–œæ¬¢è´­ä¹°é‚£äº›â€œå¯¹è¯ç»ƒä¹ â€ä¹¦ç±ã€‚æˆ‘å‘ç°è¿™äº›ä¹¦ç±éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒä»¬å¸®åŠ©æˆ‘ç†è§£äº†è¯­è¨€çš„è¿ä½œâ€”â€”ä¸ä»…ä»…æ˜¯è¯­æ³•å’Œè¯æ±‡ï¼Œè¿˜æœ‰äººä»¬åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å¦‚ä½•å®é™…ä½¿ç”¨å®ƒã€‚
- en: 'Now with the rise of large language models (LLMs), a thought occurred to me:
    could I replicate these language-learning books in a more interactive, dynamic,
    and scalable format? Could I utilize LLM to create a tool that generates fresh,
    on-demand conversations for language learners?'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…´èµ·ï¼Œæˆ‘æƒ³åˆ°ä¸€ä¸ªé—®é¢˜ï¼šæˆ‘æ˜¯å¦å¯ä»¥ä»¥ä¸€ç§æ›´äº’åŠ¨ã€åŠ¨æ€å’Œå¯æ‰©å±•çš„å½¢å¼æ¥å¤åˆ¶è¿™äº›è¯­è¨€å­¦ä¹ ä¹¦ç±ï¼Ÿæˆ‘èƒ½å¦åˆ©ç”¨ LLM åˆ›å»ºä¸€ä¸ªç”Ÿæˆæ–°é²œã€æŒ‰éœ€å¯¹è¯çš„å·¥å…·ï¼Œä¸ºè¯­è¨€å­¦ä¹ è€…æä¾›å¸®åŠ©ï¼Ÿ
- en: This thought inspired the project I would like to share with you today â€” an
    AI-powered language learning app, where learners can observe and learn from two
    AI chatbots engaged in either a user-defined **conversation** or a **debate**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæƒ³æ³•æ¿€å‘äº†æˆ‘ä»Šå¤©æƒ³ä¸å¤§å®¶åˆ†äº«çš„é¡¹ç›®â€”â€”ä¸€ä¸ªç”±äººå·¥æ™ºèƒ½é©±åŠ¨çš„è¯­è¨€å­¦ä¹ åº”ç”¨ç¨‹åºï¼Œåœ¨è¿™ä¸ªåº”ç”¨ä¸­ï¼Œå­¦ä¹ è€…å¯ä»¥è§‚å¯Ÿå¹¶å­¦ä¹ ä¸¤ä¸ª AI èŠå¤©æœºå™¨äººè¿›è¡Œçš„ç”¨æˆ·å®šä¹‰çš„**å¯¹è¯**æˆ–**è¾©è®º**ã€‚
- en: Regarding the employed tech stack, I have used Langchain, OpenAI API, gTTS,
    and Streamlit to create the application where users can define the roles, scenarios,
    or debate topics, and let the AI generate the content.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºæ‰€ä½¿ç”¨çš„æŠ€æœ¯æ ˆï¼Œæˆ‘ä½¿ç”¨äº† Langchainã€OpenAI APIã€gTTS å’Œ Streamlit æ¥åˆ›å»ºè¿™ä¸ªåº”ç”¨ï¼Œç”¨æˆ·å¯ä»¥å®šä¹‰è§’è‰²ã€åœºæ™¯æˆ–è¾©è®ºä¸»é¢˜ï¼Œè®©
    AI ç”Ÿæˆå†…å®¹ã€‚
- en: Demo for the developed language learning app. (Video by author)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¼€å‘çš„è¯­è¨€å­¦ä¹ åº”ç”¨ç¨‹åºæ¼”ç¤ºã€‚ï¼ˆè§†é¢‘ç”±ä½œè€…æä¾›ï¼‰
- en: If youâ€™re curious about how it all works, then join me as I walk you through
    the journey of building this interactive dual-chatbot system, step by step ğŸ—ºï¸ğŸ“ğŸš¶â€â™€ï¸.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹å®ƒçš„å·¥ä½œåŸç†æ„Ÿåˆ°å¥½å¥‡ï¼Œé‚£å°±è·Ÿéšæˆ‘ä¸€æ­¥ä¸€æ­¥äº†è§£æ„å»ºè¿™ä¸ªäº’åŠ¨åŒèŠå¤©æœºå™¨äººç³»ç»Ÿçš„è¿‡ç¨‹ ğŸ—ºï¸ğŸ“ğŸš¶â€â™€ï¸ã€‚
- en: You can find the complete source code [here](https://github.com/ShuaiGuo16/language_learning_app)*ğŸ’»*.
    In this blog, we will also go through the key code snippets to explain the ideas.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/ShuaiGuo16/language_learning_app)*ğŸ’»*æ‰¾åˆ°å®Œæ•´çš„æºä»£ç ã€‚åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬è¿˜å°†ä»‹ç»å…³é”®çš„ä»£ç ç‰‡æ®µä»¥è§£é‡Šè¿™äº›æƒ³æ³•ã€‚
- en: With that in mind, letâ€™s get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶å¦‚æ­¤ï¼Œæˆ‘ä»¬å¼€å§‹å§ï¼
- en: '**Table of Content**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**å†…å®¹ç›®å½•**'
- en: Â· [1\. Project Overview](#209d)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [1\. é¡¹ç›®æ¦‚è¿°](#209d)
- en: Â· [2\. Prerequisites](#9115)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [2\. å‰ç½®æ¡ä»¶](#9115)
- en: âˆ˜ [2.1 LangChain](#0dee)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [2.1 LangChain](#0dee)
- en: âˆ˜ [2.2 ConversationChain](#3988)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [2.2 ConversationChain](#3988)
- en: Â· [3\. Project Design](#d70e)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [3\. é¡¹ç›®è®¾è®¡](#d70e)
- en: âˆ˜ [3.1 Developing a single chatbot](#c790)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [3.1 å¼€å‘å•ä¸€èŠå¤©æœºå™¨äºº](#c790)
- en: âˆ˜ [3.2 Developing a dual-chatbot system](#5a8a)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [3.2 å¼€å‘åŒèŠå¤©æœºå™¨äººç³»ç»Ÿ](#5a8a)
- en: Â· [4\. App Interface Design with Streamlit](#2557)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [4\. ä½¿ç”¨ Streamlit çš„åº”ç”¨ç•Œé¢è®¾è®¡](#2557)
- en: Â· [5\. Learnings and Future Extensions](#cffe)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [5\. å­¦ä¹ æˆæœä¸æœªæ¥æ‰©å±•](#cffe)
- en: Â· [6\. Conclusion](#954a)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [6\. ç»“è®º](#954a)
- en: 1\. Project Overview
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. é¡¹ç›®æ¦‚è¿°
- en: As mentioned earlier, our goal is to create a unique language-learning app powered
    by two conversational AI or chatbots. The innovative aspect of this app lies in
    having these chatbots interact with each other, creating realistic dialogues in
    the target language. Users can observe these AI-driven conversations, use them
    as language-learning resources, and understand the practical usage of their chosen
    language.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªç”±ä¸¤ä¸ªå¯¹è¯å¼ AI æˆ–èŠå¤©æœºå™¨äººé©±åŠ¨çš„ç‹¬ç‰¹è¯­è¨€å­¦ä¹ åº”ç”¨ç¨‹åºã€‚è¿™ä¸ªåº”ç”¨ç¨‹åºçš„åˆ›æ–°ä¹‹å¤„åœ¨äºè®©è¿™äº›èŠå¤©æœºå™¨äººç›¸äº’äº’åŠ¨ï¼Œåˆ›é€ å‡ºé€¼çœŸçš„ç›®æ ‡è¯­è¨€å¯¹è¯ã€‚ç”¨æˆ·å¯ä»¥è§‚å¯Ÿè¿™äº›
    AI é©±åŠ¨çš„å¯¹è¯ï¼Œå°†å…¶ä½œä¸ºè¯­è¨€å­¦ä¹ èµ„æºï¼Œå¹¶ç†è§£æ‰€é€‰è¯­è¨€çš„å®é™…ä½¿ç”¨ã€‚
- en: In our app, users should have the flexibility to customize their learning experience
    according to their needs. They can adjust several settings including target language,
    learning mode, session length, and proficiency level.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºä¸­ï¼Œç”¨æˆ·åº”å…·å¤‡æ ¹æ®è‡ªèº«éœ€æ±‚å®šåˆ¶å­¦ä¹ ä½“éªŒçš„çµæ´»æ€§ã€‚ä»–ä»¬å¯ä»¥è°ƒæ•´å¤šä¸ªè®¾ç½®ï¼ŒåŒ…æ‹¬ç›®æ ‡è¯­è¨€ã€å­¦ä¹ æ¨¡å¼ã€ä¼šè¯æ—¶é•¿å’Œç†Ÿç»ƒç¨‹åº¦ã€‚
- en: '**Target Language** ğŸ”¤'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›®æ ‡è¯­è¨€** ğŸ”¤'
- en: Users can choose the language they wish to learn. This choice guides the language
    used by the chatbots during their interactions. For the moment, I have included
    support for English â€” â€˜enâ€™, German â€” â€˜deâ€™, Spanish â€” â€˜esâ€™, and French â€” â€˜frâ€™,
    but it is trivial to add more languages as long as the GPT model has sufficient
    knowledge about them.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·å¯ä»¥é€‰æ‹©ä»–ä»¬å¸Œæœ›å­¦ä¹ çš„è¯­è¨€ã€‚è¿™ä¸ªé€‰æ‹©å°†æŒ‡å¯¼èŠå¤©æœºå™¨äººåœ¨äº’åŠ¨è¿‡ç¨‹ä¸­ä½¿ç”¨çš„è¯­è¨€ã€‚ç›®å‰ï¼Œæˆ‘å·²ç»æ”¯æŒäº†è‹±è¯­â€”â€”â€˜enâ€™ï¼Œå¾·è¯­â€”â€”â€˜deâ€™ï¼Œè¥¿ç­ç‰™è¯­â€”â€”â€˜esâ€™ï¼Œå’Œæ³•è¯­â€”â€”â€˜frâ€™ï¼Œä½†åªè¦GPTæ¨¡å‹å¯¹è¿™äº›è¯­è¨€æœ‰è¶³å¤Ÿçš„çŸ¥è¯†ï¼Œæ·»åŠ æ›´å¤šè¯­è¨€æ˜¯å¾®ä¸è¶³é“çš„ã€‚
- en: Learning mode ğŸ“–
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å­¦ä¹ æ¨¡å¼ ğŸ“–
- en: This setting lets users select the style of conversation between the chatbots.
    In the **â€œconversationâ€** mode, users can define the **roles** (e.g., customer
    and waitstaff) and **actions** (ordering food and taking an order)for each bot
    and specify a **scenario** (at a restaurant), upon which the bots will simulate
    a realistic conversation. In the **â€œdebateâ€** mode, users are prompted to input
    a debate **topic** (Should we adopt nuclear energy?). The bots then engage in
    a lively debate on the provided topic.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè®¾ç½®å…è®¸ç”¨æˆ·é€‰æ‹©èŠå¤©æœºå™¨äººä¹‹é—´çš„å¯¹è¯é£æ ¼ã€‚åœ¨**â€œå¯¹è¯â€**æ¨¡å¼ä¸‹ï¼Œç”¨æˆ·å¯ä»¥å®šä¹‰**è§’è‰²**ï¼ˆä¾‹å¦‚ï¼Œé¡¾å®¢å’ŒæœåŠ¡å‘˜ï¼‰å’Œ**åŠ¨ä½œ**ï¼ˆç‚¹é¤å’Œæ¥å•ï¼‰ï¼Œå¹¶æŒ‡å®šä¸€ä¸ª**åœºæ™¯**ï¼ˆåœ¨é¤å…ï¼‰ï¼ŒèŠå¤©æœºå™¨äººå°†æ¨¡æ‹Ÿä¸€ä¸ªé€¼çœŸçš„å¯¹è¯ã€‚åœ¨**â€œè¾©è®ºâ€**æ¨¡å¼ä¸‹ï¼Œç”¨æˆ·è¢«æç¤ºè¾“å…¥ä¸€ä¸ªè¾©è®º**è¯é¢˜**ï¼ˆæˆ‘ä»¬æ˜¯å¦åº”è¯¥é‡‡ç”¨æ ¸èƒ½ï¼Ÿï¼‰ã€‚ç„¶åï¼ŒèŠå¤©æœºå™¨äººä¼šå›´ç»•æä¾›çš„è¯é¢˜è¿›è¡Œæ¿€çƒˆçš„è¾©è®ºã€‚
- en: The appâ€™s interface should be responsive and dynamically adjusts based on the
    learning mode selected by the user, providing a seamless user experience.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨ç¨‹åºçš„ç•Œé¢åº”è¯¥æ˜¯å“åº”å¼çš„ï¼Œå¹¶æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„å­¦ä¹ æ¨¡å¼åŠ¨æ€è°ƒæ•´ï¼Œä»¥æä¾›æ— ç¼çš„ç”¨æˆ·ä½“éªŒã€‚
- en: Session Length â°
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼šè¯æ—¶é•¿ â°
- en: The session length setting gives users control over the duration of each chatbot
    conversation or debate. This means they can have short, quick dialogues or longer,
    more in-depth discussions, depending on their preference.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼šè¯æ—¶é•¿è®¾ç½®è®©ç”¨æˆ·æ§åˆ¶æ¯æ¬¡èŠå¤©æœºå™¨äººå¯¹è¯æˆ–è¾©è®ºçš„æŒç»­æ—¶é—´ã€‚è¿™æ„å‘³ç€ä»–ä»¬å¯ä»¥è¿›è¡Œç®€çŸ­çš„å¿«é€Ÿå¯¹è¯ï¼Œæˆ–æ ¹æ®ä¸ªäººå–œå¥½è¿›è¡Œæ›´é•¿æ—¶é—´ã€æ›´æ·±å…¥çš„è®¨è®ºã€‚
- en: Proficiency Level ğŸ†
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç†Ÿç»ƒç¨‹åº¦ ğŸ†
- en: This setting tailors the complexity of the chatbot conversation to the userâ€™s
    language skill level. Beginners might prefer simpler conversations, while more
    advanced learners can handle intricate debates or discussions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè®¾ç½®å°†èŠå¤©æœºå™¨äººçš„å¯¹è¯å¤æ‚æ€§é‡èº«å®šåˆ¶ä¸ºç”¨æˆ·çš„è¯­è¨€èƒ½åŠ›æ°´å¹³ã€‚åˆå­¦è€…å¯èƒ½æ›´å–œæ¬¢ç®€å•çš„å¯¹è¯ï¼Œè€Œæ›´é«˜çº§çš„å­¦ä¹ è€…åˆ™å¯ä»¥å¤„ç†å¤æ‚çš„è¾©è®ºæˆ–è®¨è®ºã€‚
- en: 'Once the users specify those settings, they can initiate the session and watch
    as the AI chatbots spring into action, carrying out dynamic and interactive dialogues
    in accordance with the userâ€™s preferences. Our overall workflow can be illustrated
    as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ç”¨æˆ·æŒ‡å®šäº†è¿™äº›è®¾ç½®ï¼Œä»–ä»¬å°±å¯ä»¥å¯åŠ¨ä¼šè¯ï¼Œè§‚çœ‹ AI èŠå¤©æœºå™¨äººå¦‚ä½•æ ¹æ®ç”¨æˆ·çš„åå¥½è¿›è¡ŒåŠ¨æ€å’Œäº’åŠ¨çš„å¯¹è¯ã€‚æˆ‘ä»¬çš„æ•´ä½“å·¥ä½œæµç¨‹å¯ä»¥å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/5c17a979a507a63f4be9b4f03e15b7fa.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c17a979a507a63f4be9b4f03e15b7fa.png)'
- en: Workflow overview. The user-specified settings will be used to configure the
    prompt, which will be fed to the chatbots to generate conversations. The obtained
    script (together with user settings) will be used to populate the app interface.
    (Image by author)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å·¥ä½œæµç¨‹æ¦‚è¿°ã€‚ç”¨æˆ·æŒ‡å®šçš„è®¾ç½®å°†ç”¨äºé…ç½®æç¤ºï¼Œè¿™äº›æç¤ºå°†æä¾›ç»™èŠå¤©æœºå™¨äººä»¥ç”Ÿæˆå¯¹è¯ã€‚è·å¾—çš„è„šæœ¬ï¼ˆè¿åŒç”¨æˆ·è®¾ç½®ï¼‰å°†ç”¨äºå¡«å……åº”ç”¨ç¨‹åºç•Œé¢ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: 2\. Prerequisites
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. å‰ææ¡ä»¶
- en: Before we dive into the development of our app, letâ€™s familiarize ourselves
    with the tools that we will be using. In this section, weâ€™ll briefly introduce
    the LangChain library, specifically the `ConversationChain` module, which serves
    as the backbone of our app.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬æ·±å…¥å¼€å‘åº”ç”¨ç¨‹åºä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç†Ÿæ‚‰ä¸€ä¸‹æˆ‘ä»¬å°†ä½¿ç”¨çš„å·¥å…·ã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ç®€è¦ä»‹ç» LangChain åº“ï¼Œç‰¹åˆ«æ˜¯ `ConversationChain`
    æ¨¡å—ï¼Œå®ƒä½œä¸ºæˆ‘ä»¬åº”ç”¨ç¨‹åºçš„æ ¸å¿ƒéƒ¨åˆ†ã€‚
- en: 2.1 LangChain
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 LangChain
- en: Building an application powered by Large Language Models (LLMs) involves many
    complexities. You need to interface with language model providers through API
    calls, connect these models to various data sources, handle the history of user
    interactions, and design pipelines for executing complex tasks. This is where
    the LangChain library comes into play.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„åº”ç”¨ç¨‹åºæ¶‰åŠè®¸å¤šå¤æ‚æ€§ã€‚ä½ éœ€è¦é€šè¿‡ API è°ƒç”¨ä¸è¯­è¨€æ¨¡å‹æä¾›è€…è¿›è¡Œæ¥å£è¿æ¥ï¼Œå°†è¿™äº›æ¨¡å‹ä¸å„ç§æ•°æ®æºè¿æ¥ï¼Œå¤„ç†ç”¨æˆ·äº’åŠ¨çš„å†å²è®°å½•ï¼Œå¹¶è®¾è®¡æ‰§è¡Œå¤æ‚ä»»åŠ¡çš„ç®¡é“ã€‚è¿™æ­£æ˜¯
    LangChain åº“å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚
- en: '[**LangChain**](https://python.langchain.com/docs/get_started/introduction)is
    a framework dedicated to streamlining the development of LLM-powered applications.
    It offers a wide array of components that address the common pain points listed
    above. Whether itâ€™s managing interactions with the language model providers, orchestrating
    data connections, maintaining memory for historical interactions, or defining
    intricate task pipelines, LangChain has it covered.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[**LangChain**](https://python.langchain.com/docs/get_started/introduction)æ˜¯ä¸€ä¸ªæ—¨åœ¨ç®€åŒ–åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨ç¨‹åºå¼€å‘çš„æ¡†æ¶ã€‚å®ƒæä¾›äº†ä¸€ç³»åˆ—ç»„ä»¶ï¼Œè§£å†³äº†ä¸Šè¿°å¸¸è§ç—›ç‚¹ã€‚æ— è®ºæ˜¯ç®¡ç†ä¸è¯­è¨€æ¨¡å‹æä¾›è€…çš„äº’åŠ¨ï¼Œç»„ç»‡æ•°æ®è¿æ¥ï¼Œç»´æŠ¤å†å²äº’åŠ¨çš„è®°å¿†ï¼Œè¿˜æ˜¯å®šä¹‰å¤æ‚çš„ä»»åŠ¡ç®¡é“ï¼ŒLangChain
    éƒ½èƒ½åº”å¯¹è‡ªå¦‚ã€‚'
- en: A key concept introduced by LangChain is the â€œ**Chain**â€. In essence, chains
    allow us to combine multiple components together to create a single, coherent
    application. For example, a fundamental chain type in LangChain is the `LLMChain.`
    It creates a pipeline that first formats the prompt template using the user-provided
    input key values, then passes the formatted instructions to LLM, and finally returns
    the LLM output.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain ä»‹ç»çš„ä¸€ä¸ªå…³é”®æ¦‚å¿µæ˜¯â€œ**Chain**â€ã€‚æœ¬è´¨ä¸Šï¼Œé“¾å…è®¸æˆ‘ä»¬å°†å¤šä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·ï¼Œä»¥åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„åº”ç”¨ç¨‹åºã€‚ä¾‹å¦‚ï¼ŒLangChain
    ä¸­çš„ä¸€ä¸ªåŸºæœ¬é“¾ç±»å‹æ˜¯ `LLMChain`ã€‚å®ƒåˆ›å»ºäº†ä¸€ä¸ªç®¡é“ï¼Œé¦–å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„è¾“å…¥é”®å€¼æ ¼å¼åŒ–æç¤ºæ¨¡æ¿ï¼Œç„¶åå°†æ ¼å¼åŒ–çš„æŒ‡ä»¤ä¼ é€’ç»™ LLMï¼Œæœ€åè¿”å› LLM
    çš„è¾“å‡ºã€‚
- en: LangChain hosts a variety of chain types, including `RetrievalQAChain,` for
    question-answering over documents, `SummarizationChain,` for summarizing multiple
    documents, and of course, our focus for today, the `ConversationChain.`
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain ä¸»æŒå„ç§é“¾ç±»å‹ï¼ŒåŒ…æ‹¬ `RetrievalQAChain`ï¼Œç”¨äºå¯¹æ–‡æ¡£è¿›è¡Œé—®ç­”ï¼Œ`SummarizationChain`ï¼Œç”¨äºæ€»ç»“å¤šä¸ªæ–‡æ¡£ï¼Œä»¥åŠæˆ‘ä»¬ä»Šå¤©çš„é‡ç‚¹ï¼Œå³
    `ConversationChain`ã€‚
- en: 2.2 ConversationChain
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 ConversationChain
- en: '`ConversationChain`is used to facilitate interactive conversations by providing
    a framework for exchanging messages and storing conversation history. Hereâ€™s a
    sample code snippet to illustrate its usage:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConversationChain` ç”¨äºé€šè¿‡æä¾›ä¸€ä¸ªæ¶ˆæ¯äº¤æ¢å’Œå­˜å‚¨å¯¹è¯å†å²çš„æ¡†æ¶æ¥ä¿ƒè¿›äº’åŠ¨å¯¹è¯ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ç‰‡æ®µï¼Œä»¥è¯´æ˜å…¶ç”¨æ³•ï¼š'
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, the `ConversationChain` takes three inputs, *memory*, a LangChain
    component that holds the interaction history; *prompt*, the input to the LLM;
    and *llm*, the core large language model (e.g., GPT-3.5-Turbo, etc.).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œ`ConversationChain` æ¥å—ä¸‰ä¸ªè¾“å…¥ï¼Œ*memory*ï¼Œä¸€ä¸ªæŒæœ‰äº’åŠ¨å†å²çš„ LangChain ç»„ä»¶ï¼›*prompt*ï¼Œè¾“å…¥åˆ°
    LLM çš„å†…å®¹ï¼›ä»¥åŠ *llm*ï¼Œæ ¸å¿ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒGPT-3.5-Turbo ç­‰ï¼‰ã€‚
- en: Once the`ConversationChain` object is instantiated, we can simply call `conversation.predict()`
    with the user input to get LLMâ€™s response. The convenience with `ConversationChain`
    is that we can actually call `conversation.predict()` multiple times, and it automatically
    records the message history under the hood.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ `ConversationChain` å¯¹è±¡è¢«å®ä¾‹åŒ–ï¼Œæˆ‘ä»¬åªéœ€ä½¿ç”¨ç”¨æˆ·è¾“å…¥è°ƒç”¨ `conversation.predict()` å³å¯è·å¾— LLM
    çš„å“åº”ã€‚`ConversationChain` çš„ä¾¿åˆ©ä¹‹å¤„åœ¨äºï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥å¤šæ¬¡è°ƒç”¨ `conversation.predict()`ï¼Œå®ƒä¼šè‡ªåŠ¨åœ¨åå°è®°å½•æ¶ˆæ¯å†å²ã€‚
- en: In the next section, weâ€™ll harness the power of `ConversationChain`to create
    our chatbots and delve into how the memory, prompt template, and LLM are defined
    and utilized.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ `ConversationChain` çš„å¼ºå¤§åŠŸèƒ½åˆ›å»ºæˆ‘ä»¬çš„èŠå¤©æœºå™¨äººï¼Œå¹¶æ·±å…¥æ¢è®¨è®°å¿†ã€æç¤ºæ¨¡æ¿å’Œ LLM çš„å®šä¹‰ä¸ä½¿ç”¨ã€‚
- en: If you would like to learn more about LangChain, take a look at their [official
    documentation](https://python.langchain.com/docs/get_started/introduction.html).
    In addition, this [YouTube playlist](https://youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)
    also offers a comprehensive, hands-on introduction.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äº LangChain çš„ä¿¡æ¯ï¼Œå¯ä»¥æŸ¥çœ‹ä»–ä»¬çš„[å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/get_started/introduction.html)ã€‚æ­¤å¤–ï¼Œè¿™ä¸ª[YouTube
    æ’­æ”¾åˆ—è¡¨](https://youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)ä¹Ÿæä¾›äº†å…¨é¢çš„å®è·µä»‹ç»ã€‚
- en: 3\. Project Design
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. é¡¹ç›®è®¾è®¡
- en: Now that we have a clear understanding of what we want to build and the tools
    to build it, itâ€™s time to roll up our sleeves and dive into the code! In this
    section, weâ€™re going to focus on the nuts and bolts of creating our dual-chatbot
    interaction. First, weâ€™ll explore the class definition for a single chatbot and
    then expand on this to create a dual-chatbot class, enabling our two chatbots
    to interact. Weâ€™ll save the design of the app interface using Streamlit for Section
    4.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æˆ‘ä»¬å¯¹è¦æ„å»ºçš„å†…å®¹å’Œå·¥å…·æœ‰äº†æ˜ç¡®çš„äº†è§£ï¼Œå°±è¯¥åŠ¨æ‰‹ç¼–å†™ä»£ç äº†ï¼åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºåˆ›å»ºåŒèŠå¤©æœºå™¨äººäº¤äº’çš„ç»†èŠ‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ¢è®¨å•ä¸€èŠå¤©æœºå™¨äººçš„ç±»å®šä¹‰ï¼Œç„¶åæ‰©å±•è¿™ä¸€å®šä¹‰ä»¥åˆ›å»ºä¸€ä¸ªåŒèŠå¤©æœºå™¨äººç±»ï¼Œä½¿æˆ‘ä»¬çš„ä¸¤ä¸ªèŠå¤©æœºå™¨äººèƒ½å¤Ÿäº’ç›¸äº’åŠ¨ã€‚æˆ‘ä»¬å°†æŠŠä½¿ç”¨
    Streamlit è®¾è®¡åº”ç”¨ç•Œé¢çš„å·¥ä½œç•™åˆ°ç¬¬ 4 éƒ¨åˆ†ã€‚
- en: 3.1 Developing a single chatbot
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 å¼€å‘ä¸€ä¸ªå•ä¸€çš„èŠå¤©æœºå™¨äºº
- en: In this subsection, we will develop a single chatbot together, which will later
    be integrated into the dual-chatbot system. Letâ€™s start with the overall class
    design, then shift our attention to prompt engineering.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€èµ·å¼€å‘ä¸€ä¸ªå•ä¸€çš„èŠå¤©æœºå™¨äººï¼Œéšåå°†å…¶é›†æˆåˆ°åŒèŠå¤©æœºå™¨äººç³»ç»Ÿä¸­ã€‚è®©æˆ‘ä»¬ä»æ•´ä½“çš„ç±»è®¾è®¡å¼€å§‹ï¼Œç„¶åå°†æ³¨æ„åŠ›è½¬å‘æç¤ºå·¥ç¨‹ã€‚
- en: ğŸ—ï¸ **Class Design**
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ—ï¸ **ç±»è®¾è®¡**
- en: Our chatbot class should enable the management of an individual chatbot. This
    involves instantiating a chatbot with a user-specified LLM as its backbone, providing
    instructions based on the userâ€™s intent, and facilitating interactive multi-round
    conversations. With that in mind, letâ€™s start coding.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººç±»åº”è¯¥èƒ½å¤Ÿç®¡ç†ä¸€ä¸ªå•ç‹¬çš„èŠå¤©æœºå™¨äººã€‚è¿™åŒ…æ‹¬å®ä¾‹åŒ–ä¸€ä¸ªä»¥ç”¨æˆ·æŒ‡å®šçš„ LLM ä½œä¸ºåŸºç¡€çš„èŠå¤©æœºå™¨äººï¼Œæ ¹æ®ç”¨æˆ·çš„æ„å›¾æä¾›æŒ‡ä»¤ï¼Œå¹¶æ”¯æŒäº¤äº’å¼çš„å¤šè½®å¯¹è¯ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬å¼€å§‹ç¼–ç å§ã€‚
- en: 'First, import the necessary libraries:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œå¯¼å…¥å¿…è¦çš„åº“ï¼š
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we define the class constructor:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ç±»æ„é€ å‡½æ•°ï¼š
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Currently, you can only choose to use the native OpenAI API. Nevertheless, adding
    more backend LLMs is straightforward since LangChain supports various types (e.g.,
    Azure OpenAI endpoint, Anthropic chat models, PaLM API on Google Vertex AI, etc.).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼Œä½ åªèƒ½é€‰æ‹©ä½¿ç”¨åŸç”Ÿçš„ OpenAI APIã€‚ç„¶è€Œï¼Œæ·»åŠ æ›´å¤šåç«¯ LLM æ˜¯å¾ˆç®€å•çš„ï¼Œå› ä¸º LangChain æ”¯æŒå¤šç§ç±»å‹ï¼ˆä¾‹å¦‚ Azure OpenAI
    ç«¯ç‚¹ã€Anthropic èŠå¤©æ¨¡å‹ã€Google Vertex AI ä¸Šçš„ PaLM API ç­‰ï¼‰ã€‚
- en: Besides LLM, another important component we need to instantiate is *memory*,
    which tracks the conversation history. Here, we use `ConversationBufferMemory`
    for this purpose, which simply prepends the last few inputs/outputs to the current
    input of the chatbot. This is the simplest memory type offered in LangChain and
    itâ€™s sufficient for our current purpose.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº† LLMï¼Œæˆ‘ä»¬è¿˜éœ€è¦å®ä¾‹åŒ–å¦ä¸€ä¸ªé‡è¦çš„ç»„ä»¶â€”â€”*è®°å¿†*ï¼Œå®ƒè·Ÿè¸ªå¯¹è¯å†å²ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨`ConversationBufferMemory`æ¥å®ç°è¿™ä¸€ç›®çš„ï¼Œå®ƒä»…ä»…æ˜¯åœ¨èŠå¤©æœºå™¨äººçš„å½“å‰è¾“å…¥å‰æ·»åŠ æœ€åå‡ æ¡è¾“å…¥/è¾“å‡ºã€‚è¿™æ˜¯
    LangChain æä¾›çš„æœ€ç®€å•çš„è®°å¿†ç±»å‹ï¼Œå¯¹äºæˆ‘ä»¬å½“å‰çš„ç›®çš„å·²ç»è¶³å¤Ÿã€‚
- en: For a complete overview of other types of memory, please refer to the [official
    docs](https://python.langchain.com/docs/modules/memory/).
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¦å…¨é¢äº†è§£å…¶ä»–ç±»å‹çš„è®°å¿†ï¼Œè¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/modules/memory/)ã€‚
- en: 'Moving on, we need to have a class method that allows us to give instructions
    to the chatbot and make conversations with it. This is what `self.instruct()`
    for:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç»§ç»­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªç±»æ–¹æ³•ï¼Œå…è®¸æˆ‘ä»¬ç»™èŠå¤©æœºå™¨äººä¸‹è¾¾æŒ‡ä»¤å¹¶ä¸å…¶å¯¹è¯ã€‚è¿™å°±æ˜¯`self.instruct()`çš„ä½œç”¨ï¼š
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**We define a couple of settings to allow users to customize their learning
    experience.**'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬å®šä¹‰äº†ä¸€äº›è®¾ç½®ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰ä»–ä»¬çš„å­¦ä¹ ä½“éªŒã€‚**'
- en: 'In addition to what has been mentioned in â€œSection 1 Project Overviewâ€, we
    have four new attributes:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†åœ¨â€œç¬¬ 1 éƒ¨åˆ† é¡¹ç›®æ¦‚è¿°â€ä¸­æåˆ°çš„å†…å®¹å¤–ï¼Œæˆ‘ä»¬è¿˜æœ‰å››ä¸ªæ–°çš„å±æ€§ï¼š
- en: '`self.role/self.oppo_role:` this attribute takes the form of a dictionary that
    records the role name and corresponding actions. For instance:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.role/self.oppo_role:` è¿™ä¸ªå±æ€§çš„å½¢å¼æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œç”¨äºè®°å½•è§’è‰²åç§°åŠå…¶å¯¹åº”çš„åŠ¨ä½œã€‚ä¾‹å¦‚ï¼š'
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`self.oppo_role` represents the role taken by the other chatbot engaged in
    the conversation with the current chatbot. Itâ€™s essential because the current
    chatbot needs to understand who it is communicating with, providing necessary
    contextual information.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.oppo_role`è¡¨ç¤ºä¸å½“å‰èŠå¤©æœºå™¨äººè¿›è¡Œå¯¹è¯çš„å¦ä¸€ä¸ªèŠå¤©æœºå™¨äººæ‰€æ‰®æ¼”çš„è§’è‰²ã€‚è¿™æ˜¯é‡è¦çš„ï¼Œå› ä¸ºå½“å‰èŠå¤©æœºå™¨äººéœ€è¦äº†è§£å®ƒæ­£åœ¨ä¸è°æ²Ÿé€šï¼Œä»¥æä¾›å¿…è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚'
- en: '`self.scenario` sets the stage for the conversation. For â€œconversationâ€ learning
    mode, `self.scenario`represents the place where the conversation'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.scenario` ä¸ºå¯¹è¯è®¾ç½®äº†åœºæ™¯ã€‚å¯¹äºâ€œå¯¹è¯â€å­¦ä¹ æ¨¡å¼ï¼Œ`self.scenario` ä»£è¡¨å¯¹è¯å‘ç”Ÿçš„åœ°æ–¹ã€‚'
- en: is happening; for â€œdebateâ€ mode, `self.scenario`represents the debating topic.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£åœ¨å‘ç”Ÿï¼›å¯¹äºâ€œè¾©è®ºâ€æ¨¡å¼ï¼Œ`self.scenario` ä»£è¡¨è¾©è®ºçš„è¯é¢˜ã€‚
- en: Finally, `self.starter` is just a boolean flag to indicate if the current chatbot
    will initiate the conversation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œ`self.starter` åªæ˜¯ä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œç”¨äºæŒ‡ç¤ºå½“å‰èŠå¤©æœºå™¨äººæ˜¯å¦ä¼šå‘èµ·å¯¹è¯ã€‚
- en: '**We structure the prompt for the chatbot.**'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬ä¸ºèŠå¤©æœºå™¨äººæ„å»ºæç¤ºã€‚**'
- en: 'In OpenAI, a chat model generally takes a list of messages as input and returns
    a model-generated message as output. LangChain supports `SystemMessage`,`AIMessage`,
    `HumanMessage`: `SystemMessage` helps set the behavior of the chatbot, `AIMessage`
    stores previous chatbot responses, and `HumanMessage` provides requests or comments
    for the chatbot to respond to.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ OpenAI ä¸­ï¼Œä¸€ä¸ªèŠå¤©æ¨¡å‹é€šå¸¸æ¥å—ä¸€ç³»åˆ—æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›æ¨¡å‹ç”Ÿæˆçš„æ¶ˆæ¯ä½œä¸ºè¾“å‡ºã€‚LangChain æ”¯æŒ `SystemMessage`ã€`AIMessage`
    å’Œ `HumanMessage`ï¼š`SystemMessage` å¸®åŠ©è®¾ç½®èŠå¤©æœºå™¨äººçš„è¡Œä¸ºï¼Œ`AIMessage` å­˜å‚¨ä»¥å‰èŠå¤©æœºå™¨äººçš„å“åº”ï¼Œ`HumanMessage`
    æä¾›èŠå¤©æœºå™¨äººéœ€è¦å›åº”çš„è¯·æ±‚æˆ–è¯„è®ºã€‚
- en: LangChain conveniently offers `PromptTemplate` to streamline prompt generation
    and ingestion. For a chatbot application, we need to specify the `PromptTemplate`
    for all three message types. The most critical piece is setting the `SystemMessage`,
    which controls the chatbotâ€™s behavior. We have a separate method, `self._specify_system_message()`,
    to handle this, which weâ€™ll discuss in detail later.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain æ–¹ä¾¿åœ°æä¾›äº† `PromptTemplate` æ¥ç®€åŒ–æç¤ºç”Ÿæˆå’Œå¤„ç†ã€‚å¯¹äºèŠå¤©æœºå™¨äººåº”ç”¨ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ‰€æœ‰ä¸‰ç§æ¶ˆæ¯ç±»å‹æŒ‡å®š `PromptTemplate`ã€‚æœ€å…³é”®çš„éƒ¨åˆ†æ˜¯è®¾ç½®
    `SystemMessage`ï¼Œå®ƒæ§åˆ¶èŠå¤©æœºå™¨äººçš„è¡Œä¸ºã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªå•ç‹¬çš„æ–¹æ³• `self._specify_system_message()` æ¥å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œç¨åæˆ‘ä»¬ä¼šè¯¦ç»†è®¨è®ºã€‚
- en: '**Finally, we bring all the pieces together and construct a** `ConversationChain.`'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœ€åï¼Œæˆ‘ä»¬æŠŠæ‰€æœ‰éƒ¨åˆ†æ•´åˆåœ¨ä¸€èµ·ï¼Œæ„å»ºä¸€ä¸ª** `ConversationChain`ã€‚'
- en: ğŸ–‹ï¸ **Prompt Design**
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ–‹ï¸ **æç¤ºè®¾è®¡**
- en: 'Our focus now turns to guiding the chatbot in participating in the conversation
    as desired by the user. To this end, we have the `self._specify_system_message()`
    method. The signature of this method is shown below:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨çš„é‡ç‚¹æ˜¯æŒ‡å¯¼èŠå¤©æœºå™¨äººæ ¹æ®ç”¨æˆ·çš„éœ€æ±‚å‚ä¸å¯¹è¯ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æœ‰ `self._specify_system_message()` æ–¹æ³•ã€‚è¯¥æ–¹æ³•çš„ç­¾åå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Essentially, this method compiles a string, which will then be fed into the
    `SystemMessagePromptTemplate.from_template()` to instruct the chatbot, as demonstrated
    in the definition of the `self.instruct()` method above. Weâ€™ll dissect this â€œlong
    stringâ€ in the following to understand how each language learning requirement
    is incorporated into the prompt.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è´¨ä¸Šï¼Œè¿™ä¸ªæ–¹æ³•ç¼–è¯‘ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç„¶åå°†å…¶è¾“å…¥åˆ° `SystemMessagePromptTemplate.from_template()` ä»¥æŒ‡ç¤ºèŠå¤©æœºå™¨äººï¼Œå¦‚ä¸Šé¢
    `self.instruct()` æ–¹æ³•çš„å®šä¹‰æ‰€ç¤ºã€‚æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­åˆ†æè¿™ä¸ªâ€œé•¿å­—ç¬¦ä¸²â€ï¼Œä»¥äº†è§£æ¯ä¸ªè¯­è¨€å­¦ä¹ éœ€æ±‚å¦‚ä½•èå…¥æç¤ºä¸­ã€‚
- en: 1ï¸âƒ£ Session length
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ ä¼šè¯é•¿åº¦
- en: The session length is controlled by directly specifying the maximum number of
    exchanges that can happen within one session. Those numbers are hard-coded for
    the time being.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼šè¯é•¿åº¦é€šè¿‡ç›´æ¥æŒ‡å®šåœ¨ä¸€ä¸ªä¼šè¯ä¸­å¯ä»¥å‘ç”Ÿçš„æœ€å¤§äº¤æ¢æ¬¡æ•°æ¥æ§åˆ¶ã€‚è¿™äº›æ•°å­—ç›®å‰æ˜¯ç¡¬ç¼–ç çš„ã€‚
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 2ï¸âƒ£ Number of sentences the chatbot can say in one exchange
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ èŠå¤©æœºå™¨äººåœ¨ä¸€æ¬¡äº¤æ¢ä¸­å¯ä»¥è¯´çš„å¥å­æ•°é‡
- en: Apart from limiting the total number of allowed exchanges, itâ€™s also beneficial
    to restrict how much a chatbot can say within one exchange, or equivalently, the
    number of sentences.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†é™åˆ¶å…è®¸çš„æ€»äº¤æ¢æ¬¡æ•°å¤–ï¼Œé™åˆ¶èŠå¤©æœºå™¨äººåœ¨ä¸€æ¬¡äº¤æ¢ä¸­å¯ä»¥è¯´å¤šå°‘ä¹Ÿæ˜¯æœ‰ç›Šçš„ï¼Œæˆ–è€…ç­‰æ•ˆåœ°ï¼Œé™åˆ¶å¥å­æ•°é‡ã€‚
- en: In my experiments, there is usually no need to constrain this in â€œconversationâ€
    mode, as the chatbot mimics a real-life dialogue and tends to speak at a reasonable
    length. However, in â€œdebateâ€ mode, itâ€™s necessary to impose a limit. Otherwise,
    the chatbot may continue speaking, eventually generating an â€œessayâ€ ğŸ˜†.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘çš„å®éªŒä¸­ï¼Œé€šå¸¸ä¸éœ€è¦åœ¨â€œå¯¹è¯â€æ¨¡å¼ä¸­é™åˆ¶è¿™ä¸ªï¼Œå› ä¸ºèŠå¤©æœºå™¨äººæ¨¡æ‹ŸçœŸå®å¯¹è¯ï¼Œå¾€å¾€ä¼šåœ¨åˆç†çš„é•¿åº¦å†…å‘è¨€ã€‚ç„¶è€Œï¼Œåœ¨â€œè¾©è®ºâ€æ¨¡å¼ä¸‹ï¼Œéœ€è¦æ–½åŠ é™åˆ¶ï¼Œå¦åˆ™èŠå¤©æœºå™¨äººå¯èƒ½ä¼šç»§ç»­å‘è¨€ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ç¯‡â€œæ–‡ç« â€
    ğŸ˜†ã€‚
- en: 'Similar to limiting the session length, the numbers that restrict the speech
    length are also hard-coded and correspond with the userâ€™s proficiency level in
    the target language:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äºé™åˆ¶ä¼šè¯é•¿åº¦ï¼Œé™åˆ¶æ¼”è®²é•¿åº¦çš„æ•°å­—ä¹Ÿæ˜¯ç¡¬ç¼–ç çš„ï¼Œå¹¶ä¸”ä¸ç”¨æˆ·åœ¨ç›®æ ‡è¯­è¨€ä¸­çš„ç†Ÿç»ƒç¨‹åº¦ç›¸å¯¹åº”ï¼š
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 3ï¸âƒ£ Determine speech complexity
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£ ç¡®å®šæ¼”è®²å¤æ‚åº¦
- en: 'Here, we regulate the complexity level of the language the chatbot can use:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è°ƒæ•´èŠå¤©æœºå™¨äººå¯ä»¥ä½¿ç”¨çš„è¯­è¨€å¤æ‚åº¦çº§åˆ«ï¼š
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 4ï¸âƒ£ Put everything together!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 4ï¸âƒ£ æŠŠæ‰€æœ‰å†…å®¹æ•´åˆèµ·æ¥ï¼
- en: 'Hereâ€™s what the instruction looks like for different learning modes:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸åŒå­¦ä¹ æ¨¡å¼ä¸‹çš„æŒ‡ä»¤ç¤ºä¾‹ï¼š
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 5ï¸âƒ£ Who speaks first?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 5ï¸âƒ£ è°å…ˆå‘è¨€ï¼Ÿ
- en: 'Finally, we instruct the chatbot whether it should speak first or wait for
    the response from the opponent AI:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬æŒ‡ç¤ºèŠå¤©æœºå™¨äººæ˜¯å¦åº”è¯¥å…ˆå‘è¨€æˆ–ç­‰å¾…å¯¹æ–¹AIçš„å›åº”ï¼š
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we have completed the prompt design ğŸ‰ As a quick summary, this is what
    we have developed so far:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å®Œæˆäº†æç¤ºè®¾è®¡ğŸ‰ ç®€è¦æ€»ç»“ä¸€ä¸‹ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢å¼€å‘çš„å†…å®¹ï¼š
- en: '![](../Images/6c9261f866e1940098eee750f07557ee.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c9261f866e1940098eee750f07557ee.png)'
- en: The single chatbot class. (Image by author)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å•ä¸€èŠå¤©æœºå™¨äººç±»ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: 3.2 Developing a dual-chatbot system
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 å¼€å‘åŒèŠå¤©æœºå™¨äººç³»ç»Ÿ
- en: Now we arrive at the exciting part! In this subsection, we will develop a dual-chatbot
    class to let two chatbots interact with each other ğŸ’¬ğŸ’¬
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ¥åˆ°äº†ä»¤äººå…´å¥‹çš„éƒ¨åˆ†ï¼åœ¨è¿™ä¸€å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å¼€å‘ä¸€ä¸ªåŒèŠå¤©æœºå™¨äººç±»ï¼Œè®©ä¸¤ä¸ªèŠå¤©æœºå™¨äººç›¸äº’äº’åŠ¨ğŸ’¬ğŸ’¬
- en: ğŸ—ï¸ **Class Design**
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ—ï¸ **ç±»è®¾è®¡**
- en: 'Thanks to the previously developed single Chatbot class, we can effortlessly
    instantiate two chatbots in the class constructor:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºä¹‹å‰å¼€å‘çš„å•ä¸€èŠå¤©æœºå™¨äººç±»ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°åœ¨ç±»æ„é€ å‡½æ•°ä¸­å®ä¾‹åŒ–ä¸¤ä¸ªèŠå¤©æœºå™¨äººï¼š
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `self.chatbots` is a dictionary designed to store information related to
    both bots:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.chatbots`æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œç”¨äºå­˜å‚¨ä¸ä¸¤ä¸ªæœºå™¨äººç›¸å…³çš„ä¿¡æ¯ï¼š'
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `self._reset_conversation_history` serves to initiate a fresh conversation
    history and provide the initial instructions to the chatbots:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`self._reset_conversation_history`ç”¨äºå¯åŠ¨ä¸€ä¸ªæ–°çš„å¯¹è¯å†å²å¹¶æä¾›åˆå§‹æŒ‡ä»¤ç»™èŠå¤©æœºå™¨äººï¼š'
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To facilitate interaction between the two chatbots, we employ `self.step()`
    method. This method allows for one round of interaction between the two bots:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¿ƒè¿›ä¸¤ä¸ªèŠå¤©æœºå™¨äººä¹‹é—´çš„äº’åŠ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†`self.step()`æ–¹æ³•ã€‚æ­¤æ–¹æ³•å…è®¸ä¸¤ä¸ªæœºå™¨äººä¹‹é—´è¿›è¡Œä¸€è½®äº’åŠ¨ï¼š
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Notice that we have embedded a method called `self.translate()`. The purpose
    of this method is to translate the script into English. This functionality could
    be useful for language learners as they can understand the meaning of the conversation
    generated in the target language.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åµŒå…¥äº†ä¸€ä¸ªåä¸º`self.translate()`çš„æ–¹æ³•ã€‚æ­¤æ–¹æ³•çš„ç›®çš„æ˜¯å°†è„šæœ¬ç¿»è¯‘æˆè‹±è¯­ã€‚æ­¤åŠŸèƒ½å¯¹äºè¯­è¨€å­¦ä¹ è€…å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºä»–ä»¬å¯ä»¥ç†è§£åœ¨ç›®æ ‡è¯­è¨€ä¸­ç”Ÿæˆçš„å¯¹è¯çš„å«ä¹‰ã€‚
- en: 'To achieve the translation functionality, we can employ the basic `LLMChain`,
    which requires a backend LLM model and a prompt for instruction:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºå®ç°ç¿»è¯‘åŠŸèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŸºæœ¬çš„`LLMChain`ï¼Œå®ƒéœ€è¦ä¸€ä¸ªåå°LLMæ¨¡å‹å’Œä¸€ä¸ªæŒ‡ä»¤æç¤ºï¼š
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, it could be beneficial for language learners to have a summary of
    the key language learning points of the generated conversation script, be it key
    vocabulary, grammar points, or function phrases. For that, we can include a `self.summary()`
    method:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè¯­è¨€å­¦ä¹ è€…èƒ½å¤Ÿè·å¾—ç”Ÿæˆå¯¹è¯è„šæœ¬çš„å…³é”®è¯­è¨€å­¦ä¹ ç‚¹çš„æ€»ç»“å¯èƒ½æ˜¯æœ‰ç›Šçš„ï¼Œæ— è®ºæ˜¯å…³é”®è¯æ±‡ã€è¯­æ³•ç‚¹è¿˜æ˜¯åŠŸèƒ½çŸ­è¯­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥åŒ…å«ä¸€ä¸ª`self.summary()`æ–¹æ³•ï¼š
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Similar to the `self.translate()` method, we employed a basic `LLMChain` to
    perform the desired task. Note that we explicitly ask the language model to summarize
    key language learning points based on the userâ€™s proficiency level.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äº`self.translate()`æ–¹æ³•ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªåŸºæœ¬çš„`LLMChain`æ¥æ‰§è¡Œæ‰€éœ€çš„ä»»åŠ¡ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ˜ç¡®è¦æ±‚è¯­è¨€æ¨¡å‹æ ¹æ®ç”¨æˆ·çš„ç†Ÿç»ƒç¨‹åº¦æ€»ç»“å…³é”®çš„è¯­è¨€å­¦ä¹ ç‚¹ã€‚
- en: 'With that, we have completed the development of the dual-chatbot class ğŸ¥‚ As
    a quick summary, this is what we have developed so far:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†åŒèŠå¤©æœºå™¨äººç±»çš„å¼€å‘ğŸ¥‚ ç®€è¦æ€»ç»“ä¸€ä¸‹ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢å¼€å‘çš„å†…å®¹ï¼š
- en: '![](../Images/faa19b5a62676515982824900850cc7b.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/faa19b5a62676515982824900850cc7b.png)'
- en: The single chatbot & Dual-chatbot class. (Image by author)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å•ä¸€èŠå¤©æœºå™¨äºº & åŒèŠå¤©æœºå™¨äººç±»ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: 4\. App Interface Design with Streamlit
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. ä½¿ç”¨Streamlitè¿›è¡Œåº”ç”¨ç¨‹åºç•Œé¢è®¾è®¡
- en: We are now ready to develop the user interface ğŸ–¥ï¸ For this project, we will
    use the Streamlit library to construct the frontend.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¼€å‘ç”¨æˆ·ç•Œé¢ğŸ–¥ï¸ å¯¹äºè¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Streamlitåº“æ¥æ„å»ºå‰ç«¯ã€‚
- en: If youâ€™re unfamiliar, Streamlit is an open-source Python library for creating
    interactive web applications focused on data science and machine learning. It
    simplifies the process of building and deploying apps by providing an easy-to-use
    API, live code reloading for instant updates, interactive widgets for user input,
    support for data visualization libraries, and the ability to incorporate rich
    media.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸ç†Ÿæ‚‰ï¼ŒStreamlitæ˜¯ä¸€ä¸ªå¼€æºPythonåº“ï¼Œç”¨äºåˆ›å»ºä¸“æ³¨äºæ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„äº’åŠ¨å¼Webåº”ç”¨ç¨‹åºã€‚å®ƒé€šè¿‡æä¾›æ˜“äºä½¿ç”¨çš„APIã€å³æ—¶æ›´æ–°çš„å®æ—¶ä»£ç é‡è½½ã€ç”¨äºç”¨æˆ·è¾“å…¥çš„äº’åŠ¨å°éƒ¨ä»¶ã€å¯¹æ•°æ®å¯è§†åŒ–åº“çš„æ”¯æŒä»¥åŠåŒ…å«ä¸°å¯Œåª’ä½“çš„èƒ½åŠ›ï¼Œç®€åŒ–äº†æ„å»ºå’Œéƒ¨ç½²åº”ç”¨ç¨‹åºçš„è¿‡ç¨‹ã€‚
- en: 'Letâ€™s initiate with a new Python script app.py, and import the necessary libraries:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ä¸€ä¸ªæ–°çš„Pythonè„šæœ¬app.pyå¼€å§‹ï¼Œå¹¶å¯¼å…¥å¿…è¦çš„åº“ï¼š
- en: '[PRE17]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Alongside the main `streamlit`library, we also import the `streamlit_chat` library,
    a community-built Streamlit component specifically designed for creating chatbot
    UIs. Our previously-developed `DualChatbot` class is stored in the *chatbot.py*
    file, so we need to import that as well. Lastly, we import `gTTS`, which stands
    for *Google Text-to-Speech,* to add audio to the bot-generated conversation script
    in this project.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†ä¸»è¦çš„`streamlit`åº“ï¼Œæˆ‘ä»¬è¿˜å¯¼å…¥äº†`streamlit_chat`åº“ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±ç¤¾åŒºæ„å»ºçš„Streamlitç»„ä»¶ï¼Œä¸“é—¨ç”¨äºåˆ›å»ºèŠå¤©æœºå™¨äººç”¨æˆ·ç•Œé¢ã€‚æˆ‘ä»¬ä¹‹å‰å¼€å‘çš„`DualChatbot`ç±»å­˜å‚¨åœ¨*chatbot.py*æ–‡ä»¶ä¸­ï¼Œå› æ­¤ä¹Ÿéœ€è¦å¯¼å…¥è¯¥æ–‡ä»¶ã€‚æœ€åï¼Œæˆ‘ä»¬å¯¼å…¥`gTTS`ï¼Œå³*Google
    Text-to-Speech*ï¼Œä»¥ä¸ºè¿™ä¸ªé¡¹ç›®ä¸­çš„æœºå™¨äººç”Ÿæˆçš„å¯¹è¯è„šæœ¬æ·»åŠ éŸ³é¢‘ã€‚
- en: 'Before we configure the Streamlit interface, letâ€™s first define the language
    learning settings:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é…ç½®Streamlitç•Œé¢ä¹‹å‰ï¼Œè®©æˆ‘ä»¬é¦–å…ˆå®šä¹‰è¯­è¨€å­¦ä¹ è®¾ç½®ï¼š
- en: '[PRE18]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `AVATAR_SEED` is used for generating different avatar icons for different
    chatbots.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`AVATAR_SEED`ç”¨äºä¸ºä¸åŒçš„èŠå¤©æœºå™¨äººç”Ÿæˆä¸åŒçš„å¤´åƒå›¾æ ‡ã€‚'
- en: 'We begin by setting up the basic layout of the user interface and establishing
    options for the user to select:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼€å§‹è®¾ç½®ç”¨æˆ·ç•Œé¢çš„åŸºæœ¬å¸ƒå±€ï¼Œå¹¶å»ºç«‹ä¾›ç”¨æˆ·é€‰æ‹©çš„é€‰é¡¹ï¼š
- en: '[PRE19]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note the introduction of a `time_delay`variable. Itâ€™s used for specifying the
    waiting time between displaying two consecutive messages. If this delay is set
    to zero, the exchanges generated between two chatbots will appear in the app swiftly
    (limited only by OpenAIâ€™s response time). However, for user experience, it could
    be beneficial to allow enough time for the user to read the generated message
    before the next exchange appears.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„å¼•å…¥äº†`time_delay`å˜é‡ã€‚å®ƒç”¨äºæŒ‡å®šæ˜¾ç¤ºä¸¤ä¸ªè¿ç»­æ¶ˆæ¯ä¹‹é—´çš„ç­‰å¾…æ—¶é—´ã€‚å¦‚æœæ­¤å»¶è¿Ÿè®¾ç½®ä¸ºé›¶ï¼Œåˆ™ä¸¤ä¸ªèŠå¤©æœºå™¨äººä¹‹é—´ç”Ÿæˆçš„äº¤æ¢å°†è¿…é€Ÿå‡ºç°åœ¨åº”ç”¨ç¨‹åºä¸­ï¼ˆä»…å—é™äºOpenAIçš„å“åº”æ—¶é—´ï¼‰ã€‚ç„¶è€Œï¼Œä¸ºäº†ç”¨æˆ·ä½“éªŒï¼Œåœ¨ä¸‹ä¸€æ¬¡äº¤æ¢å‡ºç°ä¹‹å‰ï¼Œå…è®¸ç”¨æˆ·æœ‰è¶³å¤Ÿçš„æ—¶é—´é˜…è¯»ç”Ÿæˆçš„æ¶ˆæ¯å¯èƒ½æ˜¯æœ‰ç›Šçš„ã€‚
- en: 'Next, we initialize the Streamlit session state to store user-specific session
    data in the Streamlit app:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆå§‹åŒ–Streamlitä¼šè¯çŠ¶æ€ä»¥å­˜å‚¨ç”¨æˆ·ç‰¹å®šçš„ä¼šè¯æ•°æ®ï¼š
- en: '[PRE20]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here we answer two questions:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬å›ç­”ä¸¤ä¸ªé—®é¢˜ï¼š
- en: 1ï¸âƒ£ First of all, why do we need â€œsession_stateâ€?
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ é¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦â€œsession_stateâ€ï¼Ÿ
- en: In Streamlit, every time the user interacts with the app, Streamlit reruns the
    entire script from top to bottom, updating the appâ€™s output accordingly. However,
    this reactive nature of Streamlit can pose a challenge when you want to maintain
    user-specific data or preserve state across different interactions or pages within
    the app. Since Streamlit reloads the script on every user interaction, regular
    Python variables would lose their values, and the app would reset to its initial
    state.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Streamlitä¸­ï¼Œæ¯æ¬¡ç”¨æˆ·ä¸åº”ç”¨ç¨‹åºäº¤äº’æ—¶ï¼ŒStreamlitä¼šä»å¤´åˆ°å°¾é‡æ–°è¿è¡Œæ•´ä¸ªè„šæœ¬ï¼Œæ›´æ–°åº”ç”¨ç¨‹åºçš„è¾“å‡ºã€‚ç„¶è€Œï¼ŒStreamlitçš„è¿™ç§ååº”æ€§ç‰¹å¾åœ¨ä½ æƒ³è¦ç»´æŠ¤ç”¨æˆ·ç‰¹å®šæ•°æ®æˆ–åœ¨ä¸åŒäº¤äº’æˆ–é¡µé¢ä¹‹é—´ä¿ç•™çŠ¶æ€æ—¶å¯èƒ½ä¼šæˆä¸ºæŒ‘æˆ˜ã€‚ç”±äºStreamlitåœ¨æ¯æ¬¡ç”¨æˆ·äº¤äº’æ—¶éƒ½ä¼šé‡æ–°åŠ è½½è„šæœ¬ï¼Œå¸¸è§„Pythonå˜é‡ä¼šä¸¢å¤±å…¶å€¼ï¼Œåº”ç”¨ç¨‹åºå°†é‡ç½®ä¸ºåˆå§‹çŠ¶æ€ã€‚
- en: This is where the session_state comes in. Session state in Streamlit provides
    a way to store and retrieve data that persists throughout the userâ€™s session,
    even when the app is reloaded or the user navigates between different components
    or pages. It allows you to maintain stateful information and preserve the appâ€™s
    context for each user.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯`session_state`å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚Streamlitä¸­çš„ä¼šè¯çŠ¶æ€æä¾›äº†ä¸€ç§å­˜å‚¨å’Œæ£€ç´¢æ•°æ®çš„æ–¹å¼ï¼Œè¿™äº›æ•°æ®åœ¨ç”¨æˆ·ä¼šè¯æœŸé—´ä¼šæŒä¹…å­˜åœ¨ï¼Œå³ä½¿åº”ç”¨ç¨‹åºè¢«é‡æ–°åŠ è½½æˆ–ç”¨æˆ·åœ¨ä¸åŒç»„ä»¶æˆ–é¡µé¢ä¹‹é—´å¯¼èˆªæ—¶ã€‚å®ƒå…è®¸ä½ ä¿æŒçŠ¶æ€ä¿¡æ¯å¹¶ä¸ºæ¯ä¸ªç”¨æˆ·ä¿ç•™åº”ç”¨ç¨‹åºçš„ä¸Šä¸‹æ–‡ã€‚
- en: 2ï¸âƒ£ Secondly, what are those variables stored in the session_state?
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ å…¶æ¬¡ï¼Œ`session_state`ä¸­å­˜å‚¨äº†å“ªäº›å˜é‡ï¼Ÿ
- en: 'â€œ**bot1_mesg**â€ is a list, where each element of the list is a dictionary that
    holds the messages spoken by the first chatbot. It has the following keys: â€œroleâ€,
    â€œcontentâ€, and â€œtranslationâ€. The same definition applies to the â€œ**bot2_mesg**â€.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: â€œ**bot1_mesg**â€æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ç¬¬ä¸€å°èŠå¤©æœºå™¨äººè¯´çš„è¯ã€‚å®ƒå…·æœ‰ä»¥ä¸‹é”®ï¼šâ€œroleâ€ã€â€œcontentâ€å’Œâ€œtranslationâ€ã€‚åŒæ ·çš„å®šä¹‰é€‚ç”¨äºâ€œ**bot2_mesg**â€ã€‚
- en: â€œ**batch_flag**â€ is a boolean flag to indicate whether the conversation exchanges
    are shown all at once or with a time delay. In the current design, the chats between
    two bots will appear with a time delay when their conversation is generated for
    the first time. Afterward, the user may want to see the translations of or add
    audio to the generated conversation, the stored conversation messages (in â€œ**bot1_mesg**â€
    and â€œ**bot2_mesg**â€) will be shown all at once. This is beneficial as we donâ€™t
    need to call OpenAI API again to reduce cost and latency.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: â€œ**batch_flag**â€ æ˜¯ä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œç”¨äºæŒ‡ç¤ºå¯¹è¯äº¤æµæ˜¯å¦ä¸€æ¬¡æ€§æ˜¾ç¤ºæˆ–æœ‰æ—¶é—´å»¶è¿Ÿã€‚åœ¨å½“å‰è®¾è®¡ä¸­ï¼Œå½“ä¸¤ä¸ªèŠå¤©æœºå™¨äººä¹‹é—´çš„å¯¹è¯é¦–æ¬¡ç”Ÿæˆæ—¶ï¼Œå®ƒä»¬çš„èŠå¤©å°†ä¼šæœ‰æ—¶é—´å»¶è¿Ÿåœ°å‡ºç°ã€‚ä¹‹åï¼Œç”¨æˆ·å¯èƒ½å¸Œæœ›æŸ¥çœ‹ç”Ÿæˆå¯¹è¯çš„ç¿»è¯‘æˆ–æ·»åŠ éŸ³é¢‘ï¼Œå­˜å‚¨çš„å¯¹è¯æ¶ˆæ¯ï¼ˆåœ¨â€œ**bot1_mesg**â€å’Œâ€œ**bot2_mesg**â€ä¸­ï¼‰å°†ä¸€æ¬¡æ€§æ˜¾ç¤ºã€‚è¿™æ˜¯æœ‰åˆ©çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦å†æ¬¡è°ƒç”¨
    OpenAI APIï¼Œä»è€Œå‡å°‘æˆæœ¬å’Œå»¶è¿Ÿã€‚
- en: â€œ**translate_flag**â€ and â€œ**audio_flag**â€ are used to indicate if the translation
    and/or audio will be shown next to the original conversation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: â€œ**translate_flag**â€ å’Œ â€œ**audio_flag**â€ ç”¨äºæŒ‡ç¤ºç¿»è¯‘å’Œ/æˆ–éŸ³é¢‘æ˜¯å¦ä¼šæ˜¾ç¤ºåœ¨åŸå§‹å¯¹è¯æ—è¾¹ã€‚
- en: â€œ**message_counter**â€ is a counter that adds one whenever a message from chabot
    is displayed. The idea is to assign the message ID with this counter, as Streamlit
    requires that each UI component needs to have a unique ID.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: â€œ**message_counter**â€ æ˜¯ä¸€ä¸ªè®¡æ•°å™¨ï¼Œæ¯å½“ä¸€ä¸ªæ¥è‡ªèŠå¤©æœºå™¨äººçš„æ¶ˆæ¯æ˜¾ç¤ºæ—¶ï¼Œå®ƒä¼šåŠ ä¸€ã€‚è¿™ä¸ªæƒ³æ³•æ˜¯å°†æ¶ˆæ¯ ID ä¸æ­¤è®¡æ•°å™¨å…³è”ï¼Œå› ä¸º Streamlit
    è¦æ±‚æ¯ä¸ª UI ç»„ä»¶å¿…é¡»æœ‰å”¯ä¸€çš„ IDã€‚
- en: 'Now we can introduce the logic of letting two chatbots interact and generate
    conversations:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼•å…¥è®©ä¸¤ä¸ªèŠå¤©æœºå™¨äººäº’åŠ¨å¹¶ç”Ÿæˆå¯¹è¯çš„é€»è¾‘ï¼š
- en: '[PRE21]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Upon running the script for the first time, there will be no â€œ**dual_chatbots**â€
    key stored in the session_state (as the dual-chatbot has not been created yet).
    As a result, the code snippet shown above will be executed when the user hits
    the â€œ**Generate**â€ button on the sidebar. The two chatbots will chat back and
    forth a given number of times, and all the conversation messages are recorded
    in the session_state. The `show_message()`function is a helper function designed
    to be the sole interface to style the message display. We will go back to it at
    the end of this section.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç¬¬ä¸€æ¬¡è¿è¡Œè„šæœ¬æ—¶ï¼Œä¼šè¯çŠ¶æ€ä¸­å°†æ²¡æœ‰â€œ**dual_chatbots**â€é”®ï¼ˆå› ä¸ºåŒèŠå¤©æœºå™¨äººå°šæœªåˆ›å»ºï¼‰ã€‚å› æ­¤ï¼Œå½“ç”¨æˆ·ç‚¹å‡»ä¾§è¾¹æ ä¸Šçš„â€œ**Generate**â€æŒ‰é’®æ—¶ï¼Œä¸Šè¿°ä»£ç ç‰‡æ®µå°†è¢«æ‰§è¡Œã€‚ä¸¤ä¸ªèŠå¤©æœºå™¨äººå°†å¾€è¿”èŠå¤©ç»™å®šæ¬¡æ•°ï¼Œæ‰€æœ‰å¯¹è¯æ¶ˆæ¯éƒ½è®°å½•åœ¨ä¼šè¯çŠ¶æ€ä¸­ã€‚`show_message()`
    å‡½æ•°æ˜¯ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œæ—¨åœ¨æˆä¸ºå”¯ä¸€çš„æ¥å£æ¥æ ·å¼åŒ–æ¶ˆæ¯æ˜¾ç¤ºã€‚æˆ‘ä»¬å°†åœ¨æœ¬èŠ‚æœ«å°¾å†æ¬¡å›åˆ°å®ƒã€‚
- en: 'Now, if the user interacts with the app and changes some settings, Streamlit
    will rerun the entire script from the top. Since we have already generated the
    desired conversation script, there is no need to invoke OpenAI API again. Instead,
    we can simply retrieve the stored information:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¦‚æœç”¨æˆ·ä¸åº”ç”¨äº’åŠ¨å¹¶æ›´æ”¹ä¸€äº›è®¾ç½®ï¼ŒStreamlit å°†ä»å¤´å¼€å§‹é‡æ–°è¿è¡Œæ•´ä¸ªè„šæœ¬ã€‚ç”±äºæˆ‘ä»¬å·²ç»ç”Ÿæˆäº†æ‰€éœ€çš„å¯¹è¯è„šæœ¬ï¼Œå› æ­¤æ— éœ€å†æ¬¡è°ƒç”¨ OpenAI
    APIã€‚ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°æ£€ç´¢å­˜å‚¨çš„ä¿¡æ¯ï¼š
- en: '[PRE22]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note that there is another flag called â€œ**first_time_exec**â€ in the session
    state. This is used to indicate if the originally generated script has already
    been shown on the app. If we remove this check, the same messages will appear
    twice when running the app for the first time.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ä¼šè¯çŠ¶æ€ä¸­è¿˜æœ‰ä¸€ä¸ªåä¸ºâ€œ**first_time_exec**â€çš„æ ‡å¿—ã€‚è¿™ä¸ªæ ‡å¿—ç”¨äºæŒ‡ç¤ºåŸå§‹ç”Ÿæˆçš„è„šæœ¬æ˜¯å¦å·²ç»åœ¨åº”ç”¨ä¸­æ˜¾ç¤ºã€‚å¦‚æœæˆ‘ä»¬å»æ‰è¿™ä¸ªæ£€æŸ¥ï¼Œåº”ç”¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ç›¸åŒçš„æ¶ˆæ¯å°†ä¼šå‡ºç°ä¸¤æ¬¡ã€‚
- en: The only thing left is the inclusion of the summary of key learning points in
    the UI. For that, we can use `st.expander`. In Streamlit, `st.expander` is useful
    when we have a large amount of content or information that we want to present
    in a condensed form, initially hidden from view. When the user clicks the expander,
    the content within it will expand or collapse, thus revealing or hiding the additional
    details.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: å‰©ä¸‹çš„å”¯ä¸€ä»»åŠ¡æ˜¯åœ¨ UI ä¸­åŠ å…¥å…³é”®å­¦ä¹ ç‚¹çš„æ€»ç»“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `st.expander`ã€‚åœ¨ Streamlit ä¸­ï¼Œ`st.expander`
    å¯¹äºæˆ‘ä»¬å¸Œæœ›ä»¥ç®€æ´å½¢å¼å‘ˆç°çš„å¤§é‡å†…å®¹æˆ–ä¿¡æ¯å¾ˆæœ‰ç”¨ï¼Œæœ€åˆéšè—è§†å›¾ã€‚å½“ç”¨æˆ·ç‚¹å‡»æ‰©å±•å™¨æ—¶ï¼Œå†…å®¹å°†å±•å¼€æˆ–æŠ˜å ï¼Œä»è€Œæ˜¾ç¤ºæˆ–éšè—é¢å¤–çš„ç»†èŠ‚ã€‚
- en: '[PRE23]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Since the summary of key learning points is also generated by calling OpenAI
    API, we can save the generated summary to the session_state so that the content
    can be retrieved if the script is run a second time.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå…³é”®å­¦ä¹ ç‚¹çš„æ€»ç»“ä¹Ÿæ˜¯é€šè¿‡è°ƒç”¨ OpenAI API ç”Ÿæˆçš„ï¼Œæˆ‘ä»¬å¯ä»¥å°†ç”Ÿæˆçš„æ€»ç»“ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€ä¸­ï¼Œä»¥ä¾¿å¦‚æœè„šæœ¬ç¬¬äºŒæ¬¡è¿è¡Œæ—¶å¯ä»¥æ£€ç´¢è¿™äº›å†…å®¹ã€‚
- en: 'Finally, letâ€™s complete the Streamlit UI design with the helper function `show_message`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè®©æˆ‘ä»¬ç”¨è¾…åŠ©å‡½æ•° `show_message` å®Œæˆ Streamlit UI è®¾è®¡ï¼š
- en: '[PRE24]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'A few points warrant further explanation:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ä¸ªè¦ç‚¹éœ€è¦è¿›ä¸€æ­¥è§£é‡Šï¼š
- en: 1ï¸âƒ£ The `message()` object
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ `message()` å¯¹è±¡
- en: 'This is part of the `streamlit_chat` library and is used to display messages.
    In its simplest form, we have:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éƒ¨åˆ†å±äº `streamlit_chat` åº“ï¼Œç”¨äºæ˜¾ç¤ºæ¶ˆæ¯ã€‚åœ¨æœ€ç®€å•çš„å½¢å¼ä¸‹ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '[PRE25]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](../Images/3a8358fe3d3a897bcdca1aa15caa5e79.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a8358fe3d3a897bcdca1aa15caa5e79.png)'
- en: (Image from streamlit_chat [GitHub repository](https://github.com/AI-Yash/st-chat))
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: (å›¾ç‰‡æ¥è‡ª streamlit_chat [GitHub ä»“åº“](https://github.com/AI-Yash/st-chat))
- en: where the argument `is_user` determines if the message should be left-aligned
    or right-aligned. In our code snippet for `show_message`, we have also specified
    `avatar_style` and `seed` to set the avatar icons for two chatbots. The `key`
    argument is merely for assigning a unique ID for each message, as required by
    the Streamlit.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­å‚æ•° `is_user` å†³å®šæ¶ˆæ¯æ˜¯å·¦å¯¹é½è¿˜æ˜¯å³å¯¹é½ã€‚åœ¨æˆ‘ä»¬çš„ `show_message` ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬è¿˜æŒ‡å®šäº† `avatar_style`
    å’Œ `seed` æ¥è®¾ç½®ä¸¤ä¸ªèŠå¤©æœºå™¨äººçš„å¤´åƒå›¾æ ‡ã€‚`key` å‚æ•°ä»…ç”¨äºä¸ºæ¯æ¡æ¶ˆæ¯åˆ†é…å”¯ä¸€çš„ IDï¼Œè¿™æ˜¯ Streamlit æ‰€è¦æ±‚çš„ã€‚
- en: 2ï¸âƒ£ Text-to-speech
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ è¯­éŸ³åˆæˆ
- en: 'Here, we use gTTS library to create audio speech in the target language based
    on the generated script. This library is straightforward to use, but it does have
    a limitation: you can only have one voice. After the audio object is generated,
    we can use`st.audio` to create an audio player for each message in the app.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ gTTS åº“åŸºäºç”Ÿæˆçš„è„šæœ¬åˆ›å»ºç›®æ ‡è¯­è¨€çš„éŸ³é¢‘è¯­éŸ³ã€‚è¿™ä¸ªåº“ä½¿ç”¨èµ·æ¥éå¸¸ç®€å•ï¼Œä½†å®ƒæœ‰ä¸€ä¸ªé™åˆ¶ï¼šä½ åªèƒ½ä½¿ç”¨ä¸€ç§å£°éŸ³ã€‚åœ¨ç”ŸæˆéŸ³é¢‘å¯¹è±¡åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨
    `st.audio` ä¸ºåº”ç”¨ä¸­çš„æ¯æ¡æ¶ˆæ¯åˆ›å»ºä¸€ä¸ªéŸ³é¢‘æ’­æ”¾å™¨ã€‚
- en: 'Great! We have now completed the UI design :) Type the following command in
    your terminal:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ï¼æˆ‘ä»¬ç°åœ¨å·²ç»å®Œæˆäº† UI è®¾è®¡ :) åœ¨ç»ˆç«¯ä¸­è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼š
- en: '[PRE26]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: You should see the app in your browser and be able to interact with it. Great
    job!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åº”è¯¥èƒ½åœ¨æµè§ˆå™¨ä¸­çœ‹åˆ°åº”ç”¨ï¼Œå¹¶èƒ½å¤Ÿä¸å…¶äº’åŠ¨ã€‚å¹²å¾—å¥½ï¼
- en: '![](../Images/039cdf24564a65d3616a9dcf5c2ab365.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/039cdf24564a65d3616a9dcf5c2ab365.png)'
- en: The interface of the developed language learning app. (Image by author)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: å¼€å‘çš„è¯­è¨€å­¦ä¹ åº”ç”¨ç•Œé¢ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: 5\. Learnings and Future Extensions
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. å­¦ä¹ ä¸æœªæ¥æ‰©å±•
- en: Before we finish, I want to share with you some key learnings from this project
    and potential directions for future enhancements.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»“æŸä¹‹å‰ï¼Œæˆ‘æƒ³ä¸ä½ åˆ†äº«ä¸€äº›æ¥è‡ªè¿™ä¸ªé¡¹ç›®çš„å…³é”®å­¦ä¹ å’Œæœªæ¥æ‰©å±•çš„æ½œåœ¨æ–¹å‘ã€‚
- en: 1ï¸âƒ£ How to stop the conversation?
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ å¦‚ä½•ç»“æŸå¯¹è¯ï¼Ÿ
- en: 'This problem is actually harder than it looks if you want to do it right. Ideally,
    we would like the conversation to end naturally. However, in some of my experiments,
    I noticed that the chatbots will just keep saying â€œthank youâ€ or â€œgoodbyeâ€ to
    each other toward the end of the conversation, which unnecessarily elongated the
    conversation. A few potential solutions to this issue include:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæƒ³è¦æ­£ç¡®å®ç°ï¼Œè¿™ä¸ªé—®é¢˜å®é™…ä¸Šæ¯”çœ‹èµ·æ¥è¦å¤æ‚å¾—å¤šã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›å¯¹è¯è‡ªç„¶ç»“æŸã€‚ç„¶è€Œï¼Œåœ¨æˆ‘çš„ä¸€äº›å®éªŒä¸­ï¼Œæˆ‘æ³¨æ„åˆ°èŠå¤©æœºå™¨äººåœ¨å¯¹è¯ç»“æŸæ—¶ä¼šä¸æ–­äº’ç›¸è¯´â€œè°¢è°¢â€æˆ–â€œå†è§â€ï¼Œè¿™ä¸å¿…è¦åœ°å»¶é•¿äº†å¯¹è¯ã€‚ä¸€äº›å¯èƒ½çš„è§£å†³æ–¹æ¡ˆåŒ…æ‹¬ï¼š
- en: 'Hard Limiting of Exchange Rounds: This is perhaps the easiest solution and
    itâ€™s also what we have adopted in this project. However, it might not always be
    ideal as it can lead to prematurely terminated conversations. As a workaround,
    weâ€™ve instructed the bot in the `SystemMessage`to finish the conversation within
    a set number of exchanges.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº¤æ¢è½®æ¬¡çš„ç¡¬é™åˆ¶ï¼šè¿™å¯èƒ½æ˜¯æœ€ç®€å•çš„è§£å†³æ–¹æ¡ˆï¼Œä¹Ÿæ˜¯æˆ‘ä»¬åœ¨è¿™ä¸ªé¡¹ç›®ä¸­é‡‡ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå®ƒå¯èƒ½å¹¶ä¸æ€»æ˜¯ç†æƒ³çš„ï¼Œå› ä¸ºå®ƒå¯èƒ½å¯¼è‡´å¯¹è¯è¢«è¿‡æ—©ç»ˆæ­¢ã€‚ä½œä¸ºè§£å†³æ–¹æ³•ï¼Œæˆ‘ä»¬å·²ç»åœ¨
    `SystemMessage` ä¸­æŒ‡ç¤ºæœºå™¨äººåœ¨è®¾å®šçš„äº¤æ¢è½®æ¬¡å†…å®Œæˆå¯¹è¯ã€‚
- en: 'Use of â€œSignal Wordsâ€: The chatbot could be programmed to say specific â€˜signal
    wordsâ€™ (e.g., â€˜Conversation overâ€™) when it deems the conversation to have naturally
    ended. A logic could then be implemented to spot these â€˜signal wordsâ€™ and end
    the loop accordingly.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨â€œä¿¡å·è¯â€ï¼šèŠå¤©æœºå™¨äººå¯ä»¥è¢«ç¼–ç¨‹ä»¥åœ¨è®¤ä¸ºå¯¹è¯è‡ªç„¶ç»“æŸæ—¶è¯´å‡ºç‰¹å®šçš„â€œä¿¡å·è¯â€ï¼ˆä¾‹å¦‚ï¼Œâ€œå¯¹è¯ç»“æŸâ€ï¼‰ã€‚ç„¶åå¯ä»¥å®ç°é€»è¾‘æ¥æ£€æµ‹è¿™äº›â€œä¿¡å·è¯â€å¹¶ç›¸åº”åœ°ç»“æŸå¾ªç¯ã€‚
- en: 'Post-Processing of the Conversation: Once the chatbots have generated the conversation,
    another LLM could be deployed as an â€œeditorâ€ to prune the conversation. This could
    be an effective approach. However, its drawbacks may include designing an additional
    prompt, incurring extra costs from calling the OpenAI API again, and increasing
    latency.'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹è¯çš„åå¤„ç†ï¼šä¸€æ—¦èŠå¤©æœºå™¨äººç”Ÿæˆäº†å¯¹è¯ï¼Œå¯ä»¥éƒ¨ç½²å¦ä¸€ä¸ª LLM ä½œä¸ºâ€œç¼–è¾‘å™¨â€æ¥ä¿®å‰ªå¯¹è¯ã€‚è¿™å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå…¶ç¼ºç‚¹å¯èƒ½åŒ…æ‹¬è®¾è®¡é¢å¤–çš„æç¤ºã€è°ƒç”¨
    OpenAI API å¯èƒ½äº§ç”Ÿçš„é¢å¤–è´¹ç”¨ä»¥åŠå¢åŠ çš„å»¶è¿Ÿã€‚
- en: 2ï¸âƒ£ How to control language complexity?
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ å¦‚ä½•æ§åˆ¶è¯­è¨€å¤æ‚æ€§ï¼Ÿ
- en: 'In my experience, the developed chatbots seemed to have difficulty following
    the instructions regarding the language complexity used in the chat: sometimes
    â€œintermediateâ€ level of language usage will appear even though the proficiency
    level is set to be â€œbeginnerâ€. One reason may be the current prompt design is
    not sufficient for specifying the nuance between different complexity levels.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æˆ‘çš„ç»éªŒï¼Œå¼€å‘çš„èŠå¤©æœºå™¨äººä¼¼ä¹åœ¨éµå¾ªè¯­è¨€å¤æ‚åº¦çš„æŒ‡ç¤ºæ–¹é¢å­˜åœ¨å›°éš¾ï¼šæœ‰æ—¶å³ä½¿ç†Ÿç»ƒåº¦è®¾å®šä¸ºâ€œåˆå­¦è€…â€ï¼Œä¹Ÿä¼šå‡ºç°â€œä¸­çº§â€è¯­è¨€ä½¿ç”¨ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºå½“å‰çš„æç¤ºè®¾è®¡ä¸è¶³ä»¥æ˜ç¡®åŒºåˆ†ä¸åŒå¤æ‚åº¦çº§åˆ«ä¹‹é—´çš„ç»†å¾®å·®åˆ«ã€‚
- en: 'There are a couple of ways to address this issue: to begin with, we can perform
    *in-context learning*. That is to say, we provide examples to the chatbots and
    show them what kind of language usage we desire for different complexity levels.
    Another way forward is similar to what we have discussed above: we could use another
    LLM to adjust the complexity of the conversation. Essentially, this extra LLM
    can use the generated script as a starting point and rewrite a new script to match
    the desired proficiency level of the user.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³è¿™ä¸ªé—®é¢˜æœ‰å‡ ç§æ–¹æ³•ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œ*ä¸Šä¸‹æ–‡å­¦ä¹ *ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æä¾›ç¤ºä¾‹ç»™èŠå¤©æœºå™¨äººï¼Œå¹¶å±•ç¤ºæˆ‘ä»¬æœŸæœ›åœ¨ä¸åŒå¤æ‚åº¦çº§åˆ«ä¸­ä½¿ç”¨çš„è¯­è¨€ã€‚å¦ä¸€ç§æ–¹æ³•ä¸æˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„ç±»ä¼¼ï¼šæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ªLLMæ¥è°ƒæ•´å¯¹è¯çš„å¤æ‚æ€§ã€‚å®è´¨ä¸Šï¼Œè¿™ä¸ªé¢å¤–çš„LLMå¯ä»¥åˆ©ç”¨ç”Ÿæˆçš„è„šæœ¬ä½œä¸ºèµ·ç‚¹ï¼Œå¹¶é‡å†™ä¸€ä¸ªæ–°çš„è„šæœ¬ï¼Œä»¥åŒ¹é…ç”¨æˆ·æœŸæœ›çš„ç†Ÿç»ƒç¨‹åº¦ã€‚
- en: 3ï¸âƒ£ Better text-to-speech library?
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£ æ›´å¥½çš„æ–‡æœ¬åˆ°è¯­éŸ³åº“ï¼Ÿ
- en: 'The current project only utilized the simple gTTS library to synthesize voices,
    thereâ€™s room for improvement. More advanced libraries offer multilingual support,
    multiple-speaker support, and more natural-sounding speech. To name a few: [*pyttsx3*](https://github.com/nateshmbhat/pyttsx3),
    *Amazon Polly*, *IBM Watson TTS*, *Microsoft Azure Cognitive Services TTS*, [*Coqui.ai-TTS*](https://github.com/coqui-ai/TTS),
    as well as a recent release from Meta, [*Voicebox*](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/).'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‰é¡¹ç›®ä»…ä½¿ç”¨äº†ç®€å•çš„gTTSåº“æ¥åˆæˆè¯­éŸ³ï¼Œè¿˜æœ‰æ”¹è¿›çš„ç©ºé—´ã€‚æ›´å…ˆè¿›çš„åº“æä¾›äº†å¤šè¯­è¨€æ”¯æŒã€å¤šè¯´è¯è€…æ”¯æŒä»¥åŠæ›´è‡ªç„¶çš„è¯­éŸ³ã€‚æ¯”å¦‚ï¼š[*pyttsx3*](https://github.com/nateshmbhat/pyttsx3)ã€*Amazon
    Polly*ã€*IBM Watson TTS*ã€*Microsoft Azure Cognitive Services TTS*ã€[*Coqui.ai-TTS*](https://github.com/coqui-ai/TTS)ï¼Œä»¥åŠMetaæœ€è¿‘å‘å¸ƒçš„[*Voicebox*](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/)ã€‚
- en: 4ï¸âƒ£ More tests with different scenarios?
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 4ï¸âƒ£ æ›´å¤šä¸åŒåœºæ™¯çš„æµ‹è¯•ï¼Ÿ
- en: Due to time constraints, I tested only a few scenarios to ascertain whether
    the chatbots can generate meaningful conversations. These tests identified issues
    in my initial prompt design, providing opportunities for refinement. Additional
    scenario tests would likely reveal overlooked areas and suggest ways to enhance
    the prompt. Iâ€™ve compiled a [comprehensive list](https://github.com/ShuaiGuo16/language_learning_app/blob/main/Scenario_ideas.pdf)
    of typical â€œconversationâ€ scenarios and â€œdebateâ€ topics. Feel free to try them
    out and assess the performance of the current prompt design.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæ—¶é—´é™åˆ¶ï¼Œæˆ‘åªæµ‹è¯•äº†å‡ ä¸ªåœºæ™¯ï¼Œä»¥ç¡®å®šèŠå¤©æœºå™¨äººæ˜¯å¦èƒ½å¤Ÿç”Ÿæˆæœ‰æ„ä¹‰çš„å¯¹è¯ã€‚è¿™äº›æµ‹è¯•å‘ç°äº†æˆ‘æœ€åˆæç¤ºè®¾è®¡ä¸­çš„é—®é¢˜ï¼Œæä¾›äº†æ”¹è¿›çš„æœºä¼šã€‚é¢å¤–çš„åœºæ™¯æµ‹è¯•å¯èƒ½ä¼šæ­ç¤ºè¢«å¿½è§†çš„é¢†åŸŸï¼Œå¹¶æå‡ºæ”¹è¿›æç¤ºçš„æ–¹æ³•ã€‚æˆ‘å·²ç¼–åˆ¶äº†ä¸€ä»½[å…¨é¢çš„åˆ—è¡¨](https://github.com/ShuaiGuo16/language_learning_app/blob/main/Scenario_ideas.pdf)
    ï¼ŒåŒ…æ‹¬å…¸å‹çš„â€œå¯¹è¯â€åœºæ™¯å’Œâ€œè¾©è®ºâ€è¯é¢˜ã€‚éšæ„å°è¯•è¿™äº›åœºæ™¯ï¼Œå¹¶è¯„ä¼°å½“å‰æç¤ºè®¾è®¡çš„è¡¨ç°ã€‚
- en: 5ï¸âƒ£ Include other forms of Generative AI?
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 5ï¸âƒ£ åŒ…å«å…¶ä»–å½¢å¼çš„ç”Ÿæˆå‹AIï¼Ÿ
- en: This project primarily explored text-to-text (chatbot) and text-to-speech generative
    AI techniques. We could enhance the user experience further by leveraging other
    forms of generative AI, such as **text-to-image** or **text-to-video**.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé¡¹ç›®ä¸»è¦æ¢ç´¢äº†æ–‡æœ¬åˆ°æ–‡æœ¬ï¼ˆèŠå¤©æœºå™¨äººï¼‰å’Œæ–‡æœ¬åˆ°è¯­éŸ³çš„ç”Ÿæˆå‹AIæŠ€æœ¯ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ©ç”¨å…¶ä»–å½¢å¼çš„ç”Ÿæˆå‹AIï¼Œå¦‚**æ–‡æœ¬åˆ°å›¾åƒ**æˆ–**æ–‡æœ¬åˆ°è§†é¢‘**ï¼Œè¿›ä¸€æ­¥æå‡ç”¨æˆ·ä½“éªŒã€‚
- en: '**Text-to-Image**: For every user-inputted scenario, we could use text-to-image
    models to create corresponding figures. Displaying these figures alongside the
    generated conversation can provide visual context and enhance language learning
    engagement. Models like *StableDiffusion*, *Midjourney*, and *DALL-E* could be
    used for this purpose.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–‡æœ¬åˆ°å›¾åƒ**ï¼šå¯¹äºæ¯ä¸ªç”¨æˆ·è¾“å…¥çš„åœºæ™¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹æ¥åˆ›å»ºç›¸åº”çš„å›¾åƒã€‚å°†è¿™äº›å›¾åƒä¸ç”Ÿæˆçš„å¯¹è¯ä¸€èµ·å±•ç¤ºï¼Œå¯ä»¥æä¾›è§†è§‰ä¸Šä¸‹æ–‡å¹¶å¢å¼ºè¯­è¨€å­¦ä¹ çš„å‚ä¸æ„Ÿã€‚åƒ*StableDiffusion*ã€*Midjourney*å’Œ*DALL-E*è¿™æ ·çš„æ¨¡å‹å¯ä»¥ç”¨äºæ­¤ç›®çš„ã€‚'
- en: '**Text-to-Video**: To make the app more multimedia-focused, we could generate
    videos based on input scenarios. A tool like [*RunwayML*](https://runwayml.com/)could
    help with this. Furthermore, we might even attempt to create digital humans to
    present the conversation, which could dramatically enhance user experience if
    executed correctly. [*Synthesia*](https://www.synthesia.io/tools/digital-human?utm_term=digital+avatar&utm_campaign=Basic+Search&utm_source=google&utm_medium=cpc&hsa_acc=5132031546&hsa_cam=17790491238&hsa_grp=142067774834&hsa_ad=611252817304&hsa_src=g&hsa_tgt=aud-2090130405830%3Akwd-625911181570&hsa_kw=digital+avatar&hsa_mt=p&hsa_net=adwords&hsa_ver=3&gclid=Cj0KCQjw4s-kBhDqARIsAN-ipH35DgWBi1zs_i0xDB5FBPvzMRgKLYsLvuN2d8MEAdKbw9jFL1TYB2saAsy-EALw_wcB)might
    be a suitable tool for this purpose.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–‡æœ¬è½¬è§†é¢‘**ï¼šä¸ºäº†è®©åº”ç”¨æ›´å…·å¤šåª’ä½“åŠŸèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®è¾“å…¥åœºæ™¯ç”Ÿæˆè§†é¢‘ã€‚åƒ[*RunwayML*](https://runwayml.com/)è¿™æ ·çš„å·¥å…·å¯ä»¥å¸®åŠ©å®ç°è¿™ä¸€ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç”šè‡³å¯ä»¥å°è¯•åˆ›å»ºæ•°å­—äººæ¥å‘ˆç°å¯¹è¯ï¼Œå¦‚æœæ‰§è¡Œå¾—å½“ï¼Œè¿™å¯èƒ½ä¼šå¤§å¤§æå‡ç”¨æˆ·ä½“éªŒã€‚[*Synthesia*](https://www.synthesia.io/tools/digital-human?utm_term=digital+avatar&utm_campaign=Basic+Search&utm_source=google&utm_medium=cpc&hsa_acc=5132031546&hsa_cam=17790491238&hsa_grp=142067774834&hsa_ad=611252817304&hsa_src=g&hsa_tgt=aud-2090130405830%3Akwd-625911181570&hsa_kw=digital+avatar&hsa_mt=p&hsa_net=adwords&hsa_ver=3&gclid=Cj0KCQjw4s-kBhDqARIsAN-ipH35DgWBi1zs_i0xDB5FBPvzMRgKLYsLvuN2d8MEAdKbw9jFL1TYB2saAsy-EALw_wcB)å¯èƒ½æ˜¯ä¸€ä¸ªåˆé€‚çš„å·¥å…·ã€‚'
- en: 6ï¸âƒ£ More language learning settings?
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 6ï¸âƒ£ æ›´å¤šè¯­è¨€å­¦ä¹ è®¾ç½®ï¼Ÿ
- en: At present, our app mainly focuses on â€œconversationâ€ and â€œdebateâ€ learning modes.
    However, the potential for growth is substantial. For instance, we could introduce
    other learning modes such as â€œstorytellingâ€ and â€œcultural learning.â€ Additionally,
    we could expand the chatbotsâ€™ interaction to cater to more professional and technical
    scenarios. These might include settings like meetings, negotiations, or sectors
    like sales and marketing, law, engineering, and more. Such a feature could be
    helpful for language learners aiming to bolster their *professional* language
    proficiency.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼Œæˆ‘ä»¬çš„åº”ç”¨ä¸»è¦é›†ä¸­äºâ€œå¯¹è¯â€å’Œâ€œè¾©è®ºâ€å­¦ä¹ æ¨¡å¼ã€‚ç„¶è€Œï¼Œå¢é•¿æ½œåŠ›å·¨å¤§ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥å…¶ä»–å­¦ä¹ æ¨¡å¼ï¼Œå¦‚â€œè®²æ•…äº‹â€å’Œâ€œæ–‡åŒ–å­¦ä¹ â€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥æ‰©å±•èŠå¤©æœºå™¨äººçš„äº’åŠ¨ï¼Œä»¥é€‚åº”æ›´å¤šä¸“ä¸šå’ŒæŠ€æœ¯åœºæ™¯ã€‚è¿™äº›å¯èƒ½åŒ…æ‹¬ä¼šè®®ã€è°ˆåˆ¤ï¼Œæˆ–é”€å”®ä¸å¸‚åœºã€æ³•å¾‹ã€å·¥ç¨‹ç­‰é¢†åŸŸã€‚è¿™æ ·çš„åŠŸèƒ½å¯èƒ½å¯¹é‚£äº›å¸Œæœ›æå‡*ä¸“ä¸š*è¯­è¨€èƒ½åŠ›çš„è¯­è¨€å­¦ä¹ è€…æœ‰å¸®åŠ©ã€‚
- en: 6\. Conclusion
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. ç»“è®º
- en: Wow, what a journey! Thanks a lot for sticking with me so far :) From designing
    prompts to creating chatbots, weâ€™ve certainly covered a lot of ground. Using LangChain
    and Streamlit, weâ€™ve built a functional dual-chatbot system that can be used for
    learning language, not bad!
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å“‡ï¼Œå¤šä¹ˆç²¾å½©çš„æ—…ç¨‹ï¼éå¸¸æ„Ÿè°¢ä½ ä¸€ç›´é™ªä¼´æˆ‘ :) ä»è®¾è®¡æç¤ºåˆ°åˆ›å»ºèŠå¤©æœºå™¨äººï¼Œæˆ‘ä»¬ç¡®å®è¦†ç›–äº†å¾ˆå¤šé¢†åŸŸã€‚ä½¿ç”¨LangChainå’ŒStreamlitï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŠŸèƒ½é½å…¨çš„åŒèŠå¤©æœºå™¨äººç³»ç»Ÿï¼Œå¯ä»¥ç”¨äºè¯­è¨€å­¦ä¹ ï¼Œä¸é”™å§ï¼
- en: If you find my content useful, you could buy me a coffee [here](https://www.buymeacoffee.com/Shuaiguo09f)
    ğŸ¤— Thank you very much for your support!
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è§‰å¾—æˆ‘çš„å†…å®¹æœ‰ç”¨ï¼Œå¯ä»¥é€šè¿‡[è¿™é‡Œ](https://www.buymeacoffee.com/Shuaiguo09f)ä¹°æ¯å’–å•¡ç»™æˆ‘ğŸ¤— éå¸¸æ„Ÿè°¢ä½ çš„æ”¯æŒï¼
