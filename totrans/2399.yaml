- en: Write Readable Tests for Your Machine Learning Models with Behave
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/write-readable-tests-for-your-machine-learning-models-with-behave-ec4a27b91490](https://towardsdatascience.com/write-readable-tests-for-your-machine-learning-models-with-behave-ec4a27b91490)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Use natural language to test the behavior of your ML models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://khuyentran1476.medium.com/?source=post_page-----ec4a27b91490--------------------------------)[![Khuyen
    Tran](../Images/98aa66025ad29b618e875c75f1c400a5.png)](https://khuyentran1476.medium.com/?source=post_page-----ec4a27b91490--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ec4a27b91490--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ec4a27b91490--------------------------------)
    [Khuyen Tran](https://khuyentran1476.medium.com/?source=post_page-----ec4a27b91490--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ec4a27b91490--------------------------------)
    ·9 min read·Mar 11, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine you create an ML model to predict customer sentiment based on reviews.
    Upon deploying it, you realize that the model incorrectly labels certain positive
    reviews as negative when they’re rephrased using negative words.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/049bdad843d061aa87383a5f7e15731b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: This is just one example of how an extremely accurate ML model can fail without
    proper testing. Thus, testing your model for accuracy and reliability is crucial
    before deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'But how do you test your ML model? One straightforward approach is to use unit-test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This approach works but can be challenging for non-technical or business participants
    to understand. Wouldn’t it be nice if you could incorporate **project objectives
    and goals** into your tests, expressed in **natural language**?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d0e6e410b99df2ac762eabb205c4337a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: That is when behave comes in handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feel free to play and fork the source code of this article here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[## Data-science/data_science_tools/behave_examples at master · khuyentran1401/Data-science'
  prefs: []
  type: TYPE_NORMAL
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab or…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/khuyentran1401/Data-science/tree/master/data_science_tools/behave_examples?source=post_page-----ec4a27b91490--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: What is behave?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[behave](https://github.com/behave/behave) is a Python framework for behavior-driven
    development (BDD). BDD is a software development methodology that:'
  prefs: []
  type: TYPE_NORMAL
- en: Emphasizes collaboration between stakeholders (such as business analysts, developers,
    and testers)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables users to define requirements and specifications for a software application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since behave provides a common language and format for expressing requirements
    and specifications, it can be ideal for defining and validating the behavior of
    machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install behave, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let’s use behave to perform various tests on machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Invariance Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Invariance testing tests whether an ML model produces consistent results under
    different conditions.
  prefs: []
  type: TYPE_NORMAL
- en: An example of invariance testing involves verifying if a model is invariant
    to paraphrasing. If a model is paraphrase-variant, it may misclassify a positive
    review as negative when the review is rephrased using negative words.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/049bdad843d061aa87383a5f7e15731b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Feature File
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To use behave for invariance testing, create a directory called `features`.
    Under that directory, create a file called `invariant_test_sentiment.feature`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the `invariant_test_sentiment.feature` file, we will specify the project
    requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d0e6e410b99df2ac762eabb205c4337a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The “Given,” “When,” and “Then” parts of this file present the actual steps
    that will be executed by behave during the test.
  prefs: []
  type: TYPE_NORMAL
- en: Python Step Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To implement the steps used in the scenarios with Python, start with creating
    the `features/steps` directory and a file called `invariant_test_sentiment.py`
    within it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `invariant_test_sentiment.py` file contains the following code, which tests
    whether the sentiment produced by the [TextBlob](https://textblob.readthedocs.io/en/dev/)
    model is consistent between the original text and its paraphrased version.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Explanation of the code above:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps are identified using decorators matching the feature''s predicate:
    `given`, `when`, and `then`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The decorator accepts a string containing the rest of the phrase in the matching
    scenario step.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `context` variable allows you to share values between steps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run the `invariant_test_sentiment.feature` test, type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The output shows that the first two steps passed and the last step failed, indicating
    that the model is affected by paraphrasing.
  prefs: []
  type: TYPE_NORMAL
- en: Directional Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Directional testing is a statistical method used to assess whether the impact
    of an independent variable on a dependent variable is in a particular direction,
    either positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: An example of directional testing is to check whether the presence of a specific
    word has a positive or negative effect on the sentiment score of a given text.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/385055fc35ff3f35bb00f85ead08d732.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: To use behave for directional testing, we will create two files `directional_test_sentiment.feature`
    and `directional_test_sentiment.py` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Feature File
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code in `directional_test_sentiment.feature` specifies the requirements
    of the project as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ead5a7ac4c1c8299d8d7006ba84be61d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Notice that “And” is added to the prose. Since the preceding step starts with
    “Given,” behave will rename “And” to “Given.”
  prefs: []
  type: TYPE_NORMAL
- en: Python Step Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code in`directional_test_sentiment.py` implements a test scenario, which
    checks whether the presence of the word “awesome ” positively affects the sentiment
    score generated by the TextBlob model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The second step uses the parameter syntax `{word}`. When the `.feature` file
    is run, the value specified for `{word}` in the scenario is automatically passed
    to the corresponding step function.
  prefs: []
  type: TYPE_NORMAL
- en: This means that if the scenario states that the same sentence should include
    the word “awesome,” behave will automatically replace `{word}` with “awesome.”
  prefs: []
  type: TYPE_NORMAL
- en: This conversion is useful when you want to use different values for the `{word}`
    parameter without changing both the `.feature` file and the `.py` file.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Run the Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Since all the steps passed, we can infer that the sentiment score increases
    due to the new word’s presence.
  prefs: []
  type: TYPE_NORMAL
- en: Minimum Functionality Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Minimum functionality testing is a type of testing that verifies if the system
    or product meets the minimum requirements and is functional for its intended use.
  prefs: []
  type: TYPE_NORMAL
- en: One example of minimum functionality testing is to check whether the model can
    handle different types of inputs, such as numerical, categorical, or textual data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88fb1b0325f8be6754fd265d1df1fe6e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: To use minimum functionality testing for input validation, create two files
    `minimum_func_test_input.feature` and `minimum_func_test_input.py` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Feature File
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code in `minimum_func_test_input.feature` specifies the project requirements
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a01908e8891fafa5ddc6a8c63ec7864.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Python Step Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code in `minimum_func_test_input.py` implements the requirements, checking
    if the output generated by `predict` for a specific input type meets the expectations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Run the Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Since all the steps passed, we can conclude that the model outputs match our
    expectations.
  prefs: []
  type: TYPE_NORMAL
- en: Disadvantages of behave and why you should still use it
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will outline some drawbacks of using behave compared to pytest,
    and explain why it may still be worth considering the tool.
  prefs: []
  type: TYPE_NORMAL
- en: Learning Curve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using Behavior-Driven Development (BDD) in behavior may result in a steeper
    learning curve than the more traditional testing approach used by pytest.
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter argument:** The focus on collaboration in BDD can lead to better
    alignment between business requirements and software development, resulting in
    a more efficient development process overall.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/997f01b32b12d6697a10c99df49b456f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Slower performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: behave tests can be slower than pytest tests because behave must parse the feature
    files and map them to step definitions before running the tests.
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter argument:** behave’s focus on well-defined steps can lead to tests
    that are easier to understand and modify, reducing the overall effort required
    for test maintenance.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/acaeb6ecc483180ec3bfb2aa196c6fd1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '**Less flexibility**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: behave is more rigid in its syntax, while pytest allows more flexibility in
    defining tests and fixtures.
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter argument:** behave’s rigid structure can help ensure consistency
    and readability across tests, making them easier to understand and maintain over
    time.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/b7052dbc23df11719d20a57def2b68ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although behave has some drawbacks compared to pytest, its focus on collaboration,
    well-defined steps, and structured approach can still make it a valuable tool
    for development teams.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You have just learned how to utilize behave for testing machine
    learning models. I hope this knowledge will aid you in creating more comprehensible
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: I love writing about data science concepts and playing with different data science
    tools. You can connect with me on [LinkedIn](https://www.linkedin.com/in/khuyen-tran-1401/)
    and [Twitter](https://twitter.com/KhuyenTran16).
  prefs: []
  type: TYPE_NORMAL
- en: 'Star [this repo](https://github.com/khuyentran1401/Data-science) if you want
    to check the code for the articles I have written. Follow me on Medium to stay
    notified about my latest data science articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/pytest-for-data-scientists-2990319e55e6?source=post_page-----ec4a27b91490--------------------------------)
    [## Pytest for Data Scientists'
  prefs: []
  type: TYPE_NORMAL
- en: A Comprehensive Guide to Pytest for your Data Science Projects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'towardsdatascience.com](/pytest-for-data-scientists-2990319e55e6?source=post_page-----ec4a27b91490--------------------------------)
    [](/great-expectations-always-know-what-to-expect-from-your-data-51214866c24?source=post_page-----ec4a27b91490--------------------------------)
    [## Great Expectations: Always Know What to Expect From Your Data'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure Your Data Works as Expected Using Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/great-expectations-always-know-what-to-expect-from-your-data-51214866c24?source=post_page-----ec4a27b91490--------------------------------)
    [](/validate-your-pandas-dataframe-with-pandera-2995910e564?source=post_page-----ec4a27b91490--------------------------------)
    [## Validate Your pandas DataFrame with Pandera
  prefs: []
  type: TYPE_NORMAL
- en: Make Sure Your Data Matches Your Expectation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/validate-your-pandas-dataframe-with-pandera-2995910e564?source=post_page-----ec4a27b91490--------------------------------)
    [](/detect-defects-in-a-data-pipeline-early-with-validation-and-notifications-83e9b652e65a?source=post_page-----ec4a27b91490--------------------------------)
    [## Detect Defects in a Data Pipeline Early with Validation and Notifications
  prefs: []
  type: TYPE_NORMAL
- en: Build a Robust Data Pipeline in Python with Deepchecks and Prefect
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/detect-defects-in-a-data-pipeline-early-with-validation-and-notifications-83e9b652e65a?source=post_page-----ec4a27b91490--------------------------------)
  prefs: []
  type: TYPE_NORMAL
