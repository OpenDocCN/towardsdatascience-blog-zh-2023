- en: 'Whisper JAX vs PyTorch: Uncovering the Truth about ASR Performance on GPUs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/whisper-jax-vs-pytorch-uncovering-the-truth-about-asr-performance-on-gpus-8794ba7a42f5](https://towardsdatascience.com/whisper-jax-vs-pytorch-uncovering-the-truth-about-asr-performance-on-gpus-8794ba7a42f5)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Dive into Automatic Speech Recognition: Benchmarking Whisper JAX and PyTorch
    Implementations Across Platforms'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@luisroque?source=post_page-----8794ba7a42f5--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----8794ba7a42f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8794ba7a42f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8794ba7a42f5--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----8794ba7a42f5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8794ba7a42f5--------------------------------)
    ·8 min read·Apr 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the world of Automatic Speech Recognition (ASR), speed and accuracy are of
    great importance. The size of the data and models has been growing substantially
    recently, making it hard to be efficient. Nonetheless, the race is just starting,
    and we see new developments every week. In this article, we focus on Whisper JAX,
    a recent implementation of Whisper using a different backend framework that seems
    to run 70 times faster than OpenAI’s PyTorch implementation. We tested both CPU
    and GPU implementations and measured accuracy and execution time. Also, we defined
    experiments for small and large-size models while parametrizing batch size and
    data types to see if we could improve it further.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in [our previous article](/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281),
    Whisper is a versatile speech recognition model that excels in multiple speech-processing
    tasks. It can perform multilingual speech recognition, translation, and even voice
    activity detection. It uses a Transformer sequence-to-sequence architecture to
    predict words and tasks jointly. Whisper works as a meta-model for speech-processing
    tasks. One of the downsides of Whisper is its efficiency; it is often found to
    be fairly slow compared to other state-of-the-art models.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we go through the details of what changed with this
    new approach. We compare Whisper and Whisper JAX, highlight the main differences
    between PyTorch and JAX, and develop a pipeline to evaluate the speed and accuracy
    between both implementations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e7f2b57d50d80d6877310db46f76f667.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Can we make sense of sound efficiently? ([source](https://unsplash.com/photos/mbGxz7pt0jM))'
  prefs: []
  type: TYPE_NORMAL
- en: 'This article belongs to “Large Language Models Chronicles: Navigating the NLP
    Frontier”, a new weekly series of articles that will explore how to leverage the
    power of large models for various NLP tasks. By diving into these cutting-edge
    technologies, we aim to empower developers, researchers, and enthusiasts to harness
    the potential of NLP and unlock new possibilities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Articles published so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Summarizing the latest Spotify releases with ChatGPT](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Master Semantic Search at Scale: Index Millions of Documents with Lightning-Fast
    Inference Times using FAISS and Sentence Transformers](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Unlock the Power of Audio Data: Advanced Transcription and Diarization with
    Whisper, WhisperX, and PyAnnotate](https://medium.com/towards-data-science/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As always, the code is available on my [Github](https://github.com/luisroque/large_laguage_models).
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch vs. JAX
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Machine Learning community extensively uses powerful libraries like PyTorch
    and JAX. While they share some similarities, their inner works are quite different.
    Let’s understand the main differences.
  prefs: []
  type: TYPE_NORMAL
- en: The AI Research Lab at Meta developed PyTorch and actively maintains it today.
    It is an open-source library based on the Torch library. Researchers widely use
    PyTorch due to its dynamic computation graph, intuitive interface, and solid debugging
    capabilities. The fact that it uses dynamic graphs gives it greater flexibility
    in building new models and simplifying the modification of such models during
    runtime. It is closer to Python and specifically to the NumPy API. The main difference
    is that we are not working with arrays but with tensors, which can run on GPU,
    and supports auto differentiation.
  prefs: []
  type: TYPE_NORMAL
- en: JAX is a high-performance library developed by Google. Conversely to PyTorch,
    JAX combines the benefits of static and dynamic computation graphs. It does this
    through its *just-in-time* compilation feature, which gives flexibility and performance.
    We can think of JAX being a stack of interpreters that progressively rewrite your
    program. It eventually offloads the actual computation to XLA — the *Accelerated
    Linear Algebra* compiler, also designed and developed by Google, to accelerate
    Machine Learning computations.
  prefs: []
  type: TYPE_NORMAL
- en: Building the ARS System that uses PyTorch or JAX
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s start by building a class to handle audio transcriptions using Whisper
    with PyTorch (OpenAI’s implementation) or Whisper with JAX. Our class is a wrapper
    for the models and an interface to easily set up experiments. We want to perform
    several experiments, including specifying the device, model type, and additional
    hyperparameters for Whisper JAX. Note that we used a singleton pattern to ensure
    that as we run several experiences, we do not end up with several instances of
    the model consuming our memory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `set_pipeline` method sets up the pipeline for the specified model type.
    Depending on the value of the `model_type` attribute, the method initializes the
    pipeline using either by instantiating the `FlaxWhisperPipline` class for Whisper
    JAX or by calling the `whisper.load_model()` function for the PyTorch implementation
    of Whisper.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `run_pipeline` method transcribes the audio file and returns the results
    as a list of dictionaries containing the transcribed text and timestamps. In the
    case of Whisper JAX, it considers optional parameters like data type and batch
    size, if provided. Notice that you can set `return_timestamps`to `False` if you
    are only interested in getting the transcription. The model output is different
    if we run the transcription process with the PyTorch implementation. Thus, we
    must create a new object that aligns both return objects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the `transcribe_multiple()` method enables the transcription of multiple
    audio files. It takes a list of audio file paths and returns a list of transcriptions
    for each audio file, where each transcription is a list of dictionaries containing
    text and a tuple of start and end timestamps.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Whisper JAX vs. PyTorch Performance Comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Experimental Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We used a long audio clip with more than 30 minutes to evaluate the performance
    of Whisper variants, with a PyTorch and JAX implementation. The researchers that
    developed Whisper JAX claim that the difference is more significant when transcribing
    long audio files.
  prefs: []
  type: TYPE_NORMAL
- en: Our experimental hardware setup consists of the following key components. For
    the CPU, we have an x86_64 architecture with a total of 112 cores, powered by
    an Intel(R) Xeon(R) Gold 6258R CPU running at 2.70GHz. Regarding GPU, we use an
    NVIDIA Quadro RTX 8000 with 48 GB of VRAM.
  prefs: []
  type: TYPE_NORMAL
- en: Results and Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we discuss the results obtained from the experiments to compare
    the performance of Whisper JAX and PyTorch implementations. Our results provide
    insights into the speed and efficiency of the two implementations on both GPU
    and CPU platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Our first experiment involved running a long audio (over 30 minutes) using GPU
    and the larger Whisper model (large-v2) that requires approximately 10GB of VRAM.
    Contrary to the claim made by the authors of Whisper JAX, our results indicate
    that the JAX implementation is slower than the PyTorch version. Even with the
    incorporation of half-precision and batching, we could not surpass the performance
    of the PyTorch implementation using Whisper JAX. Whisper JAX took almost twice
    the time compared to the PyTorch implementation to perform a similar transcription.
    We also observed an unusually long transcription time when both half-precision
    and batching were employed.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f856353a082479407d8e217531fb2be5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Transcription execution time using Whisper’s PyTorch implementation
    against Whisper JAX in GPU for the large model (image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when comparing the CPU performance, our results show that
    Whisper JAX outperforms the PyTorch implementation. The speedup factor was approximately
    two times faster for Whisper JAX compared to the PyTorch version. We observed
    this pattern for the base and significant model variations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d33feeefb3e8bd21dac58ad8db241c4d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Transcription execution time using Whisper’s PyTorch implementation
    against Whisper JAX for the base and large model in CPU (image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the claim made by the authors of Whisper JAX that the second transcription
    should be much faster, our experiments did not provide supporting evidence. The
    difference in speed between the first and second transcriptions was not significant.
    Plus, we found that the pattern was similar between both Whisper and Whisper JAX
    implementations.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we presented a comprehensive analysis of the Whisper JAX implementation,
    comparing its performance to the original PyTorch implementation of Whisper. Our
    experiments aimed to evaluate the claimed 70x speed improvement using a variety
    of setups, including different hardware and hyperparameters for the Whisper JAX
    model.
  prefs: []
  type: TYPE_NORMAL
- en: The results showed that Whisper JAX outperformed the PyTorch implementation
    on CPU platforms, with a speedup factor of approximately two fold. Nonetheless,
    our experiments did not support the authors’ claims that Whisper JAX is significantly
    faster on GPU platforms. Actually, the PyTorch implementation performed better
    when transcribing long audio files using a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we found no significant difference in the speed between the first
    and second transcriptions, a claim made by the Whisper JAX authors. Both implementations
    exhibited a similar pattern in this regard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep in touch: [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)'
  prefs: []
  type: TYPE_NORMAL
