- en: Cleaning a Messy Car Dataset with Python Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/cleaning-a-messy-car-dataset-with-python-pandas-700fe10a7180](https://towardsdatascience.com/cleaning-a-messy-car-dataset-with-python-pandas-700fe10a7180)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Whether you are performing exploratory data analysis or building a complex ML
    system, you need to make sure the data is cleaned
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://sonery.medium.com/?source=post_page-----700fe10a7180--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----700fe10a7180--------------------------------)[](https://towardsdatascience.com/?source=post_page-----700fe10a7180--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----700fe10a7180--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----700fe10a7180--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----700fe10a7180--------------------------------)
    ·7 min read·Oct 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d84b2673b18c91810618f7530f6b299.png)'
  prefs: []
  type: TYPE_IMG
- en: (image created by author with Midjourney)
  prefs: []
  type: TYPE_NORMAL
- en: The web is a highly-valuable asset as a data source. For instance, a substantial
    amount of training data used to create large language models comes from the web.
  prefs: []
  type: TYPE_NORMAL
- en: However, it’s usually not in the most suitable format. Web data is mainly unstructured
    (i.e. in the form of free text). Even if it has a predefined structure, web data
    requires lots of cleaning and preprocessing before it can be used for analytical
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll take a messy dataset that includes the price and some
    other attributes of cars and clean it using the pandas library.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the dataset from my [datasets](https://github.com/SonerYldrm/datasets)
    repository if you want to follow along and execute the code yourself. It’s called
    “mock_car_dataset”. Some of the operations we’ll perform on this messy dataset
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: String manipulation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering based on strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replacing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating column values using other columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Formatting numerical data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing the data to detect issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I created the dataset with mock data. However, it’s just like a car dataset
    you’d scrape from the web. I know it because I’ve done it before.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is in CSV format. Let’s start with creating a pandas DataFrame from
    this file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The dataset contains 20 rows and 6 columns, which means we have data of 6 attributes
    for 20 cars. Although it’s a small dataset, the operations we’ll do can easily
    be applied to much larger datasets (i.e. hundreds of thousands of rows)
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see what these attributes are ( `cars.head()` will show you the following
    ):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d518112902c44fce10b8885606016d4.png)'
  prefs: []
  type: TYPE_IMG
- en: The first 5 rows of the cars DataFrame (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to check the data types. We can do so by using the `dtypes`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Some of these columns should definitely be converted to a numeric data type
    but we can’t do it in their current format. For instance, it’s not possible to
    directly convert the “$11,250” to an integer value of 11250\. Similarly, the “6
    cylinders” value needs some touches to be converted to 6.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas is a highly versatile tool for string manipulation. The operations that
    seem to be complex can be done in a single line of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, to convert the price values to integer data type, we first need
    to remove “$” and “,” from price values and then apply the `astype` function to
    change the data type. Assuming the first character of all price values is “$”,
    we can perform this operation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`str[1:]` select all characters starting from the second one, which means removing
    “$”. Then we replace “,” with nothing and finally change the data type. But, let’s
    first make sure the first characters of all price values are “$”.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use the following line of code to fix the price column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The next column to handle is the cylinders column. Let’s see the value distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `value_counts` function shows the unique values in a column along with their
    number of occurrences. What we need is to remove “ cylinders” from the values
    and replace the “other” with a value of our choice. I prefer to use the most frequent
    value as a replacement for “other”, which is 6.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can change the data type of this column to integer. The following
    line of code does all these operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the first line of the code snippet above, you may notice that we first used
    `str.replace` and then used `replace` .
  prefs: []
  type: TYPE_NORMAL
- en: '`str.replace` is used for replacing a sequence of characters in a string'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`replace` is used for entire values in a column'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s take a look at how the DataFrame looks now:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da88afd88c25f0c16157469af21f68c1.png)'
  prefs: []
  type: TYPE_IMG
- en: The first 5 rows of the cars DataFrame (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'The `make` column contains both uppercase and lowercase letters, which may
    cause the same values to be considered as different. Here is a quick test to confirm
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: “Honda” and “honda” are the same brand but they are not the same strings. We
    can quickly solve this problem by converting all the characters to lowercase or
    uppercase.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Going more specific
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When I check the unique values in the “make” column, I see values like 2007
    and 2014, which do not represent any brands (at least to my knowledge). This must
    be because of wrong data entry in free forms, which is a common issue when scraping
    data from the web.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s check the year, make, and model values for these unexpected brands.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `isin` method allows for filtering rows based on multiple values. The output
    of this line of code is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57284056ccb1f7c85e3334416a5770fa.png)'
  prefs: []
  type: TYPE_IMG
- en: (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The issue seems to be entering the year value twice, which caused the brand
    (i.e. make) value switched next to the model. There are different alternatives
    for fixing this issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'One that comes to my mind is to split the model value and use the first part
    after splitting as a replacement for the value in the make column as illustrated
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3da39fed45390e6da76a69bfd4290742.png)'
  prefs: []
  type: TYPE_IMG
- en: (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: The following line of code splits the model column for rows in which the make
    value is 2007.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/15ef0dd5e6360867c7c144489372db39.png)'
  prefs: []
  type: TYPE_IMG
- en: (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: It looks a bit weird. The reason is that some of the values contain a space
    character at the beginning, which results in 3 items after splitting. For the
    ones that do not have a space character at the beginning, the last item becomes
    None. We can solve this issue by using the `strip` method, which removes the leading
    and trailing whitespaces.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4e6b383853425bf6fe963da3edf999b4.png)'
  prefs: []
  type: TYPE_IMG
- en: (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: It is accurate now and looks much better. The next step is to apply this code
    to all the rows that have a year value in the make column.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find the make values to replace (i.e. year in the make column), you can
    execute the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'It finds the unique values in the make column and sorts them, which puts the
    year values at the beginning. The first 5 rows of the output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d899ef962db77a6abd3f55ed0dc59e98.png)'
  prefs: []
  type: TYPE_IMG
- en: (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now create a list that contains 2007 and 2014 and then use it for filtering
    the rows in which the make values need to be replaced. The following code snippet
    performs the task we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let’s confirm by checking if there are any year values in the make column.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3d5d8d9935e2a96ca3a85d9483841e16.png)'
  prefs: []
  type: TYPE_IMG
- en: (image by author)
  prefs: []
  type: TYPE_NORMAL
- en: All the year values in the make column are gone.
  prefs: []
  type: TYPE_NORMAL
- en: Final words
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Last but not least, there are many duplicate rows in the DataFrame. We can eliminate
    them using the `drop_duplicates` function. By default, it removes rows in which
    all the column values are the same. If you want to determine duplicates based
    on the values in a column or a set of columns, you can use the `subset` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Data cleaning is an essential part of any data workflow. Whether you are performing
    exploratory data analysis or building a complex ML system, you need to make sure
    the data is cleaned. Otherwise, what you produce is likely to be unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading. Please let me know if you have any feedback.
  prefs: []
  type: TYPE_NORMAL
