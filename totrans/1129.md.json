["```py\nimport pandas as pd\n\n# methods and validation split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNetCV\n\n# time series example -- GPL-3 license\nfrom pmdarima.datasets import load_taylor\n\n# src module available here: https://github.com/vcerqueira/blog\nfrom src.tde import time_delay_embedding\n\n# loading the data\nseries = load_taylor(as_series=True)\n\n# train test split\ntrain, test = train_test_split(series, test_size=0.1, shuffle=False)\n\n# ts for supervised learning\ntrain_df = time_delay_embedding(train, n_lags=10, horizon=1).dropna()\ntest_df = time_delay_embedding(test, n_lags=10, horizon=1).dropna()\n\n# creating the predictors and target variables\n# the goal is to forecast the next observation of energy demand\nX_train, y_train = train_df.drop('Series(t+1)', axis=1), train_df['Series(t+1)']\nX_test, y_test = test_df.drop('Series(t+1)', axis=1), test_df['Series(t+1)']\n\n# defining the five models composing the ensemble\nmodels = {\n    'RF': RandomForestRegressor(),\n    'KNN': KNeighborsRegressor(),\n    'LASSO': Lasso(),\n    'EN': ElasticNetCV(),\n    'Ridge': Ridge(),\n}\n\n# training and getting predictions\ntrain_forecasts, test_forecasts = {}, {}\nfor k in models:\n    models[k].fit(X_train, y_train)\n    train_forecasts[k] = models[k].predict(X_train)\n    test_forecasts[k] = models[k].predict(X_test)\n\n# predictions as pandas dataframe\nts_forecasts_df = pd.DataFrame(test_forecasts)\ntr_forecasts_df = pd.DataFrame(train_forecasts)\n```", "```py\n# src module available at https://github.com/vcerqueira/blog\n# windowing \nfrom src.ensembles.windowing import WindowLoss\n# arbitrating (a meta-learning strategy)\nfrom src.ensembles.ade import Arbitrating\n\n# combining training and testing predictions\nforecasts_df = pd.concat([tr_forecasts_df, ts_forecasts_df], axis=0).reset_index(drop=True)\n# combining training and testing observations\nactual = pd.concat([y_train, y_test], axis=0).reset_index(drop=True)\n\n# setting up windowloss dynamic combinatio rule\nwindowing = WindowLoss()\nwindow_weights = windowing.get_weights(forecasts_df, actual)\nwindow_weights = window_weights.tail(X_test.shape[0]).reset_index(drop=True)\n\n# setting up arbitrating dynamic combinatio rule\narbitrating = Arbitrating()\narbitrating.fit(tr_forecasts_df, y_train, X_train)\narb_weights = arbitrating.get_weights(X_test)\narb_weights = arb_weights.tail(X_test.shape[0])\n\n# weighting the ensemble dynamically\nwindowing_fh = (window_weights.values * ts_forecasts_df.values).sum(axis=1)\narbitrating_fh = (arb_weights.values * ts_forecasts_df.values).sum(axis=1)\n\n# combining the models with static and equal weights (average)\nstatic_average = ts_forecasts_df.mean(axis=1).values\n```"]