- en: Singular Value Decomposition vs Eigendecomposition for Dimensionality Reduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奇异值分解与特征分解在降维中的比较
- en: 原文：[https://towardsdatascience.com/singular-value-decomposition-vs-eigendecomposition-for-dimensionality-reduction-fc0d9ac24a8e](https://towardsdatascience.com/singular-value-decomposition-vs-eigendecomposition-for-dimensionality-reduction-fc0d9ac24a8e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/singular-value-decomposition-vs-eigendecomposition-for-dimensionality-reduction-fc0d9ac24a8e](https://towardsdatascience.com/singular-value-decomposition-vs-eigendecomposition-for-dimensionality-reduction-fc0d9ac24a8e)
- en: Performing PCA using both methods and comparing the results
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用两种方法执行主成分分析（PCA）并比较结果
- en: '[](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[![Rukshan
    Pramoditha](../Images/b80426aff64ff186cb915795644590b1.png)](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)
    [Rukshan Pramoditha](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[![Rukshan
    Pramoditha](../Images/b80426aff64ff186cb915795644590b1.png)](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)
    [Rukshan Pramoditha](https://rukshanpramoditha.medium.com/?source=post_page-----fc0d9ac24a8e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)
    ·8 min read·Mar 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fc0d9ac24a8e--------------------------------)
    ·阅读时间 8 分钟·2023年3月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/249648322ceade3a63b6972cb91564d2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/249648322ceade3a63b6972cb91564d2.png)'
- en: Image by [Viktor Peschel](https://pixabay.com/users/1a-photoshop-6724285/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2886285)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2886285)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Viktor Peschel](https://pixabay.com/users/1a-photoshop-6724285/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2886285)
    来自 [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2886285)
- en: Singular value decomposition (SVD) and eigendecomposition (ED) are both matrix
    factorization methods that come from linear algebra.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 奇异值分解（SVD）和特征分解（ED）都是来自线性代数的矩阵分解方法。
- en: In the field of machine learning (ML), both can be used as data reduction methods
    (i.e. for dimensionality reduction).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）领域，奇异值分解和特征分解都可以作为数据降维的方法。
- en: Previously, we’ve discussed [eigendecomposition](https://medium.com/data-science-365/eigendecomposition-of-a-covariance-matrix-with-numpy-c953334c965d)
    in detail. Today, we’ll give more emphasis on discussing SVD.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们已经详细讨论了 [特征分解](https://medium.com/data-science-365/eigendecomposition-of-a-covariance-matrix-with-numpy-c953334c965d)。今天，我们将更加重点讨论
    SVD。
- en: Principal component analysis (PCA) can be performed using both methods. PCA
    is the most popular linear dimensionality reduction technique in ML. SVD is considered
    as the underlying mathematics behind PCA. The popular ML library, Scikit-learn
    also uses SVD within its `PCA()`function to perform PCA. Therefore, SVD is more
    popular than eigendecomposition in dimensionality reduction.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）可以使用这两种方法来执行。PCA 是机器学习中最流行的线性降维技术。SVD 被认为是 PCA 背后的基础数学。流行的机器学习库 Scikit-learn
    也在其 `PCA()` 函数中使用 SVD 来执行 PCA。因此，SVD 在降维中比特征分解更受欢迎。
- en: NumPy provides high-level and easy-to-use functions to perform SVD and eigendecomposition.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 提供了高级且易于使用的函数来执行 SVD 和特征分解。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: What is singular value decomposition?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是奇异值分解？
- en: Singular value decomposition (SVD) is a type of matrix factorization method.
    It is an important mathematical operation that comes from linear algebra.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 奇异值分解（SVD）是一种矩阵分解方法。这是一个来自线性代数的重要数学运算。
- en: There are multiple ways to factorize (decompose / break down) a matrix like
    we can factorize the number 16, for example, into 2 x 8 = 16, 4 x 4 = 16, 2 x
    2 x 4 = 16, 2 x 2 x 2 x 2 = 16\. Not all factorization methods are equally important.
    It depends on the use case.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方式可以分解（分解 / 拆解）一个矩阵，就像我们可以将数字 16 分解为 2 x 8 = 16、4 x 4 = 16、2 x 2 x 4 = 16、2
    x 2 x 2 x 2 = 16 一样。并不是所有的分解方法都同样重要。这取决于具体的使用案例。
- en: Likewise, we can factorize a matrix in multiple ways of which some are more
    important. Singular value decomposition (SVD) and eigendecomposition are such
    important methods of factorizing a matrix.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以以多种方式对矩阵进行分解，其中一些更为重要。奇异值分解（SVD）和特征分解是矩阵分解中的重要方法。
- en: Singular value decomposition is the process of decomposing matrix **A** into
    the product of three matrices as in the following equation.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 奇异值分解是将矩阵**A**分解为三个矩阵乘积的过程，如下方程所示。
- en: '![](../Images/c7b6ce2cfc1fcf20b9a01bec3589f197.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7b6ce2cfc1fcf20b9a01bec3589f197.png)'
- en: '**SVD equation** (Image by author)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**SVD方程** (图片由作者提供)'
- en: '**A:** The matrix on which we perform SVD'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A:** 我们对其执行SVD的矩阵。'
- en: '**U:** A square matrix. This is called the right singular vectors matrix.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**U:** 一个方阵。这被称为右奇异向量矩阵。'
- en: '**Σ:** A diagonal matrix. This is called the singular value matrix which is
    the same size as **A**.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Σ:** 一个对角矩阵。这被称为奇异值矩阵，其大小与**A**相同。'
- en: '**V^T:** A square matrix. This is called the left singular vectors matrix.
    By default, NumPy’s SVD function returns **V^T** which is the transform of **V**.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**V^T:** 一个方阵。这被称为左奇异向量矩阵。默认情况下，NumPy的SVD函数返回**V^T**，它是**V**的转置。'
- en: The matrix **A** can be square or non-square as SVD is defined for both square
    and non-square matrices. In contrast, eigendecomposition is defined only for square
    matrices.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵**A**可以是方阵也可以是非方阵，因为SVD定义于方阵和非方阵。相比之下，特征分解仅对方阵定义。
- en: The matrix **Σ** contains singular values which are always non-negative values.
    Zero values can be included.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵**Σ**包含奇异值，这些值总是非负的。可以包含零值。
- en: The number of non-zero singular values equals the rank of matrix **A**.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 非零奇异值的数量等于矩阵**A**的秩。
- en: Singular value decomposition in NumPy
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NumPy中的奇异值分解
- en: In NumPy, SVD can be easily performed using the `svd()`function. Here is an
    example.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在NumPy中，可以使用`svd()`函数轻松地执行SVD。这里是一个示例。
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/a6000f866e46a999252e6f2f05d2d075.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6000f866e46a999252e6f2f05d2d075.png)'
- en: (Image by author)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (图片由作者提供)
- en: NumPy’s **svd()** function returns **Σ** (singular value matrix) as a vector
    (denoted by **s**), not a diagonal matrix. That vector contains all the singular
    values of **A**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy的**svd()**函数返回**Σ**（奇异值矩阵）作为一个向量（由**s**表示），而不是对角矩阵。该向量包含了矩阵**A**的所有奇异值。
- en: If you want to get the **Σ** as it is, you can do some modifications using the
    following code.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想直接获得**Σ**，可以通过以下代码进行一些修改。
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/81082c5e0db19903518e8da2eeb64741.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81082c5e0db19903518e8da2eeb64741.png)'
- en: (Image by author)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: (图片由作者提供)
- en: If you only need to compute singular values and don’t need U and Vt matrices,
    you can run the following code.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只需要计算奇异值而不需要U和Vt矩阵，你可以运行以下代码。
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/b0a958c19f33e309dde1407c08eae037.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0a958c19f33e309dde1407c08eae037.png)'
- en: (Image by author)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: (图片由作者提供)
- en: That’s how we can perform SVD in NumPy. It is much easier than you think. Next,
    we will move into the eigendecomposition part.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们如何在NumPy中执行SVD。它比你想象的要简单得多。接下来，我们将进入特征分解部分。
- en: What is eigendecomposition?
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是特征分解？
- en: Eigendecompostionn is another important matrix factorizing method.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 特征分解是另一种重要的矩阵分解方法。
- en: Eigendecomposition is the process of decomposing a square matrix A into the
    product of eigenvalues and eigenvectors as in the following equation.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 特征分解是将方阵A分解为特征值和特征向量的乘积的过程，如下方程所示。
- en: '![](../Images/93f7324a37f8fe17c6cb97ebaa464bd9.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93f7324a37f8fe17c6cb97ebaa464bd9.png)'
- en: '**The relationship between square matrix, A and its pair of eigenvalue and
    eigenvector** (Image by author)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**方阵A及其特征值和特征向量对之间的关系** (图片由作者提供)'
- en: '**A:** The matrix on which we perform eigendecomposition. It should be a square
    matrix.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A:** 我们对其执行特征分解的矩阵。它应该是一个方阵。'
- en: '**λ:** A scalar called the eigenvalue.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**λ:** 一个称为特征值的标量。'
- en: '**x:** A vector called the eigenvector.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**x:** 一个称为特征向量的向量。'
- en: The matrix **A** should be a square matrix as eigendecomposition is defined
    only for square matrices.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵**A**应该是方阵，因为特征分解仅对方阵定义。
- en: The eigenvalues can be positive or negative.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值可以是正值或负值。
- en: '*The eigenvalues and eigenvectors come in pairs. Such a pair is known as an*
    ***eigenpair****. So, matrix* ***A*** *can have multiple such eigenpairs. The
    above equation shows the relationship between* ***A*** *and one of its eigenpairs*
    [ref: [Eigendecomposition of a Covariance Matrix with NumPy](https://medium.com/data-science-365/eigendecomposition-of-a-covariance-matrix-with-numpy-c953334c965d)]'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*特征值和特征向量是成对出现的。这种配对被称为* ***特征对****。因此，矩阵* ***A*** *可以有多个这样的特征对。上述方程展示了* ***A***
    *与其一个特征对之间的关系* [ref: [用 NumPy 进行协方差矩阵的特征分解](https://medium.com/data-science-365/eigendecomposition-of-a-covariance-matrix-with-numpy-c953334c965d)]'
- en: Eigendecomposition in NumPy
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NumPy 中的特征分解
- en: In NumPy, eigendecomposition can be easily performed using the `eig()`function.
    Here is an example.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在 NumPy 中，可以使用 `eig()` 函数轻松地执行特征分解。这里是一个示例。
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/ec500f583fcaf1f81e031b0932cafcc6.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec500f583fcaf1f81e031b0932cafcc6.png)'
- en: (Image by author)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: (作者提供的图片)
- en: NumPy’s **eig()** function returns eigenvalues as a vector. That vector contains
    all the eigenvalues of **A**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 的 **eig()** 函数返回特征值作为一个向量。该向量包含了 **A** 的所有特征值。
- en: 'We’ve performed both SVD and eigendecomposition on the same matrix, **A**.
    By looking at the outputs, we can say that:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对同一个矩阵 **A** 执行了 SVD 和特征分解。通过查看输出，我们可以说：
- en: Singular value decomposition and the eigendecomposition are not the same things
    even if the matrix is square.
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 奇异值分解和特征分解即使在矩阵为方阵时也不是相同的东西。
- en: Performing PCA using singular value decomposition
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用奇异值分解执行 PCA
- en: PCA is often performed by applying SVD to the covariance matrix of standardized
    data. The covariance matrix of standardized data is exactly the same as the correlation
    matrix of non-standardized data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 通常通过对标准化数据的协方差矩阵应用 SVD 来执行。标准化数据的协方差矩阵与非标准化数据的相关矩阵完全相同。
- en: We standardize data before SVD because singular values are highly sensitive
    to the relative ranges of original features.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SVD 之前我们标准化数据，因为奇异值对原始特征的相对范围非常敏感。
- en: To demonstrate the PCA process using SVD, we’ll use the Wine dataset which has
    13 input features.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示使用 SVD 的 PCA 过程，我们将使用包含 13 个输入特征的 Wine 数据集。
- en: '**Step 1:** Getting Wine data.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1:** 获取 Wine 数据。'
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/b663ea243afd2ae6e9336d66fcfd0cba.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b663ea243afd2ae6e9336d66fcfd0cba.png)'
- en: (Image by author)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: (作者提供的图片)
- en: '**Step 2:** Standardizing data.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2:** 标准化数据。'
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Step 3:** Computing the covariance matrix of standardized data.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3:** 计算标准化数据的协方差矩阵。'
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Step 4:** Performing SVD on the covariance matrix and getting the singular
    values of the covariance matrix.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 4:** 对协方差矩阵执行 SVD 并获取协方差矩阵的奇异值。'
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/68288b1015e9d7208bc07f7c08a37e2a.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68288b1015e9d7208bc07f7c08a37e2a.png)'
- en: '**Singular values** (Image by author)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**奇异值** (作者提供的图片)'
- en: The sum of these singular values is equal to the total amount of variance in
    the data. Each singular value represents the amount of variance captured by each
    component. To calculate these things, we need to convert singular values to the
    variance explained.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些奇异值的总和等于数据中的总方差。每个奇异值表示每个组件捕获的方差量。为了计算这些内容，我们需要将奇异值转换为解释的方差。
- en: '**Step 5:** Converting singular values to the variance explained.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 5:** 将奇异值转换为解释的方差。'
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/394112bd6155fb0378806a7b75bd823b.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/394112bd6155fb0378806a7b75bd823b.png)'
- en: (Image by author)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: (作者提供的图片)
- en: The first component captures a 36.2% variance in the data. The second component
    captures a 19.2% variance in the data, and so on.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个组件捕获了数据中的 36.2% 方差。第二个组件捕获了数据中的 19.2% 方差，以此类推。
- en: '**Step 6:** Visualizing singular values to select the right number of components'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 6:** 可视化奇异值以选择正确的组件数量'
- en: Not all components contribute the same to the model. We can drop the components
    that do not capture much variance in the data and keep only the most important
    components. For that, we need to visualize all the singular values by creating
    the [*cumulative explained variance plot*](https://medium.com/data-science-365/2-plots-that-help-me-to-choose-the-right-number-of-principal-components-351a87e15a9f).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 不是所有组件对模型的贡献相同。我们可以丢弃那些对数据方差贡献不大的组件，只保留最重要的组件。为此，我们需要通过创建 [*累积解释方差图*](https://medium.com/data-science-365/2-plots-that-help-me-to-choose-the-right-number-of-principal-components-351a87e15a9f)
    来可视化所有奇异值。
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/77ddeacfd777ca9be48faf980e421099.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77ddeacfd777ca9be48faf980e421099.png)'
- en: '**Cumulative explained variance plot** (Image by author)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**累积解释方差图** (作者提供的图片)'
- en: So, it is very clear that the first 7 components capture about 90% variance
    in the data. So, we can select the first 7 components for the Wine dataset.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，很明显前7个主成分捕获了数据中约90%的方差。因此，我们可以选择前7个主成分用于葡萄酒数据集。
- en: See all selection criteria [here](/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 查看所有选择标准 [这里](/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d)。
- en: Performing PCA using eigendecomposition
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用特征分解进行主成分分析
- en: PCA can also be performed by applying eigendecomposition to the covariance matrix
    of standardized data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析也可以通过对标准化数据的协方差矩阵应用特征分解来进行。
- en: The first 3 steps are the same as before. So, I will continue with the fourth
    step.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 前3步与之前相同。因此，我将继续进行第四步。
- en: '**Step 1, Step 2, Step 3:** Same as before.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1、步骤2、步骤3：** 与之前相同。'
- en: '**Step 4:** Performing eigendecomposition on the covariance matrix and getting
    the eigenvalues of the covariance matrix.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤4：** 对协方差矩阵进行特征分解，并获得协方差矩阵的特征值。'
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/7b2205e5e8489f299d4811f258afc84b.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b2205e5e8489f299d4811f258afc84b.png)'
- en: '**Eigenvalues** (Image by author)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征值**（作者提供的图片）'
- en: The eigenvalues are exactly the same as the singular values. The reason is that
    the covariance matrix is symmetric.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值与奇异值完全相同。原因在于协方差矩阵是对称的。
- en: '![](../Images/782200fd556cd02404edb3ea4da8d15d.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/782200fd556cd02404edb3ea4da8d15d.png)'
- en: '**The covariance matrix of the standardized Wine data** (Image by author)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准化葡萄酒数据的协方差矩阵**（作者提供的图片）'
- en: 'In general, we can say that:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们可以说：
- en: For a symmetric matrix, eigenvalues are exactly the same as the singular values.
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于对称矩阵，特征值与奇异值完全相同。
- en: In other words,
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，
- en: For a symmetric matrix, singular value decomposition and the eigendecomposition
    are the same things.
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于对称矩阵，奇异值分解和特征分解是相同的。
- en: Unlike the **svd()** function, the eigenvalues returned by the **eig()** function
    are not in descending order. So, we need to manually sort them from largest to
    smallest.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与**svd()**函数不同，**eig()**函数返回的特征值不是按降序排列的。因此，我们需要手动将它们从大到小排序。
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/88f8995a3da863e8c9203d03f6e4a1fd.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/88f8995a3da863e8c9203d03f6e4a1fd.png)'
- en: '**Sorted eigenvalues in descending order** (Image by author)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**按降序排列的特征值**（作者提供的图片）'
- en: '**Step 5, Step 6:** Same as before.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤5、步骤6：** 与之前相同。'
- en: We can visualize the eigenvalues as the same as before. You will get exactly
    the same plot.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像之前一样可视化特征值。你会得到完全相同的图。
- en: Conclusions
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: By default, PCA is performed by using SVD. It can also be performed by using
    eigendecomposition. Both approaches give the same results because the covariance
    matrix is symmetric.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，主成分分析是通过使用奇异值分解（SVD）进行的。也可以通过特征分解来进行。由于协方差矩阵是对称的，两种方法给出的结果相同。
- en: In general, singular value decomposition and eigendecomposition are completely
    two different things, but for a symmetric matrix like the covariance matrix used
    in PCA, both are the same!
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一般来说，奇异值分解和特征分解是完全不同的，但对于像主成分分析中使用的协方差矩阵这样的对称矩阵，两者是相同的！
- en: This is the end of today’s article.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的文章到此结束。
- en: '**Please let me know if you’ve any questions or feedback.**'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有任何问题或反馈，请告诉我。**'
- en: Read next (Recommended)
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阅读下一篇（推荐）
- en: '[**PCA and Dimensionality Reduction Special Collection**](https://rukshanpramoditha.medium.com/list/pca-and-dimensionality-reduction-special-collection-146045a5acb5)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**主成分分析与降维特别合集**](https://rukshanpramoditha.medium.com/list/pca-and-dimensionality-reduction-special-collection-146045a5acb5)'
- en: How about an AI course?
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有兴趣了解AI课程吗？
- en: '[**Neural Networks and Deep Learning Course**](https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**神经网络与深度学习课程**](https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75)'
- en: Support me as a writer
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持我作为写作者
- en: '*I hope you enjoyed reading this article. If you’d like to support me as a
    writer, kindly consider* [***signing up for a membership***](https://rukshanpramoditha.medium.com/membership)
    *to get unlimited access to Medium. It only costs $5 per month and I will receive
    a portion of your membership fee.*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*我希望你喜欢阅读这篇文章。如果你想支持我作为写作者，请考虑* [***注册会员***](https://rukshanpramoditha.medium.com/membership)
    *以获得对Medium的无限访问。每月只需5美元，我将获得你的会员费用的一部分。*'
- en: '[](https://rukshanpramoditha.medium.com/membership?source=post_page-----fc0d9ac24a8e--------------------------------)
    [## Join Medium with my referral link - Rukshan Pramoditha'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rukshanpramoditha.medium.com/membership?source=post_page-----fc0d9ac24a8e--------------------------------)
    [## 使用我的推荐链接加入Medium - Rukshan Pramoditha'
- en: Read every story from Rukshan Pramoditha (and thousands of other writers on
    Medium). Your membership fee directly…
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读 Rukshan Pramoditha 的每个故事（以及 Medium 上其他成千上万的作家的故事）。你的会员费直接…
- en: rukshanpramoditha.medium.com](https://rukshanpramoditha.medium.com/membership?source=post_page-----fc0d9ac24a8e--------------------------------)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: rukshanpramoditha.medium.com](https://rukshanpramoditha.medium.com/membership?source=post_page-----fc0d9ac24a8e--------------------------------)
- en: Join my private list of emails
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我的私人邮件列表
- en: '*Never miss a great story from me again. By* [***subscribing to my email list***](https://rukshanpramoditha.medium.com/subscribe)*,
    you will directly receive my stories as soon as I publish them.*'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*不要再错过我讲的精彩故事了。通过* [***订阅我的邮件列表***](https://rukshanpramoditha.medium.com/subscribe)*，你将会在我发布故事后第一时间直接收到。*'
- en: Thank you so much for your continuous support! See you in the next article.
    Happy learning to everyone!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢你的持续支持！下篇文章见。祝大家学习愉快！
- en: Wine dataset info
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 葡萄酒数据集信息
- en: '**Dataset source:** You can download the original dataset [here](https://archive.ics.uci.edu/ml/datasets/Wine).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集来源：** 你可以在 [这里](https://archive.ics.uci.edu/ml/datasets/Wine) 下载原始数据集。'
- en: '**Dataset license:** This dataset is available under the [*CC BY 4.0*](https://creativecommons.org/licenses/by/4.0/)
    (*Creative Commons Attribution 4.0*) license.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集许可证：** 本数据集在 [*CC BY 4.0*](https://creativecommons.org/licenses/by/4.0/)
    (*创意共享署名 4.0*) 许可证下提供。'
- en: '**Citation:** Lichman, M. (2013). UCI Machine Learning Repository [[https://archive.ics.uci.edu/ml](https://archive.ics.uci.edu/ml)].
    Irvine, CA: University of California, School of Information and Computer Science.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**引用：** Lichman, M. (2013). UCI机器学习库 [[https://archive.ics.uci.edu/ml](https://archive.ics.uci.edu/ml)]。加利福尼亚州欧文：加利福尼亚大学信息与计算机科学学院。'
- en: '[Rukshan Pramoditha](https://medium.com/u/f90a3bb1d400?source=post_page-----fc0d9ac24a8e--------------------------------)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[Rukshan Pramoditha](https://medium.com/u/f90a3bb1d400?source=post_page-----fc0d9ac24a8e--------------------------------)'
- en: '**2023–03–20**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**2023–03–20**'
