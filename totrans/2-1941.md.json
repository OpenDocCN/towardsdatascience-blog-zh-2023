["```py\npython -m pip install aiomultiprocess\n```", "```py\nconda install -c conda-forge aiomultiprocess\n```", "```py\nimport asyncio\nimport random\n\nimport aiomultiprocess\n\nasync def coro_func(value: int) -> int:\n    await asyncio.sleep(random.randint(1, 3))\n    return value * 2\n\nasync def main():\n    results = []\n    async with aiomultiprocess.Pool() as pool:\n        async for result in pool.map(coro_func, [1, 2, 3]):\n            results.append(result)\n\n        print(results)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nimport asyncio\nimport random\n\nimport aiomultiprocess\n\nasync def coro_func(value: int) -> int:\n    await asyncio.sleep(random.randint(1, 3))\n    return value * 2\n\nasync def main():\n    tasks = []\n    async with aiomultiprocess.Pool() as pool:\n        tasks.append(pool.apply(coro_func, (1,)))\n        tasks.append(pool.apply(coro_func, (2,)))\n        tasks.append(pool.apply(coro_func, (3,)))\n\n        results = await asyncio.gather(*tasks)\n        print(results)  # Output: [2, 4, 6]\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nimport asyncio\nimport random\nimport time\n\nfrom aiohttp import ClientSession\nfrom aiomultiprocess import Pool\n\ndef cpu_bound(n: int) -> int:\n    result = 0\n    for i in range(n*100_000):\n        result += 1\n    return result\n\nasync def invoke_remote(url: str) -> int:\n    await asyncio.sleep(random.uniform(0.2, 0.7))\n    async with ClientSession() as session:\n        async with session.get(url) as response:\n            status = response.status\n            result = cpu_bound(status)\n            return result\n```", "```py\nasync def main():\n    start = time.monotonic()\n    tasks = [asyncio.create_task(invoke_remote(\"https://www.example.com\"))\n             for _ in range(30)]\n    await asyncio.gather(*tasks)\n    print(f\"All jobs done in {time.monotonic() - start} seconds\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nasync def main():\n    start = time.monotonic()\n    async with Pool() as pool:\n        tasks = [pool.apply(invoke_remote, (\"https://www.example.com\",)) \n                 for _ in range(30)]\n        await asyncio.gather(*tasks)\n    print(f\"All jobs done in {time.monotonic() - start} seconds\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nimport random\nimport asyncio\nfrom multiprocessing import Manager\nfrom multiprocessing.queues import Queue\n\nfrom aiomultiprocess import Pool\n\nasync def worker(name: str, queue: Queue):\n    while True:\n        item = queue.get()\n        if not item:\n            print(f\"worker: {name} got the end signal, and will stop running.\")\n            queue.put(item)\n            break\n        await asyncio.sleep(random.uniform(0.2, 0.7))\n        print(f\"worker: {name} begin to process value {item}\", flush=True)\n\nasync def producer(queue: Queue):\n    for i in range(20):\n        await asyncio.sleep(random.uniform(0.2, 0.7))\n        queue.put(random.randint(1, 3))\n    queue.put(None)\n\nasync def main():\n    queue: Queue = Manager().Queue()\n    producer_task = asyncio.create_task(producer(queue))\n\n    async with Pool() as pool:\n        c_tasks = [pool.apply(worker, args=(f\"worker-{i}\", queue)) \n                   for i in range(5)]\n        await asyncio.gather(*c_tasks)\n\n        await producer_task\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nimport asyncio\n\nfrom aiomultiprocess import Pool\nimport aiohttp\nfrom aiohttp import ClientSession, ClientTimeout\n\nsession: ClientSession | None = None\n\ndef init_session(timeout: ClientTimeout = None):\n    global session\n    session = aiohttp.ClientSession(timeout=timeout)\n\nasync def get_status(url: str) -> int:\n    global session\n    async with session.get(url) as response:\n        status_code = response.status\n        return status_code\n\nasync def main():\n    url = \"https://httpbin.org/get\"\n    timeout = ClientTimeout(2)\n    async with Pool(initializer=init_session, initargs=(timeout,)) as pool:\n        tasks = [asyncio.create_task(pool.apply(get_status, (url,))) \n                 for i in range(3)]\n        status = await asyncio.gather(*tasks)\n    print(status)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nimport asyncio\nimport random\n\nfrom aiomultiprocess import Pool\n\nasync def worker():\n    await asyncio.sleep(0.2)\n    result = random.random()\n    if result > 0.5:\n        print(\"will raise an exception\")\n        raise Exception(\"something error\")\n    return result\n\nasync def main():\n    pending, results = set(), []\n    async with Pool() as pool:\n        for i in range(7):\n            pending.add(asyncio.create_task(pool.apply(worker)))\n        while len(pending) > 0:\n            done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_EXCEPTION)\n            print(f\"now the count of done, pending is {len(done)}, {len(pending)}\")\n            for result in done:\n                if result.exception():\n                    pending.add(asyncio.create_task(pool.apply(worker)))\n                else:\n                    results.append(await result)\n        print(results)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nimport asyncio\nfrom random import random\n\nfrom aiomultiprocess import Pool\nfrom tenacity import *\n\n@retry()\nasync def worker(name: str):\n    await asyncio.sleep(0.3)\n    result = random()\n    if result > 0.6:\n        print(f\"{name} will raise an exception\")\n        raise Exception(\"something wrong\")\n    return result\n\nasync def main():\n    async with Pool() as pool:\n        tasks = pool.map(worker, [f\"worker-{i}\" for i in range(5)])\n        results = await tasks\n        print(results)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```", "```py\nimport asyncio\nfrom random import uniform\n\nfrom aiomultiprocess import Pool\nfrom tqdm.asyncio import tqdm_asyncio\n\nasync def worker():\n    delay = uniform(0.5, 5)\n    await asyncio.sleep(delay)\n    return delay * 10\n\nasync def main():\n    async with Pool() as pool:\n        tasks = [asyncio.create_task(pool.apply(worker)) for _ in range(1000)]\n        results = await tqdm_asyncio.gather(*tasks)\n\n        print(results[:10])\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```"]