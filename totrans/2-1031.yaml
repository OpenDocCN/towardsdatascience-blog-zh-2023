- en: Hands on Sampling Techniques and comparison, in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/hands-on-sampling-techniques-and-comparison-in-python-6342c70f2099](https://towardsdatascience.com/hands-on-sampling-techniques-and-comparison-in-python-6342c70f2099)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here‚Äôs a step-by-step tutorial on how to sample your dataset efficiently using
    Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)
    ¬∑8 min read¬∑Dec 1, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/95ead638268cc3c48bbd3a81345c2412.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: I was putting the Christmas tree up with my wife. We went to the basement, took
    the tree, brought it upstairs, and started building it from bottom to top. It‚Äôs
    always a magic momentüéÑ
  prefs: []
  type: TYPE_NORMAL
- en: 'Then it was the point to put the balls on the tree. And immediately I thought:
    there are at least three ways to put the balls on the tree.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Uniformly**: put the balls uniformly on the tree, kind of like that'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/27d251a59d187aad89471f266bb3f509.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author, made using [Freepik](https://www.freepik.com/)
  prefs: []
  type: TYPE_NORMAL
- en: '**Randomly**: put the balls randomly on the tree, closing your eyes and putting
    the ball wherever you feel like (I started doing this and my wife went MAD)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9c8b491a96c276c9551aa2c6e399e869.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author, made using [Freepik](https://www.freepik.com/)
  prefs: []
  type: TYPE_NORMAL
- en: '**Latin Hypercube**: Splitting the tree into N sections and extracting randomly
    in each one of these sections. It‚Äôs very hard to draw it without running any code,
    but a possible Latin Hypercube looks like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/e6178a5cd52634b880858d71ae374640.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author, made using [Freepik](https://www.freepik.com/)
  prefs: []
  type: TYPE_NORMAL
- en: I tried and show this to my wife. She smiled and said ‚ÄúWhatever‚Äù, so I went
    to my computer in the hope that your reaction would be something more satisfactory
    üò§
  prefs: []
  type: TYPE_NORMAL
- en: 'Jokes aside, when dealing with Machine Learning problems there are two different
    scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**You don‚Äôt have any control over the dataset**.You have a client, or a company,
    that hands you a dataset. That‚Äôs what you will have to deal with until a necessary
    (eventual) re-training will be scheduled.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For example, in the city of New York, you want to predict the price of a house
    based on some given features. They just give you the dataset and they want you
    to build your model so that when a new client arrives you have an AI software
    that can predict the price based on the features of the house of interest.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. You can build your Design of Experiment**. This is when you have a forward
    model or a real-world experiment that you can always set up to run.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, in a laboratory, you want to predict a physical signal given an
    experimental setup. You can always go to the lab and generate new data.
  prefs: []
  type: TYPE_NORMAL
- en: The considerations that you make in the two cases are completely different.
  prefs: []
  type: TYPE_NORMAL
- en: In the first case you can expect a dataset that is unbalanced in its features,
    maybe with missing input values and a skewed distribution of the target values.
    It‚Äôs the joy and damnation of a data scientist's job to deal with these things
    though. You do data augmentation, data filtering, fill in the miss values, do
    some ANOVA testing if you can and so forth. In the second case, you have complete
    control over what‚Äôs going on in your dataset, especially from the input perspective.
    This means that if you have a NaN value you can repeat the experiment, if you
    have several NaN values you can investigate that weird area of your dataset, if
    you have a suspicious large value for some given features you can just repeat
    the experiment to make sure it‚Äôs not an hallucination of your setup.
  prefs: []
  type: TYPE_NORMAL
- en: As we have this amount of control we want to make sure to cover the input parameter
    space efficiently. For example, if you have 3 parameters, and you know the boundaries
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e303cf515210c11b74440370aa35f3fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: where i goes from 1 to 3 (or from 0 to 2 if you like Python so much üòÅ). In this
    case, x_i is the i-th variable and it will always be larger than x_i^L(ower boundary),
    but it will always be smaller than x_i^U(pper boundary).
  prefs: []
  type: TYPE_NORMAL
- en: We have our 3-dimensional cube.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44eeb5bf58ae7c259e478be4f096ed53.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Now, remember that we have complete control of our dataset. How do we sample?
    In other words, how do we determine the **x**s ? What are the points that we want
    to select so that we run the forward model (experiment or simulation) and get
    the target values?
  prefs: []
  type: TYPE_NORMAL
- en: As you can expect there are multiple methods to do so. Each method has its advantages
    and disadvantages. In this study, we will discuss them, show the theory behind
    them, and display the code for everyone to use and understand more about the beautiful
    world of sampling. üôÇ
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs start with the uniform sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Uniform Sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The uniform sampling method is arguably the most simple and famous one.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is just about splitting each parameter (or dimension) in steps. Let‚Äôs assume
    that we have 3 steps per dimension, for 2 dimensions. Each dimension goes from
    0 to 1 (we will extend this in a minute). This would be the sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: (0,0)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (0,0.5)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (0,1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (0.5,0)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (0.5,0.5)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (0.5,1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (1,0)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (1,0.5)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (1,1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This means that we fix one variable at a time and increase by step. Fairly
    simple. Let‚Äôs code it:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Uniform Sampling Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How do we do this? Let‚Äôs avoid this kind of structure:'
  prefs: []
  type: TYPE_NORMAL
- en: for a in dimensions 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for b in dimension 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ‚Ä¶.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'for last letter of the alphabet in dimension number of letters in the alphabet:
    **X.append(**[a,b,‚Ä¶,last letter of the alphabet])'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We don‚Äôt want this as it is not very efficient and you need to define a variable
    per dimension and it is annoying. Let‚Äôs use the magic **numpy** instead.
  prefs: []
  type: TYPE_NORMAL
- en: the question **np.meshgrid(*points)** does what you would do using the for loop
    but in an optimized way. Your parameter dict is meant to be the dictionary that
    tells you what is the min and max for each parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this bit of code you will generate a 0/1 cube and a cube with three different
    dimensions (for example -5 to 1 in the first dimension, 0 to 10 in the second
    dimension and -1 to 1 in the third dimension):'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have three dimensions, let‚Äôs plot the first 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a89e734c64928746624d0d52f05c8423.png)'
  prefs: []
  type: TYPE_IMG
- en: 1.2 Pros and Cons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Pros:** This method is very known for two reasons. The first reason is that
    it is super easy to implement. It‚Äôs really a for loop between variables. The second
    reason is that of course you are covering the parameter space uniformly, which
    is ideal if you want to make sure not to lose important parts of the parameter
    space'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cons**: The huge problem with this method is of course the exponential dependency.
    If we assume that the number of dimensions is fixed (let‚Äôs say 6) for a steps
    = 10 design you are already looking at a million point realization. And the problem,
    again, is the exponentiality of the thing. So if you want to increase the number
    of steps by doubling it (20 steps instead of 10) you are now talking about a 64M
    point problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Random Sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An alternative to the uniform sampling is the random sampling. How does it
    work? It‚Äôs very simple: in the cube of interest, you just select the points randomly
    in the boundaries.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Random Sampling Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The random sampling method is extremely simple to code, for both 0‚Äì1 cubes
    and custom boundaries cubes. This is how:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs plot this:'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Pros and Cons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Pros:** Even in this case, the random sampling is extremely simple to understand
    and to code (as you saw). Another pro is that this method can capture the complexity
    of the output space better than the uniform sampling, especially for large dimensions.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cons**: The problem is the inherent randomness of the sampling. This can
    potentially create clusters and areas of scarce exploration.'
  prefs: []
  type: TYPE_NORMAL
- en: Just to be a little more in-depth, the paper produced by [Pedergnana et al](https://www.researchgate.net/publication/282527646_Smart_sampling_and_incremental_function_learning_for_very_large_high_dimensional_data/citations)
    (extremely good) compares the difference between these two methods and other ones,
    especially for high dimensionality.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Latin Hypercube Sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Latin Hypercube Sampling is usually defined as ‚ÄúUniformly randomized sampling‚Äù.
    I think this is a very beautiful definition. Let me explain the idea.
  prefs: []
  type: TYPE_NORMAL
- en: The key idea behind LHS is to divide the parameter space into equally probable
    intervals along each dimension and ensure that, within each interval, only one
    sample is taken. This results in a stratified and well-distributed sample that
    covers the entire parameter space.
  prefs: []
  type: TYPE_NORMAL
- en: The cool thing about the Latin Hypercube is that you can use [optimization methods](https://smt.readthedocs.io/en/latest/_src_docs/sampling_methods/lhs.html),
    for example, to maximize the minimum distance between points and place the point
    in a randomized location within its interval.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Latin Hypercube code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This method deserves a custom installation, namely Surrogate Modelling Toolbox
    (smt)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Super easy to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Pros and Cons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Latin hypercube is visually similar to random sampling, but in multiple
    dimensions, it helps to preserve a form of **regularity** in the random sampling
    without the limits of uniform sampling. This method is, in its variation, the
    preferred one for large dimensions with few samples (which is the trickiest case
    to consider). The con of this method is the fact that it is much more complex
    both to implement and to describe, so it requires domain knowledge and a little
    bit of hands-on practice.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this blog post, we saw three designs of experiment, or sampling, techniques
    for machine learning cases where a control of the input parameters is possible.
    In particular, we saw:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Uniform (Grid) Sampling**: this is a method of building a N-th dimensional
    grid, where N is the number of dimensions. Straightforward to use, but not detailed
    enough especially for large dimensions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random Sampling is the method of defining the N-th dimensional cube and extracting**
    random values in the cube. Straightforward to use and better functioning than
    uniform sampling in the case of large dimensions, but still not optimal as it
    can create clusters and too dense areas'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Latin Hypercube Sampling** is a method that regularizes Random Sampling by
    imposing that at least one point is sampled for different sections of the N-th
    dimensional hypercube. Optimal for large dimensionality and few samples but requires
    domain knowledge and an optimization procedure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We saw the three cases with coding examples for both unitary cubes (0 to 1 for
    each variable) and custom limits for each variable.
  prefs: []
  type: TYPE_NORMAL
- en: No method is perfect, and adopting one or the other depends on your end goal.
    I hope that this article gives you a little bit of a framework to work on when
    deciding which design of experiment is best to adopt :)
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you liked the article and you want to know more about machine learning,
    or you just want to ask me something, you can:'
  prefs: []
  type: TYPE_NORMAL
- en: A. Follow me on [**Linkedin**](https://www.linkedin.com/in/pieropaialunga/),
    where I publish all my stories
  prefs: []
  type: TYPE_NORMAL
- en: B. Subscribe to my [**newsletter**](https://piero-paialunga.medium.com/subscribe).
    It will keep you updated about new stories and give you the chance to text me
    to receive all the corrections or doubts you may have.
  prefs: []
  type: TYPE_NORMAL
- en: C. Become a [**referred member**](https://piero-paialunga.medium.com/membership),
    so you won‚Äôt have any ‚Äúmaximum number of stories for the month‚Äù and you can read
    whatever I (and thousands of other Machine Learning and Data Science top writers)
    write about the newest technology available.
  prefs: []
  type: TYPE_NORMAL
