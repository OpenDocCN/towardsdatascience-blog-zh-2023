- en: Hands on Sampling Techniques and comparison, in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®è·µä¸­çš„é‡‡æ ·æŠ€æœ¯å’Œæ¯”è¾ƒï¼Œä½¿ç”¨Python
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/hands-on-sampling-techniques-and-comparison-in-python-6342c70f2099](https://towardsdatascience.com/hands-on-sampling-techniques-and-comparison-in-python-6342c70f2099)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/hands-on-sampling-techniques-and-comparison-in-python-6342c70f2099](https://towardsdatascience.com/hands-on-sampling-techniques-and-comparison-in-python-6342c70f2099)
- en: Hereâ€™s a step-by-step tutorial on how to sample your dataset efficiently using
    Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•ä½¿ç”¨Pythoné«˜æ•ˆé‡‡æ ·æ•°æ®é›†çš„é€æ­¥æ•™ç¨‹
- en: '[](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----6342c70f2099--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)
    Â·8 min readÂ·Dec 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6342c70f2099--------------------------------)
    Â·8 min readÂ·2023å¹´12æœˆ1æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/95ead638268cc3c48bbd3a81345c2412.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/95ead638268cc3c48bbd3a81345c2412.png)'
- en: Image by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: I was putting the Christmas tree up with my wife. We went to the basement, took
    the tree, brought it upstairs, and started building it from bottom to top. Itâ€™s
    always a magic momentğŸ„
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å’Œæˆ‘çš„å¦»å­ä¸€èµ·å¸ƒç½®åœ£è¯æ ‘ã€‚æˆ‘ä»¬å»äº†åœ°ä¸‹å®¤ï¼Œæ‹¿äº†æ ‘ï¼ŒæŠŠå®ƒæ¬åˆ°æ¥¼ä¸Šï¼Œç„¶åä»ä¸‹å¾€ä¸Šå¼€å§‹æ­å»ºã€‚è¿™æ€»æ˜¯ä¸€ä¸ªç¥å¥‡çš„æ—¶åˆ»ğŸ„
- en: 'Then it was the point to put the balls on the tree. And immediately I thought:
    there are at least three ways to put the balls on the tree.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ˜¯æŠŠçƒæ”¾åˆ°æ ‘ä¸Šçš„ç¯èŠ‚ã€‚æˆ‘ç«‹åˆ»æƒ³åˆ°ï¼šè‡³å°‘æœ‰ä¸‰ç§æ–¹å¼å¯ä»¥æŠŠçƒæ”¾åˆ°æ ‘ä¸Šã€‚
- en: '**Uniformly**: put the balls uniformly on the tree, kind of like that'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‡åŒ€åœ°**ï¼šå°†çƒå‡åŒ€åœ°æ”¾åœ¨æ ‘ä¸Šï¼Œå°±åƒè¿™æ ·'
- en: '![](../Images/27d251a59d187aad89471f266bb3f509.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27d251a59d187aad89471f266bb3f509.png)'
- en: Image by author, made using [Freepik](https://www.freepik.com/)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ï¼Œä½¿ç”¨ [Freepik](https://www.freepik.com/) åˆ¶ä½œ
- en: '**Randomly**: put the balls randomly on the tree, closing your eyes and putting
    the ball wherever you feel like (I started doing this and my wife went MAD)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**éšæœºåœ°**ï¼šå°†çƒéšæœºåœ°æ”¾åœ¨æ ‘ä¸Šï¼Œé—­ä¸Šçœ¼ç›éšä¾¿æ”¾å“ªé‡Œï¼ˆæˆ‘å¼€å§‹è¿™æ ·åšï¼Œæˆ‘çš„å¦»å­ç–¯äº†ï¼‰'
- en: '![](../Images/9c8b491a96c276c9551aa2c6e399e869.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c8b491a96c276c9551aa2c6e399e869.png)'
- en: Image by author, made using [Freepik](https://www.freepik.com/)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ï¼Œä½¿ç”¨ [Freepik](https://www.freepik.com/) åˆ¶ä½œ
- en: '**Latin Hypercube**: Splitting the tree into N sections and extracting randomly
    in each one of these sections. Itâ€™s very hard to draw it without running any code,
    but a possible Latin Hypercube looks like this:'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ‹‰ä¸è¶…ç«‹æ–¹ä½“**ï¼šå°†æ ‘åˆ†æˆNä¸ªéƒ¨åˆ†ï¼Œå¹¶åœ¨æ¯ä¸ªéƒ¨åˆ†ä¸­éšæœºæŠ½å–ã€‚å¾ˆéš¾åœ¨ä¸è¿è¡Œä»»ä½•ä»£ç çš„æƒ…å†µä¸‹ç»˜åˆ¶ï¼Œä½†å¯èƒ½çš„æ‹‰ä¸è¶…ç«‹æ–¹ä½“å¦‚ä¸‹æ‰€ç¤ºï¼š'
- en: '![](../Images/e6178a5cd52634b880858d71ae374640.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6178a5cd52634b880858d71ae374640.png)'
- en: Image by author, made using [Freepik](https://www.freepik.com/)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ï¼Œä½¿ç”¨ [Freepik](https://www.freepik.com/) åˆ¶ä½œ
- en: I tried and show this to my wife. She smiled and said â€œWhateverâ€, so I went
    to my computer in the hope that your reaction would be something more satisfactory
    ğŸ˜¤
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°è¯•å¹¶æŠŠè¿™ä¸ªå±•ç¤ºç»™äº†æˆ‘çš„å¦»å­ã€‚å¥¹å¾®ç¬‘ç€è¯´â€œéšä¾¿â€ï¼Œäºæ˜¯æˆ‘å›åˆ°ç”µè„‘å‰ï¼Œå¸Œæœ›ä½ çš„ååº”èƒ½æ›´ä»¤äººæ»¡æ„ ğŸ˜¤
- en: 'Jokes aside, when dealing with Machine Learning problems there are two different
    scenarios:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¯´ç¬‘å½’è¯´ç¬‘ï¼Œå½“å¤„ç†æœºå™¨å­¦ä¹ é—®é¢˜æ—¶ï¼Œæœ‰ä¸¤ç§ä¸åŒçš„æƒ…å†µï¼š
- en: '**You donâ€™t have any control over the dataset**.You have a client, or a company,
    that hands you a dataset. Thatâ€™s what you will have to deal with until a necessary
    (eventual) re-training will be scheduled.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä½ æ— æ³•æ§åˆ¶æ•°æ®é›†**ã€‚ä½ æœ‰ä¸€ä¸ªå®¢æˆ·æˆ–å…¬å¸ï¼Œä¼šç»™ä½ ä¸€ä¸ªæ•°æ®é›†ã€‚è¿™æ˜¯ä½ å¿…é¡»å¤„ç†çš„ï¼Œç›´åˆ°å®‰æ’å¿…è¦çš„ï¼ˆæœ€ç»ˆçš„ï¼‰é‡æ–°è®­ç»ƒã€‚'
- en: For example, in the city of New York, you want to predict the price of a house
    based on some given features. They just give you the dataset and they want you
    to build your model so that when a new client arrives you have an AI software
    that can predict the price based on the features of the house of interest.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨çº½çº¦å¸‚ï¼Œä½ æƒ³æ ¹æ®ä¸€äº›ç»™å®šçš„ç‰¹å¾é¢„æµ‹æˆ¿å±‹çš„ä»·æ ¼ã€‚ä»–ä»¬åªç»™ä½ æ•°æ®é›†ï¼Œå¹¶å¸Œæœ›ä½ å»ºç«‹ä¸€ä¸ªæ¨¡å‹ï¼Œä»¥ä¾¿å½“æ–°å®¢æˆ·åˆ°æ¥æ—¶ï¼Œä½ æœ‰ä¸€ä¸ªAIè½¯ä»¶å¯ä»¥æ ¹æ®æ„Ÿå…´è¶£çš„æˆ¿å±‹ç‰¹å¾é¢„æµ‹ä»·æ ¼ã€‚
- en: '**2\. You can build your Design of Experiment**. This is when you have a forward
    model or a real-world experiment that you can always set up to run.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. ä½ å¯ä»¥å»ºç«‹ä½ çš„å®éªŒè®¾è®¡**ã€‚è¿™æŒ‡çš„æ˜¯ä½ æœ‰ä¸€ä¸ªå‰å‘æ¨¡å‹æˆ–ä¸€ä¸ªå¯ä»¥éšæ—¶è®¾ç½®è¿è¡Œçš„çœŸå®ä¸–ç•Œå®éªŒã€‚'
- en: For example, in a laboratory, you want to predict a physical signal given an
    experimental setup. You can always go to the lab and generate new data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨å®éªŒå®¤ä¸­ï¼Œä½ æƒ³åœ¨ç»™å®šå®éªŒè®¾ç½®çš„æƒ…å†µä¸‹é¢„æµ‹ä¸€ä¸ªç‰©ç†ä¿¡å·ã€‚ä½ å¯ä»¥éšæ—¶å»å®éªŒå®¤ç”Ÿæˆæ–°çš„æ•°æ®ã€‚
- en: The considerations that you make in the two cases are completely different.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹åšå‡ºçš„è€ƒè™‘æ˜¯å®Œå…¨ä¸åŒçš„ã€‚
- en: In the first case you can expect a dataset that is unbalanced in its features,
    maybe with missing input values and a skewed distribution of the target values.
    Itâ€™s the joy and damnation of a data scientist's job to deal with these things
    though. You do data augmentation, data filtering, fill in the miss values, do
    some ANOVA testing if you can and so forth. In the second case, you have complete
    control over whatâ€™s going on in your dataset, especially from the input perspective.
    This means that if you have a NaN value you can repeat the experiment, if you
    have several NaN values you can investigate that weird area of your dataset, if
    you have a suspicious large value for some given features you can just repeat
    the experiment to make sure itâ€™s not an hallucination of your setup.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€ä¸ªæƒ…å†µä¸‹ï¼Œä½ å¯ä»¥æœŸå¾…ä¸€ä¸ªåœ¨ç‰¹å¾ä¸Šä¸å¹³è¡¡çš„æ•°æ®é›†ï¼Œå¯èƒ½æœ‰ç¼ºå¤±çš„è¾“å…¥å€¼å’Œç›®æ ‡å€¼çš„åæ–œåˆ†å¸ƒã€‚å¤„ç†è¿™äº›é—®é¢˜æ˜¯æ•°æ®ç§‘å­¦å®¶çš„ä¹è¶£ä¸è¯…å’’ã€‚ä½ è¿›è¡Œæ•°æ®å¢å¼ºã€æ•°æ®è¿‡æ»¤ã€å¡«è¡¥ç¼ºå¤±å€¼ï¼Œå¦‚æœå¯èƒ½çš„è¯è¿›è¡Œä¸€äº›ANOVAæµ‹è¯•ç­‰ç­‰ã€‚åœ¨ç¬¬äºŒç§æƒ…å†µä¸‹ï¼Œä½ å¯¹æ•°æ®é›†ä¸­çš„æƒ…å†µæœ‰å®Œå…¨çš„æ§åˆ¶æƒï¼Œç‰¹åˆ«æ˜¯ä»è¾“å…¥çš„è§’åº¦æ¥çœ‹ã€‚è¿™æ„å‘³ç€å¦‚æœä½ æœ‰ä¸€ä¸ªNaNå€¼ï¼Œä½ å¯ä»¥é‡å¤å®éªŒï¼›å¦‚æœä½ æœ‰å‡ ä¸ªNaNå€¼ï¼Œä½ å¯ä»¥è°ƒæŸ¥æ•°æ®é›†ä¸­çš„é‚£ä¸ªå¥‡æ€ªåŒºåŸŸï¼›å¦‚æœä½ æœ‰ä¸€äº›ç‰¹å¾çš„å€¼éå¸¸å¤§ï¼Œä½ å¯ä»¥é‡å¤å®éªŒä»¥ç¡®ä¿è¿™ä¸æ˜¯ä½ è®¾ç½®çš„å¹»è§‰ã€‚
- en: As we have this amount of control we want to make sure to cover the input parameter
    space efficiently. For example, if you have 3 parameters, and you know the boundaries
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æœ‰è¿™ç§æ§åˆ¶æƒï¼Œæˆ‘ä»¬æƒ³ç¡®ä¿é«˜æ•ˆåœ°è¦†ç›–è¾“å…¥å‚æ•°ç©ºé—´ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰3ä¸ªå‚æ•°ï¼Œå¹¶ä¸”ä½ çŸ¥é“å®ƒä»¬çš„è¾¹ç•Œ
- en: '![](../Images/e303cf515210c11b74440370aa35f3fc.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e303cf515210c11b74440370aa35f3fc.png)'
- en: Image by author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: where i goes from 1 to 3 (or from 0 to 2 if you like Python so much ğŸ˜). In this
    case, x_i is the i-th variable and it will always be larger than x_i^L(ower boundary),
    but it will always be smaller than x_i^U(pper boundary).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ i ä» 1 åˆ° 3ï¼ˆæˆ–è€…ä» 0 åˆ° 2ï¼Œå¦‚æœä½ å–œæ¬¢ Python ğŸ˜ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œx_i æ˜¯ç¬¬ i ä¸ªå˜é‡ï¼Œå®ƒæ€»æ˜¯å¤§äº x_i^Lï¼ˆä¸‹è¾¹ç•Œï¼‰ï¼Œä½†æ€»æ˜¯å°äº
    x_i^Uï¼ˆä¸Šè¾¹ç•Œï¼‰ã€‚
- en: We have our 3-dimensional cube.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰æˆ‘ä»¬çš„ä¸‰ç»´ç«‹æ–¹ä½“ã€‚
- en: '![](../Images/44eeb5bf58ae7c259e478be4f096ed53.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44eeb5bf58ae7c259e478be4f096ed53.png)'
- en: Image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: Now, remember that we have complete control of our dataset. How do we sample?
    In other words, how do we determine the **x**s ? What are the points that we want
    to select so that we run the forward model (experiment or simulation) and get
    the target values?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®°ä½æˆ‘ä»¬å¯¹æ•°æ®é›†æœ‰å®Œå…¨çš„æ§åˆ¶æƒã€‚æˆ‘ä»¬å¦‚ä½•è¿›è¡Œé‡‡æ ·ï¼Ÿæ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¦‚ä½•ç¡®å®š**x**sï¼Ÿæˆ‘ä»¬æƒ³é€‰æ‹©å“ªäº›ç‚¹ï¼Œä»¥ä¾¿è¿è¡Œå‰å‘æ¨¡å‹ï¼ˆå®éªŒæˆ–æ¨¡æ‹Ÿï¼‰å¹¶è·å¾—ç›®æ ‡å€¼ï¼Ÿ
- en: As you can expect there are multiple methods to do so. Each method has its advantages
    and disadvantages. In this study, we will discuss them, show the theory behind
    them, and display the code for everyone to use and understand more about the beautiful
    world of sampling. ğŸ™‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ æ‰€æœŸå¾…çš„ï¼Œæœ‰å¤šç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚æ¯ç§æ–¹æ³•éƒ½æœ‰å…¶ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå®ƒä»¬ï¼Œå±•ç¤ºå®ƒä»¬èƒŒåçš„ç†è®ºï¼Œå¹¶æä¾›ä»£ç ä¾›å¤§å®¶ä½¿ç”¨ï¼Œè¿›ä¸€æ­¥äº†è§£ç¾å¦™çš„é‡‡æ ·ä¸–ç•Œã€‚ğŸ™‚
- en: 'Letâ€™s start with the uniform sampling:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»å‡åŒ€é‡‡æ ·å¼€å§‹ï¼š
- en: 1\. Uniform Sampling
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. å‡åŒ€é‡‡æ ·
- en: The uniform sampling method is arguably the most simple and famous one.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å‡åŒ€é‡‡æ ·æ–¹æ³•å¯ä»¥è¯´æ˜¯æœ€ç®€å•å’Œæœ€è‘—åçš„ä¸€ç§ã€‚
- en: 'It is just about splitting each parameter (or dimension) in steps. Letâ€™s assume
    that we have 3 steps per dimension, for 2 dimensions. Each dimension goes from
    0 to 1 (we will extend this in a minute). This would be the sampling:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯å°†æ¯ä¸ªå‚æ•°ï¼ˆæˆ–ç»´åº¦ï¼‰åˆ†æˆè‹¥å¹²æ­¥éª¤ã€‚å‡è®¾æˆ‘ä»¬æœ‰æ¯ä¸ªç»´åº¦3ä¸ªæ­¥éª¤ï¼Œ2ä¸ªç»´åº¦ã€‚æ¯ä¸ªç»´åº¦ä»0åˆ°1ï¼ˆæˆ‘ä»¬ç¨åä¼šæ‰©å±•ï¼‰ã€‚è¿™å°†æ˜¯é‡‡æ ·ï¼š
- en: (0,0)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (0,0)
- en: (0,0.5)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (0,0.5)
- en: (0,1)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (0,1)
- en: (0.5,0)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (0.5,0)
- en: (0.5,0.5)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (0.5,0.5)
- en: (0.5,1)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (0.5,1)
- en: (1,0)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1,0)
- en: (1,0.5)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1,0.5)
- en: (1,1)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1,1)
- en: 'This means that we fix one variable at a time and increase by step. Fairly
    simple. Letâ€™s code it:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Uniform Sampling Code
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How do we do this? Letâ€™s avoid this kind of structure:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: for a in dimensions 1
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for b in dimension 2
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: â€¦.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'for last letter of the alphabet in dimension number of letters in the alphabet:
    **X.append(**[a,b,â€¦,last letter of the alphabet])'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We donâ€™t want this as it is not very efficient and you need to define a variable
    per dimension and it is annoying. Letâ€™s use the magic **numpy** instead.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: the question **np.meshgrid(*points)** does what you would do using the for loop
    but in an optimized way. Your parameter dict is meant to be the dictionary that
    tells you what is the min and max for each parameter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this bit of code you will generate a 0/1 cube and a cube with three different
    dimensions (for example -5 to 1 in the first dimension, 0 to 10 in the second
    dimension and -1 to 1 in the third dimension):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'We have three dimensions, letâ€™s plot the first 2:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a89e734c64928746624d0d52f05c8423.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: 1.2 Pros and Cons
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Pros:** This method is very known for two reasons. The first reason is that
    it is super easy to implement. Itâ€™s really a for loop between variables. The second
    reason is that of course you are covering the parameter space uniformly, which
    is ideal if you want to make sure not to lose important parts of the parameter
    space'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '**Cons**: The huge problem with this method is of course the exponential dependency.
    If we assume that the number of dimensions is fixed (letâ€™s say 6) for a steps
    = 10 design you are already looking at a million point realization. And the problem,
    again, is the exponentiality of the thing. So if you want to increase the number
    of steps by doubling it (20 steps instead of 10) you are now talking about a 64M
    point problem.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Random Sampling
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An alternative to the uniform sampling is the random sampling. How does it
    work? Itâ€™s very simple: in the cube of interest, you just select the points randomly
    in the boundaries.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Random Sampling Code
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The random sampling method is extremely simple to code, for both 0â€“1 cubes
    and custom boundaries cubes. This is how:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s plot this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Pros and Cons
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Pros:** Even in this case, the random sampling is extremely simple to understand
    and to code (as you saw). Another pro is that this method can capture the complexity
    of the output space better than the uniform sampling, especially for large dimensions.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '**Cons**: The problem is the inherent randomness of the sampling. This can
    potentially create clusters and areas of scarce exploration.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Just to be a little more in-depth, the paper produced by [Pedergnana et al](https://www.researchgate.net/publication/282527646_Smart_sampling_and_incremental_function_learning_for_very_large_high_dimensional_data/citations)
    (extremely good) compares the difference between these two methods and other ones,
    especially for high dimensionality.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Latin Hypercube Sampling
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Latin Hypercube Sampling is usually defined as â€œUniformly randomized samplingâ€.
    I think this is a very beautiful definition. Let me explain the idea.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹‰ä¸è¶…ç«‹æ–¹ä½“æŠ½æ ·é€šå¸¸å®šä¹‰ä¸ºâ€œå‡åŒ€éšæœºæŠ½æ ·â€ã€‚æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªéå¸¸ç¾ä¸½çš„å®šä¹‰ã€‚è®©æˆ‘è§£é‡Šä¸€ä¸‹è¿™ä¸ªæ€æƒ³ã€‚
- en: The key idea behind LHS is to divide the parameter space into equally probable
    intervals along each dimension and ensure that, within each interval, only one
    sample is taken. This results in a stratified and well-distributed sample that
    covers the entire parameter space.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: LHS çš„å…³é”®æ€æƒ³æ˜¯å°†å‚æ•°ç©ºé—´åˆ’åˆ†ä¸ºæ¯ä¸ªç»´åº¦æ²¿çº¿çš„ç­‰æ¦‚ç‡åŒºé—´ï¼Œå¹¶ç¡®ä¿åœ¨æ¯ä¸ªåŒºé—´å†…åªæŠ½å–ä¸€ä¸ªæ ·æœ¬ã€‚è¿™ä¼šäº§ç”Ÿä¸€ä¸ªåˆ†å±‚ä¸”åˆ†å¸ƒå‡åŒ€çš„æ ·æœ¬ï¼Œè¦†ç›–æ•´ä¸ªå‚æ•°ç©ºé—´ã€‚
- en: The cool thing about the Latin Hypercube is that you can use [optimization methods](https://smt.readthedocs.io/en/latest/_src_docs/sampling_methods/lhs.html),
    for example, to maximize the minimum distance between points and place the point
    in a randomized location within its interval.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹‰ä¸è¶…ç«‹æ–¹ä½“çš„å¦™å¤„åœ¨äºä½ å¯ä»¥ä½¿ç”¨[ä¼˜åŒ–æ–¹æ³•](https://smt.readthedocs.io/en/latest/_src_docs/sampling_methods/lhs.html)ï¼Œä¾‹å¦‚ï¼Œæœ€å¤§åŒ–ç‚¹ä¹‹é—´çš„æœ€å°è·ç¦»ï¼Œå¹¶å°†ç‚¹æ”¾ç½®åœ¨å…¶åŒºé—´å†…çš„éšæœºä½ç½®ã€‚
- en: 3.1 Latin Hypercube code
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 æ‹‰ä¸è¶…ç«‹æ–¹ä½“ä»£ç 
- en: This method deserves a custom installation, namely Surrogate Modelling Toolbox
    (smt)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹æ³•éœ€è¦è‡ªå®šä¹‰å®‰è£…ï¼Œå³ä»£ç†å»ºæ¨¡å·¥å…·ç®±ï¼ˆsmtï¼‰
- en: '[PRE0]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Super easy to do that:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…çº§ç®€å•ï¼š
- en: 3.2 Pros and Cons
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 ä¼˜ç¼ºç‚¹
- en: The Latin hypercube is visually similar to random sampling, but in multiple
    dimensions, it helps to preserve a form of **regularity** in the random sampling
    without the limits of uniform sampling. This method is, in its variation, the
    preferred one for large dimensions with few samples (which is the trickiest case
    to consider). The con of this method is the fact that it is much more complex
    both to implement and to describe, so it requires domain knowledge and a little
    bit of hands-on practice.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹‰ä¸è¶…ç«‹æ–¹ä½“åœ¨è§†è§‰ä¸Šç±»ä¼¼äºéšæœºæŠ½æ ·ï¼Œä½†åœ¨å¤šä¸ªç»´åº¦ä¸­ï¼Œå®ƒæœ‰åŠ©äºä¿æŒéšæœºæŠ½æ ·çš„ä¸€ç§**è§„åˆ™æ€§**ï¼Œè€Œä¸å—å‡åŒ€æŠ½æ ·çš„é™åˆ¶ã€‚è¿™ä¸ªæ–¹æ³•åœ¨å…¶å˜ä½“ä¸­æ˜¯é«˜ç»´åº¦å°‘æ ·æœ¬ï¼ˆè¿™æ˜¯æœ€æ£˜æ‰‹çš„æƒ…å†µï¼‰çš„é¦–é€‰ã€‚è¿™ä¸ªæ–¹æ³•çš„ç¼ºç‚¹åœ¨äºå®ƒåœ¨å®ç°å’Œæè¿°ä¸Šéƒ½æ›´å¤æ‚ï¼Œå› æ­¤éœ€è¦é¢†åŸŸçŸ¥è¯†å’Œä¸€äº›å®é™…æ“ä½œç»éªŒã€‚
- en: 4\. Conclusions
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. ç»“è®º
- en: 'In this blog post, we saw three designs of experiment, or sampling, techniques
    for machine learning cases where a control of the input parameters is possible.
    In particular, we saw:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸‰ç§å®éªŒè®¾è®¡æˆ–æŠ½æ ·æŠ€æœ¯ï¼Œé€‚ç”¨äºå¯ä»¥æ§åˆ¶è¾“å…¥å‚æ•°çš„æœºå™¨å­¦ä¹ æ¡ˆä¾‹ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬è®¨è®ºäº†ï¼š
- en: '**Uniform (Grid) Sampling**: this is a method of building a N-th dimensional
    grid, where N is the number of dimensions. Straightforward to use, but not detailed
    enough especially for large dimensions.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‡åŒ€ï¼ˆç½‘æ ¼ï¼‰æŠ½æ ·**ï¼šè¿™æ˜¯æ„å»º N ç»´ç½‘æ ¼çš„æ–¹æ³•ï¼Œå…¶ä¸­ N æ˜¯ç»´åº¦çš„æ•°é‡ã€‚ä½¿ç”¨ç®€å•ï¼Œä½†å¯¹äºå¤§ç»´åº¦æ¥è¯´ä¸å¤Ÿè¯¦ç»†ã€‚'
- en: '**Random Sampling is the method of defining the N-th dimensional cube and extracting**
    random values in the cube. Straightforward to use and better functioning than
    uniform sampling in the case of large dimensions, but still not optimal as it
    can create clusters and too dense areas'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**éšæœºæŠ½æ ·æ˜¯å®šä¹‰ N ç»´ç«‹æ–¹ä½“å¹¶æå–**ç«‹æ–¹ä½“å†…éšæœºå€¼çš„æ–¹æ³•ã€‚ä½¿ç”¨ç®€å•ï¼Œåœ¨å¤§ç»´åº¦çš„æƒ…å†µä¸‹æ¯”å‡åŒ€æŠ½æ ·æ›´æœ‰æ•ˆï¼Œä½†ä»ç„¶ä¸ç†æƒ³ï¼Œå› ä¸ºå®ƒå¯èƒ½ä¼šåˆ›å»ºèšç±»å’Œè¿‡äºå¯†é›†çš„åŒºåŸŸã€‚'
- en: '**Latin Hypercube Sampling** is a method that regularizes Random Sampling by
    imposing that at least one point is sampled for different sections of the N-th
    dimensional hypercube. Optimal for large dimensionality and few samples but requires
    domain knowledge and an optimization procedure'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ‹‰ä¸è¶…ç«‹æ–¹ä½“æŠ½æ ·**æ˜¯ä¸€ç§é€šè¿‡åœ¨ N ç»´è¶…ç«‹æ–¹ä½“çš„ä¸åŒéƒ¨åˆ†è‡³å°‘æŠ½å–ä¸€ä¸ªç‚¹æ¥è§„èŒƒåŒ–éšæœºæŠ½æ ·çš„æ–¹æ³•ã€‚é€‚ç”¨äºé«˜ç»´åº¦å’Œæ ·æœ¬è¾ƒå°‘çš„æƒ…å†µï¼Œä½†éœ€è¦é¢†åŸŸçŸ¥è¯†å’Œä¼˜åŒ–ç¨‹åºã€‚'
- en: We saw the three cases with coding examples for both unitary cubes (0 to 1 for
    each variable) and custom limits for each variable.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°ä¸‰ç§æƒ…å†µçš„ç¼–ç ç¤ºä¾‹ï¼ŒåŒ…æ‹¬å•ä½ç«‹æ–¹ä½“ï¼ˆæ¯ä¸ªå˜é‡çš„èŒƒå›´ä»0åˆ°1ï¼‰å’Œæ¯ä¸ªå˜é‡çš„è‡ªå®šä¹‰é™åˆ¶ã€‚
- en: No method is perfect, and adopting one or the other depends on your end goal.
    I hope that this article gives you a little bit of a framework to work on when
    deciding which design of experiment is best to adopt :)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰æ–¹æ³•æ˜¯å®Œç¾çš„ï¼Œé€‰æ‹©å“ªç§æ–¹æ³•å–å†³äºä½ çš„æœ€ç»ˆç›®æ ‡ã€‚å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½ä¸ºä½ åœ¨å†³å®šé‡‡ç”¨å“ªç§å®éªŒè®¾è®¡æ—¶æä¾›ä¸€ç‚¹æ¡†æ¶ :)
- en: 5\. Conclusions
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. ç»“è®º
- en: 'If you liked the article and you want to know more about machine learning,
    or you just want to ask me something, you can:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œæƒ³äº†è§£æ›´å¤šæœºå™¨å­¦ä¹ ç›¸å…³å†…å®¹ï¼Œæˆ–è€…æœ‰å…¶ä»–é—®é¢˜ï¼Œä½ å¯ä»¥ï¼š
- en: A. Follow me on [**Linkedin**](https://www.linkedin.com/in/pieropaialunga/),
    where I publish all my stories
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: A. å…³æ³¨æˆ‘åœ¨[**Linkedin**](https://www.linkedin.com/in/pieropaialunga/)ï¼Œæˆ‘ä¼šå‘å¸ƒæˆ‘çš„æ‰€æœ‰æ•…äº‹
- en: B. Subscribe to my [**newsletter**](https://piero-paialunga.medium.com/subscribe).
    It will keep you updated about new stories and give you the chance to text me
    to receive all the corrections or doubts you may have.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è®¢é˜…æˆ‘çš„[**æ–°é—»é€šè®¯**](https://piero-paialunga.medium.com/subscribe)ã€‚å®ƒå°†ä½¿ä½ äº†è§£æœ€æ–°çš„æ•…äº‹ï¼Œå¹¶ç»™ä½ æœºä¼šé€šè¿‡çŸ­ä¿¡è”ç³»æˆ‘ï¼Œè·å–æ‰€æœ‰çš„ä¿®æ­£æˆ–è§£ç­”ä½ çš„ç–‘é—®ã€‚
- en: C. Become a [**referred member**](https://piero-paialunga.medium.com/membership),
    so you wonâ€™t have any â€œmaximum number of stories for the monthâ€ and you can read
    whatever I (and thousands of other Machine Learning and Data Science top writers)
    write about the newest technology available.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æˆä¸º[**æ¨èä¼šå‘˜**](https://piero-paialunga.medium.com/membership)ï¼Œè¿™æ ·ä½ å°±ä¸ä¼šå—åˆ°â€œæ¯æœˆæ•…äº‹æ•°é‡ä¸Šé™â€çš„é™åˆ¶ï¼Œå¯ä»¥é˜…è¯»æˆ‘ï¼ˆä»¥åŠæ•°åƒåå…¶ä»–æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦é¡¶çº§ä½œè€…ï¼‰æ’°å†™çš„å…³äºæœ€æ–°æŠ€æœ¯çš„å†…å®¹ã€‚
