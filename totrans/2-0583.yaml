- en: Crafting Effective Prompts for Summarization Using Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用大语言模型制作有效总结提示
- en: 原文：[https://towardsdatascience.com/crafting-effective-prompts-for-summarization-using-large-language-models-dbbdf019f664](https://towardsdatascience.com/crafting-effective-prompts-for-summarization-using-large-language-models-dbbdf019f664)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/crafting-effective-prompts-for-summarization-using-large-language-models-dbbdf019f664](https://towardsdatascience.com/crafting-effective-prompts-for-summarization-using-large-language-models-dbbdf019f664)
- en: Artificial intelligence and large language models
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能和大语言模型
- en: Distilling key points after >2 years of experience and from AI developers’ own
    tutorials, hands-on and with examples.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在拥有超过2年的经验以及来自AI开发者自身的教程、实践和示例之后提炼出的关键点。
- en: '[](https://lucianosphere.medium.com/?source=post_page-----dbbdf019f664--------------------------------)[![LucianoSphere
    (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page-----dbbdf019f664--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dbbdf019f664--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dbbdf019f664--------------------------------)
    [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page-----dbbdf019f664--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lucianosphere.medium.com/?source=post_page-----dbbdf019f664--------------------------------)[![LucianoSphere
    (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page-----dbbdf019f664--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dbbdf019f664--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dbbdf019f664--------------------------------)
    [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page-----dbbdf019f664--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dbbdf019f664--------------------------------)
    ·8 min read·Oct 24, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----dbbdf019f664--------------------------------)
    ·8分钟阅读·2023年10月24日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5d9c95adc4b403b4cdbf2d4155e8083a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d9c95adc4b403b4cdbf2d4155e8083a.png)'
- en: Photo by [Emiliano Vittoriosi](https://unsplash.com/@emilianovittoriosi?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Emiliano Vittoriosi](https://unsplash.com/@emilianovittoriosi?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In an era of abundant information—think of the large numbers of articles published
    on every possible topic, the time spent at meetings and presentations, or the
    volume of e-mails you get everyday at work—the ability to distill complex content
    into concise, insightful summaries is invaluable. Summarization tools have existed
    for some time, but the recent advent of large language models such as those from
    the GPT, Bard, or LLaMa series among the most popular ones, has taken summarization
    to new levels. This is so because large language models do not work as fixed-rule
    summarizers but rather can “understand” the contents of the input text and produce
    succinct summaries with much more flexibility than tools not using language models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息丰富的时代——想想每天发布的大量文章，会议和演讲中消耗的时间，或你在工作中收到的电子邮件数量——将复杂内容提炼成简洁、富有洞察力的摘要的能力是无价的。总结工具已经存在了一段时间，但最近大语言模型的出现，如GPT、Bard或LLaMa系列中的一些最受欢迎的模型，已经将总结提升到了新的高度。这是因为大语言模型不是作为固定规则的总结器工作，而是可以“理解”输入文本的内容，并以比不使用语言模型的工具更大的灵活性生成简明的摘要。
- en: In particular, passing the right prompt to the language model can achieve not
    only plain summarization but also rephrasing in a specific style, changing between
    passive and active form, changing the narrative perspective, even understanding
    texts that contain pieces in different languages or tones and writing a consistent
    summary in a single tone and language. None of these is possible with summarization
    tools not powered by large language models, which rapidly became rather obsolete.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，传递正确的提示给语言模型不仅可以实现普通的总结，还可以按照特定风格进行重新措辞、在被动和主动形式之间转换、更改叙述视角，甚至理解包含不同语言或语调的文本，并用单一语调和语言写出一致的摘要。这些都是不具备大语言模型支持的总结工具所无法实现的，这些工具迅速变得相当过时。
- en: From my above statement, then, it is obvious that the key to harnessing the
    full potential of large language models in summarization lies in crafting prompts
    that guide them effectively. Here I will overview the most important points you
    must consider when writing prompts expected to produce high-quality summaries
    across a range of content types.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从我上述的陈述来看，显然，发挥大型语言模型在总结中的全部潜力的关键在于制定有效引导它们的提示。在这里，我将概述编写期望生成高质量摘要的提示时必须考虑的最重要的要点。
- en: '**The power of prompts**'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**提示的力量**'
- en: Prompts serve as the interface between human intention and AI execution. They
    provide the necessary instructions and context for the language model to generate
    summaries that meet the user’s needs. This means they must be complete, from including
    explicit guidelines and requests on what you expect in its output to including
    relevant information that provides context. You will see examples of all these
    points through my article.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 提示作为人类意图与人工智能执行之间的接口。它们提供了语言模型生成符合用户需求的摘要所需的指令和背景。这意味着提示必须是完整的，包括对输出的明确指导和要求，以及提供背景的相关信息。你将通过我的文章看到这些要点的示例。
- en: 'Effective prompts share common characteristics that make them powerful tools
    for extracting meaningful summaries. They are clear, specific, and tailored to
    the content and context of the task at hand. An ideal prompt leaves no room for
    ambiguity. It precisely articulates what the user wants to extract from the content.
    For example, instead of asking, ‘Summarize this article’ a more effective prompt
    would be something like:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的提示具有共同的特征，使其成为提取有意义摘要的强大工具。它们清晰、具体，并针对任务的内容和背景量身定制。理想的提示不留模糊空间。它准确表达了用户希望从内容中提取的内容。例如，与其要求“总结这篇文章”，更有效的提示应该是：
- en: '*Generate a point-by-point summary of the key findings and arguments in the
    following article.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*生成以下文章关键发现和论点的逐点总结。*'
- en: 'Context is crucial in generating relevant summaries. Prompts should provide
    context about the source material, the target audience, and the desired level
    of detail. This ensures that the language model “understands” nuances in the content
    and thus can produce a summary that aligns with the user’s goals. For example,
    you can include in a prompt information explaining that the text to be summarized
    is the memo of a meeting, or a scientific article, or a collage of news about
    a topic, or a podcast, or an e-mail, or an example of the kind of output you expect.
    I have already written several programs that exploit GPT-3.5 or GPT-4 in ways
    specialized to make summaries in some of those situations, and I could always
    see a big impact of the context passed in the prompt, especially at the beginning
    of it. See for example these two articles:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文在生成相关摘要中至关重要。提示应提供有关来源材料、目标受众和期望细节水平的背景信息。这确保语言模型“理解”内容中的细微差别，从而生成符合用户目标的摘要。例如，你可以在提示中包括解释待总结的文本是会议备忘录、科学文章、某主题的新闻汇编、播客、电子邮件或你期望的输出示例的信息。我已经编写了几种程序，利用GPT-3.5或GPT-4在这些情况下生成总结，并且我总能看到提示中传递的背景影响很大，尤其是在开头部分。例如，请参见这两篇文章：
- en: '[](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dbbdf019f664--------------------------------)
    [## Control web apps via natural language by casting speech to commands with GPT-3'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dbbdf019f664--------------------------------)
    [## 通过将语音转换为命令来控制网页应用程序，使用GPT-3'
- en: One last article showcasing practical applications of GPT3, with a full explanation
    of the workflow and details on the…
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后一篇文章展示了GPT3的实际应用，详细解释了工作流程和细节……
- en: towardsdatascience.com](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dbbdf019f664--------------------------------)
    [](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dbbdf019f664--------------------------------)
    [## Coupling GPT-3 with speech recognition and synthesis to achieve a fully talking
    chatbot that runs…
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dbbdf019f664--------------------------------)
    [](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dbbdf019f664--------------------------------)
    [## 将 GPT-3 与语音识别和合成结合，实现完全对话的聊天机器人…
- en: How I created this web app with which you can talk naturally with GPT-3 about
    any topic you want, all web-based in your…
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我是如何创建这个网络应用程序的，你可以用它与 GPT-3 自然对话，讨论你想要的任何主题，全程基于网络…
- en: towardsdatascience.com](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dbbdf019f664--------------------------------)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dbbdf019f664--------------------------------)
- en: Depending on the task, prompts can also specify the desired level of abstraction
    in the summary. For instance, one might request a high-level overview, an in-depth
    analysis, a brief synthesis of key points, or a list of the key points, and so
    on. Prompts can also tune the scholarly level of the output; for example, one
    can ask a language model to summarize a hardcore scientific article “keeping scientific
    rigor” or “writing it for a 10 year old”, or to explain a piece of code “as pseudocode”
    or “only the basic ideas behind how it works”. Of course, the requested levels
    of abstraction and scholarly should align with the purpose of the summary.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任务，提示也可以指定总结的期望抽象层次。例如，可以请求高级概述、深入分析、关键点的简要综合或关键点的列表等等。提示还可以调整输出的学术层次；例如，可以要求语言模型总结一篇“保持科学严谨”的硬核科学文章，或“为
    10 岁儿童编写”，或解释一段代码“作为伪代码”或“仅解释其基本原理”。当然，请求的抽象层次和学术层次应与总结的目的相一致。
- en: 'Case study: my Summarizer Almighty chatbot'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 案例研究：我的 Summarizer Almighty 聊天机器人
- en: 'I developed a web app called “Summarizer Almighty” to tackle two problems at
    once: summarizing texts that are too long to fit as input to language models,
    and focusing on specific questions or instructions provided by the user -contrary
    to general summarization.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我开发了一个名为“Summarizer Almighty”的网络应用程序，以同时解决两个问题：总结长度过长的文本以适配语言模型输入，并关注用户提供的特定问题或指示——而不是一般总结。
- en: As I wrote it in first place, Summarizer Almighty utilizes the GPT-3.5-turbo
    language model to analyze and extract relevant information from lengthy documents
    based on user-provided questions or instructions. I have just updated it to GPT-4,
    which is much more expensive to run but provides substantially better responses
    in many cases.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我最初所写，Summarizer Almighty 利用 GPT-3.5-turbo 语言模型来分析和提取基于用户提供的问题或指示的长文档中的相关信息。我刚刚将其更新到
    GPT-4，虽然运行成本更高，但在许多情况下提供了更好的响应。
- en: 'To do its work, Summarizer Almighty splits the input document into overlapping
    chunks, which are individually analyzed and summarized through a special prompt
    of this type:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成工作，Summarizer Almighty 将输入文档拆分为重叠的块，这些块通过这种特殊提示进行单独分析和总结：
- en: '*Can you reply to “[user’s question]” considering the following piece of text
    taken from the article under study? If not, reply ‘FALSE’ and nothing else. If
    yes, reply ‘TRUE’ followed by the answer. Here’s the paragraph: “[chunk of text
    extracted from the document, optimized to around 3000 tokens]”*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*你能根据以下文章中的文本回复“[用户的问题]”吗？如果不能，请回复‘FALSE’而不做其他回复。如果可以，请回复‘TRUE’，并附上答案。以下是段落：“[从文档中提取的文本块，优化到大约
    3000 个 tokens]”*'
- en: 'Sending subsequently its inputs to the language model through its API, Summarizer
    Almighty accumulates partial answers into a growing paragraph that will contain
    several “FALSE” outputs and some “TRUE” outputs, the latter followed by explanations
    or answers as requested. At the very end, the program displays all partial outputs
    and then calls the language model once more, this time with an injected prompt
    that says:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随后将输入发送到语言模型的 API，Summarizer Almighty 将部分答案积累成一个不断增长的段落，其中包含多个“FALSE”输出和一些“TRUE”输出，后者附有解释或答案。最后，程序显示所有部分输出，然后再次调用语言模型，这次使用注入的提示：
- en: '*Please answer to “[user’s question]” using the information provided below,
    taken from sections of a longer text: [concatenation of all answers provided by
    calls that returned TRUE].*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*请回答“[用户的问题]”使用以下提供的信息，这些信息来自较长文本的各个部分：[所有返回TRUE的调用所提供的答案的连接]。*'
- en: 'Accessible for free (but you must provide a working OpenAI API for GPT models),
    I think Summarizer Almighty can be valuable in research, news writing, education,
    business, and other situations where time is limited and detailed information
    is crucial, saving time and effort. To know more, please check out my dedicated
    article:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 免费使用（但你必须提供有效的OpenAI API以使用GPT模型），我认为Summarizer Almighty在研究、新闻写作、教育、商业以及其他时间有限且详细信息至关重要的情况下非常有价值，能够节省时间和精力。欲了解更多，请查看我专门撰写的文章：
- en: '[](https://pub.towardsai.net/engineering-prompt-chains-with-language-models-to-craft-a-summarizer-almighty-web-app-7286de0b0a71?source=post_page-----dbbdf019f664--------------------------------)
    [## Engineering Prompt Chains With Language Models to Craft a “Summarizer Almighty”
    Web App'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 使用语言模型工程提示链来打造“终极摘要器”Web应用](https://pub.towardsai.net/engineering-prompt-chains-with-language-models-to-craft-a-summarizer-almighty-web-app-7286de0b0a71?source=post_page-----dbbdf019f664--------------------------------)'
- en: This free tool analyzes documents of arbitrary lengths, looking for information
    about a question or instruction…
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这个免费工具可以分析任意长度的文档，寻找有关问题或指令的信息……
- en: pub.towardsai.net](https://pub.towardsai.net/engineering-prompt-chains-with-language-models-to-craft-a-summarizer-almighty-web-app-7286de0b0a71?source=post_page-----dbbdf019f664--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[pub.towardsai.net](https://pub.towardsai.net/engineering-prompt-chains-with-language-models-to-craft-a-summarizer-almighty-web-app-7286de0b0a71?source=post_page-----dbbdf019f664--------------------------------)'
- en: '**From OpenAI’s own resources on how to craft better prompts**'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**来自OpenAI关于如何制定更好提示的资源**'
- en: OpenAI’s large language models are probably the most successful ones in the
    market out there right now. And objectively speaking, they were the first really
    good ones to roll out. Besides, they are in my opinion the easiest to use in practice
    -just through API calls and no installs. And the best documented ones…
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的大型语言模型可能是当前市场上最成功的模型。客观来说，它们是第一个真正优秀的模型。此外，在我看来，它们在实践中是最容易使用的——仅通过API调用，无需安装。而且文档也最全面……
- en: 'Indeed, OpenAI’s website has several resources aimed at helping you to write
    better prompts. And it’s not only about general rules and formats to pass in the
    prompt, but also about using special tokens and instructions. For example, the
    page dedicated specifically to best practices for prompt engineering with OpenAI’s
    API explains specifically that instructions should rather be passed at the beginning
    (as I also explained earlier in this article based on my own experience), that
    you can use tokens such as triple quotes ””” or hashtags ### to separate instructions
    from context, that providing leading words and examples of the kinds of outputs
    you expect is very helpful, and much more:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，OpenAI的网站上有许多资源旨在帮助你编写更好的提示。这不仅涉及到提示中传递的一般规则和格式，还涉及到使用特殊的标记和指令。例如，专门讲解OpenAI
    API提示工程最佳实践的页面特别说明了指令应该尽量在开头传递（正如我在本文中根据自己的经验也解释过的那样），你可以使用像三重引号”””或井号###来将指令与上下文分开，提供引导词和期望输出的示例是非常有帮助的，还有更多：
- en: '[## Best practices for prompt engineering with OpenAI API | OpenAI Help Center'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 使用OpenAI API进行提示工程的最佳实践 | OpenAI帮助中心](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?source=post_page-----dbbdf019f664--------------------------------)'
- en: How to give clear and effective instructions to GPT-3 and Codex
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何向GPT-3和Codex提供清晰有效的指令
- en: help.openai.com](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?source=post_page-----dbbdf019f664--------------------------------)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[help.openai.com](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?source=post_page-----dbbdf019f664--------------------------------)'
- en: 'OpenAI’s community forum also contains a section specifically designed to asking
    and answering questions about prompt engineering:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的社区论坛还包含一个专门设计的部分，用于提问和回答关于提示工程的问题：
- en: '[](https://community.openai.com/c/prompting/8?source=post_page-----dbbdf019f664--------------------------------)
    [## Prompting'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 提示工程](https://community.openai.com/c/prompting/8?source=post_page-----dbbdf019f664--------------------------------) '
- en: Learn more about prompting by sharing best practices, your favorite prompts,
    and more!
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过分享最佳实践、你喜欢的提示等来了解更多关于提示的内容！
- en: community.openai.com](https://community.openai.com/c/prompting/8?source=post_page-----dbbdf019f664--------------------------------)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[community.openai.com](https://community.openai.com/c/prompting/8?source=post_page-----dbbdf019f664--------------------------------)'
- en: '**Iterative Refinement**'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One important point I have observed in my vast experience, mainly with Google’s
    Bard and with language models of the GPT family, is that often, refining prompts
    iteratively is essential. You may need to experiment with different phrasings,
    instructions, or parameters to optimize the quality of the generated summaries.
    Very often, the first output is not what I want, specially when it has to do with
    summarization, because the language model can’t magically understand what your
    exact intentions are, where you want to focus, what tone you expect in the output,
    and other details that, as discussed above, you must inject into the model through
    the prompt. When this happens, that is most of the times, I need to either iterate
    with the language model a few times until I converge to what I expected, or try
    different starting prompts until I find the model provides the kinds of outputs
    I expect.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes you can get a first generation and feed it back to the model together
    with a new prompt designed to improve the output; but sometimes you need to start
    over from scratch by entering a totally new prompt. On a few occasions, checking
    the multiple outputs from the language model or re-running it on the same prompt
    can result in better generations, but this is often not the case.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'One tool that helps regarding some aspects, especially about the quality of
    the outputs produced by GPT models when used programmatically, is keeping an eye
    on the probabilities associated to each produced token, as I have described here
    for GPT-3:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[](/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c?source=post_page-----dbbdf019f664--------------------------------)
    [## Exploring Token Probabilities as a Means to Filter GPT-3’s Answers'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: To build better GPT-3-powered chatbots
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c?source=post_page-----dbbdf019f664--------------------------------)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusions**'
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Effective prompts are the key to unlocking the full potential of summarization
    powered by large language models, ensuring that the produced summaries are relevant,
    concise, insightful, tailored to exactly what you need, and written the way you
    need. Well-crafted prompts lead to more precise and relevant summaries, ensuring
    that the computer program focuses on extracting the information that is relevant
    to you. Clear prompts reduce the need for extensive post-processing, saving valuable
    time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Mastering the -as many call it and I don’t disagree- “art” of crafting prompts
    will be, or rather is already now, an essential skill in modern work. Whether
    it’s extracting insights from articles, research papers, meetings, or any other
    content, proper prompting guides your language model towards generating meaningful
    and actionable summaries. Put my advice into practice and check this out for yourself.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Some related articles you may like
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](https://medium.com/ido-imake/i-build-gpt-powered-tools-that-run-on-the-web-chatbots-summarizes-translators-e-mail-writers-78e303210cb?source=post_page-----dbbdf019f664--------------------------------)
    [## I build GPT-powered tools that run on the web (chatbots, summarizes, translators,
    e-mail writers'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[我构建的运行在网页上的GPT驱动工具（聊天机器人、摘要、翻译器、电子邮件写作工具）](https://medium.com/ido-imake/i-build-gpt-powered-tools-that-run-on-the-web-chatbots-summarizes-translators-e-mail-writers-78e303210cb?source=post_page-----dbbdf019f664--------------------------------)'
- en: Check out my examples, and you are free to contact me for jobs!
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看我的示例，你可以自由联系我获取工作机会！
- en: medium.com](https://medium.com/ido-imake/i-build-gpt-powered-tools-that-run-on-the-web-chatbots-summarizes-translators-e-mail-writers-78e303210cb?source=post_page-----dbbdf019f664--------------------------------)  [##
    All my articles on GPT-3 as of October 2022
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[我在2022年10月的所有关于GPT-3的文章](https://medium.com/ido-imake/i-build-gpt-powered-tools-that-run-on-the-web-chatbots-summarizes-translators-e-mail-writers-78e303210cb?source=post_page-----dbbdf019f664--------------------------------)'
- en: My favorite language model and how to use it for multiple purposes in online
    applications with pure JavaScript and…
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我最喜欢的语言模型及其如何在在线应用中利用纯JavaScript进行多种用途的使用方式…
- en: 'lucianosphere.medium.com](https://lucianosphere.medium.com/all-my-articles-on-gpt-3-as-of-october-2022-10e95dcae199?source=post_page-----dbbdf019f664--------------------------------)
    [](https://medium.com/ido-imake/i-write-about-science-and-technology-part-1-my-main-content-on-data-science-artificial-5419e58ed7d1?source=post_page-----dbbdf019f664--------------------------------)
    [## I Write About Science and Technology -Part 1: My Main Content on Data Science,
    Artificial…'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[我在2022年10月关于GPT-3的所有文章](https://lucianosphere.medium.com/all-my-articles-on-gpt-3-as-of-october-2022-10e95dcae199?source=post_page-----dbbdf019f664--------------------------------)
    [我写关于科学和技术的文章 - 第一部分：我的数据科学、人工智能的主要内容](https://medium.com/ido-imake/i-write-about-science-and-technology-part-1-my-main-content-on-data-science-artificial-5419e58ed7d1?source=post_page-----dbbdf019f664--------------------------------)'
- en: Recently, I’ve started having job requests on writing about science and technology,
    one client focused on biology…
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最近，我开始收到关于科学和技术写作的工作请求，其中一位客户专注于生物学…
- en: medium.com](https://medium.com/ido-imake/i-write-about-science-and-technology-part-1-my-main-content-on-data-science-artificial-5419e58ed7d1?source=post_page-----dbbdf019f664--------------------------------)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[我写关于科学和技术的文章 - 第一部分：我的数据科学、人工智能的主要内容](https://medium.com/ido-imake/i-write-about-science-and-technology-part-1-my-main-content-on-data-science-artificial-5419e58ed7d1?source=post_page-----dbbdf019f664--------------------------------)'
- en: '[***www.lucianoabriata.com***](https://www.lucianoabriata.com/) *I write about
    everything that lies in my broad sphere of interests: nature, science, technology,
    programming, etc.* [***Subscribe to get my new stories***](https://lucianosphere.medium.com/subscribe)
    ***by email****. To* ***consult about small jobs*** *check my* [***services page
    here***](https://lucianoabriata.altervista.org/services/index.html)*. You can*
    [***contact me here***](https://lucianoabriata.altervista.org/office/contact.html)***.***'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[***www.lucianoabriata.com***](https://www.lucianoabriata.com/) *我写的内容涉及我广泛的兴趣领域：自然、科学、技术、编程等。*
    [***订阅以获取我的新故事***](https://lucianosphere.medium.com/subscribe) ***通过电子邮件****。要*
    ***咨询小型工作*** *请查看我的* [***服务页面***](https://lucianoabriata.altervista.org/services/index.html)*。你可以*
    [***在这里联系我***](https://lucianoabriata.altervista.org/office/contact.html)***。***'
