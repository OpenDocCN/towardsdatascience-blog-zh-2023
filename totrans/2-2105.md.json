["```py\nimport re\nimport pandas as pd\n# src module available here: https://github.com/vcerqueira/tsa4climate/tree/main/src\nfrom src.log import LogTransformation\n\n# a sample here: https://github.com/vcerqueira/tsa4climate/tree/main/content/part_2/assets\nassets = 'path_to_data_directory'\n\nDATE_TIME_COLS = ['month', 'day', 'calendar_year', 'hour']\n# we'll focus on the data collected at particular station called smf1\nSTATION = 'smf1'\n\nCOLUMNS_PER_FILE = \\\n    {'incoming_solar_final.csv': DATE_TIME_COLS + [f'{STATION}_sin_w/m2'],\n     'wind_dir_raw.csv': DATE_TIME_COLS + [f'{STATION}_wd_deg'],\n     'snow_depth_final.csv': DATE_TIME_COLS + [f'{STATION}_sd_mm'],\n     'wind_speed_final.csv': DATE_TIME_COLS + [f'{STATION}_ws_m/s'],\n     'dewpoint_final.csv': DATE_TIME_COLS + [f'{STATION}_dpt_C'],\n     'precipitation_final.csv': DATE_TIME_COLS + [f'{STATION}_ppt_mm'],\n     'vapor_pressure.csv': DATE_TIME_COLS + [f'{STATION}_vp_Pa'],\n     'relative_humidity_final.csv': DATE_TIME_COLS + [f'{STATION}_rh'],\n     'air_temp_final.csv': DATE_TIME_COLS + [f'{STATION}_ta_C'],\n     }\n\ndata_series = {}\nfor file in COLUMNS_PER_FILE:\n    file_data = pd.read_csv(f'{assets}/{file}')\n\n    var_df = file_data[COLUMNS_PER_FILE[file]]\n\n    var_df['datetime'] = \\\n        pd.to_datetime([f'{year}/{month}/{day} {hour}:00'\n                        for year, month, day, hour in zip(var_df['calendar_year'],\n                                                          var_df['month'],\n                                                          var_df['day'],\n                                                          var_df['hour'])])\n\n    var_df = var_df.drop(DATE_TIME_COLS, axis=1)\n    var_df = var_df.set_index('datetime')\n    series = var_df.iloc[:, 0].sort_index()\n\n    data_series[file] = series\n\nmv_series = pd.concat(data_series, axis=1)\nmv_series.columns = [re.sub('_final.csv|_raw.csv|.csv', '', x) for x in mv_series.columns]\nmv_series.columns = [re.sub('_', ' ', x) for x in mv_series.columns]\nmv_series.columns = [x.title() for x in mv_series.columns]\n\nmv_series = mv_series.astype(float)\n```", "```py\nimport pandas as pd\n\ndef mts_to_tabular(data: pd.DataFrame,\n                   n_lags: int,\n                   horizon: int,\n                   return_Xy: bool = False,\n                   drop_na: bool = True):\n    \"\"\"\n    Time delay embedding with multivariate time series\n    Time series for supervised learning\n\n    :param data: multivariate time series as pd.DataFrame\n    :param n_lags: number of past values to used as explanatory variables\n    :param horizon: how many values to forecast\n    :param return_Xy: whether to return the lags split from future observations\n\n    :return: pd.DataFrame with reconstructed time series\n    \"\"\"\n\n    # applying time delay embedding to each variable\n    data_list = [time_delay_embedding(data[col], n_lags, horizon)\n                 for col in data]\n\n    # concatenating the results in a single dataframe\n    df = pd.concat(data_list, axis=1)\n\n    if drop_na:\n        df = df.dropna()\n\n    if not return_Xy:\n        return df\n\n    is_future = df.columns.str.contains('\\+')\n\n    X = df.iloc[:, ~is_future]\n    Y = df.iloc[:, is_future]\n\n    if Y.shape[1] == 1:\n        Y = Y.iloc[:, 0]\n\n    return X, Y\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\n# target variable\nTARGET = 'Solar Irradiance'\n# number of lags for each variable\nN_LAGS = 24\n# forecasting horizon for solar irradiance\nHORIZON = 48\n\n# leaving the last 30% of observations for testing\ntrain, test = train_test_split(mv_series, test_size=0.3, shuffle=False)\n\n# transforming the time series into a tabular format\nX_train, Y_train_all = mts_to_tabular(train, N_LAGS, HORIZON, return_Xy=True)\nX_test, Y_test_all = mts_to_tabular(train, N_LAGS, HORIZON, return_Xy=True)\n\n# subsetting the target variable\ntarget_columns = Y_train_all.columns.str.contains(TARGET)\nY_train = Y_train_all.iloc[:, target_columns]\nY_test = Y_test_all.iloc[:, target_columns]\n```", "```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sktime.transformations.series.date import DateTimeFeatures\n\nfrom src.holdout import Holdout\n\n# including datetime information to model seasonality\nhourly_feats = DateTimeFeatures(ts_freq='H',\n                                keep_original_columns=True,\n                                feature_scope='efficient')\n\n# building a pipeline\npipeline = Pipeline([\n    # feature extraction based on datetime\n    ('extraction', hourly_feats),\n    # removing correlated explanatory variables\n    ('correlation_filter', FunctionTransformer(func=correlation_filter)),\n    # applying feature selection based on recursive feature elimination\n    ('select', RFE(estimator=RandomForestRegressor(max_depth=5), step=3)),\n    # building a random forest model for forecasting\n    ('model', RandomForestRegressor())]\n)\n\n# parameter grid for optimization\nparam_grid = {\n    'extraction': ['passthrough', hourly_feats],\n    'select__n_features_to_select': np.linspace(start=.1, stop=1, num=10),\n    'model__n_estimators': [100, 200]\n}\n\n# optimizing the pipeline with random search\nmodel = RandomizedSearchCV(estimator=pipeline,\n                           param_distributions=param_grid,\n                           scoring='neg_mean_squared_error',\n                           n_iter=25,\n                           n_jobs=5,\n                           refit=True,\n                           verbose=2,\n                           cv=Holdout(n=X_train.shape[0]),\n                           random_state=123)\n\n# running random search\nmodel.fit(X_train, Y_train)\n\n# checking the selected model\nmodel.best_estimator_\n# Pipeline(steps=[('extraction',\n#                  DateTimeFeatures(feature_scope='efficient', ts_freq='H')),\n#                 ('correlation_filter',\n#                  FunctionTransformer(func=<function correlation_filter at 0x28cccfb50>)),\n#                 ('select',\n#                  RFE(estimator=RandomForestRegressor(max_depth=5),\n#                      n_features_to_select=0.9, step=3)),\n#                 ('model', RandomForestRegressor(n_estimators=200))])\n```", "```py\n# getting forecasts for the test set\nforecasts = model.predict(X_test)\nforecasts = pd.DataFrame(forecasts, columns=Y_test.columns)\n```"]