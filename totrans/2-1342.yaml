- en: Introduction to Apache Iceberg Tables
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Iceberg è¡¨ä»‹ç»
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009](https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009](https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009)
- en: A few Compelling Reasons to Choose Apache Iceberg for Data Lakes
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é€‰æ‹© Apache Iceberg ä½œä¸ºæ•°æ®æ¹–çš„å‡ ä¸ªä»¤äººä¿¡æœçš„ç†ç”±
- en: '[](https://mshakhomirov.medium.com/?source=post_page-----a791f1758009--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----a791f1758009--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a791f1758009--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a791f1758009--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----a791f1758009--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mshakhomirov.medium.com/?source=post_page-----a791f1758009--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----a791f1758009--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a791f1758009--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a791f1758009--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----a791f1758009--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a791f1758009--------------------------------)
    Â·8 min readÂ·Apr 10, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a791f1758009--------------------------------)
    Â·8 åˆ†é’Ÿé˜…è¯»Â·2023å¹´4æœˆ10æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8757d57a9e2fc3aae50cadf617507568.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8757d57a9e2fc3aae50cadf617507568.png)'
- en: Photo by [Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç”± [Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)
    æä¾›çš„ç…§ç‰‡ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '**Apache Iceberg**: What is it? Apache Iceberg â€” is it a new data lake file
    format? A table format? Why is it so good? Time travel for data lakes?'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache Iceberg**ï¼šè¿™æ˜¯ä»€ä¹ˆï¼ŸApache Icebergâ€”â€”å®ƒæ˜¯æ–°çš„æ•°æ®æ¹–æ–‡ä»¶æ ¼å¼å—ï¼Ÿè¿˜æ˜¯è¡¨æ ¼æ ¼å¼ï¼Ÿå®ƒä¸ºä½•å¦‚æ­¤ä¼˜ç§€ï¼Ÿæ•°æ®æ¹–çš„æ—¶é—´æ—…è¡Œï¼Ÿ'
- en: I will try to answer all these questions in this story.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†åœ¨è¿™ä¸ªæ•…äº‹ä¸­å°è¯•å›ç­”æ‰€æœ‰è¿™äº›é—®é¢˜ã€‚
- en: Transactionally consistent data lake tables with point-in-time snapshot isolation
    is all we need.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: äº‹åŠ¡ä¸€è‡´çš„æ•°æ®æ¹–è¡¨ä»¥åŠæ—¶é—´ç‚¹å¿«ç…§éš”ç¦»æ˜¯æˆ‘ä»¬æ‰€éœ€çš„ä¸€åˆ‡ã€‚
- en: Selecting a table format is a crucial choice for anybody pursuing a data lake
    or data mesh strategy. Some important data lake platform features to consider
    include **schema evolution support,** **read and write time**, **scalability**
    (is data processing Hadoop splittable?), **compression** efficiency and **time
    travel** to name a few.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©è¡¨æ ¼æ ¼å¼æ˜¯ä»»ä½•è¿½æ±‚æ•°æ®æ¹–æˆ–æ•°æ®ç½‘æ ¼ç­–ç•¥çš„äººéƒ½å¿…é¡»åšå‡ºçš„å…³é”®é€‰æ‹©ã€‚é€‰æ‹©æ•°æ®æ¹–å¹³å°æ—¶éœ€è¦è€ƒè™‘çš„ä¸€äº›é‡è¦åŠŸèƒ½åŒ…æ‹¬**æ¨¡å¼æ¼”å˜æ”¯æŒ**ã€**è¯»å†™æ—¶é—´**ã€**å¯æ‰©å±•æ€§**ï¼ˆæ•°æ®å¤„ç†æ˜¯å¦å¯ä»¥Hadoopåˆ†å‰²ï¼Ÿï¼‰ã€**å‹ç¼©**æ•ˆç‡ä»¥åŠ**æ—¶é—´æ—…è¡Œ**ç­‰ã€‚
- en: Choosing the right file and table format based on business requirements will
    define how fast and cost-effective your data platform might be.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©æ­£ç¡®çš„æ–‡ä»¶å’Œè¡¨æ ¼æ ¼å¼å°†å†³å®šä½ çš„æ•°æ®å¹³å°çš„é€Ÿåº¦å’Œæˆæœ¬æ•ˆç›Šã€‚
- en: '**Iceberg** is a ***table format***, engine and file format agnostic. Iceberg
    is not, in general, a development of a previous technology like **Apache Hive**.
    And it is a good thing, because developing something from an older technology
    might be limiting. A good example is how schema can change over time, and Iceberg
    can help to handle this as simply as renaming a column. ***It was designed and
    is proven to perform in data lake platforms at scale on the worldâ€™s most demanding
    workloads.***'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**Iceberg** æ˜¯ä¸€ç§***è¡¨æ ¼æ ¼å¼***ï¼Œå¼•æ“å’Œæ–‡ä»¶æ ¼å¼æ— å…³ã€‚Iceberg é€šå¸¸ä¸æ˜¯åƒ**Apache Hive**è¿™æ ·çš„æ—§æŠ€æœ¯çš„å¼€å‘ã€‚è¿™æ˜¯ä»¶å¥½äº‹ï¼Œå› ä¸ºä»æ—§æŠ€æœ¯ä¸­å¼€å‘å¯èƒ½ä¼šæœ‰å±€é™æ€§ã€‚ä¸€ä¸ªå¥½çš„ä¾‹å­æ˜¯æ¨¡å¼å¦‚ä½•éšæ—¶é—´å˜åŒ–ï¼Œè€ŒIcebergå¯ä»¥åƒé‡å‘½ååˆ—ä¸€æ ·ç®€å•åœ°å¤„ç†è¿™ç§å˜åŒ–ã€‚***å®ƒè¢«è®¾è®¡å¹¶è¯æ˜åœ¨å…¨çƒæœ€è‹›åˆ»çš„å·¥ä½œè´Ÿè½½ä¸­å¤§è§„æ¨¡çš„æ•°æ®æ¹–å¹³å°ä¸Šè¡¨ç°è‰¯å¥½ã€‚***'
- en: More and more data tools introduce Iceberg tables support.
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¶Šæ¥è¶Šå¤šçš„æ•°æ®å·¥å…·å¼€å§‹å¼•å…¥å†°å±±è¡¨çš„æ”¯æŒã€‚
- en: 'For instance, we can create an Apache Iseberg table in AWS Athena (must be
    engine 3) like so:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ AWS Athenaï¼ˆå¿…é¡»æ˜¯å¼•æ“ 3ï¼‰ä¸­è¿™æ ·åˆ›å»ºä¸€ä¸ª Apache Iceberg è¡¨ï¼š
- en: 'Googleâ€™s BigQuery now also supports Iceberg tables:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è°·æ­Œçš„ BigQuery ç°åœ¨ä¹Ÿæ”¯æŒ Iceberg è¡¨ï¼š
- en: Iceberg tables and data platform types
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†°å±±è¡¨å’Œæ•°æ®å¹³å°ç±»å‹
- en: Netflix created Iceberg originally, and it was supported and donated to the
    Apache Software Foundation eventually. Now, Iceberg is developed independently,
    it is a completely non-profit, open-source project and is focused on dealing with
    challenging data platform architectures.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix æœ€åˆåˆ›å»ºäº† Icebergï¼Œæœ€ç»ˆå®ƒå¾—åˆ°äº† Apache è½¯ä»¶åŸºé‡‘ä¼šçš„æ”¯æŒå’Œæèµ ã€‚ç°åœ¨ï¼ŒIceberg ç‹¬ç«‹å¼€å‘ï¼Œå®ƒæ˜¯ä¸€ä¸ªå®Œå…¨éç›ˆåˆ©çš„å¼€æºé¡¹ç›®ï¼Œä¸“æ³¨äºå¤„ç†å¤æ‚çš„æ•°æ®å¹³å°æ¶æ„ã€‚
- en: It supports multiple big data file formats, including Apache Avro, Apache Parquet,
    and Apache ORC.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ”¯æŒå¤šç§å¤§æ•°æ®æ–‡ä»¶æ ¼å¼ï¼ŒåŒ…æ‹¬ Apache Avroã€Apache Parquet å’Œ Apache ORCã€‚
- en: Keeping data in the data lake is one the most simple solutions when we design
    the data platform.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¾è®¡æ•°æ®å¹³å°æ—¶ï¼Œå°†æ•°æ®ä¿å­˜åœ¨æ•°æ®æ¹–ä¸­æ˜¯æœ€ç®€å•çš„è§£å†³æ–¹æ¡ˆä¹‹ä¸€ã€‚
- en: It requires much less maintenance compared to modern data warehouse solutions.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç›¸æ¯”äºç°ä»£æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆï¼Œå®ƒéœ€è¦çš„ç»´æŠ¤è¦å°‘å¾—å¤šã€‚
- en: Data lakes are typically used to store all types of data â€” structured and unstructured
    â€” at any size. Data lakes were traditionally connected with the Apache Hadoop
    Distributed File System (HDFS). However, organizations are increasingly using
    object storage solutions such as Amazon S3, Google Cloud Storage or Microsoft
    Azure Data Lake Storage.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ¹–é€šå¸¸ç”¨äºå­˜å‚¨æ‰€æœ‰ç±»å‹çš„æ•°æ®â€”â€”ç»“æ„åŒ–å’Œéç»“æ„åŒ–â€”â€”æ— è®ºå¤§å°ã€‚æ•°æ®æ¹–ä¼ ç»Ÿä¸Šä¸ Apache Hadoop åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼ˆHDFSï¼‰è¿æ¥ã€‚ç„¶è€Œï¼Œç»„ç»‡è¶Šæ¥è¶Šå¤šåœ°ä½¿ç”¨å¯¹è±¡å­˜å‚¨è§£å†³æ–¹æ¡ˆï¼Œå¦‚
    Amazon S3ã€Google Cloud Storage æˆ– Microsoft Azure Data Lake Storageã€‚
- en: In a few words, data lakes simplify data management by centralizing the data.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç®€è€Œè¨€ä¹‹ï¼Œæ•°æ®æ¹–é€šè¿‡é›†ä¸­ç®¡ç†æ•°æ®æ¥ç®€åŒ–æ•°æ®ç®¡ç†ã€‚
- en: 'Opposite to that, when every access is routed through a single system ( data
    warehouse), it simplifies concurrency management and updates but limits flexibility
    and raises costs. I previously wrote about it here:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ­¤ç›¸åï¼Œå½“æ¯æ¬¡è®¿é—®éƒ½é€šè¿‡ä¸€ä¸ªå•ä¸€ç³»ç»Ÿï¼ˆæ•°æ®ä»“åº“ï¼‰è¿›è¡Œæ—¶ï¼Œå®ƒç®€åŒ–äº†å¹¶å‘ç®¡ç†å’Œæ›´æ–°ï¼Œä½†é™åˆ¶äº†çµæ´»æ€§å¹¶å¢åŠ äº†æˆæœ¬ã€‚æˆ‘ä¹‹å‰åœ¨è¿™é‡Œå†™è¿‡ï¼š
- en: '[](/data-platform-architecture-types-f255ac6e0b7?source=post_page-----a791f1758009--------------------------------)
    [## Data Platform Architecture Types'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/data-platform-architecture-types-f255ac6e0b7?source=post_page-----a791f1758009--------------------------------)
    [## æ•°æ®å¹³å°æ¶æ„ç±»å‹'
- en: How well does it answer your business needs? Dilemma of a choice.
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å®ƒåœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ»¡è¶³äº†æ‚¨çš„ä¸šåŠ¡éœ€æ±‚ï¼Ÿé€‰æ‹©çš„å›°å¢ƒã€‚
- en: towardsdatascience.com](/data-platform-architecture-types-f255ac6e0b7?source=post_page-----a791f1758009--------------------------------)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/data-platform-architecture-types-f255ac6e0b7?source=post_page-----a791f1758009--------------------------------)
- en: It is all great but while building a data lake data platform we might face some
    other issues as well, i.e. no time travel, no schema evolution support, and complexity
    of data transformation and data definition.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€åˆ‡éƒ½å¾ˆæ£’ï¼Œä½†åœ¨æ„å»ºæ•°æ®æ¹–æ•°æ®å¹³å°æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½è¿˜ä¼šé‡åˆ°å…¶ä»–ä¸€äº›é—®é¢˜ï¼Œä¾‹å¦‚æ²¡æœ‰æ—¶é—´æ—…è¡Œã€æ²¡æœ‰æ¨¡å¼æ¼”å˜æ”¯æŒä»¥åŠæ•°æ®è½¬æ¢å’Œå®šä¹‰çš„å¤æ‚æ€§ã€‚
- en: When we build a data lake data platform, external tables will most likely bring
    the whole set of cons related to that architectureâ€¦ but Iceberg helps to solve
    this.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬æ„å»ºæ•°æ®æ¹–æ•°æ®å¹³å°æ—¶ï¼Œå¤–éƒ¨è¡¨é€šå¸¸ä¼šå¸¦æ¥ä¸è¯¥æ¶æ„ç›¸å…³çš„ä¸€æ•´å¥—ç¼ºç‚¹â€¦â€¦ä½† Iceberg æœ‰åŠ©äºè§£å†³è¿™äº›é—®é¢˜ã€‚
- en: '**At least some well-known limitations of traditional external tables:**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¼ ç»Ÿå¤–éƒ¨è¡¨çš„ä¸€äº›å·²çŸ¥é™åˆ¶ï¼š**'
- en: For example, we **canâ€™t modify them with DML statements and data consistency
    is not guaranteed.** Having said that, if the underlying data was changed during
    the processing we might not get consistent results.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬**ä¸èƒ½é€šè¿‡ DML è¯­å¥ä¿®æ”¹å®ƒä»¬ï¼Œä¸”æ•°æ®ä¸€è‡´æ€§ä¸èƒ½å¾—åˆ°ä¿è¯**ã€‚è¯è™½å¦‚æ­¤ï¼Œå¦‚æœåœ¨å¤„ç†è¿‡ç¨‹ä¸­åº•å±‚æ•°æ®å‘ç”Ÿå˜åŒ–ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå¾—åˆ°ä¸ä¸€è‡´çš„ç»“æœã€‚
- en: Have usually a **limited number of concurrent queries** in modern data warehouses,
    i.e. 4 in BigQuery.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç°ä»£æ•°æ®ä»“åº“ä¸­é€šå¸¸æœ‰**æœ‰é™çš„å¹¶å‘æŸ¥è¯¢æ•°**ï¼Œä¾‹å¦‚ BigQuery ä¸­ä¸º 4ã€‚
- en: External tables **do not work with clustering** and will not let export data
    from them.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤–éƒ¨è¡¨**ä¸æ”¯æŒé›†ç¾¤**ï¼Œä¹Ÿä¸å…è®¸ä»ä¸­å¯¼å‡ºæ•°æ®ã€‚
- en: Will not let us use wildcards to reference table names.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å…è®¸ä½¿ç”¨é€šé…ç¬¦å¼•ç”¨è¡¨åã€‚
- en: '**No time travel features**'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ²¡æœ‰æ—¶é—´æ—…è¡ŒåŠŸèƒ½**'
- en: From my experience, data consistency is one of the most important features large-scale
    analytics would require. Iceberg solves it and now multiple engines ( Spark, Hive,
    Presto, Dremio, etc.) can operate on the same table simultaneously.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æˆ‘çš„ç»éªŒï¼Œæ•°æ®ä¸€è‡´æ€§æ˜¯å¤§è§„æ¨¡åˆ†ææ‰€éœ€çš„æœ€é‡è¦çš„ç‰¹æ€§ä¹‹ä¸€ã€‚Iceberg è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œç°åœ¨å¤šä¸ªå¼•æ“ï¼ˆå¦‚ Sparkã€Hiveã€Prestoã€Dremio
    ç­‰ï¼‰å¯ä»¥åŒæ—¶æ“ä½œåŒä¸€å¼ è¡¨ã€‚
- en: It also offers many other brilliant features such as rollback to the previous
    table version (to quietly resolve issues), and advanced data filtering capabilities
    at scale when processing huge amounts of data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿˜æä¾›äº†è®¸å¤šå…¶ä»–å‡ºè‰²çš„åŠŸèƒ½ï¼Œä¾‹å¦‚å›æ»šåˆ°å…ˆå‰çš„è¡¨ç‰ˆæœ¬ï¼ˆä»¥æ‚„æ‚„è§£å†³é—®é¢˜ï¼‰ï¼Œä»¥åŠåœ¨å¤„ç†æµ·é‡æ•°æ®æ—¶çš„é«˜çº§æ•°æ®è¿‡æ»¤èƒ½åŠ›ã€‚
- en: Data consistency and improved processing efficiency
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®ä¸€è‡´æ€§å’Œæ”¹è¿›çš„å¤„ç†æ•ˆç‡
- en: A good example is when an ETL process modifies the dataset by adding and deleting
    files from storage, another application reading the dataset may process a partial
    or inconsistent representation of the dataset and produce inaccurate results.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¥½çš„ä¾‹å­æ˜¯ï¼Œå½“ ETL è¿‡ç¨‹é€šè¿‡ä»å­˜å‚¨ä¸­æ·»åŠ å’Œåˆ é™¤æ–‡ä»¶æ¥ä¿®æ”¹æ•°æ®é›†æ—¶ï¼Œå¦ä¸€ä¸ªè¯»å–æ•°æ®é›†çš„åº”ç”¨ç¨‹åºå¯èƒ½ä¼šå¤„ç†æ•°æ®é›†çš„éƒ¨åˆ†æˆ–ä¸ä¸€è‡´çš„è¡¨ç¤ºï¼Œä»è€Œäº§ç”Ÿä¸å‡†ç¡®çš„ç»“æœã€‚
- en: Iceberg would typically mitigate these risks by leveraging lots of manifest
    (metadata) files to take snapshots along the way the data is being processed.
    It will capture schemas and maintain deltas, including file information and partitioning
    data to guarantee consistency and complete isolation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Iceberg é€šå¸¸é€šè¿‡åˆ©ç”¨å¤§é‡æ¸…å•ï¼ˆå…ƒæ•°æ®ï¼‰æ–‡ä»¶æ¥ç¼“è§£è¿™äº›é£é™©ï¼Œä»¥ä¾¿åœ¨æ•°æ®å¤„ç†è¿‡ç¨‹ä¸­è¿›è¡Œå¿«ç…§ã€‚å®ƒå°†æ•è·æ¨¡å¼å¹¶ç»´æŠ¤å¢é‡ï¼ŒåŒ…æ‹¬æ–‡ä»¶ä¿¡æ¯å’Œåˆ†åŒºæ•°æ®ï¼Œä»¥ä¿è¯ä¸€è‡´æ€§å’Œå®Œå…¨éš”ç¦»ã€‚
- en: Iceberg also automatically arranges snapshot metadata in a hierarchical manner
    which ensures quick and efficient table modifications without redefining all dataset
    files, resulting in optimal performance while working at data lake scale.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Iceberg è¿˜ä¼šè‡ªåŠ¨ä»¥å±‚æ¬¡ç»“æ„çš„æ–¹å¼æ’åˆ—å¿«ç…§å…ƒæ•°æ®ï¼Œè¿™ç¡®ä¿äº†å¿«é€Ÿé«˜æ•ˆçš„è¡¨æ ¼ä¿®æ”¹ï¼Œæ— éœ€é‡æ–°å®šä¹‰æ‰€æœ‰æ•°æ®é›†æ–‡ä»¶ï¼Œä»è€Œåœ¨æ•°æ®æ¹–è§„æ¨¡ä¸‹å®ç°æœ€ä½³æ€§èƒ½ã€‚
- en: Iceberg offers SQL commands that allow you to combine new data (MERGE), change
    old rows, and remove specific rows.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Iceberg æä¾› SQL å‘½ä»¤ï¼Œå…è®¸ä½ åˆå¹¶æ–°æ•°æ®ï¼ˆMERGEï¼‰ã€æ›´æ”¹æ—§è¡Œå’Œåˆ é™¤ç‰¹å®šè¡Œã€‚
- en: Iceberg can eagerly rebuild data files to improve read performance or employ
    delete deltas to speed up updates.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Iceberg å¯ä»¥ç§¯æé‡å»ºæ•°æ®æ–‡ä»¶ä»¥æé«˜è¯»å–æ€§èƒ½ï¼Œæˆ–è€…ä½¿ç”¨åˆ é™¤å¢é‡åŠ å¿«æ›´æ–°é€Ÿåº¦ã€‚
- en: 'A good merge example can be found here:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¥½çš„åˆå¹¶ç¤ºä¾‹å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ï¼š
- en: '[](/advanced-sql-techniques-for-beginners-211851a28488?source=post_page-----a791f1758009--------------------------------)
    [## Advanced SQL techniques for beginners'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[//advanced-sql-techniques-for-beginners-211851a28488?source=post_page-----a791f1758009--------------------------------](//advanced-sql-techniques-for-beginners-211851a28488?source=post_page-----a791f1758009--------------------------------)
    [## åˆå­¦è€…çš„é«˜çº§ SQL æŠ€å·§'
- en: On a scale from 1 to 10 how good are your data warehousing skills?
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨ 1 åˆ° 10 çš„èŒƒå›´å†…ï¼Œä½ çš„æ•°æ®ä»“åº“æŠ€èƒ½æœ‰å¤šå¥½ï¼Ÿ
- en: towardsdatascience.com](/advanced-sql-techniques-for-beginners-211851a28488?source=post_page-----a791f1758009--------------------------------)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/advanced-sql-techniques-for-beginners-211851a28488?source=post_page-----a791f1758009--------------------------------)'
- en: 'Another one which can be applied to that AWS Athena table above is this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªå¯ä»¥åº”ç”¨äºä¸Šè¿° AWS Athena è¡¨æ ¼çš„ç¤ºä¾‹å¦‚ä¸‹ï¼š
- en: '![](../Images/2ddfd9ebb83759959e340d702256c0e3.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ddfd9ebb83759959e340d702256c0e3.png)'
- en: Image by author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Time travel feature
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ—¶é—´æ—…è¡ŒåŠŸèƒ½
- en: 'Modern data warehouses allow to time travel in your data, i.e. we can go to
    a specific timestamp to get that particular state of data in our table. For instance,
    in Google Cloud BigQuery we can run this SQL below to do so:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç°ä»£æ•°æ®ä»“åº“å…è®¸ä½ åœ¨æ•°æ®ä¸­è¿›è¡Œæ—¶é—´æ—…è¡Œï¼Œå³æˆ‘ä»¬å¯ä»¥è½¬åˆ°ç‰¹å®šçš„æ—¶é—´æˆ³ä»¥è·å–è¡¨æ ¼ä¸­çš„ç‰¹å®šæ•°æ®çŠ¶æ€ã€‚ä¾‹å¦‚ï¼Œåœ¨ Google Cloud BigQuery ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¿è¡Œä»¥ä¸‹
    SQL æ¥å®ç°ï¼š
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It might be a â€œnice-to-haveâ€ feature for data lake platforms as well.
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿå¯èƒ½æ˜¯æ•°æ®æ¹–å¹³å°çš„ä¸€ä¸ªâ€œä¸é”™çš„é™„åŠ åŠŸèƒ½â€ã€‚
- en: 'If you design a data architecture around files, such as Apache ORC or Apache
    Parquet, you will profit from ease of implementation, but you will also run into
    that issue described above. Time travel is not supported. Schema evolution has
    always been a problem too. When fields change over time it might be a problem.
    For instance, AVRO file format has schema evolution support and I previously wrote
    about big data file formatsâ€™ pros and cons here:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å›´ç»•æ–‡ä»¶è®¾è®¡æ•°æ®æ¶æ„ï¼Œä¾‹å¦‚ Apache ORC æˆ– Apache Parquetï¼Œä½ å°†å—ç›Šäºå®ç°çš„ç®€ä¾¿ï¼Œä½†ä½ ä¹Ÿä¼šé‡åˆ°ä¸Šè¿°æåˆ°çš„é—®é¢˜ã€‚æ—¶é—´æ—…è¡Œä¸è¢«æ”¯æŒã€‚æ¨¡å¼æ¼”å˜ä¸€ç›´æ˜¯ä¸ªé—®é¢˜ã€‚å½“å­—æ®µéšæ—¶é—´å˜åŒ–æ—¶å¯èƒ½ä¼šå‡ºç°é—®é¢˜ã€‚ä¾‹å¦‚ï¼ŒAVRO
    æ–‡ä»¶æ ¼å¼æ”¯æŒæ¨¡å¼æ¼”å˜ï¼Œæˆ‘ä¹‹å‰å†™è¿‡å…³äºå¤§æ•°æ®æ–‡ä»¶æ ¼å¼ä¼˜ç¼ºç‚¹çš„æ–‡ç« ï¼š
- en: '[](/big-data-file-formats-explained-275876dc1fc9?source=post_page-----a791f1758009--------------------------------)
    [## Big Data File Formats, Explained'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[//big-data-file-formats-explained-275876dc1fc9?source=post_page-----a791f1758009--------------------------------](//big-data-file-formats-explained-275876dc1fc9?source=post_page-----a791f1758009--------------------------------)
    [## å¤§æ•°æ®æ–‡ä»¶æ ¼å¼è¯¦è§£'
- en: Parquet vs ORC vs AVRO vs JSON. Which one to choose and how to use them?
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Parquet ä¸ ORC ä¸ AVRO ä¸ JSONã€‚è¯¥é€‰æ‹©å“ªä¸ªä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Ÿ
- en: towardsdatascience.com](/big-data-file-formats-explained-275876dc1fc9?source=post_page-----a791f1758009--------------------------------)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/big-data-file-formats-explained-275876dc1fc9?source=post_page-----a791f1758009--------------------------------)'
- en: Iceberg keeps the whole history within the Iceberg table format, with no storage
    system dependencies.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Iceberg å°†æ•´ä¸ªå†å²è®°å½•ä¿å­˜åœ¨ Iceberg è¡¨æ ¼æ ¼å¼ä¸­ï¼Œæ²¡æœ‰å­˜å‚¨ç³»ç»Ÿä¾èµ–ã€‚
- en: Iceberg table users may query past states at any Iceberg snapshot or historical
    point in time for consistent results, comparison, or rollback to remedy errors
    since the historical state is immutable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Iceberg è¡¨æ ¼ç”¨æˆ·å¯ä»¥åœ¨ä»»ä½• Iceberg å¿«ç…§æˆ–å†å²æ—¶é—´ç‚¹æŸ¥è¯¢è¿‡å»çš„çŠ¶æ€ï¼Œä»¥è·å¾—ä¸€è‡´çš„ç»“æœã€è¿›è¡Œæ¯”è¾ƒæˆ–å›æ»šä»¥ä¿®å¤é”™è¯¯ï¼Œå› ä¸ºå†å²çŠ¶æ€æ˜¯ä¸å¯å˜çš„ã€‚
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Schema evolution support
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å¼æ¼”è¿›æ”¯æŒ
- en: Itâ€™s not a secret that data lake files might change over time, as well as their
    schemas. Adding a column in the Iceberg table now will not return â€œdeadâ€ data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ¹–æ–‡ä»¶ä»¥åŠå®ƒä»¬çš„æ¨¡å¼éšç€æ—¶é—´çš„æ¨ç§»å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼Œè¿™å¹¶ä¸æ˜¯ç§˜å¯†ã€‚ç°åœ¨åœ¨ Iceberg è¡¨ä¸­æ·»åŠ ä¸€åˆ—ä¸ä¼šè¿”å›â€œæ— æ•ˆâ€æ•°æ®ã€‚
- en: Column names and the order can be changed. The best part is that schema updates
    never need to rebuild your table.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—åå’Œé¡ºåºå¯ä»¥æ›´æ”¹ã€‚æœ€æ£’çš„æ˜¯ï¼Œæ¨¡å¼æ›´æ–°ä»ä¸éœ€è¦é‡å»ºä½ çš„è¡¨ã€‚
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Iceberg allows for in-place table changes and it ensures correctness, i.e. new
    columns added never read existing values from another column. When data volume
    varies, we now can modify partition layout or change a table schema just using
    SQL, even for nested structures, i.e.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Iceberg å…è®¸å°±åœ°ä¿®æ”¹è¡¨ï¼Œå¹¶ç¡®ä¿æ­£ç¡®æ€§ï¼Œå³æ·»åŠ çš„æ–°åˆ—æ°¸è¿œä¸ä¼šä»å…¶ä»–åˆ—ä¸­è¯»å–ç°æœ‰å€¼ã€‚å½“æ•°æ®é‡å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä»…é€šè¿‡ SQL ä¿®æ”¹åˆ†åŒºå¸ƒå±€æˆ–æ›´æ”¹è¡¨æ¨¡å¼ï¼Œå³ä½¿æ˜¯åµŒå¥—ç»“æ„ã€‚
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is what Iceberg calls Partition evolution.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ Iceberg æ‰€è°“çš„åˆ†åŒºæ¼”è¿›ã€‚
- en: When you modify a partition specification, the existing data written with an
    earlier specification remains unaffected.
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å½“ä½ ä¿®æ”¹åˆ†åŒºè§„èŒƒæ—¶ï¼Œä½¿ç”¨æ—©æœŸè§„èŒƒå†™å…¥çš„ç°æœ‰æ•°æ®ä¸ä¼šå—åˆ°å½±å“ã€‚
- en: Each partition versionâ€™s metadata is saved separately. Iceberg does not require
    expensive diversions such as rewriting table data or moving to a new table.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªåˆ†åŒºç‰ˆæœ¬çš„å…ƒæ•°æ®è¢«å•ç‹¬ä¿å­˜ã€‚Iceberg ä¸éœ€è¦æ˜‚è´µçš„æ“ä½œï¼Œä¾‹å¦‚é‡å†™è¡¨æ•°æ®æˆ–è¿ç§»åˆ°æ–°è¡¨ã€‚
- en: Improved partitioning
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ”¹è¿›çš„åˆ†åŒº
- en: In Iceberg terms it is called â€œHidden partitionsâ€. The traditional data lake
    way of using partitions is called â€œHive partitioning layoutâ€.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Iceberg ä¸­ï¼Œè¿™è¢«ç§°ä¸ºâ€œéšè—åˆ†åŒºâ€ã€‚ä¼ ç»Ÿçš„æ•°æ®æ¹–åˆ†åŒºæ–¹å¼ç§°ä¸ºâ€œHive åˆ†åŒºå¸ƒå±€â€ã€‚
- en: 'Letâ€™s consider an external table with Hive partitioning layout in BigQuery:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªåœ¨ BigQuery ä¸­å…·æœ‰ Hive åˆ†åŒºå¸ƒå±€çš„å¤–éƒ¨è¡¨ï¼š
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Partitions must be explicit in Hive and are shown as columns, thus the `**user_transactions**`
    table would contain a `**dt**` date column. This means that all SQL queries that
    do something with our table will have to have `**dt**` filter in addition to a
    `**timestamp**` filter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Hive ä¸­ï¼Œåˆ†åŒºå¿…é¡»æ˜¯æ˜ç¡®çš„ï¼Œå¹¶ä¸”æ˜¾ç¤ºä¸ºåˆ—ï¼Œå› æ­¤ `**user_transactions**` è¡¨å°†åŒ…å«ä¸€ä¸ª `**dt**` æ—¥æœŸåˆ—ã€‚è¿™æ„å‘³ç€å¯¹æˆ‘ä»¬è¡¨è¿›è¡Œæ“ä½œçš„æ‰€æœ‰
    SQL æŸ¥è¯¢éƒ½å¿…é¡»é™¤äº† `**timestamp**` è¿‡æ»¤å™¨å¤–ï¼Œè¿˜è¦æœ‰ `**dt**` è¿‡æ»¤å™¨ã€‚
- en: Hive requires partition values. It does not understand the link between the
    transaction timestamp and `dt` in our table example above.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Hive éœ€è¦åˆ†åŒºå€¼ã€‚å®ƒä¸äº†è§£äº‹åŠ¡æ—¶é—´æˆ³å’Œæˆ‘ä»¬è¡¨ä¸­çš„ `dt` ä¹‹é—´çš„è”ç³»ã€‚
- en: '**Oppositely**, Iceberg generates partition values by taking a column value
    and, if needed, modifying it. Iceberg is in charge of translating transaction
    **`timestamp**` to `**dt**` and maintaining the connection. Iceberg may hide partitioning
    since it does not require user-maintained partition columns.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç›¸å**ï¼ŒIceberg é€šè¿‡å–åˆ—å€¼å¹¶åœ¨å¿…è¦æ—¶è¿›è¡Œä¿®æ”¹æ¥ç”Ÿæˆåˆ†åŒºå€¼ã€‚Iceberg è´Ÿè´£å°†äº‹åŠ¡**`timestamp`** è½¬æ¢ä¸º `**dt**`
    å¹¶ç»´æŠ¤è¿æ¥ã€‚Iceberg å¯èƒ½ä¼šéšè—åˆ†åŒºï¼Œå› ä¸ºå®ƒä¸éœ€è¦ç”¨æˆ·ç»´æŠ¤åˆ†åŒºåˆ—ã€‚'
- en: Partition values are always created appropriately and utilized to speed up queries
    wherever possible.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†åŒºå€¼æ€»æ˜¯è¢«é€‚å½“åœ°åˆ›å»ºå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ç”¨äºåŠ é€ŸæŸ¥è¯¢ã€‚
- en: '`dt` would be invisible to both producers and consumers and queries no longer
    rely on the actual physical layout of our table.'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`dt` å¯¹ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…éƒ½æ˜¯ä¸å¯è§çš„ï¼ŒæŸ¥è¯¢ä¸å†ä¾èµ–äºæˆ‘ä»¬è¡¨çš„å®é™…ç‰©ç†å¸ƒå±€ã€‚'
- en: 'It helps to avoid partitioning errors while transforming the data. For example,
    using the wrong date format, led to incorrect partitioning, not failures: `**20230101**`
    instead of `**2023â€“01â€“01**`. ***This is a well-known and most common problem with
    Hive partitioning payout.*** Another problem that Iceberg helps to solve is that
    in Hive partitioning layout all working queries are related to the tableâ€™s partitioning
    scheme, therefore changing the partitioning setup will break queries.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæœ‰åŠ©äºé¿å…åœ¨è½¬æ¢æ•°æ®æ—¶å‡ºç°åˆ†åŒºé”™è¯¯ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨é”™è¯¯çš„æ—¥æœŸæ ¼å¼ï¼Œå¯¼è‡´ä¸æ­£ç¡®çš„åˆ†åŒºï¼Œè€Œä¸æ˜¯å¤±è´¥ï¼š`**20230101**` ä»£æ›¿ `**2023â€“01â€“01**`ã€‚***è¿™æ˜¯
    Hive åˆ†åŒºå¸ƒå±€ä¸­ä¸€ä¸ªä¼—æ‰€å‘¨çŸ¥ä¸”æœ€å¸¸è§çš„é—®é¢˜ã€‚*** å¦ä¸€ä¸ª Iceberg æœ‰åŠ©äºè§£å†³çš„é—®é¢˜æ˜¯ï¼Œåœ¨ Hive åˆ†åŒºå¸ƒå±€ä¸­ï¼Œæ‰€æœ‰å·¥ä½œçš„æŸ¥è¯¢éƒ½ä¸è¡¨çš„åˆ†åŒºæ–¹æ¡ˆç›¸å…³ï¼Œå› æ­¤æ›´æ”¹åˆ†åŒºè®¾ç½®å°†ä¼šç ´åæŸ¥è¯¢ã€‚
- en: Conclusion
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Relational databases and data warehouses both support atomic transactions and
    time travel but they do it in their proprietary way. Iceberg, being an Apache
    project, is completely open source and not reliant on any specific tools or data
    lake engines.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å…³ç³»å‹æ•°æ®åº“å’Œæ•°æ®ä»“åº“éƒ½æ”¯æŒåŸå­äº‹åŠ¡å’Œæ—¶é—´æ—…è¡Œï¼Œä½†å®ƒä»¬ä»¥å…¶ä¸“æœ‰çš„æ–¹å¼å®ç°ã€‚Iceberg ä½œä¸ºä¸€ä¸ª Apache é¡¹ç›®ï¼Œæ˜¯å®Œå…¨å¼€æºçš„ï¼Œä¸ä¾èµ–äºä»»ä½•ç‰¹å®šçš„å·¥å…·æˆ–æ•°æ®æ¹–å¼•æ“ã€‚
- en: Iceberg supports industry-standard file formats like Parquet, ORC, and Avro
    and is compatible with key data lake engines such as Dremio, Spark, Hive, and
    Presto. Its wide community collaboration generates new ideas and provides assistance
    in the long term. It features various active communities, such as public Slack
    channels, in which everyone is free and welcome to participate. It was designed
    and is proven to perform in data lake platforms at scale on the worldâ€™s largest
    workloads and environments.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Iceberg æ”¯æŒè¡Œä¸šæ ‡å‡†æ–‡ä»¶æ ¼å¼å¦‚ Parquetã€ORC å’Œ Avroï¼Œå¹¶ä¸”ä¸ Dremioã€Sparkã€Hive å’Œ Presto ç­‰å…³é”®æ•°æ®æ¹–å¼•æ“å…¼å®¹ã€‚å…¶å¹¿æ³›çš„ç¤¾åŒºåˆä½œç”Ÿæˆæ–°æƒ³æ³•ï¼Œå¹¶æä¾›é•¿æœŸçš„å¸®åŠ©ã€‚å®ƒæ‹¥æœ‰å„ç§æ´»è·ƒçš„ç¤¾åŒºï¼Œä¾‹å¦‚å…¬å…±
    Slack é¢‘é“ï¼Œä»»ä½•äººéƒ½å¯ä»¥è‡ªç”±å‚ä¸ã€‚å®ƒç»è¿‡è®¾è®¡å¹¶è¯æ˜åœ¨å…¨çƒæœ€å¤§å·¥ä½œè´Ÿè½½å’Œç¯å¢ƒä¸­çš„æ•°æ®æ¹–å¹³å°ä¸Šè¡¨ç°å‡ºè‰²ã€‚
- en: Organizations now can enjoy the full potential and advantages of moving to a
    data lake architecture by utilizing Iceberg. Feel the cost-effectiveness of cloud
    storage-based data platforms with no need to sacrifice the features and capabilities
    of traditional databases and data warehouse solutions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ç»„ç»‡ç°åœ¨å¯ä»¥é€šè¿‡åˆ©ç”¨ Iceberg å……åˆ†å‘æŒ¥æ•°æ®æ¹–æ¶æ„çš„æ½œåŠ›å’Œä¼˜åŠ¿ã€‚ä½“éªŒåŸºäºäº‘å­˜å‚¨çš„æ•°æ®å¹³å°çš„æˆæœ¬æ•ˆç›Šï¼ŒåŒæ—¶æ— éœ€ç‰ºç‰²ä¼ ç»Ÿæ•°æ®åº“å’Œæ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆçš„åŠŸèƒ½å’Œèƒ½åŠ›ã€‚
- en: It makes our data lake platform really flexible and reliable
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å®ƒä½¿æˆ‘ä»¬çš„æ•°æ®æ¹–å¹³å°çœŸæ­£çµæ´»ä¸”å¯é 
- en: '**To conclude these are the benefits of the Iceberg table format:**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ€»ç»“ä¸€ä¸‹ï¼ŒIceberg è¡¨æ ¼æ ¼å¼çš„ä¼˜ç‚¹å¦‚ä¸‹ï¼š**'
- en: Several separate programs can handle the same dataset concurrently and consistently.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šä¸ªç‹¬ç«‹ç¨‹åºå¯ä»¥åŒæ—¶ä¸€è‡´åœ°å¤„ç†ç›¸åŒçš„æ•°æ®é›†ã€‚
- en: Improved data processing and data reliability (more efficient updates for very
    large data lake-scale tables).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ”¹è¿›çš„æ•°æ®å¤„ç†å’Œæ•°æ®å¯é æ€§ï¼ˆé’ˆå¯¹éå¸¸å¤§çš„æ•°æ®æ¹–è§„æ¨¡è¡¨æ ¼çš„æ›´æ–°æ›´åŠ é«˜æ•ˆï¼‰ã€‚
- en: Improved schema handling as it evolves over time.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæ”¹è¿›çš„æ¨¡å¼å¤„ç†ã€‚
- en: ETL pipelines are greatly simplified (By acting on data in place in the data
    lake rather than transporting data between numerous separate systems).
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ETL ç®¡é“å¤§å¤§ç®€åŒ–ï¼ˆé€šè¿‡å¯¹æ•°æ®æ¹–ä¸­çš„æ•°æ®è¿›è¡Œæ“ä½œï¼Œè€Œä¸æ˜¯åœ¨å¤šä¸ªç‹¬ç«‹ç³»ç»Ÿä¹‹é—´ä¼ è¾“æ•°æ®ï¼‰ã€‚
- en: 'Recommended read:'
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨èé˜…è¯»ï¼š
- en: 1\. [https://cloud.google.com/bigquery/docs/time-travel](https://cloud.google.com/bigquery/docs/time-travel)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. [https://cloud.google.com/bigquery/docs/time-travel](https://cloud.google.com/bigquery/docs/time-travel)
- en: 2\. [https://www.apache.org/](https://www.apache.org/)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. [https://www.apache.org/](https://www.apache.org/)
- en: 3\. [https://hive.apache.org/](https://hive.apache.org/)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. [https://hive.apache.org/](https://hive.apache.org/)
- en: 4\. [https://iceberg.apache.org/community/](https://iceberg.apache.org/community/)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. [https://iceberg.apache.org/community/](https://iceberg.apache.org/community/)
- en: 5\. [https://cloud.google.com/bigquery/docs/iceberg-tables](https://cloud.google.com/bigquery/docs/iceberg-tables)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. [https://cloud.google.com/bigquery/docs/iceberg-tables](https://cloud.google.com/bigquery/docs/iceberg-tables)
- en: 6\. [https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7](https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. [https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7](https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7)
- en: 7\. [https://medium.com/towards-data-science/big-data-file-formats-explained-275876dc1fc9](https://medium.com/towards-data-science/big-data-file-formats-explained-275876dc1fc9)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. [https://medium.com/towards-data-science/big-data-file-formats-explained-275876dc1fc9](https://medium.com/towards-data-science/big-data-file-formats-explained-275876dc1fc9)
- en: 8\. [https://iceberg.apache.org/docs/latest/evolution/](https://iceberg.apache.org/docs/latest/evolution/)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. [https://iceberg.apache.org/docs/latest/evolution/](https://iceberg.apache.org/docs/latest/evolution/)
- en: 9\. [https://iceberg.apache.org/docs/latest/partitioning/#icebergs-hidden-partitioning](https://iceberg.apache.org/docs/latest/partitioning/#icebergs-hidden-partitioning)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 9\. [https://iceberg.apache.org/docs/latest/partitioning/#icebergs-hidden-partitioning](https://iceberg.apache.org/docs/latest/partitioning/#icebergs-hidden-partitioning)
- en: 10\. [https://cloud.google.com/bigquery/docs/external-data-cloud-storage#sql](https://cloud.google.com/bigquery/docs/external-data-cloud-storage#sql)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 10\. [https://cloud.google.com/bigquery/docs/external-data-cloud-storage#sql](https://cloud.google.com/bigquery/docs/external-data-cloud-storage#sql)
