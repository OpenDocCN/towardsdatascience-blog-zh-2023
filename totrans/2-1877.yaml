- en: 'Sklearn Tutorial: Module 3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sklearn 教程：模块 3
- en: 原文：[https://towardsdatascience.com/sklearn-tutorial-module-3-08c9ae5cb8fa](https://towardsdatascience.com/sklearn-tutorial-module-3-08c9ae5cb8fa)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/sklearn-tutorial-module-3-08c9ae5cb8fa](https://towardsdatascience.com/sklearn-tutorial-module-3-08c9ae5cb8fa)
- en: I took the official sklearn MOOC tutorial. Here are my takeaways.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我参加了官方的 sklearn MOOC 教程。以下是我的收获。
- en: '[](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)[![Yoann
    Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----08c9ae5cb8fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----08c9ae5cb8fa--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)[![Yoann
    Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----08c9ae5cb8fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----08c9ae5cb8fa--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----08c9ae5cb8fa--------------------------------)
    ·9 min read·Dec 1, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----08c9ae5cb8fa--------------------------------)
    ·9 分钟阅读·2023年12月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'This is the third post in my scikit-learn tutorial series. If you didn’t catch
    it, I strongly recommend my first two posts — it’ll be way easier to follow along:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我 scikit-learn 教程系列中的第三篇文章。如果你错过了，我强烈推荐你阅读前两篇文章——这样会更容易跟上：
- en: '[](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----08c9ae5cb8fa--------------------------------)
    [## Sklearn Tutorial: Module 1'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----08c9ae5cb8fa--------------------------------)
    [## Sklearn 教程：模块 1'
- en: I took the official sklearn MOOC tutorial. Here are my takeaways.
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我参加了官方的 sklearn MOOC 教程。以下是我的收获。
- en: 'towardsdatascience.com](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----08c9ae5cb8fa--------------------------------)
    [](/sklearn-tutorial-module-2-0739c44f595a?source=post_page-----08c9ae5cb8fa--------------------------------)
    [## Sklearn tutorial: module 2'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----08c9ae5cb8fa--------------------------------)
    [](/sklearn-tutorial-module-2-0739c44f595a?source=post_page-----08c9ae5cb8fa--------------------------------)
    [## Sklearn 教程：模块 2
- en: I took the official sklearn MOOC tutorial. Here are my takeaways.
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我参加了官方的 sklearn MOOC 教程。以下是我的收获。
- en: towardsdatascience.com](/sklearn-tutorial-module-2-0739c44f595a?source=post_page-----08c9ae5cb8fa--------------------------------)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/sklearn-tutorial-module-2-0739c44f595a?source=post_page-----08c9ae5cb8fa--------------------------------)
- en: In this third module, we’ll see what hyperparameters are, and why and how we
    should optimize them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三模块中，我们将了解什么是超参数，以及我们为什么和如何优化它们。
- en: '![](../Images/78274fa0cd73bdb11c003e4596c49c6a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/78274fa0cd73bdb11c003e4596c49c6a.png)'
- en: Photo by [Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Glenn Carstens-Peters](https://unsplash.com/@glenncarstenspeters?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: What’s a hyperparameter
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是超参数
- en: When setting up our model so far, we only changed either the preprocessing,
    the kind of model, or both — but we haven’t really played with the model’s hyperparameters.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置模型时，我们只改变了预处理、模型类型或两者——但我们还没有真正调整模型的超参数。
- en: A model’s hyperparameters are parameters that are set by us, data scientists,
    when creating our model/pipeline. They are parameters that define the model before
    it sees any data. You could say that they allow us to define different “variants”
    of the same pipeline.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的超参数是我们数据科学家在创建模型/管道时设定的参数。它们是在模型看到任何数据之前定义模型的参数。可以说，它们允许我们定义相同管道的不同“变体”。
- en: Hyperparameters typically influence the model’s complexity, and as a consequence,
    the learning process and the overall model performance. Given a dataset and the
    problem you want to solve, your job as a data scientist is to find the best “hyper-parametrized
    model” among the infinite space of “hyperparametrized models.”
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数通常会影响模型的复杂性，从而影响学习过程和整体模型性能。给定数据集和你想解决的问题，作为数据科学家的你需要在“超参数化模型”的无限空间中找到最佳的“超参数化模型”。
- en: The hyperparameters are not to be confused with the internal parameters that
    are learned by the model during the learning process — those internal parameters
    that are learned are also called “coefficients.” For example, in polynomial regression,
    the hyperparameter (set before learning) is the degree of the regression, while
    the internal parameters learned using the train set are the polynomial coefficients
    (the a/b/c in aX² + bX + c). Put another way, you first set the degree (hyperparameter),
    and then the regression fit is done using the data (internal coefficients are
    learned) — not the other way around.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数不应与模型在学习过程中学到的内部参数混淆——这些内部参数也称为“系数”。例如，在多项式回归中，超参数（在学习之前设置）是回归的度数，而使用训练集学到的内部参数是多项式系数（a/b/c
    在 aX² + bX + c 中）。换句话说，你首先设置度数（超参数），然后使用数据进行回归拟合（内部系数被学习）——而不是反过来。
- en: 'As a consequence, model hyperparameters can be set when model/preprocessors
    are created. For example, in scikit-learn:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，模型超参数可以在模型/预处理器创建时设置。例如，在 scikit-learn 中：
- en: '`PolynomialFeatures(degree=degree)`: the polynomial degree created from each
    feature'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PolynomialFeatures(degree=degree)`：根据每个特征创建的多项式度数。'
- en: '`Ridge(alpha=5)`: regularization term of the linear ridge regression'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ridge(alpha=5)`：线性岭回归的正则化项。'
- en: '`SVC(C=1.0, kernel="rbf")`: regularization parameter and kernel for a support
    vector classifier. Depending on the kernel chosen, additionnal hyperparameters
    are available'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SVC(C=1.0, kernel="rbf")`：用于支持向量分类器的正则化参数和核函数。根据选择的核函数，还可以使用其他超参数。'
- en: '`KNeighborsClassifier(n_neighbhors=5)`: the number of neighbors considered
    in a K-nearest neighbors classifier'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`KNeighborsClassifier(n_neighbors=5)`：在 K 近邻分类器中考虑的邻居数量。'
- en: '`StandarScaler(with_mean=True, with_std=True)`: the standard scaler preprocessor
    can also be tuned with its hyperparameters, wheter to remove the mean and/or divide
    by the standard deviation'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StandardScaler(with_mean=True, with_std=True)`：标准化器预处理器也可以通过其超参数进行调节，比如是否去除均值和/或除以标准差。'
- en: 'Those examples show that the available hyperparameters depend on the whole
    pipeline you use for your model. For example the following pipeline has the hyperparameters
    of both the scaler and the regressor:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子表明，可用的超参数取决于你为模型使用的整个管道。例如，以下管道具有标准化器和回归器的超参数：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As we will see below, hyperparameters can also be read and set after a pipeline
    has been created. We will even see that individual steps can be considered as
    hyperparameters (for example, the “kind” of the scaler preprocessor, with possible
    values “StandardScaler”, “MinMaxScaler”, etc).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，超参数还可以在管道创建后进行读取和设置。我们甚至会看到个别步骤可以被视为超参数（例如，标准化器预处理器的“类型”，其可能的值有“StandardScaler”、“MinMaxScaler”等）。
- en: Note that for a given dataset, just like a certain kind of model could outperform
    another one — a hyperparameter could outperform another one. Put another way,
    for every dataset, there is an optimum hyperparameter set.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，对于给定的数据集，就像某种模型可能优于另一种模型一样——某个超参数也可能优于另一个。换句话说，对于每个数据集，都存在一个最佳的超参数集。
- en: 'So remember:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所以请记住：
- en: '**Hyperparameters correspond to parameters you set when creating the model,
    before the model is fed with a dataset.**'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数对应于在创建模型时设置的参数，在模型接收数据集之前。**'
- en: '**They correspond to every parameter you can set when creating a pipeline,
    given each step in the pipeline.**'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它们对应于你在创建管道时可以设置的每个参数，具体取决于管道中的每一步。**'
- en: '**The optimal hyperparameter set depends on the goal of the ML exercise and
    the input dataset.**'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最佳超参数集取决于 ML 任务的目标和输入数据集。**'
- en: '**Our job is to find the best hyperparameter.**'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**我们的工作是找到最佳的超参数。**'
- en: The rest of this post explains how to access and modify hyperparameters of models,
    and the different ways to search and optimize such hyperparameters.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本文其余部分解释了如何访问和修改模型的超参数，以及搜索和优化这些超参数的不同方法。
- en: 'How to get/set hyperparameters of a pipeline/model:'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何获取/设置管道/模型的超参数：
- en: 'In sklearn, once a model or pipeline has been created, an API is available
    to:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在 sklearn 中，一旦创建了模型或管道，就可以使用 API 来：
- en: list the hyperparameters available and their respective values
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出可用的超参数及其各自的值。
- en: change their value
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改其值。
- en: '**For a given model, you can get the list of all the hyperparameters and their
    values with the**`**.get_params()**` **method**:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于给定的模型，你可以使用**`**.get_params()**` **方法获取所有超参数及其值**：'
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Several important things are to be noticed:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 几个重要的事项需要注意：
- en: '`.get_params()` return a dict, including a `steps` entry that contains the
    list of the steps of the pipeline'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.get_params()` 返回一个字典，包括一个 `steps` 条目，该条目包含管道步骤的列表'
- en: the names used when creating the pipeline, `preprocecssor` and `lin_reg`in our
    case, are used and stored in this parameter dict
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建管道时使用的名称，`preprocecssor` 和 `lin_reg` 在我们的例子中，被用于和存储在这个参数字典中
- en: as such, each step’s hyperparameters are named using the conventions `<step_name>__<parameter_name>`,
    with a double underscore between the step’s name and the step’s parameter’s name
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，每个步骤的超参数都使用`<step_name>__<parameter_name>`的约定命名，步骤名称和步骤参数名称之间用双下划线分隔
- en: For the API interface to be consistent, note that *all* parameters are returned
    in this dict, including some hyperparameters that do not have an impact of the
    performance (like `lin_reg__n_jobs` and `preprocessor__copy`).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 API 接口一致，请注意*所有*参数都在这个字典中返回，包括一些对性能没有影响的超参数（如`lin_reg__n_jobs`和`preprocessor__copy`）。
- en: '**Similarly, we can change the value of any of those parameters using the following
    consistent API with** `**set_params(name=value)**`**:**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**类似地，我们可以使用以下一致的 API 来更改这些参数中的任何一个值** `**set_params(name=value)**`**:**'
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As mentioned before, we can even change a step completely using the same API:
    here we changed from a StandardScaler to a MinMaxScaler preprocessor. Notice the
    differences in parameters available after the change of preprocessor type (still
    called ‘preprocessor,’ but the corresponding hyperparameters are those of a MinMaxScaler).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们甚至可以使用相同的 API 完全更改一个步骤：这里我们将预处理器从 StandardScaler 更改为 MinMaxScaler。注意在更改预处理器类型后，参数的可用差异（仍称为‘preprocessor’，但相应的超参数是
    MinMaxScaler 的那些）。
- en: Manual hyperparameter tuning
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动超参数调优
- en: Now that we know what hyperparameters are, how to get/set them, and why we should
    optimize them, let’s take a first approach to do such optimization.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了什么是超参数，如何获取/设置它们，以及为什么我们应该优化它们，让我们首先采取一种方法来进行优化。
- en: 'As for any optimization problem, we identify:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何优化问题，我们识别：
- en: 'The “space” we want to explore: this is all the hyperparameter values we want
    to try.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要探索的“空间”：这就是我们想要尝试的所有超参数值。
- en: 'The value we want to optimize: here it corresponds to the model’s performance
    through its score.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要优化的值：这里对应于模型的性能得分。
- en: 'The simplest and most inefficient, non-robust way to do such optimization is
    using a loop on one hyperparameter and using the score of a single train/test
    split:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单且最无效、非鲁棒的优化方式是对一个超参数使用循环，并使用单次训练/测试划分的得分：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: So in this first approach, we manually write a loop, in which the pipe is fitted
    and tested. **A first improvement we can do is to use cross-validation in order
    to compute a more meaningfull score:**
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这种初步方法中，我们手动编写了一个循环，其中管道被拟合和测试。**我们可以做的第一个改进是使用交叉验证来计算一个更有意义的得分：**
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Using cross-validation, we have a more robust estimation of the model’s performance
    for each value of the hyperparameter.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用交叉验证，我们对每个超参数值都有一个更稳健的模型性能估计。
- en: 'Now let’s improve further with optimisation of 2 hyperparameters: we have to
    nest 2 loops, one for each hyperparameters:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过优化两个超参数进一步改进：我们需要嵌套两个循环，每个超参数一个：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, what if we want to optimize on 3, 4, 10, or more hyperparameters? And what
    if we want to try 10 different values for each of those hyperparameters? We’d
    have to write many, many nested loops and inspect many, many scores.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们想优化 3、4、10 或更多的超参数呢？如果我们想对每个超参数尝试 10 种不同的值呢？我们必须编写许多嵌套循环并检查许多得分。
- en: '**This is why scikit-learn provides helper functions to automate this hyperparameter
    searching process, like GridSearchCV and RandomSearchCV.**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**这就是为什么 scikit-learn 提供了自动化这个超参数搜索过程的辅助函数，如 GridSearchCV 和 RandomSearchCV。**'
- en: Automatic tuning using GridSearch
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GridSearch 进行自动调优
- en: 'The first automatic approach provided by sklearn to optimize hyperparameters
    is called `GridSearchCV`. **The idea is to use a dict to specify all values for
    each single hyperparameters, and all combinations will be tested**. For example,
    to reproduce the example above where `with_mean`could be `[True, False]` and `with_std`
    could be `[True, False]`we’d use:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn 提供的第一个自动化方法来优化超参数被称为`GridSearchCV`。**这个方法的核心思想是使用字典来指定每个超参数的所有值，并测试所有组合**。例如，为了重现上述示例，其中`with_mean`可以是`[True,
    False]`，`with_std`可以是`[True, False]`，我们会使用：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This first snippet only creates a `model` : yes, a new model, that wraps the
    true low-level pipeline. This new grid-seach model can be fitted, again using
    `model_grid_search.fit`. During this fitting step, all combinations of hyperparameters
    are tested and the model performance computed using cross-validation. Once the
    grid-search is fitted, it can be used as any other predictor (by calling predict
    or score for example), using the model with the best parameters found during fit:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第一个代码片段仅创建了一个`model`：是的，一个新的模型，它封装了真正的低级管道。这个新的网格搜索模型可以拟合，再次使用`model_grid_search.fit`。在这个拟合步骤中，所有超参数组合都会被测试，并使用交叉验证计算模型性能。一旦网格搜索拟合完成，它可以像其他预测器一样使用（例如调用predict或score），使用在拟合过程中找到的最佳参数的模型：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So in other words, fitting a GridSearch model means trying all combinations
    and keeping the best one.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，拟合一个GridSearch模型意味着尝试所有组合并保留最佳的一个。
- en: 'An important feature to remember is that we can use a list of dictionaries
    instead of just a dictionary to specify the combinations we want to try, in order
    to refine the hyperparameter sets that should be tested. For example:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的特点是，我们可以使用字典列表而不仅仅是单个字典来指定我们想尝试的组合，以便精细调整应测试的超参数集合。例如：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Stochastic tuning with RandomizedSearchCV
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用RandomizedSearchCV进行随机调优
- en: 'When the hyperparameters are continuous-valued and live on a great range of
    values, and/or the number of hyperparameters to tune is important, and/or the
    model is computationally complex, the full combination approach of GridSearchCV
    shows its limitations: the fitting time starts to increase. There is obviously
    a tradeoff between the number of hyperparameter sets to test versus the total
    time.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当超参数是连续值且范围很大，和/或需要调整的超参数数量很重要，和/或模型计算复杂时，GridSearchCV的全组合方法显现出它的局限性：拟合时间开始增加。显然，测试超参数集合的数量与总时间之间存在权衡。
- en: To circumvent these limitations and improve our chances to find a good — if
    not the best — hyperparameter set, we can use a random approach to sample the
    hyperparameters space.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了规避这些限制并提高找到一个好的——如果不是最好的——超参数集合的机会，我们可以使用随机方法来抽样超参数空间。
- en: The idea is to specify all the possible values for all the hyperparameters and
    try sets at random.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是指定所有超参数的所有可能值，并随机尝试集合。
- en: Using a random approach to optimize numerical problems is a common trick, like
    for numerical integration or optimization problems.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用随机方法来优化数值问题是一种常见的技巧，例如用于数值积分或优化问题。
- en: 'To do so in sklearn, we use `RandomizedSearchCV` — the usage is exactly the
    same as `GridSearchCV`. For example, say we want to optimize a support vector
    classifier by tuning its C parameter which can have any value from 0 to infinity,
    as well as some other hyperparameters like kernel and gamma:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在sklearn中实现这一点，我们使用`RandomizedSearchCV` —— 使用方法与`GridSearchCV`完全相同。例如，假设我们想通过调整其C参数（可以是从0到无穷大的任何值）以及其他超参数如kernel和gamma来优化支持向量分类器：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we allow the search to try 1000 hyperparameter sets, using `n_iter` to
    control the number of tries.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们允许搜索尝试1000个超参数集合，使用`n_iter`来控制尝试次数。
- en: '**So remember: the randomized approach allows trying hyperparameters randomly
    and controlling the number of tries using n_iter. This approach is useful when
    some hyperparameters are continuously-valued and/or may take a wide range of values.**'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**所以记住：随机化方法允许随机尝试超参数，并使用n_iter控制尝试次数。当一些超参数是连续值且/或可能取一个广泛的值范围时，这种方法是有用的。**'
- en: Nested cross-validation pattern
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌套交叉验证模式
- en: 'In order to train and find the best the best-hyperparameter model found using
    `GridSearchCV`/`RandomizedSearchCV`, we use the original train set from the first
    split. This first-split train set was used internally using another train/test
    split. In other words:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练和找到使用`GridSearchCV`/`RandomizedSearchCV`发现的最佳超参数模型，我们使用第一次拆分的原始训练集。这个第一次拆分的训练集在内部使用了另一个训练/测试拆分。换句话说：
- en: 'First split: the original dataset is split into X_train and X_test.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一次拆分：原始数据集被拆分成X_train和X_test。
- en: 'Then X_train is used to optimize the hyperparameters by training/testing each
    hyperparameter set using N internal splits (the number of folds): so X_train is
    split n-times into another X_train/X_test. The models are fitted/tested for each
    hyperparameter set, and the model performance is evaluated using cross-validation.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后X_train被用来通过训练/测试每个超参数集合，使用N个内部拆分（折数）来优化超参数：所以X_train被拆分n次成另一个X_train/X_test。模型对于每个超参数集合进行拟合/测试，并使用交叉验证评估模型性能。
- en: Finally, the best model found is tested and evaluated on the original X_test
    set.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，找到的最佳模型在原始 X_test 集上进行测试和评估。
- en: This means that this approach only provides us with a single evaluation of the
    generalization performance, since only the original X_test set is retained and
    never used in the learning steps (both fitting and optimizing). In order to improve
    our estimation of the generalization performance, we can use an outer cross-validation
    loop.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着这种方法仅为我们提供了对泛化性能的单次评估，因为仅保留了原始 X_test 集，且在学习步骤（拟合和优化）中从未使用。为了改善对泛化性能的估计，我们可以使用外部交叉验证循环。
- en: 'So remember: the outer loop is used to estimate the generalization performance
    of the overall fitting/optimizing process. In other words, the estimated best
    model’s performance is evaluated using cross-validation.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所以请记住：外部循环用于估计整体拟合/优化过程的泛化性能。换句话说，估计的最佳模型性能是通过交叉验证来评估的。
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This way, we get the best of both worlds, at the price of additional computation.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以在增加计算量的代价下获得两全其美的效果。
- en: Wrapup
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This third module was dedicated to hyperparameters:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个模块专注于超参数：
- en: Hyperparameters are parameters that define the way the model works and learns;
    they define its complexity. They should not be confused with the internal coefficients
    learned by the model when it is presented with the train set.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数是定义模型工作和学习方式的参数，它们定义了模型的复杂性。它们不应与模型在展示训练集时学习到的内部系数混淆。
- en: Since these hyperparameters greatly influence the model, they must be optimized
    to improve the model’s performance for the given task at stake. The best hyperparameters
    depend on the input data.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这些超参数对模型有很大影响，因此必须对其进行优化，以提高模型在给定任务上的表现。最佳超参数取决于输入数据。
- en: Optimizing hyperparameters can be done using cross-validated search methods
    like grid-search and random-search.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化超参数可以通过交叉验证搜索方法，如网格搜索和随机搜索来完成。
- en: A good practice when optimizing hyperparameters is to use the nested-cross-validation
    pattern to estimate the best-fitted model performance.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在优化超参数时，一个好的做法是使用嵌套交叉验证模式来估计最佳拟合模型的性能。
- en: 'You might like some of my other posts, make sure to check them out:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会喜欢我其他的一些帖子，确保查看一下：
- en: '![Yoann Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![Yoann Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
- en: Sklearn tutorial
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sklearn 教程
- en: '[View list](https://mocquin.medium.com/list/sklearn-tutorial-2e46a0e06b39?source=post_page-----08c9ae5cb8fa--------------------------------)9
    stories![](../Images/4ffe6868fb22c241a959bd5d5a9fd5d7.png)![](../Images/8aa32b00faa0ef7376e121ba9c9ffdb7.png)![](../Images/9f986423d7983bc08fc2073534603c35.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/sklearn-tutorial-2e46a0e06b39?source=post_page-----08c9ae5cb8fa--------------------------------)9
    个故事![](../Images/4ffe6868fb22c241a959bd5d5a9fd5d7.png)![](../Images/8aa32b00faa0ef7376e121ba9c9ffdb7.png)![](../Images/9f986423d7983bc08fc2073534603c35.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
- en: Scientific/numerical python
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 科学/数值 Python
- en: '[View list](https://mocquin.medium.com/list/scientificnumerical-python-9ce115122ab6?source=post_page-----08c9ae5cb8fa--------------------------------)3
    stories![Ironicaly, an array of containers](../Images/4ecd0326a3efdda93947f60872018d41.png)![](../Images/f11076a724463f7b11d819d95bcf0ea4.png)![](../Images/e340b22f444d2bd311537341cf1a105a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/scientificnumerical-python-9ce115122ab6?source=post_page-----08c9ae5cb8fa--------------------------------)3
    个故事![具有讽刺意味的容器数组](../Images/4ecd0326a3efdda93947f60872018d41.png)![](../Images/f11076a724463f7b11d819d95bcf0ea4.png)![](../Images/e340b22f444d2bd311537341cf1a105a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
- en: Data science and Machine Learning
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学与机器学习
- en: '[View list](https://mocquin.medium.com/list/data-science-and-machine-learning-ba3fb2206051?source=post_page-----08c9ae5cb8fa--------------------------------)3
    stories![](../Images/c078e74fd67e0141c2b54b82823c78d4.png)![](../Images/79988eda04a078da9373f03d7db51c51.png)![](../Images/6a5966e529bf4ba9b16c592fec7b591a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/data-science-and-machine-learning-ba3fb2206051?source=post_page-----08c9ae5cb8fa--------------------------------)3
    篇故事![](../Images/c078e74fd67e0141c2b54b82823c78d4.png)![](../Images/79988eda04a078da9373f03d7db51c51.png)![](../Images/6a5966e529bf4ba9b16c592fec7b591a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----08c9ae5cb8fa--------------------------------)'
- en: Fourier-transforms for time-series
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列的傅里叶变换
- en: '[View list](https://mocquin.medium.com/list/fouriertransforms-for-timeseries-ed423e3f38ad?source=post_page-----08c9ae5cb8fa--------------------------------)4
    stories![](../Images/86efd63d329650eb9b6d7c33625d6884.png)![](../Images/c693e4e596df5c1a8ef1b0fb3777d7ac.png)![](../Images/b6bc5330fb2d92bc3aad36f5bbc950da.png)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/fouriertransforms-for-timeseries-ed423e3f38ad?source=post_page-----08c9ae5cb8fa--------------------------------)4
    篇故事![](../Images/86efd63d329650eb9b6d7c33625d6884.png)![](../Images/c693e4e596df5c1a8ef1b0fb3777d7ac.png)![](../Images/b6bc5330fb2d92bc3aad36f5bbc950da.png)'
