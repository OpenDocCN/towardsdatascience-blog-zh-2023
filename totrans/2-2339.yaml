- en: What Is the Environmental Impact of AI?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/what-is-the-environmental-impact-of-ai-b8af55ec169e](https://towardsdatascience.com/what-is-the-environmental-impact-of-ai-b8af55ec169e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The new AI Index report points out the vast amount of energy that AI like ChatGPT
    require — though there is a positive side, too
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)[![Alan
    Jones](../Images/359379fab1d6685ff08080b98173e67c.png)](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)
    [Alan Jones](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)
    ·6 min read·Apr 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3fd74ad59f0fbf43893e40662d549918.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Jason Blackeye](https://unsplash.com/@jeisblack?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: A small but important part of the *AI Index Report* for 2023¹ points to the
    growing concern about the energy consumption required for AI training.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'Spoiler alert: it’s quite a lot.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: There’s no standard benchmark for tracking the carbon intensity of AI systems,
    so the report focuses on research from a recent paper by Luccioni et al., 2022²
    which records the energy requirements of a number of large language models (LLMs)
    including ChatGPT.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The following table shows the energy requirements for training four different
    AI models and the CO2 emissions associated with it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8694704f08c5994ddc13dae2bd9f812e.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: 'Image by author, data source: Luccioni, et al., 2022²'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: The data contains a number of measurements but the bottom line is represented
    by the power consumption and CO2 emissions which I have summarised in the charts
    below.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/462033742b2de182498726e0415e1615.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: 'Power Consumption of four AI models — Image by author, data source: Luccioni,
    et al., 2022²'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: There is quite a difference between the various models and, as you can see,
    OpenAI’s GPT-3 comes top with a consumption of over 1200 Megawatt-hours. That’s
    about as much electricity as 120 US homes would consume in a year according to
    consumption figures by the U.S. Energy Information Administration³. That certainly
    seems like a lot of energy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: The chart below illustrates the CO2 emissions which follow a similar pattern.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f877739a29b5ad3ce3c83282fe18e38.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: 'CO2 emissions of four AI models — Image by author, data source: Luccioni, et
    al., 2022²'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Luccioni, the paper’s principal author, is a researcher at Hugging Face Inc.
    and the work is mostly concerned with BLOOM, her company’s alternative to ChatGPT.
    The figures for other models are approximate and based on what public information
    is available ([Bloomberg](https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure)
    reports Lucciana saying that nothing is really known about ChatGPT and that it
    could just be “…three raccoons in a trench coat.” — does that mean GPT-4 will
    be four raccoons?).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: CO2 emissions for training ChatGPT are equivalent to around 500 flights from
    New York to San Francisco
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The AI Index Report makes some comparisons with other energy-intensive activities
    and their CO2 emissions (see chart, below). It finds for example, that the CO2
    emissions generated in training ChatGPT are equivalent to one passenger taking
    a flight from New York to San Francisco around 500 times! Or the total energy
    consumption of a single American over 28 years!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/82e15c6e88f807258e92e6723ae160f3.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: 'Energy consumption comparisons: AI models and real-life examples. Image by
    author, data source AI Index Report¹'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Unsurprisingly, the single air passenger does not produce zero emissions as
    it may appear from the chart above (the figure is nearly 1 tonne). You can see
    the actual numbers more clearly in this table:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8fa9dc44568b79f98ca3d4b8b424199.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: 'Energy consumption comparisons: AI models and real-life examples. Image by
    author, data source AI Index Report¹'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: But it’s not all bad news.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: AI can also reduce energy consumption
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: According to [Bloomberg](https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure),
    while AI models are getting larger (and presumably more energy intensive), the
    companies creating them are working on improving efficiency. Microsoft, Google
    and Amazon — the cloud companies that host much of the work — all are aiming for
    carbon-negative or carbon-neutral operations. This is, of course, highly desirable.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Also, while training AI systems is energy-intensive, recent research shows that
    AI systems can also be used to optimize energy consumption. A paper from DeepMind⁴
    released in 2022 details the results of a 2021 experiment in which it trained
    an AI called BCOOLER to optimize cooling in Google’s data centres.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2de2a1c96e21552eeef79cddf568820e.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: Energy saving by BCOOLER. Image by author, data source AI Index¹
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: The graph above shows the energy-saving results from one BCOOLER experiment.
    After three months, a, roughly, 12.7% energy saving was achieved.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Even if carbon neutrality is achieved, the use of AI to increase the efficiency
    of these centres will also make them cheaper to run. Maybe we should be thinking
    about applying AI to other energy-intensive industries, too.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: I doubt that we are currently in a position to know exactly what the eventual
    toll on the environment will be. LLMs like ChatGPT are not going away and so the
    energy that needs to be spent in training them is definitely going to be spent.
    On the other hand, it’s not the case that people are going to stop flying NY to
    SF, heating their homes or using their cars.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: But we should try and put some of this somewhat shocking data into perspective.
    While a ChatGPT training session might use as much energy as one American does
    in 28 years (which sounds an awful lot), it is also true that 330 million Americans,
    the population of the USA, emit around **10 million times more CO2** than a single
    ChatGPT session⁵.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: And there appear to be around 20 flights a day from New York to San Francisco,
    and say that each flight serves 150 passengers; that works out to be over 1 million
    tonnes of CO2 emissions per year — **more than 2000 ChatGPTs⁵**.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: For single entities, ChatGPT, and its like, clearly use a lot of energy (and
    thus — at the moment, at least — produce a lot of CO2 emissions) but compared
    to energy consumption and CO2 emissions from other human activity, are they really
    very significant (there are, after all, a lot more humans than LLMs)?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Also, it’s got to be good news that the large cloud hosting companies are aiming
    to achieve carbon neutrality which, if achieved, will reduce CO2 emissions to
    zero. So while energy use might remain high, the aim is to make its environmental
    impact neutral.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, AI can be used to mitigate some of the energy use in data centres.
    Maybe similar technology could be used in airlines and other energy-intensive
    industries.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line, however, is that we are all producing more CO2 than we should,
    so any additional energy use, that is not produced from renewables, is moving
    in the wrong direction.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading, I hope you found this useful. If you would like to see more
    of my work, please visit my [website](http://alanjones2.github.io).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: You can also get updates by subscribing to my occasional, free, [newsletter
    on Substack](https://technofile.substack.com).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: If you are not a Medium member you can sign up using my [referral link](https://medium.com/@alan-jones/membership)
    and get to read any Medium content for only $5 per month.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The AI Index 2023 Annual Report
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Nestor Maslej, Loredana Fattorini, Erik Brynjolfsson, John Etchemendy, Katrina
    Ligett, Terah Lyons, James Manyika, Helen Ngo, Juan Carlos Niebles, Vanessa Parli,
    Yoav Shoham, Russell Wald, Jack Clark, and Raymond Perrault, “*The AI Index 2023
    Annual Report,*” AI Index Steering Committee, Institute for Human-Centered AI,
    Stanford University, Stanford, CA, April 2023.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: The *AI Index 2023 Annual Report* by Stanford University is licensed under [Attribution-NoDerivatives
    4.0 International](https://creativecommons.org/licenses/by-nd/4.0/?ref=chooser-v1).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: You can find the complete report on the [AI Index](https://aiindex.stanford.edu/)
    page at Stanford University.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在斯坦福大学的[AI Index](https://aiindex.stanford.edu/)页面找到完整报告。
- en: 2\. [*Estimating the carbon footprint of BLOOM, a 176B parameter language model*](https://arxiv.org/pdf/2211.02001.pdf),
    Luccioni et al., 2022.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. [*估算BLOOM的碳足迹，一个176B参数的语言模型*](https://arxiv.org/pdf/2211.02001.pdf)，Luccioni等人，2022。
- en: 3\. The [U.S. Energy Information Administration](https://www.eia.gov/tools/faqs/faq.php?id=97&t=3#:~:text=In%202021,%20the%20average%20annual,about%20886%20kWh%20per%20month.)
    estimates that in 2021, the average annual electricity consumption of a U.S. residential
    utility customer was 10,632 kilowatt hours (kWh).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. [美国能源信息管理局](https://www.eia.gov/tools/faqs/faq.php?id=97&t=3#:~:text=In%202021,%20the%20average%20annual,about%20886%20kWh%20per%20month.)
    估计2021年，美国住宅电力用户的年平均电力消耗为10,632千瓦时（kWh）。
- en: 4\. [Controlling Commercial Cooling Systems Using Reinforcement Learning](https://www.deepmind.com/publications/controlling-commercial-cooling-systems-using-reinforcement-learning),
    DeepMind, 2022
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. [使用强化学习控制商业冷却系统](https://www.deepmind.com/publications/controlling-commercial-cooling-systems-using-reinforcement-learning)，DeepMind，2022
- en: '5\. CO2 emissions from other sources (these are rough calculations):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 来自其他来源的CO2排放（这些是粗略计算）：
- en: 330 million Americans emit 18 tonnes of CO2 each year, that’s 330m x 18, 5900m
    tonnes of CO2–10 million ChatGPTs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 3.3亿美国人每年排放18吨CO2，即3.3亿 x 18，5900万吨CO2——1000万个ChatGPT。
- en: Approx. 20 flights (each day), NY to SF, with around 150 passengers on board
    produce 20 x 150, or 3000 tonnes of CO2\. That’s 3000 x 365, about 1 million tonnes
    of CO2 per year — 2000 ChatGPTs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 约20个航班（每天），从纽约到旧金山，每个航班大约有150名乘客，产生20 x 150，即3000吨的CO2。这相当于3000 x 365，大约每年1百万吨的CO2——2000个ChatGPT。
