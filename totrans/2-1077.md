# 如何基于 AWS 构建级联数据管道（第 1 部分）

> 原文：[https://towardsdatascience.com/how-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2](https://towardsdatascience.com/how-i-built-a-cascading-data-pipeline-based-on-aws-997b212a84d2)

## 自动化、可扩展且强大

[](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)[![Memphis Meng](../Images/5a2b214eb5d5ab884b18224c471662c0.png)](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------) [Memphis Meng](https://anzhemeng.medium.com/?source=post_page-----997b212a84d2--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----997b212a84d2--------------------------------) ·14 分钟阅读·2023年7月31日

--

今天我要分享一些我引以为豪的数据工程项目的经验。你将了解到我为何使用这些工具和 AWS 组件，以及我如何设计架构。

![](../Images/4f95b8b2918bb62a2337706df55ff6e3.png)

作者提供的图片

**免责声明**：本文本内容受到我与一个未命名实体的经验启发。然而，某些关键商业利益和细节已故意用虚构数据/代码替代或省略，以保持机密性和隐私。因此，实际涉及的商业利益的完整和准确程度保留。

# 前提条件

1.  对 Python 的了解

1.  对 AWS 组件的了解，如 DynamoDB、Lambda 无服务器、SQS 和 CloudWatch

1.  对 [YAML](https://en.wikipedia.org/wiki/YAML) 和 [SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html) 的舒适编码体验

# 背景

假设你是一个数据工程师，需要不断更新数据仓库中的数据。例如，你需要定期与 [Dunder Mifflin Paper Co.](https://dundermifflinpaper.com) 的销售记录同步。（我知道这不是一个现实的场景，但请尽情享受 :)！）数据通过供应商的 API 发送给你，你需要确保分支、员工（实际上只考虑销售人员）和销售的信息是最新的。提供的 API 有以下 3 个路径：

1.  `/branches` ，接受分支名称作为查询参数以检索指定分支的元数据；

1.  `/employees` ，接受分支 ID 作为查询参数以检索某个分支所有员工的信息，响应中包括一个表示员工职业的键值对；

1.  `/sales`，接受员工ID作为查询参数来检索销售人员的所有销售记录，响应包括一个指示交易完成时间的键值对。

总的来说，API的返回结果如下：

`/branches` 路径：

[PRE0]

`/employees` 路径：

[PRE1]

`/sales` 路径：

[PRE2]

期望你的最终工作将使数据分析师能够仅通过SQL查询来检索他们分析所需的数据。

# 思路

最终，我们将有3个不同的地方分别存储分支、销售人员和销售的数据，这一点说起来很简单。数据将通过访问特定的API路径来导入。然而，由于所有这些实体的标识符大多是自动生成的，实践者不大可能提前获得这些ID。相反，由于我们通常可以找到分支名称，因此可以使用第一个路径来获取分支的元数据及其员工的ID。然后，我们可以使用员工ID访问`/employees`路径，`/sales`路径也是如此。***这就是我称这个流程为级联的原因。***

为了确保我们的数据库大部分时间是最新的，必须足够频繁地执行这些操作。但另一方面，我们也需要考虑成本和潜在的API访问配额。因此，每小时运行一次是适当的，尽管可以说尚未达到最佳。

最后但同样重要的是，让我们讨论AWS。首先，执行这些操作的代码将由[**AWS Lambda**](https://aws.amazon.com/lambda/)运行，因为它能够使用200多个AWS服务和应用程序作为触发器，包括[SQS](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-sqs.html)和[EventBridge](https://docs.aws.amazon.com/eventbridge/index.html)。数据将通过**SQS**传递，作为AWS提供的最成熟的消息服务之一。最后，从API抓取的信息将存储在**DynamoDB**中。对于一些有经验的读者来说，利用**DynamoDB**作为数据仓库工具可能会令人困惑，因为这是一个NoSQL数据库服务，而数据仓库通常与NoSQL数据库不兼容。我确实意识到这一点，DynamoDB表在这里将仅作为临时存储表，因为我可以利用其在键值/文档数据模型模式中的灵活性，然后最终将JSON格式的API检索数据转换为数据仓库记录。如果你对我实现DynamoDB-S3加载的细节感兴趣，可以查看[**这篇文章**](https://medium.com/plumbersofdatascience/a-real-time-streaming-channel-c8bbae187c83)。

# 实现

这是我最终工作的结构。

[PRE3]

有3个文件夹（*/branches*，*/salespersons*，*/sales*），分别包含每个lambda函数的代码。*Utils.py* 是一个多功能文件，其中的函数、变量和类被全局应用。模板.yml 是我们将用来声明和部署AWS资源以建立数据管道的AWS CloudFormation模板。

每个文件夹中的`Lambda_function.py`是代码执行的入口函数：

[PRE4]

/Service/config.py 返回*template.yml*中输入的环境变量：

[PRE5]

`/Service/service.py` 是我们实际处理数据的地方。基本上，该功能由一个或两个触发器（时间调度器）调用，在从数据源（API或SQS队列）中检索数据之前。数据将以键值对的形式打包，如有需要，更新到相应的DynamoDB表中，然后该功能分发其成员的标识符（即，分支中的所有员工，销售人员的所有销售记录）。

以 `/branches/service/service.py` 为例。它的功能包括：

1.  一旦被唤醒，立即从API `/branches` 获取所有数据；

1.  检查DynamoDB数据表中每个销售人员的个人信息是否存在和准确，如果不更新，则插入数据记录；

1.  获取所有员工的ID，并将其连同分支ID作为消息通过SQS队列传递给尾部函数（*/salespersons*）。

实际操作中，实施方式如下：

[PRE6]

最后，我们需要为构建和部署做准备：

[PRE7]

# 问答

是的，我正在进行自问自答的环节。在编码时，挑战自己“为什么？”或“怎么做？”通常是有帮助的，这样我会对自己所做的每个决定有更多信心，也能证明我使用的每个工具。

## a. 我如何监控这些功能？

我使用[CloudWatch警报](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html)。CloudWatch警报监视任何可用的指标或AWS CloudWatch支持的指标计算。它们可以根据给定阈值在指定时间内对指标或计算进行自定义操作。

对我来说，最关键的是在发生错误时立即学习和解决。因此，我为所有3个功能设置了以1个错误为阈值的警报，也就是说，只要出现错误就会触发警报。我希望在不不断盯着CloudWatch仪表板的情况下识别错误，因此警报的操作是将通知推送到SNS主题，该主题将警报转发到我的电子邮件收件箱。

如果你在一个协作环境中工作，我建议你通过将其发送到Slack频道，分发到分发列表中的所有地址，或将其包含在共享邮箱中，以扩展可见性。

## b. 你为什么按现在的方式定义表的键？

这是基于现实情况的。显然，分支之间有所不同，因此它们的 ID 足以作为分支表中的唯一**哈希键**，符合[1NF 约束](https://en.wikipedia.org/wiki/Database_normalization)。相比之下，销售人员和销售表则需要额外的键进行规范化。

因为在现实中，一个分支可能在记录中有多个员工，而员工允许从一个分支转移到另一个分支，从数据模式的角度来看，分支与员工之间的关系是多对多的。而且正因为如此，只有销售记录 ID + 销售人员 ID + 分支 ID（交易发生时的分支）组合才能指向销售表中的一个确切记录。瓶颈在于像 DynamoDB 这样的文档数据库允许最多两个属性作为键，我选择了销售人员 ID 作为**排序键**，而不是分支 ID，以确保销售记录与销售人员之间的关系。销售和分支之间的差异将在接下来的问题中解释。

## c. 我如何建立销售和分支之间的联系？为什么？

数据供应商在销售记录中未能包含分支信息。处理这个问题的万灵药是从最上层（分支收集器函数）到最底层附加分支 ID。然而，这种方式忽略了一些极端情况。例如，[吉姆·哈尔普特](https://en.wikipedia.org/wiki/Jim_Halpert) 在他在斯克兰顿分支的最后一天进行了销售。由于一些技术问题，这条记录没有被添加到他的销售记录列表中，也没有发布到 API 上，直到第二个工作日他被预设为转移到斯坦福德的员工。

没有上下文很难发现标签错误，尤其是当根本原因来自供应商时。从我的经验来看，此阶段的调试非常依赖于我们的反馈。这就是为什么我让销售表中的分支 ID 成为一个宽松的键值对；否则，需要额外的工作来删除和重写该项。

## d. 我如何触发销售人员和销售收集器函数？

SQS 队列是 Lambda 函数官方允许的触发操作之一，因此这是唤醒这两个函数的自然选择，因为它们已经设置为监听队列。我绕了一下路，绕过了 API 所有者施加的最大访问限制。如果我让我的函数在消息到达时立即从队列中获取并访问 API，将会有多个函数几乎同时处理消息，这使得管道架构失效，因为它可能很容易超过 API 配额。通过设置每分钟的时间调度器（我为每个函数创建了两个调度器），处理频率从毫秒级下降到秒级。通过这种方式，数据管道中的消息流量得到了缓解。

## e. 如何避免重复操作？

几乎不可能在不实际访问API（真相来源）的情况下判断收集的数据是否是最新的。因此，我们不能减少API访问次数，而是可以像我在上一个问题中所做的那样降低超出API访问配额的风险。

如果数据流的目标是DynamoDB，每次从API接收时都会完全更新每条记录。令人担忧的是，我们从DynamoDB到S3的火hose 流带宽不足，导致运输偶尔中断。鉴于这一情况，我在更新之前插入了一个合理性检查。此检查将记录的每个属性值与最近从API提取的值进行比较。除非记录完全没有变化，否则现有记录将被覆盖。

附件是合理性检查函数：

[PRE8]

# 部署

在每个文件夹中，执行

[PRE9]

然后返回到上一级文件夹：

[PRE10]

# 最终工作

[我的 GitHub 仓库](https://github.com/MemphisMeng/Cascading-ETL-pipeline/tree/dev)

# 版权信息

+   [作为代码的图表](https://diagrams.mingrammer.com/)提供了所有支持简洁可视化的工具

+   [《办公室》（The Office](https://www.imdb.com/title/tt0386676/)是一个精彩的节目，带来的欢笑和灵感。
