- en: 'Web Speech API: What Works, What Doesn’t, and How to Improve It by Linking
    It to a GPT Language Model'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Web Speech API：什么有效，什么无效，以及如何通过将其与GPT语言模型连接来改进它
- en: 原文：[https://towardsdatascience.com/web-speech-api-what-works-what-doesnt-and-how-to-improve-it-by-linking-it-to-a-gpt-language-dc1afde54ced](https://towardsdatascience.com/web-speech-api-what-works-what-doesnt-and-how-to-improve-it-by-linking-it-to-a-gpt-language-dc1afde54ced)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/web-speech-api-what-works-what-doesnt-and-how-to-improve-it-by-linking-it-to-a-gpt-language-dc1afde54ced](https://towardsdatascience.com/web-speech-api-what-works-what-doesnt-and-how-to-improve-it-by-linking-it-to-a-gpt-language-dc1afde54ced)
- en: Part of a series on how modern AI and other technologies could assist more efficient
    human-computer interactions
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系列文章的一部分，探讨现代人工智能和其他技术如何帮助更高效的人机交互
- en: '[](https://lucianosphere.medium.com/?source=post_page-----dc1afde54ced--------------------------------)[![LucianoSphere
    (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page-----dc1afde54ced--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc1afde54ced--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc1afde54ced--------------------------------)
    [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page-----dc1afde54ced--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lucianosphere.medium.com/?source=post_page-----dc1afde54ced--------------------------------)[![LucianoSphere
    (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page-----dc1afde54ced--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc1afde54ced--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc1afde54ced--------------------------------)
    [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page-----dc1afde54ced--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc1afde54ced--------------------------------)
    ·15 min read·Dec 6, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc1afde54ced--------------------------------)
    ·阅读时间15分钟·2023年12月6日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a173108cd0621793832a4adc1033b257.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a173108cd0621793832a4adc1033b257.png)'
- en: Photo by [palesa](https://unsplash.com/@palesa08?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[palesa](https://unsplash.com/@palesa08?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: I am of the idea that modern technologies enable today much simpler and natural
    human-computer interactions than what current software actually proposes. Indeed,
    I think technologies are ripe enough that we could just go without traditional
    interfaces and move forward with a revolution in user experience.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为现代技术使得人机交互变得比目前的软件所提供的要简单和自然得多。实际上，我认为技术已经足够成熟，我们可以不依赖传统接口，向用户体验的革命迈进。
- en: Large language models have certainly triggered one stage of this revolution,
    particularly in how we ask for information. However, I think technologies can
    still provide much more. For example, we are still largely stuck with flat screens
    despite the decreasing costs of VR headsets; we are still using mouse, keyboard,
    and touch gestures to operate devices despite the level of advancement of technologies
    like eye-gazing, speech-recognition and body limb tracking; we are still reading
    out a lot despite great advances in speech synthesis.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型无疑引发了这场革命的一个阶段，特别是在我们询问信息的方式上。然而，我认为技术仍然可以提供更多。例如，尽管虚拟现实头显的成本在降低，我们仍然主要使用平面屏幕；尽管眼动追踪、语音识别和身体部位追踪等技术已达到较高水平，我们仍然使用鼠标、键盘和触控手势来操作设备；尽管语音合成技术取得了重大进展，我们仍然在大量阅读。
- en: I feel current technologies are ripe enough to offer human-computer interactions
    almost like those in Star Trek (if you don’t know what I mean, [check this](https://www.youtube.com/watch?v=Drr6_zikuZQ)),
    yet we want to be stuck in the past.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我认为，当前的技术已经足够成熟，能够提供几乎像《星际迷航》中那样的人机交互（如果你不明白我的意思，[请查看这个](https://www.youtube.com/watch?v=Drr6_zikuZQ)），然而我们却仍然想停留在过去。
- en: With this article I’m starting a short series dedicated to how human-computer
    interactions could change forever thanks to modern technologies that **already
    work very well**, as you will be able to test yourself with the pieces of code
    and example apps I will share.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我开始了一系列短文，专注于现代技术如何使人机交互发生根本性改变，这些技术**已经非常成熟**，你将通过我分享的代码片段和示例应用来亲自测试。
- en: Faithful to my style, I will talk specifically about web-based implementations
    of all these modern technologies. And I start here with the Web Speech API integrated
    into web browsers, discussing its power, showing some use cases, highlighting
    limitations and exemplifying how some of these limitations can be overcome by
    coupling it to large language models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 忠于我的风格，我将特别讨论这些现代技术的基于网页的实现。我将从集成到网页浏览器中的 Web Speech API 开始，讨论其功能，展示一些用例，强调其局限性，并举例说明如何通过将其与大型语言模型结合来克服这些局限性。
- en: 'This series is based on a recent project on which I worked to build a first-of-type
    web app for immersive, multiuser molecular graphics and modeling, HandMol:'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本系列基于我最近参与的一个项目，旨在构建一种首创的网络应用程序，提供沉浸式、多用户的分子图形和建模功能，名为 HandMol：
- en: '[](https://pub.towardsai.net/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443?source=post_page-----dc1afde54ced--------------------------------)
    [## Coupling Four AI Models to Deliver the Ultimate Experience in Immersive Visualization
    and Modeling'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pub.towardsai.net/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443?source=post_page-----dc1afde54ced--------------------------------)
    [## 结合四种 AI 模型以提供终极沉浸式可视化和建模体验'
- en: Read on about how this new free app called HandMol achieves immersive, collaborative
    visualization and modeling of…
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 继续阅读关于这款名为 HandMol 的新免费应用程序如何实现沉浸式、协作式的可视化和建模…
- en: pub.towardsai.net](https://pub.towardsai.net/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443?source=post_page-----dc1afde54ced--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: pub.towardsai.net](https://pub.towardsai.net/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443?source=post_page-----dc1afde54ced--------------------------------)
- en: (Modern) Speech Recognition and Speech Synthesis
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: （现代）语音识别和语音合成
- en: Two technologies in particular that have been around for almost two decades
    and have a lot to offer in powering more natural human-computer interactions,
    are speech recognition and speech synthesis.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是语音识别和语音合成这两项技术，已经存在近二十年，并在推动更自然的人机互动方面提供了很多可能性。
- en: 'Speech recognition, or ASR after Automatic Speech Recognition or STT after
    Speech-To-Text, converts spoken language into written text. It has two main broad
    applications:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别，或称 ASR（自动语音识别）或 STT（语音转文本），将口语语言转换为书面文本。它有两个主要的广泛应用：
- en: Command a piece of hardware such as a smartphone or computer through spoken
    instructions, best if in a natural way. Think of how you use your smartphone,
    or Alexa or Siri via voice commands.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过口头指令控制如智能手机或计算机等硬件，最好以自然的方式进行。想象一下你如何通过语音命令使用智能手机、Alexa 或 Siri。
- en: Transcribing (and perhaps then displaying, storing or analyzing) what is being
    said in a conversation. Think about meeting transcription, video captioning, etc.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转录（或许随后显示、存储或分析）对话中所说的内容。考虑一下会议转录、视频字幕等。
- en: Both applications relate directly to the topic of this blog post, and are materialized
    for web programmers through the Web Speech API.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个应用程序直接相关于本博客文章的主题，并通过 Web Speech API 实现了对网页程序员的支持。
- en: Speech synthesis, or TTS after Text-To-Speech, converts written text into spoken
    language. It allows computers and other devices to generate human-like speech,
    making information accessible audibly just as you see here on Medium articles.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 语音合成，或称 TTS（文本转语音），将书面文本转换为口语语言。它使计算机和其他设备能够生成类似人类的语音，使信息能够以听觉方式访问，就像你在 Medium
    文章中看到的那样。
- en: Speech Synthesis finds application in a variety of scenarios, including accessibility
    features for visually impaired users, interactive voice response systems, and
    multimedia content enrichment.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 语音合成在各种场景中都有应用，包括为视力障碍用户提供的辅助功能、交互式语音响应系统以及多媒体内容的丰富化。
- en: Together, STT and TTS enable a more inclusive and versatile interaction with
    digital content, opening up opportunities for hands-free and screen-free operation
    and personalized user experiences.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 语音转录（STT）和语音合成（TTS）使与数字内容的互动更加包容和多样化，开辟了免提和免屏操作以及个性化用户体验的机会。
- en: Brief history of ASR and TTS technologies
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语音识别和语音合成技术的简要历史
- en: 'Speech recognition and synthesis have evolved significantly over the years,
    especially with the integration of modern AI models and advancements in machine
    learning techniques. They date back to the mid-20th century when early attempts
    were made to use computers for language processing. Initial models faced challenges
    with accents, dialects, homophones, and speech nuances, both in producing and
    understanding speech. Advancements in statistical models and symbolic natural
    language processing gradually improved ASR systems, but a breakthrough occurred
    in the late 2010s with the introduction of transformers, especially for ASR: by
    leveraging on attention mechanisms, new methods for speech recognition could capture
    long-range dependencies and contextual understanding, thus dramatically improving
    the accuracy of speech-to-text conversion.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别和合成在近年来取得了显著进展，特别是随着现代 AI 模型的整合和机器学习技术的进步。它们可以追溯到20世纪中期，当时首次尝试使用计算机进行语言处理。早期模型在处理口音、方言、同音词和语音细微差别时面临挑战，无论是在语音生成还是理解方面。统计模型和符号自然语言处理的进步逐步改善了
    ASR 系统，但在2010年代末期，随着变换器的引入，尤其是对 ASR 的突破性进展：通过利用注意机制，新的语音识别方法能够捕捉长期依赖关系和上下文理解，从而显著提高了语音转文本转换的准确性。
- en: STT is somewhat more complex than TTS, due to a larger number of variables to
    account for. The most modern methods, however, work remarkably well. Without going
    into details as this would be out of scope, modern STT involves a complex process
    with multiple stages and AI models working together. Key stages include pre-processing
    of audio input, feature extraction, phoneme extraction, language model decision-making,
    and decoding into a sequence of words. Modern ASR models often use transformers
    in all stages, preserving long-range couplings in information for better accuracy
    and coherence. The most advanced ASR systems include language model elements built
    right into their core modules; such native integration has proven essential for
    high transcription and recognition accuracy.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: STT 比 TTS 更复杂一些，因为需要考虑更多的变量。然而，最现代的方法表现非常出色。虽然不深入细节，但现代 STT 涉及一个复杂的过程，多个阶段和
    AI 模型协同工作。关键阶段包括音频输入的预处理、特征提取、音素提取、语言模型决策和解码成单词序列。现代 ASR 模型通常在所有阶段使用变换器，保留信息中的长期耦合，以提高准确性和连贯性。最先进的
    ASR 系统包括直接内置在核心模块中的语言模型元素；这种原生集成被证明对高转录和识别准确性至关重要。
- en: Modern ASR and TTS technologies can certainly do much more than mere speech
    recognition or synthesis, actually approaching a kin of “understanding of spoken
    language”. See, the most advanced STT and TTS models can transcribe audio to text
    or synthesize audio from text in multiple languages, some even being able of identifying
    languages automatically, adapting to context, detecting or simulating different
    speakers, annotating transcribed words with timestamps, dealing with punctuation
    and with non-verbal vocalization, allowing for customizable dictionaries of words,
    etc.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现代 ASR 和 TTS 技术确实能做得远远不止单纯的语音识别或合成，实际上接近于“对口语的理解”。比如，最先进的 STT 和 TTS 模型可以将音频转录为文本或从文本合成音频，支持多种语言，有些甚至能够自动识别语言，适应上下文，检测或模拟不同的说话者，用时间戳注释转录词汇，处理标点符号和非语言发声，允许自定义词典等。
- en: If you are getting excited about all these features and the possibility of exploiting
    them in your web app from the Web Speech API, there are quite a few limitations
    that you need to learn about, that will kind of disappoint you because what the
    browsers support is not state-of-the-art. Fortunately, though, coupling the Web
    Speech API with large language models can alleviate some of these problems, as
    many modern ASR and TTS technologies do and as I will show you here by using GPT-3.5-turbo
    or GPT-4 programmatically. And if that’s not enough, you will learn that there
    are companies offering their own (paid) APIs to perform ASR and TTS at the state
    of the art.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对 Web Speech API 中所有这些功能以及在你的 Web 应用中利用它们感到兴奋，你需要了解一些限制，这可能会让你失望，因为浏览器支持的功能还不是最先进的。然而，幸运的是，将
    Web Speech API 与大型语言模型结合使用可以缓解这些问题，就像许多现代 ASR 和 TTS 技术一样，我将在这里通过编程使用 GPT-3.5-turbo
    或 GPT-4 来展示这一点。如果这还不够，你还会发现有些公司提供他们自己的（付费）API 来进行最先进的 ASR 和 TTS。
- en: The Web Speech API, Its Parts, and its Availability
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Web Speech API、其组件及其可用性
- en: 'The Web Speech API is a web standard that enables web applications to incorporate
    voice data into their functionality. It has two parts: SpeechRecognition, which
    allows speech input and recognition, and SpeechSynthesis, which allows speech
    output and synthesis.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Web Speech API 是一个网络标准，允许 web 应用将语音数据融入其功能中。它有两个部分：SpeechRecognition，允许语音输入和识别，以及
    SpeechSynthesis，允许语音输出和合成。
- en: 'The Web Speech API was first proposed by Google in 2010, and was implemented
    in Chrome 25 in 2013\. Since then, it has been supported by other browsers, with
    varying degrees of compatibility and functionality. And support as of December
    2023 is very heterogeneous, as caniuse.com reports, especially for speech recognition:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Web Speech API 最早由 Google 在 2010 年提出，并在 2013 年的 Chrome 25 中实现。从那时起，它得到了其他浏览器的支持，但兼容性和功能性各不相同。根据
    caniuse.com 的报告，截至 2023 年 12 月，支持情况非常不均衡，尤其是在语音识别方面：
- en: '![](../Images/81b20b63c28b44cc97984a8bfb6555d1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81b20b63c28b44cc97984a8bfb6555d1.png)'
- en: Screenshot from [https://caniuse.com/?search=web%20speech%20api](https://caniuse.com/?search=web+speech+api)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 截图来自[https://caniuse.com/?search=web%20speech%20api](https://caniuse.com/?search=web+speech+api)
- en: In my own experience, I have seen the API’s speech recognition modules work
    nicely only on Safari and Chrome, including their iOS and Android versions, respectively.
    Note that other chromium-based browsers such as Brave or Oculus Browser (the web
    browser of Meta’s Quest browsers for virtual reality) do not support speech recognition.
    This happens because Google’s speech recognition service is proprietary and requires
    a license to use, which Google does not grant to other browsers. Note on top of
    this that since speech recognition in Chrome is handled by a system based on cloud
    computing, browsers centered in user privacy such as Brave would face a hard decision
    to make, should Google allow them to run speech recognition with their resources.
    Oh and by the way, talking about privacy, note that all speech recognition taking
    place through the Web Speech API needs that the calling webpage be served via
    https!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，我发现 API 的语音识别模块仅在 Safari 和 Chrome 中表现良好，包括它们的 iOS 和 Android 版本。请注意，其他基于
    Chromium 的浏览器，如 Brave 或 Oculus Browser（Meta 的 Quest 虚拟现实浏览器）不支持语音识别。这是因为 Google
    的语音识别服务是专有的，需要许可证使用，而 Google 不授予其他浏览器使用许可证。值得注意的是，由于 Chrome 中的语音识别由基于云计算的系统处理，以用户隐私为中心的浏览器如
    Brave 将面临一个艰难的决定，如果 Google 允许它们使用自己的资源进行语音识别。哦，顺便提一下，谈到隐私，请注意，所有通过 Web Speech
    API 进行的语音识别都需要调用的网页通过 https 提供服务！
- en: Speech synthesis, contrary to speech recognition, is handled properly by all
    major browsers in computers (except the old Internet Explorer from Microsoft,
    now replaced by their Edge which does support it) and most browsers for smartphones.
    For TTS, https is not mandatory at the moment.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与语音识别相反，语音合成在计算机上的所有主要浏览器（除了已被 Microsoft 的 Edge 替代的旧版 Internet Explorer，它现在支持语音合成）和大多数智能手机浏览器中都能得到妥善处理。对于
    TTS，当前不强制要求 https。
- en: In what follows, I will focus specifically on the Web Speech API and how you
    can use it in Chrome, although in principle the core elements should work the
    same in all other browsers that support the API.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将专注于 Web Speech API 以及如何在 Chrome 中使用它，尽管原则上核心元素在所有其他支持该 API 的浏览器中应该工作相同。
- en: Using Chrome’s Web Speech API
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Chrome 的 Web Speech API
- en: To use the Web Speech API programmatically, you need to create an instance of
    the SpeechRecognition or SpeechSynthesis interface, depending on whether you want
    to use speech input or output -or you might well create both and use them in the
    same app!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要以编程方式使用 Web Speech API，你需要创建 SpeechRecognition 或 SpeechSynthesis 接口的实例，具体取决于你想使用语音输入还是输出——或者你也可以创建两者，并在同一个应用中使用它们！
- en: Speech Recognition
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语音识别
- en: 'For example, to create a speech recognition object, you can go as simple as
    this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要创建一个语音识别对象，你可以简单地这样做：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'However, you better check that ASR is actually enabled in the browser. Then,
    the minimal block of code would look like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你最好检查一下 ASR 在浏览器中是否实际上已启用。然后，最简单的代码块看起来如下：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can use the methods and properties of the object as shown above to control
    the speech recognition service and put it to work in the best possible way. The
    most used commands and properties are **start**, **stop**, **abort**, **lang**,
    **interimResults**, etc. You can also add event listeners to handle the events
    that are fired by the object, such as **onstart**, **onend**, **onresult**, **onerror**,
    etc.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用如上所示的对象的方法和属性来控制语音识别服务，并以最佳方式使用它。最常用的命令和属性包括**start**、**stop**、**abort**、**lang**、**interimResults**等。你还可以添加事件监听器来处理对象触发的事件，例如**onstart**、**onend**、**onresult**、**onerror**等。
- en: One particularly interesting property very worthy of attention, unfortunately
    for a negative reason, is that of “grammars”. Speech recognition “grammars” are
    supposed to allow a piece of code doing ASR to understand words that it would
    normally not understand or it would rank low. This functionality is especially
    important to correct pronunciation and the use of names, jargon, local expressions,
    etc. You will find some information [here](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition/grammars)
    but I won’t dig into details because… it just doesn’t work, and many people are
    complaining about this; moreover, there’s a whole move to just drop grammars from
    the API, as no browser currently supports it well (see [here](https://github.com/WICG/speech-api/pull/58)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别值得关注的属性，遗憾的是因为负面的原因，是“grammars”。语音识别的“grammars”应该允许一个进行ASR的代码理解它通常无法理解或排名较低的词汇。这个功能对于纠正发音和使用名字、行话、地方表达等尤其重要。你可以在[这里](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition/grammars)找到一些信息，但我不会深入细节，因为……它确实不起作用，很多人对此表示抱怨；此外，还有一个整体的趋势是从API中删除“grammars”，因为目前没有浏览器支持它（见[这里](https://github.com/WICG/speech-api/pull/58)）。
- en: To know more about the properties and events of the SpeechRecognition object,
    [check this out](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关SpeechRecognition对象的属性和事件的更多信息，[查看此处](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition)。
- en: 'And for a global, complete example of how to use the Web Speech API for speech
    recognition, check out this official example that shows how to change a web page’s
    background color through spoken commands:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以及如何使用Web语音API进行语音识别的全球完整示例，请查看这个官方示例，它展示了如何通过口头命令更改网页的背景颜色：
- en: '[](https://github.com/mdn/dom-examples/blob/main/web-speech-api/speech-color-changer/script.js?source=post_page-----dc1afde54ced--------------------------------)
    [## dom-examples/web-speech-api/speech-color-changer/script.js at main · mdn/dom-examples'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[## dom-examples/web-speech-api/speech-color-changer/script.js at main · mdn/dom-examples](https://github.com/mdn/dom-examples/blob/main/web-speech-api/speech-color-changer/script.js?source=post_page-----dc1afde54ced--------------------------------)'
- en: Code examples that accompany various MDN DOM and Web API documentation pages
    …
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 附带各种MDN DOM和Web API文档页面的代码示例……
- en: github.com](https://github.com/mdn/dom-examples/blob/main/web-speech-api/speech-color-changer/script.js?source=post_page-----dc1afde54ced--------------------------------)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/mdn/dom-examples/blob/main/web-speech-api/speech-color-changer/script.js?source=post_page-----dc1afde54ced--------------------------------)'
- en: Speech Synthesis
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语音合成
- en: 'Similarly, to create a speech synthesis object, you can write:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，要创建一个语音合成对象，你可以写：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, you can create instances of the **SpeechSynthesisUtterance** interface,
    which represent the specific speech requests that you want to synthesize. You
    can set the properties of the utterance, such as text, voice, rate, pitch, volume,
    etc. You can use the methods and properties of the object to control the speech
    synthesis service, such as speak, pause, resume, cancel, getVoices, etc. You can
    also add event listeners to handle the events that are fired by the utterance,
    such as onstart, onend, onerror, etc. For example, to synthesize a text and log
    when it starts and ends, you can write:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以创建**SpeechSynthesisUtterance**接口的实例，这些实例代表你希望合成的特定语音请求。你可以设置utterance的属性，例如文本、声音、语速、音调、音量等。你可以使用对象的方法和属性来控制语音合成服务，例如speak、pause、resume、cancel、getVoices等。你还可以添加事件监听器来处理utterance触发的事件，例如onstart、onend、onerror等。例如，要合成文本并在开始和结束时记录日志，你可以这样写：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'What I really like to do in my web apps is to have a function that can receive
    a string and just speak it up. I call this function speakUp(), and it looks like
    this:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我在我的Web应用程序中真正喜欢做的是创建一个可以接收字符串并将其朗读出来的函数。我称这个函数为speakUp()，它看起来是这样的：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Problems of ASR and TTS via the Web Speech API, and how to Correct Some of Them
    Using a Large Language Model
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Web Speech API进行ASR和TTS的问题，以及如何使用大型语言模型纠正其中的一些问题
- en: The Web Speech API is very easy to use, as you saw. It is also free and doesn’t
    even require any API key, nor does it have any limits in how much and often you
    can call it.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Web Speech API 使用起来非常简单，如你所见。它也是免费的，不需要任何API密钥，也没有调用次数和频率的限制。
- en: However, in trying it over and over I see that the system is down quite often,
    especially for ASR. Moreover, the API sometimes seems to switch off all by itself,
    with many people asking about this without clear solutions. Worst of all, although
    the free API is OK for some applications, it is far from the state of the art,
    regarding both speech recognition and synthesis. Compared to what I explained
    in the introduction about modern ASR systems in general, Chrome’s service for
    ASR can do very little!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通过反复尝试，我发现系统经常出现故障，尤其是在ASR方面。此外，API有时似乎会自行关闭，许多人对此提出了问题但没有明确的解决方案。最糟糕的是，虽然免费的API在某些应用中可以使用，但无论是语音识别还是合成，都远未达到最先进的水平。与我在介绍中提到的现代ASR系统相比，Chrome的ASR服务几乎无法提供任何实质性的功能！
- en: Speech recognition is not very accurate or reliable, nor is it tolerant to accents
    and dialects. It is virtually useless even with just some noise. It doesn’t detect
    language automatically, it doesn’t detect multiple people talking in the same
    conversation, it handles punctuation ok but gets confused with vocalizations,
    etc.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别的准确性和可靠性都不高，也不耐受口音和方言。即使有一些噪音，它也几乎没有用。它无法自动检测语言，无法识别同一对话中的多个人，标点处理还可以，但对声音化表达感到困惑等。
- en: The speech recognition service comes with privacy and security issues, as the
    voice data is transmitted to external servers or third parties without the user’s
    consent or knowledge.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别服务存在隐私和安全问题，因为语音数据被传输到外部服务器或第三方，而未经用户同意或了解。
- en: The speech synthesis service doesn’t have very natural or expressive voices,
    especially for languages other than English.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 语音合成服务的声音不够自然或富有表现力，尤其是对于英语以外的语言。
- en: Besides, as we saw above the speech recognition and synthesis services are very
    dependent on the browser and the device, and may not be available or consistent
    across different platforms and regions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，正如我们所见，语音识别和合成服务在浏览器和设备上非常依赖，可能在不同的平台和地区不可用或不一致。
- en: And because of their limited power, they may have ethical and social implications
    such as bias, discrimination, deception, manipulation, or impersonation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其能力有限，它们可能会带来伦理和社会影响，如偏见、歧视、欺骗、操控或冒充。
- en: As a developer, and also as a user, you should be aware of these limitations
    and challenges, and use the Web Speech API responsibly and appropriately.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发者和用户，你应该意识到这些局限性和挑战，并负责任且恰当地使用Web Speech API。
- en: Alleviating Problems of Speech Recognition by using a Large Language Model
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过使用大型语言模型缓解语音识别问题
- en: Of the above problems, those related to ASR are the most important ones. Solving
    many of these problems requires action at the most basic level when recognition
    is taking place. However, the most important problems related to transcription
    accuracy and jargon completion can be fixed with a large language model, as I’m
    doing via GPT-3.5-turbo or GPT-4, programmatically and right in JavaScript inside
    the web app.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上述问题中，与ASR相关的问题是最重要的。解决这些问题中的许多需要在最基础的识别层面采取行动。然而，与转录准确性和术语补全相关的最重要的问题可以通过大型语言模型解决，正如我通过GPT-3.5-turbo或GPT-4在JavaScript中编程实现的那样。
- en: '***How this works***'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '***这如何工作***'
- en: Essentially, one calls the language model with a prompt explaining what the
    inputs will look like and what the outputs should be for those inputs, followed
    by the actual (raw) transcription coming from the speech recognized by the API.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，你通过一个提示调用语言模型，解释输入内容的样子和这些输入的输出应该是什么，然后是来自API识别的实际（原始）转录。
- en: 'In the [web app that triggered all this work](https://medium.com/towards-artificial-intelligence/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443),
    speech recognition is used to trigger commands. For example, if the user says
    “zoom in”, or “enlarge”, or a similar order, then the visualization (the app is
    for molecular graphics) must be scaled up. This app’s prompt looks like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在[触发所有这些工作的Web应用程序](https://medium.com/towards-artificial-intelligence/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443)中，语音识别用于触发命令。例如，如果用户说“放大”或“扩大”或类似的命令，那么可视化（该应用程序用于分子图形）必须放大。该应用程序的提示如下：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s see this in detail. Here’s the **System** element of the prompt:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解一下。以下是提示的**系统**元素：
- en: You receive texts from speech recognition and act accordingly by triggering
    commands, effectively correcting speech recognition as in the examples provided
    below. If you don’t understand the request or the request is not in the list,
    you run the command didntUnderstand().
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你从语音识别中接收文本并据此执行命令，实际上纠正语音识别，如下面提供的示例。如果你不理解请求或请求不在列表中，你将运行命令didntUnderstand()。
- en: Then, see how the User/Assistant pairs provide examples of possible inputs that
    produce the same or a related output, for example “Zoom in” and “Enlarge” both
    result in a call to scale(+), while “Zoom out” calls scale(-).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，看看用户/助手对的示例如何提供可能的输入，这些输入会产生相同或相关的输出，例如“放大”和“扩大”都导致调用scale(+)，而“缩小”调用scale(-)。
- en: 'In other pieces of the code you will find entries that “teach” the language
    model to correct inputs in a way that will prevent the program from crashing and
    at the same time increase the chances of producing the right output. For example,
    “minimize” as spoken by me is often recognized as “mini mice”, and “ANI” which
    is not a standard English word gets recognized as “Annie”. Then I can instruct
    the language model with examples like these:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码的其他部分，你会发现一些条目“教”语言模型以一种可以防止程序崩溃的方式来纠正输入，同时增加产生正确输出的机会。例如，我说的“最小化”经常被识别为“mini
    mice”，“ANI”这个非标准英语单词被识别为“Annie”。然后我可以用这样的示例来指导语言模型：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The trick works remarkably well, and this is no big wonder because at the end
    of the day, this is at the core of the most modern language models like Whisper,
    which embed language models directly into the speech recognition procedure!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技巧效果非常好，这并不奇怪，因为归根结底，这正是现代语言模型如Whisper的核心，这些模型将语言模型直接嵌入到语音识别过程中！
- en: 'On closing this section and just for completion, of course the full prompt
    must be inside the promise resolved from a fetch to the language model, which
    in my case is often GPT-3.5-turbo or GPT-4 from OpenAI:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束这一部分时，为了完整性，当然完整的提示必须包含在从语言模型获取的承诺中，在我的情况下，通常是OpenAI的GPT-3.5-turbo或GPT-4：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Some case uses for Chrome’s Web Speech API
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Chrome的Web Speech API的一些应用案例
- en: 'Besides the app that triggered this series of blog posts ([here](https://pub.towardsai.net/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443)),
    I can share with you these other projects that use the speech recognition and/or
    synthesis APIs:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 除了触发这一系列博客文章的应用程序（[在这里](https://pub.towardsai.net/coupling-four-ai-models-to-deliver-the-ultimate-experience-in-immersive-visualization-and-modeling-9f52a4bd1443)），我还可以与你分享其他使用语音识别和/或合成API的项目：
- en: 'In this example, I used Chrome’s speech recognition capabilities together with
    GPT-3 to create a web app that writes e-mails from your spoken notes and guidelines:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我结合了Chrome的语音识别功能和GPT-3，创建了一个从你的口述笔记和指南中编写电子邮件的Web应用程序：
- en: '[](https://pub.towardsai.net/a-web-app-for-automated-e-mail-writing-from-voice-notes-using-gpt-3-e8e98e4ffb6f?source=post_page-----dc1afde54ced--------------------------------)
    [## A Web App for Automated E-mail Writing From Voice Notes, Using GPT-3'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 一个基于GPT-3的自动化电子邮件写作Web应用程序，来自语音笔记'
- en: I coupled Chrome’s speech recognition engine with GPT-3 to create a web app
    that writes e-mails from your spoken notes…
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我将Chrome的语音识别引擎与GPT-3结合起来，创建了一个从你的口述笔记中编写电子邮件的Web应用程序……
- en: pub.towardsai.net](https://pub.towardsai.net/a-web-app-for-automated-e-mail-writing-from-voice-notes-using-gpt-3-e8e98e4ffb6f?source=post_page-----dc1afde54ced--------------------------------)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[pub.towardsai.net](https://pub.towardsai.net/a-web-app-for-automated-e-mail-writing-from-voice-notes-using-gpt-3-e8e98e4ffb6f?source=post_page-----dc1afde54ced--------------------------------)'
- en: 'Here, I show you how to build a chatGPT-like bot that can listen to you and
    reply orally; again, this couples Chrome’s Web Speech API for recognition and
    synthesis with GPT-3 as the language model powerling the chatbot’s “brain”:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我展示了如何构建一个类似chatGPT的机器人，它可以听你说话并口头回复；同样，这将Chrome的Web Speech API用于识别和合成，与GPT-3作为驱动聊天机器人“脑力”的语言模型结合：
- en: '[](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dc1afde54ced--------------------------------)
    [## Coupling GPT-3 with speech recognition and synthesis to achieve a fully talking
    chatbot that runs…'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dc1afde54ced--------------------------------)
    [## 将GPT-3与语音识别和合成结合，实现一个完全对话的聊天机器人...'
- en: How I created this web app with which you can talk naturally with GPT-3 about
    any topic you want, all web-based in your…
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我是如何创建这个网页应用的，你可以自然地与GPT-3谈论任何你想要的话题，全基于网页的...
- en: towardsdatascience.com](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dc1afde54ced--------------------------------)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/coupling-gpt-3-with-speech-recognition-and-synthesis-to-achieve-a-fully-talking-chatbot-that-runs-abfcb7bf580?source=post_page-----dc1afde54ced--------------------------------)
- en: 'In this other example as use Chrome’s speech recognition capability to control
    a web app, in this case using GPT-3 to cast spoken requests into commands:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个其他示例中，使用Chrome的语音识别功能来控制一个网页应用，在这种情况下使用GPT-3将口头请求转化为命令：
- en: '[](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dc1afde54ced--------------------------------)
    [## Control web apps via natural language by casting speech to commands with GPT-3'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dc1afde54ced--------------------------------)
    [## 通过将语音转化为命令来控制网页应用，与GPT-3一起使用'
- en: One last article showcasing practical applications of GPT3, with a full explanation
    of the workflow and details on the…
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后一篇文章展示了GPT-3的实际应用，详细解释了工作流程和细节...
- en: towardsdatascience.com](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dc1afde54ced--------------------------------)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/control-web-apps-via-natural-language-by-casting-speech-to-commands-with-gpt-3-113177f4eab1?source=post_page-----dc1afde54ced--------------------------------)
- en: Beyond the Web Speech API
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越Web Speech API
- en: I described above that some web browsers don’t support speech synthesis, most
    don’t support speech recognition. I also explained that Chrome’s built-in speech
    API is not great, especially for speech recognition, and that some of these limitations
    can be overcome with language models; however, not all problems can be solved
    with that strategy, and hence many features that modern ASR systems have are totally
    lacking.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我在上面描述了某些网页浏览器不支持语音合成，大多数也不支持语音识别。我还解释了Chrome的内置语音API并不出色，尤其是对于语音识别，并且这些限制的一些问题可以通过语言模型来克服；然而，并非所有问题都可以用这种策略解决，因此许多现代ASR系统具有的功能是完全缺失的。
- en: In this context, it is important to know that browsers may support speech recognition
    and synthesis by using alternative services or solutions -paid in contrast to
    Chrome’s free API, but in principle more powerful.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，了解浏览器可能支持语音识别和合成是重要的，通过使用替代服务或解决方案——这些服务或解决方案是付费的，相比于Chrome的免费API，原则上更强大。
- en: Just to mention some companies offering this API service, check Gladia, Speechly,
    AssemblyAI, Deepgram, Spechmatics (this one showing off with a great example [here](https://www.speechmatics.com/)),
    and some others. Even Google has an ASR system separate from that they offer for
    free in Chrome, that certainly works much better, and other tech giants like Microsoft
    and AWS have their own products made available via APIs. You could even download
    OpenAI’s open-source Whisper and set a service to run it specifically for you,
    even customized to your needs -although for this you rather go straight away with
    a company that provides it via an API, such as [Gladia.io](https://www.gladia.io/).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 仅提及一些提供此API服务的公司，可以查看Gladia、Speechly、AssemblyAI、Deepgram、Spechmatics（这个有一个很棒的示例[在这里](https://www.speechmatics.com/)），以及其他一些公司。即使是Google也有一个与他们在Chrome中免费提供的系统不同的ASR系统，它显然效果更好，其他科技巨头如Microsoft和AWS也通过API提供了他们自己的产品。你甚至可以下载OpenAI的开源Whisper，并设置一个专门为你运行的服务，甚至可以根据你的需求进行定制——不过你还是直接去找一个通过API提供的公司，比如[Gladia.io](https://www.gladia.io/)。
- en: Of course, unless you do a closed implementation (for example using Whisper
    on a local server), most of these services will require that you send audio to
    their servers, thus potentially compromising privacy. However, for non-sensitive
    tasks, they might be a perfect getaway, even with some quite low costs in many
    cases.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，除非你做的是封闭实现（例如在本地服务器上使用Whisper），否则大多数这些服务都需要你将音频发送到他们的服务器，这可能会危及隐私。然而，对于非敏感任务来说，它们可能是一个完美的选择，即使在许多情况下成本相对较低。
- en: Further reads
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
    [## Web Speech API - Web APIs | MDN'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
    [## Web Speech API - Web APIs | MDN'
- en: The Web Speech API enables you to incorporate voice data into web apps. The
    Web Speech API has two parts…
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Web Speech API 使你能够将语音数据集成到网络应用程序中。Web Speech API 有两个部分…
- en: developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
    [](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
    [## Using the Web Speech API - Web APIs | MDN
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
    [](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
    [## Using the Web Speech API - Web APIs | MDN
- en: Speech recognition involves receiving speech through a device's microphone,
    which is then checked by a speech…
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语音识别涉及通过设备的麦克风接收语音，然后由语音…
- en: developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API?source=post_page-----dc1afde54ced--------------------------------)
- en: '[***www.lucianoabriata.com***](https://www.lucianoabriata.com/) *I write about
    everything that lies in my broad sphere of interests: nature, science, technology,
    programming, etc.* [***Subscribe to get my new stories***](https://lucianosphere.medium.com/subscribe)
    ***by email****. To* ***consult about small jobs*** *check my* [***services page
    here***](https://lucianoabriata.altervista.org/services/index.html)*. You can*
    [***contact me here***](https://lucianoabriata.altervista.org/office/contact.html)***.***
    *You can* [***tip me here***](https://paypal.me/LAbriata)*.*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[***www.lucianoabriata.com***](https://www.lucianoabriata.com/) *我写关于我广泛兴趣领域的一切：自然、科学、技术、编程等。*
    [***订阅以获取我的新故事***](https://lucianosphere.medium.com/subscribe) ***通过电子邮件****。要*
    ***咨询小型工作*** *请查看我的* [***服务页面在这里***](https://lucianoabriata.altervista.org/services/index.html)*。你可以*
    [***在这里联系我***](https://lucianoabriata.altervista.org/office/contact.html)***。***
    *你可以* [***在这里给我小费***](https://paypal.me/LAbriata)*.*'
