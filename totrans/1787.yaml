- en: 'Retro-Engineering a Database Schema: GPT vs. Bard vs. LLama2 (Episode 2)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/retro-engineering-a-database-schema-gpt-vs-bard-vs-llama2-episode-2-e7f144a6753b](https://towardsdatascience.com/retro-engineering-a-database-schema-gpt-vs-bard-vs-llama2-episode-2-e7f144a6753b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In my previous article, I benchmarked GPT-4 model against Bard. Now Llama-2
    enters the arena and it‚Äôs high time we see how it performs against its competitors!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)[![Pierre-Louis
    Bescond](../Images/bb236055962b420fb3ab22088ab28f11.png)](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)
    [Pierre-Louis Bescond](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)
    ¬∑6 min read¬∑Oct 6, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2941f397ecb8ea1cf96ab9c325122f57.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Dustin Humes](https://unsplash.com/@dustinhumes_photography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The Initial (and Final) Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As explained [in this first article](https://medium.com/p/2e2776e8af86), we‚Äôll
    start with a fake AI-generated dataset containing employees‚Äô information.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/retro-engineering-a-database-schema-and-quality-checks-gpt-vs-bard-2e2776e8af86?source=post_page-----e7f144a6753b--------------------------------)
    [## Retro-engineering a database schema and quality checks: GPT vs. Bard'
  prefs: []
  type: TYPE_NORMAL
- en: Can LLMs retro-engineer a consolidated dataset to design the original database
    and suggest the corresponding data‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/retro-engineering-a-database-schema-and-quality-checks-gpt-vs-bard-2e2776e8af86?source=post_page-----e7f144a6753b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The original table has 11 columns x 7688 rows but we‚Äôll limit the extract to
    a sample of 50 rows to accommodate current LLMs token limitations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0c36c37aab2a4cf97caf94e274d64dcd.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample of the source data (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: '*(Note: the notebook and data source are available at the end of the article)*'
  prefs: []
  type: TYPE_NORMAL
- en: Retro-Engineering the Data Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The idea here is to ask each LLM to analyze this sample data and provide some
    insight into what the initial data scheme might look like.
  prefs: []
  type: TYPE_NORMAL
- en: 'We‚Äôll keep the same prompt as the one we used for GPT-4 and Bard:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Ok great! ‚Ä¶ But now the question is ‚ÄúWhere can I test Llama-2?‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several options available:'
  prefs: []
  type: TYPE_NORMAL
- en: The most obvious one (but also more complex and expensive üí∏) is to host the
    model on a dedicated server in your cloud architecture. This is usually a good
    option if you intend to serve heavy-duty applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep in mind that the virtual machines required to run an LLM can go from 2‚Äì3$/hour
    for a small model‚Ä¶ up to 18$/hour if you want to host LLama2‚Äì70b properly, according
    to Azure üò®
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An intermediary solution ‚Äî recommended [by Yann Lecun himself](https://www.linkedin.com/feed/update/urn:li:activity:7109561666324885504?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7109561666324885504%2C7111453478513733632%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287111453478513733632%2Curn%3Ali%3Aactivity%3A7109561666324885504%29)
    ‚Äî is to use platforms like [Anyscale](https://www.anyscale.com/) which, for example,
    offers $1 for 1M token on Llama-2‚Äì70b-chat (when Azure pricing is between $30
    and $60 for GPT-4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The awesome Hugging Face platform also offers us a testbed. A good way, for
    example, to keep our finances straight!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat?source=post_page-----e7f144a6753b--------------------------------)
    [## Llama 2 7B Chat - a Hugging Face Space by huggingface-projects'
  prefs: []
  type: TYPE_NORMAL
- en: Discover amazing ML apps made by the community
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: huggingface.co](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat?source=post_page-----e7f144a6753b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: While writing this second episode, I also discovered [https://chat.lmsys.org/](https://chat.lmsys.org/)
    that allows you to execute one single prompt with two models in parallel. Perfect
    to benchmark their performance. This is the tool I‚Äôll use for this article.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d98758be443f6eec0e3aabe30a2c800d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Paz Arando](https://unsplash.com/@pazarando?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing results (LLama-2)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When running the benchmark on ChatGPT, we chose the most advanced and generally
    available version: 4.0.'
  prefs: []
  type: TYPE_NORMAL
- en: In the same spirit, we‚Äôll run our query on the ‚Äú[LLama-2‚Äì70b-chat](https://ai.meta.com/llama/)‚Äù
    version which, as its name suggests, has a size of 70 billion parameters and a
    context window of 4096 tokens.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying Categorical and Confidential Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Even if one could challenge the fact that ‚ÄúEmployee_ID‚Äù actually belongs to
    confidential data (but the more I think about it, the more it makes sense), LLama-2
    managed to find all categorical and confidential columns, by order of appearance
    ‚úÖ
  prefs: []
  type: TYPE_NORMAL
- en: Suggesting a database model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Again, Llama-2 does pretty well by properly converting categorical columns into
    sub-tables with key/label pairs. ‚úÖ
  prefs: []
  type: TYPE_NORMAL
- en: Separating the confidential data into another table like ChatGPT did would have
    been a plus but that‚Äôs already a near result! üî∂
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the ‚Äúage‚Äù column has disappeared from the suggested schema. ‚ùå
  prefs: []
  type: TYPE_NORMAL
- en: SQL Scripts to create tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I‚Äôll continue here with the ‚Äúacid test‚Äù üß™ of simply running these queries in
    Snowflake and checking what the result looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Besides the fact that ‚Äúage‚Äù still missing, everything runs like a charm and
    all tables are created seamlessly in Snowflake! ‚úÖ
  prefs: []
  type: TYPE_NORMAL
- en: Data Quality Checks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, Llama-2 suggests some common wisdom:'
  prefs: []
  type: TYPE_NORMAL
- en: Check for duplicates ‚úÖ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check invalid characters ‚úÖ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '‚Ä¶ and also tries to adapt to the nature of some fields:'
  prefs: []
  type: TYPE_NORMAL
- en: A valid email address format ‚úÖ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative or non-numeric values for ‚Äúsalary‚Äù & ‚Äúannual_evaluation‚Äù ‚úÖ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '‚Ä¶ but also produces some mistakes:'
  prefs: []
  type: TYPE_NORMAL
- en: For example, it won‚Äôt be unusual to find identical first (or even last) names
    in the table so duplicates should be accepted ‚ùå
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking back at what ChatGPT did, identifying ranges for columns like salary,
    age or even defining the acceptable values for the annual evaluation, Llama-2
    provides an ‚Äúaverage‚Äù answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion for Llama-2‚Äì70b:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Identifying Categorical and Confidential Data ‚úÖ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suggesting a database model ‚úÖ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL Scripts to create tables ‚úÖ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Quality Checks üî∂
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion (Updated with Llama-2)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT-4k clearly outperforms Bard and Llama-2 when it comes to understanding a
    dataset, designing a proper data model (here under the 3rd Normal Form (3NF)),
    writing the corresponding SQL queries, and suggesting data quality checks.
  prefs: []
  type: TYPE_NORMAL
- en: For this specific task (database retro-engineering), Llama-2 achieves a higher
    performance than Bard.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the answers above, I believe that the insights provided by Llama-2
    are much more valuable than those provided by Bard.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d6dbaa44d89f44de9848183352e5cb06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Notes:'
  prefs: []
  type: TYPE_NORMAL
- en: In late August, Meta released a ‚ÄúCode Llama‚Äù model that we could also benchmark,
    perhaps in a future article.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I used the predefined temperature of 0.7 for the inference, meaning that executing
    the same queries with the same model could produce different results. I decided
    to simply keep the first result provided by the model, not to bias the analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ‚è© Links to the corresponding [Jupyter Notebook](https://github.com/pierrelouisbescond/medium_articles/blob/main/medium_llm_db_retro_eng_load_and_format_data.ipynb)
    and [CSV Data Source](https://github.com/pierrelouisbescond/medium_articles/blob/main/Employees_Base.csv).
  prefs: []
  type: TYPE_NORMAL
- en: As usual, I have tried to identify all the necessary steps if you‚Äôd like to
    reproduce the analysis, but do not hesitate to contact me if there are any missing
    instructions in this tutorial!
  prefs: []
  type: TYPE_NORMAL
- en: 'And feel free to check out my other posts on Medium:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad?source=post_page-----e7f144a6753b--------------------------------)
    [## Pierre-Louis Bescond‚Äôs articles on Medium'
  prefs: []
  type: TYPE_NORMAL
- en: Data Science, Machine Learning and Innovation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pl-bescond.medium.com](https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad?source=post_page-----e7f144a6753b--------------------------------)
  prefs: []
  type: TYPE_NORMAL
