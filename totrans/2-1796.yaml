- en: Run ChatGPT and GPT Models on Your Website with PHP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨PHPåœ¨ä½ çš„ç½‘ç«™ä¸Šè¿è¡ŒChatGPTå’ŒGPTæ¨¡å‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/run-chatgpt-and-gpt-models-on-your-website-with-php-517ea20266d7](https://towardsdatascience.com/run-chatgpt-and-gpt-models-on-your-website-with-php-517ea20266d7)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/run-chatgpt-and-gpt-models-on-your-website-with-php-517ea20266d7](https://towardsdatascience.com/run-chatgpt-and-gpt-models-on-your-website-with-php-517ea20266d7)
- en: A very simple solution to deliver AI with GPT models to your users
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸€ç§éå¸¸ç®€å•çš„è§£å†³æ–¹æ¡ˆï¼Œå°†GPTæ¨¡å‹çš„AIäº¤ä»˜ç»™ä½ çš„ç”¨æˆ·
- en: '[](https://medium.com/@bnjmn_marie?source=post_page-----517ea20266d7--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----517ea20266d7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----517ea20266d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----517ea20266d7--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----517ea20266d7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bnjmn_marie?source=post_page-----517ea20266d7--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----517ea20266d7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----517ea20266d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----517ea20266d7--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----517ea20266d7--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----517ea20266d7--------------------------------)
    Â·12 min readÂ·May 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----517ea20266d7--------------------------------)
    Â·12åˆ†é’Ÿé˜…è¯»Â·2023å¹´5æœˆ2æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/674c26153559ff00625bba226d4b3458.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/674c26153559ff00625bba226d4b3458.png)'
- en: Image from [Pixabay](https://pixabay.com/illustrations/media-internet-message-network-3683580/).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥è‡ª[Pixabay](https://pixabay.com/illustrations/media-internet-message-network-3683580/)ã€‚
- en: GPT models can improve the user experience of websites and web apps. They can
    translate, summarize, answer questions, and do many other tasks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: GPTæ¨¡å‹å¯ä»¥æå‡ç½‘ç«™å’Œç½‘ç»œåº”ç”¨çš„ç”¨æˆ·ä½“éªŒã€‚å®ƒä»¬å¯ä»¥ç¿»è¯‘ã€æ€»ç»“ã€å›ç­”é—®é¢˜ï¼Œè¿˜èƒ½å®Œæˆè®¸å¤šå…¶ä»–ä»»åŠ¡ã€‚
- en: Integrating all these functionalities into your online service is fairly easy
    with OpenAI API. Currently, OpenAI only provides official support for Python and
    NodeJS bindings.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰è¿™äº›åŠŸèƒ½é›†æˆåˆ°ä½ çš„åœ¨çº¿æœåŠ¡ä¸­ï¼Œé€šè¿‡OpenAI APIç›¸å½“ç®€å•ã€‚ç›®å‰ï¼ŒOpenAIä»…æä¾›å¯¹Pythonå’ŒNodeJSç»‘å®šçš„å®˜æ–¹æ”¯æŒã€‚
- en: Many [third-party bindings](https://github.com/openai-php/client) have been
    developed by the community to facilitate deployment in other programming languages.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤š[ç¬¬ä¸‰æ–¹ç»‘å®š](https://github.com/openai-php/client)å·²ç»ç”±ç¤¾åŒºå¼€å‘ï¼Œä»¥ä¾¿åœ¨å…¶ä»–ç¼–ç¨‹è¯­è¨€ä¸­è¿›è¡Œéƒ¨ç½²ã€‚
- en: In this article, I will show you how to connect your website to OpenAIâ€™s API
    in PHP. I will also explain how to parse and interpret the results returned by
    the API.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å±•ç¤ºå¦‚ä½•å°†ä½ çš„ç½‘ç«™è¿æ¥åˆ°OpenAIçš„APIã€‚æˆ‘è¿˜ä¼šè§£é‡Šå¦‚ä½•è§£æå’Œè§£è¯»APIè¿”å›çš„ç»“æœã€‚
- en: I will only cover GPT models but you can follow the same process for DALL-E
    and Whisper models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†åªæ¶µç›–GPTæ¨¡å‹ï¼Œä½†ä½ å¯ä»¥ä½¿ç”¨ç›¸åŒçš„æµç¨‹æ¥å¤„ç†DALL-Eå’ŒWhisperæ¨¡å‹ã€‚
- en: Pre-requisites
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…ˆå†³æ¡ä»¶
- en: GPT models
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPTæ¨¡å‹
- en: 'You donâ€™t need to be familiar with the GPT models to understand and implement
    this article, but I still recommend you to read my simple introduction about GPT
    models:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸éœ€è¦ç†Ÿæ‚‰GPTæ¨¡å‹å°±å¯ä»¥ç†è§£å’Œå®ç°è¿™ç¯‡æ–‡ç« ï¼Œä½†æˆ‘ä»å»ºè®®ä½ é˜…è¯»æˆ‘å…³äºGPTæ¨¡å‹çš„ç®€å•ä»‹ç»ï¼š
- en: '[](/a-gentle-introduction-to-gpt-models-e02b093a495b?source=post_page-----517ea20266d7--------------------------------)
    [## A Gentle Introduction to GPT Models'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-gentle-introduction-to-gpt-models-e02b093a495b?source=post_page-----517ea20266d7--------------------------------)
    [## GPTæ¨¡å‹çš„ç®€å•ä»‹ç»'
- en: Welcome to the new world of token generators
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¬¢è¿æ¥åˆ°ä»¤ç‰Œç”Ÿæˆå™¨çš„æ–°ä¸–ç•Œ
- en: towardsdatascience.com](/a-gentle-introduction-to-gpt-models-e02b093a495b?source=post_page-----517ea20266d7--------------------------------)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-gentle-introduction-to-gpt-models-e02b093a495b?source=post_page-----517ea20266d7--------------------------------)
- en: PHP
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PHP
- en: You will only need to know the basics of PHP.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åªéœ€äº†è§£PHPçš„åŸºç¡€çŸ¥è¯†ã€‚
- en: 'I will use a PHP library that we can install with Composer (so you will need
    Composer) and that requires at least PHP 8.1\. *Note: You wonâ€™t be able to install
    the library with an older version of PHP.*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†ä½¿ç”¨ä¸€ä¸ªå¯ä»¥é€šè¿‡Composerå®‰è£…çš„PHPåº“ï¼ˆæ‰€ä»¥ä½ éœ€è¦Composerï¼‰ï¼Œå¹¶ä¸”è¦æ±‚è‡³å°‘PHP 8.1ã€‚*æ³¨æ„ï¼šä½ æ— æ³•åœ¨æ—§ç‰ˆæœ¬çš„PHPä¸Šå®‰è£…è¯¥åº“ã€‚*
- en: OpenAI account
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAIè´¦æˆ·
- en: 'You will need an OpenAI account. If you donâ€™t have one, here is my guide on
    how to create and manage an OpenAI account:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦ä¸€ä¸ªOpenAIè´¦æˆ·ã€‚å¦‚æœä½ æ²¡æœ‰ï¼Œè¯·å‚è€ƒæˆ‘çš„æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºå’Œç®¡ç†OpenAIè´¦æˆ·ï¼š
- en: '[](https://medium.com/@bnjmn_marie/openai-account-documentation-playground-and-models-hyperparameters-fb1dada13260?source=post_page-----517ea20266d7--------------------------------)
    [## OpenAI Account: Documentation, Playground, and Modelsâ€™ Hyperparameters'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[## OpenAI è´¦æˆ·ï¼šæ–‡æ¡£ã€æ¸¸ä¹åœºå’Œæ¨¡å‹çš„è¶…å‚æ•°](https://medium.com/@bnjmn_marie/openai-account-documentation-playground-and-models-hyperparameters-fb1dada13260?source=post_page-----517ea20266d7--------------------------------)'
- en: All you need to know to start using OpenAI API
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ OpenAI API æ‰€éœ€äº†è§£çš„å…¨éƒ¨å†…å®¹
- en: medium.com](https://medium.com/@bnjmn_marie/openai-account-documentation-playground-and-models-hyperparameters-fb1dada13260?source=post_page-----517ea20266d7--------------------------------)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@bnjmn_marie/openai-account-documentation-playground-and-models-hyperparameters-fb1dada13260?source=post_page-----517ea20266d7--------------------------------)'
- en: You will have to create an API key in your account and have a few cents of credits
    remaining if you want to run the examples.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³è¿è¡Œç¤ºä¾‹ï¼Œä½ éœ€è¦åœ¨è´¦æˆ·ä¸­åˆ›å»ºä¸€ä¸ª API å¯†é’¥å¹¶ä¿ç•™å‡ åˆ†é’±çš„ç§¯åˆ†ã€‚
- en: OpenAI PHP
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI PHP
- en: We will use the client maintained by [OpenAI PHP](https://github.com/openai-php/client)
    (MIT license) to communicate with OpenAI API.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨ç”± [OpenAI PHP](https://github.com/openai-php/client)ï¼ˆMIT è®¸å¯è¯ï¼‰ç»´æŠ¤çš„å®¢æˆ·ç«¯ä¸ OpenAI
    API è¿›è¡Œé€šä¿¡ã€‚
- en: 'Other PHP libraries do the same, but I choose this one for the following reasons:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä»– PHP åº“ä¹Ÿèƒ½åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†æˆ‘é€‰æ‹©è¿™ä¸ªåº“æ˜¯å› ä¸ºä»¥ä¸‹åŸå› ï¼š
- en: It is listed by OpenAI which is a reasonable guarantee that this library can
    be trusted.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒç”± OpenAI åˆ—å‡ºï¼Œåˆç†ä¿è¯äº†è¿™ä¸ªåº“å¯ä»¥ä¿¡ä»»ã€‚
- en: It has the most stars on GitHub among all the PHP bindings for OpenAI API.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ‰€æœ‰ PHP ç»‘å®š OpenAI API çš„åº“ä¸­ï¼Œå®ƒåœ¨ GitHub ä¸Šæ‹¥æœ‰æœ€å¤šçš„ starsã€‚
- en: It is easy to install and use.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜“äºå®‰è£…å’Œä½¿ç”¨ã€‚
- en: It is regularly updated to take into account the changes in the API and new
    OpenAI models.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒä¼šå®šæœŸæ›´æ–°ï¼Œä»¥è€ƒè™‘ API çš„å˜åŒ–å’Œæ–°çš„ OpenAI æ¨¡å‹ã€‚
- en: 'To install it, open a terminal, go to your website/app parentâ€™s root directory,
    and run composer as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å®‰è£…å®ƒï¼Œæ‰“å¼€ç»ˆç«¯ï¼Œè¿›å…¥ä½ çš„ç½‘ç«™/åº”ç”¨ç¨‹åºçˆ¶ç›®å½•ï¼Œå¹¶æŒ‰å¦‚ä¸‹æ–¹å¼è¿è¡Œ composerï¼š
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you donâ€™t have any errors, you can start using OpenAI API with PHP.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ²¡æœ‰ä»»ä½•é”™è¯¯ï¼Œä½ å¯ä»¥å¼€å§‹ä½¿ç”¨ PHP çš„ OpenAI APIã€‚
- en: Setting up your API Key in PHP
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨ PHP ä¸­è®¾ç½®ä½ çš„ API å¯†é’¥
- en: You must create an API key in your OpenAI account.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¿…é¡»åœ¨ä½ çš„ OpenAI è´¦æˆ·ä¸­åˆ›å»ºä¸€ä¸ª API å¯†é’¥ã€‚
- en: For safety reasons, I recommend creating a new API key for each web app you
    want to connect to the API.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ºäºå®‰å…¨åŸå› ï¼Œæˆ‘å»ºè®®ä¸ºæ¯ä¸ªä½ å¸Œæœ›è¿æ¥åˆ° API çš„ Web åº”ç”¨ç¨‹åºåˆ›å»ºä¸€ä¸ªæ–°çš„ API å¯†é’¥ã€‚
- en: If one of your products has a security breach, you can then just destroy the
    key in your OpenAI account without affecting your other apps.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çš„æŸä¸ªäº§å“å‘ç”Ÿäº†å®‰å…¨æ¼æ´ï¼Œä½ å¯ä»¥åªé”€æ¯ OpenAI è´¦æˆ·ä¸­çš„å¯†é’¥ï¼Œè€Œä¸ä¼šå½±å“å…¶ä»–åº”ç”¨ã€‚
- en: 'You should not write this key directly in your PHP file but use an OS environment
    variable to store it. For instance, with Ubuntu/Debian, run:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸åº”è¯¥ç›´æ¥åœ¨ PHP æ–‡ä»¶ä¸­å†™å…¥è¿™ä¸ªå¯†é’¥ï¼Œè€Œæ˜¯ä½¿ç”¨æ“ä½œç³»ç»Ÿç¯å¢ƒå˜é‡æ¥å­˜å‚¨å®ƒã€‚ä¾‹å¦‚ï¼Œåœ¨ Ubuntu/Debian ä¸Šï¼Œè¿è¡Œï¼š
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In your PHP script you can get the value of this environment variable with:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½ çš„ PHP è„šæœ¬ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è·å–è¿™ä¸ªç¯å¢ƒå˜é‡çš„å€¼ï¼š
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you donâ€™t have access to your OS environment variables, the simplest alternative
    is to define a PHP constant in a separate file that you will require in all your
    PHP scripts using the API.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ— æ³•è®¿é—®æ“ä½œç³»ç»Ÿç¯å¢ƒå˜é‡ï¼Œæœ€ç®€å•çš„æ›¿ä»£æ–¹æ¡ˆæ˜¯åœ¨ä¸€ä¸ªå•ç‹¬çš„æ–‡ä»¶ä¸­å®šä¹‰ä¸€ä¸ª PHP å¸¸é‡ï¼Œå¹¶åœ¨æ‰€æœ‰ä½¿ç”¨ API çš„ PHP è„šæœ¬ä¸­å¼•å…¥è¯¥æ–‡ä»¶ã€‚
- en: 'For instance, create a file â€œkey.phpâ€, preferably not in your website''s main
    directory, and write:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåˆ›å»ºä¸€ä¸ªæ–‡ä»¶â€œkey.phpâ€ï¼Œæœ€å¥½ä¸è¦æ”¾åœ¨ä½ ç½‘ç«™çš„ä¸»ç›®å½•ä¸­ï¼Œå¹¶å†™å…¥ï¼š
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then write the following at the top of all your files that will use the API:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨æ‰€æœ‰å°†ä½¿ç”¨ API çš„æ–‡ä»¶é¡¶éƒ¨å†™å…¥ä»¥ä¸‹å†…å®¹ï¼š
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Completion tasks with GPT models in PHP
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GPT æ¨¡å‹çš„ PHP è¡¥å…¨ä»»åŠ¡
- en: OpenAI PHP client supports all the tasks accessible through OpenAI API. In this
    article, I will focus on â€œcompletion tasksâ€ using GPT models.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI PHP å®¢æˆ·ç«¯æ”¯æŒé€šè¿‡ OpenAI API è®¿é—®çš„æ‰€æœ‰ä»»åŠ¡ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†é‡ç‚¹è®¨è®ºä½¿ç”¨ GPT æ¨¡å‹çš„â€œè¡¥å…¨ä»»åŠ¡â€ã€‚
- en: A completion task is a task in which we **prompt** the model with a text and
    the API answers by adding text after this prompt.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¥å…¨ä»»åŠ¡æ˜¯æŒ‡æˆ‘ä»¬ **æç¤º** æ¨¡å‹ä¸€ä¸ªæ–‡æœ¬ï¼ŒAPI é€šè¿‡åœ¨æ­¤æç¤ºåæ·»åŠ æ–‡æœ¬æ¥ä½œå‡ºå›åº”ã€‚
- en: 'There are two different types of completion tasks proposed by the API:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: API æä¾›äº†ä¸¤ç§ä¸åŒç±»å‹çš„è¡¥å…¨ä»»åŠ¡ï¼š
- en: 'standard: a GPT-3 or GPT-4 model is prompted and then generates tokens following
    this prompt'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'standard: æç¤º GPT-3 æˆ– GPT-4 æ¨¡å‹å¹¶ç”Ÿæˆè·Ÿéšè¯¥æç¤ºçš„ tokens'
- en: 'chat: Given a list of messages describing a conversation history, the model
    will return a response. So here, the prompt is a set of messages with information
    about whether it was written by the model or the user.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'chat: ç»™å®šä¸€ä¸ªæè¿°å¯¹è¯å†å²çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¨¡å‹å°†è¿”å›ä¸€ä¸ªå“åº”ã€‚å› æ­¤ï¼Œè¿™é‡Œçš„æç¤ºæ˜¯ä¸€ç»„åŒ…å«å…³äºæ˜¯æ¨¡å‹è¿˜æ˜¯ç”¨æˆ·å†™çš„ä¿¡æ¯çš„æ¶ˆæ¯ã€‚'
- en: I will demonstrate how to use the OpenAI PHP client for these two types of tasks.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ OpenAI PHP å®¢æˆ·ç«¯æ¥å®Œæˆè¿™ä¸¤ç§ç±»å‹çš„ä»»åŠ¡ã€‚
- en: Completion task with GPT-3
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GPT-3 å®Œæˆä»»åŠ¡
- en: First, we need an objective. What do we want the GPT model to accomplish?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªç›®æ ‡ã€‚æˆ‘ä»¬å¸Œæœ› GPT æ¨¡å‹å®Œæˆä»€ä¹ˆï¼Ÿ
- en: For this article, letâ€™s say that our goal is to â€œtranslateâ€ text into emojis.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬å¯ä»¥è®¾å®šç›®æ ‡æ˜¯â€œå°†â€æ–‡æœ¬ç¿»è¯‘æˆè¡¨æƒ…ç¬¦å·ã€‚
- en: One of the most critical steps when using GPT models is to find a good prompt
    for our task. If your prompt is not good, the modelâ€™s answer wonâ€™t be great either.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GPT æ¨¡å‹æ—¶æœ€å…³é”®çš„æ­¥éª¤ä¹‹ä¸€æ˜¯æ‰¾åˆ°é€‚åˆæˆ‘ä»¬ä»»åŠ¡çš„è‰¯å¥½æç¤ºã€‚å¦‚æœä½ çš„æç¤ºä¸å¥½ï¼Œæ¨¡å‹çš„å›ç­”ä¹Ÿä¸ä¼šå¾ˆå‡ºè‰²ã€‚
- en: '*Whatâ€™s a good prompt?*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä»€ä¹ˆæ˜¯å¥½çš„æç¤ºï¼Ÿ*'
- en: Prompt engineering is a very active research area. I wonâ€™t tackle this topic
    here but I plan to do it in my next article.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå·¥ç¨‹æ˜¯ä¸€ä¸ªéå¸¸æ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚æˆ‘ä¸ä¼šåœ¨è¿™é‡Œè®¨è®ºè¿™ä¸ªè¯é¢˜ï¼Œä½†æˆ‘è®¡åˆ’åœ¨æˆ‘çš„ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­è¿›è¡Œæ¢è®¨ã€‚
- en: 'For our task, [inspired by previous machine translation work using large language
    models](https://medium.com/towards-data-science/translate-with-chatgpt-f85609996a7f),
    I propose the following prompt that gave reasonably good results:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬çš„ä»»åŠ¡ï¼Œ[å—åˆ°ä¹‹å‰ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„æœºå™¨ç¿»è¯‘å·¥ä½œçš„å¯å‘](https://medium.com/towards-data-science/translate-with-chatgpt-f85609996a7f)ï¼Œæˆ‘æå‡ºäº†ä»¥ä¸‹æç¤ºï¼Œå–å¾—äº†ç›¸å½“ä¸é”™çš„ç»“æœï¼š
- en: 'Translate the following text into emoji:'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè¡¨æƒ…ç¬¦å·ï¼š
- en: ''
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[TXT]'
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[TXT]'
- en: Where [TXT] will be replaced by the text to translate into emojis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ [TXT] å°†è¢«æ›¿æ¢ä¸ºè¦ç¿»è¯‘æˆè¡¨æƒ…ç¬¦å·çš„æ–‡æœ¬ã€‚
- en: This prompt has the advantage to be short. It wonâ€™t cost much to use it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæç¤ºçš„ä¼˜ç‚¹æ˜¯ç®€çŸ­ã€‚ä½¿ç”¨å®ƒä¸ä¼šèŠ±è´¹å¤ªå¤šã€‚
- en: 'For example, we will try to translate into emojis the following text:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†å°è¯•å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè¡¨æƒ…ç¬¦å·ï¼š
- en: '*I would like a hamburger without onions.*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*æˆ‘æƒ³è¦ä¸€ä¸ªä¸åŠ æ´‹è‘±çš„æ±‰å ¡ã€‚*'
- en: 'So our prompt becomes:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬çš„æç¤ºå˜æˆäº†ï¼š
- en: 'Translate the following text into emoji:'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè¡¨æƒ…ç¬¦å·ï¼š
- en: ''
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I would like a hamburger without onions.
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³è¦ä¸€ä¸ªä¸åŠ æ´‹è‘±çš„æ±‰å ¡ã€‚
- en: 'With the OpenAI PHP client, we can do this with the following code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ OpenAI PHP å®¢æˆ·ç«¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç å®ç°ï¼š
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this code, I assume you are in the root directory of your website.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä»£ç ä¸­ï¼Œæˆ‘å‡è®¾ä½ åœ¨ä½ çš„ç½‘ç«™çš„æ ¹ç›®å½•ä¸‹ã€‚
- en: 'It should print a sequence of emojis. I obtained this one:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåº”è¯¥æ‰“å°ä¸€ç³»åˆ—è¡¨æƒ…ç¬¦å·ã€‚æˆ‘å¾—åˆ°äº†è¿™ä¸ªï¼š
- en: '*ğŸ”ğŸš«ğŸ§…*'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ğŸ”ğŸš«ğŸ§…*'
- en: You may get a different sequence since GPT models are â€œ*non-deterministic*â€.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¼šå¾—åˆ°ä¸åŒçš„åºåˆ—ï¼Œå› ä¸º GPT æ¨¡å‹æ˜¯â€œ*éç¡®å®šæ€§çš„*â€ã€‚
- en: I used the â€œtext-davinci-003â€ GPT model which is the most powerful GPT-3 model.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨äº†â€œtext-davinci-003â€ GPT æ¨¡å‹ï¼Œè¿™æ˜¯æœ€å¼ºå¤§çš„ GPT-3 æ¨¡å‹ã€‚
- en: You can use a cheaper GPT model if your task is very simple. For instance, we
    can try to replace the model â€œtext-davinci-003â€ with â€œadaâ€.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çš„ä»»åŠ¡éå¸¸ç®€å•ï¼Œä½ å¯ä»¥ä½¿ç”¨æ›´ä¾¿å®œçš„ GPT æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ç”¨â€œadaâ€æ›¿æ¢â€œtext-davinci-003â€æ¨¡å‹ã€‚
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'I got the following answer:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¾—åˆ°äº†ä»¥ä¸‹å›ç­”ï¼š
- en: For example, enter This is the text â€œLooking For a hamburger
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¾“å…¥ è¿™æ˜¯æ–‡æœ¬ â€œLooking For a hamburgerâ€
- en: Yes, this is quite bad. There arenâ€™t any emojis in this response. Choosing the
    right model is the most critical choice you will have to make when integrating
    the OpenAI API into your product.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œè¿™ç›¸å½“ç³Ÿç³•ã€‚è¿™ä¸ªå›åº”ä¸­æ²¡æœ‰ä»»ä½•è¡¨æƒ…ç¬¦å·ã€‚é€‰æ‹©æ­£ç¡®çš„æ¨¡å‹æ˜¯ä½ åœ¨å°† OpenAI API é›†æˆåˆ°äº§å“ä¸­æ—¶å¿…é¡»åšå‡ºçš„æœ€å…³é”®çš„é€‰æ‹©ã€‚
- en: If you choose an old or small model, the result will be of low quality and may
    not complete the task requested.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ é€‰æ‹©ä¸€ä¸ªæ—§çš„æˆ–å°å‹çš„æ¨¡å‹ï¼Œç»“æœä¼šå¾ˆä½è´¨é‡ï¼Œå¹¶ä¸”å¯èƒ½æ— æ³•å®Œæˆè¯·æ±‚çš„ä»»åŠ¡ã€‚
- en: If you choose a bigger model, you may get the best results but for a higher
    cost.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ é€‰æ‹©ä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹ï¼Œä½ å¯èƒ½ä¼šå¾—åˆ°æœ€å¥½çš„ç»“æœï¼Œä½†æˆæœ¬ä¼šæ›´é«˜ã€‚
- en: You will have to try several models to figure out which is the best option given
    your objective. As a starting point, OpenAI provides some usage [suggestions along
    with a list of available models](https://platform.openai.com/docs/models/overview).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦å°è¯•å¤šä¸ªæ¨¡å‹ï¼Œä»¥ç¡®å®šå“ªä¸ªæ˜¯æœ€é€‚åˆä½ ç›®æ ‡çš„é€‰é¡¹ã€‚ä½œä¸ºèµ·ç‚¹ï¼ŒOpenAI æä¾›äº†ä¸€äº›ä½¿ç”¨[å»ºè®®å’Œå¯ç”¨æ¨¡å‹åˆ—è¡¨](https://platform.openai.com/docs/models/overview)ã€‚
- en: In addition to the model name and prompt, the completion task can take many
    more parameters. They are all described in the [API documentation](https://platform.openai.com/docs/api-reference/completions/create).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†æ¨¡å‹åç§°å’Œæç¤ºï¼Œå®Œæˆä»»åŠ¡è¿˜å¯ä»¥æ¥å—æ›´å¤šå‚æ•°ã€‚å®ƒä»¬éƒ½åœ¨[API æ–‡æ¡£](https://platform.openai.com/docs/api-reference/completions/create)ä¸­æè¿°ã€‚
- en: 'We can precise for instance the maximum number of tokens in the response as
    follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æŒ‡å®šä¾‹å¦‚å“åº”ä¸­çš„æœ€å¤§æ ‡è®°æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This shouldnâ€™t generate anything but 1 line break. *Why?*
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸åº”è¯¥ç”Ÿæˆä»»ä½•å†…å®¹ï¼Œåªæœ‰ 1 è¡Œç©ºç™½ã€‚*ä¸ºä»€ä¹ˆï¼Ÿ*
- en: 1 emoji consists of 3 tokens for text-davinci-003\. So if we set â€˜max_tokensâ€™
    to 2, the model canâ€™t even generate 1 emoji.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 1 ä¸ªè¡¨æƒ…ç¬¦å·ç”± text-davinci-003 ä¸­çš„ 3 ä¸ªæ ‡è®°ç»„æˆã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬å°†â€˜max_tokensâ€™è®¾ç½®ä¸º 2ï¼Œæ¨¡å‹ç”šè‡³æ— æ³•ç”Ÿæˆ 1 ä¸ªè¡¨æƒ…ç¬¦å·ã€‚
- en: '*How do I know an emoji is made of 3 tokens?*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*æˆ‘æ€ä¹ˆçŸ¥é“ä¸€ä¸ªè¡¨æƒ…ç¬¦å·ç”± 3 ä¸ªæ ‡è®°ç»„æˆï¼Ÿ*'
- en: I simply checked it in the playground of my OpenAI user account. For instance,
    if you put there â€œğŸ”ğŸš«ğŸ§…â€, the model will count 9 tokens.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨æˆ‘çš„ OpenAI ç”¨æˆ·è´¦æˆ·çš„ playground ä¸­ç®€å•æ£€æŸ¥äº†ä¸€ä¸‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨é‚£é‡Œè¾“å…¥â€œğŸ”ğŸš«ğŸ§…â€ï¼Œæ¨¡å‹ä¼šè®¡ç®—å‡º 9 ä¸ª tokensã€‚
- en: Moreover, the GPT model generates a line break before the sequence of emojis.
    It counts as an additional token. In total, GPT answered me with 10 tokens.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼ŒGPT æ¨¡å‹åœ¨ emoji åºåˆ—å‰ç”Ÿæˆä¸€ä¸ªæ¢è¡Œç¬¦ã€‚å®ƒç®—ä½œä¸€ä¸ªé¢å¤–çš„ tokenã€‚æ€»çš„æ¥è¯´ï¼ŒGPT ç»™äº†æˆ‘ 10 ä¸ª tokens çš„å›ç­”ã€‚
- en: Note that the â€œ$resultâ€ variable contains all this information. We will have
    a look at it in the next part below.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œâ€œ$resultâ€å˜é‡åŒ…å«æ‰€æœ‰è¿™äº›ä¿¡æ¯ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢çš„ä¸‹ä¸€éƒ¨åˆ†ä¸­æŸ¥çœ‹å®ƒã€‚
- en: But before that, letâ€™s have a look at the chat completion task.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨æ­¤ä¹‹å‰ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹èŠå¤©å®Œæˆä»»åŠ¡ã€‚
- en: Chat completion task
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èŠå¤©å®Œæˆä»»åŠ¡
- en: Chat completion tasks are slightly different from what we did with GPT-3\. Chat
    tasks are powered by gpt-3.5-turbo, which also powers ChatGPT.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: èŠå¤©å®Œæˆä»»åŠ¡ä¸æˆ‘ä»¬ä½¿ç”¨ GPT-3 æ—¶ç•¥æœ‰ä¸åŒã€‚èŠå¤©ä»»åŠ¡ç”± gpt-3.5-turbo æä¾›æ”¯æŒï¼Œå®ƒä¹Ÿä¸º ChatGPT æä¾›æ”¯æŒã€‚
- en: With gpt-3.5-turbo, the â€œpromptâ€ parameter is replaced by â€œmessagesâ€.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ gpt-3.5-turbo ä¸­ï¼Œâ€œpromptâ€ å‚æ•°è¢«â€œmessagesâ€ æ›¿ä»£ã€‚
- en: 'Technically, â€œmessagesâ€ are associative arrays with two required keys, and
    one optional, as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æŠ€æœ¯ä¸Šè®²ï¼Œâ€œmessagesâ€ æ˜¯åŒ…å«ä¸¤ä¸ªå¿…éœ€é”®å’Œä¸€ä¸ªå¯é€‰é”®çš„å…³è”æ•°ç»„ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: 'role (required): Can be either â€œsystemâ€, â€œassistantâ€, or â€œuserâ€. At the time
    I write this article, â€œsystemâ€ is almost ignored according to OpenAI documentation.
    It leaves â€œassistantâ€ which is the model, and â€œuserâ€ which is a human.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'role (required): å¯ä»¥æ˜¯â€œsystemâ€ï¼Œâ€œassistantâ€æˆ–â€œuserâ€ã€‚åœ¨æˆ‘æ’°å†™æœ¬æ–‡æ—¶ï¼ŒOpenAI æ–‡æ¡£ä¸­å‡ ä¹å¿½ç•¥äº†â€œsystemâ€ã€‚å‰©ä¸‹çš„æ˜¯â€œassistantâ€å³æ¨¡å‹ï¼Œä»¥åŠâ€œuserâ€å³äººç±»ã€‚'
- en: 'content (required): This is where we put our prompt, or the context of our
    prompt, for instance, the chat history.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'content (required): è¿™æ˜¯æˆ‘ä»¬æ”¾ç½®æç¤ºæˆ–æç¤ºçš„ä¸Šä¸‹æ–‡çš„åœ°æ–¹ï¼Œä¾‹å¦‚èŠå¤©å†å²ã€‚'
- en: 'name (optional): If you want to give a specific name to the author of the message.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'name (optional): å¦‚æœä½ æƒ³ç»™æ¶ˆæ¯çš„ä½œè€…æŒ‡å®šä¸€ä¸ªç‰¹å®šçš„åå­—ã€‚'
- en: The length and number of messages are virtually unlimited. That way, the gpt-3.5-turbo
    can accept a very long chat history as input.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯çš„é•¿åº¦å’Œæ•°é‡å‡ ä¹æ˜¯æ— é™çš„ã€‚è¿™æ ·ï¼Œgpt-3.5-turbo å¯ä»¥æ¥å—éå¸¸é•¿çš„èŠå¤©å†å²ä½œä¸ºè¾“å…¥ã€‚
- en: 'Chat completion can perform similar tasks as the standard GPT-3\. In the documentation,
    OpenAI wrote the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: èŠå¤©å®Œæˆå¯ä»¥æ‰§è¡Œä¸æ ‡å‡† GPT-3 ç›¸ä¼¼çš„ä»»åŠ¡ã€‚åœ¨æ–‡æ¡£ä¸­ï¼ŒOpenAI å†™äº†å¦‚ä¸‹å†…å®¹ï¼š
- en: Because `gpt-3.5-turbo` performs at a similar capability to `text-davinci-003`
    but at 10% the price per token, we recommend `gpt-3.5-turbo` for most use cases.
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å› ä¸º `gpt-3.5-turbo` çš„èƒ½åŠ›ä¸ `text-davinci-003` ç›¸ä¼¼ï¼Œä½†æ¯ä¸ª token çš„ä»·æ ¼ä»…ä¸º 10%ï¼Œæ‰€ä»¥æˆ‘ä»¬æ¨èåœ¨å¤§å¤šæ•°ç”¨ä¾‹ä¸­ä½¿ç”¨
    `gpt-3.5-turbo`ã€‚
- en: Letâ€™s check it with our task of translating text into emojis.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨ç¿»è¯‘æ–‡æœ¬ä¸º emoji çš„ä»»åŠ¡æ¥æ£€æŸ¥å®ƒã€‚
- en: 'We only have a few modifications to perform:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€è¿›è¡Œå°‘é‡ä¿®æ”¹ï¼š
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: I obtained the same answer as with text-davinci-003, â€œğŸ”ğŸš«ğŸ§…â€, but at 10% of text-davinci-003's
    price per token.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è·å¾—äº†ä¸ text-davinci-003 ç›¸åŒçš„ç­”æ¡ˆï¼Œâ€œğŸ”ğŸš«ğŸ§…â€ï¼Œä½†ä»·æ ¼ä»…ä¸º text-davinci-003 çš„ 10%ã€‚
- en: Now that you know how to communicate with OpenAI API in PHP, we can have a closer
    look at what the API returns. As we will see, there are useful data in the response
    that we can use to monitor the API cost, keep track of the users' activity (e.g.,
    to flag prohibited behavior), etc.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ çŸ¥é“å¦‚ä½•åœ¨ PHP ä¸­ä¸ OpenAI API é€šä¿¡ï¼Œæˆ‘ä»¬å¯ä»¥æ›´ä»”ç»†åœ°æŸ¥çœ‹ API è¿”å›çš„å†…å®¹ã€‚æ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œå“åº”ä¸­åŒ…å«æœ‰ç”¨çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ¥ç›‘æ§
    API æˆæœ¬ã€è·Ÿè¸ªç”¨æˆ·æ´»åŠ¨ï¼ˆä¾‹å¦‚æ ‡è®°ç¦æ­¢çš„è¡Œä¸ºï¼‰ç­‰ã€‚
- en: Interpreting OpenAI API response with PHP
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ PHP è§£è¯» OpenAI API å“åº”
- en: 'We can make a printable version of the â€œ$resultâ€ variables like this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è¿™æ ·åˆ¶ä½œâ€œ$resultâ€å˜é‡çš„å¯æ‰“å°ç‰ˆæœ¬ï¼š
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For a chat completion task, it will print this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºèŠå¤©å®Œæˆä»»åŠ¡ï¼Œå®ƒå°†æ‰“å°å‡ºå¦‚ä¸‹å†…å®¹ï¼š
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*Note: I manually masked part of the â€œidâ€.*'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šæˆ‘æ‰‹åŠ¨é®è”½äº†éƒ¨åˆ†â€œidâ€ã€‚*'
- en: 'We have the following entries:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ä»¥ä¸‹æ¡ç›®ï¼š
- en: 'id: A unique ID assigned by OpenAI to the response. This information can help
    to track interactions between the API and your users.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'id: OpenAI ä¸ºå“åº”åˆ†é…çš„å”¯ä¸€ IDã€‚è¿™äº›ä¿¡æ¯å¯ä»¥å¸®åŠ©è·Ÿè¸ª API å’Œç”¨æˆ·ä¹‹é—´çš„äº¤äº’ã€‚'
- en: 'object: The type of task performed.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'object: æ‰§è¡Œçš„ä»»åŠ¡ç±»å‹ã€‚'
- en: 'created: The timestamp of the creation of the response.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'created: å“åº”åˆ›å»ºçš„æ—¶é—´æˆ³ã€‚'
- en: 'model: The model used to generate the response.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'model: ç”¨äºç”Ÿæˆå“åº”çš„æ¨¡å‹ã€‚'
- en: 'choices: By default, you will get only one message for a chat completion task,
    unless you change the â€œnâ€ option when calling the API.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'choices: é»˜è®¤æƒ…å†µä¸‹ï¼Œä½ å°†ä»…è·å¾—ä¸€ä¸ªèŠå¤©å®Œæˆä»»åŠ¡çš„æ¶ˆæ¯ï¼Œé™¤éä½ åœ¨è°ƒç”¨ API æ—¶æ›´æ”¹â€œnâ€é€‰é¡¹ã€‚'
- en: 'index: The index, starting at 0, of the message generated.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'index: ä» 0 å¼€å§‹çš„æ¶ˆæ¯ç´¢å¼•ã€‚'
- en: 'message: Information about the message generated.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'message: å…³äºç”Ÿæˆçš„æ¶ˆæ¯çš„ä¿¡æ¯ã€‚'
- en: 'role: The role of the author of the message.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'role: æ¶ˆæ¯å‘é€è€…çš„è§’è‰²ã€‚'
- en: 'content: The message itself.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'content: æ¶ˆæ¯æœ¬èº«ã€‚'
- en: 'finish_reason: The reason why the API stopped the generation of the message.
    By default it will be â€œstopâ€, i.e., the model stopped the generation without any
    constraints. It can change if you indicated a â€œstopâ€ parameter when calling the
    API. The model would then stop the generation after generating one of the tokens
    you mentioned in â€œstopâ€.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: finish_reasonï¼šAPI åœæ­¢ç”Ÿæˆæ¶ˆæ¯çš„åŸå› ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°†æ˜¯â€œstopâ€ï¼Œå³æ¨¡å‹åœ¨æ²¡æœ‰ä»»ä½•çº¦æŸçš„æƒ…å†µä¸‹åœæ­¢ç”Ÿæˆã€‚å¦‚æœä½ åœ¨è°ƒç”¨ API æ—¶æŒ‡å®šäº†â€œstopâ€å‚æ•°ï¼Œåˆ™å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚ç„¶åï¼Œæ¨¡å‹ä¼šåœ¨ç”Ÿæˆäº†ä½ åœ¨â€œstopâ€ä¸­æåˆ°çš„ä¸€ä¸ªæ ‡è®°ååœæ­¢ç”Ÿæˆã€‚
- en: 'usage: Information about the length in tokens. It can be used to monitor the
    API cost.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: usageï¼šæœ‰å…³ä»¤ç‰Œé•¿åº¦çš„ä¿¡æ¯ã€‚å®ƒå¯ä»¥ç”¨äºç›‘æ§ API æˆæœ¬ã€‚
- en: 'prompt_tokens: The number of tokens in your prompt.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: prompt_tokensï¼šä½ æç¤ºä¸­çš„ä»¤ç‰Œæ•°é‡ã€‚
- en: 'completion_tokens: The number of tokens in the message generated by the API.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: completion_tokensï¼šAPI ç”Ÿæˆçš„æ¶ˆæ¯ä¸­çš„ä»¤ç‰Œæ•°é‡ã€‚
- en: 'total_tokens: The sum of â€œprompt_tokensâ€ and â€œcompletion_tokensâ€.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: total_tokensï¼š â€œprompt_tokensâ€å’Œâ€œcompletion_tokensâ€çš„æ€»å’Œã€‚
- en: The most important fields are â€œchoicesâ€, since this is what you will have to
    deliver to your users, and â€œusageâ€ since this is the only metric that will tell
    you how much it cost to generate this answer.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€é‡è¦çš„å­—æ®µæ˜¯â€œchoicesâ€ï¼Œå› ä¸ºè¿™æ˜¯ä½ å°†è¦äº¤ä»˜ç»™ç”¨æˆ·çš„å†…å®¹ï¼Œä»¥åŠâ€œusageâ€ï¼Œå› ä¸ºè¿™æ˜¯å”¯ä¸€èƒ½å¤Ÿå‘Šè¯‰ä½ ç”Ÿæˆè¿™ä¸ªç­”æ¡ˆèŠ±è´¹äº†å¤šå°‘çš„æŒ‡æ ‡ã€‚
- en: To know the exact cost of an API call, you have to multiply the value of â€œtotal_tokensâ€
    by the cost of the model per token. Note that OpenAI shows pricing for 1,000 tokens
    so you will have to divide this number by 1,000 to get the price per token.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¦çŸ¥é“ API è°ƒç”¨çš„ç¡®åˆ‡æˆæœ¬ï¼Œä½ å¿…é¡»å°†â€œtotal_tokensâ€çš„å€¼ä¹˜ä»¥æ¯ä¸ªä»¤ç‰Œçš„æ¨¡å‹æˆæœ¬ã€‚æ³¨æ„ OpenAI æ˜¾ç¤ºçš„æ˜¯ 1,000 ä¸ªä»¤ç‰Œçš„ä»·æ ¼ï¼Œå› æ­¤ä½ éœ€è¦å°†è¿™ä¸ªæ•°å­—é™¤ä»¥
    1,000 æ¥è·å¾—æ¯ä¸ªä»¤ç‰Œçš„ä»·æ ¼ã€‚
- en: 'For instance, if we use a model costing $0.002 per 1,000 tokens, and â€œtotal_tokensâ€
    is 32, we can compute the total cost as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨æ¯ 1,000 ä¸ªä»¤ç‰ŒèŠ±è´¹ $0.002 çš„æ¨¡å‹ï¼Œè€Œâ€œtotal_tokensâ€ä¸º 32ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼è®¡ç®—æ€»æˆæœ¬ï¼š
- en: 0.002 / 1000 * 32 = 0.000064
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 0.002 / 1000 * 32 = 0.000064
- en: This API call would cost $0.000064.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ª API è°ƒç”¨å°†èŠ±è´¹ $0.000064ã€‚
- en: The response fields of a standard GPT-3 completion are almost identical to the
    fields of the chat completion task.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡å‡† GPT-3 å®Œæˆçš„å“åº”å­—æ®µä¸èŠå¤©å®Œæˆä»»åŠ¡çš„å­—æ®µå‡ ä¹ç›¸åŒã€‚
- en: 'The only notable difference is that a â€œtext.completionâ€ task can also return
    the log probabilities of the *t* most probable tokens. You can indicate â€œtâ€ when
    you call the API with the â€œlogprobsâ€ parameter. The maximum value of *t* is 5\.
    *Note: OpenAIâ€™s API reference indicates that you can manually request OpenAI a
    greater number if your application needs it.*'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å”¯ä¸€æ˜¾è‘—çš„åŒºåˆ«æ˜¯ï¼Œâ€œtext.completionâ€ä»»åŠ¡è¿˜å¯ä»¥è¿”å› *t* ä¸ªæœ€å¯èƒ½çš„ä»¤ç‰Œçš„æ—¥å¿—æ¦‚ç‡ã€‚ä½ å¯ä»¥åœ¨è°ƒç”¨ API æ—¶ä½¿ç”¨â€œlogprobsâ€å‚æ•°æ¥æŒ‡ç¤ºâ€œtâ€ã€‚*t*
    çš„æœ€å¤§å€¼æ˜¯ 5ã€‚*æ³¨æ„ï¼šOpenAI çš„ API å‚è€ƒæ–‡æ¡£è¡¨ç¤ºï¼Œå¦‚æœä½ çš„åº”ç”¨éœ€è¦æ›´å¤§çš„å€¼ï¼Œä½ å¯ä»¥æ‰‹åŠ¨è¯·æ±‚ OpenAIã€‚*
- en: Whatâ€™s next for an Integration in a web app/website?
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨ç½‘é¡µåº”ç”¨ç¨‹åº/ç½‘ç«™ä¸­é›†æˆçš„ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆï¼Ÿ
- en: We have learned how to communicate with OpenAI API in PHP. Your online service
    can now exploit all the power of GPT models.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»å­¦ä¼šäº†å¦‚ä½•ç”¨ PHP ä¸ OpenAI API é€šä¿¡ã€‚ä½ çš„åœ¨çº¿æœåŠ¡ç°åœ¨å¯ä»¥åˆ©ç”¨ GPT æ¨¡å‹çš„å…¨éƒ¨åŠŸèƒ½ã€‚
- en: The next step would be to implement the front end. You donâ€™t need to do something
    over-complicated for this. A simple AJAX script, using jQuery for instance, would
    be enough to asynchronously get the response from the PHP script that made the
    API call.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥å°†æ˜¯å®ç°å‰ç«¯ã€‚ä½ ä¸éœ€è¦ä¸ºæ­¤åšè¿‡äºå¤æ‚çš„äº‹æƒ…ã€‚ä¸€ä¸ªç®€å•çš„ AJAX è„šæœ¬ï¼Œä¾‹å¦‚ä½¿ç”¨ jQueryï¼Œå°±è¶³å¤Ÿå¼‚æ­¥åœ°ä»æ‰§è¡Œ API è°ƒç”¨çš„ PHP è„šæœ¬ä¸­è·å–å“åº”ã€‚
- en: 'It can be as simple as this:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå¯ä»¥ç®€å•åˆ°è¿™æ ·ï¼š
- en: '[PRE11]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This would print the content of the chat completion inside an HTML object with
    the id attribute set to â€œmy_GPT_responseâ€.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æŠŠèŠå¤©å®Œæˆçš„å†…å®¹æ‰“å°åœ¨ä¸€ä¸ª HTML å¯¹è±¡ä¸­ï¼Œè¯¥å¯¹è±¡çš„ id å±æ€§è®¾ç½®ä¸ºâ€œmy_GPT_responseâ€ã€‚
- en: 'Your PHP script must receive the â€œpromptâ€ as a $_POST variable, and the API
    answer should be encoded into a JSON object, as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„ PHP è„šæœ¬å¿…é¡»æ¥æ”¶â€œpromptâ€ä½œä¸º $_POST å˜é‡ï¼Œå¹¶ä¸” API å›ç­”åº”è¯¥ç¼–ç ä¸º JSON å¯¹è±¡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE12]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To conclude this article, I should mention once again that you must always check
    what you are sending to the API to ensure that you are not violating the policies
    and terms of use of OpenAI.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘åº”è¯¥å†æ¬¡æåˆ°ï¼Œä½ å¿…é¡»å§‹ç»ˆæ£€æŸ¥ä½ å‘é€ç»™ API çš„å†…å®¹ï¼Œä»¥ç¡®ä¿ä½ æ²¡æœ‰è¿å OpenAI çš„æ”¿ç­–å’Œä½¿ç”¨æ¡æ¬¾ã€‚
- en: You can exploit the [moderation model](https://platform.openai.com/docs/api-reference/moderations),
    free of use, proposed by OpenAI that can flag unsafe content before you send it
    to a GPT model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åˆ©ç”¨ [å®¡æŸ¥æ¨¡å‹](https://platform.openai.com/docs/api-reference/moderations)ï¼Œè¿™æ˜¯
    OpenAI æä¾›çš„å…è´¹æœåŠ¡ï¼Œå¯ä»¥åœ¨å°†å†…å®¹å‘é€åˆ° GPT æ¨¡å‹ä¹‹å‰æ ‡è®°ä¸å®‰å…¨çš„å†…å®¹ã€‚
- en: It is also important to check the age of your users. [OpenAIâ€™s terms of use](https://openai.com/policies/terms-of-use)
    prohibit the use of their services for children under 13 while children under
    18 can use the services only with the supervision of an adult.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯æ£€æŸ¥ç”¨æˆ·çš„å¹´é¾„ã€‚[OpenAI çš„ä½¿ç”¨æ¡æ¬¾](https://openai.com/policies/terms-of-use)ç¦æ­¢13å²ä»¥ä¸‹çš„å„¿ç«¥ä½¿ç”¨å…¶æœåŠ¡ï¼Œè€Œ18å²ä»¥ä¸‹çš„å„¿ç«¥åªèƒ½åœ¨æˆäººç›‘ç£ä¸‹ä½¿ç”¨è¿™äº›æœåŠ¡ã€‚
- en: '*If you like this article and would be interested to read the next ones, the
    best way to support my work is to become a Medium member using this link:*'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« å¹¶ä¸”å¯¹æ¥ä¸‹æ¥çš„æ–‡ç« æ„Ÿå…´è¶£ï¼Œæ”¯æŒæˆ‘å·¥ä½œçš„æœ€ä½³æ–¹å¼æ˜¯é€šè¿‡è¿™ä¸ªé“¾æ¥æˆä¸º Medium ä¼šå‘˜ï¼š*'
- en: '[](https://medium.com/@bnjmn_marie/membership?source=post_page-----517ea20266d7--------------------------------)
    [## Join Medium with my referral link - Benjamin Marie'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bnjmn_marie/membership?source=post_page-----517ea20266d7--------------------------------)
    [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium - æœ¬æ°æ˜Â·ç›ä¸½'
- en: Join Our AI Community and Get Access to Cutting-Edge Research This blog aims
    to demystify recent advances in AI forâ€¦
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„AIç¤¾åŒºï¼Œè·å–å‰æ²¿ç ”ç©¶æˆæœã€‚æœ¬åšå®¢æ—¨åœ¨æ­ç¤ºæœ€è¿‘åœ¨AIé¢†åŸŸçš„è¿›å±•â€¦â€¦
- en: medium.com](https://medium.com/@bnjmn_marie/membership?source=post_page-----517ea20266d7--------------------------------)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@bnjmn_marie/membership?source=post_page-----517ea20266d7--------------------------------)
- en: '*If you are already a member and want to support this work,* [*just follow
    me on Medium*](https://medium.com/@bnjmn_marie)*.*'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦‚æœä½ å·²ç»æ˜¯ä¼šå‘˜å¹¶å¸Œæœ›æ”¯æŒè¿™é¡¹å·¥ä½œï¼Œ* [*è¯·åœ¨ Medium ä¸Šå…³æ³¨æˆ‘*](https://medium.com/@bnjmn_marie)*ã€‚*'
