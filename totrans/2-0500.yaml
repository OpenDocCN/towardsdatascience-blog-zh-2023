- en: GPT Is an Unreliable Information Store
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT是一个不可靠的信息存储库
- en: 原文：[https://towardsdatascience.com/chatgpt-insists-i-am-dead-and-the-problem-with-language-models-db5a36c22f11](https://towardsdatascience.com/chatgpt-insists-i-am-dead-and-the-problem-with-language-models-db5a36c22f11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chatgpt-insists-i-am-dead-and-the-problem-with-language-models-db5a36c22f11](https://towardsdatascience.com/chatgpt-insists-i-am-dead-and-the-problem-with-language-models-db5a36c22f11)
- en: Understanding the limitations and dangers of large language models
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解大型语言模型的局限性和危险
- en: '[](https://medium.com/@nobleackerson?source=post_page-----db5a36c22f11--------------------------------)[![Noble
    Ackerson](../Images/e89361fc2723b2b08384ace7f081bfed.png)](https://medium.com/@nobleackerson?source=post_page-----db5a36c22f11--------------------------------)[](https://towardsdatascience.com/?source=post_page-----db5a36c22f11--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----db5a36c22f11--------------------------------)
    [Noble Ackerson](https://medium.com/@nobleackerson?source=post_page-----db5a36c22f11--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@nobleackerson?source=post_page-----db5a36c22f11--------------------------------)[![Noble
    Ackerson](../Images/e89361fc2723b2b08384ace7f081bfed.png)](https://medium.com/@nobleackerson?source=post_page-----db5a36c22f11--------------------------------)[](https://towardsdatascience.com/?source=post_page-----db5a36c22f11--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----db5a36c22f11--------------------------------)
    [Noble Ackerson](https://medium.com/@nobleackerson?source=post_page-----db5a36c22f11--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----db5a36c22f11--------------------------------)
    ·9 min read·Feb 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----db5a36c22f11--------------------------------)
    ·阅读时间9分钟·2023年2月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/877f131a65aa9cec5806a78ebd5af18a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/877f131a65aa9cec5806a78ebd5af18a.png)'
- en: “Searching for meaning” Photo by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “寻找意义” 作者拍摄
- en: Large language models (or generative pre-trained transformers, GPT) need more
    reliable information accuracy checks to be considered for Search.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（或生成预训练变换器，GPT）需要更可靠的信息准确性检查，才适合用于搜索。
- en: These models are great at creative applications such as storytelling, art, or
    music and creating privacy-preserving synthetic data for applications.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型在讲故事、艺术、音乐等创造性应用以及为应用创建隐私保护的合成数据方面表现出色。
- en: These models fail, however, at consistent factual accuracy due to [AI hallucinations](https://www.wired.com/story/ai-has-a-hallucination-problem-thats-proving-tough-to-fix/)
    and transfer learning limitations in ChatGPT, Bing Chat, and Google Bard.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些模型由于[AI幻觉](https://www.wired.com/story/ai-has-a-hallucination-problem-thats-proving-tough-to-fix/)和ChatGPT、Bing
    Chat以及Google Bard中的迁移学习限制，无法保持一致的事实准确性。
- en: First, let’s define what AI hallucinations are. There are instances where a
    large language model creates information that is not based on factual evidence
    but may be influenced by its transformer architecture’s bias or erroneous decoding.
    In other words, the model makes up facts, which can be problematic in domains
    where factual accuracy is critical.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义一下什么是AI幻觉。有时，大型语言模型会生成基于不真实证据的信息，这些信息可能受到其变换器架构的偏见或错误解码的影响。换句话说，该模型会编造事实，这在对事实准确性要求严格的领域中可能会造成问题。
- en: Ignoring consistent factual accuracy is dangerous in a world where accurate
    and reliable information is paramount in battling misinformation and disinformation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个准确和可靠的信息对抗虚假信息和错误信息至关重要的世界中，忽视一致的事实准确性是危险的。
- en: Search companies should reconsider “re-inventing search” by mixing Search with
    unfiltered GPT-powered chat modalities to avoid potential harm to public health,
    political stability, or social cohesion.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索公司应该重新考虑“重新发明搜索”，将搜索与未经过滤的GPT驱动聊天模式混合，以避免对公共健康、政治稳定或社会凝聚力的潜在危害。
- en: This article extends this assertion with an example of how ChatGPT is convinced
    that I have been dead for four years and how my obituary, which seems very real,
    highlights the risks of using GPTs for search-based information retrieval. You
    can try it by plugging my name into ChatGPT and then convince it that I’m alive.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本文通过一个例子扩展了这一断言，展示了ChatGPT如何确信我已经去世四年，以及我那看起来非常真实的讣告，突显了使用GPT进行基于搜索的信息检索的风险。你可以尝试在ChatGPT中输入我的名字，然后让它相信我还活着。
- en: A few weeks ago, I decided to dive into some light research after learning that
    Google wiped $100 billion off its market cap because of a rushed demo where Bard,
    the ChatGPT competitor, shared some inaccurate information. The market seems to
    [react negatively to the reliability and trustworthiness of this tech](https://www.cnbc.com/video/2023/02/16/the-new-york-times-kevin-roose-on-his-conversation-with-microsofts-ai-powered-chatbot-bing.html),
    but I don’t feel we’re connecting these concerns with the medium enough.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 几周前，我决定做一些轻度研究，因为我了解到 Google 因为 Bard——ChatGPT 的竞争者——在一次匆忙的演示中分享了一些不准确的信息，从而让其市值蒸发了
    1000 亿美元。市场似乎对这种技术的[可靠性和可信度反应负面](https://www.cnbc.com/video/2023/02/16/the-new-york-times-kevin-roose-on-his-conversation-with-microsofts-ai-powered-chatbot-bing.html)，但我觉得我们并没有充分将这些担忧与媒体联系起来。
- en: 'I decided to “egosurf” on ChatGPT. *Note: I just discovered the word egosurf*.
    We’ve all Googled ourselves before but this time with ChatGPT.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定在 ChatGPT 上“自我搜索”。*注：我刚发现“自我搜索”这个词*。我们都曾在 Google 上搜索过自己，但这次是用 ChatGPT 来搜索。
- en: 'This decision was intentional because what better way to test for factual accuracy
    than to ask it about me? And this decision didn’t disappoint; I consistently got
    the same result: **I learned I was dead.**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个决定是故意的，因为没有比问它关于我的事情更好的事实准确性测试方式了。而且这个决定没有让人失望；我一直得到相同的结果：**我学到我已经死了。**
- en: '![](../Images/7650da69d1d2fed0fdb668108903f6fc.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7650da69d1d2fed0fdb668108903f6fc.png)'
- en: ChatGPT claims I died in 2019
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 声称我在 2019 年去世
- en: '[Here is a truncated copy](https://gist.github.com/stigsfoot/acf985bf3a22c5c46ed787e34f638991)
    of the entire conversation.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[这是整个对话的截取版本](https://gist.github.com/stigsfoot/acf985bf3a22c5c46ed787e34f638991)。'
- en: ChatGPT thinks I’m dead!?
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT 认为我死了！？
- en: ChatGPT insisted I was dead, doubled down when I pushed back and created a whole
    new persona. I now understand why large language models are unreliable information
    stores and why Microsoft Bing should pull the chat modality out from it’s search
    experience.
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ChatGPT 坚持说我已经死了，当我反驳时它更加固执，并创建了一个全新的角色。我现在明白了为什么大型语言模型是不可靠的信息来源，也理解了为什么微软 Bing
    应该将聊天功能从其搜索体验中移除。
- en: Oh… and I also learned had I had created other tech ventures after [my previous
    startup, LynxFit](https://9to5google.com/2014/12/08/google-glass-app-lynxfit-join-apx-labs/).
    It seems confused by what my co-founders and I built at LynxFit, and it makes
    up a whole story that I founded a transportation company in Ghana. Ghana? That’s
    also where I’m from. Wait…**falsehoods mixed with truth is classic misinformation**.
    What’s going on?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 哦……我还了解到，如果我在[我的前一家创业公司 LynxFit](https://9to5google.com/2014/12/08/google-glass-app-lynxfit-join-apx-labs/)之后创建了其他技术企业的话，那就更奇怪了。它似乎对我和我的联合创始人在
    LynxFit 建立的内容感到困惑，编造了一个故事，说我在加纳创办了一家运输公司。加纳？那也是我来自的地方。等等……**虚假与真实混合是经典的虚假信息**。到底发生了什么？
- en: Ok, it got one fact half right and made up pretty much every other fact is upsetting.
    I’m pretty sure I’m still alive. At Lynxfit, I built AR software to track and
    coach users' workouts with Wearables, not a smart jump rope. Also, I’m Ghanaian
    by heritage, but I have never built a transportation app for Ghana.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，它对一个事实半对半错，其他几乎所有事实都是编造的，这让人不安。我很确定我还活着。在 Lynxfit，我开发了 AR 软件来跟踪和指导用户的穿戴式健身训练，而不是一个智能跳绳。此外，我是加纳裔，但我从未为加纳开发过运输应用。
- en: '**All seems plausible, but ole’ Mendacious Menendez over here made up the entire
    thing.**'
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**一切似乎都很合理，但这位“虚伪的门德西斯”编造了整个故事。**'
- en: OpenAI’s documentation clearly states that ChatGPT has techniques to admit its
    mistakes through users' contextual clues or feedback. So naturally, I gave it
    a few contextual clues and feedback to let it know it was “dreaming of a variant
    Earth-Two Noble Ackerson” and not the one from this reality. That did not work,
    and it doubled down and chose to fail harder.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 的文档明确指出，ChatGPT 具备通过用户的上下文线索或反馈承认错误的技术。因此，自然而然地，我给了它一些上下文线索和反馈，告诉它它在“梦见一个变种的
    Earth-Two Noble Ackerson”，而不是来自这个现实的那一个。这并没有奏效，它更加固执，选择了更严重的错误。
- en: '![](../Images/9137bf800f8019d4d3afdc28b3822007.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9137bf800f8019d4d3afdc28b3822007.png)'
- en: ChatGPT doubles down on incorrect facts. Verifying if it thinks its response
    is factual.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 对错误的事实固执己见。验证它是否认为自己的回答是事实。
- en: Um…are you sure? Trying to nudge a chatbot towards being factual is like yelling
    at a PA system that is playing back a recorded message. It is a whacky thing to
    do but for “research” I spent an hour with this thing. After all, [OpenAI claims
    it admits mistakes with some ‘prompt coaxing’](https://openai.com/blog/chatgpt/).
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 嗯……你确定吗？试图让聊天机器人变得更为真实，就像对着播放录音的公共广播系统大喊大叫一样。这是一件很古怪的事情，但为了“研究”，我花了一个小时与这个东西互动。毕竟，[OpenAI声称通过一些‘提示引导’可以承认错误](https://openai.com/blog/chatgpt/)。
- en: A total waste of time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 完全浪费时间。
- en: '![](../Images/979d262ce4da3880108f8e38d4aff04f.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/979d262ce4da3880108f8e38d4aff04f.png)'
- en: Acknowledges and attempts to provide information on how it gets its evidence
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 承认并尝试提供有关其获取证据的方式的信息。
- en: A while later, it switches to a new mode after I constrain it by asking it to
    admit it didn’t know an answer.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间后，它在我限制它、要求它承认不知道答案后，切换到了新的模式。
- en: '![](../Images/886f517192ef187babff9282dc6150dd.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/886f517192ef187babff9282dc6150dd.png)'
- en: The AI insists it’s right …so I guess I’m from New Jersey
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: AI坚持认为它是对的……所以我想我来自新泽西。
- en: '**Large Language models are unreliable information stores. What can we do about
    this?**'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**大型语言模型是不可靠的信息存储库。我们该如何解决这个问题？**'
- en: '**By design, these systems do not know what they do or don’t know.**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**从设计上讲，这些系统不知道它们知道或不知道什么。**'
- en: In my grim example, I’m dead, and from New Jersey, well, I’m not. It is hard
    to know precisely why ChatGPT thinks this, and complex to understand why. It is
    possible I could be roped into a large category of tech CEOs during my startup
    days that built a fitness startup, one of whom passed away during that time. It
    conflated relationships between subjects and predicates to be convinced I had
    died.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我那个悲惨的例子中，我已经死了，而来自新泽西的我，嗯，我还活着。很难准确知道ChatGPT为什么会这样认为，也很复杂理解其原因。可能是因为我在创办初创公司期间被归入了一个大型技术CEO的类别，他们创建了一个健身初创公司，其中一个人在那段时间去世了。它混淆了主语和谓语之间的关系，以为我已经去世。
- en: GPT is trained on massive amounts of text data without any inherent ability
    to verify the accuracy or truthfulness of the information presented in that data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: GPT是在大量文本数据上进行训练的，没有固有的能力来验证所提供信息的准确性或真实性。
- en: Relying too much on large language models within Search applications, such as
    Bing, or as a replacement for Search, such as OpenAI’s ChatGPT, will result in
    adverse and unintended harm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 过度依赖大型语言模型在搜索应用中的表现，例如Bing，或作为搜索的替代品，例如OpenAI的ChatGPT，将会导致负面和意外的伤害。
- en: Put more plainly, in its current state, ChatGPT **should not** be considered
    an evolution of Search.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 更直白地说，在其当前状态下，ChatGPT **不应**被视为搜索的进化。
- en: So should we build on top of factually unreliable GPTs?
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么我们是否应该在事实不可靠的GPT上进行构建？
- en: Yes. Though when we do, we must ensure we add the appropriate trust and safety
    checks and the practical constraints through techniques I’ll share below. When
    building atop these foundational models, we can minimize inaccuracy using proper
    guardrails with techniques like prompt engineering and context injection.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。不过，当我们这样做时，我们必须确保添加适当的信任和安全检查，并通过我下面将要分享的技术进行实际约束。在这些基础模型之上构建时，我们可以通过适当的保护措施，使用如提示工程和上下文注入等技术来最小化不准确性。
- en: Or, if we have our own larger datasets, more advanced approaches such as Transfer
    learning, fine-tuning, and reinforcement learning are areas to consider.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们拥有更大的数据集，则可以考虑更先进的方法，如迁移学习、微调和强化学习。
- en: Transfer learning (Fine-tuning specifically) is one technique to improve the
    accuracy of models in specific domains, but it still falls short.
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习（特别是微调）是一种提高模型在特定领域准确性的技术，但它仍然存在不足之处。
- en: Let’s talk about transfer learning or fine-tuning, a technique replicating large
    language models. While these techniques can improve the model’s accuracy in specific
    domains, they do not necessarily solve the issue of AI hallucinations. This means
    that even if the model gets some things right based on the new data domain, it’s
    being transformed with, it may still create inaccurate or false information based
    on how large language models are architected.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论迁移学习或微调，这是复制大型语言模型的一种技术。虽然这些技术可以提高模型在特定领域的准确性，但它们并不一定解决AI幻觉的问题。这意味着，即使模型基于新的数据领域正确地获取了一些信息，由于大型语言模型的架构问题，它仍可能生成不准确或虚假的信息。
- en: Large language models lack deductive reasoning or a cognitive architecture which
    makes them epistemologically blind to what it knows it knows and its known unknowns.
    After all, Generative Pre-trained Transformers (aka large language models) are
    [incredibly sophisticated text prediction engines](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)
    and have no way to identify the patterns that lead to the facts or hallucinations
    they generate.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型缺乏演绎推理或认知架构，这使它们在认识到自己知道什么和已知的未知领域时存在认识上的盲点。毕竟，生成预训练变换器（即大型语言模型）是[极其复杂的文本预测引擎](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)，没有办法识别导致其生成事实或幻觉的模式。
- en: Microsoft’s ambition to integrate a fined tuned GPT within Bing is problematic
    and is an awful strategy when deep fakes, conspiracies, and disinformation are
    the norm in 2023\. Today, end users require facts with sources and attribution
    to avoid chaos. Microsoft should know better.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 微软计划将调整后的GPT集成到Bing中，这在2023年虚假信息、阴谋论和深度伪造成为常态的情况下是一个有问题且糟糕的策略。今天，最终用户需要带有来源和归属的事实以避免混乱。微软应该更明智。
- en: Then there’s Google. I understand why Google keeps LaMDA’s large language model
    under wraps and only uses this emergent technology internally for Search and other
    services. Unfortunately, they saw Bing Chat then they panicked. Google invented
    most of this tech; they know the dangers. Google should know better.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是谷歌。我理解为什么谷歌将LaMDA的大型语言模型保密，并只在内部用于搜索和其他服务。不幸的是，他们看到Bing Chat后感到恐慌。谷歌发明了大多数这项技术；他们知道其危险性。谷歌应该更明智。
- en: For Large Language models to be a component of Search, we need ways to understand
    the provenance and lineage of the generated responses of these large language
    models.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使大型语言模型成为搜索的一部分，我们需要了解这些大型语言模型生成的响应的来源和传承。
- en: 'This way, we can:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以：
- en: Provide attribution of sources,
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供来源的归属，
- en: Provide a level of confidence for each response the AI generates, or
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为AI生成的每个响应提供一个置信度等级，或者
- en: Right now, we’re not there yet though I hope we see these innovations soon.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们还没有达到这个目标，但我希望这些创新能尽快出现。
- en: As part of this research, I demonstrate ways to increase factual accuracy and
    ward off hallucinations using the [OpenAI Text Completions model endpoint](https://platform.openai.com/docs/guides/completion/prompt-design).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我展示了如何使用[OpenAI文本补全模型端点](https://platform.openai.com/docs/guides/completion/prompt-design)提高事实准确性并防止幻觉。
- en: '![](../Images/d3b1c4384eca32b8f52cf774781e2243.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3b1c4384eca32b8f52cf774781e2243.png)'
- en: Checking factual accuracy with the GPT3 Completions Model Endpoint
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPT3补全模型端点检查事实准确性
- en: In a similar example, I asked the GPT3 model, “who won the 100-meter dash at
    the 2020 Olympics?”
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在类似的例子中，我问了GPT3模型，“谁赢得了2020年奥运会100米短跑？”
- en: It responds, ***“The 100-meter dash at the 2020 Olympics was won by Jamaica’s
    Shelly-Ann Fraser-Pryce.”***
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它回应道，***“2020年奥运会100米短跑由牙买加的谢利-安·弗雷泽-普赖斯赢得。”***
- en: '![](../Images/29050abde8904e004d12216c09b6c90f.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29050abde8904e004d12216c09b6c90f.png)'
- en: 'An example to highlight factual accuracy (i.e., hallucinations or confabulation).
    Prompt: “who won the 100-meter dash 2020 Olympics?”'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一个突显事实准确性的例子（即幻觉或编造）。提示：“谁赢得了2020年奥运会100米短跑？”
- en: Sounds factual, but the truth is more nuanced as the 2020 Olympics were postponed
    a year due to the pandemic. For developers of large language models, it is important
    to take steps to reduce the likelihood of AI hallucinations. For end-users, it’s
    essential to bring critical thinking and not be overly reliant on AI results.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很真实，但实际上更复杂，因为2020年奥运会由于疫情推迟了一年。对于大型语言模型的开发者来说，采取措施减少AI幻觉的可能性至关重要。对于最终用户来说，带着批判性思维使用AI结果，避免过度依赖AI的结果是必要的。
- en: So, as a developer, what are some ways to reduce the likelihood of AI making
    up facts, given the flaws of large language models? One lower-barrier-to-entry
    approach is prompt engineering. Prompt engineering involves crafting prompts and
    adding prompt constraints to guide the model toward accurate responses.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，作为开发者，有哪些方法可以减少AI编造事实的可能性，鉴于大型语言模型的缺陷？一种门槛较低的方法是提示工程。提示工程涉及构造提示和添加提示约束，以引导模型生成准确的响应。
- en: Prompt engineering
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示工程
- en: '![](../Images/a605343c914ee3c95df38a0004976b66.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a605343c914ee3c95df38a0004976b66.png)'
- en: '[Prompt engineering tip](https://platform.openai.com/docs/guides/completion/prompt-design)
    using prompt constraints to show the API how to admit it doesn’t know a fact.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示工程技巧](https://platform.openai.com/docs/guides/completion/prompt-design)，使用提示约束来展示
    API 如何承认它不知道某个事实。'
- en: Or you can feed it specific context to the domain you care about using Context
    injection.
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 或者，你可以通过上下文注入将其提供给你关心的领域的特定上下文。
- en: '![](../Images/1531e15e8da7f72a26189c01253b1dc6.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1531e15e8da7f72a26189c01253b1dc6.png)'
- en: Controlling hallucination by constraining the model domain-specific prompts.
    “How many times have the Eagles beaten the Patriots in a Superbowl” Model responds
    correctly with Once.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通过限制模型领域特定的提示来控制幻觉。“老鹰队在超级碗中击败爱国者队多少次？”模型正确回答为一次。
- en: The context ingestion method is faster and cheaper but requires domain knowledge
    and expertise to be effective. This approach can be particularly useful in domains
    where the accuracy and relevance of the generated text are critical. You should
    expect to see this approach in enterprise contexts such as in customer service
    or medical diagnosis.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文摄取方法更快且更便宜，但需要领域知识和专业技能才能有效。这种方法在生成文本的准确性和相关性至关重要的领域特别有用。你应该在企业环境中看到这种方法，例如在客户服务或医疗诊断中。
- en: Another approach is to use embedding (for example, for vector or semantic Search),
    which involves using the OpenAI Embeddings model endpoint to search for related
    concepts and terms known to be true. This method is more expensive but is also
    more reliable and accurate.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是使用嵌入（例如，用于向量或语义搜索），这涉及使用 OpenAI 嵌入模型端点来搜索已知为真的相关概念和术语。这种方法更贵，但也更可靠和准确。
- en: '![](../Images/03dd1eb6e3a7a26f37871e3a780971a3.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03dd1eb6e3a7a26f37871e3a780971a3.png)'
- en: '*Human-readable text and vectorized text pair.*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*人类可读文本与向量化文本对。*'
- en: AI hallucinations are a real and potentially dangerous issue in large language
    models. Fine-tuning does not necessarily solve the problem; however, the Embeddings
    approach is where a user's query is matched with the nearest, most likely factual
    hit in a vector database using [cosine similarity](https://github.com/openai/openai-python/blob/ede0882939656ce4289cb4f61142e7658bb2dec7/openai/embeddings_utils.py)
    or equivalent.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: AI 幻觉是大型语言模型中一个真实且潜在危险的问题。微调不一定能解决这个问题；然而，嵌入方法则是通过[余弦相似度](https://github.com/openai/openai-python/blob/ede0882939656ce4289cb4f61142e7658bb2dec7/openai/embeddings_utils.py)或同等方法，将用户的查询与向量数据库中最接近、最可能的真实信息进行匹配。
- en: '![](../Images/e9025cdebd7dabe452834c974a9a9fb1.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9025cdebd7dabe452834c974a9a9fb1.png)'
- en: AI confabulates additional incorrect facts about me. None of this is true.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: AI 构造了关于我的额外不正确的事实。这些都不是真的。
- en: 'In summary: Keeping up with the pace of innovation without breaking things.'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结：跟上创新的步伐而不破坏事物。
- en: Let’s learn from the past. To ensure factual accuracy, it’s essential to be
    aware of the impacts of unintentionally pushing false information given the scale
    OpenAI is innovating. Developers should reduce the likelihood of disproportionate
    product failure where incorrect information is presented in the context of factually
    correct information, as the hundred million plus early adopters of ChatGPT, such
    as through prompt engineering or vector search. By doing so, we can help ensure
    that the information provided by large language models is accurate and reliable.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从过去中学习。为了确保事实准确性，必须意识到在 OpenAI 创新的规模下，不小心传播虚假信息的影响。开发人员应减少在事实准确的信息背景下呈现不正确信息的产品失败可能性，例如通过提示工程或向量搜索。这样，我们可以帮助确保大型语言模型提供的信息是准确和可靠的。
- en: I admire the OpenAI’s strategy of putting these tools in people's hands to get
    early feedback in a controlled process across industries or domains but to a point.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我欣赏 OpenAI 将这些工具交到人们手中，以在各个行业或领域中进行受控的早期反馈，但也有其局限性。
- en: '[Not at their scale](https://www.wsj.com/articles/microsoft-says-it-plans-multibillion-dollar-investment-in-openai-11674483180).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[不适用于他们的规模](https://www.wsj.com/articles/microsoft-says-it-plans-multibillion-dollar-investment-in-openai-11674483180)。'
- en: I **do not** admire the “moving fast” even if the solution is still a “somewhat
    broken” attitude.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我**不**欣赏“快速行动”即使解决方案仍然是“有点破损”的态度。
- en: '**Hard disagree.**'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**强烈不同意。**'
- en: Don't “move fast and break things” at this scale.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种规模下，不要“快速行动并破坏事物”。
- en: This ethos should be nuked from orbit, especially with non-deterministic transformative
    technology controlled by a massive startup like OpenAI. Sam Altman should know
    better.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这种理念应该被从轨道上彻底摧毁，特别是在像OpenAI这样的大型初创公司控制的非确定性变革技术面前。萨姆·奥特曼应该知道更好。
- en: For the startups innovating in this space out there. There are a lot of you;
    hear me out.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在这个领域进行创新的初创公司来说。你们很多，听我说。
- en: The stakes are too high when misinformation leads to representational harm,
    [**leading to hefty fines**](https://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook);
    you don’t want that loss of trust in your customers or, worse, for your startup
    to die.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当虚假信息导致代表性伤害时，风险太高了，[**可能会面临巨额罚款**](https://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook)；你不想失去客户的信任，或者更糟的是，让你的初创公司倒闭。
- en: Stakes may be low for a massive corporation like Microsoft at this point, or
    at least until someone gets hurt, or a Government gets taken over. Mixing modalities
    is also a cluttered and confusing experience. This decision will lead to disproportionate
    product failure and a lack of adoption in Bing once the hype dies down. This is
    not how you grow your 8% Bing search market share.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像微软这样的大公司来说，目前的风险可能很低，或者至少直到有人受到伤害，或者政府被接管为止。混合模式也是一种杂乱和令人困惑的体验。这项决定将导致产品失败的比例过高，一旦炒作退去，Bing
    的采用率将会下降。这不是你提升8% Bing搜索市场份额的方式。
- en: I hope you enjoyed this article. Hopefully, I’ve proven I’m very much alive.
    This has been part of a series of posts on the **Responsible use of AI**. For
    my thoughts on algorithmic bias and fairness, see this previous post.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这篇文章。希望我已经证明我非常活跃。这是关于**负责任使用人工智能**的一系列文章中的一部分。有关算法偏见和公平性的我的想法，请参见之前的文章。
- en: '[](https://becominghuman.ai/mitigating-ai-bias-with-bias-6d237452258e?source=post_page-----db5a36c22f11--------------------------------)
    [## Mitigating AI Bias, with …Bias'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 缓解人工智能偏见，...偏见](https://becominghuman.ai/mitigating-ai-bias-with-bias-6d237452258e?source=post_page-----db5a36c22f11--------------------------------)'
- en: This article is part of my Data Trust series of talks. The purpose of these
    articles are to break down complex but…
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这篇文章是我数据信任系列演讲的一部分。这些文章的目的是解构复杂但...
- en: becominghuman.ai](https://becominghuman.ai/mitigating-ai-bias-with-bias-6d237452258e?source=post_page-----db5a36c22f11--------------------------------)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[成为人类](https://becominghuman.ai/mitigating-ai-bias-with-bias-6d237452258e?source=post_page-----db5a36c22f11--------------------------------)'
- en: '*Want more like this? Read more here and follow*, *reach me on* [*Twitter*](https://www.twitter.com/nobleackerson)*,
    watch my past speaking engagements on* [*Youtube*](https://www.youtube.com/@stigsfoot/videos),
    *or connect with me on* [*LinkedIn*](https://linkedin.com/in/noblea).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*想要更多这样的内容？阅读更多信息并关注*，[*Twitter*](https://www.twitter.com/nobleackerson)*，观看我过去的演讲视频在*
    [*Youtube*](https://www.youtube.com/@stigsfoot/videos)*，或者在* [*LinkedIn*](https://linkedin.com/in/noblea)*与我联系。'
