["```py\nimport torch\nimport numpy as np\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import Subset, DataLoader\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport random\nfrom tqdm import tqdm\n\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nimport pandas as pd\n\ndef set_seed(no):\n    torch.manual_seed(no)\n    random.seed(no)\n    np.random.seed(no)\n    os.environ['PYTHONHASHSEED'] = str()\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nset_seed(100)\n```", "```py\nbatch_size = 8\n\ntransformation = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\ntrainset = torchvision.datasets.Food101(root='./data', split='train',\n                                        download=True, transform=transformation)\n\ntestset = torchvision.datasets.Food101(root='./data', split='test',\n                                       download=True, transform=transformation)\n\n# train_indices = random.sample(range(len(trainset)), 20000)\n# test_indices = random.sample(range(len(testset)), 5000)\n\n# trainset = Subset(trainset, train_indices)\n# testset  = Subset(testset, test_indices)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False)\n\nclasses = trainset.classes\n\nprint(len(trainset), len(testset))\nprint(len(trainloader), len(testloader))\n```", "```py\n# Get a batch of images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# Plot the images\nfig, axes = plt.subplots(1, len(images),figsize=(12,12))\nfor i, ax in enumerate(axes):\n    # Convert the tensor image to numpy format\n    image = images[i].numpy()\n    image = image.transpose((1, 2, 0))  # Transpose to (height, width, channels)\n\n    # Normalize the image\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    normalized_image = (image * std) + mean\n    # Display the image\n    ax.imshow(normalized_image)\n    ax.axis('off')\n    ax.set_title(f'Label: {labels[i]}')\n\n# Show the plot\nplt.show()\n```", "```py\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device)\n\n#training\ntrain_embeddings = []\ntrain_labels = []\n\ndinov2_vits14.eval()\nwith torch.no_grad():\n  for data, labels in tqdm(trainloader):\n    image_embeddings_batch = dinov2_vits14(data.to(device))\n\n    train_embeddings.append(image_embeddings_batch.detach().cpu().numpy())\n    train_labels.append(labels.detach().cpu().numpy())\n\n#testing\ntest_embeddings = []\ntest_labels = []\n\ndinov2_vits14.eval()\nwith torch.no_grad():\n  for data, labels in tqdm(testloader):\n    image_embeddings_batch = dinov2_vits14(data.to(device))\n\n    test_embeddings.append(image_embeddings_batch.detach().cpu().numpy())\n    test_labels.append(labels.detach().cpu().numpy())\n\n#concatinate result\ntrain_embeddings_f = np.vstack(train_embeddings)\ntrain_labels_f = np.concatenate(train_labels).flatten()\n\ntest_embeddings_f = np.vstack(test_embeddings)\ntest_labels_f = np.concatenate(test_labels).flatten()\n\ntrain_embeddings_f.shape, train_labels_f.shape, test_embeddings_f.shape, test_labels_f.shape\n```", "```py\ndef evaluate_classifiers(X_train, y_train, X_test, y_test):\n    # Support Vector Machine (SVM)\n    svm_classifier = SVC()\n    svm_classifier.fit(X_train, y_train)\n    svm_predictions = svm_classifier.predict(X_test)\n\n    # XGBoost Classifier\n    xgb_classifier = XGBClassifier(tree_method='gpu_hist')\n    xgb_classifier.fit(X_train, y_train)\n    xgb_predictions = xgb_classifier.predict(X_test)\n\n    # K-Nearest Neighbors (KNN) Classifier\n    knn_classifier = KNeighborsClassifier()\n    knn_classifier.fit(X_train, y_train)\n    knn_predictions = knn_classifier.predict(X_test)\n\n    # Calculating Top-1\n    top1_svm = accuracy_score(y_test, svm_predictions)\n    top1_xgb = accuracy_score(y_test, xgb_predictions)\n    top1_knn = accuracy_score(y_test, knn_predictions)\n\n    # Calculating F1 Score\n    f1_svm = f1_score(y_test, svm_predictions, average='weighted')\n    f1_xgb = f1_score(y_test, xgb_predictions, average='weighted')\n    f1_knn = f1_score(y_test, knn_predictions, average='weighted')\n\n    return pd.DataFrame({\n        'SVM': {'Top-1 Accuracy': top1_svm, 'F1 Score': f1_svm},\n        'XGBoost': {'Top-1 Accuracy': top1_xgb,'F1 Score': f1_xgb},\n        'KNN': {'Top-1 Accuracy': top1_knn, 'F1 Score': f1_knn}\n    })\n\nX_train = train_embeddings_f  # Training data features\ny_train = train_labels_f  # Training data labels\nX_test = test_embeddings_f   # Test data features\ny_test = test_labels_f   # Test data labels\n\nresults = evaluate_classifiers(X_train, y_train, X_test, y_test)\nprint(results)\n```"]