["```py\npip install -U git+https://github.com/huggingface/diffusers.git@main\n```", "```py\nimport torch\nfrom diffusers import StableDiffusionPipeline\n\ntext2img_pipe = StableDiffusionPipeline.from_pretrained(\n    \"stablediffusionapi/deliberate-v2\"\n    , torch_dtype = torch.float16\n    , safety_checker = None\n).to(\"cuda:0\")\n\nlora_path = \"<path/to/lora.safetensors>\"\ntext2img_pipe.load_lora_weights(lora_path)\n```", "```py\nfrom diffusers import EulerDiscreteScheduler\n\nprompt = \"\"\"\nМаша making extreme selfie on skyscraper, bird's eye view, from above, night, smiling\n\"\"\"\nneg_prompt = \"\"\"\nNSFW,deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, mutated hands and fingers, disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation\n\"\"\"\n\ntext2img_pipe.scheduler = EulerDiscreteScheduler.from_config(text2img_pipe.scheduler.config)\n\nimage = text2img_pipe(\n    prompt = prompt\n    , negative_prompt = neg_prompt\n    , generator = torch.Generator(\"cuda:0\").manual_seed(3135098381)\n    , num_inference_steps = 28\n    , guidance_scale = 8\n    , width = 512\n    , height = 768\n).images[0]\ndisplay(image)\n```", "```py\ntext2img_pipe.unload_lora_weights()\nlora_path = \"<path/to/lora.safetensors>\"\n\nlora_w = 0.5\ntext2img_pipe._lora_scale = lora_w\n\nstate_dict, network_alphas = text2img_pipe.lora_state_dict(\n    lora_path\n)\n\nfor key in network_alphas:\n    network_alphas[key] = network_alphas[key] * lora_w\n\n#network_alpha = network_alpha * lora_w\ntext2img_pipe.load_lora_into_unet(\n    state_dict = state_dict\n    , network_alphas = network_alphas\n    , unet = text2img_pipe.unet\n)\n\ntext2img_pipe.load_lora_into_text_encoder(\n    state_dict = state_dict\n    , network_alphas = network_alphas\n    , text_encoder = text2img_pipe.text_encoder\n)\n```", "```py\ntext2img_pipe.unload_lora_weights()\n```"]