["```py\n# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport glob \nimport random \n\nfrom PIL import Image\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\nimport shap\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import ConfusionMatrixDisplay as cmd\n```", "```py\n# Paths of example images\nex_paths = [\"../../data/object_detection/0_b812cd70-4eff-11ed-9b15-f602a686e36d.jpg\",\n          \"../../data/object_detection/0_d1edcc80-4ef6-11ed-8ddf-a46bb6070c92.jpg\",\n          \"../../data/object_detection/1_cb171726-4ef7-11ed-8ddf-a46bb6070c92.jpg\"]\n\n# Plot example images\nfig, ax = plt.subplots(1, 3, figsize=(15, 5))\nfig.set_facecolor('white')\n\nfor i, path in enumerate(ex_paths):\n\n    # Load image\n    img =  Image.open(path)\n\n    # Get target\n    name = path.split(\"/\")[-1]\n    target = int(name.split(\"_\")[0])\n\n    # Plot image\n    ax[i].imshow(img)\n    ax[i].axis(\"off\")\n\n    # Set title\n    title = [\"GO\",\"STOP\"][target]\n    ax[i].set_title(title,size=20)\n```", "```py\ndef threshold(img,cutoff,invert=False):\n    \"\"\"Apply intesity thresholding\"\"\"\n\n    img = np.array(img)\n\n    # Greyscale image\n    img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n\n    #Apply cutoff\n    img[img>cutoff] = 255 #white\n    img[img<=cutoff] = 0 #black\n\n    # Scale to 0-1    \n    img = img/255\n\n    # Invert image so black = 1\n    if invert: \n        img = 1 - img\n\n    return img\n```", "```py\n# Load paths\npaths = glob.glob(\"../../data/object_detection/*.jpg\")\n\n# Load images and targets\nimages = [Image.open(path) for path in paths]\ntarget = [int(path.split(\"/\")[-1].split(\"_\")[0]) for path in paths]\n\n# Apply thresholding and get intensity\nthresh_img = [threshold(img,60,True) for img in images]\nintensity = [np.average(img) for img in thresh_img]\n```", "```py\n# Split data into go and stop images\ngo_data = [intensity[i] for i in range(len(target)) if target[i]==0]\nstop_data = [intensity[i] for i in range(len(target)) if target[i]==1]\ndata= [go_data,stop_data]\n\nfig = plt.figure(figsize=(5,5))\n\n# Plot boxplot\nplt.boxplot(data)\nplt.hlines(y=0.065,xmin=0.5,xmax=2.5,color='r')\nplt.xticks([1,2],['GO','STOP'])\nplt.ylabel(\"Average Intensity\",size=15)\n```", "```py\n# Predict using average intensity\nprediction = [1 if i>0.065 else 0 for i in intensity]\n\n# Evaluate\nacc = metrics.accuracy_score(target,prediction)\nprec,rec,_,_ = score(target, prediction,average='macro')\n\nprint('Accuracy: {}'.format(round(acc,4)))\nprint('Precision: {}'.format(round(prec,4)))\nprint('Recall: {}'.format(round(rec,4)))\n\n# Plot confusion matrix\ncm = metrics.confusion_matrix(target, prediction)\ncm_display = cmd(cm, display_labels = ['GO', 'STOP'])\n\ncm_display.plot()\n```", "```py\nclass ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, paths, transform):\n\n        self.paths = paths\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        \"\"\"Get image and target (x, y) coordinates\"\"\"\n\n        # Read image\n        path = self.paths[idx]\n        image = cv2.imread(path, cv2.IMREAD_COLOR)\n        image = Image.fromarray(image)\n\n        # Transform image\n        image = self.transform(image)\n\n        # Get target\n        target = path.split(\"/\")[-1].split(\"_\")[0]\n        target = [[1,0],[0,1]][int(target)]\n\n        target = torch.Tensor(target)\n\n        return image, target\n\n    def __len__(self):\n        return len(self.paths)\n```", "```py\nTRANSFORMS = transforms.Compose([\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n```", "```py\npaths = glob.glob(\"../../data/object_detection/*.jpg\")\n\n# Shuffle the paths\nrandom.shuffle(paths)\n\n# Create a datasets for training and validation\nsplit = int(0.8 * len(paths))\ntrain_data = ImageDataset(paths[:split], TRANSFORMS)\nvalid_data = ImageDataset(paths[split:], TRANSFORMS)\n```", "```py\n# Prepare data for Pytorch model\ntrain_loader = DataLoader(train_data, batch_size=128, shuffle=True)\nvalid_loader = DataLoader(valid_data, batch_size=valid_data.__len__())\n```", "```py\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        # Convolutional layers\n        self.conv_layers = nn.Sequential(\n            # Sees 224x224x3 image tensor\n            nn.Conv2d(3, #RGB channels\n                            16, #number of kernels\n                            3, #size of kernels\n                            padding=1), \n            nn.MaxPool2d(2),\n            nn.ReLU(),\n\n            # Sees 112x112x16 tensor\n            nn.Conv2d(16, 32, 3, padding=1),\n            nn.MaxPool2d(2),\n            nn.ReLU(),\n\n            # Sees 56x56x32 tensor\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.MaxPool2d(2),\n            nn.ReLU()\n        )\n\n        # Fully connected layers\n        self.fc_layers = nn.Sequential(\n            # Sees flattened 28 * 28 * 64 tensor\n            nn.Dropout(0.25),\n            nn.Linear(64 * 28 * 28, 500),\n            nn.ReLU(),\n            nn.Linear(500, 2),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.view(-1, 64 * 28 * 28)\n        x = self.fc_layers(x)\n        return x\n```", "```py\n# create a complete CNN\nmodel = Net()\nprint(model)\n\n# move tensors to GPU if available\ndevice = torch.device('mps')\nmodel.to(device)\n```", "```py\n# specify loss function (binary cross-entropy)\ncriterion = nn.BCELoss()\n\n# specify optimizer\noptimizer = torch.optim.Adam(model.parameters())\n```", "```py\nname = \"object_detection_cnn\" # Change this to save a new model\n\n# Train the model\nmin_loss = np.inf\nfor epoch in range(20):\n\n    model = model.train()\n    for images, target in iter(train_loader):\n\n        images = images.to(device)\n        target = target.to(device)\n\n        # Zero gradients of parameters\n        optimizer.zero_grad()  \n\n        # Execute model to get outputs\n        output = model(images)\n\n        # Calculate loss\n        loss = criterion(output, target)\n\n        # Run backpropogation to accumulate gradients\n        loss.backward()\n\n        # Update model parameters\n        optimizer.step()\n\n    # Calculate validation loss\n    model = model.eval()\n\n    images, target = next(iter(valid_loader))\n    images = images.to(device)\n    target = target.to(device)\n\n    output = model(images)\n    valid_loss = criterion(output, target)\n\n    print(\"Epoch: {}, Validation Loss: {}\".format(epoch, valid_loss.item()))\n\n    # Save model with lowest loss\n    if valid_loss < min_loss:\n        print(\"Saving model\")\n        torch.save(model, '../../models/{}.pth'.format(name))\n\n        min_loss = valid_loss\n```", "```py\n# Load saved model \nmodel = torch.load('../../models/object_detection_cnn.pth')\nmodel.eval()\nmodel.to(device)\n```", "```py\n# Get images and targets\nimages, target = next(iter(valid_loader))\nimages = images.to(device)\ntarget = [int(t[1]) for t in target]\n```", "```py\n# Get predictions\noutput=model(images)\nprediction = [1 if o[1] > 0.5 else 0 for o in output]\n```", "```py\n# Load saved model \nmodel = torch.load('../../models/object_detection_cnn.pth')\n\n# Use CPU\ndevice = torch.device('cpu')\nmodel = model.to(device)\n\n#Load 100 images for background\nshap_loader = DataLoader(train_data, batch_size=100, shuffle=True)\nbackground, _ = next(iter(shap_loader))\nbackground = background.to(device)\n\n#Create SHAP explainer \nexplainer = shap.DeepExplainer(model, background)\n\n# Load test images\ntest_images = [Image.open(path) for path in ex_paths]\ntest_images = np.array(test_images)\n\ntest_input = [TRANSFORMS(img) for img in test_images]\ntest_input = torch.stack(test_input).to(device)\n\n# Get SHAP values\nshap_values = explainer.shap_values(test_input)\n\n# Reshape shap values and images for plotting\nshap_numpy = list(np.array(shap_values).transpose(0,1,3,4,2))\ntest_numpy = np.array([np.array(img) for img in test_images])\n\nshap.image_plot(shap_numpy, test_numpy,show=False)\n```"]