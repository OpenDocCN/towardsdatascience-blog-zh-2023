- en: Maximum Likelihood Estimation for Beginners (with R code)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初学者的最大似然估计（附R代码）
- en: 原文：[https://towardsdatascience.com/a-laymans-guide-to-maximum-likelihood-estimation-with-r-code-9e992a10ecd9](https://towardsdatascience.com/a-laymans-guide-to-maximum-likelihood-estimation-with-r-code-9e992a10ecd9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-laymans-guide-to-maximum-likelihood-estimation-with-r-code-9e992a10ecd9](https://towardsdatascience.com/a-laymans-guide-to-maximum-likelihood-estimation-with-r-code-9e992a10ecd9)
- en: Intuitive explanation of maximum likelihood method
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最大似然方法的直观解释
- en: '[](https://medium.com/@jaekim8080?source=post_page-----9e992a10ecd9--------------------------------)[![Jae
    Kim](../Images/34716958ecfe8c0540f5cf5c1640d587.png)](https://medium.com/@jaekim8080?source=post_page-----9e992a10ecd9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e992a10ecd9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e992a10ecd9--------------------------------)
    [Jae Kim](https://medium.com/@jaekim8080?source=post_page-----9e992a10ecd9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jaekim8080?source=post_page-----9e992a10ecd9--------------------------------)[![Jae
    Kim](../Images/34716958ecfe8c0540f5cf5c1640d587.png)](https://medium.com/@jaekim8080?source=post_page-----9e992a10ecd9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e992a10ecd9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e992a10ecd9--------------------------------)
    [Jae Kim](https://medium.com/@jaekim8080?source=post_page-----9e992a10ecd9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e992a10ecd9--------------------------------)
    ·4 min read·Mar 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e992a10ecd9--------------------------------)
    ·4 min read·Mar 14, 2023
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The maximum likelihood principle is a fundamental method of estimation for a
    large number of models in data science, machine learning, and artificial intelligence.
    It is applicable to a range of methods from the logit model for classification
    to information theories in deep learning. This article is aimed to provide an
    intuitive introduction to the principle.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最大似然原理是数据科学、机器学习和人工智能中大量模型的基本估计方法。它适用于从分类的logit模型到深度学习中的信息理论等各种方法。本文旨在提供对该原理的直观介绍。
- en: Suppose you have three data points x = (1, 2, 3), and you believe that they
    are generated from a normal distribution with the unknown mean (μ) and standard
    deviation equal to 1, i.e., N(μ,1).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有三个数据点x = (1, 2, 3)，你认为它们是从均值未知（μ）且标准差为1的正态分布中生成的，即N(μ,1)。
- en: '*Given these data points you have, what is the most likely value of μ?*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*考虑这些数据点，最可能的μ值是什么？*'
- en: This is the question that the method of maximum likelihood estimation is designed
    to answer.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最大似然估计方法旨在回答的问题。
- en: '![](../Images/8f59e21317a146d3fef8961a03fdf93f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f59e21317a146d3fef8961a03fdf93f.png)'
- en: Image created by the author
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建
- en: Suppose the researcher considers three possible values of μ = (0, 2, 6) as likely
    candidates. Which one of these values are most likely for the data observed?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设研究人员考虑了μ = (0, 2, 6)这三个可能的值作为候选值。哪一个值最有可能是观察到的数据的值？
- en: The figure above plots three normal distribution probability (density) functions
    for N(0,1), N(2,1), and N(6,1), respectively in blue, black, and green. That is,
    they are respectively f(X|μ=0), f(X|μ=2), f(X|μ=6), where
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 上图分别用蓝色、黑色和绿色绘制了N(0,1)、N(2,1)和N(6,1)的三个正态分布概率（密度）函数。即，它们分别是f(X|μ=0)、f(X|μ=2)、f(X|μ=6)。
- en: Created by the author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创建
- en: The red square dots at the bottom indicate x=(1, 2, 3), which are the observed
    data points.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 底部的红色方块点表示x=(1, 2, 3)，这些是观察到的数据点。
- en: It is obvious from the above plots that the data points x is most likely to
    have generated from N(2,1). They are quite unlikely from N(0,1), and even more
    so from N(6,1). Hence, we can say that the value of μ = 2 is associated with the
    highest likelihood or compatibility with x = (1, 2, 3).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图表可以明显看出，数据点x最有可能来自N(2,1)。它们来自N(0,1)的可能性相当低，来自N(6,1)的可能性更低。因此，我们可以说μ = 2的值与x
    = (1, 2, 3)的兼容性最高。
- en: If we consider all other possible values of μ, and convinced that 2 is most
    likely to have generated x, then it is the maximum likelihood estimate for μ.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑所有其他可能的μ值，并且确信2最有可能生成x，那么它就是μ的最大似然估计。
- en: 'Let us define some mathematical details:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一些数学细节：
- en: 'f(X1,X2,X3|μ): **joint** **probability** **density function** of X, given μ.
    It shows the probability density of X, given the value of μ.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: f(X1,X2,X3|μ)：**联合** **概率** **密度函数**，给定 μ。它展示了在给定 μ 的情况下 X 的概率密度。
- en: 'L(μ|x1,x2,x3): **likelihood function** of μ, given x. It shows the likelihood
    of μ, given the observed data x=(x1, x2, x3).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: L(μ|x1,x2,x3)：**似然函数**，给定 x。它展示了在给定观察数据 x=(x1, x2, x3) 的情况下 μ 的似然。
- en: The difference is that the density function is indexed by random variable X,
    given a value of parameter such as μ; while the likelihood function is indexed
    by the parameter, given the observed data x.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 区别在于密度函数是通过随机变量 X 索引，给定如 μ 这样的参数值；而似然函数是通过参数索引，给定观察到的数据 x。
- en: The two functions are related as
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数的关系为
- en: L(μ|x1,x2,x3) = k f(x1,x2,x3|μ),
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: L(μ|x1,x2,x3) = k f(x1,x2,x3|μ)。
- en: where k > 0 is any constant. Let us assume that k = 1 for simplicity. Then the
    two functions are almost the same, with the difference being their arguments and
    the conditioning values. If we assume for simplicity that X’s are independent,
    then we can write (since the joint probability is a product of individual probabilities
    under independence)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 k > 0 是任何常数。为了简便起见，我们假设 k = 1。那么这两个函数几乎相同，区别在于它们的参数和条件值。如果我们为简单起见假设 X 们是独立的，那么我们可以写出（因为在独立情况下联合概率是个体概率的乘积）
- en: L(μ|x1,x2,x3) = f(x1|μ) × f(x2|μ) × f(x3|μ).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: L(μ|x1,x2,x3) = f(x1|μ) × f(x2|μ) × f(x3|μ)。
- en: '![](../Images/769bb47ce63c0e666f870c421bb7194e.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/769bb47ce63c0e666f870c421bb7194e.png)'
- en: Image created by the author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建
- en: 'The above table shows the values of the likelihood function L(μ|x1,x2,x3) when
    x=(1, 2, 3): the values listed in the last column as a product of those in the
    first three. The highest likelihood value achieved is at μ = 2.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 上表显示了当 x=(1, 2, 3) 时似然函数 L(μ|x1,x2,x3) 的值：最后一列列出了这些值的乘积。最大似然值出现在 μ = 2。
- en: Now we consider all possible values of μ, and plot the likelihood and log-of-likelihood
    functions as a function of μ. The log-of-likelihood function is defined as
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们考虑 μ 的所有可能值，并将似然和对数似然函数作为 μ 的函数进行绘制。对数似然函数定义为
- en: '*l*(μ|x1,x2,x3) = log[L(μ|x1,x2,x3)],'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*l*(μ|x1,x2,x3) = log[L(μ|x1,x2,x3)]，'
- en: where log() is the natural logarithmic function. The log-of-likelihood is a
    monotonic transformation of the likelihood function. It is widely used because
    it is analytically tractable, being additive and linear.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 log() 是自然对数函数。对数似然是似然函数的单调变换。它被广泛使用，因为它在分析上是可处理的，具有可加性和线性。
- en: '![](../Images/1fc02b374dc4c813f189845faf701ce4.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fc02b374dc4c813f189845faf701ce4.png)'
- en: Image created by the author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建
- en: The functions are plotted as above. It is clear from the above plots that the
    likelihood or log-of-likelihood is maximized at μ = 2, which is the maximum likelihood
    estimate for x = (1, 2, 3).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数如图所示。从上面的图中可以清楚地看到，似然或似然对数在 μ = 2 时最大，这也是 x = (1, 2, 3) 的最大似然估计。
- en: Analytically, it can be shown that the sample mean is the maximum likelihood
    estimator for a sample generated independently from N(μ,1), and the sample mean
    of x = (1, 2, 3) is indeed 2.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析上，可以证明样本均值是从 N(μ,1) 独立生成的样本的最大似然估计量，而 x = (1, 2, 3) 的样本均值确实是 2。
- en: 'R code for the calculations and plots are as below:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 计算和绘图的 R 代码如下：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To conclude, the maximum likelihood estimation method is widely used to for
    many models and methods in data science. Its concept and principle are often not
    fully understood by the researchers and practitioners. This post is aimed to provide
    an intuitive explanation of the method without introducing the analytical details.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，最大似然估计方法被广泛应用于数据科学中的许多模型和方法。其概念和原理通常未被研究人员和实践者完全理解。本文旨在提供一种直观的解释，而不介绍分析细节。
- en: Thanks for reading!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: Please follow me for more engaging stories!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 请关注我，获取更多有趣的故事！
