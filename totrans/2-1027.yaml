- en: 'Hands-on Generative AI with GANs using Python: Autoencoders'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-autoencoders-c77232b402fc](https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-autoencoders-c77232b402fc)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/6fa218e9894ae7f7c804d4ccfef9edc1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Photo by [GR Stocks](https://unsplash.com/@grstocks?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Start with Autoencoders to better understand GANs
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----c77232b402fc--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----c77232b402fc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c77232b402fc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c77232b402fc--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----c77232b402fc--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c77232b402fc--------------------------------)
    ·6 min read·Mar 21, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years, generative models have gained popularity due to Artificial
    Intelligent’s ability to produce synthetic instances that are almost indistinguishable
    from real data. Neural Networks like Chat GPT, which can generate text, and DALLE,
    which can generate wholly original graphics, may be familiar to you.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: The website [thispersondoesnotexist.com](https://this-person-does-not-exist.com/en),
    where an AI-generated image of a person who doesn’t exist shows each time you
    visit the link, is one well-known example of generative networks. This is only
    one among many illustrations of the amazing possibilities of generative AI.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Over time, Generative AI has evolved and as research advanced different architectures
    were born to solve many application cases. But in order to start learning about
    the topic of generative AI, you need to be familiar with one architecture: Generative
    Adversarial Networks (GANs).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: GANs Overview
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ultimate **goal of a generative network is to generate new data that has
    the same distribution as its training set.** Generative networks are typically
    considered part of unsupervised learning in machine learning because they do not
    require labelled data. The Generative Adversarial Network (GAN) concept, proposed
    by Ian Goodfellow in 2014, is a popular paper “[*Generative Adversarial Nets*](https://arxiv.org/pdf/1406.2661.pdf)”.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Initially, the GAN architecture was based on fully connected layers that were
    trained to **generate low-resolution images**, such as handwritten digits. Since
    then, there have been numerous improvements and applications of GANs. They have
    been used for tasks such as image-to-image translation, image super-resolution,
    and image inpainting, where the network learns to reconstruct missing parts of
    an image.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，GAN的架构基于全连接层，旨在**生成低分辨率图像**，如手写数字。从那时起，GAN经历了众多改进和应用。它们已被用于图像到图像的转换、图像超分辨率和图像修补等任务，其中网络学习重建图像的缺失部分。
- en: GANs can also be used in supervised and semi-supervised learning tasks. For
    example, Conditional GANs can generate data based on certain conditions, such
    as generating images of different animals based on user input. Semi-supervised
    GANs use labelled data to improve the quality of generated data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: GANs也可以用于监督学习和半监督学习任务。例如，条件GANs可以根据某些条件生成数据，如根据用户输入生成不同动物的图像。半监督GANs使用标记数据来提高生成数据的质量。
- en: The applications of GANs extend far beyond image generation. These models have
    been used in NLP (Natural Language Processing), music generation, and even drug
    discovery! The potential of generative models is huge, and as technology continues
    to advance, we can expect even more innovative applications to emerge.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: GANs的应用远不止于图像生成。这些模型已被应用于NLP（自然语言处理）、音乐生成甚至药物发现！生成模型的潜力巨大，随着技术的不断进步，我们可以期待更多创新应用的出现。
- en: GANs are attractive because they can generate data with the same distribution
    as their training data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GANs很有吸引力，因为它们可以生成与训练数据分布相同的数据。
- en: Autoencoders Before GANs
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自编码器与GANs
- en: To fully understand how these Generative Adversarial Networks work, it’s helpful
    to first start with Autoencoders. Autoencoders are a type of neural network that
    can compress and decompress training data, making them useful for data compression
    and feature extraction.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要完全理解这些生成对抗网络的工作原理，首先了解自编码器是很有帮助的。自编码器是一种可以压缩和解压训练数据的神经网络类型，使其在数据压缩和特征提取方面非常有用。
- en: '**Standard Autoencoders are not capable of generating new data**, but they
    serve as a useful starting point for understanding GANs. Autoencoders consist
    of two concatenated networks — an encoder network and a decoder network. The encoder
    network receives a **d-dimensional input feature x and encodes it into a p-dimensional
    vector z**. In other words, the role of the encoder is to learn how to model the
    function z= f(X). **Vector z is also called latent vector**. Usually, the dimension
    of the latent vector is lower than the original input vector, so **p<d**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准自编码器无法生成新数据**，但它们作为理解GANs的有用起点。自编码器由两个串联的网络组成——编码器网络和解码器网络。编码器网络接收**d维输入特征x，并将其编码为p维向量z**。换句话说，编码器的角色是学习如何建模函数z
    = f(X)。**向量z也称为潜在向量**。通常，潜在向量的维度低于原始输入向量，因此**p < d**'
- en: The **decoder** network **takes** the encoded vector **z and reconstructs the
    original input feature x**. **The objective of the autoencoder is to minimize
    the difference between the original input feature and the reconstructed feature**.
    By doing so, **the autoencoder learns to compress and decompress the input data
    while preserving its essential features**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**解码器**网络**接收**编码后的向量**z并重建原始输入特征x**。**自编码器的目标是最小化原始输入特征与重建特征之间的差异**。通过这样做，**自编码器学习在压缩和解压输入数据的同时保留其本质特征**。'
- en: Let’s see a picture representing the autoencoder architecture.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个表示自编码器架构的图片。
- en: '![](../Images/2870a78625634c5309e753a7607f6e4b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2870a78625634c5309e753a7607f6e4b.png)'
- en: Autoencoder Architecture (Image By Author)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器架构（图像由作者提供）
- en: While **autoencoders can be used for data compression and feature extraction,
    they are not capable of generating new data like GANs.**
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**虽然自编码器可以用于数据压缩和特征提取，但它们无法像GANs那样生成新数据。**'
- en: In this simple example, both the encoder and decoder are simple linear layers
    that compress and decompress space. **More complex architectures can have multiple
    layers and contain different types of layers, such as convolutional ones if we
    are applying the model to images.**
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的例子中，编码器和解码器都是简单的线性层，用于压缩和解压空间。**更复杂的架构可以包含多个层，并且可能包含不同类型的层，例如在应用于图像模型时使用卷积层。**
- en: Let’s see a trivial implementation of autoencoder in PyTorch.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在PyTorch中自编码器的一个简单实现。
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The AutoEncoder class extends nn.Module as usual and consists of an encoder
    and a decoder both linear layers, which take an input a vector x of size input_shape
    (e.g. 784) reduces it to a latent space of size 128 and eventually the original
    size vector is reconstructed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: AutoEncoder 类像往常一样继承 nn.Module，包括一个编码器和一个解码器，它们都是线性层，接受一个大小为 input_shape（例如
    784）的输入向量 x，将其减少到大小为 128 的潜在空间，最终重建原始大小的向量。
- en: Other Types of AutoEncoders
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他类型的 AutoEncoders
- en: We have seen that commonly the size of the latent vector is smaller than that
    of the input vector, so compression takes place, i.e., **p<d**. These types of
    autoencoders are called **undercomplete**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，通常潜在向量的大小小于输入向量的大小，因此发生压缩，即 **p<d**。这类 autoencoders 被称为 **undercomplete**。
- en: But we can create a latent vector with a size larger than the input vector,
    **p>d**. Of course, **overcomplete autoencoders**! But what are they used for?
    They can be used for **noise reduction**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们可以创建一个比输入向量更大的潜在向量，**p>d**。当然，**overcomplete autoencoders**！但它们的用途是什么？它们可以用于
    **降噪**。
- en: During the training of these networks, noise is added to the input data, think
    of images that are blurred for example, and the network must be able to reconstruct
    the noise-free image. This particular architecture is called denoising autoencoder.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些网络的训练过程中，输入数据中会添加噪声，例如模糊的图像，网络必须能够重建无噪声的图像。这种特定的架构称为去噪 autoencoder。
- en: '![](../Images/1c5fd6e04e9d564a956c473fa40100e1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c5fd6e04e9d564a956c473fa40100e1.png)'
- en: Basic Denoising Architecture (Image By Author)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基本去噪架构（图片作者）
- en: Real Example of Autoencoder
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Autoencoder 的实际示例
- en: Let us now look at an example of how to implement a more complex Autoencoder
    using PyTorch to generate synthetic data similar to the MNIST dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个如何使用 PyTorch 实现更复杂的 Autoencoder 的例子，该 Autoencoder 用于生成类似于 MNIST 数据集的合成数据。
- en: First of all as usual we install and import the libraries we will need.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，像往常一样，我们安装并导入所需的库。
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we simply import the dataset. In Pytorch this is very easy because the library
    provides methods to download the dataset quickly. So we instantiate both the dataset
    and then the dataloader that we will need to train the network. We also define
    a transformation to convert images to tensors when they are processed by the network.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需导入数据集。在 Pytorch 中这非常简单，因为库提供了快速下载数据集的方法。所以我们实例化数据集，然后是我们需要训练网络的 dataloader。我们还定义了一个转换，将图像在被网络处理时转换为张量。
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now it’s time to create the AutoEncoder class as we did before. But in this
    case, both the encoder and the decoder will be deeper since they will be composed
    of more layers so as to better capture image features.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候创建 AutoEncoder 类了，就像之前一样。但在这种情况下，编码器和解码器都会更深，因为它们将由更多的层组成，以更好地捕捉图像特征。
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can see it is not much more complicated than the trivial example seen
    at the beginning.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它并没有比最初看到的简单例子复杂多少。
- en: Now as is always the case when we train a model, we instantiate the class, and
    define a loss and an optimizer. MSELoss and Adam here.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们训练模型时总是这样，我们实例化类，并定义一个损失函数和一个优化器。在这里是 MSELoss 和 Adam。
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The moment of training the network has come. We have to iterate over our dataloader
    and reshape the input so it matches the model architecture. We then calculate
    the output and loss obtained, and save everything aside on a list that we can
    plot at the end of the training.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 训练网络的时刻来了。我们必须遍历我们的 dataloader，并调整输入以匹配模型架构。然后计算输出和获得的损失，并将所有内容保存到一个列表中，以便在训练结束时绘制。
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Okay, our network is trained! Now we can plot the original images against their
    reconstructed images from the network.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，我们的网络已经训练完成！现在我们可以将原始图像与网络重建的图像进行对比。
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/9d062ed06421a4b2e062a271196a1bc9.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d062ed06421a4b2e062a271196a1bc9.png)'
- en: 'Original vs Reconstructed (src: [https://arxiv.org/pdf/2003.05991.pdf](https://arxiv.org/pdf/2003.05991.pdf))'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '原始 vs 重建（来源: [https://arxiv.org/pdf/2003.05991.pdf](https://arxiv.org/pdf/2003.05991.pdf)）'
- en: Final Thoughts
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: Learning about Autoencoders is very helpful to understand how GANs work. In
    this article, we saw a little bit about the theory of these architectures and
    then we saw how they can be used to reconstruct the output of MNIST images. They’re
    a lot of fun to use, plus they’re also useful for various reasons, some of which
    include compressing and decompressing input or denoising of images as we’ve seen.
    **In the next article, I will explain how Autoencoders are related to GANs and
    we will see how to implement them.** Follow me for future articles![😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 学习自编码器对于理解生成对抗网络（GANs）的工作原理非常有帮助。在这篇文章中，我们了解了一些关于这些架构的理论，然后看到它们如何用于重构MNIST图像的输出。使用它们非常有趣，而且它们也有各种用途，其中一些包括压缩和解压输入或去噪图像，正如我们所见。**在下一篇文章中，我将解释自编码器如何与GANs相关，并且我们将看到如何实现它们。**
    关注我以获取未来的文章![😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
- en: The End
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束
- en: '*Marcello Politi*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*Marcello Politi*'
- en: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [CV](https://march-08.github.io/digital-cv/)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [CV](https://march-08.github.io/digital-cv/)'
