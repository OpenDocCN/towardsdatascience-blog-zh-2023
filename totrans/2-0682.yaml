- en: Decision Tree Regressor in Excel
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Excel中的决策树回归
- en: 原文：[https://towardsdatascience.com/decision-tree-regressor-in-excel-2d29d16df1db](https://towardsdatascience.com/decision-tree-regressor-in-excel-2d29d16df1db)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/decision-tree-regressor-in-excel-2d29d16df1db](https://towardsdatascience.com/decision-tree-regressor-in-excel-2d29d16df1db)
- en: '![](../Images/704b63133df778fd0325d550992bcd91.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/704b63133df778fd0325d550992bcd91.png)'
- en: Photo by [Kevin Young](https://unsplash.com/@kevinjyoung?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Kevin Young](https://unsplash.com/@kevinjyoung?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: A Step-by-Step Guide for Machine Learning Beginners
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面向机器学习初学者的逐步指南
- en: '[](https://medium.com/@angela.shi?source=post_page-----2d29d16df1db--------------------------------)[![Angela
    and Kezhan Shi](../Images/a89d678f2f3887c0c2ff3928f9d767b4.png)](https://medium.com/@angela.shi?source=post_page-----2d29d16df1db--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2d29d16df1db--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2d29d16df1db--------------------------------)
    [Angela and Kezhan Shi](https://medium.com/@angela.shi?source=post_page-----2d29d16df1db--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@angela.shi?source=post_page-----2d29d16df1db--------------------------------)[![Angela和Kezhan
    Shi](../Images/a89d678f2f3887c0c2ff3928f9d767b4.png)](https://medium.com/@angela.shi?source=post_page-----2d29d16df1db--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2d29d16df1db--------------------------------)[![数据科学探索](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2d29d16df1db--------------------------------)
    [Angela和Kezhan Shi](https://medium.com/@angela.shi?source=post_page-----2d29d16df1db--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2d29d16df1db--------------------------------)
    ·6 min read·Mar 23, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[数据科学探索](https://towardsdatascience.com/?source=post_page-----2d29d16df1db--------------------------------)
    ·6分钟阅读·2023年3月23日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: I am writing a series of articles about implementing machine learning algorithms
    using Excel, which is an excellent tool for understanding the workings of these
    algorithms without programming.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我正在写一系列关于使用Excel实现机器学习算法的文章，这是一个了解这些算法工作原理而无需编程的绝佳工具。
- en: In this article, we will implement the algorithm of the decision tree regressor
    step by step.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将一步步实现决策树回归算法。
- en: 'I will use a Google Sheet to demonstrate the implementation process. If you’d
    like to access this sheet, as well as others I’ve developed — such as linear regression
    with gradient descent, logistic regression, neural networks with backpropagation,
    KNN, k-means, and more to come — please consider supporting me on Ko-fi. You can
    find all of these resources at the following link: [https://ko-fi.com/s/4ddca6dff1](https://ko-fi.com/s/4ddca6dff1)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用Google表格演示实现过程。如果您希望访问这个表格以及我开发的其他表格——例如梯度下降的线性回归、逻辑回归、带反向传播的神经网络、KNN、K均值等——请考虑在Ko-fi上支持我。您可以在以下链接找到所有这些资源：[https://ko-fi.com/s/4ddca6dff1](https://ko-fi.com/s/4ddca6dff1)
- en: A Simple Decision Tree with a Simple dataset
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的数据集上的简单决策树
- en: Let’s use a simple dataset with only one continuous feature.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个只有一个连续特征的简单数据集。
- en: '![](../Images/9df88702c0faaf46171e4d283c42ce9e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9df88702c0faaf46171e4d283c42ce9e.png)'
- en: Decision tree regression in Excel simple dataset — image by author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Excel中简单数据集的决策树回归——作者提供的图像
- en: We can visually guess that for the first split, there are two possible values
    one around 5.5 and the other around 12\. Now the question is, which one do we
    choose?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直观地猜测，对于第一次分裂，有两个可能的值，一个在5.5左右，另一个在12左右。现在的问题是，我们选择哪个？
- en: To determine this, we can see a result from scikit learn using the DecisionTreeRegressor
    estimator. The image below shows that the first split is 5.5 since it leads to
    the lowest squared error. What does this mean exactly?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定这一点，我们可以查看使用DecisionTreeRegressor估计器的scikit learn的结果。下图显示了第一次分裂是5.5，因为它导致了最低的平方误差。这到底意味着什么？
- en: '![](../Images/22cf33bf6a49b0ffef0520a6dfb1a715.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22cf33bf6a49b0ffef0520a6dfb1a715.png)'
- en: Simple Decision tree regression — image by author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的决策树回归——作者提供的图像
- en: 'This is exactly what we are going to find out: how do we determine the value
    for the first split with an implementation in Excel? Once we determine the value
    for the first split, we can apply the same process for the following splits. That
    is why we will only implement the first split in Excel.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们要找出的：如何通过在Excel中实现第一次分裂来确定其值？一旦确定第一次分裂的值，我们可以对随后的分裂应用相同的过程。这就是为什么我们将只在Excel中实现第一次分裂。
- en: Algorithmic Principle of Decision Tree Regressors
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树回归器的算法原理
- en: Decision tree algorithms in 3 steps
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策树算法的三步骤
- en: 'I wrote [an article to always distinguish three steps of machine learning to
    learn it in an effective way](https://medium.com/towards-data-science/machine-learning-in-three-steps-how-to-efficiently-learn-it-aefcf423a9e1),
    and let’s apply the principle to Decision Tree Regressors:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我写了[一篇文章来始终区分机器学习的三个步骤，以有效地学习它](https://medium.com/towards-data-science/machine-learning-in-three-steps-how-to-efficiently-learn-it-aefcf423a9e1)，让我们将这个原则应用于决策树回归器：
- en: '**1\. Model:** the model here is a set of rules, it is interesting to notice
    that it is different from a mathematical function-based model in the sense that
    for linear regression, we can write the model in the following form: y=aX+b, and
    the parameters a and b are to be determined. For a decision tree, the model is
    not parametric.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1\. 模型：** 这里的模型是一组规则，值得注意的是，它与基于数学函数的模型不同，例如线性回归中，我们可以将模型写成 y=aX+b，其中参数 a
    和 b 需要确定。而决策树模型则是非参数的。'
- en: '**2\. Model fitting:** for a decision tree, we also call this process fully
    growing a tree. In the case of a Decision Tree Regressor, the leaves will contain
    only one observation with thus a MSE of zero.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2\. 模型拟合：** 对于决策树，我们也称这一过程为完全生长一棵树。在决策树回归器的情况下，叶节点将仅包含一个观察值，因此MSE为零。'
- en: '**3\. Model tuning:** for a decision tree, we also call it pruning, which consists
    of optimizing the hyperparameters such as the minimum number of observations in
    the leaves and the maximum depth.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3\. 模型调整：** 对于决策树，我们也称之为剪枝，包括优化超参数，如叶节点中的最小观察数和最大深度。'
- en: Training process
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练过程
- en: Growing a tree consists of recursively partitioning the input data into smaller
    and smaller chunks or regions. For each region, a prediction can be calculated.
    In the case of regression, the prediction is the average of the target variable
    for the region.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 生长一棵树包括递归地将输入数据划分为越来越小的块或区域。对于每个区域，可以计算预测值。在回归的情况下，预测值是该区域的目标变量的平均值。
- en: At each step of the building process, the algorithm selects the feature and
    the split value that maximizes the one criterion, and in the case of a regressor,
    it is often the Mean Squared Error (MSE) between the actual value and the prediction.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建过程的每一步，算法选择特征和分裂值，以最大化一个标准，而对于回归器，这通常是实际值与预测值之间的均方误差（MSE）。
- en: Tuning or pruning
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整或剪枝
- en: The pruning process can be seen as dropping nodes and leaves from a fully grown
    tree, or it is also equivalent to say that the building process stops when a criterion
    is met, such as a maximum depth or a minimum number of samples in each leaf node.
    And these are the hyperparameters that can be optimized with the tuning process.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 剪枝过程可以看作是从完全生长的树中删除节点和叶子，或者也可以等同于说当满足某个标准时（如最大深度或每个叶节点中的最小样本数）构建过程停止。这些就是可以通过调整过程优化的超参数。
- en: Below we have some examples of trees with different value of max depth.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些具有不同最大深度值的树的示例。
- en: '![](../Images/ce425193980e93660c02103190c00dbc.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce425193980e93660c02103190c00dbc.png)'
- en: Decision tree regression with different max depth— image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 不同最大深度的决策树回归— 作者提供的图像
- en: Inferencing process
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理过程
- en: Once the decision tree regressor is built, it can be used to predict the target
    variable for new input instances by applying the rules and traversing the tree
    from the root node to a leaf node that corresponds to the input’s feature values.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦决策树回归器建立完成，它可以通过应用规则和从根节点遍历到与输入特征值对应的叶节点来预测新输入实例的目标变量。
- en: The predicted target value for the input instance is then the mean of the target
    values of the training samples that fall into the same leaf node.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入实例的预测目标值是落在同一叶节点中的训练样本的目标值的均值。
- en: Implementation in Excel of the First Split
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Excel中实现第一次分裂
- en: 'Here are the steps we will follow:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将遵循的步骤：
- en: List all possible splits
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有可能的分裂
- en: For each split, we will calculate the MSE (Mean Squared Error)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每一个分割，我们将计算 MSE（均方误差）
- en: We will select the split that minimizes the MSE as the optimal next split
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将选择最小化 MSE 的分割作为最优下一个分割
- en: All possible splits
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所有可能的分割
- en: First, we have to list all the possible splits that are the average values of
    two consecutive values. There is no need to test more values.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要列出所有可能的分割，这些分割是两个连续值的平均值。不需要测试更多的值。
- en: '![](../Images/62f2a2716d465906a80f571bac86e760.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62f2a2716d465906a80f571bac86e760.png)'
- en: Decision tree regression in Excel with possible splits — image by author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Excel 中的决策树回归可能的分割 — 作者图片
- en: MSE calculation for each possible split
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每个可能分割的 MSE 计算
- en: As a starting point, we can calculate the MSE before any splits. This also means
    that the prediction is just the average value of y. And the MSE is equivalent
    to the Standard Deviation of y.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作为起点，我们可以在任何分割之前计算均方误差（MSE）。这也意味着预测只是 y 的平均值。而 MSE 相当于 y 的标准差。
- en: Now, the idea is to find a split so that the MSE with a split is lower than
    before. It is possible that the split does not significantly improve the performance
    (or lower the MSE), then the final tree would be trivial, that is the average
    value of y.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，目标是找到一个分割，使得分割后的 MSE 低于之前的值。可能分割不会显著提高性能（或降低 MSE），那么最终的树将会很简单，即 y 的平均值。
- en: For each possible split, we can then calculate the MSE (Mean Squared Error).
    The image below shows the calculation for the first possible split, which is x
    = 2.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一个可能的分割，我们可以计算 MSE（均方误差）。下图显示了第一个可能分割的计算结果，即 x = 2。
- en: '![](../Images/4ef5116c70eb2a2e6781ce45ac54bae1.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ef5116c70eb2a2e6781ce45ac54bae1.png)'
- en: Decision tree regression in Excel MSE for all possible splits — image by author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Excel 中的决策树回归所有可能分割的 MSE — 作者图片
- en: 'We can see the details of the calculation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看计算的详细信息：
- en: 'Cut the dataset into two regions: with the value x=2, we determine two possibilities
    x<2 or x>2, so the x axis is cut into two parts.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集切割成两个区域：以 x=2 为例，我们确定了两个可能性 x<2 或 x>2，因此 x 轴被分成两部分。
- en: 'Calculate the prediction: for each part, we calculate the average of y. That
    is the potential prediction for y.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算预测值：对于每一部分，我们计算 y 的平均值。这是 y 的潜在预测值。
- en: 'Calculate the error: then we compare the prediction to the actual value of
    y'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算误差：然后我们将预测值与实际的 y 值进行比较
- en: 'Calculate the squared error: for each observation, we can know calculate the
    square error.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算平方误差：对于每个观察值，我们可以计算平方误差。
- en: '![](../Images/93db904dbc1354de6e8485d37f62ac8e.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93db904dbc1354de6e8485d37f62ac8e.png)'
- en: Decision tree regression in Excel with all possible splits — image by author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Excel 中的决策树回归所有可能分割 — 作者图片
- en: Optimal split
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最优分割
- en: For each possible split, we do the same to obtain the MSE. In Excel, we can
    copy and paste the formula and the only value that changes is the possible split
    value for x.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一个可能的分割，我们做相同的操作以获得 MSE。在 Excel 中，我们可以复制并粘贴公式，唯一变化的是 x 的可能分割值。
- en: '![](../Images/271d64a43ea7187bdcd8061e91fe9289.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/271d64a43ea7187bdcd8061e91fe9289.png)'
- en: Decision tree regression in Excel splits— image by author
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Excel 中的决策树回归分割 — 作者图片
- en: Then we can plot the MSE on the y-axis and the possible split on the x-axis,
    and now we can see that there is a minimum of MSE for x=5.5, this is exactly the
    result obtained with python code.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以将 MSE 绘制在 y 轴上，将可能的分割绘制在 x 轴上，现在我们可以看到 x=5.5 时 MSE 最小，这正是通过 Python 代码得到的结果。
- en: '![](../Images/79041106a2a75b51b2bb2fa4ce12cb2b.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79041106a2a75b51b2bb2fa4ce12cb2b.png)'
- en: Decision tree regression in Excel Minimumization of MSE — image by author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Excel 中的决策树回归 MSE 的最小化 — 作者图片
- en: Exercise you can do
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你可以做的练习
- en: 'Now, you can play with the Google Sheet:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以使用 Google Sheet 进行操作：
- en: you can modify the dataset
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以修改数据集
- en: you can introduce a categorical feature
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以引入一个分类特征
- en: you can try to find the next split
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以尝试寻找下一个分割
- en: you can change the criterion, instead of MSE, you can use absolute error, Poisson
    or friedman_mse as indicated in the documentation of [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以改变标准，不仅使用 MSE，还可以使用绝对误差、泊松误差或 friedman_mse，正如 [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)
    文档中所示
- en: you can change the target variable to a binary variable, normally, this becomes
    a classification task, but 0 or 1 are also numbers so the criterion MSE still
    can be applied. But if you want to create a proper classifier, you have to apply
    the usual criterion Entroy or Gini. I will soon publish another article for the
    Decision Tree Classifier, stay tuned.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将目标变量更改为二进制变量，通常这会变成一个分类任务，但0或1也是数字，因此标准MSE仍然适用。但如果你想创建一个合适的分类器，你必须应用通常的标准**Entroy**或**Gini**。我会很快发布另一篇关于决策树分类器的文章，敬请关注。
- en: Conclusion
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Using Excel, it is possible to implement one split to gain more insights into
    how Decision Tree Regressors work. Even though we didn’t create a full tree, it
    is still interesting since the most important part is finding the optimal split
    among all possible splits.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Excel，可以进行一次分割，以深入了解决策树回归器如何工作。尽管我们没有创建完整的树，但这仍然很有趣，因为最重要的部分是找到所有可能分割中的最佳分割。
- en: 'I write about machine learning and data science and I explain complex concepts
    in a clear way. Please follow me with the link below and get full access to my
    articles: [https://medium.com/@angela.shi/membership](https://medium.com/@angela.shi/membership)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我写关于机器学习和数据科学的文章，并以清晰的方式解释复杂概念。请通过下面的链接关注我，并获得对我的文章的全部访问权限：[https://medium.com/@angela.shi/membership](https://medium.com/@angela.shi/membership)
