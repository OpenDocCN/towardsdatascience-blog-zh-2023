- en: You Can’t Step in the Same River Twice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/you-cant-step-in-the-same-river-twice-cfacf7cee305](https://towardsdatascience.com/you-cant-step-in-the-same-river-twice-cfacf7cee305)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/5a6342f9f1812f624416fcc0889cb8bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vladislav Babienko](https://unsplash.com/@garri?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: “The Book of Why” Chapters 7&8, a Read with Me series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://zzhu17.medium.com/?source=post_page-----cfacf7cee305--------------------------------)[![Zijing
    Zhu, PhD](../Images/436b22e28798b87261c4814a7e2b20e3.png)](https://zzhu17.medium.com/?source=post_page-----cfacf7cee305--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cfacf7cee305--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cfacf7cee305--------------------------------)
    [Zijing Zhu, PhD](https://zzhu17.medium.com/?source=post_page-----cfacf7cee305--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cfacf7cee305--------------------------------)
    ·18 min read·Dec 20, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: In my [previous articles](https://zzhu17.medium.com/list/causality-book-club-def5f1fd00fe),
    we learned about confounders and colliders in observational data that hinder establishing
    reliable causal relationships. The solution Pearl provided is to draw causal diagrams
    and use [the backdoor criterion](https://medium.com/towards-data-science/causal-diagram-confronting-the-achilles-heel-in-observational-data-a69cdb1c4818)
    to find the sets of confounders to block and leave the colliders and mediators
    along.
  prefs: []
  type: TYPE_NORMAL
- en: However, when dealing with confounding variables that cannot be observed or
    measured, it becomes difficult to estimate causality from the observational data.
    Coping with this issue, in Chapter 7 of "The Book of Why," Judea Pearl introduced
    the **do-calculus rules**. These rules are particularly useful for the **front-door
    criterion** and **instrumental variables**. They can be used to establish causality
    even when unobservable confounding variables are present.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Chapter 8, we will explore the amazing world of **counterfactuals**. Opening
    with Poet Robert Frost’s famous lines:'
  prefs: []
  type: TYPE_NORMAL
- en: “And sorry I could not travel both
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And be one traveler, long I stood…”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pearl states although it’s impossible to travel both paths or step into the
    same rivers twice, our brains can imagine what would have happened if we had taken
    the other path. In order to specify and pass down the wisdom to robots, Pearl
    introduces the distinctions between **necessary cause** and **sufficient cause**
    and how to utilize **Structure Causal Models** to conduct counterfactual analysis
    systematically.
  prefs: []
  type: TYPE_NORMAL
- en: As we pass the midpoint, the chapters are getting more technical and information-intensive.
    In the following section, I will first discuss how to deal with unobserved confounders,
    unfortunately, with some math, for Rung 2 interventions. Then, I will discuss
    counterfactuals, a Rung 3 application.
  prefs: []
  type: TYPE_NORMAL
- en: The front-door criterion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Starting with a causal diagram that we use to understand the causal impact
    of X on Y:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c814390a491ccc898d9cbd232091c0ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author based on “The Book of Why” Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: Here, X is impacting Y through a mediator, M. However, we cannot estimate causality
    directly from data without controlling the confounder U. The backdoor path from
    **“U -> X”** generates a spurious correlation between X and Y. The backdoor criterion
    tells us to control U, but what if U is unobservable?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2859c9542b29a925fdd8de186d02de4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Tobias Tullius](https://unsplash.com/@tobiastu?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in analyzing the causal relationship between smoke (X) and cancer
    (Y), we might see this causal diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9a2dc16f21bea5cfb655467c6c6a1637.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author based on “The Book of Why” Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: Here, smoking causes cancer through the accumulation of tar deposits, and there
    is a confounder, the smoking gene, which, as argued by some researchers, can influence
    both one’s smoking behaviors and the chances of getting lung cancer. We couldn’t
    collect data on such genes because we don’t know whether they exist. Thus, back-door
    adjustments cannot work in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the causal impact, we can use the **front-door criterion** instead.
    The front door here is the mediating process, where smoking increases tar deposits
    and increases the chances of getting cancer. If we cannot estimate smoke to cancer
    directly, can we estimate how smoke causally impacts tar with how tar causally
    impacts cancer instead? Here are the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Smoking -> Tar**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is only one back door path from smoking to tar:'
  prefs: []
  type: TYPE_NORMAL
- en: Smoking <- Smoking Gene -> Cancer <- Tar
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'And it’s blocked by the Collider cancer. So, we can estimate the causal impact
    of smoking to tar directly from data by calculating the conditional probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2: Tar -> Cancer**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one back door path from tar to cancer:'
  prefs: []
  type: TYPE_NORMAL
- en: Tar <- Smoking <- Smoking Gene -> Cancer
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here, both smoking and the smoking gene are the confounders, but we can control
    one of them to block the path. Since we don’t have data about the smoking gene,
    we can control smoking instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To estimate how tar impacts cancer causally, we measure the following four
    probabilities from the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The probability of getting cancer through accumulated tar in the smoking population:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(cancer|tar, smoking) * P(smoking)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The probability of getting cancer through accumulating tar in the non-smoking
    population:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(cancer|tar, no smoking) * P(no smoking)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The probability of getting cancer without enough tar in the smoking population:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(cancer|no tar, smoking) * P(smoking)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The probability of getting cancer without enough tar in the non-smoking population:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(cancer|no tar, no smoking) * P(no smoking)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Step 3: Smoking -> Tar -> Cancer**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we know the causal impact of smoking on tar and the causal impact of tar
    on cancer, we can derive the unbiased causal impact of smoking on cancer through
    the front door adjustment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, in more general terms, for any causal diagram that resembles the previous
    one in these ways:'
  prefs: []
  type: TYPE_NORMAL
- en: X affects Y through only a mediator M, which is also the front door;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is an unobservable confounder U, correlated with X and Y but not with
    the mediator M;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following formula using the front door adjustment works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/71a74d584715ba5991d19a85859b27e2.png)'
  prefs: []
  type: TYPE_IMG
- en: The front door adjustment
  prefs: []
  type: TYPE_NORMAL
- en: 'Compared to the back door adjustment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/78235dee46b1b2a3a03b5946ddd1aef4.png)'
  prefs: []
  type: TYPE_IMG
- en: The back door adjustment
  prefs: []
  type: TYPE_NORMAL
- en: Both formulas estimate the causal impact of X on Y, and they all remove the
    ***do*** operator successfully. This means we can estimate the causal impact from
    data, i.e., **drawing Rung 2&3 conclusions from Rung 1 data**. In the front door
    adjustment formula, we also removed the unobserved confounders U successfully.
    In the smoking to cancer case, we can estimate the impact of smoking without including
    the smoking gene.
  prefs: []
  type: TYPE_NORMAL
- en: 'The front door criterion opens the door for squeezing a bit more juice out
    of observational data, even facing unmeasurable confounders. However, there are
    challenges regarding its applications since the real world usually functions messier
    and more complicated than the textbook causal diagrams. For example, the unobserved
    confounder could also impact the mediator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/acd41b7c71ee11dd44fc60d9804eb713.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author based on “The Book of Why” Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: Even with this complication, as long as the relationship between U and M is
    weak, using the “gold standard” randomized control trial (RCT) estimation of P(Y|do(X))
    as a benchmark, the empirical research shows that using the front door adjustment
    provides a better estimation than the back door adjustment without blocking all
    necessary back doors due to unobserved confounders.
  prefs: []
  type: TYPE_NORMAL
- en: Do-calculus rules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the example above that illustrates the front door adjustment, Pearl also
    summaries three rules that provide general guidance in the process of removing
    ***do***s :'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 1 shows if variable W is irrelevant to Y, or its direct path to Y is blocked
    by variable Z, then removing or adding W will not change the following probabilities:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/97b86132ea4f0e43063e6c534850ceeb.png)'
  prefs: []
  type: TYPE_IMG
- en: Rule 1 of do-calculus
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 2 shows if a variable set Z blocks all back-door paths from X to Y, then
    conditional on Z will remove the ***do*** operation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/ca6a040c3cea7685510c47af09d8b585.png)'
  prefs: []
  type: TYPE_IMG
- en: Rule 2 of do-calculus
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 3 shows if there are no causal paths from X to Y, then we can remove the
    ***do*** operation entirely:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d29ed8fbdd9ed0e5ad77a422750c7892.png)'
  prefs: []
  type: TYPE_IMG
- en: Rule 3 of do-calculus
  prefs: []
  type: TYPE_NORMAL
- en: The above three rules set the foundation for ***do-***calculus that allows us
    to derive Rung 2 and 3 causal impacts out of observational data. Rule 1 shows
    what variables are useful to collect from the data; Rule 2 shows how to derive
    intervention, a Rung 2 conclusion, out of observational data; Rule 3 shows whether
    an intervention will be effective.
  prefs: []
  type: TYPE_NORMAL
- en: 'More math alert: skip if math gives you a headache'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the three rules, we can revisit the smoking-to-cancer causal diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9a2dc16f21bea5cfb655467c6c6a1637.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author based on “The Book of Why” Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: 'And see how we utilize Rules 2 and 3 even in more general cases. Here are the
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2009ee11e1dcf4a723fcd593be106f03.png)'
  prefs: []
  type: TYPE_IMG
- en: 7 Steps Based on “The Book of Why” Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, to understand how smoking causally impacts cancer, we are using the front
    door path smoking -> tar -> cancer in 7 steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 is based on probability theories where we introduce the mediator t, tar,
    to estimate the causal impact;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 2 is based on Rule 2\. Since tar -> cancer’s back door is blocked by s,
    smoking, we can replace (do(s), t) with (do(s), do(t));
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 3 is based on Rule 2 again. Since smoking -> tar doesn’t have back doors,
    we can replace do(s) with s;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 4 is based on Rule 3\. Since smoking is only causally impacting cancer
    through tar, we can replace P(c|do(s), do(t)) with P(c|do(t));
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 5 is based on probability theories, where we introduce different spectra
    of S into the equation. In this case, we have smoking vs non-smoking;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 6 is based on Rule 2\. Again, tar -> cancer’s back door is blocked by s,
    so we replace (do(t), s’) with (t, s’);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 7 is based on Rule 3\. Since tar doesn’t have a causal impact on smoking,
    we replace P(s’|do(t)) with P(s’).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the last equation, we can see that we have removed the do operation completely,
    and there are no unobservable variables. The next step will be using data to calculate
    the causal impact.
  prefs: []
  type: TYPE_NORMAL
- en: Instrument variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another way to deal with the unobserved confounder is to find instrument variables.
    The definition of instrument variables is better illustrated in a causal diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2314bc16954bca29b097e7199e3ee57.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author based on “The Book of Why” Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: 'Supposedly, when estimating the causal impact of X on Y, there is an unobservable
    confounder U that prevents us from getting the correct estimation. If there exists
    a variable Z that satisfies:'
  prefs: []
  type: TYPE_NORMAL
- en: Z and U are not correlated. In the diagram, there is no arrow between Z and
    U;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Z is the direct cause of X;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Z only affects Y through X. In other words, there is no direct or indirect arrow
    from Z to Y except Z->X->Y.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Z will be a very good instrument variable if all conditions are satisfied. Instrument
    variables are very useful in many scientific fields. In the book, Pearl provides
    an example of using instrument variables to study a medicine’s treatment effect
    during clinical trials.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4b18fb3115e92d2a88d536f00ecdf22.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [AbsolutVision](https://unsplash.com/@alterego_swiss?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The medicine was invented to lower patients' cholesterol levels. Although clinical
    trials are usually randomized, they still face the challenge of noncompliance,
    where subjects receive the medicine but choose not to take it.
  prefs: []
  type: TYPE_NORMAL
- en: Their decisions on not taking the medicine can depend on multiple factors, like
    how sick they are, and are usually unobservable or hard to measure. The existence
    of noncompliances will reduce the estimation of drug effectiveness, and we don’t
    really have a good way to predict how many noncompliances there will be in a clinical
    trial.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, researchers introduce an instrument variable, “Assigned,” into
    the RCT design. “Assigned” takes the value one if the patient is randomly assigned
    to receive the drug and zero if they receive a placebo. We will have the following
    causal diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/40d093b2bd7cfa3d31d861eaee7e9b74.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author based on “The Book of Why” Chapter 7
  prefs: []
  type: TYPE_NORMAL
- en: '“Assigned” is an instrument variable because:'
  prefs: []
  type: TYPE_NORMAL
- en: The assignment of receiving pills is randomized among patients. Thus, it is
    not correlated with any confounders U;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which groups patients are assigned to will determine which treatment they receive,
    either a drug or a placebo. Thus, “Assigned” is the direct cause of “Received”;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether a patient is put into a placebo group or not doesn’t affect his or her
    cholesterol level directly. Thus, “Assigned” only affects Cholesterol through
    Received.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we find or establish an instrument variable, we can estimate three relationships
    in the observational data:'
  prefs: []
  type: TYPE_NORMAL
- en: The causal impact of Assigned -> Received;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The causal impact of Assigned -> Cholesterol;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The causal impact of Received -> Cholesterol by removing the “Assigned -> Received”
    impact from “Assigned -> Cholesterol”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s the definition of an instrument variable, along with an example. Pearl’s
    book contains more examples of how instrument variables can be used to solve the
    unobserved confounders’ problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Counterfactuals: What could have been?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Moving from Rung 2 to Rung 3 of the causality ladder, we are now facing the
    problem of finding what could have been the outcome without the treatment. This
    is different from Rung 2 interventions in two aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**From average causal effect to individual causal effect:**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So far, the causal impact we have discussed is focused on a population or subpopulation.
    For example, does smoke cause cancer or not for everyone? However, the more applicable
    question, especially in solving real-world problems, is the **individual causal
    effect**. For example, if I start smoking, does it cause me to have cancer? If
    I give this customer a discount, will he or she buy more products? The personalized
    causation can be inferred through counterfactual analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88260dc6383b5204d0e956f23c183cc5.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ilya lix](https://unsplash.com/@ilya90?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. There are two types of counterfactuals:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In binary settings, the outcome and potential outcome have two options. In
    the example of smoke vs cancer, the outcome is either getting cancer or no cancer.
    Correspondingly, there would be two types of potential outcomes and two sets of
    causal factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Necessary causation:** If one person gets cancer, the potential outcome is
    no cancer, and we determine whether smoking is what the lawyers called “***but-for
    causation***”: the cancer would not have developed ***but for*** the smoking behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sufficient causation:** If one person does not get cancer, the potential
    outcome is cancer, and we determine whether having a smoking behavior would have
    developed cancer for this person.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distinguishing necessary causation and sufficient causation not only helps robot
    think more like a human in determining causality but us find better action points
    given different goals and scenarios—more on this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Matching vs Structure Causal Models (SCM)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When posed with the question of what could have been, we may approach it as
    a missing data problem. Take the example of figuring out how increasing education
    can improve income for different people. Here is the data summarized in a table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b03a3b9d6b77e95e10445629cbf7dafe.png)'
  prefs: []
  type: TYPE_IMG
- en: Table by author based on “The Book of Why” Chapter 8, Table 8.1
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we have various data entries from different employees and their current
    experience level (EX) and their highest education level (ED). To simplify, we
    assume three levels of education: 0 = high school degree, 1 = college degree,
    and 2 = graduate degree.'
  prefs: []
  type: TYPE_NORMAL
- en: Their salaries are also reported as S0, S1, S2\. Note that since each employee
    can only have one highest-level education degree at a given time point, we will
    have two missing entries for S0, S1, and S2 for all employees.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we approach filling the question marks in the above table as a missing data
    problem, we have two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Matching:**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We find similar employees and match salary levels at different education levels.
    For example, in the table, we only have one extra feature — Experience, and we
    see Bert and Caroline both have nine years of experience, then we can have S2(Bert)
    = S2(Caroline) = $97,000, and S1(Caroline) = S1(Bert) = $92,500\. Two missing
    data filled!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/30b999ea225e29eba554a522f3166336.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kara Eads](https://unsplash.com/@karaeads?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Linear Regression or more complicated models**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the strong assumption that all data came from some unknown random sources,
    standard statistical models find models that best fit the data. In a linear regression
    model, we might find an equation like this for this particular problem:'
  prefs: []
  type: TYPE_NORMAL
- en: S = $65,000 + 2,500*EX + 5,000*ED
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the coefficients, the equation tells us on average, one level increase
    in education increases salary by $5,000\. We can use more complicated models when
    feature space increases.
  prefs: []
  type: TYPE_NORMAL
- en: What’s wrong with these methods? Fundamentally, they are both approaches that
    are data-driven rather than model-driven. We are still trying to solve a Rung
    3 problem with Rung 1 approaches. Thus, no matter how complicated our models get
    and how many more features we gain to predict the outcome variable, we still face
    the fundamental flaw of missing the causal mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this simple example, one problem we have is Experience and Education are
    not independent of each other. Generally, more education may reduce the years
    of experience for an individual. If Bert were to have a graduate degree rather
    than the college degree he has right now, his experience level would be lower
    than nine years. Thus, he would not be a good match with the nine-year experienced
    graduate degree holder Caroline anymore. In summarize, we will have a causal graph
    that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/998116513aa35bbd1a5d3b58846b758a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author based on “The Book of Why” Chapter 8
  prefs: []
  type: TYPE_NORMAL
- en: 'The causal diagram indicates that Education not only has a direct causal impact
    on Salary, but it also affects Salary through the mediator Experience. Thus, we
    will need two equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several points to make regarding these equations, which constitute
    the Structure Causal Models (SCM) for this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: Salary is a function of Experience, Education, and some unobservable variable
    that affects Salary U_s. Note the unobservable variable is exogenous, meaning
    they are not correlated with Education and Experience;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experience is a function of Education and some unobservable variables that affect
    Experience U_ex.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fact that there is no function shows Education as a function of Experience
    means that there are no causal effects from Experience to Education. This is the
    assumption we make.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These two equations assume causalities between the right-hand side (the outcome)
    and the left-hand side(the treatment).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The unobservable variables U_s and U_ex quantify the uncertainties at the individual
    level, which differs from Bayesian networks that use probabilities at causal links
    to quantify uncertainties. They are independent of Experience or Education and
    can be customized by individuals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function f represents the relationship between the features and the outcome
    variable. It can be both linear and non-linear, depending on the assumptions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we still assume a linear relationship, we will have the following equations
    based on the data and our understanding of how education affects experience:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'With these equations, we can calculate every one’s idiosyncratic factors U_s
    and U_ex to predict counterfactuals. Take Alice as an example. We know S(Alice)
    is 81000, EX(Alice) is six, and ED(Alice) is 0\. First, plug these into the second
    equation to get U_ex. We want to plug in the second equation because it only contains
    ED, the only causal factor of our interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, rather than simply plugging EX(Alice) into the equations, we are using
    this value indirectly. Knowing EX(Alice) equals six helps us calculate U_ex(Alice).
    Then we plug S(Alice), ED(Alice) and U_ex(Alice) into the first equation to get
    U_s(Alice):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we have the functions for Alice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the SCMs are ready, we can do a counterfactual analysis for Alice. We
    can calculate what would be her salary had she attended college. If ED(Alice)
    is 1 instead of 0, we will first calculate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then calculate S_1(Alice):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the difference we might get from the regression model where we plug in
    ED(Alice) = 1 and EX(Alice)=6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a simple example of utilizing SCMs to understand the causal impact
    and calculate the counterfactuals at the individual level. In summary, Pearl calls
    “the first law of causal inference”:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2c22fb9cc83f8aa8ade93df5fdc722b.png)'
  prefs: []
  type: TYPE_IMG
- en: The equation shows the potential outcome Y_x(u) can be imputed by Model M_x
    if we can remove all back-door paths to X. Here, the model takes much more flexibility
    than linear regression models as long as the causality is embedded based on the
    causal diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Necessary Cause (PN) vs. Sufficient Cause (PS)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand counterfactuals, we have two different measurements: the probability
    of necessity (PN) and the probability of sufficiency (PS). To see the difference,
    let’s use an example: the house is set on fire because someone struck the match,
    and there is oxygen in the air:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/498baf304dd8f465c3a85f8028987864.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Both match and oxygen are causal factors in a house on fire. However, they
    differ in PN and PS. The probability of necessity is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the house was on fire, and a match had struck (Y=1, x=1). This
    probability asks if the house would not have been on fire had the match not struck
    (Y_(x=0) = 0). This probability is very high because even though we have enough
    oxygen, with fire from the match, the house will not be on fire.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70c7e0ba1ad9abe0b0bfeee0e9d87d50.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Erick Zajac](https://unsplash.com/@erickzajac?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The same logic applies when we calculate the PN for x=oxygen. The fire would
    not occur if there were not enough oxygen in the house, even if we struck the
    match.
  prefs: []
  type: TYPE_NORMAL
- en: The probability of necessity shows what would happen to the outcome variable
    if the treatment ***hadn’t*** happened. If the probability is high, it means this
    treatment is a necessary cause. In a court setting, proving the victim wouldn’t
    have died if the accused hadn’t done something is enough to convict.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the probability of sufficient is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the house was not on fire, and a match hadn’t struck (Y=0, x=0).
    This probability asks if the house would have been on fire had the match struck
    (Y_(x=0) = 0). This probability is also very high because usually, oxygen is everywhere,
    and the house is very likely to be on fire with oxygen and fire from striking
    the match.
  prefs: []
  type: TYPE_NORMAL
- en: The PS for oxygen, however, is very low. The fire would not likely occur just
    because the house has oxygen. Oxygen is not sufficient to set the house on fire.
    We need the action of bringing other fire sources like striking the match.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the probability of sufficient tells us what would happen to the outcome
    variable if the treatment ***had*** happened. If the probability is high, it means
    this treatment is a sufficient cause. In this case, striking the match qualifies
    as a sufficient cause for a house fire, but oxygen doesn’t.
  prefs: []
  type: TYPE_NORMAL
- en: Why distinguish PS and PN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Why bother making these distinctions?*** In a nutshell, although multiple
    variables can be the causal factors for an outcome, human brains automatically
    “rank” these factors based on some conditions. Psychologists found that humans
    imagining actions could have been done to turn around an undesired outcome. They
    are more likely to:'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine undoing a rare event than a common one. For example, striking a match
    is a more rare event compared to having oxygen in the house. (Hopefully!)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human is more likely to blame their own actions, i.e., striking a match, than
    events not under their control.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As Pearl emphasizes, embedding both PN and PS into models would suggest a systematic
    way for teaching robots to produce meaningful explanations of the observed outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38dad1dd70e580cceeb2f748d85c9cb9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Brett Jordan](https://unsplash.com/@brett_jordan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, understanding the distinctions between PS and PN guides us to
    the action points. Climate scientists who study and find the cause of the extreme
    heat waves may have two different statements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'PN: There is a 90% probability that man-made climate change was a necessary
    cause of a heat wave;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PS: There is an 80% probability that climate change will be sufficient to produce
    a heat wave this strong at least once every 50 years.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The PN statement tells us about attribution: who was responsible for the heat
    wave — man-made climate change. It finds the cause. The PS statement tells us
    about policy. It says we are better prepared for the heat waves because more is
    happening. Who caused it? Not specified. Both statements are informative, just
    in different ways.'
  prefs: []
  type: TYPE_NORMAL
- en: '**What a long read!** This completes the 5th article in this “Read with Me”
    series for Judea Pearl’s “The Book of Why.” Thanks for hanging to the end. Chapters
    7 and 8 are definitely information-dense. I hope this article is helpful to you.
    If you haven’t read the first four articles, check them out here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Kick-off: Start with A Cat Story**](https://medium.com/towards-data-science/read-with-me-a-causality-book-club-edd7085d6ae6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Chapter1&2: Data Tells Us ‘What” and We Always Seek for “Why”**](https://medium.com/towards-data-science/data-tells-us-what-and-we-always-seek-for-why-66da7dc3f24d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Chapter3&4: Causal Diagram: Confronting the Achilles’ Heel in Observational
    Data**](https://medium.com/towards-data-science/causal-diagram-confronting-the-achilles-heel-in-observational-data-a69cdb1c4818)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Chapter5&6:Why Understanding the Data-Generation Process Is More Important
    Than the Data Itself**](https://zzhu17.medium.com/towards-data-science/why-understanding-the-data-generation-process-is-more-important-than-the-data-itself-f1b3b847e662)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If interested, [subscribe to my email list](https://zzhu17.medium.com/subscribe)
    to join the currently ongoing biweekly discussions. We will have one more article
    to come that will focus on mediators and conclude the series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/what-makes-a-strong-ai-012315722793?source=post_page-----cfacf7cee305--------------------------------)
    [## What Makes A Strong AI?'
  prefs: []
  type: TYPE_NORMAL
- en: “The Book of Why” Chapters 9&10, a Read with Me series
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/what-makes-a-strong-ai-012315722793?source=post_page-----cfacf7cee305--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'And a bonus article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-is-causal-inference-different-in-academia-and-industry-fb5afd12e2e7?source=post_page-----cfacf7cee305--------------------------------)
    [## How is Causal Inference Different in Academia and Industry?'
  prefs: []
  type: TYPE_NORMAL
- en: A Bonus Article for “The Book of Why” Series
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-is-causal-inference-different-in-academia-and-industry-fb5afd12e2e7?source=post_page-----cfacf7cee305--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: As always, I highly encourage you to read, think, and share your main takeaways
    here or on [your own blog](https://youtu.be/oFDl0-SKAL8?si=r1QiRIizhDBdvX-A).
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks for reading. If you like this article, don’t forget to:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Check my recent articles about*** [***the 4Ds in data storytelling: making
    art out of science***](https://medium.com/towards-data-science/the-4ds-in-data-storytelling-making-art-out-of-science-c4998ed7875e);[***continuous
    learning in data science***](/continuous-learning-a-data-scientists-odyssey-8d3006c2ce01)***;***
    [***how I become a data scientist***](/how-i-became-a-data-scientist-7f5b10606612)***;***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Check my*** [***other articles***](https://zzhu17.medium.com/my-blog-posts-gallery-ac6e01fe5cc3)
    ***on different topics like*** [***data science interview preparation***](https://zzhu17.medium.com/list/data-science-interview-preparation-bfb0986a61a3)***;***
    [***causal inference***](/causal-inference-what-why-and-how-d7336b0081ec)***;***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***Subscribe***](https://zzhu17.medium.com/subscribe) ***to my email list;***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***Sign up for medium membership***](https://zzhu17.medium.com/membership)***;***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Or follow me on*** [***YouTube***](https://youtube.com/channel/UCMs6go1pvY5OOy1DXVtMo5A)
    ***and watch my most recent YouTube videos:***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
