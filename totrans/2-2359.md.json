["```py\nclass Transcription:\n    \"\"\"\n    A class to handle audio transcriptions using either the Whisper or Whisper JAX model.\n\n    Attributes:\n        audio_file_path (str): Path to the audio file to transcribe.\n        model_type (str): The type of model to use for transcription, either \"whisper\" or \"whisper_jax\".\n        device (str): The device to use for inference (e.g., \"cpu\" or \"cuda\").\n        model_name (str): The specific model to use (e.g., \"base\", \"medium\", \"large\", or \"large-v2\").\n        dtype (Optional[str]): The data type to use for Whisper JAX, either \"bfloat16\" or \"bfloat32\".\n        batch_size (Optional[int]): The batch size to use for Whisper JAX.\n    \"\"\"\n    _instance = None\n\n    def __new__(cls, *args, **kwargs):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n        return cls._instance\n\n    def __init__(\n        self,\n        audio_file_path: str,\n        model_type: str = \"whisper\",\n        device: str = \"cpu\",\n        model_name: str = \"base\",\n        dtype: Optional[str] = None,\n        batch_size: Optional[int] = None,\n    ):\n        self.audio_file_path = audio_file_path\n        self.device = device\n        self.model_type = model_type\n        self.model_name = model_name\n        self.dtype = dtype\n        self.batch_size = batch_size\n        self.pipeline = None\n```", "```py\n def set_pipeline(self) -> None:\n        \"\"\"\n        Set up the pipeline for the specified model type.\n\n        Returns:\n            None\n        \"\"\"\n        if self.model_type == \"whisper_jax\":\n            pipeline_kwargs = {}\n            if self.dtype:\n                pipeline_kwargs[\"dtype\"] = getattr(jnp, self.dtype)\n            if self.batch_size:\n                pipeline_kwargs[\"batch_size\"] = self.batch_size\n\n            self.pipeline = FlaxWhisperPipline(\n                f\"openai/whisper-{self.model_name}\", **pipeline_kwargs\n            )\n        elif self.model_type == \"whisper\":\n            self.pipeline = whisper.load_model(\n                self.model_name,\n                torch.device(\"cuda:0\") if self.device == \"gpu\" else self.device,\n            )\n        else:\n            raise ValueError(f\"Invalid model type: {self.model_type}\")\n```", "```py\n def run_pipeline(self) -> List[Dict[str, Union[Tuple[float, float], str]]]:\n        \"\"\"\n        Run the transcription pipeline a second time.\n\n        Returns:\n            A list of dictionaries, each containing text and a tuple of start and end timestamps.\n        \"\"\"\n        if not hasattr(self, \"pipeline\"):\n            raise ValueError(\"Pipeline not initialized. Call set_pipeline() first.\")\n\n        if self.model_type == \"whisper_jax\":\n            outputs = self.pipeline(\n                self.audio_file_path, task=\"transcribe\", return_timestamps=True\n            )\n            return outputs[\"chunks\"]\n        elif self.model_type == \"whisper\":\n            result = self.pipeline.transcribe(self.audio_file_path)\n            formatted_result = [\n                {\n                    \"timestamp\": (segment[\"start\"], segment[\"end\"]),\n                    \"text\": segment[\"text\"],\n                }\n                for segment in result[\"segments\"]\n            ]\n            return formatted_result\n        else:\n            raise ValueError(f\"Invalid model type: {self.model_type}\")\n```", "```py\n def transcribe_multiple(\n        self, audio_file_paths: List[str]\n    ) -> List[List[Dict[str, Union[Tuple[float, float], str]]]]:\n        \"\"\"\n        Transcribe multiple audio files using the specified model type.\n\n        Args:\n            audio_file_paths (List[str]): A list of audio file paths to transcribe.\n\n        Returns:\n            List[List[Dict[str, Union[Tuple[float, float], str]]]]: A list of transcriptions for each audio file, where each transcription is a list of dictionaries containing text and a tuple of start and end timestamps.\n        \"\"\"\n        transcriptions = []\n\n        for audio_file_path in audio_file_paths:\n            self.audio_file_path = audio_file_path\n            self.set_pipeline()\n            transcription = self.run_pipeline()\n\n            transcriptions.append(transcription)\n\n        return transcriptions\n```"]