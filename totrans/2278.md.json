["```py\n# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport glob \nimport random \n\nfrom PIL import Image\nimport cv2\n\nimport torch\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\nimport shap\nfrom sklearn.metrics import mean_squared_error\n```", "```py\n#Load example image\nname = \"32_50_c78164b4-40d2-11ed-a47b-a46bb6070c92.jpg\"\nx = int(name.split(\"_\")[0])\ny = int(name.split(\"_\")[1])\n\nimg = Image.open(\"../data/room_1/\" + name)\nimg = np.array(img)\ncv2.circle(img, (x, y), 8, (0, 255, 0), 3)\n\nplt.imshow(img)\n```", "```py\nclass ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, paths, transform):\n\n        self.transform = transform\n        self.paths = paths\n\n    def __getitem__(self, idx):\n        \"\"\"Get image and target (x, y) coordinates\"\"\"\n\n        # Read image\n        path = self.paths[idx]\n        image = cv2.imread(path, cv2.IMREAD_COLOR)\n        image = Image.fromarray(image)\n\n        # Transform image\n        image = self.transform(image)\n\n        # Get target\n        target = self.get_target(path)\n        target = torch.Tensor(target)\n\n        return image, target\n\n    def get_target(self,path):\n        \"\"\"Get the target (x, y) coordinates from path\"\"\"\n\n        name = os.path.basename(path)\n        items = name.split('_')\n        x = items[0]\n        y = items[1]\n\n        # Scale between -1 and 1\n        x = 2.0 * (int(x)/ 224 - 0.5) # -1 left, +1 right\n        y = 2.0 * (int(y) / 244 -0.5)# -1 top, +1 bottom\n\n        return [x, y]\n\n    def __len__(self):\n        return len(self.paths)\n```", "```py\nTRANSFORMS = transforms.Compose([\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\npaths = glob.glob('../data/room_1/*')\n\n# Shuffle the paths\nrandom.shuffle(paths)\n\n# Create a datasets for training and validation\nsplit = int(0.8 * len(paths))\ntrain_data = ImageDataset(paths[:split], TRANSFORMS)\nvalid_data = ImageDataset(paths[split:], TRANSFORMS)\n\n# Prepare data for Pytorch model\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_data, batch_size=valid_data.__len__())\n```", "```py\noutput_dim = 2 # x, y\ndevice = torch.device('mps') # or 'cuda' if you have a GPU\n\n# RESNET 18\nmodel = torchvision.models.resnet18(pretrained=True)\nmodel.fc = torch.nn.Linear(512, output_dim)\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters())\n```", "```py\nname = \"direction_model_1\" # Change this to save a new model\n\n# Train the model\nmin_loss = np.inf\nfor epoch in range(10):\n\n    model = model.train()\n    for images, target in iter(train_loader):\n\n        images = images.to(device)\n        target = target.to(device)\n\n        # Zero gradients of parameters\n        optimizer.zero_grad()  \n\n        # Execute model to get outputs\n        output = model(images)\n\n        # Calculate loss\n        loss = torch.nn.functional.mse_loss(output, target)\n\n        # Run backpropogation to accumulate gradients\n        loss.backward()\n\n        # Update model parameters\n        optimizer.step()\n\n    # Calculate validation loss\n    model = model.eval()\n\n    images, target = next(iter(valid_loader))\n    images = images.to(device)\n    target = target.to(device)\n\n    output = model(images)\n    valid_loss = torch.nn.functional.mse_loss(output, target)\n\n    print(\"Epoch: {}, Validation Loss: {}\".format(epoch, valid_loss.item()))\n\n    if valid_loss < min_loss:\n        print(\"Saving model\")\n        torch.save(model, '../models/{}.pth'.format(name))\n\n        min_loss = valid_loss\n```", "```py\ndef model_evaluation(loaders,labels,save_path = None):\n\n    \"\"\"Evaluate direction models with mse and scatter plots\n        loaders: list of data loaders\n        labels: list of labels for plot title\"\"\"\n\n    n = len(loaders)\n    fig, axs = plt.subplots(1, n, figsize=(7*n, 6))\n\n    # Evalution metrics\n    for i, loader in enumerate(loaders):\n\n        # Load all data\n        images, target = next(iter(loader))\n        images = images.to(device)\n        target = target.to(device)\n\n        output=model(images)\n\n        # Get x predictions\n        x_pred=output.detach().cpu().numpy()[:,0]\n        x_target=target.cpu().numpy()[:,0]\n\n        # Calculate MSE\n        mse = mean_squared_error(x_target, x_pred)\n\n        # Plot predcitons\n        axs[i].scatter(x_target,x_pred)\n        axs[i].plot([-1, 1], \n                [-1, 1], \n                color='r', \n                linestyle='-', \n                linewidth=2)\n\n        axs[i].set_ylabel('Predicted x', size =15)\n        axs[i].set_xlabel('Actual x', size =15)\n        axs[i].set_title(\"{0} MSE: {1:.4f}\".format(labels[i], mse),size = 18)\n\n    if save_path != None:\n        fig.savefig(save_path)\n```", "```py\n# Load saved model \nmodel = torch.load('../models/direction_model_1.pth')\nmodel.eval()\nmodel.to(device)\n\n# Create new loader for all data\ntrain_loader = DataLoader(train_data, batch_size=train_data.__len__())\n\n# Evaluate model on training and validation set\nloaders = [train_loader,valid_loader]\nlabels = [\"Train\",\"Validation\"]\n\n# Evaluate on training and validation set\nmodel_evaluation(loaders,labels)\n```", "```py\n# Load saved model \nmodel = torch.load('../models/direction_model_1.pth') \n\n# Use CPU\ndevice = torch.device('cpu')\nmodel = model.to(device)\n```", "```py\n#Load 100 images for background\nshap_loader = DataLoader(train_data, batch_size=100, shuffle=True)\nbackground, _ = next(iter(shap_loader))\nbackground = background.to(device)\n```", "```py\n#Create SHAP explainer \nexplainer = shap.DeepExplainer(model, background)\n```", "```py\n# Load test images of right and left turn\npaths = glob.glob('../data/room_1/*')\ntest_images = [Image.open(paths[0]), Image.open(paths[3])]\ntest_images = np.array(test_images)\n\ntest_input = [TRANSFORMS(img) for img in test_images]\ntest_input = torch.stack(test_input).to(device)\n\n# Get SHAP values\nshap_values = explainer.shap_values(test_input)\n```", "```py\n# Reshape shap values and images for plotting\nshap_numpy = list(np.array(shap_values).transpose(0,1,3,4,2))\ntest_numpy = np.array([np.array(img) for img in test_images])\n\nshap.image_plot(shap_numpy, test_numpy,show=False)\n```"]