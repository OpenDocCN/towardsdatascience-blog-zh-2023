["```py\nawesome_pipeline.fit(X, y)\n```", "```py\nfrom sklearn.base import TransformerMixin\nfrom sklearn.preprocessing import QuantileTransformer\n\nisinstance(QuantileTransformer(), TransformerMixin)\n```", "```py\nTrue\n```", "```py\nEstimators inherit from the BaseEstimator class\n```", "```py\nTrue\n```", "```py\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.pipeline import make_pipeline\n\n# Define the numeric pipeline\nnumeric_pipeline = make_pipeline(\n    StandardScaler(), SimpleImputer(), LinearRegression()\n)\n\nnumeric_pipeline.fit(only_numeric_X, y)\n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Define the categorical pipeline\ncategorical_pipeline = make_pipeline(\n    SimpleImputer(strategy=\"most_frequent\"),\n    StandardScaler(),\n    LogisticRegression(),\n)\n```", "```py\nnumeric_pipeline\n```", "```py\nPipeline(steps=[('standardscaler', StandardScaler()),\n                ('simpleimputer', SimpleImputer()),\n                ('linearregression', LinearRegression())])\n```", "```py\nfrom sklearn.pipeline import Pipeline\n\nnumeric_pipeline = Pipeline(\n    steps=[\n        (\"scale\", StandardScaler()),\n        (\"impute\", SimpleImputer()),\n        (\"lr\", LinearRegression()),\n    ]\n)\n```", "```py\nnums = [\"numeric_1\", \"numeric_2\", \"numeric_3\"]\ncats = [\"categorical_1\", \"categorical_2\", \"categorical_3\"]\n```", "```py\nnumeric_pipe = make_pipeline(SimpleImputer(), QuantileTransformer())\ncategorical_pipe = make_pipeline(\n    SimpleImputer(strategy=\"most_frequent\"), OrdinalEncoder()\n)\n```", "```py\nfrom sklearn.compose import ColumnTransformer\n\ntransformers = ColumnTransformer(\n    transformers=[\n        (\"numeric\", numeric_pipeline, nums),\n        (\"categorical\", categorical_pipeline, cats),\n    ]\n)\n```", "```py\nX_transformed = transformers.fit_transform(X)\n```", "```py\nfull_pipeline_reg = make_pipeline(transformers, LinearRegression())\n\n# You can also use `Pipeline` class for named steps\nfull_pipeline_clf = Pipeline(\n    steps=[\n        (\"preprocess\", transformers),\n        (\"clf\", LogisticRegression()),\n    ]\n)\n```", "```py\n# y is a classification label\nfull_pipeline_clf.fit(X, y)\n\n# y is a numeric label\nfull_pipeline_reg.fit(X, y)\n```", "```py\nimport numpy as np\nfrom sklearn.compose import make_column_selector\n\nnumeric_cols = make_column_selector(dtype_include=np.number)\ncategoricals = make_column_selector(dtype_exclude=np.number)\n```", "```py\npattern = \"^(word1|word2)\"\nfiltered_columns = make_column_selector(pattern)\n```", "```py\nfrom sklearn.compose import make_column_transformer\n\n# Automatically capture cols based on dtype\nnums = make_column_selector(dtype_include=np.number)\ncats = make_column_selector(dtype_exclude=np.number)\n\n# Build the pipelines\nnumeric_pipe = make_pipeline(...)\ncategorical_pipe = make_pipeline(...)\n\ntransformers = make_column_transformer(\n    (nums, numeric_pipe), (cats, categorical_pipe)\n)\n```", "```py\nfrom sklearn import set_config\n\nset_config(display=\"diagram\")\n```", "```py\nfrom shutil import rmtree\nfrom tempfile import mkdtemp\n\nfrom sklearn.decomposition import PCA\n\n# Make a temporary directory\ncache_dir = mkdtemp()\n\nestimators = [(\"reduce_dim\", PCA()), (\"clf\", LogisticRegression())]\nmy_pipe = Pipeline(estimators, memory=cache_dir)\n\n# Run the pipeline\n...\n\n# Remove the cache directory at the end of your script\nrmtree(cache_dir)\n```", "```py\nisinstance(my_pipe, BaseEstimator)\n```", "```py\nTrue\n```", "```py\nfrom sklearn.model_selection import cross_validate\n\nresults = cross_validate(\n    estimator=full_pipeline_clf,\n    X,\n    y,\n    cv=5,\n    n_jobs=-1,\n    scoring=[\"accuracy\", \"logloss\"],\n)\n```", "```py\nfrom sklearn.model_selection import HalvingGridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.svm import SVC\n\n# Define the pipeline with ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"numeric\", num_pipe, num_cols),\n        (\"categorical\", cat_pipe, cat_cols),\n    ]\n)\n\npipe = Pipeline(\n    [(\"preprocessor\", preprocessor), (\"classifier\", SVC())]\n)\n\nparam_grid = {\n    \"preprocessor__numeric__with_mean\": [True, False],\n    \"preprocessor__categorical__min_frequency\": [2, 4, 6],\n    \"classifier__C\": [0.1, 1, 10],\n    \"classifier__kernel\": [\"linear\", \"rbf\"],\n}\n\nsearch = HalvingGridSearchCV(\n    pipe, param_grid, cv=5, factor=2, random_state=42\n)\n```", "```py\nparam_grid = {\n    \"preprocessor__numeric__with_mean\": [True, False],\n    \"preprocessor__categorical__min_frequency\": [2, 4, 6],\n    \"classifier__C\": [0.1, 1, 10],\n    \"classifier__kernel\": [\"linear\", \"rbf\"],\n}\n```", "```py\ndef num_missing_row(X: pd.DataFrame, y=None):\n    # Calculate some metrics across rows\n    num_missing = X.isnull().sum(axis=1)\n\n    # Add the above series as a new feature to the df\n    X[\"num_missing\"] = num_missing\n\n    return X\n```", "```py\nfrom sklearn.preprocessing import FunctionTransformer\n\n# Create a custom transformer\ncustom_transformer = FunctionTransformer(func=num_missing_row)\n\n# Pass it into a pipeline\nnumeric_pipe = make_pipeline(\n    StandardScaler(), customer_transformer, LinearRegression()\n)\n```", "```py\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.preprocessing import QuantileTransformer\n\n# Define the pipeline for X\ntransformers = ColumnTransformer(...)\nfull_pipeline = make_pipeline(transformers, LinearRegression())\n\n# Define the transformer for y\nqt = QuantileTransformer(output_distribution=\"normal\")\n\n# Define the final regressor\ntt = TransformedTargetRegressor(\n    regressor=full_pipeline, transformer=qt\n)\n\ntt.fit(X, y)\n```"]