- en: 'Cutout, Mixup, and Cutmix: Implementing Modern Image Augmentations in PyTorch'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Cutout、Mixup 和 Cutmix：在 PyTorch 中实现现代图像增强
- en: 原文：[https://towardsdatascience.com/cutout-mixup-and-cutmix-implementing-modern-image-augmentations-in-pytorch-a9d7db3074ad](https://towardsdatascience.com/cutout-mixup-and-cutmix-implementing-modern-image-augmentations-in-pytorch-a9d7db3074ad)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cutout-mixup-and-cutmix-implementing-modern-image-augmentations-in-pytorch-a9d7db3074ad](https://towardsdatascience.com/cutout-mixup-and-cutmix-implementing-modern-image-augmentations-in-pytorch-a9d7db3074ad)
- en: Data augmentation techniques for Computer Vision implemented in Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用 Python 实现的计算机视觉数据增强技术
- en: '[](https://medium.com/@iamleonie?source=post_page-----a9d7db3074ad--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page-----a9d7db3074ad--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a9d7db3074ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a9d7db3074ad--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page-----a9d7db3074ad--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iamleonie?source=post_page-----a9d7db3074ad--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page-----a9d7db3074ad--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a9d7db3074ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a9d7db3074ad--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page-----a9d7db3074ad--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a9d7db3074ad--------------------------------)
    ·9 min read·Apr 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----a9d7db3074ad--------------------------------)
    ·阅读时间 9 分钟·2023 年 4 月 14 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9c2cd9a7e9619a0232564ae5df5fe0b3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c2cd9a7e9619a0232564ae5df5fe0b3.png)'
- en: Cutmix image augmentation (Background image drawn by the author, artificial
    photograph of statue generated with DALLE)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Cutmix 图像增强（背景图像由作者绘制，人工生成的雕像照片使用 DALLE）
- en: It’s almost guaranteed that applying data augmentations will improve the performance
    of your neural network. Augmentations are a regularization technique that artificially
    expands your training data and helps your Deep Learning model generalize better.
    Thus, image augmentations can improve the model performance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎可以保证，应用数据增强会提升你的神经网络性能。增强是一种正则化技术，可以人工扩展你的训练数据，帮助你的深度学习模型更好地泛化。因此，图像增强可以提升模型性能。
- en: Image augmentations can improve the model performance
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图像增强可以提升模型性能
- en: Classical image augmentation techniques for convolutional neural networks in
    computer vision are scaling, cropping, flipping, or rotating an image.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的图像增强技术用于计算机视觉中的卷积神经网络，包括缩放、裁剪、翻转或旋转图像。
- en: 'In a recent article about [intermediate Deep Learning techniques](/intermediate-deep-learning-with-transfer-learning-f1aba5a814f),
    we learned that the most effective image augmentation techniques aside from the
    classical ones are:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近的一篇关于[中级深度学习技术](/intermediate-deep-learning-with-transfer-learning-f1aba5a814f)的文章中，我们了解到除了经典技术之外，最有效的图像增强技术是：
- en: '[Cutout](#a4b0) [2]'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cutout](#a4b0) [2]'
- en: '[Mixup](#c805) [4]'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mixup](#c805) [4]'
- en: '[Cutmix](#8a53) [3]'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cutmix](#8a53) [3]'
- en: '![](../Images/ce29c82e0d40ffe0118468fcd443604c.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce29c82e0d40ffe0118468fcd443604c.png)'
- en: 'Data Augmentation Techniques: Mixup, Cutout, Cutmix'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强技术：Mixup、Cutout、Cutmix
- en: This article will briefly describe the above image augmentations and their implementations
    in Python for the PyTorch Deep Learning framework.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将简要描述上述图像增强及其在 PyTorch 深度学习框架中的 Python 实现。
- en: Setup
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置
- en: 'This tutorial will use a toy example of a “vanilla” image classification problem.
    The task is to classify images of tulips and roses:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将使用一个“基础”的图像分类问题作为示例。任务是分类郁金香和玫瑰的图像：
- en: '![](../Images/24714a2fbc65e76b46ab0b87b1a2b4cf.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24714a2fbc65e76b46ab0b87b1a2b4cf.png)'
- en: 'Toy dataset [1] for image classification: Roses or tulips.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 用于图像分类的玩具数据集[1]：玫瑰还是郁金香。
- en: '*Insert your data here!* — To follow along in this article, your dataset should
    look something like this:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*在此插入你的数据！* — 为了跟随本文，你的数据集应该类似于这样：'
- en: '![](../Images/b43b29fe87f67bc2974bd7044861e9b4.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b43b29fe87f67bc2974bd7044861e9b4.png)'
- en: Toy dataset [1] for image classification. Insert your data here.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用于图像分类的玩具数据集[1]。在此插入你的数据。
- en: PyTorch (version 1.11.0), OpenCV (version 4.5.4), and `albumentations` (version
    1.3.0).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch（版本 1.11.0）、OpenCV（版本 4.5.4）和 `albumentations`（版本 1.3.0）。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The PyTorch `Dataset` loads an image with OpenCV.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch `Dataset`使用OpenCV加载图像。
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The PyTorch `DataLoader` then partitions the dataset into batches of 8 images
    each for this example. The basic image transformation resizes the images to 256
    by 256 pixels.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch `DataLoader`随后将数据集划分为每批8张图像。这些基本图像变换将图像调整为256x256像素。
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Below you can see the training code for a vanilla image classification problem.
    All distracting code parts are omitted to simplify the code and only bring attention
    to the relevant parts.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以看到一个普通图像分类问题的训练代码。所有分散注意力的代码部分已被省略，以简化代码并只关注相关部分。
- en: Since we have a binary classification problem, we will be using `nn.CrossEntropyLoss()`.
    This is noteworthy because we will be implementing a custom loss function later.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有一个二分类问题，我们将使用`nn.CrossEntropyLoss()`。这是值得注意的，因为我们稍后将实现一个自定义损失函数。
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Cutout
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Cutout
- en: Cutout [2] was introduced in a paper called “Improved regularization of convolutional
    neural networks with cutout.” by DeVries & Taylor in 2017.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Cutout [2] 在2017年由DeVries & Taylor在论文“Improved regularization of convolutional
    neural networks with cutout.”中提出。
- en: Brief description
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简要描述
- en: The core idea behind Cutout image augmentation is to randomly remove a square
    region of pixels in an input image during training.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Cutout图像增强的核心思想是在训练期间随机去除输入图像中的一个方形像素区域。
- en: '![](../Images/ccd607604f875ab08a0e3e444605ff77.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccd607604f875ab08a0e3e444605ff77.png)'
- en: Cutout image augmentation
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Cutout图像增强
- en: Cutout can prevent overfitting by forcing the model to learn more robust features.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Cutout可以通过迫使模型学习更强健的特征来防止过拟合。
- en: 'Strengths:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 优势：
- en: Easy to implement (see [implementation of Cutout](#36ba))
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现简单（见[Cutout的实现](#36ba)）
- en: Can remove noise, e.g., background
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以去除噪声，例如背景
- en: 'Weaknesses:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点：
- en: Can remove important features, especially in sparse images
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以移除重要特征，特别是在稀疏图像中
- en: Implementation in Python with PyTorch
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch的Python实现
- en: Luckily, Cutout is available in [Albumentations](https://albumentations.ai/docs/),
    an image augmentation library. You can use the `CoarseDropout` class (a `Cutout`
    class was available in earlier library versions but has been deprecated).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Cutout在[Albumentations](https://albumentations.ai/docs/)图像增强库中可用。你可以使用`CoarseDropout`类（早期库版本中有`Cutout`类，但已被弃用）。
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The returned sample batch looks as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的样本批次如下所示：
- en: '![](../Images/4d24c9c5d9a7dbbdbe30b9407018014a.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d24c9c5d9a7dbbdbe30b9407018014a.png)'
- en: Cutout image augmentation applied to sample batch.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对样本批次应用了Cutout图像增强。
- en: Mixup
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mixup
- en: 'Mixup [4] was introduced in a paper called “mixup: Beyond empirical risk minimization”
    by Zhang, Cisse, Dauphin, & Lopez-Paz also in 2017.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 'Mixup [4] 在2017年由Zhang, Cisse, Dauphin & Lopez-Paz在论文“mixup: Beyond empirical
    risk minimization”中提出。'
- en: Brief description
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简要描述
- en: The core idea behind Mixup image augmentation is to mix a random pair of input
    images and their labels during training.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Mixup图像增强的核心思想是在训练期间混合一对随机的输入图像及其标签。
- en: '![](../Images/05b9840f200b24f205e3c1a8f480ac0b.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05b9840f200b24f205e3c1a8f480ac0b.png)'
- en: Mixup image augmentation
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Mixup图像增强
- en: Mixup can prevent overfitting by creating more **diverse** training samples
    and thus forcing the model to learn more generalizable features invariant to small
    changes in the images.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Mixup可以通过创建更多**多样化**的训练样本来防止过拟合，从而迫使模型学习对图像中的小变化不变的更具通用性的特征。
- en: 'Strengths:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 优势：
- en: Relatively easy to implement (see [implementation of Mixup](#02e8))
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现相对简单（见[Mixup的实现](#02e8)）
- en: Increases diversity in the training data
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加训练数据的多样性
- en: 'Weaknesses:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点：
- en: Can create blurred images, especially for images with complex textures
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以创建模糊图像，特别是对于复杂纹理的图像
- en: Implementation in Python with PyTorch
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch的Python实现
- en: You must implement a `mixup()` function to apply Mixup image augmentation to
    your Deep Learning training pipeline. The following code is taken initially from
    [this Kaggle Notebook by Riad](https://www.kaggle.com/code/riadalmadani/fastai-effb0-base-model-birdclef2023)
    and modified for this article.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须实现一个`mixup()`函数，以将Mixup图像增强应用到你的深度学习训练管道中。以下代码最初来自于[Riad的这个Kaggle Notebook](https://www.kaggle.com/code/riadalmadani/fastai-effb0-base-model-birdclef2023)，并为本文进行了修改。
- en: The `mixup()` function applies Mixup to a full batch. The pairs are generated
    by shuffling the batch and selecting one image from the original batch and one
    from the shuffled batch.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`mixup()`函数将Mixup应用于整个批次。对会生成配对的操作通过打乱批次并从原始批次中选择一张图像和从打乱的批次中选择一张图像来实现。'
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In addition to the function that augments the images and labels, we must modify
    the loss function with a custom `mixup_criterion()` function. This function returns
    the loss for the two labels according to the `lam`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了增强图像和标签的函数，我们还必须使用自定义 `mixup_criterion()` 函数修改损失函数。该函数根据 `lam` 返回两个标签的损失。
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `mixup()` and `mixup_criterion()` functions, are not applied in the PyTorch
    `Dataset` but in the training code as shown below.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`mixup()` 和 `mixup_criterion()` 函数不会应用于 PyTorch `Dataset`，而是在训练代码中应用，如下所示。'
- en: Since the augmentation is applied to the full batch, we will also add a variable
    `p_mixup` that controls the portion of batches that will be augmented. E.g. `p_mixup
    = 0.5` would apply Mixup augmentation to 50 % of batches in an epoch.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于增强应用于整个批次，我们还将添加一个变量 `p_mixup` 来控制将被增强的批次比例。例如，`p_mixup = 0.5` 将对一个 epoch
    中的 50% 批次应用 Mixup 增强。
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The returned sample batch looks as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的样本批次如下所示：
- en: '![](../Images/4436f8f8b5fb5384fb5d05486c1ee739.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4436f8f8b5fb5384fb5d05486c1ee739.png)'
- en: Mixup image augmentation applied to sample batch.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于样本批次的 Mixup 图像增强。
- en: Cutmix
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Cutmix
- en: 'Cutmix [3] was introduced in a paper called “Cutmix: Regularization strategy
    to train strong classifiers with localizable features.” by Yun, Han, Oh, Chun,
    Choe & Yoo in 2019.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 'Cutmix [3] 在2019年的一篇名为“Cutmix: Regularization strategy to train strong classifiers
    with localizable features.”的论文中由 Yun、Han、Oh、Chun、Choe 和 Yoo 提出。'
- en: Brief description
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简要描述
- en: The core idea behind cutmix image augmentation is to randomly select a pair
    of input images during training, cut a random patch of pixels from the first image
    and paste it to the second image, and then mix their labels proportionally to
    the area of the patch.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Cutmix 图像增强的核心思想是在训练过程中随机选择一对输入图像，从第一张图像中剪切一个随机的像素块并将其粘贴到第二张图像上，然后按像素块的面积成比例混合它们的标签。
- en: '![](../Images/15012b33bde276cdcc559a2ba44032a8.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15012b33bde276cdcc559a2ba44032a8.png)'
- en: Cutmix image augmentation
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Cutmix 图像增强
- en: Cutmix can prevent overfitting by forcing the model to learn more robust and
    discriminative features.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Cutmix 可以通过迫使模型学习更强健和具有区分性的特征来防止过拟合。
- en: 'Cutmix combines the strength and weaknesses of [Cutout](#a4b0) and [Mixup](#c805):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Cutmix 结合了 [Cutout](#a4b0) 和 [Mixup](#c805) 的优缺点：
- en: 'Strengths:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：
- en: Relatively easy to implement (see [implementation of Cutmix](#00b8))
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对容易实现（参见 [Cutmix 的实现](#00b8)）
- en: Increases diversity in the training data
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加训练数据的多样性
- en: 'Weaknesses:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点：
- en: Can create unrealistic images due to unnatural compositions
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于不自然的组合，可能会生成不真实的图像
- en: Can remove important features, especially in sparse images
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会移除重要特征，尤其是在稀疏图像中
- en: Implementation in Python with PyTorch
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PyTorch 的 Python 实现
- en: The implementation for Cutmix is similar to the [implementation of Mixup](#02e8).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Cutmix 的实现类似于 [Mixup 的实现](#02e8)。
- en: First, you will also need a custom function `cutmix()` that applies the image
    augmentation. The following code is taken initially from [this Kaggle Notebook
    by Riad](https://www.kaggle.com/code/riadalmadani/fastai-effb0-base-model-birdclef2023)
    and modified for this article.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你还需要一个自定义函数 `cutmix()` 来应用图像增强。以下代码最初取自 [Riad 的 Kaggle Notebook](https://www.kaggle.com/code/riadalmadani/fastai-effb0-base-model-birdclef2023)
    并为本文做了修改。
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The rest is the same as for [Mixup](#02e8):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的与 [Mixup](#02e8) 相同：
- en: Define a `cutmix_criterion()` functions to handle the custom loss (see the implementation
    of `mixup_criterion()`)
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 `cutmix_criterion()` 函数来处理自定义损失（参见 `mixup_criterion()` 的实现）
- en: Define a variable `p_cutmix` to control the portion of batches that will be
    augmented (see `p_mixup`)
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义变量 `p_cutmix` 来控制将被增强的批次比例（参见 `p_mixup`）
- en: Apply `cutmix()` and `cutmix_criterion()` in accordance to `p_cutmix` in the
    training code (see the [implementation of Mixup](#02e8))
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练代码中根据 `p_cutmix` 应用 `cutmix()` 和 `cutmix_criterion()`（参见 [Mixup 的实现](#02e8)）
- en: 'The returned sample batch looks as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的样本批次如下所示：
- en: '![](../Images/9537f35e4ece1973dca502b3c16f9de2.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9537f35e4ece1973dca502b3c16f9de2.png)'
- en: Cutmix image augmentation applied to sample batch.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于样本批次的 Cutmix 图像增强。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This article has summarized three modern effective data augmentation techniques
    for computer vision:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 本文总结了三种现代有效的数据增强技术，用于计算机视觉：
- en: '[Cutout](#a4b0) [2]: randomly remove a square region of pixels in an input
    image'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cutout](#a4b0) [2]：随机去除输入图像中的一个方形区域的像素'
- en: '[Mixup](#c805) [4]: mix a random pair of input images and their labels'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mixup](#c805) [4]：混合一对随机的输入图像及其标签'
- en: '[Cutmix](#8a53) [3]: randomly select a pair of input images, cut a random patch
    of pixels from the first image and paste it to the second image, and then mix
    their labels proportionally to the area of the patch.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cutmix](#8a53) [3]: 随机选择一对输入图像，从第一张图像中剪切出一个随机像素块，将其粘贴到第二张图像上，然后按像素块的面积比例混合它们的标签。'
- en: '![](../Images/ce29c82e0d40ffe0118468fcd443604c.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce29c82e0d40ffe0118468fcd443604c.png)'
- en: 'Data Augmentation Techniques: Mixup, Cutout, Cutmix (Image by the author)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强技术：Mixup, Cutout, Cutmix（图片由作者提供）
- en: While Cutout applies the augmentation to a single image, Mixup and Cutmix create
    a new image from a pair of input images.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Cutout将增强应用于单张图像，但Mixup和Cutmix则从一对输入图像中创建新图像。
- en: 'All of the discussed image augmentation techniques are easy to relatively easy
    to implement: For Cutout, the [Albumentations](https://albumentations.ai/docs/)
    library already has an implementation available out of the box. For Mixup and
    Cutmix the implementations are relatively simple and require the implementation
    of an augmentation function and a custom loss function.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 所有讨论的图像增强技术都相对容易实现：对于Cutout，[Albumentations](https://albumentations.ai/docs/)库已经提供了现成的实现。对于Mixup和Cutmix，实施相对简单，需要实现一个增强函数和一个自定义损失函数。
- en: Enjoyed This Story?
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 享受这个故事吗？
- en: '[*Subscribe for free*](https://medium.com/subscribe/@iamleonie) *to get notified
    when I publish a new story.*'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[*免费订阅*](https://medium.com/subscribe/@iamleonie) *以便在我发布新故事时收到通知。*'
- en: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----a9d7db3074ad--------------------------------)
    [## Get an email whenever Leonie Monigatti publishes.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----a9d7db3074ad--------------------------------)
    [## 每当Leonie Monigatti发布新内容时，通过电子邮件收到通知。'
- en: Get an email whenever Leonie Monigatti publishes. By signing up, you will create
    a Medium account if you don’t already…
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每当Leonie Monigatti发布新内容时，您将通过电子邮件收到通知。通过注册，您将创建一个Medium帐户（如果您尚未拥有的话）……
- en: medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----a9d7db3074ad--------------------------------)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----a9d7db3074ad--------------------------------)
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/804250ab/),[*Twitter*](https://twitter.com/helloiamleonie)*,
    and* [*Kaggle*](https://www.kaggle.com/iamleonie)*!*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/804250ab/)、[*Twitter*](https://twitter.com/helloiamleonie)*和*
    [*Kaggle*](https://www.kaggle.com/iamleonie)*上找到我！*'
- en: References
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Dataset
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: '[1] The used image dataset was created by the author by collecting eight images
    from [Unsplash.com](https://unsplash.com/de). The dataset is publicly available
    on [Kaggle](https://www.kaggle.com/datasets/iamleonie/roses-or-tulips), and the
    image sources are attributed in the dataset description. Since images on Unsplash
    are available for commercial use and the collection of the eight photographs does
    not replicate a similar or competing service to Unsplash, the dataset is licensed
    under CC BY-SA 4.0'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 使用的图像数据集由作者从[Unsplash.com](https://unsplash.com/de)收集的八张图片创建。该数据集在[Kaggle](https://www.kaggle.com/datasets/iamleonie/roses-or-tulips)上公开提供，数据集描述中注明了图像来源。由于Unsplash上的图片可以用于商业用途，并且这八张照片的收集并不重复类似或竞争的Unsplash服务，因此该数据集在CC
    BY-SA 4.0许可证下使用。'
- en: '[](https://www.kaggle.com/datasets/iamleonie/roses-or-tulips?source=post_page-----a9d7db3074ad--------------------------------)
    [## Roses or Tulips'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/datasets/iamleonie/roses-or-tulips?source=post_page-----a9d7db3074ad--------------------------------)
    [## 玫瑰还是郁金香'
- en: Toy dataset containing only 8 images (4 tulips and 4 roses) taken from Unsplash.
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 玩具数据集仅包含8张图片（4张郁金香和4张玫瑰），均来自Unsplash。
- en: www.kaggle.com](https://www.kaggle.com/datasets/iamleonie/roses-or-tulips?source=post_page-----a9d7db3074ad--------------------------------)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.kaggle.com](https://www.kaggle.com/datasets/iamleonie/roses-or-tulips?source=post_page-----a9d7db3074ad--------------------------------)'
- en: Image References
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像参考
- en: If not otherwise stated, all images are created by the author.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图像均由作者创建。
- en: Literature
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文献
- en: '[2] DeVries, T., & Taylor, G. W. (2017). Improved regularization of convolutional
    neural networks with cutout. *arXiv preprint arXiv:1708.04552*.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] DeVries, T., & Taylor, G. W. (2017). Improved regularization of convolutional
    neural networks with cutout. *arXiv预印本 arXiv:1708.04552*。'
- en: '[3] Yun, S., Han, D., Oh, S. J., Chun, S., Choe, J., & Yoo, Y. (2019). Cutmix:
    Regularization strategy to train strong classifiers with localizable features.
    In *Proceedings of the IEEE/CVF international conference on computer vision* (pp.
    6023–6032).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Yun, S., Han, D., Oh, S. J., Chun, S., Choe, J., & Yoo, Y. (2019). Cutmix:
    Regularization strategy to train strong classifiers with localizable features.
    In *IEEE/CVF国际计算机视觉会议论文集* (第6023–6032页)。'
- en: '[4] Zhang, H., Cisse, M., Dauphin, Y. N., & Lopez-Paz, D. (2017) mixup: Beyond
    empirical risk minimization. arXiv preprint arXiv:1710.09412.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] 张华、Cisse M.、Dauphin Y. N. 和 Lopez-Paz D. (2017) mixup: 超越经验风险最小化。arXiv
    预印本 arXiv:1710.09412。'
