- en: How to Detect Hallucinations in LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何检测LLM中的幻觉
- en: 原文：[https://towardsdatascience.com/real-time-llm-hallucination-detection-9a68bb292698](https://towardsdatascience.com/real-time-llm-hallucination-detection-9a68bb292698)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/real-time-llm-hallucination-detection-9a68bb292698](https://towardsdatascience.com/real-time-llm-hallucination-detection-9a68bb292698)
- en: Teaching Chatbots to Say “I Don’t Know”
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 教导聊天机器人说“我不知道”
- en: '[](https://medium.com/@brezeanu.iulia?source=post_page-----9a68bb292698--------------------------------)[![Iulia
    Brezeanu](../Images/f108eeec620ec9be40778dfaceca4e6c.png)](https://medium.com/@brezeanu.iulia?source=post_page-----9a68bb292698--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9a68bb292698--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9a68bb292698--------------------------------)
    [Iulia Brezeanu](https://medium.com/@brezeanu.iulia?source=post_page-----9a68bb292698--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@brezeanu.iulia?source=post_page-----9a68bb292698--------------------------------)[![尤利娅·布雷泽安努](../Images/f108eeec620ec9be40778dfaceca4e6c.png)](https://medium.com/@brezeanu.iulia?source=post_page-----9a68bb292698--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9a68bb292698--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9a68bb292698--------------------------------)
    [尤利娅·布雷泽安努](https://medium.com/@brezeanu.iulia?source=post_page-----9a68bb292698--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9a68bb292698--------------------------------)
    ·10 min read·Dec 31, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----9a68bb292698--------------------------------)
    ·10分钟阅读·2023年12月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a1e0d8fcdb97251e27161a08f711a2c3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1e0d8fcdb97251e27161a08f711a2c3.png)'
- en: Photo by [visuals](https://unsplash.com/@visuals?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[视觉](https://unsplash.com/@visuals?utm_source=medium&utm_medium=referral)提供的照片，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上'
- en: '**Who is Evelyn Hartwell?**'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**伊夫琳·哈特维尔是谁？**'
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Evelyn Hartwell is an American author, speaker, and life coach…
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**伊夫琳·哈特维尔**是一位美国作家、演讲者和生活教练…'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Evelyn Hartwell is a Canadian ballerina and the founding Artistic Director…
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**伊夫琳·哈特维尔**是一位加拿大芭蕾舞演员以及创始艺术总监…'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Evelyn Hartwell is an American actress known for her roles in the…
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**伊夫琳·哈特维尔**是一位美国演员，以其在…中的角色而闻名'
- en: No, Evelyn Hartwell is not a con artist with multiple false identities, living
    a deceptive triple life with various professions. In fact, she doesn’t exist at
    all, but the model, instead of telling me that it doesn’t know, starts making
    facts up. We are dealing with an LLM Hallucination.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 不，**伊夫琳·哈特维尔**并不是一个拥有多个虚假身份的诈骗犯，她过着一种伪装的三重生活，拥有各种职业。实际上，她根本不存在，但模型并没有告诉我它不知道，而是开始编造事实。我们正面临LLM幻觉的问题。
- en: Long, detailed outputs can seem really convincing, even if fictional. Does it
    mean that we cannot trust chatbots and have to manually fact-check the outputs
    every time? Fortunately, there could be ways to make chatbots less likely to say
    fabricated things with the right safeguards.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 长篇详细的输出可能看起来非常可信，即使是虚构的。这是否意味着我们不能信任聊天机器人，每次都需要手动核实输出的真实性？幸运的是，通过正确的保护措施，可能会有方法使聊天机器人不太容易编造信息。
- en: '![](../Images/b8715346e238a15d9203a36d4b79d5ab.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8715346e238a15d9203a36d4b79d5ab.png)'
- en: text-davinci-003 prompt completion on a fictional person. Image by the author.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: text-davinci-003在虚构人物上的提示完成。图片由作者提供。
- en: For the outputs above, I set a higher temperature of 0.7\. I am allowing the
    LLM to change the structure of its sentences in order not to have identical text
    for each generation. The differences between outputs should be just semantic,
    not factual.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上述输出，我设置了较高的温度0.7。我允许LLM更改句子的结构，以避免每次生成相同的文本。输出之间的差异应仅为语义上的，而非事实上的。
- en: This simple idea allowed for introducing a new sample-based hallucination detection
    mechanism. If the LLM’s outputs to the same prompt contradict each other, they
    will likely be hallucinations. If they are entailing each other, it implies the
    information is factual. [2]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的想法引入了一种基于样本的幻觉检测机制。如果LLM对相同的提示产生的输出相互矛盾，那么这些输出很可能是幻觉。如果它们相互包含，这意味着信息是事实的。[2]
- en: For this type of evaluation, we only require the text outputs of the LLMs. This
    is known as black-box evaluation. Also, because we don’t need any external knowledge,
    is called zero-resource. [5]
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种类型的评估，我们只需要LLM的文本输出。这被称为黑箱评估。此外，由于我们不需要任何外部知识，这也被称为零资源。[5]
- en: Sentence embeddings cosine distance
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 句子嵌入的余弦距离
- en: Let’s start with a very basic way of measuring similarity. We will compute the
    pairwise cosine similarity between corresponding pairs of embedded sentences.
    We normalize them because we need to focus only on the vector’s direction, not
    magnitude. The function below takes as input the originally generated sentence
    called *output* and a list of 3 sample outputs called *sampled_passages*. All
    the completions are found in the image at the beginning of the article.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一种非常基本的相似性度量方法开始。我们将计算嵌入句子对应对的成对余弦相似性。我们对其进行归一化，因为我们只需要关注向量的方向，而不是大小。下面的函数以原始生成的句子
    *output* 和一个包含 3 个样本输出的列表 *sampled_passages* 作为输入。所有的完成都在文章开头的图片中找到。
- en: For generating the embeddings, I am using the *all-MiniLM-L6-v2* lightweight
    model. Embedding a sentence turns it into its vectorial representation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为生成嵌入，我使用了轻量级模型 *all-MiniLM-L6-v2*。嵌入一个句子将其转换为向量表示。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We generate embeddings for every output of the LLM; then, we compute the pairwise
    cos similarity using the *pairwise_cos_sim* function from sentence_transformers.
    We’ll compare the original response to each new sample response and then do the
    average.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为 LLM 的每个输出生成嵌入；然后，使用 *pairwise_cos_sim* 函数计算成对余弦相似性。我们将原始响应与每个新样本响应进行比较，然后计算平均值。
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is the intuition behind how the function works with a very simple pair
    of vectors in a 2D cartesian space. A and B are the original vectors, and Â and
    B̂ are the normalized ones.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是函数如何在二维笛卡尔空间中使用一对非常简单的向量的直观解释。A 和 B 是原始向量，而 Â 和 B̂ 是归一化后的向量。
- en: '![](../Images/63fb8aad86273624bbcab08a6d98b86a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63fb8aad86273624bbcab08a6d98b86a.png)'
- en: Pairwise cos similarity computation. Image by author.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 成对余弦相似性计算。图片由作者提供。
- en: From the image above, we can see that the angle between the vectors is approximately
    30⁰, so they are close to each other. The cosine is approximately 0.87\. The closer
    the cosine is to 1, the closer the vectors are to each other.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图片中，我们可以看到向量之间的角度大约是 30⁰，所以它们彼此接近。余弦值大约是 0.87。余弦值越接近 1，向量之间就越接近。
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The *cos_sim_score* for our embedded outputs has an average value of 0.52.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的嵌入输出的 *cos_sim_score* 平均值为 0.52。
- en: To understand how to interpret this number, let’s compare it to the cosine similarity
    score for some valid outputs where we ask for information about an existing person.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解如何解读这个数字，让我们将其与一些有效输出的余弦相似性分数进行比较，这些输出涉及关于现有人物的信息。
- en: '![](../Images/0d9e93b1a0ab023cf40360920a25feda.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d9e93b1a0ab023cf40360920a25feda.png)'
- en: Image by the author — text-davinci-003 prompt completion on Nicolas Cage
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 — text-davinci-003 在尼古拉斯·凯奇上的提示完成
- en: The pairwise cosine similarity score, in this case, is 0.93\. Looks promising,
    especially as it’s a very fast method of assessing the similarity between outputs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，成对余弦相似性分数是 0.93。这看起来很有前景，特别是作为一种非常快速的方法来评估输出之间的相似性。
- en: '![](../Images/6ea42b42b117d82bbca2d92ba555ae49.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ea42b42b117d82bbca2d92ba555ae49.png)'
- en: Duration of cosine similarity computation. Image by author.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似性计算的持续时间。图片由作者提供。
- en: SelfCheckGPT- BERTScore
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SelfCheckGPT- BERTScore
- en: The BERTScore builds on the pairwise cosine similarity idea we implemented previously.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore 基于我们之前实现的成对余弦相似性思想。
- en: '![](../Images/cf99047f6b68bccf007a88f2335b7aa1.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf99047f6b68bccf007a88f2335b7aa1.png)'
- en: '[1]'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]'
- en: The default tokenizer for computing the contextual embeddings is RobertaTokenizer.
    Contextual embeddings differ from static embeddings because they take into account
    the context around the word. For example, the word “bat” would correspond to different
    token values depending on whether the context refers to a “flying mammal” or a
    “baseball bat”.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 用于计算上下文嵌入的默认分词器是 RobertaTokenizer。上下文嵌入不同于静态嵌入，因为它们考虑了词汇周围的上下文。例如，“bat” 这个词会根据上下文是指“飞行的哺乳动物”还是“棒球棒”而对应不同的标记值。
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let’s take an inside look at the *selfcheck_bertscore.predict* function. Instead
    of passing the full original output as an argument, we split it into individual
    sentences.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解一下*自检_bert评分.predict*函数。我们没有将完整的原始输出作为参数传递，而是将其拆分为单独的句子。
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This step is important because the s*elfcheck_bertscore.predict* function computes
    the BERTScore for each sentence into the original response matched to each sentence
    from the samples. First, it creates an array with the number of rows equal to
    the number of sentences in the original output and the number of columns equal
    to the number of samples.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个步骤很重要，因为*s*elfcheck_bertscore.predict*函数计算了每个原始响应中的句子与样本中的每个句子的BERTScore。首先，它创建一个数组，其中行数等于原始输出中的句子数，列数等于样本的数量。
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The model used for computing the BERTScore between the candidate and reference
    sentences is RoBERTa large with 17 layers. Our original output has 4 sentences,
    which I will call r1,r2,r3, and r4\. The first sample has two sentences: c1 and
    c2\. We compute the F1 BERTScore for each sentence from the original output matched
    to each sentence from the first sample. Then we do base rescaling with respect
    to the baseline tensor b = **tensor([0.8315, 0.8315, 0.8312]).** The baseline
    *b* was computed using 1 million randomly paired sentences from the Common Crawl
    monolingual datasets. They computed the BERTScore for each pair and averaged it.
    This represents a lower bound since random pairs have little semantic overlap.
    [1]'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 用于计算候选句子和参考句子之间BERTScore的模型是具有17层的RoBERTa large。我们的原始输出有4个句子，我将其称为r1、r2、r3和r4。第一个样本有两个句子：c1和c2。我们计算原始输出中每个句子与第一个样本中每个句子的F1
    BERTScore。然后，我们进行基于基线张量b = **tensor([0.8315, 0.8315, 0.8312])**的基础重标定。基线*b*是通过使用来自Common
    Crawl单语数据集的100万对随机句子计算的。他们计算了每对句子的BERTScore并取其平均值。这代表了一个下界，因为随机对的语义重叠很少。[1]
- en: '![](../Images/f36695e660baa06c3c12a4d723bbb817.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f36695e660baa06c3c12a4d723bbb817.png)'
- en: F1 BERTScore. Image by author.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: F1 BERTScore。图片来源：作者。
- en: We keep the BERTScore of each sentence from the original response with the most
    similar sentence from each drawn sample. The logic is that if a piece of information
    appears across multiple samples generated from the same prompt, there is a good
    chance that the information is factual. If a statement only appears in one sample
    and not in any other samples from the same prompt, it is more likely to be a fabrication.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保留原始响应中每个句子与每个抽样样本中最相似句子的BERTScore。逻辑是，如果某条信息出现在从相同提示生成的多个样本中，那么该信息很可能是事实。如果某个声明仅出现在一个样本中，而在相同提示的其他样本中没有出现，则更可能是虚构的。
- en: 'Let’s add the maximum similarities in the array for the first sample:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为第一个样本添加数组中的最大相似度：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we repeat the process for the other two samples:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对另外两个样本重复这个过程：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Then we compute the mean for each row, giving us the similarity score between
    each sentence from the original response and each subsequent sample.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们计算每一行的平均值，从而得到原始响应中每个句子与每个后续样本的相似度评分。
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The hallucination score for each sentence is obtained by subtracting from 1
    each of the values above.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 每个句子的幻觉评分通过从1中减去上述每个值来获得。
- en: '![](../Images/fc51bc337c55dd83eb0197b028d818d4.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc51bc337c55dd83eb0197b028d818d4.png)'
- en: Hallucination Score for **Evelyn Hartwell.** Image by author.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**伊夫琳·哈特维尔**的幻觉评分。图片来源：作者。'
- en: Comparing the results with the answers for Nicolas Cage.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将结果与尼古拉斯·凯奇的答案进行比较。
- en: '![](../Images/e5664b0a28cfd118ee2bace1817e2d3c.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5664b0a28cfd118ee2bace1817e2d3c.png)'
- en: Hallucination Score for **Nicolas Cage.** Image by author.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**尼古拉斯·凯奇**的幻觉评分。图片来源：作者。'
- en: Seems reasonable; the hallucination score for the valid outputs is low, and
    the one for the made-up outputs is high. Unfortunately, the process of computing
    the BERTScore is very time-consuming, which makes it a bad candidate for real-time
    hallucination detection.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来很合理；有效输出的幻觉评分较低，而虚构输出的幻觉评分较高。不幸的是，计算BERTScore的过程非常耗时，这使得它不适合实时幻觉检测。
- en: '![](../Images/4ee064186184b0e41ebcb423be656ccd.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ee064186184b0e41ebcb423be656ccd.png)'
- en: Duration of BERTScore computation. Image by author.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore计算的持续时间。图片来源：作者。
- en: SelfCheckGPT-NLI
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SelfCheckGPT-NLI
- en: Natural language inference (NLI) involves determining whether a hypothesis logically
    follows from or contradicts a given premise. The relationship is classified as
    entailment, contradiction, or neutral. For SelfCheck-NLI, we utilize the DeBERTa-v3-large
    model that has been fine-tuned on the MNLI dataset to perform NLI.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言推断（NLI）涉及确定一个假设是否从给定的前提中逻辑推导出来，或与之矛盾。关系被分类为蕴含、矛盾或中立。对于SelfCheck-NLI，我们使用经过MNLI数据集微调的DeBERTa-v3-large模型来执行NLI。
- en: '![](../Images/7a9282e68753d179435e2a373e8ed2e5.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a9282e68753d179435e2a373e8ed2e5.png)'
- en: NLI flowchart [5]
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: NLI流程图 [5]
- en: Below are some examples of premise-hypothesis pairs and their labels.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些前提—假设对及其标签的示例。
- en: '![](../Images/2e008b99d66c2bdb9eff170d4317575e.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e008b99d66c2bdb9eff170d4317575e.png)'
- en: Examples of context — hypothesis pairs [4]
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文—假设对的示例 [4]
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In the *selfcheck_nli.predict* function, each sentence from the original response
    is paired with each of the three samples.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *selfcheck_nli.predict* 函数中，将原始响应中的每个句子与三个样本中的每一个配对。
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/c5a5164130faa7dfc8204aa03f508412.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5a5164130faa7dfc8204aa03f508412.png)'
- en: Probability of contradiction w.r.t the first sentence and each sample. Image
    by the author.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 相对于第一个句子和每个样本的矛盾概率。图像由作者提供。
- en: Now we repeat the process for each of the four sentences.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对每个四个句子重复这个过程。
- en: '![](../Images/2aacc18868931a0c2d24dd7172452797.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2aacc18868931a0c2d24dd7172452797.png)'
- en: SelfCheck-NLI for **Evelyn Hartwell**. Image by author.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**Evelyn Hartwell** 的SelfCheck-NLI。图像由作者提供。'
- en: We can see that the model is outputting an extremely high probability of contradiction.
    Now we compare with the factual outputs.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到模型输出了一个极高的矛盾概率。现在我们与实际输出进行比较。
- en: '![](../Images/c4c36a43c4dec21c4fb079860a3dd886.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4c36a43c4dec21c4fb079860a3dd886.png)'
- en: SelfCheck-NLI for **Nicolas Cage**. Image by author.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nicolas Cage** 的SelfCheck-NLI。图像由作者提供。'
- en: The model is doing a great job! Unfortunately, the NLI check is a bit too long.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 模型表现得非常好！不幸的是，NLI检查时间有点长。
- en: '![](../Images/f5886c2dc74d23ebfaa48cabf5959d6d.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5886c2dc74d23ebfaa48cabf5959d6d.png)'
- en: Duration of NLI computation. Image by author.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: NLI计算的持续时间。图像由作者提供。
- en: SelfCheckGPT-Prompt
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SelfCheckGPT-Prompt
- en: Newer methods have started using LLMs themselves to evaluate generated text.
    Instead of using a formula to calculate a score, we will send the output along
    with the three samples to gpt-3.5-turbo. The model will decide how consistent
    the original output is with respect to the other three samples generated. [3]
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 更新的方法已经开始使用LLMs自身来评估生成的文本。我们将输出和三个样本一起发送到gpt-3.5-turbo，而不是使用公式来计算评分。模型将决定原始输出与生成的其他三个样本的相符程度。
    [3]
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The self-similarity score returned for Evelyn Hartwell is **0**. Meanwhile,
    the score for the outputs related to Nicolas Cage is **0.95**. The time needed
    for getting the score is also pretty low.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Evelyn Hartwell，返回的自相似度评分是**0**。与此同时，与Nicolas Cage相关的输出评分是**0.95**。获取评分所需的时间也相当短。
- en: '![](../Images/1eef89548b1aa1e5636d1108f8ba37d1.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1eef89548b1aa1e5636d1108f8ba37d1.png)'
- en: Duration of LLM self-similarity score computation. Image by author.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: LLM自相似度评分计算的持续时间。图像由作者提供。
- en: This seems to be the best solution for our case, as we were also expecting from
    the comparative analysis of the source paper [2]. SelfCheckGPTPrompt significantly
    outperformed all other methods, with NLI being the second-best performing method.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎是我们案例的最佳解决方案，因为我们从源论文的比较分析中也预期到了这一点 [2]。SelfCheckGPTPrompt显著优于所有其他方法，NLI是表现第二好的方法。
- en: '![](../Images/f282730302c98cb10856ad56ad442574.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f282730302c98cb10856ad56ad442574.png)'
- en: Hallucination detection evaluation results [6]
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉检测评估结果 [6]
- en: The evaluation dataset was created by generating synthetic Wikipedia articles
    using the WikiBio dataset and GPT-3\. To avoid obscure concepts, 238 article topics
    were randomly sampled from the top 20% of the longest articles. GPT-3 was prompted
    to generate the first paragraphs in a Wikipedia style for each concept.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 评估数据集是通过使用WikiBio数据集和GPT-3生成合成的维基百科文章创建的。为了避免模糊的概念，从最长的文章的前20%中随机抽取了238个文章主题。GPT-3被提示以维基百科风格为每个概念生成首段。
- en: '![](../Images/4572558b7d2959e4c8f9fae771d003b8.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4572558b7d2959e4c8f9fae771d003b8.png)'
- en: Evaluation dataset creation [5]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 评估数据集创建 [5]
- en: Next, these generated passages were manually annotated for factuality at the
    sentence level. Each sentence was labeled as major inaccurate, minor inaccurate,
    or accurate based on predefined guidelines. In total, 1908 sentences were annotated,
    with around 40% major inaccurate, 33% minor inaccurate, and 27% accurate.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，这些生成的段落被人工注释以评估其准确性。根据预定义的指南，每个句子被标记为主要不准确、次要不准确或准确。总共标注了1908个句子，其中约40%为主要不准确，33%为次要不准确，27%为准确。
- en: To assess annotator agreement, 201 sentences had dual annotations. If the annotators
    agreed, that label was used; otherwise, the worst-case label was chosen. Inter-annotator
    agreement measured by Cohen’s kappa was 0.595 when selecting between accurate,
    minor inaccurate, and major inaccurate and 0.748 when minor/major inaccuracies
    were combined into one label.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估标注者的一致性，200个句子有双重标注。如果标注者达成一致，则使用该标签；否则，选择最坏的标签。通过 Cohen’s kappa 测量的标注者间一致性在选择准确、轻微不准确和主要不准确之间为
    0.595，而在将轻微/主要不准确合并为一个标签时为 0.748。
- en: The evaluation metric, AUC-PR, refers to the area under the precision-recall
    curve, which is a metric used to evaluate classification models.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标 AUC-PR 指的是精确度-召回曲线下的面积，这是用于评估分类模型的指标。
- en: Real-time hallucination detection
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时幻觉检测
- en: As a final application, let’s build a Streamlit app for real-time hallucination
    detection. As mentioned before, the best metric is the LLM self-similarity score.
    We will use a threshold of 0.5 to decide whether to display the generated output
    or a disclaimer.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最终应用，我们来构建一个 Streamlit 应用以实现实时幻觉检测。如前所述，最佳指标是 LLM 自相似性分数。我们将使用 0.5 的阈值来决定是显示生成的输出还是免责声明。
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now, we can visualize the final result.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以可视化最终结果。
- en: '![](../Images/ed68b9f6c037cb4a2683cd121470d830.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed68b9f6c037cb4a2683cd121470d830.png)'
- en: Streamlit app demo. Image by author.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit 应用演示。图片由作者提供。
- en: Conclusion
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The results are very promising! Hallucination detection in chatbots has been
    a long-discussed quality problem.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常令人鼓舞！聊天机器人中的幻觉检测一直是一个长期讨论的质量问题。
- en: What makes the techniques outlined here so exciting is the novel approach of
    using an LLM to evaluate the outputs of other LLMs. Specifically done by generating
    multiple responses to the same prompt and comparing their consistency.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这里所述技术之所以令人兴奋，是因为采用了使用 LLM 评估其他 LLM 输出的新颖方法。具体做法是生成多个对同一提示的响应并比较其一致性。
- en: There is still more work to be done, but rather than relying on human evaluation
    or hand-crafted rules, it seems to be a good direction to let the models themselves
    catch the inconsistencies.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然需要做更多的工作，但与其依赖人工评估或手工制定规则，不如让模型本身捕捉不一致性，这似乎是一个不错的方向。
- en: . . .
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: . . .
- en: '*If you enjoyed this article, join* [***Text Generation***](https://textgeneration.substack.com/)
    *— our newsletter has two weekly posts with the latest insights on Generative
    AI and Large Language Models.*'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章，加入* [***文本生成***](https://textgeneration.substack.com/) *——我们的新闻通讯每周发布两篇文章，提供有关生成
    AI 和大语言模型的最新见解。*'
- en: '*You can find the full code for this project on* [*GitHub*](https://github.com/partycia/real-time-hallucination-detection.git)*.*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可以在* [*GitHub*](https://github.com/partycia/real-time-hallucination-detection.git)*上找到这个项目的完整代码。*'
- en: '*You can also find me on* [*LinkedIn*](https://www.linkedin.com/in/ibrezeanu/)*.*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*你也可以在* [*LinkedIn*](https://www.linkedin.com/in/ibrezeanu/)*上找到我。*'
- en: . . .
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: . . .
- en: 'References:'
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[BERTSCORE: EVALUATING TEXT GENERATION WITH BERT](https://arxiv.org/abs/1904.09675)'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[BERTSCORE: 使用 BERT 评估文本生成](https://arxiv.org/abs/1904.09675)'
- en: '[SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative
    Large Language Models](https://arxiv.org/abs/2303.08896)'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[SELFCHECKGPT: 生成大语言模型的零资源黑箱幻觉检测](https://arxiv.org/abs/2303.08896)'
- en: '[https://learn.deeplearning.ai/quality-safety-llm-applications](https://learn.deeplearning.ai/quality-safety-llm-applications)'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://learn.deeplearning.ai/quality-safety-llm-applications](https://learn.deeplearning.ai/quality-safety-llm-applications)'
- en: '[A Broad-Coverage Challenge Corpus for'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[广覆盖挑战语料库用于'
- en: Sentence Understanding through Inference](https://aclanthology.org/N18-1101)
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过推断进行句子理解](https://aclanthology.org/N18-1101)
- en: '[https://drive.google.com/file/d/13LUBPUm4y1nlKigZxXHn7Cl2lw5KuGbc/view](https://drive.google.com/file/d/13LUBPUm4y1nlKigZxXHn7Cl2lw5KuGbc/view)'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://drive.google.com/file/d/13LUBPUm4y1nlKigZxXHn7Cl2lw5KuGbc/view](https://drive.google.com/file/d/13LUBPUm4y1nlKigZxXHn7Cl2lw5KuGbc/view)'
- en: '[https://drive.google.com/file/d/1EzQ3MdmrF0gM-83UV2OQ6_QR1RuvhJ9h/view](https://drive.google.com/file/d/1EzQ3MdmrF0gM-83UV2OQ6_QR1RuvhJ9h/view)'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://drive.google.com/file/d/1EzQ3MdmrF0gM-83UV2OQ6_QR1RuvhJ9h/view](https://drive.google.com/file/d/1EzQ3MdmrF0gM-83UV2OQ6_QR1RuvhJ9h/view)'
