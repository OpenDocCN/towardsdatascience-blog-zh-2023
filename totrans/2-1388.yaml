- en: 'Knowledge Graph Transformers: Architecting Dynamic Reasoning for Evolving Knowledge'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识图谱转换器：构建动态推理以适应不断演变的知识
- en: 原文：[https://towardsdatascience.com/knowledge-graph-transformers-architecting-dynamic-reasoning-for-evolving-knowledge-712e056725e0](https://towardsdatascience.com/knowledge-graph-transformers-architecting-dynamic-reasoning-for-evolving-knowledge-712e056725e0)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/knowledge-graph-transformers-architecting-dynamic-reasoning-for-evolving-knowledge-712e056725e0](https://towardsdatascience.com/knowledge-graph-transformers-architecting-dynamic-reasoning-for-evolving-knowledge-712e056725e0)
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----712e056725e0--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----712e056725e0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----712e056725e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----712e056725e0--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----712e056725e0--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----712e056725e0--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----712e056725e0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----712e056725e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----712e056725e0--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----712e056725e0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----712e056725e0--------------------------------)
    ·7 min read·Oct 28, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----712e056725e0--------------------------------)
    ·阅读时间 7 分钟·2023年10月28日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件用于提升本文文本的语法、流畅性和可读性。*'
- en: Knowledge graphs, which represent facts as interconnected entities, have emerged
    as a pivotal technique for enhancing AI systems with the capacity to assimilate
    and contextualize knowledge.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱通过将事实表示为相互连接的实体，已成为增强 AI 系统的一种关键技术，具备整合和上下文化知识的能力。
- en: However, real-world knowledge continuously evolves, necessitating dynamic representations
    that can capture the fluid, time-sensitive intricacies of the world.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现实世界的知识不断演变，需要动态的表示方法来捕捉世界的流动和时间敏感的复杂性。
- en: Temporal knowledge graphs (TKGs) fulfill this need by incorporating a temporal
    dimension, with each relationship tagged with a timestamp denoting its period
    of validity. TKGs allow modeling not only the connections between entities but
    also the dynamics of these relationships, unlocking new potentials for AI.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 时序知识图谱（TKGs）通过引入时间维度来满足这一需求，每个关系都有一个时间戳标记其有效期。TKGs 允许不仅建模实体之间的连接，还可以建模这些关系的动态，从而为
    AI 解锁新的潜力。
- en: While TKGs have garnered substantial research attention, their application in
    specialized domains remains an open frontier. In particular, the financial sector
    possesses attributes like rapidly evolving markets and multifaceted textual data
    that could significantly benefit from dynamic knowledge graphs. However, underdeveloped
    access to high-quality financial knowledge graphs has constrained advances in
    this domain.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管时序知识图谱（TKGs）已引起了大量研究关注，但其在专业领域的应用仍然是一个未开发的前沿领域。特别是金融领域具有市场快速发展的特征和多层次的文本数据，这些都可能从动态知识图谱中显著受益。然而，缺乏高质量金融知识图谱的访问限制了该领域的进展。
- en: Addressing this gap, Xiaohui Victor Li(2023) introduces an innovative, open-source
    Financial Dynamic Knowledge Graph (FinDKG) powered by a novel temporal knowledge
    graph learning model named Knowledge Graph Transformer (KGTransformer).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这一空白，Xiaohui Victor Li（2023）介绍了一种创新的开源金融动态知识图谱（FinDKG），该图谱由一种名为知识图谱转换器（KGTransformer）的新型时序知识图谱学习模型驱动。
- en: '[](https://github.com/xiaohui-victor-li/FinDKG/tree/main/FinDKG_dataset?source=post_page-----712e056725e0--------------------------------)
    [## FinDKG/FinDKG_dataset at main · xiaohui-victor-li/FinDKG'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/xiaohui-victor-li/FinDKG/tree/main/FinDKG_dataset?source=post_page-----712e056725e0--------------------------------)
    [## FinDKG/FinDKG_dataset at main · xiaohui-victor-li/FinDKG'
- en: 'Data and Model implementation for paper: FinDKG: Dynamic Knowledge Graph with
    Large Language Models for Global Finance…'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据和模型实现文献：FinDKG：结合大语言模型的全球金融动态知识图谱……
- en: github.com](https://github.com/xiaohui-victor-li/FinDKG/tree/main/FinDKG_dataset?source=post_page-----712e056725e0--------------------------------)
    [](https://xiaohui-victor-li.github.io/FinDKG/?source=post_page-----712e056725e0--------------------------------)
    [## Financial Dynamic Knowledge Graph
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/xiaohui-victor-li/FinDKG/tree/main/FinDKG_dataset?source=post_page-----712e056725e0--------------------------------)
    [](https://xiaohui-victor-li.github.io/FinDKG/?source=post_page-----712e056725e0--------------------------------)
    [## 财务动态知识图谱'
- en: This website provides the Financial Dynamic Knowledge Graph (FinDKG) portal,
    driven by graph AI model KGTransformer…
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本网站提供了财务动态知识图谱（FinDKG）门户，驱动该门户的是图形AI模型KGTransformer……
- en: xiaohui-victor-li.github.io](https://xiaohui-victor-li.github.io/FinDKG/?source=post_page-----712e056725e0--------------------------------)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[xiaohui-victor-li.github.io](https://xiaohui-victor-li.github.io/FinDKG/?source=post_page-----712e056725e0--------------------------------)'
- en: The FinDKG, constructed from a corpus of global financial news spanning over
    two decades, encapsulates both quantitative indicators and qualitative drivers
    of financial systems into an interconnected, temporal framework. The authors demonstrate
    FinDKG’s utility in generating actionable insights for real-world applications
    like risk monitoring and thematic investing.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: FinDKG由跨越二十多年的全球财务新闻语料库构建，将财务系统的定量指标和定性驱动因素封装到一个相互关联的时间框架中。作者展示了FinDKG在生成可操作的洞察力方面的实用性，例如风险监测和主题投资。
- en: The KGTransformer model, designed to handle the intricacies of TKGs, is shown
    to outperform existing static knowledge graph models on benchmark TKG datasets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: KGTransformer模型旨在处理TKGs的复杂性，并在基准TKG数据集上表现优于现有的静态知识图谱模型。
- en: The architecture leverages recent advances like meta-relation modeling, graph
    attention networks, and temporal point processes to achieve strong results.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 该架构利用了最新的进展，如元关系建模、图注意网络和时间点过程，以实现强劲的结果。
- en: Through access to open-sourced resources like FinDKG, KGTransformer, and the
    fine-tuned Integrated Contextual Knowledge Graph Generator (ICKG) model, this
    work aims to catalyze interdisciplinary research at the intersection of knowledge
    graphs and finance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过访问开源资源，如FinDKG、KGTransformer以及经过微调的集成上下文知识图谱生成器（ICKG）模型，这项工作旨在推动知识图谱与金融交叉学科研究。
- en: By harnessing dynamic knowledge graphs to generate nuanced financial insights,
    this research highlights impactful directions for injecting structured knowledge
    into data-driven finance and economics.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用动态知识图谱生成细致的财务洞察，这项研究突显了将结构化知识注入数据驱动的金融和经济学中的有影响力的方向。
- en: The capabilities showcased through FinDKG underscore the power of knowledge
    graphs in capturing the fluid complexities of the real world.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: FinDKG展示的能力突显了知识图谱在捕捉现实世界流动复杂性方面的强大力量。
- en: Transformer (KGT) model have expansive potential across industries. In supply
    chain management, KGTs can track supplier performance, forecast demand, and identify
    risks over time.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer（KGT）模型在各个行业中具有广泛的潜力。在供应链管理中，KGT可以跟踪供应商表现，预测需求，并识别随时间变化的风险。
- en: With knowledge representation and reasoning serving as active frontiers in artificial
    intelligence, this study signifies an important step towards building intelligent
    systems proficient in dynamic understanding.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 随着知识表示和推理作为人工智能的前沿领域，这项研究标志着向构建精通动态理解的智能系统迈出重要一步。
- en: Limitations of Static Graph Networks
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态图网络的局限性
- en: Most existing graph neural networks are designed for static graphs and do not
    account for temporal dynamics. For instance, models like Graph Convolutional Networks
    (GCNs) and Graph Attention Networks (GATs) aggregate information from neighboring
    nodes disregarding any temporal patterns.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有的图神经网络设计用于静态图，不考虑时间动态。例如，图卷积网络（GCNs）和图注意网络（GATs）等模型从邻近节点聚合信息，而忽视了任何时间模式。
- en: This static assumption severely restricts their reasoning capacity on TKGs.
    Without considering temporal context, predictions made using static embeddings
    quickly become outdated as the graph evolves.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这种静态假设严重限制了它们在TKGs上的推理能力。不考虑时间上下文，使用静态嵌入做出的预测会随着图谱的演变迅速过时。
- en: Furthermore, static models treat all edges uniformly, lacking the nuance to
    model relationships that vary in importance or validity over time. Their representation
    also remains confined to immediate neighbors, lacking a broader temporal perspective.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，静态模型将所有边缘视为均匀的，缺乏建模关系随时间变化的重要性或有效性的细微差别。它们的表示也仅限于直接邻居，缺乏更广泛的时间视角。
- en: TKGs require models that can understand time-dependent edge importance, adapt
    their decision-making as relationships and entities evolve, and make predictions
    while considering both past and future implications.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: TKGs需要能够理解时间相关的边重要性、随着关系和实体演变调整决策，并在考虑过去和未来影响的同时进行预测的模型。
- en: Let’s see how KGTs achieve this.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看KGTs如何实现这一点。
- en: Introducing Knowledge Graph Transformers
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入知识图谱变换器
- en: KGTs present a new paradigm of architectures specialized for dynamic learning
    on TKGs. They bring together graph neural networks and transformers in an innovative
    fashion.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: KGTs展示了一种专门用于TKG动态学习的新架构范式。它们以创新的方式将图神经网络和变换器结合在一起。
- en: 'At their core, KGTs incorporate **inductive biases** that make their design
    uniquely suited for TKG-based reasoning. These include:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，KGTs包含**归纳偏置**，使其设计特别适合于基于TKG的推理。这些包括：
- en: '**Explicit temporal modeling** to capture evolutionary dynamics'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**明确的时间建模** 以捕捉演变动态'
- en: '**Multi-relational handling** to represent heterogeneous relationships'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多关系处理** 以表示异质关系'
- en: '**Continuous entity tracking** to allow temporal adaptability'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连续实体跟踪** 以实现时间适应性'
- en: '**Graph-level summarization** to enable broader context'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图级汇总** 以实现更广泛的上下文'
- en: 'Let’s break down how KGTs implement these capabilities:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解KGTs如何实现这些能力：
- en: Explicit Temporal Modeling
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 明确的时间建模
- en: KGTs use separate entity and relation RNNs (Recurrent Neural Networks) to model
    the temporal evolution of node embeddings.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: KGTs使用独立的实体和关系RNN（递归神经网络）来建模节点嵌入的时间演变。
- en: As new events get added to the TKG, the RNNs update the embeddings to reflect
    the new state. This allows maintaining a representation of how an entity or relationship
    changes over time.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 随着新事件被添加到TKG中，RNN会更新嵌入以反映新的状态。这使得能够保持实体或关系随时间变化的表示。
- en: The RNNs also enable ordered sequence modeling, where the embedding at time
    *t* depends on prior timesteps — mimicking real-world temporal dynamics.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: RNN还支持有序序列建模，其中时间*t*的嵌入依赖于先前的时间步——模拟现实世界的时间动态。
- en: Multi-Relational Handling
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多关系处理
- en: In line with recent multi-relational graph network advances, KGTs employ relation-specific
    parameters to handle varied semantic connections.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 根据最近的多关系图网络进展，KGTs采用特定于关系的参数来处理各种语义连接。
- en: For example, the “Employed_By” and “Friends_With” relations have very different
    implications, which the model captures using distinct weights for each relation
    type.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，“Employed_By”和“Friends_With”关系具有非常不同的含义，模型通过对每种关系类型使用不同的权重来捕捉这些差异。
- en: This nuanced handling prevents over-generalization and improves predictive quality.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种细致的处理防止了过度泛化，并提高了预测质量。
- en: Continuous Entity Tracking
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续实体跟踪
- en: Instead of processing the TKG in isolated snapshots, KGTs continuously update
    embeddings as new events get added to the graph.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: KGTs不是在孤立的快照中处理TKG，而是随着新事件的添加不断更新嵌入。
- en: This allows smoothly tracking entities over time rather than re- initializing
    at each timestep. The resulting continuity preserves temporal contexts and enables
    the model to adapt as the TKG evolves.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得能够平滑地跟踪实体，而不是在每个时间步重新初始化。结果的连续性保持了时间上下文，并使模型能够随着TKG的演变进行适应。
- en: Graph-Level Summarization
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图级汇总
- en: In addition to neighboring node states, KGTs also incorporate a global graph
    embedding summarizing the entire state of the TKG up to a certain time.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 除了邻近节点状态，KGTs还包含一个全局图嵌入，汇总了TKG在某一时刻的全部状态。
- en: This provides crucial temporal context and improves predictions by considering
    the broader impacts of new events spanning beyond immediately affected entities.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了至关重要的时间上下文，并通过考虑新事件对超出立即受影响实体的广泛影响来改善预测。
- en: The graph embedding is calculated using a temporal attention mechanism over
    all nodes, enabling adaptive and efficient summarization.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图嵌入是通过对所有节点进行时间注意力机制计算的，从而实现自适应和高效的汇总。
- en: Architectural Components
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构组件
- en: 'KGTs comprise several interconnected components that impart the aforementioned
    capabilities:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: KGTs由多个相互连接的组件组成，这些组件赋予了上述能力：
- en: '**Input Layer:** Accepts initial node features or embeddings.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入层：** 接受初始节点特征或嵌入。'
- en: '**Temporal Embeddings:** Serve as specialized embeddings encoding time-evolving
    properties using RNNs.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间嵌入：** 作为专门的嵌入，通过RNN编码时间演变的属性。'
- en: '**Structural Embeddings:** Capture node neighborhoods and global topology through
    attentive message passing between neighbors.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构嵌入：** 通过邻居间的关注消息传递捕捉节点邻域和全局拓扑。'
- en: '**Position Encodings:** Provide temporal awareness of absolute positions analogous
    to transformer architectures.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**位置编码：** 提供了类似于变换器架构的绝对位置的时间感知。'
- en: '**Feed Forward Layers:** Enable deeper semantic integration using multi-layer
    perceptrons.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前馈层：** 使用多层感知机实现更深层次的语义集成。'
- en: '**Output Layer:** Returns node embeddings or predictions tailored to the end
    task.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出层：** 返回适合最终任务的节点嵌入或预测。'
- en: The components are stacked in a layered architecture, with each block refining
    and enriching the embeddings further. Skip connections allow combining both local
    and global perspectives.tional details, such as normalization layers, dropout,
    and specific activation functions, would be incorporated into the equations.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 组件以分层架构堆叠，每个块进一步精炼和丰富嵌入。跳跃连接允许结合局部和全局视角。附加细节，如归一化层、丢弃和特定激活函数，将被纳入方程中。
- en: '![](../Images/25a1ef731ba19ee6a2c41e798dc7291e.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25a1ef731ba19ee6a2c41e798dc7291e.png)'
- en: Advantages over Existing Methods
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相对于现有方法的优势
- en: 'The unique architectural attributes of KGTs lend them multiple advantages over
    previous state-of-the-art models on temporal graphs:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: KGTs 的独特架构属性使其相较于以往的最先进模型在时间图上的应用具有多重优势：
- en: '**Generalization:** KGTs can handle previously unseen entities, relations,
    and events by leveraging the learned inductive biases. Comparatively, many existing
    models rely on re-training.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**泛化：** KGTs 可以通过利用学习到的归纳偏差处理之前未见过的实体、关系和事件。相比之下，许多现有模型依赖于重新训练。'
- en: '**Reasoning:** The temporally-enriched entity and graph representations learned
    by KGTs lead to improved predictive reasoning on temporal graphs outperforming
    previous models.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理：** KGTs 学习的时间增强实体和图表示导致在时间图上的预测推理有所改善，超越了之前的模型。'
- en: '**Efficiency:** Mechanisms like the graph embedding avoid having to process
    lengthy historical sequences, improving training and inference efficiency on large
    TKGs.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率：** 像图嵌入这样的机制避免了处理冗长的历史序列，从而提高了对大型 TKGs 的训练和推理效率。'
- en: '**Interpretability:** Components like relation-specific parameters and temporal
    attention provide insight into the model’s working, improving interpretability
    over black-box models.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性：** 像关系特定参数和时间注意力这样的组件提供了对模型工作的洞察，提高了相较于黑箱模型的可解释性。'
- en: Overall, KGTs advance the state-of-the-art in dynamic reasoning on temporal
    knowledge graphs. Their strong empirical performance coupled with architectural
    transparency highlights their potential as a robust and practical solution for
    modeling complex time-evolving domains.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，KGTs 在时间知识图谱上的动态推理领域推进了最先进技术。他们强大的实证表现与架构透明度相结合，突出显示了它们作为建模复杂时间演变领域的强大而实际的解决方案的潜力。
- en: 'A sea of applications :'
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用领域广泛：
- en: The introduction of KGTs stimulates intriguing opportunities at the intersection
    of knowledge representation, reasoning, and time-series modeling — opening new
    frontiers in dynamic graph learning. As TKGs find expanding real-world applications,
    KGTs signify an impactful step towards endowing AI agents with a temporal understanding
    of the world around them.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: KGT 的引入在知识表示、推理和时间序列建模的交汇处激发了令人兴奋的机会——开辟了动态图学习的新领域。随着 TKGs 在实际应用中的不断扩展，KGTs
    代表了赋予 AI 代理对其周围世界的时间理解的一个重要步骤。
- en: This research makes significant strides in advancing the modeling of evolving
    real-world systems using dynamic knowledge graphs and specialized learning techniques.
    Through the introduction of an open-source Financial Knowledge Graph (FinDKG)
    and an innovative Knowledge Graph Transformer (KGTransformer) model, this work
    provides both practical tools and methodological advances to the field.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究在使用动态知识图谱和专业学习技术推进演变中的现实系统建模方面取得了重大进展。通过引入开源金融知识图谱（FinDKG）和创新的知识图谱变换器（KGTransformer）模型，这项工作为该领域提供了实际工具和方法上的进步。
- en: The creation of FinDKG from a corpus of global financial news demonstrates the
    feasibility of constructing domain-specific dynamic knowledge graphs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从全球金融新闻语料库创建 FinDKG 展示了构建领域特定动态知识图谱的可行性。
- en: FinDKG encapsulates both qualitative and quantitative aspects of financial systems
    in an interconnected, temporal framework. The use cases presented, from risk monitoring
    to thematic investing, highlight FinDKG’s utility in generating nuanced insights.
    This application potential is further expanded through the availability of FinDKG
    as an open-source resource.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: FinDKG 将金融系统的定性和定量方面封装在一个相互关联的时间框架中。所展示的用例，从风险监控到主题投资，突显了 FinDKG 在生成深刻见解方面的实用性。通过将
    FinDKG 作为开源资源，进一步扩大了其应用潜力。
- en: On the methodology front, KGTransformer pushes forward the state-of-the-art
    in dynamic knowledge graph learning. By combining architectural elements like
    graph attention networks, meta-relation modeling, and temporal point processes,
    KGTransformer achieves strong performance on benchmark dynamic graph datasets.
    The model is shown to outperform existing static knowledge graph models that do
    not account for temporal contexts. The introduction of components like relation-specific
    parameters and continuous entity tracking provide more expressive representations
    to handle evolving graphs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在方法论方面，KGTransformer 推动了动态知识图谱学习的最前沿。通过结合图注意力网络、元关系建模和时间点过程等架构元素，KGTransformer
    在基准动态图数据集上表现出色。模型被证明优于那些不考虑时间上下文的现有静态知识图谱模型。引入关系特定参数和连续实体追踪等组件提供了更具表现力的表示，以处理不断演变的图谱。
- en: The innovations presented in this research catalyze myriad possibilities at
    the intersection of knowledge representation, reasoning, and time-series modeling.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究中提出的创新在知识表示、推理和时间序列建模的交汇处催生了无数可能性。
- en: The availability of open-sourced resources like FinDKG, KGTransformer, and the
    ICKG language model provides fertile ground for other researchers to build upon
    this work and expand such techniques to new domains.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: FinDKG、KGTransformer 和 ICKG 语言模型等开源资源的可用性为其他研究人员在此基础上进一步发展这些技术并扩展到新领域提供了肥沃的土壤。
- en: 'Some promising directions include:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一些有前景的方向包括：
- en: Constructing dynamic knowledge graphs for specialized verticals like healthcare,
    education, transportation etc. that can benefit from temporal reasoning.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为像医疗、教育、交通等专业领域构建动态知识图谱，这些领域可以从时间推理中获益。
- en: Enhancing KGTransformer’s capabilities using recent advances in self-supervised
    learning and contrastive methods for graph representation learning.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用最近在自监督学习和对比方法方面的进展来增强 KGTransformer 的能力，以进行图表示学习。
- en: Combining the strengths of large language models with structured knowledge graphs
    for an integrated reasoning framework.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将大型语言模型的优势与结构化知识图谱结合，形成一个集成推理框架。
- en: Empirical comparisons of graph learning techniques with traditional time-series
    models on temporal forecasting tasks.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对图学习技术与传统时间序列模型在时间预测任务上的实证比较。
- en: Architectural improvements to KGTransformer like incorporating transformer encoders
    or improving temporal memory.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 KGTransformer 的架构改进，如引入变换器编码器或改进时间记忆。
- en: By harnessing the dual powers of transformer networks and structured knowledge
    graphs, this research enables richer dynamic understanding critical for intelligent
    systems operating in the real world.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用变换器网络和结构化知识图谱的双重优势，本研究实现了对智能系统在现实世界中操作的丰富动态理解。
- en: As knowledge representation and reasoning over time remain open frontiers, the
    groundwork established here serves as a springboard for impactful innovation at
    the confluence of machine learning and symbolic AI.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 随着知识表示和时间推理仍然是开放领域，此处建立的基础工作为机器学习和符号 AI 的交汇处的有影响力创新提供了跳板。
- en: '![](../Images/b7728e92b26e9a4a2893c01909838677.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7728e92b26e9a4a2893c01909838677.png)'
- en: Image by the author
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '***Note from Towards Data Science’s editors:*** *While we allow independent
    authors to publish articles in accordance with our* [*rules and guidelines*](/questions-96667b06af5)*,
    we do not endorse each author’s contribution. You should not rely on an author’s
    works without seeking professional advice. See our* [*Reader Terms*](/readers-terms-b5d780a700a4)
    *for details.*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '***来自 Towards Data Science 编辑的备注：*** *尽管我们允许独立作者根据我们的* [*规则和指南*](/questions-96667b06af5)*发布文章，但我们不对每位作者的贡献表示支持。您不应在未经专业建议的情况下依赖作者的作品。有关详细信息，请参见我们的*
    [*读者条款*](/readers-terms-b5d780a700a4) *。*'
