- en: 9 Tips for Training Models on your University’s HPC Cluster
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在大学HPC集群上训练模型的9个技巧
- en: 原文：[https://towardsdatascience.com/9-tips-for-training-models-on-your-universitys-hpc-cluster-a703eb87f3d6](https://towardsdatascience.com/9-tips-for-training-models-on-your-universitys-hpc-cluster-a703eb87f3d6)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/9-tips-for-training-models-on-your-universitys-hpc-cluster-a703eb87f3d6](https://towardsdatascience.com/9-tips-for-training-models-on-your-universitys-hpc-cluster-a703eb87f3d6)
- en: How to effectively run and debug code in a resource-constrained environment
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何在资源受限的环境中有效运行和调试代码
- en: '[](https://conorosullyds.medium.com/?source=post_page-----a703eb87f3d6--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page-----a703eb87f3d6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a703eb87f3d6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a703eb87f3d6--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page-----a703eb87f3d6--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://conorosullyds.medium.com/?source=post_page-----a703eb87f3d6--------------------------------)[![Conor
    O''Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page-----a703eb87f3d6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a703eb87f3d6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a703eb87f3d6--------------------------------)
    [Conor O''Sullivan](https://conorosullyds.medium.com/?source=post_page-----a703eb87f3d6--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a703eb87f3d6--------------------------------)
    ·6 min read·Mar 28, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----a703eb87f3d6--------------------------------)
    ·6分钟阅读·2023年3月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c5fc4bc25739d8d8186821bd8e9d602a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5fc4bc25739d8d8186821bd8e9d602a.png)'
- en: Photo by [Martijn Baudoin](https://unsplash.com/ja/@martijnbaudoin?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Martijn Baudoin](https://unsplash.com/ja/@martijnbaudoin?utm_source=medium&utm_medium=referral)拍摄，刊登在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Queue job, wait 24 hours, **cuda runtime error:** out of memory
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 排队作业，等待24小时，**cuda runtime error:** 内存不足
- en: Queue job, wait 24 hours, **FileNotFoundError:** No such file or directory
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 排队作业，等待24小时，**FileNotFoundError:** 没有这样的文件或目录
- en: Queue job, wait 24 hours, **RuntimeError:** stack expects each tensor…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 排队作业，等待24小时，**RuntimeError:** 堆栈期望每个张量……
- en: AHHHGH!!!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 啊啊啊啊啊!!!
- en: Debugging code on a high-performance computing (HPC) cluster can be incredibly
    frustrating. To make matters worse, at university you will be sharing resources
    with other students. Jobs will be added to a queue. You can wait hours before
    you even know if your code has errors.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在高性能计算（HPC）集群上调试代码可能非常令人沮丧。更糟糕的是，在大学里你将与其他学生共享资源。作业将被添加到队列中。你可能要等待几个小时才能知道代码是否有错误。
- en: I’ve recently been training models on my university’s HPC. I’ve learned some
    things (the hard way). I want to share these tips and tricks to hopefully make
    your experience a bit smoother. I’ll keep things general so you can apply them
    to any system.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近我在大学的HPC上训练模型。我学到了一些东西（是艰难的方式）。我想分享这些技巧，希望能让你的体验更顺利。我会保持通用，以便你可以将它们应用到任何系统。
- en: Do as much development on your personal machine as possible
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尽可能在个人机器上进行开发
- en: An HPC cluster has one objective — crunch the numbers. No fancy IDE, no debugger
    and no co-pilot. Do you really want to code your entire project using vim?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: HPC集群有一个目标——处理数据。没有华丽的IDE，没有调试器，也没有副驾驶。你真的想用vim编写整个项目吗？
- en: To avoid going insane (save that for your thesis), you should develop the code
    on your own machine. Train the model for at least **1 epoch** using a **small
    sample**. Include tests to make sure the data is loaded correctly and that all
    results are saved. It is no fun training a model for 50 epochs to find you forgot
    to save the best one (yes, I did this).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免发疯（把那些留给你的论文吧），你应该在自己的机器上开发代码。用**小样本**训练模型至少**1个周期**。包含测试以确保数据正确加载并且所有结果都已保存。训练模型50个周期却发现忘记保存最佳结果是毫无乐趣的（是的，我确实做过这个）。
- en: Keep the code simple
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保持代码简单
- en: Any additional steps you include in the code will increase the chance of a failed
    run. You should only run the processes that need heavy computing power. For example,
    after the model has been trained you will want to evaluate it. This can be done
    on your local machine. If your test set is small enough even a CPU will do.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你在代码中包含的任何额外步骤都会增加运行失败的可能性。你应该只运行需要大量计算能力的进程。例如，模型训练完成后，你会想要对其进行评估。这可以在本地机器上完成。如果你的测试集足够小，甚至
    CPU 也可以使用。
- en: Do not hardcode any paths or variables
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不要硬编码任何路径或变量
- en: When moving the code from your local machine to HPC, some things will inevitably
    have to change. For example, the file paths for loading data and saving results.
    I was developing on a Mac but the HPC has a Linux operating system. This meant
    I needed to change the device from “mps” to “cuda”.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当将代码从本地机器移动到 HPC 时，某些事情不可避免地需要更改。例如，加载数据和保存结果的文件路径。我是在 Mac 上开发的，但 HPC 使用的是 Linux
    操作系统。这意味着我需要将设备从“mps”更改为“cuda”。
- en: '![](../Images/049220951feba249272f10d2004a4fe4.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/049220951feba249272f10d2004a4fe4.png)'
- en: 'Figure 1: examples of variables to be updated (source: author)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：待更新变量示例（来源：作者）
- en: Do not hardcode anything that will need to change. Use variables and define
    them right at the top of your script. This makes them easy to change and you will
    not forget anything. Trust me! You do not want to scroll through lines of code
    using vim.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不要硬编码任何需要更改的内容。使用变量并在脚本顶部定义它们。这使得它们易于更改，并且你不会忘记任何东西。相信我！你不想用 vim 滚动查看代码行。
- en: Increase batch size
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增加批量大小
- en: In **Figure 1** above, you can see one of the variables I included is **batch_size.**
    This is the number of samples that are loaded and used to update model parameters
    at each iteration. A larger batch size means you can process more samples in parallel
    on a GPU leading to faster training times.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的**图 1**中，你可以看到我包含的一个变量是**batch_size**。这是每次迭代中加载和用于更新模型参数的样本数量。较大的批量大小意味着你可以在
    GPU 上并行处理更多样本，从而加快训练时间。
- en: Increasing this on your local machine will quickly lead to a “**cuda runtime
    error:** out of memory”. In comparison, the HPC can handle a larger batch size.
    However, it is [important to not increase it too much](https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e)
    as this can have a negative effect on model accuracy. I simply doubled the batch
    size from 32 to 64.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地机器上增加这一点很快会导致“**cuda runtime error:** out of memory”错误。相比之下，HPC 可以处理更大的批量大小。然而，[重要的是不要增加过多](https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e)，因为这可能会对模型准确性产生负面影响。我只是将批量大小从
    32 加倍到 64。
- en: Use system arguments for any experiments
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对任何实验使用系统参数
- en: As far as possible, you want to avoid editing code on the HPC. At the same time,
    to train the best model you will need to do experiments. To get around this, use
    system arguments. As seen in **Figure 2**, these allow you to update variables
    in your script at the command line.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能避免在 HPC 上编辑代码。同时，为了训练最佳模型，你需要进行实验。为了解决这个问题，使用系统参数。如**图 2**所示，这些参数允许你在命令行中更新脚本中的变量。
- en: '![](../Images/69e87f0472b4305dd0f21d9519f6409b.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69e87f0472b4305dd0f21d9519f6409b.png)'
- en: 'Figure 2: examples of system arguments (source: author)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：系统参数示例（来源：作者）
- en: The first one allows me to update the save path of the final model (**model_nam**e).
    The others allow me to **sample, scale** and **clean** the data in various ways
    (see **Figure 3**). You could even update the model architecture. For example,
    by passing in a list [x,y,z] that defines the number of nodes in the hidden layers
    of a neural network.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个变量允许我更新最终模型的保存路径（**model_nam**e）。其他变量允许我以各种方式**采样、缩放**和**清理**数据（见**图 3**）。你甚至可以更新模型架构。例如，通过传递一个列表[x,y,z]来定义神经网络隐藏层中的节点数量。
- en: '![](../Images/1739baee9a425eb964921541c87ec490.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1739baee9a425eb964921541c87ec490.png)'
- en: 'Figure 3: training a U-Net with 4 data cleaning experiments (source: author)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：用 4 个数据清理实验训练 U-Net（来源：作者）
- en: Include a sample argument
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包含一个示例参数
- en: The **sample** system argument is particularly useful. The one I’ve included
    above is a binary flag. If set to true, the modelling code will be run using a
    subset of 1000 samples. You could also pass in the actual number of samples as
    an integer.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**sample** 系统参数特别有用。我上面包含的这个是一个二进制标志。如果设置为 true，建模代码将使用 1000 个样本的子集运行。你也可以传递实际的样本数量作为整数。'
- en: Often I schedule 2 jobs right after each other — the sampled and full dataset
    runs. The sampled run will usually complete within a few minutes (unless someone
    is hogging all the GPUs!!). This helps point out any pesky bugs. If something
    goes wrong, I have the opportunity to stop the full dataset run, correct it and
    kick it off again before the end of the day.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常会在两个作业之间安排紧接着的运行——一个是采样数据集运行，另一个是完整数据集运行。采样运行通常会在几分钟内完成（除非有人占用了所有的 GPU!!）。这有助于指出那些烦人的错误。如果出现问题，我有机会在一天结束前停止完整数据集的运行，进行修正，然后重新启动。
- en: Be verbose
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 详尽说明
- en: 'No, I’m not talking about your friend majoring in finance. Your code should
    tell you as much as possible. This will help fix any bugs that do occur. Use those
    print statements! Some things I find useful to print on each run:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 不，我不是在谈论你那个主修金融的朋友。你的代码应该尽可能地告诉你更多信息。这将帮助修复任何出现的错误。使用那些打印语句！我发现每次运行时打印的一些有用信息包括：
- en: The system device (i.e. cuda or CPU)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统设备（即 cuda 或 CPU）
- en: Length of the dataset, training and validation sets
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的长度、训练集和验证集
- en: A sample of the data before and after any transformations
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据在任何转换前后的样本
- en: Training and validation loss for each epoch and batch
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个 epoch 和 batch 的训练损失和验证损失
- en: The model architecture
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型架构
- en: The value for any system arguments
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何系统参数的值
- en: You never know what is going to go wrong. For machine learning, logical errors
    can be difficult to identify. Your code can run perfectly but produce a model
    that is absolute garbage. Having a record of the process will help you trace back
    to where an error is coming from. This is especially important if you want to
    run multiple experiments.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你永远不知道会出什么问题。对于机器学习来说，逻辑错误可能很难被识别。你的代码可能运行得很好，但产生的模型却是完全无用的。拥有一个过程记录将帮助你追溯错误的来源。如果你打算进行多次实验，这一点尤其重要。
- en: Use a diff checker
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 diff 比较工具
- en: Things will go wrong. Very wrong. I broke my own rules and made a few changes
    to the script on the HPC. Okay, I made many changes. I lost track of what I had
    done and the code would not run properly. This is where a [diff checker](https://www.diffchecker.com/text-compare/#editor)
    came in handy.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 事情会出错的。非常糟糕。我打破了自己的规则，在 HPC 上对脚本进行了几处修改。好吧，我做了很多修改。我失去了对自己所做更改的追踪，代码无法正常运行。在这种情况下，[diff
    比较工具](https://www.diffchecker.com/text-compare/#editor)就派上了用场。
- en: It will compare, line-by-line, the text in one document to another. I used it
    to compare the script on the HPC to one of my local machines. This pointed out
    what I had changed and I could immediately identify the problem.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 它会逐行比较一个文档中的文本与另一个文档中的文本。我用它来比较 HPC 上的脚本与我本地机器上的一个脚本。这指出了我所做的更改，我可以立即识别出问题。
- en: '![](../Images/dfd059907e9e9f6d1e4e3d24fee2d307.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfd059907e9e9f6d1e4e3d24fee2d307.png)'
- en: 'Figure 4: pointing out the difference in HPC and local script (source: [diff
    checker](https://www.diffchecker.com/text-compare/#editor))'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：指出 HPC 和本地脚本中的差异（来源：[diff 比较工具](https://www.diffchecker.com/text-compare/#editor)）
- en: Be realistic about your research
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对你的研究保持现实
- en: The tips so far have lacked detail. There is a lot you can do to [speed up the
    training for specific model packages (e.g. XGBoost)](https://medium.com/towards-data-science/how-to-speed-up-xgboost-model-training-fcf4dc5dbe5f).
    [Keeping better track of your data and models](https://medium.com/@iamleonie/intro-to-mlops-data-and-model-versioning-fa623c220966)
    can also help avoid errors and confusion. But, really, there is only so much you
    can do. My final tip is to be realistic about what you can achieve with your available
    resources.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的提示还缺乏细节。你可以做很多事情来[加快特定模型包（例如 XGBoost）的训练速度](https://medium.com/towards-data-science/how-to-speed-up-xgboost-model-training-fcf4dc5dbe5f)。[更好地跟踪你的数据和模型](https://medium.com/@iamleonie/intro-to-mlops-data-and-model-versioning-fa623c220966)也可以帮助避免错误和混乱。但实际上，你能做的也有限。我的最终建议是对你在可用资源下能实现的目标保持现实。
- en: In the era of LLMs, this may be disheartening. It seems like all the major breakthroughs
    are achieved with increasing computational power. You must consider that a model
    the size of GPT-3 is [estimated to cost **$450,000** to train](https://www.mosaicml.com/blog/gpt-3-quality-for-500k#).
    This rivals some departments' entire budgets! You simply cannot compete.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 时代，这可能会令人沮丧。所有主要的突破似乎都是通过增加计算能力来实现的。你必须考虑到，一个像 GPT-3 这样大小的模型[训练成本估计为 **45万美元**](https://www.mosaicml.com/blog/gpt-3-quality-for-500k#)。这与一些部门的整个预算相当！你根本无法竞争。
- en: Yet, you can still make a valuable contribution. Fine-tuning models do not need
    as many resources. Collecting and labelling data is often a more significant contribution
    than chasing SOTA on benchmarks. Every sub-domain to which you apply machine learning
    will come with its own challenges. Often a lack of resources will lead to more
    innovative solutions to these challenges. So be thankful for those long job queues…
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您仍然可以做出有价值的贡献。微调模型不需要那么多资源。收集和标注数据往往比在基准测试中追求 SOTA 更为重要。每个应用机器学习的子领域都会带来自己的挑战。通常，资源的匮乏会促使我们对这些挑战提出更具创新性的解决方案。所以要感谢那些漫长的工作队列……
- en: Oh, who am I kidding!! Anyone want to buy me a GPU?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，我在自欺欺人！！有谁愿意买给我一块 GPU 吗？
- en: I hope you enjoyed this article! You can support me by becoming one of my [**referred
    members**](https://conorosullyds.medium.com/membership) **:)**
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您喜欢这篇文章！您可以通过成为我的 [**推荐会员**](https://conorosullyds.medium.com/membership)
    **:)** 来支持我
- en: '[](https://conorosullyds.medium.com/membership?source=post_page-----a703eb87f3d6--------------------------------)
    [## Join Medium with my referral link — Conor O’Sullivan'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://conorosullyds.medium.com/membership?source=post_page-----a703eb87f3d6--------------------------------)
    [## 通过我的推荐链接加入 Medium — Conor O’Sullivan]'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为 Medium 会员，您的会员费的一部分会分配给您阅读的作者，您可以全面访问每个故事……
- en: conorosullyds.medium.com](https://conorosullyds.medium.com/membership?source=post_page-----a703eb87f3d6--------------------------------)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[conorosullyds.medium.com](https://conorosullyds.medium.com/membership?source=post_page-----a703eb87f3d6--------------------------------)'
- en: '| [Twitter](https://twitter.com/conorosullyDS) | [YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w)
    | [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup) — sign up for FREE access
    to a [Python SHAP course](https://adataodyssey.com/courses/shap-with-python/)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '| [Twitter](https://twitter.com/conorosullyDS) | [YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w)
    | [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup) — 免费注册获取 [Python SHAP 课程](https://adataodyssey.com/courses/shap-with-python/)'
- en: References
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Michael Galarnyk](https://medium.com/u/c07aac64b6e1?source=post_page-----a703eb87f3d6--------------------------------)
    **How to Speed Up XGBoost Model Training** [https://medium.com/towards-data-science/how-to-speed-up-xgboost-model-training-fcf4dc5dbe5f](https://medium.com/towards-data-science/how-to-speed-up-xgboost-model-training-fcf4dc5dbe5f)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[Michael Galarnyk](https://medium.com/u/c07aac64b6e1?source=post_page-----a703eb87f3d6--------------------------------)
    **如何加速 XGBoost 模型训练** [https://medium.com/towards-data-science/how-to-speed-up-xgboost-model-training-fcf4dc5dbe5f](https://medium.com/towards-data-science/how-to-speed-up-xgboost-model-training-fcf4dc5dbe5f)'
- en: '[Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----a703eb87f3d6--------------------------------)
    **Intro to MLOps: Data and Model Versionin**g [https://medium.com/@iamleonie/intro-to-mlops-data-and-model-versioning-fa623c220966](https://medium.com/@iamleonie/intro-to-mlops-data-and-model-versioning-fa623c220966)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----a703eb87f3d6--------------------------------)
    **MLOps简介：数据和模型版本管理** [https://medium.com/@iamleonie/intro-to-mlops-data-and-model-versioning-fa623c220966](https://medium.com/@iamleonie/intro-to-mlops-data-and-model-versioning-fa623c220966)'
- en: '[Kevin Shen](https://medium.com/u/c1ed18ad484c?source=post_page-----a703eb87f3d6--------------------------------)
    **Effect of batch size on training dynamics** [https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e](https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kevin Shen](https://medium.com/u/c1ed18ad484c?source=post_page-----a703eb87f3d6--------------------------------)
    **批量大小对训练动态的影响** [https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e](https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e)'
