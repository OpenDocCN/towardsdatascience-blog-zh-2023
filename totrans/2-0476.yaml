- en: Categorize Free-Text Bank Transaction Descriptions Using BERT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用BERT对自由文本银行交易描述进行分类
- en: 原文：[https://towardsdatascience.com/categorize-free-text-bank-transaction-descriptions-using-bert-44c9cc87735b](https://towardsdatascience.com/categorize-free-text-bank-transaction-descriptions-using-bert-44c9cc87735b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/categorize-free-text-bank-transaction-descriptions-using-bert-44c9cc87735b](https://towardsdatascience.com/categorize-free-text-bank-transaction-descriptions-using-bert-44c9cc87735b)
- en: I built myself an Expense Tracking Tool
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我为自己建立了一个开支跟踪工具
- en: '[](https://jin-cui.medium.com/?source=post_page-----44c9cc87735b--------------------------------)[![Jin
    Cui](../Images/e5ddcbaa6d7da38f960d2c5fea71b538.png)](https://jin-cui.medium.com/?source=post_page-----44c9cc87735b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----44c9cc87735b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----44c9cc87735b--------------------------------)
    [Jin Cui](https://jin-cui.medium.com/?source=post_page-----44c9cc87735b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jin-cui.medium.com/?source=post_page-----44c9cc87735b--------------------------------)[![Jin
    Cui](../Images/e5ddcbaa6d7da38f960d2c5fea71b538.png)](https://jin-cui.medium.com/?source=post_page-----44c9cc87735b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----44c9cc87735b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----44c9cc87735b--------------------------------)
    [Jin Cui](https://jin-cui.medium.com/?source=post_page-----44c9cc87735b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----44c9cc87735b--------------------------------)
    ·7 min read·Jan 30, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----44c9cc87735b--------------------------------)
    ·7分钟阅读·2023年1月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1a38931da456d880799b9fea6b82d20c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a38931da456d880799b9fea6b82d20c.png)'
- en: Expense by Category. Chart by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 按类别统计开支。图表由作者提供
- en: The Situation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情况说明
- en: I purchased a property towards the end of calendar year 2022 with a mortgage.
    Given the increase in financial commitments, I wanted to keep a tab on my expenses.
    It had never occurred to me prior to this point, that I actually had no idea where
    I have been spending the most. Figuring this out may be a good starting point
    for my own expense management.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我在2022年年底购买了一处房产，并办理了抵押贷款。由于财务承诺的增加，我想对自己的开支进行监控。直到这一点之前，我从未意识到自己实际上不知道自己最常花钱的地方。弄清楚这一点可能是我自己开支管理的一个良好起点。
- en: Naturally I turned to the bank transactions data which I downloaded from the
    online banking portal in a *.csv* format. A snippet of this for the last few days
    of 2022 is provided below.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自然，我转向了从在线银行门户下载的银行交易数据，格式为 *.csv*。下面是2022年最后几天的数据片段。
- en: '![](../Images/2077e5d1baa9ed2ae7aa8b08a0685e57.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2077e5d1baa9ed2ae7aa8b08a0685e57.png)'
- en: 'Image 1: Writer’s bank transaction data. Image by author'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图片1：作者的银行交易数据。图片由作者提供
- en: Based on snippet above, it seems I spent proportionally more on food (as highlighted
    in green). More importantly, the transaction descriptions are free-text based,
    is there a way to automatically classify these into a number of pre-defined expense
    categories (e.g. food, grocery shopping, utilities and etc.)?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上面的数据片段，似乎我在食品上的支出比例较高（如绿色高亮所示）。更重要的是，交易描述是基于自由文本的，有没有办法自动将这些描述分类到一些预定义的开支类别中（例如食品、杂货购物、水电费等）？
- en: There is at least one way using pre-trained Large Language Models like BERT,
    and this article offers a tutorial as to how!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像BERT这样的预训练大型语言模型至少有一种方法，本文提供了如何进行操作的教程！
- en: '**A 2023 Introduction to BERT**'
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**2023年 BERT 介绍**'
- en: Whilst ChatGPT being a state-of-the-art **Text Generation** model is attracting
    a lot of attention at this time, it is generally not considered a **General Purpose**
    model — one such as BERT which can be used across multiple Natural Language Understanding
    tasks. Some examples of these are Grammar Detection, Sentiment Classification,
    Text Similarity, Q & A Inference and etc.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ChatGPT作为一种先进的**文本生成**模型目前受到广泛关注，但它通常不被认为是**通用**模型——例如BERT可以用于多种自然语言理解任务。一些示例包括语法检测、情感分类、文本相似性、问答推理等。
- en: BERT was developed and released by Google in 2018\. It’s a pre-trained model
    using text passages on Wikipedia and BookCorpus (to ensure the training data are
    grammatically sound).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: BERT由谷歌于2018年开发和发布。它是一个使用维基百科和BookCorpus中的文本段落进行预训练的模型（以确保训练数据在语法上是准确的）。
- en: The BERT model I’ll be using for the purpose of this tutorial is available on
    Hugging Face through the sentence_transformer library, which is a Python framework
    for creating sentence, text and image embeddings.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中使用的 BERT 模型可以通过 Hugging Face 的 sentence_transformer 库获得，该库是一个用于创建句子、文本和图像嵌入的
    Python 框架。
- en: Steps for Building the Expense Classifier
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建费用分类器的步骤
- en: 'How do I ultimately convert the free-text transaction descriptions into an
    expense category? There are a couple of strategies I can think of. In this tutorial,
    I’ll be providing a step-by-step guide for building the Expense Classifier based
    on (cosine) similarity of word embeddings. The steps are outlined below:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我究竟如何将自由文本交易描述转换为费用类别？我能想到几种策略。在本教程中，我将提供一个基于（余弦）词嵌入相似度的费用分类器的逐步指南。步骤如下：
- en: Manually label a credible number of transaction descriptions into an expense
    category (e.g. food, entertainment). This creates a set of labelled training data.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动将大量交易描述标记为一个费用类别（例如，食品、娱乐）。这会创建一组标记的训练数据。
- en: Parse individual transaction descriptions in the training data above as word
    embeddings using BERT (i.e. convert texts into a numerical vector). **Step 1**
    and **Step 2** collectively ensure that the training data is assigned to a particular
    expense category as well as a word embedding vector.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 BERT 将上述训练数据中的单个交易描述解析为词嵌入（即将文本转换为数值向量）。**步骤 1**和**步骤 2**共同确保训练数据被分配到特定的费用类别以及词嵌入向量。
- en: Repeat **Step 2** for new transaction descriptions (i.e. convert unseen texts
    into a numerical vector)
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对新的交易描述重复**步骤 2**（即将未见过的文本转换为数值向量）
- en: Pair the word embeddings in **Step 3** with the most similar word embeddings
    from the training data, and assign the same expense category
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**步骤 3**中的词嵌入与训练数据中最相似的词嵌入配对，并分配相同的费用类别
- en: Python Implementation
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 实现
- en: This section sets out the Python codes for loading the required packages as
    well as for implementing the steps as outlined above (apart from **Step 1** which
    is a manual labelling step).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了加载所需包以及实施上述步骤的 Python 代码（不包括**步骤 1**，这是一项手动标记步骤）。
- en: '**Step 0: Import the required libraries**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 0：导入所需的库**'
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Step 1: Label training data**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：标记训练数据**'
- en: I manually labelled 200 transaction descriptions into a expense category. For
    instance, the transaction descriptions in **Image 1** were assigned an expense
    category as shown in the image below. I have also assigned categories such as
    utilities (i.e. for electricity and gas), car and gift to other transactions in
    the training data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我手动将 200 个交易描述标记为一个费用类别。例如，**图像 1**中的交易描述被分配了如下图所示的费用类别。我还将公共事业（即电费和煤气费）、汽车和礼品等类别分配给了训练数据中的其他交易。
- en: '![](../Images/bea125c7ecded038ac1a2c3f8b867725.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bea125c7ecded038ac1a2c3f8b867725.png)'
- en: 'Image 3: Manual label of training data. Image by author'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 3：训练数据的手动标记。图片作者提供
- en: '**Step 2: Create word embeddings for training data using BERT**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：使用 BERT 创建训练数据的词嵌入**'
- en: We start by defining a function for cleaning the text data. This includes lower-casing
    words, removing special characters including dates (which are not useful in informing
    the expense category).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义一个用于清理文本数据的函数。这包括将单词小写、去除特殊字符（包括日期，这些在确定费用类别时并不有用）。
- en: Stemming, lemmatization or removing stop words which are common practices in
    an NLP data cleaning pipeline are generally not required when using a BERT model
    due to its Byte-Pair Encoding and Attention mechanisms.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 BERT 模型时，通常不需要进行词干提取、词形还原或去除停用词等 NLP 数据清理管道中的常见做法，因为 BERT 模型使用了字节对编码和注意力机制。
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We then apply the function to the transaction descriptions, loaded as *text_raw*
    from the dataframe shown in **Image 1** (*df_transaction_description*).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将函数应用于交易描述，这些描述从**图像 1**中作为*text_raw*加载（*df_transaction_description*）。
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The snippet below shows an example of a particular transaction before and after
    data cleaning was applied.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下片段显示了数据清理应用前后的特定交易示例。
- en: '![](../Images/bf3838aeaf95973bcf23ea0d0e9ecb45.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf3838aeaf95973bcf23ea0d0e9ecb45.png)'
- en: 'Image 2: Data cleaning example. Image by author'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 2：数据清理示例。图片作者提供
- en: We then run the cleaned texts through BERT. I’ve selected the ‘*paraphrase-mpnet-base-v2*’
    BERT model known for modelling sentence similarity. Per its [documentation on
    Hugging Face](https://huggingface.co/sentence-transformers/paraphrase-mpnet-base-v2),
    it maps sentences and paragraphs to a 768 dimensional dense vector space and can
    be used for tasks like clustering or semantic search.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将清理后的文本输入到BERT中。我选择了'*paraphrase-mpnet-base-v2*' BERT 模型，该模型以建模句子相似性而闻名。根据其在[Hugging
    Face](https://huggingface.co/sentence-transformers/paraphrase-mpnet-base-v2)上的文档，它将句子和段落映射到一个768维的密集向量空间，并可用于诸如聚类或语义搜索等任务。
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'A snippet of the word embeddings for the first few transactions is provided
    below:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下方提供了前几笔交易的词嵌入片段：
- en: '![](../Images/7e34cb4bc7897cf40aca823654d87c18.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e34cb4bc7897cf40aca823654d87c18.png)'
- en: 'Image 4: BERT embeddings. Image by author'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 4：BERT 嵌入。图像由作者制作
- en: '**Step 3: Create word embeddings for unseen data**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3：为未见数据创建词嵌入**'
- en: I’ve selected 20 transactions from the data which didn’t make the training data
    (for the purpose of this tutorial, randomly selected transactions). These are
    shown in the image below.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我从未见过的数据中选择了20笔交易（为了本教程的目的，随机选择了交易）。这些交易显示在下图中。
- en: '![](../Images/93028502aadcd1ca7b7ff30b54fd0865.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93028502aadcd1ca7b7ff30b54fd0865.png)'
- en: 'Image 5: Unseen transactions. Image by author'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 5：未见交易。图像由作者制作
- en: The transaction descriptions above are loaded as *text_test_raw*. Similar to
    **Step 2**, these are run through BERT for embedding.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 上述交易描述作为*text_test_raw*加载。类似于**步骤 2**，这些数据通过BERT进行嵌入处理。
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Step 4: Pair unseen data with most similar training data**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 4：将未见数据与最相似的训练数据配对**'
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: d_output dataframe shows that the unseen data have been assigned a fairly reasonable
    expense category.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: d_output 数据框显示，未见数据已被分配到一个相当合理的费用类别。
- en: '![](../Images/eea9109b46c9e201dbfe93d5c908a576.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eea9109b46c9e201dbfe93d5c908a576.png)'
- en: 'Image 6: Unseen data matched with training data. Image by author'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 6：未见数据与训练数据的匹配。图像由作者制作
- en: Now whenever new expenses come through, simply feed them to the model!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每当有新的费用产生时，只需将其输入模型即可！
- en: '**Bonus Step: Plotting expenses by category**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**附加步骤：按类别绘制费用图**'
- en: I have actually applied the steps above to all my expenses in calendar year
    2022\. The plot below shows the resultant expense dollar amounts by the assigned
    category.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我实际上将上述步骤应用于了2022日历年度的所有费用。下图展示了按分配类别计算的费用金额。
- en: '![](../Images/1a38931da456d880799b9fea6b82d20c.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a38931da456d880799b9fea6b82d20c.png)'
- en: 'Chart 7: Expense plot by category. Chart by author'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图表 7：按类别划分的费用图。图表由作者制作
- en: 'Key observations were:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 主要观察结果如下：
- en: I spent the most on Food in 2022, followed by Mortgage repayments and Utility
    bills.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在2022年，我在食品上的开支最多，其次是抵押贷款还款和公用事业账单。
- en: Although Credit Card repayment had the highest amount, it is assumed that Credit
    Card spending could be attributed to other expense categories in the same proportion.
    This assumption also applies to the PayPal category.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管信用卡还款金额最高，但假设信用卡支出可以按相同比例分配到其他费用类别。这一假设也适用于PayPal类别。
- en: Based on the data, I probably want to cut back on spending on Food for more
    spending on Groceries (i.e. start cooking at home as opposed to dining out) in
    2023.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据数据，我可能希望减少食品开支，将更多支出转向杂货（即，开始在家做饭而不是外出就餐）以便于2023年。
- en: My spending on Beauty products was probably driven by instances where I went
    shopping with the wife…
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我在美容产品上的支出可能是因为我和妻子一起购物的情况……
- en: In addition, it’s super easy to return the transactions with the highest spending
    within a particular category. For instance, my highest spending in the Food expense
    category in 2022 were shown in the screen print below. I’m happy with the results
    as some of these restaurants weren’t present in the training data. Despite this,
    BERT was still able to allocate these transactions to the Food category.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，返回特定类别中最高支出的交易非常简单。例如，我在2022年食品费用类别中的最高支出如屏幕截图所示。我对结果感到满意，因为这些餐厅中有些在训练数据中并不存在。尽管如此，BERT
    仍然能够将这些交易分配到食品类别。
- en: '![](../Images/2cb18ec6e14bec4ad0f30c101ff953a7.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cb18ec6e14bec4ad0f30c101ff953a7.png)'
- en: 'Image 7: Top expenses.Image by author'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 7：主要费用。图像由作者制作
- en: Concluding Thoughts
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This article provides a comprehensive tutorial in building an expense tracking
    tool. All I’ve done really is translating the free-text transaction descriptions
    to a language the machine understands using BERT, and letting the machine do the
    hard yards!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提供了一个构建开支跟踪工具的全面教程。我做的就是将自由文本的交易描述翻译成机器理解的语言，使用BERT，并让机器完成繁重的工作！
- en: An alternative approach is to replace **Step 4** of this tutorial by passing
    the same wording embeddings through a classification model — something for the
    readers to experiment with further.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是通过将相同的词向量嵌入传递到分类模型中，来替代本教程的**第4步**——这是给读者进一步实验的内容。
- en: If you like this article of mine, feel free to have a read of the [others](https://jin-cui.medium.com/).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢我的这篇文章，可以随意阅读其他的[文章](https://jin-cui.medium.com/)。
- en: '*As I ride the AI/ML wave, I enjoy writing and sharing step-by-step guides
    and how-to tutorials in a comprehensive language with ready-to-run codes. If you
    would like to access all my articles (and articles from other practitioners/writers
    on Medium), you can sign up using* [*the link*](https://medium.com/@jin-cui/membership)
    *here!*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*随着我踏上AI/ML的浪潮，我喜欢用全面的语言撰写和分享一步一步的指南和如何做的教程，并附带可运行的代码。如果你想访问我所有的文章（以及Medium上其他从业者/作者的文章），你可以通过*
    [*这个链接*](https://medium.com/@jin-cui/membership) *注册！*'
