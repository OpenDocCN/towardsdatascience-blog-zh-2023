- en: 'CFXplorer: Counterfactual Explanation Generation Python Package'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/cfxplorer-counterfactual-explanation-generation-python-package-483ca4221ab8](https://towardsdatascience.com/cfxplorer-counterfactual-explanation-generation-python-package-483ca4221ab8)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduces a Python package for generating counterfactual explanations for tree-based
    algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@kyosuke1029?source=post_page-----483ca4221ab8--------------------------------)[![Kyosuke
    Morita](../Images/05b868cd1e4629fe56a09bd6cf3553be.png)](https://medium.com/@kyosuke1029?source=post_page-----483ca4221ab8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----483ca4221ab8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----483ca4221ab8--------------------------------)
    [Kyosuke Morita](https://medium.com/@kyosuke1029?source=post_page-----483ca4221ab8--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----483ca4221ab8--------------------------------)
    ·9 min read·Aug 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: The importance of interpretability in machine learning models is growing as
    they are increasingly applied in real‐world scenarios. Understanding how models
    make decisions benefits not only the model's users but also those who are affected
    by the decisions made by the model. **Counterfactual explanations** have been
    developed to cope with this issue, as they allow individuals to understand how
    they would achieve a desirable outcome by perturbing their original data. In the
    short term, counterfactual explanation possibly demonstrates actionable suggestions
    to those who are affected by a machine learning model decision. For example, a
    person who was rejected for a loan application could know what could have done
    to be accepted this time and that would be useful to improve on their next application.
  prefs: []
  type: TYPE_NORMAL
- en: Lucic et al. [1] proposed FOCUS, which is designed to generate optimal distance
    counterfactual explanations to the original data for all the instances in tree‐based
    machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: CFXplorer is a Python package that generates counterfactual explanations for
    a given model and data by using the FOCUS algorithm. This article introduces and
    showcases how CFXplorer can be used for generating counterfactual explanations.
  prefs: []
  type: TYPE_NORMAL
- en: Links
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'GitHub repo: [https://github.com/kyosek/CFXplorer](https://github.com/kyosek/CFXplorer)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Documentation: [https://cfxplorer.readthedocs.io/en/latest/?badge=latest](https://cfxplorer.readthedocs.io/en/latest/?badge=latest)'
  prefs: []
  type: TYPE_NORMAL
- en: 'PyPI: [https://pypi.org/project/CFXplorer/](https://pypi.org/project/CFXplorer/)'
  prefs: []
  type: TYPE_NORMAL
- en: Table of contents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FOCUS algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CFXplorer examples
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/b2e3eb017778d73d446df457c29e6e82.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Wesley Sanchez](https://unsplash.com/@wesleycs12?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 1\. FOCUS algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section briefly introduces the FOCUS algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generation of counterfactual explanations is a problem that has been addressed
    by several existing methods. Wachter, Mittelstadt, and Russell [2] formulated
    this problem into an optimisation framework, however, this approach is limited
    to differentiable models. The FOCUS aimed to extend the framework to non-differentiable
    models, specifically tree-based algorithms, by introducing a probabilistic model
    approximation. A crucial aspect of this method is the approximation of a pretrained
    tree-based model, represented as *f*, achieved by replacing each split in each
    tree with a sigmoid function with a parameter *σ* that is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6eff59d726022cd8252176ad65ac196.png)'
  prefs: []
  type: TYPE_IMG
- en: where *σ ∈ R>0.*
  prefs: []
  type: TYPE_NORMAL
- en: 'This sigmoid function is incorporated into the function *t ̃_j(x)* that approximates
    the node *j* activation *t_j(x)* of the tree-based model *f* for a given input
    *x*. This function is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c1dfa8e0e9e58ef974b5f907b1534388.png)'
  prefs: []
  type: TYPE_IMG
- en: where θ_j is a threshold for activation of node *j*.
  prefs: []
  type: TYPE_NORMAL
- en: 'This method approximates a single decision tree *T*. A tree approximation can
    be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/708f245c76d76dcb0588e4b36ae96a37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Additionally, this method replaces the maximum operation of *f*, which is an
    ensemble of *M* many trees with weights *ω_m ∈ R* by a softmax function with temperature
    *τ ∈ R>0*. Thus, the approximation *f ̃* can be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be102c7870180743bbf81cbf23ab7d9a.png)'
  prefs: []
  type: TYPE_IMG
- en: It is important to note that this approximation method can be applied to any
    tree-based model.
  prefs: []
  type: TYPE_NORMAL
- en: The main claims of the FOCUS algorithm are that this method is able to (i) generate
    counterfactual explanations for all instances in a dataset and (ii) find counterfactual
    explanations that are closer to the original input for tree-based algorithms than
    existing frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. CFXplorer examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section demonstrates two examples of how you can use the CFXplorer package.
    The first one would be a simple example, where you can learn the basic usage of
    the package. The second example shows how to search the optimal hyperparameters
    of FOCUS by using the Optuna [3] package. As this article went through in the
    previous section, there are a few hyperparameters of FOCUS. Those can be optimised
    by integrating with hyperparameter tuning packages.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Simple example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this simple example, we create random data, a decision tree model, and use
    CFXplorer to generate counterfactual explanations. The Python package CFXplorer
    generates counterfactual explanations by using the FOCUS algorithm. This section
    demonstrates how to use this package to do so.
  prefs: []
  type: TYPE_NORMAL
- en: '**Installation**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can install the package by using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: First, import the packages.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We create a dummy dataset to be fed to the decision tree model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: CFXplorer takes only standardised feature values (between 0 and 1), thus we
    need to scale them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now train the decision tree model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We combine all the above and run them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Once we got the data and the model, we initialise `Focus`. Focus takes several
    arguments to customize. Yet for simplicity, we can use the number of iterations
    and distance function in this example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Other arguments of FOCUS are;
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can generate counterfactual explanations by using `generate method
    of FOCUS.`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We can check those generated counterfactual explanations in a plot.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ddd6d9a365d50e090f1366859c55e7a2.png)'
  prefs: []
  type: TYPE_IMG
- en: We can observe that many of the predictions == 1 were located on the right-hand
    side before applying FOCUS, but after applying it, they turned into predictions
    == 0\. The same for the predictions == 0 before FOCUS were on the left-hand side
    and turned into predictions == 1.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Hyperparameter optimisation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mainly, there are four hyperparameters of FOCUS, specifically, sigma (Equation
    1), temperature (Equation 4), distance weight, which is a trade‐off parameter
    between distance loss and prediction loss, and the learning rate of Adam [4].
  prefs: []
  type: TYPE_NORMAL
- en: '*Note 1: In this example, we will use the decision tree model, thus we won’t
    use the* `*temperature*` *hyperparameter.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Note 2: You can consider the optimisation algorithm (here we are using* `*Adam*`
    *) as a hyperparameter, but we won’t optimise that in this section and the same
    for other hyperparameters of* `*Adam*` *except for the learning rate for simplicity.*'
  prefs: []
  type: TYPE_NORMAL
- en: This section uses Optuna to optimise the hyperparameters of FOCUS. Optuna is
    a strong hyperparameter optimisation tool, which performs Bayesian optimisation.
    Besides Optuna, we can again use the same functions that we have created above;
    `generate_example_data`, `standardize_features` and `train_decision_tree_model`.
  prefs: []
  type: TYPE_NORMAL
- en: Below is the objective function. It defines which hyperparameter to be tuned
    and what to optimise. In this example, we are tuning 3 hyperparameters in `Focus`
    class, namely sigma, distance weight and the learning rate of Adam optimiser.
    The search spaces of those hyperparameters are defined as `trial.suggest_float`
    or `trial.suggest_int.` The loss function is defined as `cfe_distance /100 + pow(unchanged_ever,
    2).` The reason for this is, as written in the docstring of the function, we want
    to prioritise finding counterfactual explanations over minimising the mean distance.
    Therefore, we take the number of unchanged instances of squares.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: it is important to set the argument of* `*Focus*` *class* `*hyperparameter_tuning*`
    *to* `*True.*` *Otherwise, it won’t return the number of unchanged instances and
    mean counterfactual explanation distances.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Once we defined the objective function, we can start tuning those hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: More comprehensive examples can be found in [the package repository](https://github.com/kyosek/CFXplorer/tree/master/examples).
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several limitations of the Focus class. Here is a list of them:'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, the Focus class can only be applied to scikit-learn `DecisionTreeClassifier`,
    `RandomForestClassifier` and `AdaBoostClassifier`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While categorical features may be included in the feature set, it is important
    to note that the interpretation of changes in categorical features, such as transitioning
    from age 40 to 20, may not provide meaningful insights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The input features should be scaled to the range of 0 and 1 before applying
    Focus. Therefore, it is necessary to transform the features prior to using the
    Focus. However, this scaling process may introduce some additional complexity
    when interpreting the features after applying the Focus.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The computational cost increases depending on the given model. When you have
    a large model, it might not be possible to execute the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5\. Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CFXplorer Python package offers comprehensive usage of the FOCUS algorithm
    to generate optimal distances of counterfactual explanations for a given tree-based
    algorithms. Although there are several limitations, this package should be useful
    for those who want to explore counterfactual outcomes in a tree-based model.
  prefs: []
  type: TYPE_NORMAL
- en: This article went through the theoretical background of the FOCUS algorithm,
    code examples to demonstrate how to use CFXplorer, and a few current limitations.
    In the future, I will be adding more counterfactual explanation generation methods
    to this package.
  prefs: []
  type: TYPE_NORMAL
- en: Hope you find this article useful.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A. Lucic, H. Oosterhuis, H. Haned, and M. de Rijke. “FOCUS: Flexible optimizable
    counterfactual explanations for tree ensembles.” In: Proceedings of the AAAI Conference
    on Artificial Intelligence. Vol. 36\. 5\. 2022, pp. 5313– 5322.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'S. Wachter, B. Mittelstadt, and C. Russell. “Counterfactual explanations without
    opening the black box: Automated decisions and the GDPR.” In: Harv. JL & Tech.
    31 (2017), p. 841.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'T. Akiba, S. Sano, T. Yanase, T. Ohta, and M. Koyama. “Optuna: A next-generation
    hyperparameter optimization framework.” In: Proceedings of the 25th ACM SIGKDD
    international conference on knowledge discovery & data mining. 2019, pp. 2623–2631.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D. P. Kingma and J. Ba. “Adam: A method for stochastic optimization.” In: arXiv
    preprint arXiv:1412.6980 (2014).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
