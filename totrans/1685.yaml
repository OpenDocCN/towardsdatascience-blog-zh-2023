- en: Pro GPU System vs Consumer GPU System for Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pro-gpu-system-vs-consumer-gpu-system-for-deep-learning-a62bec69f557](https://towardsdatascience.com/pro-gpu-system-vs-consumer-gpu-system-for-deep-learning-a62bec69f557)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hardware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Why you might consider going pro
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)[![Mike
    Clayton](../Images/2d37746b13b7d2ff1c6515893914da97.png)](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)
    [Mike Clayton](https://medium.com/@maclayton?source=post_page-----a62bec69f557--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a62bec69f557--------------------------------)
    ·21 min read·Apr 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f24ad59210450dc7f7fab7e6456b0d01.png)'
  prefs: []
  type: TYPE_IMG
- en: '*The professional workstation that will be utilised in this article. Image
    via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Having a GPU (or graphics card) in your system is almost essential when it
    comes to training neural networks, especially deep neural networks. The difference
    in training speed of a fairly modest GPU is a night and day difference when compared
    to a CPU.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**….but at what point might you consider jumping into the realms of professional,
    rather than consumer, level GPUs? Is there a huge difference in training and inference
    speed? Or is it other factors that make the jump compelling?**'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim of this article is to give you an idea of the main differences between
    a GPU you might use as a normal consumer (or starting out in machine/deep learning),
    and those used in higher end systems. The type of systems that might be used in
    the development and/or inference of advanced deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from being an interesting exercise in understanding the distinctions between
    cutting edge pro equipment and consumer level hardware in terms of pure processing
    speed, it will also highlight some of the other limitations that are present in
    consumer level GPUs, and associated systems, when dealing with cutting edge deep
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Which GPUs are you referring to when you say “Pro” or “Consumer”?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The “real world” differences will be covered in the rest of the article, but
    if you want a solid technical distinction, with example graphics cards and specifications,
    then this section should cover it.
  prefs: []
  type: TYPE_NORMAL
- en: As detailed in one of my [previous articles](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b),
    NVIDIA are the only sensible option when it comes to GPUs for deep learning and
    neural networks at the current time. This is mainly due to their more thorough
    integration into platforms such as TensorFlow and PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: Making the distinction between professional and consumer, in terms of specifications
    from the manufacturer, is therefore relatively straight forward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anything from the following page is the current batch of NVIDIA’s consumer
    graphics cards:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.nvidia.com/en-gb/geforce/graphics-cards/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA GeForce Graphics Cards'
  prefs: []
  type: TYPE_NORMAL
- en: Explore NVIDIA GeForce graphics cards. RTX 40 series, RTX 30 series, RTX 20
    series and GTX 16 series.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.nvidia.com](https://www.nvidia.com/en-gb/geforce/graphics-cards/?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '…and professional level GPUs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.nvidia.com/en-us/design-visualization/desktop-graphics/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA RTX & Quadro Desktop Workstations'
  prefs: []
  type: TYPE_NORMAL
- en: See how 3D artists, architects, and product designers are using the powerful
    features of NVIDIA RTX ™ and Omniverse ™…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.nvidia.com](https://www.nvidia.com/en-us/design-visualization/desktop-graphics/?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also GPUs, mainly used in data centres, that go beyond even the pro
    level graphics cards listed above. The A100 is a good example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.nvidia.com/en-us/data-center/a100/?source=post_page-----a62bec69f557--------------------------------)
    [## NVIDIA A100 GPUs Power the Modern Data Center'
  prefs: []
  type: TYPE_NORMAL
- en: The NVIDIA EGX ™ platform includes optimized software that delivers accelerated
    computing across the infrastructure…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.nvidia.com](https://www.nvidia.com/en-us/data-center/a100/?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also get an idea of the system specifications and GPUs being used in
    professional data centre and workstation systems certified by NVIDIA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[## NVIDIA-Certified Systems'
  prefs: []
  type: TYPE_NORMAL
- en: The NVIDIA-Certified Systems program has assembled the industry's most complete
    set of accelerated workload performance…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: docs.nvidia.com](https://docs.nvidia.com/ngc/ngc-deploy-on-premises/nvidia-certified-systems/index.html?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The Plan
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I generally find that a real demonstration (or experiment) is the best way to
    illustrate a point, rather than just relying on specs and statistics provided
    by the manufacturers.
  prefs: []
  type: TYPE_NORMAL
- en: With that in mind, although the article will discuss the relevant statistics,
    it will also directly compare three different GPUs (pro and consumer), at differing
    levels of sophistication, on the same deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: This should help to highlight what is important, and what isn’t, when considering
    whether a professional level GPU is for you.
  prefs: []
  type: TYPE_NORMAL
- en: The GPU Specs — A Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/652e61b5741fc1ee64f48d026de6b88b.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ann H](https://www.pexels.com/photo/sand-sign-texture-writing-11022641/)
    on [Pexels](https://www.pexels.com/)
  prefs: []
  type: TYPE_NORMAL
- en: 'For the experiment, there will be three different graphics cards, but four
    levels of comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA RTX 1070 (Basic)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NVIDIA Tesla T4 (Mid range)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NVIDIA RTX 6000 Ada (High end)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2 x NVIDIA RTX 6000 Ada (Double high end!)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So how do these different graphics cards compare in terms of raw specs?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/31ffd6303b1c9dc911b2332516c9b24a.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of different graphics cards — Table by author
  prefs: []
  type: TYPE_NORMAL
- en: '***Note:*** *I have included the RTX 4090 in the table above as it is the pinnacle
    of current consumer level graphics cards, and probably the best direct comparison
    to the RTX 6000 Ada. I will reference the 4090 throughout the article as a comparison
    point, although it will not feature in the benchmarks.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the table above is just a load of number with no meaning, then I recommend
    my previous article which goes over some of the jargon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b?source=post_page-----a62bec69f557--------------------------------)
    [## How to Pick the Best Graphics Card for Machine Learning'
  prefs: []
  type: TYPE_NORMAL
- en: Speed up your training, and iterate faster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The Professional System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/0df47511780765ce613b7afceb97a5cd.png)'
  prefs: []
  type: TYPE_IMG
- en: '*A view from all angles of the professional workstation utilised in this article.
    Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  prefs: []
  type: TYPE_NORMAL
- en: One of the problems with producing an article like this is that you need access
    to a professional level system, and therefore one of the main hurdles is…cost.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, there are companies out there that will give access to their equipment
    for trial runs, to allow you to see if it fits your needs. In this particular
    case [Exxact](https://www.exxactcorp.com/) have been kind enough to allow remote
    access to one of their builds for a limited period so I can get the comparisons
    I need.
  prefs: []
  type: TYPE_NORMAL
- en: …the workstation is worth in the region of USD 25,000
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To drive home my point about how much these systems can cost I estimate the
    workstation I have been given access to is worth in the region of **USD 25,000**.
    If you want to depress (or impress?) yourself further you can take a look at the
    [**configurator**](https://www.exxactcorp.com/VWS-148320247/configurator) and
    see what can realistically be achieved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Incidentally, if you are seriously in the market for this level of hardware
    you can apply for a remote ‘‘test drive’’ too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[## NVIDIA H100 Test Drive | Exxact'
  prefs: []
  type: TYPE_NORMAL
- en: Test Drive Your Application on the Latest NVIDIA TechnologySign up for remote
    access to our fully-equipped GPU servers…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.exxactcorp.com](https://www.exxactcorp.com/Services/Test-Drive?utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Test+Drive&source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the complete specs of the “professional” system for those that are
    interested:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0ad06958c07074b8fa0fb9888eab08b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Specification of the professional system — Table by author
  prefs: []
  type: TYPE_NORMAL
- en: '***Note:*** *Feel free to refer to any of the images in this article that included
    the two gold looking GPUs in a black computer case, as those are actual pictures
    of the system detailed above.*'
  prefs: []
  type: TYPE_NORMAL
- en: It is interesting to note that having a high end system is not just about stuffing
    the best graphics card you can get your hands on into your current system. Other
    components need to scale up too. System RAM, motherboard, CPU, cooling, and of
    course power.
  prefs: []
  type: TYPE_NORMAL
- en: The Contenders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/afed16c91fe7b379c2ddad574b3321ed.png)'
  prefs: []
  type: TYPE_IMG
- en: The NVIDIA GeForce GTX 1070 FTW that will be used as the base in this article
    — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA GeForce GTX 1070
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the bottom of the pack is the GTX 1070, which is readily available to most
    people, but is still ***significantly*** faster than a CPU. It also has a decent
    amount of GPU RAM at 8GB. A good simple consumer level base.
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA Tesla T4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Tesla T4 is maybe a strange addition, but there are a few reasons for this.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to note is that the Tesla T4 is actually a professional graphics
    card, it is just a few generations old.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of processing speed it is roughly the equivalent of an RTX 2070, but
    it has double the GPU RAM at 16GB. This additional RAM puts it firmly in the mid
    range of this test. Current generation consumer cards tend to have RAM in this
    range (RTX 4070 [12GB] and RTX 4080 [16GB]), so it represents consumer graphics
    cards in terms of GPU RAM quite nicely.
  prefs: []
  type: TYPE_NORMAL
- en: The final reason is that you can easily access one of these graphics cards for
    free in [Colab](https://colab.research.google.com/). That means anybody reading
    this article can get their hands dirty and run the code to see for themselves!
  prefs: []
  type: TYPE_NORMAL
- en: The Pro GPU — NVIDIA RTX 6000 Ada
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/17dfd95d7bee19fde31b3b39dd1f0fb1.png)'
  prefs: []
  type: TYPE_IMG
- en: '*A view of the two NVIDIA RTX 6000 Ada graphics cards installed in the professional
    workstation utilised in this article. Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  prefs: []
  type: TYPE_NORMAL
- en: There is no doubt about it, the RTX 6000 Ada is an impressive graphics card
    both in terms of specs…and price. With an **MSRP of USD 6,800** it is definitely
    not a cheap graphics card. So why would you buy one (or more!?) if you can get
    an RTX 4090 for a mere USD 1599 (MSRP)?
  prefs: []
  type: TYPE_NORMAL
- en: The RTX 4090 has half the RAM and uses 50% more power than the RTX 6000 Ada
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I slipped an RTX 4090 into the table to attempt to answer this question. It
    helps to demonstrate what tend to be the two most obvious differences between
    a consumer graphics card and a professional graphics card (at least from the specifications
    alone):'
  prefs: []
  type: TYPE_NORMAL
- en: the amount of GPU RAM available
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: the maximum power draw in use
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The RTX 4090 has **half the RAM** and **uses 50% more power** than the RTX 6000
    Ada. This is no accident, as will become evident as the article progresses.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, considering the higher power draw of the RTX 4090, it is also worth
    noting that the RTX 6000 Ada is still roughly **10% faster.**
  prefs: []
  type: TYPE_NORMAL
- en: Does this additional RAM and reduced power consumption really make a difference?
    Hopefully, the comparison will help to answer that later in the article.
  prefs: []
  type: TYPE_NORMAL
- en: Any other less obvious advantages?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, yes. There are a few additional benefits to getting a professional level
    graphics card.
  prefs: []
  type: TYPE_NORMAL
- en: '***Reliability***'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db2c37140746242f9b9fda939760a2d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [WikiImages](https://pixabay.com/users/wikiimages-1897/?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=62827)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=62827)
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA RTX professional graphics cards are certified with a broad range of professional
    applications, tested by leading independent software vendors (ISVs) and workstation
    manufacturers, and backed by a global team of support specialists.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: -[nvidia.com](https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/rtx-6000/proviz-print-rtx6000-datasheet-web-2504660.pdf)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In essence this means the graphics cards are likely to be more reliable and
    crash resistant, both on a software (drivers), and hardware level, and if you
    do have a problem, there is an extensive professional network available to solve
    the problem. These factors are obviously very important for enterprise applications
    where time is money.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine running a complicated deep learning model for a few days and then losing
    the results due to a crash or bug. Then spending a significant amount more time
    potentially dealing with the problem. Not good!
  prefs: []
  type: TYPE_NORMAL
- en: Is this peace of mind an additional reason to pay up? That really depends on
    your priorities, and scale...
  prefs: []
  type: TYPE_NORMAL
- en: '***Scale***'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d1bde7e0264bca185dd044513861d617.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Daniele Levis Pelusi](https://unsplash.com/@yogidan2012?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/4mpsEm3EGak?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: If you are designing a computer system to have optimal GPU processing power,
    then it may well be that you need more than one GPU. There will obviously be a
    limit on how many GPUs can fit in the system based primarily on the availability
    of motherboard slots, and physical space constraints in the case.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are other limiting factors directly related to the GPU itself,
    and this is where consumer GPUs and professional GPUs start to deviate in terms
    of design.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the fact that a professional motherboard may have availability for
    four dual slot GPUs (like the pro system in this article). So in theory you could
    fit 4 x RTX 6000 Ada GPUs into the system no problem at all. However, you would
    only be able to fit 2 x RTX 4090 on the same board. Why? Because the 4090 is a
    triple slot graphics card (~61mm thick), whereas the 6000 is a dual slot graphics
    card (~40mm thick).
  prefs: []
  type: TYPE_NORMAL
- en: Consumer level GPUs are just not designed with the same constraints in mind
    (i.e. high density builds), and therefore start to be less useful as you scale
    up.
  prefs: []
  type: TYPE_NORMAL
- en: '***Cooling***'
  prefs: []
  type: TYPE_NORMAL
- en: Following on from the potential sizing problem…even if the consumer graphics
    card was the same dual slot design, there are further issues.
  prefs: []
  type: TYPE_NORMAL
- en: Pro level GPUs tend to be built with cooling systems (blower type) that are
    designed to draw air through the graphics cards from front to back with a sealed
    shroud to direct the air **straight out of the case** (i.e. no hot air recirculating
    through the case). This allows for pro GPUs to be stacked tightly into the case,
    and still be able to efficiently cool themselves. All with minimal impact on other
    components, or GPUs, in the rest of the case.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b7183e130e50d9105f71d7289223a3f.png)'
  prefs: []
  type: TYPE_IMG
- en: Two graphics cards one utilising a ‘blower’ cooling system and the other a more
    common fan cooling system. Photo by [Nana Dua](https://www.pexels.com/photo/black-and-silver-car-wheel-4581613/)
    on [Pexels](https://www.pexels.com/). Annotations by author.
  prefs: []
  type: TYPE_NORMAL
- en: Consumer GPUs, on the whole, tend to use fan cooling from above/below. This
    inevitably means hot air from the GPU will recirculate in the case to some degree,
    necessitating excellent case ventilation.
  prefs: []
  type: TYPE_NORMAL
- en: However, in cases with multiple GPUs, the close proximity of the other graphics
    cards would make fan cooling very ineffective, and will inevitably lead to sub-optimal
    temperatures for both the GPUs, and other components in close proximity.
  prefs: []
  type: TYPE_NORMAL
- en: All-in-all professional graphics cards are designed to be tightly and efficiently
    packed into systems, whilst also staying cool and self contained.
  prefs: []
  type: TYPE_NORMAL
- en: '***Accuracy***'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68d46195a35471852d50fa101bcc2036.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ricardo Arce](https://unsplash.com/@jrarce?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/cY_TCKr5bek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: This really isn’t particularly relevant to deep learning specifically, but pro
    GPUs tend to have ECC (Error-Correcting Code) RAM. This would be useful where
    high precision (i.e. a low level of potential random errors from bit flips) is
    a must for whatever processes you are running through the graphics card.
  prefs: []
  type: TYPE_NORMAL
- en: However, deep learning models are sometimes tuned to be **less** numerically
    precise (half-precision 8-bit calculations), so this is not something that is
    likely to be of real concern for the calculations being run.
  prefs: []
  type: TYPE_NORMAL
- en: Although if those random bit flips happen to crash your model, then it may just
    be worth consideration too.
  prefs: []
  type: TYPE_NORMAL
- en: The Deep Learning Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/9cb88fa46938284cad845cb26ae8024c.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Pixabay](https://www.pexels.com/photo/adult-blur-books-close-up-261909/)
  prefs: []
  type: TYPE_NORMAL
- en: For the deep learning model I wanted something that is advanced, industry leading,
    and demanding for the GPUs. It also has to be scalable in terms of difficulty
    as the GPUs on test have a wide range of capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: A pro level model, for a pro level graphics card
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the model to be industry standard rules out building a model from scratch,
    so for this comparison an existing, tried and tested, model will be used by utilising
    transfer learning.
  prefs: []
  type: TYPE_NORMAL
- en: Heavy data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To ensure the input data is heavy, the analysis will be image based, specifically
    image classification.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final criteria is scalability, and there is a particular set of models out
    there that fits this criteria perfectly…
  prefs: []
  type: TYPE_NORMAL
- en: EfficientNet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[EfficientNet](https://keras.io/api/applications/efficientnet/) consists of
    a family of image classification models (B0 to B7). Each model gets progressively
    more complicated (and accurate). It also has a different expected input shape
    for the images that you feed in as you progress through the family of models,
    which increases data input size.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c161d9c0ab0fcf926c4bbb9aa17306c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Comparison of the different EfficientNet models — Data from [EfficientNet:
    Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/pdf/1905.11946.pdf)
    — Table by author'
  prefs: []
  type: TYPE_NORMAL
- en: 'This has a two fold effect:'
  prefs: []
  type: TYPE_NORMAL
- en: as you progress through the different EfficientNet models, the model parameters
    will increase (i.e. a more complicated and demanding model for the GPUs to process)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: the volume of raw data that needs to be processed will also increase (ranging
    from 224x224 pixels up to 600x600 pixels)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ultimately, this gives a large range of possibilities in terms of loading the
    GPUs both in terms of processing speed and GPU RAM requirements.
  prefs: []
  type: TYPE_NORMAL
- en: The Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The [data](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)¹ utilised
    in this article is a set of images which depict the three possible combinations
    of hand position used in the game rock-paper-scissors.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/36774ae755eb3b167772996581fd5ac3.png)'
  prefs: []
  type: TYPE_IMG
- en: Four examples from the three different categories of the [dataset](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors).
    Composite image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Each image is of type PNG, and of dimensions 300(W) pixels x 200(H) pixels,
    in full colour.
  prefs: []
  type: TYPE_NORMAL
- en: The original dataset contains 2188 images in total, but for this article a smaller
    selection has been used, which comprises of precisely 2136 images (712 images
    for each category). This slight reduction in total images from the original has
    been done simply to balance the classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The balanced dataset that was used in this article is available here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/thetestspecimen/notebooks/tree/main/datasets/rock_paper_scissors?source=post_page-----a62bec69f557--------------------------------)
    [## notebooks/datasets/rock_paper_scissors at main · thetestspecimen/notebooks'
  prefs: []
  type: TYPE_NORMAL
- en: These datasets are a selection of the original "rock paper scissors" dataset
    as detailed in the references section…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/thetestspecimen/notebooks/tree/main/datasets/rock_paper_scissors?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/ce6041dc727b1d38f2fd19a3f8f4261a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kelly Sikkema](https://unsplash.com/@kellysikkema?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/4JxV3Gs42Ks?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned previously, there are various levels of EfficientNet available,
    so for the purposes of testing, the following will be run on each GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '**EfficientNet B0** (simple)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**EfficientNet B3** (intermediate)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**EfficientNet B7** (intensive)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This will test the graphics cards speed capabilities due to the difference in
    overall parameters of each model, but also a wide range of RAM requirements as
    the input image sizes will vary too.
  prefs: []
  type: TYPE_NORMAL
- en: The EfficientNet models will have all of their layers unlocked and allowed to
    learn.
  prefs: []
  type: TYPE_NORMAL
- en: 'The three final models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Speed Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The speed of the GPUs will be judged by how quickly they can complete an epoch.
  prefs: []
  type: TYPE_NORMAL
- en: To be more specific, there will be a minimum of two epochs run on each graphics
    card, and the second epoch will be used to judge the processing speed. The first
    epoch generally has some additional loading time, so would not be a good reference
    for general execution time.
  prefs: []
  type: TYPE_NORMAL
- en: The time to run the first epoch will be listed only for reference.
  prefs: []
  type: TYPE_NORMAL
- en: GPU RAM Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To test the limits of the GPU RAM, the batch size for each graphics card, and
    each EfficientNet model (i.e. B0, B3 or B7), has been tuned to be as close as
    possible to the limit for that particular graphics card (i.e. to fill the GPU
    RAM as much as possible).
  prefs: []
  type: TYPE_NORMAL
- en: The actual peak GPU RAM utilisation for the run will also be disclosed for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/58a7cdf931b08f72018c64ec24fa5128.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Oskar Yildiz](https://unsplash.com/@oskaryil?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/cOkpTiJMGzA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: 'As ever, I have made all the python scripts (GTX 1070 and RTX 6000 Ada) and
    notebooks (Tesla T4) available on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/thetestspecimen/notebooks/tree/main/pro-vs-consumer-graphics-card?source=post_page-----a62bec69f557--------------------------------)
    [## notebooks/pro-vs-consumer-graphics-card at main · thetestspecimen/notebooks'
  prefs: []
  type: TYPE_NORMAL
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab or…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/thetestspecimen/notebooks/tree/main/pro-vs-consumer-graphics-card?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also access the notebooks for the Tesla T4 directly on Colab if you
    so wish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'EfficientNetB0:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B0.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: 'EfficientNetB3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B3.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: 'EfficientNetB7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/ab36cfbae94a8d3e5dd11db50b483d32.png)](https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/pro-vs-consumer-graphics-card/rps_t4_tf_B7.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: The Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/07b2b58f8ce44db7d0d0703e05a3e93f.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Pixabay](https://www.pexels.com/photo/business-commerce-computer-delivery-263194/)
  prefs: []
  type: TYPE_NORMAL
- en: EfficientNet B0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/777a63908da503045aeb462939760cba.png)'
  prefs: []
  type: TYPE_IMG
- en: EfficientNet B3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/06c1457350384a0f6731185373fefbff.png)'
  prefs: []
  type: TYPE_IMG
- en: EfficientNet B7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/7a6c34f8712e1ac26d7e22315665111d.png)'
  prefs: []
  type: TYPE_IMG
- en: '***Note:*** *for the first epoch I have listed a number of seconds in brackets.
    This is the time difference between the first and second epoch.*'
  prefs: []
  type: TYPE_NORMAL
- en: Discussion — Execution Speed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/ef885c6083787cb3235968f4817c2f8f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Arek Socha](https://pixabay.com/users/qimono-1962238/?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=1249610)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&amp%3Butm_medium=referral&amp%3Butm_campaign=image&amp%3Butm_content=1249610)
  prefs: []
  type: TYPE_NORMAL
- en: The first item to look at is execution speed.
  prefs: []
  type: TYPE_NORMAL
- en: EfficientNet B0 doesn’t cause much of a challenge for any of the graphics cards
    with this particular dataset, with all completing an epoch in a matter of seconds.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is important to remember that the dataset utilised in this article
    is small, and in reality the two RTX 6000 Ada graphics cards are approximately
    **17 times faster** that the GTX 1070 (and Tesla T4) in terms of execution speed.
    The story is pretty much the same for EfficientNet B3 (8x faster) and B7 (11x
    faster).
  prefs: []
  type: TYPE_NORMAL
- en: The difference is that this slow down in speed, when viewed as execution time,
    starts to become more of a hindrance the more complicated the model gets.
  prefs: []
  type: TYPE_NORMAL
- en: For example, to execute a single epoch, on this very small dataset, using EfficientNet
    B7 with a GTX 1070 takes approximately 15 mins. Compare that to just over 1 minute
    with a pair of RTX 6000 Ada.
  prefs: []
  type: TYPE_NORMAL
- en: …and it gets worse.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s be realistic. No model is going to converge in one epoch. Four hundred
    might be a more reasonable number for a model like EfficientNet.
  prefs: []
  type: TYPE_NORMAL
- en: That would be the difference between **4 days** on a GPU like the GTX 1070,
    and only a few hours (6.5 to be precise) on a dual RTX 6000 Ada setup. Then consider
    that a real dataset doesn’t have only 2188 images, it could have millions (for
    reference [ImageNet](https://www.image-net.org/) has just over **14 million images**).
  prefs: []
  type: TYPE_NORMAL
- en: Industry progress
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another thing to bear in mind is progress in industry. EfficientNet is a few
    years old now, and things have moved on.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a small example take [NoisyStudent](https://arxiv.org/pdf/1911.04252v4.pdf),
    which builds on the standard EfficientNets with a variation called EfficientNet-L2
    and states:'
  prefs: []
  type: TYPE_NORMAL
- en: Due to the large model size, the training time of EfficientNet-L2 is approximately
    five times the training time of EfficientNet-B7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: -[Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/pdf/1911.04252v4.pdf)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …so speed really does matter if you need to stay at the cutting edge.
  prefs: []
  type: TYPE_NORMAL
- en: What does that mean for pro vs consumer graphics cards then?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The truth is that if you **only** look at speed of execution there is very little
    difference between professional and consumer GPUs if you compare like for like.
    An RTX 4090 is near as makes no difference the same speed as an RTX 6000 Ada.
  prefs: []
  type: TYPE_NORMAL
- en: An RTX 4090 is near as makes no difference the same speed as an RTX 6000 Ada.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: All this little experiment has illustrated so far is that speed is very important,
    as industry standard models are progressing in complexity quite quickly. Older
    generation graphics cards are noticeably slower already. To keep up requires **at
    least** staying on the cutting edge of hardware.
  prefs: []
  type: TYPE_NORMAL
- en: …scale matters a great deal when answering this question.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …but with the speed of progression (just look at the rapid accent of GTP-3 and
    GTP-4) it also appears that if you want to stay at the cutting edge, one GPU,
    even at the level of the RTX 4090 or RTX 6000 Ada, is unlikely to be enough. If
    that is the case, then the superior cooling, less power draw and more compact
    size of the professional level graphics cards are a significant advantage when
    building a system.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, scale matters a great deal when answering this question.
  prefs: []
  type: TYPE_NORMAL
- en: However, speed is only one facet. Now let’s move on to the GPU RAM, where things
    get a little more interesting…
  prefs: []
  type: TYPE_NORMAL
- en: Discussion — GPU RAM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPU RAM is a significant consideration in some situations, and can be a literal
    limiting factor as to whether certain models, or datasets, can be utilised at
    all.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see the pair of RTX 6000 Ada in full flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d888542c0d46ff23fd76e6d112f96c4c.png)'
  prefs: []
  type: TYPE_IMG
- en: The two RTX 6000 Ada GPUs running a deep learning model. Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'You may notice in the image above that the GPU RAM is at 100% for both GPUs.
    However, the this is not the real usage:'
  prefs: []
  type: TYPE_NORMAL
- en: By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject
    to `[*CUDA_VISIBLE_DEVICES*](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)`)
    visible to the process. This is done to more efficiently use the relatively precious
    GPU memory resources on the devices by reducing memory fragmentation.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[-tensorflow.org](https://www.tensorflow.org/guide/gpu)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The limits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The absolute limit is brought home quite starkly by the fact that the GTX 1070
    (which has 8GB of GPU RAM) is only capable of running EfficientNet B7 with a batch
    size of 1 (i.e. it can process 1 image at a time before having to update the model
    parameters and load the next image into the GPU RAM).
  prefs: []
  type: TYPE_NORMAL
- en: 'This causes two problems:'
  prefs: []
  type: TYPE_NORMAL
- en: You lose speed of execution due to frequent parameter updates in addition to
    loading in fresh data to the GPU RAM more regularly (i.e. larger batch sizes are
    inherently quicker.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the input image size gets any larger, the model will not be able to run at
    all, as it won’t fit one single image into the GPU RAM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Even the Tesla T4 which has a not too shabby 16GB of GPU memory only manages
    a batch size of 2 on EfficientNet B7.
  prefs: []
  type: TYPE_NORMAL
- en: As detailed earlier, 16GB of GPU RAM is a good representation of the majority
    of current generation consumer GPUs, with only the RTX 4090 having more at 24GB.
    So this is a fairly significant downfall for consumer GPUs if you are dealing
    with memory heavy raw data.
  prefs: []
  type: TYPE_NORMAL
- en: At this point it suddenly becomes clear why all the professional GPUs are so
    RAM heavy when compared to their consumer equivalents. As mentioned in the discussion
    for the speed of execution, EfficientNet is no longer at the bleeding edge, so
    the reality today is probably even more demanding than outlined in the tests for
    this article.
  prefs: []
  type: TYPE_NORMAL
- en: System density
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another consideration in regard to GPU RAM is system density.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the system I have been given access to has a motherboard that
    can take 4 double height GPUs (I have also seen systems with up to 8 GPUs). This
    means that if GPU RAM is a priority in your system, then professional GPUs are
    a no brainer:'
  prefs: []
  type: TYPE_NORMAL
- en: 4 x RTX 6000 Ada = 192GB GPU RAM and 1200W of power draw
  prefs: []
  type: TYPE_NORMAL
- en: 4 x RTX 4090 = 96GB GPU RAM and 1800W of power draw
  prefs: []
  type: TYPE_NORMAL
- en: (…and as I have already mentioned earlier in the article the RTX 4090 is a triple
    slot GPU so this isn’t even realistic. In reality only two RTX 4090 graphics cards
    would actually fit, but for the sake of easy comparison let’s assume it would
    work.)
  prefs: []
  type: TYPE_NORMAL
- en: That is no small difference. To match the RTX 6000 Ada system in terms of GPU
    RAM you would need two separate systems drawing at least **three times the power**.
  prefs: []
  type: TYPE_NORMAL
- en: To match the RTX 6000 Ada system in terms of RAM you would need two separate
    systems drawing at least three times the power.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Don’t forget that as you would need two separate systems, you would have to
    fork out for additional CPUs, power supplies, motherboards, cooling, cases etc.
  prefs: []
  type: TYPE_NORMAL
- en: A side note on system RAM…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/ffbcf362988e23943cc958ed6a9f0a7b.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Did you notice 8 sticks of 64GB system RAM above and below the CPU in the
    professional system? Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth pointing out, that it is not just the GPU RAM that matters.
    As the GPU RAM scales up you need to increase the system RAM in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may note in the Jupyter notebooks for the Tesla T4 that I have commented
    out the following optimisations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This is because, for EfficientNet B7, the training will crash if they are enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Why?
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the “.cache()” optimisation keeps the data in system memory to feed
    it efficiently to the GPU, and the Colab instance only has 12GB of system memory.
    Which is not enough, even though the GPU RAM peaks at 9.9GB:'
  prefs: []
  type: TYPE_NORMAL
- en: This [.cache()] will save some operations (like file opening and data reading)
    from being executed during each epoch.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: -[tensorflow.org](https://www.tensorflow.org/guide/data_performance)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, the professional system has 8 sticks of 64GB system RAM, for a total
    of 512GB of system RAM. So even though the two RTX 6000 Ada GPUs combined have
    96GB of GPU RAM, there is still plenty of overhead in the system RAM to deal with
    heavy caching.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/921383d94b40284165c0c98bef51c2b2.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image via* [*Exxact Corporation*](https://www.exxactcorp.com/category/Deep-Learning-Solutions?page=1&utm_source=web+referral&utm_medium=backlink&utm_campaign=Michael+Clayton&utm_term=Medium+Towards+Data+Science)
    *under license to Michael Clayton*'
  prefs: []
  type: TYPE_NORMAL
- en: So, are professional level graphics cards better than consumer cards for deep
    learning?
  prefs: []
  type: TYPE_NORMAL
- en: Money no object. Yes, they are.
  prefs: []
  type: TYPE_NORMAL
- en: Does that mean that you should discard considering consumer level graphics cards
    for deep learning?
  prefs: []
  type: TYPE_NORMAL
- en: No, it doesn’t.
  prefs: []
  type: TYPE_NORMAL
- en: It all comes down to specific requirements, and more often than not scale.
  prefs: []
  type: TYPE_NORMAL
- en: Large datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you know that your workload is going to be RAM intensive (large language
    models, image, or video based analysis for example) then professional graphics
    cards of the same generation and processing speed tend to have roughly double
    the GPU RAM.
  prefs: []
  type: TYPE_NORMAL
- en: It all comes down to specific requirements, and scale.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is a significant advantage, especially considering there is no elevation
    in energy requirements to achieve this compared to a consumer graphics card.
  prefs: []
  type: TYPE_NORMAL
- en: Smaller datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you don’t have high RAM requirements, then the question is more nuanced and
    relies on whether reliability, compatibility, support, energy consumption, and
    that additional 10% in terms of speed are worth the quite significant hike in
    price.
  prefs: []
  type: TYPE_NORMAL
- en: Scale
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are about to invest in significant infrastructure, then reliability,
    energy consumption and system density may move from low priority to quite significant
    considerations. Areas that professional GPUs excel at.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, if you need a smaller system, and high GPU RAM requirements aren’t
    important, then considering consumer level graphics cards may turn out to be beneficial.
    Factors associated with large scale, such as reliability and energy consumption
    will become less of an issue, and system density won’t matter at all.
  prefs: []
  type: TYPE_NORMAL
- en: The final word
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All in all it is a balancing act, but if I had to pick two items to summarise
    the most important factors in choosing between a consumer GPU and professional
    GPU it would be:'
  prefs: []
  type: TYPE_NORMAL
- en: GPU RAM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: System scale
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you have **either** high GPU RAM requirements, or will need larger systems
    with multiple GPUs, then you need a professional level GPU/GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Otherwise, most likely, consumer level will be a better deal.
  prefs: []
  type: TYPE_NORMAL
- en: If you found this article interesting or useful, remember to follow me, or [sign
    up for my newsletter](https://medium.com/@maclayton/subscribe) for more content
    like this.
  prefs: []
  type: TYPE_NORMAL
- en: If you haven’t already, you could also consider [subscribing to Medium](https://medium.com/@maclayton/membership).
    Your membership fee directly supports, not just me, but other writers you read
    too. You’ll also get full unrestricted access to every story on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: Using my referral link to sign up will grant me a small kickback with zero effect
    on your membership, so thank you if you choose to do so.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@maclayton/membership?source=post_page-----a62bec69f557--------------------------------)
    [## Join Medium with my referral link - Mike Clayton'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Mike Clayton (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@maclayton/membership?source=post_page-----a62bec69f557--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Julien de la Bruère-Terreault, [Rock-Paper-Scissors Images](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)
    (2018), Kaggle, License: [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)'
  prefs: []
  type: TYPE_NORMAL
