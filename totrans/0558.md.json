["```py\nimport torch\nfrom generative.networks.nets import ControlNet, DiffusionModelUNet\n\n# Load pre-trained diffusion model\ndiffusion_model = DiffusionModelUNet(\n    spatial_dims=2,\n    in_channels=3,\n    out_channels=3,\n    num_res_blocks=2,\n    num_channels=[256, 512, 768],\n    attention_levels=[False, True, True],\n    with_conditioning=True,\n    cross_attention_dim=1024,\n    num_head_channels=[0, 512, 768],\n)\ndiffusion_model.load_state_dict(torch.load(\"diffusion_model.pt\"))\n\n# Create ControlNet\ncontrolnet = ControlNet(\n    spatial_dims=2,\n    in_channels=3,\n    num_res_blocks=2,\n    num_channels=[256, 512, 768],\n    attention_levels=[False, True, True],\n    with_conditioning=True,\n    cross_attention_dim=1024,\n    num_head_channels=[0, 512, 768],\n    conditioning_embedding_in_channels=1,\n    conditioning_embedding_num_channels=[64, 128, 128, 256],\n)\n\n# Create trainable copy of the diffusion model\ncontrolnet.load_state_dict(diffusion_model.state_dict(), strict=False)\n\n# Lock the weighht of the diffusion model\nfor p in diffusion_model.parameters():\n    p.requires_grad = False\n```", "```py\n # Training Loop\n...\n\nimages = batch[\"t1w\"].to(device)\ncond = batch[\"flair\"].to(device)\n\n...\n\nnoise = torch.randn_like(latent_representation).to(device)\nnoisy_z = scheduler.add_noise(\n    original_samples=latent_representation, noise=noise, timesteps=timesteps\n)\n\n# Compute trainable part\ndown_block_res_samples, mid_block_res_sample = controlnet(\n    x=noisy_z, timesteps=timesteps, context=prompt_embeds, controlnet_cond=cond\n)\n\n# Using controlnet outputs to control diffusion model behaviour\nnoise_pred = diffusion_model(\n    x=noisy_z,\n    timesteps=timesteps,\n    context=prompt_embeds,\n    down_block_additional_residuals=down_block_res_samples,\n    mid_block_additional_residual=mid_block_res_sample,\n)\n\n# Then compute diffusion model loss as usual\n...\n```"]