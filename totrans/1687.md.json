["```py\ndef train(x, y, scales, optimiser, epochs):\n    estimated_scales = []\n    n_classes = np.unique(y).shape[0]\n    n_features = x.shape[1]\n    counts = np.zeros(n_classes)\n    mean_cond_class = []\n    std_feature_given_class = []\n    for c_k in range(n_classes):\n        mean_cond_class.append(np.mean(x[np.squeeze(y==c_k)], axis=0))\n    mean_cond_class = np.asarray(mean_cond_class, dtype=np.float32)\n    x_c = np.concatenate((x,y.reshape(-1,1)), axis=1)\n\n    mv_normal_diag = tfd.MultivariateNormalDiag(loc=mean_cond_class,scale_diag=scales)\n\n    x = np.expand_dims(x , 1).astype('float32')\n\n    for i in range(epochs):\n        with tf.GradientTape() as tape:\n            tape.watch(mv_normal_diag.trainable_variables)\n            predictions = - mv_normal_diag.log_prob(x)\n            p1 = tf.reduce_sum(predictions[np.squeeze(y==0)][:,0])\n            p2 = tf.reduce_sum(predictions[np.squeeze(y==1)][:,1])\n            loss = p1 + p2\n            grads = tape.gradient(loss, mv_normal_diag.trainable_variables)\n\n        opt.apply_gradients(zip(grads, mv_normal_diag.trainable_variables))\n        estimated_scales.append(mv_normal_diag.trainable_variables[0].numpy())\n        print('Step {:03d}: Loss: {:.3f}: Scale1: {:.3f}: Scale2: {:.3f}'.format(i, loss, mv_normal_diag.trainable_variables[0].numpy()[0], mv_normal_diag.trainable_variables[0].numpy()[1]))\n    estimated_scales = np.asarray(estimated_scales)\n    return estimated_scales, mv_normal_diag\n```", "```py\nscales = tf.Variable([1., 1.], name='scales')\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)\nepochs = 100\n```", "```py\nscales_arr, class_conditionals_binary = train(x_train, y_train, scales, opt, epochs)\n\n-----\nStep 000: Loss: 290.708: Scale1: 0.990: Scale2: 0.990\nStep 001: Loss: 288.457: Scale1: 0.980: Scale2: 0.980\nStep 002: Loss: 286.196: Scale1: 0.970: Scale2: 0.970\nStep 003: Loss: 283.924: Scale1: 0.960: Scale2: 0.960\nStep 004: Loss: 281.641: Scale1: 0.950: Scale2: 0.950\nStep 005: Loss: 279.348: Scale1: 0.940: Scale2: 0.940\n[...]\n```", "```py\npredictions = predict(prior_binary, class_conditionals_binary, x_test)\n\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Test accuracy: {:.4f}\".format(accuracy))\n\n---------\nTest accuracy: 0.92\n```", "```py\nplt.figure(figsize=(9, 5))\nplot_data(x_train, y_train)\nx0_min, x_0_max = x_train[:, 0].min()-0.5, x_train[:, 0].max()+0.5\nx1_min, x_1_max = x_train[:, 1].min()-0.5, x_train[:, 1].max()+0.5\ncontour_plot((x0_min, x0_max), (x1_min, x1_max), \n             lambda x: predict(prior_binary, class_conditionals_binary, x), \n             1, label_colors, levels=[-0.5, 0.5, 1.5],\n             num_points=200)\nplt.title(\"Training set with decision regions\")\nplt.show()\n```", "```py\ndef get_logistic_regression_params(prior, class_conditionals):\n    cov = class_conditionals.covariance()[0]\n    cov_inv = tf.linalg.inv(cov)\n    mu0 = class_conditionals.parameters['loc'][0]\n    mu1 = class_conditionals.parameters['loc'][1]\n    w = np.matmul(cov_inv,(mu0-mu1))\n    w0 = - 0.5 * (np.matmul(tf.transpose(mu0), np.matmul(cov_inv, mu0)))\\\n         + 0.5 * (np.matmul(tf.transpose(mu1), np.matmul(cov_inv, mu1)))\\\n         + np.log(prior.parameters['probs'][0] / prior.parameters['probs'][1])\n    return w, w0\n\nw, w0 = get_logistic_regression_params(prior_binary, class_conditionals_binary)\n```", "```py\nfig, ax = plt.subplots(1, 1, figsize=(9, 5))\nplot_data(x_train, y_train, alpha=0.35)\nx0_min, x0_max = x_train[:, 0].min()-0.5, x_train[:, 0].max()+0.5\nx1_min, x1_max = x_train[:, 1].min()-0.5, x_train[:, 1].max()+0.5\nX0, X1 = get_meshgrid((x0_min, x0_max), (x1_min, x1_max))\n\nlogits = np.dot(np.array([X0.ravel(), X1.ravel()]).T, w) + w0\nZ = tf.math.sigmoid(logits)\nlr_contour = ax.contour(X0, X1, np.array(Z).T.reshape(*X0.shape), levels=10)\nax.clabel(lr_contour, inline=True, fontsize=10)\ncontour_plot((x0_min, x0_max), (x1_min, x1_max), \n             lambda x: predict(prior_binary, class_conditionals_binary, x), \n             1, label_colors, levels=[-0.5, 0.5, 1.5],\n             num_points=200)\nplt.title(\"Training set with prediction contours\")\nplt.show()\n```"]