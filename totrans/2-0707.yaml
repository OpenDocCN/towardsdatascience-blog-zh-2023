- en: Demystify Data Backfilling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解密数据回填
- en: 原文：[https://towardsdatascience.com/demystify-data-backfilling-cf1713d7f7a3](https://towardsdatascience.com/demystify-data-backfilling-cf1713d7f7a3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/demystify-data-backfilling-cf1713d7f7a3](https://towardsdatascience.com/demystify-data-backfilling-cf1713d7f7a3)
- en: Let’s talk about data engineers’ nightmare
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们谈谈数据工程师的噩梦
- en: '[](https://medium.com/@xiaoxugao?source=post_page-----cf1713d7f7a3--------------------------------)[![Xiaoxu
    Gao](../Images/8712a7e5f3bad0d2abd7e04792fad66f.png)](https://medium.com/@xiaoxugao?source=post_page-----cf1713d7f7a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cf1713d7f7a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cf1713d7f7a3--------------------------------)
    [Xiaoxu Gao](https://medium.com/@xiaoxugao?source=post_page-----cf1713d7f7a3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@xiaoxugao?source=post_page-----cf1713d7f7a3--------------------------------)[![Xiaoxu
    Gao](../Images/8712a7e5f3bad0d2abd7e04792fad66f.png)](https://medium.com/@xiaoxugao?source=post_page-----cf1713d7f7a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cf1713d7f7a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cf1713d7f7a3--------------------------------)
    [Xiaoxu Gao](https://medium.com/@xiaoxugao?source=post_page-----cf1713d7f7a3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cf1713d7f7a3--------------------------------)
    ·10 min read·Nov 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cf1713d7f7a3--------------------------------)
    ·10分钟阅读·2023年11月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a374b8c9a41614e60b77cc9adf59a72a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a374b8c9a41614e60b77cc9adf59a72a.png)'
- en: Created by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创建
- en: As data engineers, we encounter unique challenges every day. But if there is
    one daunting task that stands out, it must be the backfill. A flawed backfill
    means excessive processing time, data contamination, and substantial cloud bills.
    And yeah, it also means you need one more backfill job to fix it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据工程师，我们每天都会遇到独特的挑战。但如果有一项令人畏惧的任务，那一定是回填。回填不当意味着处理时间过长、数据污染以及高额的云账单。对了，这也意味着你需要另一个回填任务来修复它。
- en: Completing your first successful data backfill is a data engineering rite of
    passage. — Dagster
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 完成第一次成功的数据回填是数据工程师的一项重要经历。— Dagster
- en: Backfill task demands a set of data engineering skills to be effectively accomplished
    such as domain knowledge to validate results, tooling expertise to run backfill
    jobs, and a solid understanding of the database to optimize the process. When
    all of these elements are intertwined within a single task, things can go wrong.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 回填任务需要一系列数据工程技能才能有效完成，例如验证结果的领域知识、运行回填任务的工具专长以及优化流程的数据库扎实理解。当这些元素交织在一个任务中时，可能会出现问题。
- en: In this article, we will explore the concept of data backfilling, its necessity,
    and efficient implementation methods. Whether you are a beginner in backfilling
    or someone who often feels panic about such tasks, this article will calm your
    mind and help you regain your confidence.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将深入探讨数据回填的概念、其必要性以及高效实施的方法。无论你是回填新手还是经常对这类任务感到恐慌的人，这篇文章都会让你平静下来，帮助你重拾信心。
- en: What is backfill?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是回填？
- en: Backfill is the process of filling in missing data from the past on a new table
    that didn’t exist before, or replacing old data with new records. It’s usually
    not a recurring job and it’s necessary only for data pipelines that update the
    table incrementally.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 回填是将过去缺失的数据填充到之前不存在的新表中，或用新记录替换旧数据的过程。它通常不是一个定期任务，仅在数据管道增量更新表时才需要。
- en: '![](../Images/a4a38246ad78cbd9985c2ea75635871d.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4a38246ad78cbd9985c2ea75635871d.png)'
- en: Difference between regular job and backfill job (created by author)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 常规任务与回填任务的区别（作者创建）
- en: For example, a table is partitioned on `date` column. A regular daily job updates
    just the latest 2 partitions. In contrast, a backfill job can update partitions
    all the way back to the initial one in the table. If the regular job updates the
    entire table each time, a backfill job becomes unnecessary as the historical data
    will naturally be updated through the regular job.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个表按`date`列分区。一个常规的每日任务只更新最新的2个分区。相比之下，一个回填任务可以更新表中最初的所有分区。如果常规任务每次都更新整个表，那么回填任务就不必要了，因为历史数据会通过常规任务自然更新。
- en: So, when do we need to backfill?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么，我们什么时候需要回填呢？
- en: In general, there are a few common scenarios. Let’s see if you find them familiar.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，有一些常见的场景。让我们看看你是否觉得这些场景熟悉。
- en: '**Create a new table and want to fill in missing historical data**'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建新表并希望填补缺失的历史数据**'
- en: You’ve just developed a new table for analyzing the monthly e-commerce sales
    performance. The data pipeline selects only the transactions that occurred within
    the given month. When deploying the data pipeline, it generates a report exclusively
    for the current month. To produce historical monthly reports, a backfill job is
    required. The number of partitions updated in a backfill job depends on both the
    business requirements and data availability in the source table.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚开发了一个新的表来分析每月的电子商务销售业绩。数据管道只选择发生在给定月份的交易。在部署数据管道时，它仅为当前月份生成报告。要生成历史月度报告，需要一个回填作业。回填作业中更新的分区数量取决于业务需求和源表中的数据可用性。
- en: '![](../Images/c8fa125360da1ee158c9673b332a15f9.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8fa125360da1ee158c9673b332a15f9.png)'
- en: Develop a new table with a backfill job (created by author)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用回填作业开发新表（由作者创建）
- en: '**Fix a bug in data pipeline and want to update the entire historical data**'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修复数据管道中的错误并希望更新整个历史数据**'
- en: Whoops, you’ve discovered a bug in the join logic. It should have been a left
    join instead of an inner join. You quickly fixed the issue to ensure data quality
    going forward, but what about the data in the past? It’s still using the left
    join. The backfill job here is to correct the historical data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀，你发现了联接逻辑中的错误。它应该是左联接而不是内联接。你迅速修复了这个问题，以确保数据质量，但过去的数据呢？它仍在使用左联接。这里的回填作业是纠正历史数据。
- en: '![](../Images/9cdd238379f1fa003eb1e5f173162622.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cdd238379f1fa003eb1e5f173162622.png)'
- en: Bug fix with a backfill job (created by author)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用回填作业修复错误（由作者创建）
- en: '**A downtime in data pipeline and want to catch up**'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据管道停机并希望追赶**'
- en: The data pipeline may experience downtime for a few days leading to data gaps.
    Once the pipeline is restored, it will need to catch up on its scheduled runs.
    Fortunately, most modern data orchestration tools offer automatic catch-up functionality,
    so it needs less manual intervention than other scenarios.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管道可能会经历几天的停机，从而导致数据缺口。一旦管道恢复，它需要赶上其计划的运行。幸运的是，大多数现代数据编排工具提供自动追赶功能，因此相比其他情况，需要的人工干预较少。
- en: '![](../Images/50d2a1dbed5f8b6a0eb896d354b23c5f.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50d2a1dbed5f8b6a0eb896d354b23c5f.png)'
- en: Catch up on missing data with a backfill job (created by author)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用回填作业追赶缺失的数据（由作者创建）
- en: '*Do you have other scenarios? You are welcome to share with us in the comments.*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*你有其他场景吗？欢迎在评论中与我们分享。*'
- en: As seen from the graphs, backfill is a time-consuming job as it involves many
    partitions. To prevent unnecessary complexity, it’s a best practice to first ask
    the team and stakeholders about the intended use of the backfilled data and whether
    a backfill is indeed necessary. What’s the time range for backfill? Will the stakeholders
    get long-term benefits from the backfill? As the company grows, the table similarly
    grows. Ultimately, we may reach the point where backfilling the entire table becomes
    unfeasible and we need to decide where to cut off.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以看出，回填是一个耗时的工作，因为它涉及许多分区。为了防止不必要的复杂性，最佳做法是首先询问团队和利益相关者关于回填数据的预期用途以及是否确实需要回填。回填的时间范围是什么？利益相关者是否能从回填中获得长期收益？随着公司的增长，表格也会增长。**最终，我们可能会达到回填整个表格变得不可行的地步，需要决定在哪里截断。**
- en: Another important question to consider is whether we have the authority to modify
    historical data. In certain scenarios, changing historical data like finance data
    can mean a lot for a company, particularly when that data has undergone auditing.
    Understanding the business impact before updating the history is crucial as no
    one wants to get involved in legal issues.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的重要问题是我们是否有权限修改历史数据。在某些情况下，修改像财务数据这样的历史数据对公司可能意义重大，特别是当这些数据经过审计时。更新历史记录前理解业务影响至关重要，因为没有人愿意涉及法律问题。
- en: Table partition
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 表分区
- en: Now, let’s look at the technical aspect of the backfill. It wouldn’t be possible
    to discuss backfill without mentioning the table partition. Partitioning is an
    approach to incremental table updates. The partition column divides the table
    into a set of partitions. The backfill job updates these partitions one after
    another. Partition is also a unit of parallelism that allows the concurrent execution
    of multiple backfill jobs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看回填的技术方面。如果不提及表分区，就无法讨论回填。分区是增量表更新的一种方法。分区列将表划分为一组分区。回填作业会一个接一个地更新这些分区。分区也是一种并行单元，允许多个回填作业同时执行。
- en: There is a trade-off between the size of each partition and the number of partitions.
    A higher number of partitions results in a more granular division of data, the
    backfill job is more targeted and specific. However, it’s generally recommended
    not to create overly small partitions (e.g. less than 1G) because it may not effectively
    utilize the resources. Imagine comparing opening a single 1GB file and opening
    10 separate 100MB files — the former is typically more efficient. On the other
    hand, overly large partitions can result in a long backfill job because it might
    involve data that is not in the scope.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 每个分区的大小与分区数量之间存在权衡。更多的分区会导致数据更为细粒度地划分，回填作业会更加有针对性和具体。然而，通常建议不要创建过小的分区（例如，小于1G），因为这样可能无法有效利用资源。想象一下比较打开一个1GB的文件和打开10个分别为100MB的文件——前者通常更高效。另一方面，过大的分区可能导致回填作业时间过长，因为这可能涉及到超出范围的数据。
- en: '![](../Images/3ae986c2d16ee2078e4b7c09526c3ef1.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ae986c2d16ee2078e4b7c09526c3ef1.png)'
- en: Trade-off between big partition and small partition (created by author)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 大分区和小分区之间的权衡（由作者创建）
- en: Each data warehouse has a different recommended partition size based on how
    the metadata is accessed and the optimal utilization of resources. Additionally,
    think about which granularity makes the most sense for the table. For example,
    a common partition strategy is to partition on a `date` column where we expect
    an equal distribution across the days. However, if the data size for each day
    proves to be small, an alternative approach could be to partition it based on
    months or years.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据仓库根据元数据的访问方式和资源的最佳利用情况有不同的推荐分区大小。此外，还需要考虑哪种粒度对表最有意义。例如，一种常见的分区策略是在`date`列上进行分区，其中我们期望数据在各天之间均匀分布。然而，如果每一天的数据量很小，那么另一种方法可以是按月份或年份进行分区。
- en: Backfill strategy
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回填策略
- en: As previously mentioned, a backfill job demands a mix of data engineering skills.
    The majority of the critical factors for a successful backfill job are actually
    established before the job itself starts.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，回填作业需要数据工程技能的综合运用。成功的回填作业的大部分关键因素实际上是在作业本身开始之前就已经确定了。
- en: '**Bring data backfilling into the initial table design discussion**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**将数据回填纳入初始表设计讨论**'
- en: It’s a good practice to involve the discussion on backfill as early as possible
    because it can influence the table design, such as the partition strategy, as
    mentioned earlier. Particularly when the regular job doesn’t update the entire
    table with each run, it’s essential to have a backfilling plan to update historical
    data when required.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 早期涉及回填讨论是一种良好的实践，因为这可能会影响表的设计，例如前面提到的分区策略。特别是当常规作业并不每次都更新整个表时，必须有一个回填计划，以便在需要时更新历史数据。
- en: For certain tables such as small dimension tables, doing a full-table refresh
    each time can be a more favorable idea to eliminate the need for backfill. On
    the other hand, for fact tables with consistent linear growth, incremental table
    updates are preferable because we don’t want the cloud bill or server costs to
    grow linearly alongside the data growth.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些表，例如小型维度表，每次进行全表刷新可能是一个更为理想的选择，以避免需要回填。另一方面，对于具有一致线性增长的事实表，增量表更新更为可取，因为我们不希望云账单或服务器成本随着数据增长而线性增长。
- en: '**Make data pipeline idempotent**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**使数据管道具有幂等性**'
- en: Idempotency refers to running the same operation multiple times without changing
    the result. It’s a fundamental data pipeline design principle that every data
    engineer should know. Before a code change, rerunning the same Airflow task with
    the same input should consistently produce the same output. You don’t want to
    see any duplication or different output. Therefore, for an incremental table update,
    use `replace` rather than `append` mode to avoid duplicates. Moreover, use Airflow
    variables such as `data_interval_end` and not time-sensitive functions like `current_date()`
    in the transformation logic as `current_date()` gives different output based on
    the execution time of the job.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 幂等性指的是多次运行相同操作而不改变结果。这是每个数据工程师应该了解的基本数据管道设计原则。在代码更改之前，使用相同输入重新运行相同的 Airflow
    任务应始终产生相同的输出。你不希望看到任何重复或不同的输出。因此，对于增量表更新，使用 `replace` 而非 `append` 模式以避免重复。此外，在转换逻辑中使用
    Airflow 变量如 `data_interval_end`，而不是像 `current_date()` 这样的时间敏感函数，因为 `current_date()`
    的输出会根据作业的执行时间而不同。
- en: Idempotency is a critical precondition for a successful backfill and it ensures
    that data is only changed according to the expected change and not influenced
    by others. In this example, `date` column in the dataframe consistently represents
    the expected scheduled time and is not tied to the actual execution time of the
    task.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 幂等性是成功回填的关键前提，它确保数据只根据预期的变化进行更改，而不受其他因素影响。在这个例子中，数据框中的 `date` 列始终表示预期的计划时间，而不是与任务的实际执行时间相关联。
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Make a wise decision on the scope of backfilling and do it**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**对回填范围做出明智决策并执行**'
- en: The backfill job can be intense if the scope is not chosen wisely. Whatever
    time and money is taken in one partition will be multiplied in the backfill job.
    You can use the historical run to estimate costs and time beforehand. If the estimation
    surpasses your budget, then first understand the use case. Is this required for
    a one-off analysis? Then consider creating a temporary view on top of the existing
    table. Is the scope too big for the use case? Then reducing the partition size
    to a more manageable level. Is it still too much? Then perhaps consider using
    a more efficient or cost-effective technology.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果范围选择不当，回填作业可能会非常繁重。一个分区所花费的时间和金钱在回填作业中会被放大。你可以利用历史运行来提前估算成本和时间。如果估算超出预算，那么首先了解用例。这是为了进行一次性的分析吗？那么考虑在现有表上创建一个临时视图。范围对于用例来说是否太大？那么将分区大小减少到更可管理的水平。如果仍然太多，那么可能需要考虑使用更高效或更具成本效益的技术。
- en: Another very important point is to evaluate downstream impacts. When backfilling
    the source table, there may be a need to extend the backfill to downstream tables
    as well. I know it can be challenging to uncover all hidden connections. But if
    it’s a significant challenge for your team, consider leveraging a data lineage
    tool to systematically identify all downstream dependencies.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常重要的点是评估下游影响。在回填源表时，可能需要将回填扩展到下游表。我知道揭示所有隐藏连接可能很具挑战性。但如果这是你团队面临的重大挑战，考虑利用数据血缘工具系统性地识别所有下游依赖关系。
- en: Once the scope has been defined, it’s time to take action. Fortunately, many
    data tools natively support backfilling. In [Airflow](https://airflow.apache.org/docs/apache-airflow/stable/cli-and-env-variables-ref.html#backfill),
    you can either rerun the task from Airflow UI or use the command `airflow dags
    backfill`. In [dbt](https://docs.getdbt.com/docs/build/incremental-models#how-do-i-rebuild-an-incremental-model),
    you can use the command `dbt run --full-refresh` or pass a custom variable like
    `dbt run -s my_model --vars '{"start":"2023-11-01"}'`. Other tools like [Dagster](https://docs.dagster.io/concepts/partitions-schedules-sensors/backfills)
    and [Mage](https://docs.mage.ai/orchestration/backfills/overview) also have their
    own way of running backfill jobs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦范围定义好，就该采取行动了。幸运的是，许多数据工具原生支持回填。在 [Airflow](https://airflow.apache.org/docs/apache-airflow/stable/cli-and-env-variables-ref.html#backfill)
    中，你可以通过 Airflow UI 重新运行任务，也可以使用命令 `airflow dags backfill`。在 [dbt](https://docs.getdbt.com/docs/build/incremental-models#how-do-i-rebuild-an-incremental-model)
    中，你可以使用命令 `dbt run --full-refresh` 或传递自定义变量，例如 `dbt run -s my_model --vars '{"start":"2023-11-01"}'`。像
    [Dagster](https://docs.dagster.io/concepts/partitions-schedules-sensors/backfills)
    和 [Mage](https://docs.mage.ai/orchestration/backfills/overview) 等其他工具也有自己运行回填作业的方法。
- en: Be careful with the schema change. For changes that are compatible such as adding
    a new column, many data tools populate empty values for records before the first
    partition in the backfill job. For incompatible changes like deleting columns
    or changing data type, you need to recreate the entire table.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模式更改要小心。对于兼容的更改，如添加新列，许多数据工具会在回填作业中为第一个分区之前的记录填充空值。对于不兼容的更改，如删除列或更改数据类型，你需要重新创建整个表。
- en: '**Use DDL or DML to backfill the table**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用DDL或DML回填表格**'
- en: The good news is that there are alternative methods for backfilling the table,
    eliminating the need for executing many time-consuming Airflow runs. The truth
    is very often, we want to backfill only specific columns, not all of them. Thus,
    running computations for irrelevant columns is an inefficient use of resources.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，有替代方法可以回填表格，从而无需执行许多耗时的Airflow运行。实际上，我们往往只希望回填特定的列，而不是所有列。因此，针对无关列进行计算是资源的低效使用。
- en: 'A shortcut is to update the table using DDL or DML. For instance, in a situation
    where transformation for `quantity` changes from `quantity = amount * price` to
    `quantity = amount * price * exchange_rate`. We can simply backfill the table
    using `UPDATE` statement:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个捷径是使用DDL或DML更新表格。例如，在`quantity`的变换从`quantity = amount * price`改为`quantity
    = amount * price * exchange_rate`的情况下。我们可以简单地使用`UPDATE`语句回填表格：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In most cases, this is more efficient than running a backfill job in Airflow.
    Same for incompatible schema change, if recreating the entire table is expensive,
    consider use `DDL` to delete a column or alter data type.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，这比在Airflow中运行回填作业更高效。对于不兼容的模式更改，如果重新创建整个表非常昂贵，可以考虑使用`DDL`删除列或更改数据类型。
- en: '**Parallel backfilling jobs**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行回填作业**'
- en: 'Another optimization tip is to parallelize your backfill jobs. If 10 Airflow
    backfill jobs update 10 partitions, they can potentially run in parallel with
    these configs in place:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个优化技巧是将回填作业并行化。如果10个Airflow回填作业更新10个分区，它们可以在这些配置到位的情况下并行运行：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This approach allows for concurrent updates of multiple partitions, eliminating
    the need for sequential waiting. However, we need to make sure that the data warehouse
    supports concurrent writes and check its concurrency level. Additionally, there
    shouldn’t be any dependency among partitions such as today’s partition being computed
    based on yesterday’s partition.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法允许同时更新多个分区，消除了顺序等待的需要。然而，我们需要确保数据仓库支持并发写入并检查其并发级别。此外，分区之间不应有任何依赖关系，例如今天的分区不能基于昨天的分区进行计算。
- en: '**Backfill within a regular run**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**常规运行中的回填**'
- en: Sometimes we also want to automatically “backfill” the table as part of the
    normal run. What does it mean? This happens for example when a regular batch contains
    a few late-arrived records that need retrospective updates to historical data.
    Because it happens so often, it should be incorporated into the regular run instead
    of manually triggering it.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们也希望在正常运行中自动“回填”表格。这是什么意思？例如，当常规批处理包含一些迟到的记录，需要对历史数据进行回溯更新时，就会发生这种情况。由于这种情况非常频繁，因此应将其纳入常规运行中，而不是手动触发它。
- en: An example is counting accumulated total purchased orders in an e-commerce.
    Now, suppose a situation where a customer made an order on 11–01, but the order
    information doesn’t get ingested until 11–03 due to system delays. When order
    information is received on 11–03, it should update the number on 11–01 and 11–02
    as well.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是统计电子商务中的累计总购买订单。现在，假设一种情况，客户在11月1日下了订单，但由于系统延迟，订单信息直到11月3日才被处理。当11月3日收到订单信息时，应该更新11月1日和11月2日的数据。
- en: '![](../Images/901c17261e804285aa946a696b2eea20.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/901c17261e804285aa946a696b2eea20.png)'
- en: Transaction data with late orders (created by author)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟订单的交易数据（由作者创建）
- en: '![](../Images/e287c3c6a2d842612eaffdfda077b7ca.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e287c3c6a2d842612eaffdfda077b7ca.png)'
- en: Before and after backfill summary table (created by author)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 回填前后的汇总表（由作者创建）
- en: In this case, the “internal backfill” is triggered by an update on the input
    data, not the transformation logic. Depending on how late the record is, the job
    can potentially update more than one partition. The greater the delay, the more
    partitions need adjustment. Hence, it’s essential to monitor the performance and
    perhaps implement another process to prevent overloading the regular job.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，“内部回填”是由输入数据的更新触发的，而不是由转换逻辑触发的。根据记录的延迟情况，作业可能会更新多个分区。延迟越大，需要调整的分区就越多。因此，监控性能至关重要，可能需要实施另一种流程以防止常规作业过载。
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Post-backfill
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回填后
- en: Wow, that’s a lot of reading so far. I’m glad that you made it here. Triggering
    a backfill job is not the end of the process. We must actively monitor the performance
    as issues can arise at any point during the process. A key benefit of backfilling
    the table partition by partition is that if things go wrong midway, you have the
    flexibility to resume from the failed partition, not restart from the beginning.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，到目前为止有很多阅读内容。我很高兴你能看到这里。触发回填作业并不是过程的结束。我们必须积极监控性能，因为问题可能在过程中任何时候出现。逐个分区回填表的一个关键好处是，如果过程中出现问题，你可以灵活地从失败的分区恢复，而不是从头开始。
- en: Communication is the key to any data change. Make sure stakeholders are involved
    in the process. Think about creating scripts to automatically send notifications
    and ask for verification to all users of the backfilled table once the job is
    done.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 沟通是任何数据变更的关键。确保利益相关者参与过程。考虑在作业完成后创建脚本，自动发送通知并请求对回填表的所有用户进行验证。
- en: Conclusion
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: That was it! I hope you enjoy it and get inspired in one way or the other. The
    backfill job is challenging, but it should never be a black box or something that
    scares you away. Next time, there is no need to take a deep breath and pray hard
    before pressing the button :))
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样了！希望你喜欢，并以某种方式获得启发。回填作业是具有挑战性的，但它不应该是一个黑箱或让你感到害怕的东西。下次，不必在按下按钮前深呼吸并祈祷：))
- en: For those already familiar with backfilling. I hope you still gained some insights
    from this article. Feel free to share additional tips or tricks you may have —
    we’d love to hear from you! Cheers!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于已经熟悉回填的人。我希望你仍然从这篇文章中获得了一些见解。如果你有额外的技巧或窍门，请随时分享——我们很想听到你的声音！干杯！
- en: Reference
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考
- en: '[](https://dagster.io/blog/backfills-in-ml?source=post_page-----cf1713d7f7a3--------------------------------)
    [## Backfills in Data & Machine Learning: A Primer | Dagster Blog'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dagster.io/blog/backfills-in-ml?source=post_page-----cf1713d7f7a3--------------------------------)
    [## 数据与机器学习中的回填：入门 | Dagster 博客]'
- en: Recovering from a bad backfill is a painful experience for any data engineer.
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从糟糕的回填中恢复对任何数据工程师来说都是一个痛苦的经历。
- en: dagster.io](https://dagster.io/blog/backfills-in-ml?source=post_page-----cf1713d7f7a3--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[dagster.io](https://dagster.io/blog/backfills-in-ml?source=post_page-----cf1713d7f7a3--------------------------------)'
