- en: Chain of Thought Prompting Facilitate LLMs Reasoning Abilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938](https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Demonstrated with examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    ·6 min read·Jun 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/002f67384a5ad5ec102fb526b86c9eea.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Juan Rumimpunu](https://unsplash.com/@earbiscuits?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/nLXOatvTaLo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) are proven to be highly efficient at solving a
    variety of tasks from summarizing documents to writing code in different programming
    languages.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, they just get better with newly announced models like ChatGPT and
    GPT-4, unlocking a world of opportunities with LLM-based applications.
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to their extraordinary skills, LLMs sometimes fail to demonstrate very
    simple reasoning abilities and fail to solve questions that can easily be tackled
    down by a fourth grader.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of research has been done in this area aiming to understand why LLMs fail
    to perform such tasks and to make them get better.
  prefs: []
  type: TYPE_NORMAL
- en: One study that focuses on this particular issue is [chain-of-thought prompting](https://arxiv.org/abs/2201.11903),
    introduced by Google research, brain team.
  prefs: []
  type: TYPE_NORMAL
- en: Chain-of-thought prompting
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A prompting technique with a structure of {input, chain-of-thought, output},
    where chain-of-thought is a series of intermediate natural language reasoning
    steps.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The models are given a few examples with input and output (few-shot learning)
    and then asked a question that involves a multi-step or arithmetic reasoning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key takeaways from the [paper](https://arxiv.org/abs/2201.11903):'
  prefs: []
  type: TYPE_NORMAL
- en: Chain-of-thought prompting outperforms standard prompting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The difference between chain-of-thought prompting and standard prompting becomes
    more evident on larger models. The performance increase with chain-of-prompting
    is proportional to the number of parameters of the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The chain-of-thought prompting technique is simply solving the problem step-by-step.
    Each step is based on logical reasoning. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: John has 2 houses. Each house has 3 bedrooms and there are 2 windows
    in each bedroom. Each house has 1 kitchen with 2 windows. Also, each house has
    5 windows that are not in the bedrooms or kitchens.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How many windows are there in John’s houses?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Answer: Each house has 3 bedrooms with 2 windows each, which makes it 6 bedroom
    windows. Each house has 1 kitchen with 2 windows, which makes it 2 kitchen windows.
    There are also 5 windows that are not in the kitchen or bedroom. So there are
    6 + 2 + 5 = 13 windows per house. Since there are 2 houses, there are 2 x 13 =
    26 houses in John’s houses.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can follow different steps to reach the correct answer. For such questions,
    there are almost always more than one path to get to the answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In standard prompting, we’d just ask the above question to an LLM and expect
    it to give the answer. Let’s try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Wrong answer!
  prefs: []
  type: TYPE_NORMAL
- en: We don’t know how the model gets this answer, which brings us to another advantage
    of chain-of-thought prompting. The model responds with a step-by-step answer,
    which makes the debugging process easier. We can easily spot where things go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: With chain-of-prompting technique, we add a few questions and their answers
    to the prompt to do few-shot prompting. The answers are in the form of a step-by-step
    solution (i.e. demonstrates a chain-of-thought).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the updated prompt and the response of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Correct answer!
  prefs: []
  type: TYPE_NORMAL
- en: The response is a step-by-step explanation of the thought process of the model
    (chain-of-thought) just like the examples shown in the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go over another example. Here is the standard prompting version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Wrong answer!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try the same question with chain-of-thought prompting by providing a
    few input-output examples (few-shot learning):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Correct answer!
  prefs: []
  type: TYPE_NORMAL
- en: Final words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The chain-of-thought prompting clearly increases the ability of LLMs at certain
    tasks. I suggest reading the entire [paper](https://arxiv.org/abs/2201.11903)
    if you’d like to learn more about the experiments they conducted.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that, as also mentioned in the paper, the benefits of
    chain-of-thought prompting only become evident when applied to models with approximately
    100 billion parameters, and it doesn’t significantly enhance the performance of
    smaller models.
  prefs: []
  type: TYPE_NORMAL
- en: The experiment results yield to the conclusion that smaller models produce fluent
    but illogical chains of thought, which leads to a worse performance than standard
    prompting.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Wei, Jason, et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large
    Language Models. ArXiv. [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
  prefs: []
  type: TYPE_NORMAL
