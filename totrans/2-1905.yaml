- en: 'Stable Diffusion as an API: Make a Person-Removing Microservice'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Stable Diffusion作为API：创建一个去除人物的微服务
- en: 原文：[https://towardsdatascience.com/stable-diffusion-as-an-api-5e381aec1f6](https://towardsdatascience.com/stable-diffusion-as-an-api-5e381aec1f6)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stable-diffusion-as-an-api-5e381aec1f6](https://towardsdatascience.com/stable-diffusion-as-an-api-5e381aec1f6)
- en: '![](../Images/a964e08268efee5aaf0f29c6237487db.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a964e08268efee5aaf0f29c6237487db.png)'
- en: Landscape image produced using Stable Diffusion 2 (by author).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Stable Diffusion 2生成的风景图像（作者提供）。
- en: Remove people from photos with a Stable Diffusion microservice
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Stable Diffusion微服务从照片中去除人物
- en: '[](https://medium.com/@masonmcgough?source=post_page-----5e381aec1f6--------------------------------)[![Mason
    McGough](../Images/4b465e0eef1590b1f12dea23a6f688e1.png)](https://medium.com/@masonmcgough?source=post_page-----5e381aec1f6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5e381aec1f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5e381aec1f6--------------------------------)
    [Mason McGough](https://medium.com/@masonmcgough?source=post_page-----5e381aec1f6--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@masonmcgough?source=post_page-----5e381aec1f6--------------------------------)[![Mason
    McGough](../Images/4b465e0eef1590b1f12dea23a6f688e1.png)](https://medium.com/@masonmcgough?source=post_page-----5e381aec1f6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5e381aec1f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5e381aec1f6--------------------------------)
    [Mason McGough](https://medium.com/@masonmcgough?source=post_page-----5e381aec1f6--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5e381aec1f6--------------------------------)
    ·12 min read·Feb 4, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5e381aec1f6--------------------------------)
    ·阅读时间12分钟·2023年2月4日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Overview
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: Stable Diffusion is a cutting-edge open-source tool for generating images from
    text. The Stable Diffusion Web UI opens up many of these features with an API
    as well as the interactive UI. We will first introduce how to use this API, then
    set up an example using it as a privacy-preserving microservice to remove people
    from images.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 是一个前沿的开源工具，用于从文本生成图像。Stable Diffusion Web UI 通过API以及交互式用户界面提供了许多这些功能。我们将首先介绍如何使用这个API，然后设置一个示例，将其作为一个隐私保护微服务来从图像中去除人物。
- en: Introduction to Generative AI
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成AI介绍
- en: So many innovations in machine learning-based data generators happened last
    year you might be able to call 2022 the “Year of Generative AI.” We had [DALL-E
    2](https://openai.com/dall-e-2/), the text-to-image generation model from OpenAI
    that produced strikingly realistic images of astronauts riding horses and dogs
    wearing people clothes. [GitHub Copilot](https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/),
    the powerful code completion tool that will autocomplete statements, write documentation,
    and implement entire functions for you from a single comment, was released to
    the public as a subscription service. We had [Dream Fields](https://www.ajayjain.net/dreamfields/),
    [Dream Fusion](https://dreamfusion3d.github.io/), and [Magic3D](https://research.nvidia.com/labs/dir/magic3d/),
    a series of groundbreaking models capable of producing textured 3D models from
    text alone. Last but certainly not least we had [ChatGPT](https://openai.com/blog/chatgpt/),
    the cutting-edge AI chatbot which these days needs no introduction.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 去年，基于机器学习的数据生成器出现了许多创新，2022年或许可以称为“生成AI的年度”。我们迎来了 [DALL-E 2](https://openai.com/dall-e-2/)，这是OpenAI的文本到图像生成模型，生成了令人惊叹的现实主义图像，如宇航员骑马和穿着人类衣物的狗。
    [GitHub Copilot](https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/)，这个强大的代码补全工具可以自动完成语句、编写文档，并根据单个评论实现完整的功能，已经作为订阅服务公开发布。我们还看到了
    [Dream Fields](https://www.ajayjain.net/dreamfields/)、[Dream Fusion](https://dreamfusion3d.github.io/)
    和 [Magic3D](https://research.nvidia.com/labs/dir/magic3d/)，一系列能够仅通过文本生成纹理化3D模型的突破性模型。最后但同样重要的是我们迎来了
    [ChatGPT](https://openai.com/blog/chatgpt/)，这个前沿的AI聊天机器人如今无需介绍。
- en: This list barely even scratches the surface. In just the world of generative
    image models like DALL-E 2 we also have [Midjourney](https://www.midjourney.com/),
    [Google Imagen](https://imagen.research.google/), [StarryAI](https://starryai.com/),
    [WOMBO Dream](https://dream.ai/create), [NightCafe](https://nightcafe.studio/),
    [InvokeAI](https://invoke-ai.github.io/InvokeAI/), [Lexica Aperture](https://lexica.art/aperture),
    [Dream Studio](https://beta.dreamstudio.ai/), [Deforum](https://deforum.github.io/)…
    I think you get the *picture*. 😉 📷 It seems like no exaggeration to say that generative
    AI has captured the imaginations of the whole world.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表几乎只是触及了表面。在像DALL-E 2这样的生成图像模型世界中，我们还有[Midjourney](https://www.midjourney.com/)、[Google
    Imagen](https://imagen.research.google/)、[StarryAI](https://starryai.com/)、[WOMBO
    Dream](https://dream.ai/create)、[NightCafe](https://nightcafe.studio/)、[InvokeAI](https://invoke-ai.github.io/InvokeAI/)、[Lexica
    Aperture](https://lexica.art/aperture)、[Dream Studio](https://beta.dreamstudio.ai/)、[Deforum](https://deforum.github.io/)……我想你已经明白了*画面*。😉
    📷 说生成AI已经捕捉了整个世界的想象力，似乎并不夸张。
- en: Stable Diffusion
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳定扩散
- en: While many of the popular generative AI tools like ChatGPT, GitHub Copilot,
    and DALL-E 2 are proprietary and paywalled, the open-source community has not
    skipped a beat. Last year, LMU Munich, Runway, and Stability AI collaborated to
    publicly share [Stable Diffusion](https://github.com/CompVis/stable-diffusion),
    a powerful yet efficient text-to-image model efficient enough to run on consumer
    hardware. This means that anyone with a decent GPU and an internet connection
    can download the Stable Diffusion code and model weights, bringing low-cost image
    generation to the world.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多流行的生成AI工具如ChatGPT、GitHub Copilot和DALL-E 2是专有的且需付费的，但开源社区并没有停下脚步。去年，LMU慕尼黑大学、Runway和Stability
    AI合作公开分享了[Stable Diffusion](https://github.com/CompVis/stable-diffusion)，这是一个强大但高效的文本到图像模型，足够高效以在消费级硬件上运行。这意味着任何拥有一台不错GPU和互联网连接的人都可以下载Stable
    Diffusion代码和模型权重，将低成本图像生成带给世界。
- en: Stable Diffusion Web UI
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳定扩散网络界面
- en: The [Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui),
    one of the most popular tools leveraging Stable Diffusion, exposes a wide range
    of the settings and features of Stable Diffusion in an interactive browser-based
    user interface. A lesser-known feature of this project is that you can use it
    as an HTTP API, allowing you to request images from your own applications.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)是利用Stable
    Diffusion的最受欢迎工具之一，它在基于浏览器的用户界面中暴露了Stable Diffusion的广泛设置和功能。该项目一个鲜为人知的功能是，你可以将其作为HTTP
    API使用，允许你从自己的应用程序中请求图像。'
- en: '![](../Images/b361ece7b8424e89b5c7e22e9230c880.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b361ece7b8424e89b5c7e22e9230c880.png)'
- en: The Stable Diffusion Web UI with an example generation (photo by author).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion Web UI的示例生成（作者提供的照片）。
- en: It has a metric truckload of features, such as inpainting, outpainting, resizing,
    upscaling, variations, and many more. The [project wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features)
    provides a great overview of all the features. In addition, it provides scripting
    for extensibility.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有大量功能，如修补、扩展、调整大小、放大、变体等。 [项目wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features)
    提供了所有功能的详细概述。此外，它还提供了扩展性脚本。
- en: Setup
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置
- en: 'Before beginning, ensure that you have a GPU (NVIDIA preferably but AMD is
    also supported) with at least 8GB of VRAM to play with on your system. That will
    ensure that you can load the model into memory. Next, you want to clone the repo
    to your system (for instance via HTTPS):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保你的系统中有一个GPU（最好是NVIDIA，但AMD也支持），且至少有8GB的显存。这将确保你可以将模型加载到内存中。接下来，你需要将代码库克隆到你的系统中（例如通过HTTPS）：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Follow the [installation instructions](https://github.com/AUTOMATIC1111/stable-diffusion-webui#installation-and-running)
    for your system as they may be different from mine. I used an install of Ubuntu
    18.04 to set this up, but it should also work on Windows and Apple Silicon. These
    instructions will include setting up a Python environment, so make sure that whichever
    environment you set up is active when you launch the server later.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的系统遵循[安装说明](https://github.com/AUTOMATIC1111/stable-diffusion-webui#installation-and-running)，因为这些可能与你的有所不同。我使用的是Ubuntu
    18.04进行设置，但它也应该适用于Windows和Apple Silicon。这些说明将包括设置Python环境，因此请确保在稍后启动服务器时，所设置的环境处于活动状态。
- en: 'Once that is done, we need a copy of the model weights. I am using [Stable
    Diffusion 2.0](https://huggingface.co/stabilityai/stable-diffusion-2), but [Stable
    Diffusion 2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1) is now
    available as well. Whichever option you pick, be sure to download the weights
    for the [stablediffusion](https://github.com/Stability-AI/stablediffusion) repository.
    Lastly, copy those weights to the `models/Stable-diffusion` folder like so:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们需要一份模型权重的副本。我使用的是 [Stable Diffusion 2.0](https://huggingface.co/stabilityai/stable-diffusion-2)，但现在也有
    [Stable Diffusion 2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1)
    可用。无论你选择哪个选项，确保下载 [stablediffusion](https://github.com/Stability-AI/stablediffusion)
    仓库的权重。最后，将这些权重复制到 `models/Stable-diffusion` 文件夹中，如下所示：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now you should be ready to start generating images! To launch the server, execute
    the following from the root directory (be sure that the environment you set up
    is activated):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该准备好开始生成图像了！要启动服务器，请在根目录下执行以下操作（确保你设置的环境已激活）：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The server will take some time to get set up, as it likely needs to install
    requirements, load the model weights into memory, and check for embeddings, among
    other things. When it is ready, you should see a message in your terminal that
    looks like this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器需要一些时间来设置，因为它可能需要安装要求、将模型权重加载到内存中、检查嵌入等。准备好后，你应该会在终端中看到类似下面的消息：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The UI is browser-based, so navigate to “[127.0.0.1:7860](http://127.0.0.1:7860)"
    in your favorite web browser. If it is working, it should look something like
    this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户界面是基于浏览器的，因此在你喜欢的网页浏览器中导航到 “[127.0.0.1:7860](http://127.0.0.1:7860)” 。如果它正常工作，它应该看起来像这样：
- en: '![](../Images/3ea02f9b2002eee7e0ce6eedd81f3629.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ea02f9b2002eee7e0ce6eedd81f3629.png)'
- en: The Stable Diffusion Web UI when first opened (photo by author).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散 Web 用户界面首次打开时（作者拍摄）。
- en: Usage
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用
- en: You should now be ready to generate some images! Go ahead and generate something
    by entering text into the “Prompt” field and clicking “Generate.” If this is your
    first time using this UI, take a second to explore and learn some of its features
    and settings. Refer to [the wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki)
    if you have any questions. This knowledge will come in handy later when designing
    your API.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该准备好生成一些图像了！进入“提示”字段中输入文本并点击“生成”以生成一些内容。如果这是你第一次使用这个用户界面，花点时间探索并了解其一些功能和设置。如果有任何问题，请参考
    [维基](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki)。这些知识在设计你的 API
    时会很有用。
- en: I will not delve too deep into how to use the web UI since many others before
    me have done so. However, I will provide the following cheat sheet of basic settings
    for reference.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会过于深入地讲解如何使用网页用户界面，因为之前有很多人已经做了。不过，我会提供以下基本设置的备忘单以供参考。
- en: '**Sampling method**: The sampling algorithm. This can greatly affect the content
    of the generated image and overall appearance. The execution time and the results
    can differ greatly between methods. Ideally experiment with this option first.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样方法**：采样算法。这会极大地影响生成图像的内容和整体外观。不同方法的执行时间和结果可能会有很大差异。理想情况下，首先尝试这个选项。'
- en: '**Sampling steps**: The number of denoising steps during the image generation
    process. Some results will change drastically with the number of steps whereas
    others will quickly lead to diminishing returns. A value of 20–50 is ideal for
    most samplers.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样步骤**：图像生成过程中的去噪步骤数。某些结果会随着步骤数量的变化而剧烈改变，而其他结果则会很快出现边际效益递减。大多数采样器理想的步骤数为
    20–50。'
- en: '**Width**, **Height**: The output image dimensions. For SD 2.0, 768x768 is
    the preferred resolution. The resolution can affect the generated content.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**宽度**，**高度**：输出图像的尺寸。对于 SD 2.0，768x768 是首选分辨率。分辨率会影响生成的内容。'
- en: '**CFG scale**: The [Classifier-Free Guidance](https://arxiv.org/abs/2207.12598)
    (CFG) scale. Increasing this increases how much the image is impacted by the prompt.
    Lower values produce more creative results.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CFG比例**： [无分类器引导](https://arxiv.org/abs/2207.12598) (CFG) 比例。增加这个比例会增加图像受到提示的影响。较低的值会产生更具创意的结果。'
- en: '**Denoising strength**: Determines how much variation on the original image
    to allow for. A value of 0.0 results in no change. A value of 1.0 disregards the
    original image entirely. Starting with a value between 0.4–0.6 is generally a
    safe option.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**去噪强度**：确定允许原始图像的变化程度。值为 0.0 时没有变化。值为 1.0 时完全忽略原始图像。一般来说，从 0.4–0.6 的值开始是一个安全的选择。'
- en: '**Seed**: The random seed value. Useful when you want to compare the effect
    of a setting with as little variation as possible. If you like a particular generation
    but want to modify it a bit, copy the seed.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**种子**：随机种子值。当你想比较设置效果而尽可能减少变化时，这很有用。如果你喜欢某个特定生成但想稍作修改，请复制种子。'
- en: Using Stable Diffusion as an API
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 Stable Diffusion 作为 API 使用
- en: 'The web UI is meant for a single user and works great as an interactive art
    tool for making your own creations. However, if we want to build applications
    using this as the engine then we will want an API. A lesser-known (and lesser-documented)
    feature of the stable-diffusion-webui project is that it also has a built-in API.
    The web UI is built with [Gradio](https://gradio.app/) but there is also a FastAPI
    app that can be launched with the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 网络用户界面旨在供单个用户使用，并且作为一个互动艺术工具制作自己的创作非常好。然而，如果我们想要使用它作为引擎来构建应用程序，我们将需要一个 API。stable-diffusion-webui
    项目的一个鲜为人知（且文档较少）的功能是它还具有内置的 API。网络用户界面是用 [Gradio](https://gradio.app/) 构建的，但也有一个可以用以下命令启动的
    FastAPI 应用：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This gives us an API that exposes many of the features we had in the web UI.
    We can send POST requests with our prompt and parameters and receive responses
    that contain output images.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一个 API，暴露了我们在网络用户界面中拥有的许多功能。我们可以发送带有提示和参数的 POST 请求，并接收包含输出图像的响应。
- en: Create a microservice
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个微服务
- en: As an example, we will now set up a simple microservice that removes people
    from photos. This has many applications, such as preserving the privacy of individuals.
    We can use stable diffusion as a rudimentary privacy-preserving filter, which
    removes people from photos without any unsightly mosaicing or pixel blocking.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，我们现在将设置一个简单的微服务，用于从照片中移除人物。这有很多应用，例如保护个人隐私。我们可以使用稳定扩散作为一种原始的隐私保护过滤器，它可以从照片中去除人物而没有任何难看的马赛克或像素块。
- en: Note that this is a basic setup; it does not include encryption, load-balancing,
    multitenancy, RBAC, or any other features. This setup may not be suitable for
    production, but it can be useful for setting up applications on a home or private
    server.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这只是一个基本设置；它不包括加密、负载均衡、多租户、RBAC 或任何其他功能。这个设置可能不适合生产环境，但可以用于在家庭或私人服务器上设置应用程序。
- en: Start application in API mode
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以 API 模式启动应用程序
- en: 'The following instructions will use the server in API mode, so go ahead and
    stop the web UI for now with CTRL+C. Start it up again in API mode with the `--api`
    option:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下说明将使用 API 模式运行服务器，因此请先通过 CTRL+C 停止网络用户界面（web UI）。然后使用 `--api` 选项以 API 模式重新启动它：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The server should print something like this when it is ready:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务器准备好时，它应该会打印出类似以下内容的信息：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It can also be useful to run the server in a headless state without the UI.
    To enable just the API without the Gradio app:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 运行服务器而不带用户界面的无头状态也可能很有用。要仅启用 API 而不使用 Gradio 应用：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Send a request to the API
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向 API 发送请求
- en: The first thing we will want to do is demonstrate how to make a request to the
    API. We wish to send a POST request to the `txt2img` (i.e. “text-to-image”) API
    of the application to simply generate an image.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要做的是演示如何向 API 发出请求。我们希望向应用程序的 `txt2img`（即“文本到图像”）API 发送 POST 请求，以简单地生成一张图像。
- en: 'We will use the `requests` package, so install that if you have not already:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `requests` 包，因此如果你还没有安装，请先安装它：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can send a request containing a prompt as a simple string. The server will
    return an image as a [base64](https://en.wikipedia.org/wiki/Base64)-encoded PNG
    file, which we will need to decode. To decode a base64 image, we simply use `base64.b64decode(b64_image)`.
    The following script should be all you need to test this out:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以发送一个包含简单字符串的提示的请求。服务器将返回一个 [base64](https://en.wikipedia.org/wiki/Base64)
    编码的 PNG 文件，我们需要对其进行解码。要解码 base64 图像，我们只需使用 `base64.b64decode(b64_image)`。以下脚本应该可以测试这个功能：
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Copy the contents to a file and name it `sample-request.py`. Now execute this
    with:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将内容复制到一个文件中，并将其命名为 `sample-request.py`。现在使用以下命令执行它：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If it worked, it should save a copy of the image to the file `dog.png`. Mine
    looked like this dapper fellow:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，它应该会将图像保存为文件 `dog.png`。我的图像看起来像这样这位衣着光鲜的家伙：
- en: '![](../Images/f4ee5a19b1d19b4de18ac8f09681aebb.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4ee5a19b1d19b4de18ac8f09681aebb.png)'
- en: Image created with ‘sample-request.py’ (photo by author).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用‘sample-request.py’创建的图像（作者拍摄的照片）。
- en: Keep in mind that your results will vary from mine. If you encounter issues,
    double-check the output from the terminal running the stable diffusion app. It
    could be that the server was not finished setting up yet. If you get an issue
    like “404 Not Found,” double-check that the URL was typed correctly and is pointing
    to the correct address (e.g. 127.0.0.1).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，您的结果可能与我的不同。如果遇到问题，请仔细检查运行稳定扩散应用的终端输出。可能是服务器尚未完成设置。如果遇到“404 Not Found”的问题，请仔细检查
    URL 是否正确输入，并指向正确的地址（例如 127.0.0.1）。
- en: Masking an image
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像掩膜。
- en: 'If all is working so far, then great! But how can we use this to modify images
    we already have? For that we will want to use the `img2img` (i.e. “image-to-image”)
    API. This API uses stable diffusion to modify an image that you submit. We will
    use the [inpainting feature](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#inpainting):
    given an image and a mask, the inpainting technique will try to replace the masked
    portion of the image with content generated by stable diffusion. The mask acts
    as a weight that smoothly interpolates between the original image and a generation
    to blend the two together.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果到目前为止一切正常，那就太好了！但是我们如何使用它来修改已有的图像呢？为此，我们将使用 `img2img`（即“图像到图像”）API。该 API 使用稳定扩散来修改您提交的图像。我们将使用
    [修复功能](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#inpainting)：给定图像和掩膜，修复技术将尝试用稳定扩散生成的内容替换图像中被掩膜遮挡的部分。掩膜作为权重，平滑地插值于原始图像和生成内容之间，将两者融合在一起。
- en: Rather than make a mask by hand, we will attempt to generate one using one of
    the many pre-trained computer vision models available to us. We will use the “person”
    class of the model outputs to generate a mask. While an object detection model
    would work, I chose to use a segmentation model so that you can experiment with
    using either dense masks or bounding boxes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试使用许多可用的预训练计算机视觉模型之一生成掩膜，而不是手动制作掩膜。我们将使用模型输出中的“person”类别来生成掩膜。虽然对象检测模型也可以，但我选择使用分割模型，以便您可以尝试使用密集掩膜或边界框。
- en: We will need a sample image to test with. We could download one from the Internet,
    but in the spirit of preserving privacy (and copyright), why not make one with
    stable diffusion? The following is one I generated with the prompt “beautiful
    mountain landscape, a woman walking away from the camera.”
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个示例图像进行测试。我们可以从互联网上下载一个，但为了保护隐私（和版权），为什么不使用稳定扩散生成一个呢？以下是我使用提示词“美丽的山地风景，一个女人背对镜头走开”生成的图像。
- en: '![](../Images/a2a07a10abe92d5e95f51db818854298.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2a07a10abe92d5e95f51db818854298.png)'
- en: Image generated by stable diffusion (photo by author).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散生成的图像（照片作者提供）。
- en: You can download this one, but I encourage you to try to generate one yourself.
    Of course, you can use real photos as well. The following is minimal code to apply
    a stock segmentation model from `torchvision` to this image as a mask.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以下载这个，但我鼓励您尝试自己生成一个。当然，您也可以使用真实照片。以下是将 `torchvision` 的库存分割模型应用于此图像作为掩膜的最小代码。
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Like before, copy this to a file named `segment-person.py`. Execute the code
    with the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 像之前一样，将其复制到名为 `segment-person.py` 的文件中。使用以下命令执行代码：
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The resulting prediction should look something like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 结果预测应该类似于这个：
- en: '![](../Images/042dc0bd35ef951cfb12daf3ecb788ff.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/042dc0bd35ef951cfb12daf3ecb788ff.png)'
- en: Result of segmentation mask applied to image (photo by author).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 应用到图像上的分割掩膜结果（照片作者提供）。
- en: We now have the machinery to make requests to the API and to predict bounding
    boxes. Now we can start building out our microservice.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了向 API 发出请求和预测边界框的工具。现在可以开始构建我们的微服务了。
- en: Person removal microservice
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人物移除微服务。
- en: 'Let us now turn to our practical example: removing people from images. The
    microservice should do the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转到实际示例：从图像中移除人物。微服务应执行以下操作：
- en: Read a number of input arguments
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取一些输入参数。
- en: Load an image from a file
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文件中加载图像。
- en: Apply a segmentation model with the class “person” to the image to create a
    mask
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将“person”类别的分割模型应用于图像以创建掩膜。
- en: Convert the image and mask to base64 encoding
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像和掩膜转换为 base64 编码。
- en: Send a request containing the base64-encoded image, the base64-encoded mask,
    the prompt, and any arguments to the `img2img` API of the local server
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个请求，包含 base64 编码的图像、base64 编码的掩膜、提示词和任何参数到本地服务器的 `img2img` API。
- en: Decode and save the output image as a file
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码并将输出图像保存为文件。
- en: 'Since we already covered all of these steps individually, the microservice
    has already been implemented for you in [this GitHub Gist](https://gist.github.com/Mason-McGough/9733aff5bc9d04faecfbb81074617315).
    Now download the script and execute it on the image “woman-on-trail.png” (or whichever
    image you like) using the following command:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经单独涵盖了所有这些步骤，微服务已经为您在 [这个 GitHub Gist](https://gist.github.com/Mason-McGough/9733aff5bc9d04faecfbb81074617315)
    中实现了。现在下载脚本并使用以下命令在“woman-on-trail.png”（或您喜欢的任何图片）上执行：
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `-W` and `-H` indicate the desired output width and height, respectively.
    It will save the generated image as `inpaint-person.png` and the corresponding
    mask as `mask_inpaint-person.png`. Yours will be different, but this is the output
    I received:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`-W` 和 `-H` 分别表示所需的输出宽度和高度。它将生成的图像保存为 `inpaint-person.png`，对应的掩模保存为 `mask_inpaint-person.png`。您的输出会有所不同，但这是我收到的结果：'
- en: '![](../Images/c2b2c2a0fdc22772c274443559b753a3.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2b2c2a0fdc22772c274443559b753a3.png)'
- en: Result of API call using the raw segmentation mask (image by author).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原始分割掩模的API调用结果（图像由作者提供）。
- en: Hmm, not quite what we are looking for. Seems that much of the person still
    remains, particularly the silhouette. We may need to mask a larger area. For this,
    let us try converting the mask to a bounding box. We can do this using the `-B`
    flag.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这不是我们想要的。似乎很多人的轮廓仍然存在，特别是剪影。我们可能需要掩盖更大的区域。为此，我们可以尝试将掩模转换为边界框。我们可以使用`-B`标志来完成这一操作。
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output I received is this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我收到的输出是：
- en: '![](../Images/13239ae2bb31628762428c05fb379093.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13239ae2bb31628762428c05fb379093.png)'
- en: Result of API call using a bounding box as mask (photo by author).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用边界框作为掩模的API调用结果（照片由作者提供）。
- en: That is also not quite right! A concrete column is not something we would expect
    to find in the middle of a trail. Perhaps bringing in a prompt will help steer
    things in the right direction. We use the `-p` flag to add the prompt “mountain
    scenery, landscape, trail” to the request. We also dilate the bounding box with
    `-D 32` to remove some of the edge effects and blur the bounding box with `-b
    16` to blend the mask with the background a bit.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这也不完全正确！混凝土柱子不是我们期望在小径中间找到的东西。也许引入一个提示会有助于引导方向。我们使用`-p`标志将提示“山地风景，景观，小径”添加到请求中。我们还使用`-D
    32`扩展边界框，以去除一些边缘效果，并使用`-b 16`模糊边界框，使掩模与背景稍微融合。
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'With this I received the following output:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个我得到了以下输出：
- en: '![](../Images/af78bf46b1810c8eef81bd6d66fd9685.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af78bf46b1810c8eef81bd6d66fd9685.png)'
- en: Result of final API call (photo by author).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最终API调用的结果（照片由作者提供）。
- en: Now that is looking plausible! Keep playing around with different images, settings,
    and prompts to get it working for your use case. To see a complete list of arguments
    and hints available with this script, enter `python inpaint-person.py -h`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看起来很有可能！继续尝试不同的图片、设置和提示，以便适应您的用例。要查看该脚本可用的完整参数和提示列表，请输入 `python inpaint-person.py
    -h`。
- en: Discussion
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: It is very likely that your images looked very different from the ones above.
    Because it is an inherently stochastic process, even using stable diffusion with
    the same settings can produce radically different outputs. There is quite a steep
    learning curve to understand all of the features and proper prompt design and
    even then the results can be finicky. Making an image look exactly the way you
    like is extremely difficult and requires much trial and error.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您的图片很可能与上述图片差别很大。因为这是一个本质上随机的过程，即使使用相同设置的稳定扩散也会产生截然不同的结果。理解所有特性和正确的提示设计有相当陡峭的学习曲线，即便如此，结果也可能很挑剔。让一张图片完全符合您的喜好极其困难，需要经过大量的试验和错误。
- en: 'To aid in your quest, keep the following tips in mind:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您，请记住以下提示：
- en: Use the web UI to find the right parameters that work for your use case before
    moving to the API.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在转到API之前，使用Web UI找到适合您用例的正确参数。
- en: Rely on the prompt matrix and X/Y plot features when finetuning an image to
    your liking. These will help you rapidly explore the parameter search space.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将图像微调到您喜欢的状态时，依赖于提示矩阵和X/Y图特性。这些将帮助您快速探索参数搜索空间。
- en: Be mindful of the seeds. If you like a specific output but want to iterate on
    it, copy the seed.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意种子。如果您喜欢特定的输出但想要对其进行迭代，请复制种子。
- en: Try a different generator like Midjourney! Every tool is slightly different.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试使用不同的生成器，如 Midjourney！每个工具略有不同。
- en: Use Internet resources like [Lexica](https://lexica.art/) as inspiration and
    to find good prompts.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用互联网资源，如 [Lexica](https://lexica.art/) 来获取灵感并寻找好的提示。
- en: Use the “Create a text file next to every image with generation parameters”
    option in the settings menu to keep track of the prompts and settings you use
    to make every image.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在设置菜单中使用“在每张图片旁边创建一个文本文件，并记录生成参数”选项，以跟踪你用来制作每张图片的提示和设置。
- en: Most importantly, have fun!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，要玩得开心！
