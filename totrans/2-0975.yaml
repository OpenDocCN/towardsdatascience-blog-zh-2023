- en: Getting Started with Databricks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 Databricks
- en: 原文：[https://towardsdatascience.com/getting-started-with-databricks-11af3db4f595](https://towardsdatascience.com/getting-started-with-databricks-11af3db4f595)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/getting-started-with-databricks-11af3db4f595](https://towardsdatascience.com/getting-started-with-databricks-11af3db4f595)
- en: A Beginner’s Guide to Databricks
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Databricks 初学者指南
- en: '[](https://spierre91.medium.com/?source=post_page-----11af3db4f595--------------------------------)[![Sadrach
    Pierre, Ph.D.](../Images/0e4aab43c2b981546d552beccf2259ab.png)](https://spierre91.medium.com/?source=post_page-----11af3db4f595--------------------------------)[](https://towardsdatascience.com/?source=post_page-----11af3db4f595--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----11af3db4f595--------------------------------)
    [Sadrach Pierre, Ph.D.](https://spierre91.medium.com/?source=post_page-----11af3db4f595--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://spierre91.medium.com/?source=post_page-----11af3db4f595--------------------------------)[![Sadrach
    Pierre, Ph.D.](../Images/0e4aab43c2b981546d552beccf2259ab.png)](https://spierre91.medium.com/?source=post_page-----11af3db4f595--------------------------------)[](https://towardsdatascience.com/?source=post_page-----11af3db4f595--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----11af3db4f595--------------------------------)
    [Sadrach Pierre, Ph.D.](https://spierre91.medium.com/?source=post_page-----11af3db4f595--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----11af3db4f595--------------------------------)
    ·9 min read·May 8, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----11af3db4f595--------------------------------)
    ·9 分钟阅读·2023年5月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c2c2e8095e951f4e978e8ed16e16747c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2c2e8095e951f4e978e8ed16e16747c.png)'
- en: Image by [Alexander Grey](https://www.pexels.com/@mccutcheon/) on [Pexels](https://www.pexels.com/photo/assorted-color-bricks-1148496/)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Alexander Grey](https://www.pexels.com/@mccutcheon/) 提供，来源于 [Pexels](https://www.pexels.com/photo/assorted-color-bricks-1148496/)
- en: '[Databricks](https://www.databricks.com/) allows data scientists to easily
    create and manage notebooks for research, experimentation, and deployment. The
    appeal of platforms like Databricks includes seamless integration with cloud services,
    tooling for model maintenance, and scalability.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Databricks](https://www.databricks.com/) 使数据科学家能够轻松创建和管理用于研究、实验和部署的笔记本。像 Databricks
    这样的平台的吸引力包括与云服务的无缝集成、模型维护工具和可扩展性。'
- en: Databricks is very useful for model experimentation and maintenance. Databricks
    has a machine learning library, called [MLflow](https://mlflow.org/docs/latest/index.html),
    that provides useful tooling for model development and deployment. With MLflow,
    you can log models as well as metadata associated with the models such as performance
    metrics and hyperparameters. This makes it very straightforward to run experiments
    and analyze results.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 对于模型实验和维护非常有用。Databricks 拥有一个机器学习库，称为 [MLflow](https://mlflow.org/docs/latest/index.html)，提供了用于模型开发和部署的有用工具。使用
    MLflow，你可以记录模型以及与模型相关的元数据，例如性能指标和超参数。这使得运行实验和分析结果变得非常简单。
- en: Many Databricks features are useful for scaling steps within the machine learning
    workflow such as data loading, model training, and model logging. [Koalas](https://koalas.readthedocs.io/en/latest/user_guide/index.html)
    is a library in Databricks that is a more efficient alternative to pandas. [Pandas
    User-defined functions](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.pandas_udf.html)
    (UDF) allow you to apply custom functions, which are usually computationally costly,
    in a distributed manner which can significantly reduce runtime. Databricks also
    allows you to configure jobs on larger machines which can be useful for dealing
    with large data and heavy computation. Further, the model registry allows you
    to run and store experiment results for hundreds or even thousands of models.
    This is useful in terms of scaling the number of models that are researcher develops
    and eventually deploys.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 Databricks 功能对于在机器学习工作流中的步骤进行扩展非常有用，例如数据加载、模型训练和模型日志记录。[Koalas](https://koalas.readthedocs.io/en/latest/user_guide/index.html)
    是 Databricks 中一个更高效的替代 pandas 的库。[Pandas 用户定义函数](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.pandas_udf.html)（UDF）允许你以分布式的方式应用自定义函数，这些函数通常计算成本较高，这可以显著减少运行时间。Databricks
    还允许你在更大的机器上配置作业，这对于处理大型数据和繁重计算非常有用。此外，模型注册表允许你运行和存储数百甚至数千个模型的实验结果。这在扩展研究人员开发并最终部署的模型数量方面非常有用。
- en: In this article, we will cover some of the basics of Databricks. First, we will
    walk through a simple data science workflow where we will build a churn classification
    model. We will then see how we can use tools like Koalas and Pandas UDF to speed
    up specific operations. Finally, we will see how we can use Mlflow to help us
    run experiments and inspect results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will be working with the [Telco churn data set](https://www.kaggle.com/datasets/blastchar/telco-customer-churn).
    This data contains customer billing information for a fictional Telco company.
    It specifies whether a customer stopped or continued using the service, known
    as churning. The data is publicly available and is free to use, share and modify
    under the [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To start, navigate to the [Databricks](https://www.databricks.com/try-databricks?itm_data=SiteWide-Footer-Trial#account)
    website and click on “Get Started for Free”:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1833bb5257a37267be55369da10dd456.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7132230adf1dd365961072333422b604.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Enter your information and click continue. Next you will be prompted to select
    a cloud platform. We won’t be working with any external cloud platforms in this
    article. At the bottom of the right-hand panel click on “Get Started with Community
    Edition”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/47b4cf8fadf2dc1b18ecdda54087b542.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Next follow the steps to create a Community Edition Account.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Importing Data
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start by navigating to the ‘data’ tab in left-hand panel:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/710105e82b0f331d186f3977383befea.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Next click on ‘data’ and then click on create table:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/82186947892e23899896d43944c6f617.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Next drag and drop the churn CSV file in the space where it says “Drop files
    to upload, or click to browse”
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aef4c8446f872bd219dc0a9697379116.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon uploading the CSV you should see the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f6159b520e0f8d5a8a600ca26ed1884.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'Next click on “Create Table in Notebook”. A Databricks filestore (DBFS) example
    notebook with logic for writing this file to the Databricks filestore will pop
    up:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9d5c8a6f415b7ec67c04372e63aa9ecf.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: DBFS allows Databricks users to upload and manage data. The system is distributed
    so it is very useful for storing and managing large amounts of data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'The first cell specifies logic for reading the Churn data we uploaded:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If we run this cell we get the following result:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e89cf88ee2e09b9320df833875babbe.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'We see that the table includes column names that aren’t very useful (_c0, _c1,
    … etc). To fix this we need to specify first_row_is_header= “true”:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When we run this cell, we now get:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c184ccb2e954b0405be52c3e2e73e2d4.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on the table you can scroll to the right and see the additional
    columns in the data:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/94ff60c5df24c025d4a7a23810c85e82.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Building a Classification Model
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s proceed by building a churn classification model using our uploaded data
    in Databricks. On the left hand panel click on ‘create’:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/00b82dbbe6d74f453ccd9374bf21b383.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Next click on notebook:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e4171ef867f29c334133c338ae695725.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s name our notebook “churn_model”:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07459b4fe80e8ee77549ac32d1cd8e88.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can copy the logic from the DBFS example notebook allowing us to access
    the data:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0c9c84a0c875711beccfd49796f6504d.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'Next let’s convert the spark dataframe into a Pandas dataframe:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s build a [Catboost](https://catboost.ai/en/docs/) classification model.
    Catboost is a tree-based ensemble machine learning algorithm that uses gradient
    boosting to improve the performance of the successive trees used in the ensemble.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s pip install the Catboost package. We do this in a cell at the top of
    the notebook:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be5bf3c5bf77210667036049c47f64cd.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'And let’s build a Catboost churn classification model. Let’s use tenure, monthly
    charges, and contract to predict churn outcome. Let’s convert the churn column
    to binary values:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Catboost allows us to handle categorical variables directly without the need
    to convert them to machine readable codes. To do this we just define a list that
    contains the names of the categorical columns:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When defining the Catboost model object we set the cat_features parameter equal
    to this list. Let’s split our data for training and testing:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And we can train out Catboost model. We’ll just use default parameter values:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And we can evaluate performance:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/b06f8c585dc03a0c56b49e5fcd11e531.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: Screenshot Taken by Author
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Koalas
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here we converted a spark dataframe to a pandas dataframe. This is fine for
    our small data set, but as data size grows Pandas becomes slow and inefficient.
    An alternative to Pandas is the [Koalas](https://koalas.readthedocs.io/en/latest/user_guide/index.html)
    library. Koalas is a package developed by Databricks that is a distributed version
    of Pandas. To use Koalas we can pip install Databricks at the top of our notebook:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And we import Koalas from databricks:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And to convert our spark dataframe to a Koalas dataframe we do the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Pandas UDF
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pandas UDF is another useful tool in databricks. It allows you to apply a function
    to a dataframe in a distributed manner. This is useful for increasing the efficiency
    of calculations done on large dataframes. For example, we can define a function
    that takes a data frame and builds a catboost model. We can then use Pandas UDF
    to apply this function at a grouped or categorical level. Let’s build a model
    for each value of internet service.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas UDF是Databricks中的另一个有用工具。它允许你以分布式方式应用函数到数据框上。这对于提高对大数据框进行计算的效率非常有用。例如，我们可以定义一个函数，该函数接受一个数据框并构建一个Catboost模型。然后我们可以使用Pandas
    UDF在分组或分类层次上应用这个函数。让我们为每个互联网服务值构建一个模型。
- en: 'To start we need to define our function and schema for Pandas UDF. The schema
    simply specifies the column names and their data types:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义Pandas UDF的函数和模式。模式简单地指定了列名及其数据类型：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next we will define our function. We will simply include the logic we defined
    earlier in a function called ‘build_model’. To use pandas UDF we add the decorator
    ‘@pandas_udf’:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将定义我们的函数。我们将把之前定义的逻辑简单地包含在一个名为‘build_model’的函数中。为了使用Pandas UDF，我们添加装饰器‘@pandas_udf’：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And we can include the model building logic in our function. We’ll also store
    the predictions and the true churn values in our dataframe:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在我们的函数中包含模型构建逻辑。我们还会将预测和真实流失值存储在我们的数据框中：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally we can apply this function to our dataframe. Let’s convert our Koalas
    dataframe back to a spark dataframe:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将这个函数应用到我们的数据框中。让我们将我们的Koalas数据框转换回spark数据框：
- en: '[PRE14]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And we can convert the resulting spark data frame to a Pandas dataframe (also
    can convert back to Koalas) and display the first five rows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以将生成的spark数据框转换为Pandas数据框（也可以转换回Koalas），并显示前五行：
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/7d7a6d6e0d90aa171bb314febfa49294.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d7a6d6e0d90aa171bb314febfa49294.png)'
- en: Screenshot Taken by Author
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: Even though we stored predictions, you can use Pandas UDF to store any information
    that you get as a result of a calculation done on a dataframe. An interesting
    excercise is to include accuracy score and precision score in the output spark
    dataframe for each internet service value.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们存储了预测结果，你也可以使用Pandas UDF来存储你在数据框计算结果中获得的任何信息。一个有趣的练习是将准确度评分和精确度评分包含在输出的spark数据框中，每个互联网服务值都有。
- en: Getting started with MLflow
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用MLflow
- en: 'Another useful tool in Databricks is MlFlow. MlFlow allows you to easily run,
    log and analyze experiments. For this demonstration we will work with the first
    model object we defined earlier in our notebook. Let’s pip install Mlflow at the
    top of our notebook:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在Databricks中，另一个有用的工具是MlFlow。MlFlow允许你轻松运行、记录和分析实验。在本演示中，我们将使用之前在笔记本中定义的第一个模型对象。让我们在笔记本的顶部使用`pip
    install Mlflow`：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'and import Mlflow:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 并导入Mlflow：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s proceed by setting an experiment name:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过设置实验名称继续：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/ece718ef0810f75c49e364d8783c5125.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ece718ef0810f75c49e364d8783c5125.png)'
- en: Screenshot Taken by Author
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: 'One thing we can log is the Catboost feature importance which will allow us
    to analyze which features are important for predicting churn:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以记录的一件事是Catboost特征重要性，这将帮助我们分析哪些特征对预测流失重要：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/61d697cf0cd3ade2fa45a47407969ff9.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61d697cf0cd3ade2fa45a47407969ff9.png)'
- en: Screenshot Taken by Author
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: 'We can then log our Catboost model using the log_model method:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用`log_model`方法记录我们的Catboost模型：
- en: '[PRE20]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We get a notification stating “Logged 1 run to an experiment in Mlflow”:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收到通知，说明“已记录1次实验运行到Mlflow”：
- en: '![](../Images/5dcbf7507226f71a575afc05f72460f3.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5dcbf7507226f71a575afc05f72460f3.png)'
- en: Screenshot Taken by Author
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: 'We can click on the run and see the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以点击运行并查看以下内容：
- en: '![](../Images/c9cdd08df9849da12ea2ec121b4e60a5.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9cdd08df9849da12ea2ec121b4e60a5.png)'
- en: Screenshot Taken by Author
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: This is where we can see metrics like model performance and model artifacts
    such as feature importance. Both of these we will show how to log in Mlflow shortly.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到模型性能和模型工件（如特征重要性）的指标。我们将很快展示如何在Mlflow中记录这两者。
- en: 'We can also click on the experiment:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以点击实验：
- en: '![](../Images/6746fb34aa53ee8160544871102f1002.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6746fb34aa53ee8160544871102f1002.png)'
- en: Screenshot Taken by Author
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: This is where we see each run associated with the experiment. This is useful
    for keeping track of experiments such as modifying Catboost parameters, training
    data, engineered features etc.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们可以看到与实验相关的每次运行。这对于跟踪实验如修改Catboost参数、训练数据、工程特征等非常有用。
- en: 'Finally, let’s log feature importance as an artifact, accuracy score and precision
    score as metrics, and the list of categorical inputs as a parameter:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将特征重要性记录为工件，将准确度分数和精确度分数记录为指标，并将分类输入列表记录为参数：
- en: '[PRE21]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'If we click on the run we see we logged feature importance, accuracy score
    and precision score, and categorical inputs:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们点击运行，我们可以看到记录了特征重要性、准确度分数和精确度分数，以及分类输入：
- en: '![](../Images/643d1f2fbfce6e299a1fc5b6c4fa401a.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/643d1f2fbfce6e299a1fc5b6c4fa401a.png)'
- en: Screenshot Taken by Author
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图
- en: The code in the Databricks notebook has been ported to a ipython file and is
    available in [GitHub](https://github.com/spierre91/medium_code/blob/master/data_bricks_tutorials/churn_model.ipynb).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks notebook 中的代码已移植到一个 ipython 文件，并可以在[GitHub](https://github.com/spierre91/medium_code/blob/master/data_bricks_tutorials/churn_model.ipynb)上获取。
- en: Conclusion
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this post, we discussed how to get started with Databricks. First, we saw
    how to add upload data to the DBFS. We then created a notebook and showed how
    to access the uploaded file in the notebook. We then proceed to discuss tools
    available in Databricks that help data scientists and researchers scale data science
    solutions. First, we saw how to convert spark dataframes to Koalas dataframe,
    which are a faster alternative to Pandas. We then saw how to apply customer functions
    to spark data frames using Pandas UDF. This is very useful for heavy computational
    tasks that need to be performed on large dataframes. Finally, we saw how to log
    metrics, parameters, and artifacts associated with modeling experiments. Having
    familiarity with these tools is important for anyone working in the data science,
    machine learning, and machine learning engineering spaces.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们讨论了如何开始使用 Databricks。首先，我们展示了如何将数据上传到 DBFS。然后，我们创建了一个 notebook，并展示了如何在
    notebook 中访问上传的文件。接着，我们讨论了 Databricks 中的一些工具，这些工具可以帮助数据科学家和研究人员扩展数据科学解决方案。首先，我们展示了如何将
    spark 数据框转换为 Koalas 数据框，后者是 Pandas 的更快替代品。然后，我们展示了如何使用 Pandas UDF 将自定义函数应用于 spark
    数据框。这对于需要在大型数据框上执行的重计算任务非常有用。最后，我们展示了如何记录与建模实验相关的指标、参数和工件。对这些工具的熟悉对于从事数据科学、机器学习和机器学习工程的人员来说非常重要。
