["```py\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n# Create data\nX, y = make_classification(random_state=42)\n\n# Split the data into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n```", "```py\n# Scale the data\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Train the random forest\nrandom_forest = RandomForestClassifier(n_estimators=10)\nrandom_forest.fit(X_train_scaled, y_train)\n\n# Predict with the random forest\nrandom_forest.predict(X_test_scaled)\n```", "```py\nfrom sklearn.pipeline import Pipeline\n\n# Create a pipeline that combines the scaling and training\npipe = Pipeline([\n  ('scaler', MinMaxScaler(feature_range=(0, 1))), \n  ('forest', RandomForestClassifier(n_estimators=10))\n])\n\n# Fit the pipeline to the training data\npipe.fit(X_train, y_train)\n\n# Predict with the random forest\npipe.score(X_test, y_test) \n```", "```py\n# Gives us the components of the pipeline\nprint(pipe.named_steps)\n\n# Output:\n{'scaler': MinMaxScaler(), 'forest': RandomForestClassifier(n_estimators=10)}\n\n# Can now access each of them\nprint(pipe.named_steps[\"forest\"])\n\n# Output:\nRandomForestClassifier(n_estimators=10)\n```", "```py\n# Gives us the number of features passed into the pipeline\nprint(pipe.n_features_in_)\n\n# Output:\n20\n```", "```py\nfrom sklearn.pipeline import make_pipeline\n\n# Automatically assign names to the components\npipe = make_pipeline(MinMaxScaler(), RandomForestClassifier(n_estimators=10))\nprint(pipe)\n\n# Output:\nPipeline(\n  steps=[\n    ('minmaxscaler', MinMaxScaler()),\n    ('randomforestclassifier',RandomForestClassifier(n_estimators=10))\n  ]\n)\n```"]