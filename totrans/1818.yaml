- en: 'Seamless CI/CD Pipelines with GitHub Actions on GCP: Your Tools for Effective
    MLOps'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012](https://towardsdatascience.com/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[THE FULL STACK 7-STEPS MLOPS FRAMEWORK](https://towardsdatascience.com/tagged/full-stack-mlops)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Lesson 7: Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using
    Github Actions.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/?source=post_page-----96f676f72012--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----96f676f72012--------------------------------)[](https://towardsdatascience.com/?source=post_page-----96f676f72012--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----96f676f72012--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----96f676f72012--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----96f676f72012--------------------------------)
    ¬∑19 min read¬∑Jun 15, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c34e9ba645996ba5d4b808f1f130f93.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial represents **lesson 7 out of a 7-lesson course** that will walk
    you step-by-step through how to **design, implement, and deploy an ML system**
    using **MLOps good practices**. During the course, you will build a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  prefs: []
  type: TYPE_NORMAL
- en: '*By the end of this course, you will understand all the fundamentals of designing,
    coding and deploying an ML system using a batch-serving architecture.*'
  prefs: []
  type: TYPE_NORMAL
- en: This course *targets mid/advanced machine learning engineers* who want to level
    up their skills by building their own end-to-end projects.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Table of Contents:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Lessons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lesson 7: Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using
    Github Actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lesson 7: Code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***At the end of this 7 lessons course, you will know how to:***'
  prefs: []
  type: TYPE_NORMAL
- en: design a batch-serving architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Hopsworks as a feature store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: design a feature engineering pipeline that reads data from an API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a training pipeline with hyper-parameter tunning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: implement a batch prediction pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Poetry to build your own Python packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy your own private PyPi server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: orchestrate everything with Airflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the predictions to code a web app using FastAPI and Streamlit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Docker to containerize your code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Great Expectations to ensure data validation and integrity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: monitor the performance of the predictions over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy everything to GCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a CI/CD pipeline using GitHub Actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If that sounds like a lot, don't worry. After you cover this course, you will
    understand everything I said before. Most importantly, you will know WHY I used
    all these tools and how they work together as a system.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. This course is designed to quickly read and replicate
    the code along the articles.**'
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the course, you will know how to implement the diagram below.
    Don't worry if something doesn't make sense to you. I will explain everything
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the architecture you will build during the course [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: By the **end of Lesson 7**, you will know how to manually deploy the 3 ML pipelines
    and the web app to GCP. Also, you will build a CI/CD pipeline that will automate
    the deployment process using GitHub Actions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Course Lessons:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Batch Serving. Feature Stores. Feature Engineering Pipelines.](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Training Pipelines. ML Platforms. Hyperparameter Tuning.](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Consume and Visualize your Model''s Predictions using FastAPI and Streamlit.
    Dockerize Everything.](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github
    Actions.**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[[Bonus] Behind the Scenes of an ‚ÄòImperfect‚Äô ML Project ‚Äî Lessons and Insights](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As Lesson 7 focuses on teaching you how to deploy all the components to GCP
    and build a CI/CD pipeline around it, for the full experience, we recommend you
    watch the other lessons of the [course](https://towardsdatascience.com/tagged/full-stack-mlops).
  prefs: []
  type: TYPE_NORMAL
- en: Check out [Lesson 4](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)
    to learn how to orchestrate the 3 ML pipelines using Airflow and [Lesson 6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
    to see how to consume the model's predictions using FastAPI and Streamlit.
  prefs: []
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We used a free & open API that provides hourly energy consumption values for
    all the energy consumer types within Denmark [1].
  prefs: []
  type: TYPE_NORMAL
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data has 4 main attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 ‚Äî divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total Consumption:** Total electricity consumption in kWh'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would in real-time.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4eab6debdb7ba94406b8d0a8e28e3438.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot from our web app showing how we forecasted the energy consumption
    for area = 1 and consumer_type = 212 [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data points have an hourly resolution. For example: "2023‚Äì04‚Äì15 21:00Z",
    "2023‚Äì04‚Äì15 20:00Z", "2023‚Äì04‚Äì15 19:00Z", etc.'
  prefs: []
  type: TYPE_NORMAL
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  prefs: []
  type: TYPE_NORMAL
- en: '*Check out the video below to better understand what the data looks like* üëá'
  prefs: []
  type: TYPE_NORMAL
- en: Course & data source overview [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'Lesson 7: Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using
    Github Actions.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of Lesson 7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within Lesson 7, I will teach you 2 things:'
  prefs: []
  type: TYPE_NORMAL
- en: How to manually deploy the 3 ML pipelines and the web app to GCP.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to automate the deployment process with a CI/CD pipeline using GitHub Actions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/a0fb9d4a6918ea3cfabd95f66a8c7fc3.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the final architecture with the Lesson 7 components highlighted in
    blue [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: In other words, you will take everything you have done so far and show it to
    the world.
  prefs: []
  type: TYPE_NORMAL
- en: As long your work sits on your computer, it can be the best ML solution in the
    world, but unfortunately, it won't add any value.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing how to deploy your code is critical to any project.
  prefs: []
  type: TYPE_NORMAL
- en: So remember‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: We will use GCP as the cloud provider and GitHub Actions as the CI/CD tool.
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical Concepts & Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**CI/CD:** CI/CD stands for continuous integration and continuous delivery.'
  prefs: []
  type: TYPE_NORMAL
- en: The CI step mainly consists of building and testing your code every time you
    push code to git.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CD step automatically deploys your code to multiple environments: dev,
    staging, and production.'
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your specific software requirements, you need or do not need all
    the specifications of a standard CI/CD pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you might work on a proof of concept. Then a staging environment
    might be overkill. But having a dev and production CD pipeline will drastically
    improve your productivity.
  prefs: []
  type: TYPE_NORMAL
- en: '**GitHub Actions:** GitHub Actions is one of the most popular CI/CD tools out
    there in the wild. It is directly integrated into your GitHub repository. The
    sweet part is that you don''t need any VMs to run your CI/CD pipeline. Everything
    is running on GitHub''s computers.'
  prefs: []
  type: TYPE_NORMAL
- en: You need to specify a set of rules within a YAML file, and GitHub Actions will
    take care of the rest. I will show you how it works in this article.
  prefs: []
  type: TYPE_NORMAL
- en: '***GitHub Actions*** *is entirely* ***free*** *for public repositories. How
    awesome is that?*'
  prefs: []
  type: TYPE_NORMAL
- en: As a side note. Using GitHub Actions, you can trigger any job based on various
    repository events, but using it as a CI/CD tool is the most common use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lesson 7: Code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[You can access the GitHub repository here.](https://github.com/iusztinpaul/energy-forecasting)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** All the installation instructions are in the READMEs of the repository.
    Here you will jump straight to the code.'
  prefs: []
  type: TYPE_NORMAL
- en: '*The code and instructions for Lesson 7 are under the following:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[***deploy/***](https://github.com/iusztinpaul/energy-forecasting/tree/main/deploy)‚Äî
    Docker and shell deploying files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***.github/workflows***](https://github.com/iusztinpaul/energy-forecasting/tree/main/.github/workflows)
    ‚Äî GitHub Actions CI/CD workflows'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***README_DEPLOY***](https://github.com/iusztinpaul/energy-forecasting/blob/main/README_DEPLOY.md)
    ‚Äî README dedicated to deploying the code to GCP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***README_CICD*** ‚Äî README dedicated to setting up the CI/CD pipeline'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepare Credentials
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Directly storing credentials in your git repository is a huge security risk.
    That is why you will inject sensitive information using a **.env** file.
  prefs: []
  type: TYPE_NORMAL
- en: The **.env.default** is an example of all the variables you must configure.
    It is also helpful to store default values for attributes that are not sensitive
    (e.g., project name).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/87b81fc121cea9485a6b41dd4d656eb8.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot of the .env.default file [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: To replicate this article, you must set up all the infrastructure and services
    used during the [course](https://towardsdatascience.com/tagged/full-stack-mlops).
  prefs: []
  type: TYPE_NORMAL
- en: '*2 main components can be deployed separately.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**#1\. The 3 ML pipelines:**'
  prefs: []
  type: TYPE_NORMAL
- en: Feature Pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training Pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batch Prediction Pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For **#1.**, you have to set up the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Hopsworks*](https://www.hopsworks.ai/) *(free)* ‚Äî Feature Store: [Lesson
    1](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*W&B*](https://wandb.ai/site) *(free)*‚Äî ML Platform: [Lesson 2](/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*GCS buckets*](https://cloud.google.com/storage) *(free)* ‚Äî Storage on GCP:
    [Lesson 3](/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Airflow*](https://airflow.apache.org/) *(free)*‚Äî Open source orchestration
    tool: [Lesson 4](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**#2\. Web App:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[*FastAPI*](https://fastapi.tiangolo.com/) *backend (free)*: [Lesson 6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Streamlit*](https://streamlit.io/) *Predictions Dashboard (free)*: [Lesson
    6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Streamlit*](https://streamlit.io/) *Monitoring Dashboard (free)*: [Lesson
    6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fortunately, for **#2.**, you have to set up only the GCP [GCS buckets](https://cloud.google.com/storage)
    used as storage.
  prefs: []
  type: TYPE_NORMAL
- en: But note that if you do only section **#2.**, you won't have any data to consume
    within your web app.
  prefs: []
  type: TYPE_NORMAL
- en: We don't want to overflow this article with boring stuff, such as setting up
    credentials. Still, fortunately, if you're going to implement and replicate the
    entire [course](https://towardsdatascience.com/tagged/full-stack-mlops), you have
    step-by-step instructions in previous articles and the [GitHub README](https://github.com/iusztinpaul/energy-forecasting).
  prefs: []
  type: TYPE_NORMAL
- en: If you want to see (and not replicate) how we deployed our code to GCP and built
    the GitHub Actions workflows, you don't have to bother with any of the credentials.
    Just proceed to the following sections ‚úåÔ∏è
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE:** The only service that doesn‚Äôt have a freemium plan is within this
    lesson. *When I wrote this course, deploying and testing the infrastructure on
    GCP cost me ~20$.* But I had a brand new GCP account that offered me 300$ in GCP
    credits, thus indirectly making it free of charge. Just remember to delete all
    the GCP resources when you are done, and you will be OK.'
  prefs: []
  type: TYPE_NORMAL
- en: Manually Deploy to GCP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, let''s manually deploy the *2 main components* to GCP:'
  prefs: []
  type: TYPE_NORMAL
- en: ML Pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web App
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But, as a first step, let's *set up all the GCP resources we need for the deployment*.
    After, you will SSH to your machines and deploy your code.
  prefs: []
  type: TYPE_NORMAL
- en: '[*For more info, access the GitHub deployment README.*](https://github.com/iusztinpaul/energy-forecasting/blob/main/README_DEPLOY.md)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Set Up Resources***'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs go to your GCP *energy_consumption* project and create the following
    resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Admin VM Service Account with IAP Access
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expose Ports Firewall Rule
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: IAP for TCP Tunneling Firewall Rule
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VM for the Pipeline
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VM for the Web App
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: External Static IP
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Don‚Äôt get discouraged by the fancy names. You will have access to step-by-step
    guides using this article + the GCP documentation I will provide.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** If you don‚Äôt plan to replicate the infrastructure on your GCP infrastructure,
    skip the ***‚ÄúSet Up Resources‚Äù*** section and go directly to ‚Äú***Deploy the ML
    Pipeline‚Äù***.'
  prefs: []
  type: TYPE_NORMAL
- en: '*#1\. Admin VM Service Account with IAP Access*'
  prefs: []
  type: TYPE_NORMAL
- en: We need a new GCP service account with admin rights & IAP access to the GCP
    VMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have to create a new service account and assign to it the following roles:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute Instance Admin (v1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IAP-secured Tunnel User
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service Account Token Creator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service Account User
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'IAP stands for Identity-Aware Proxy. It is a way to create tunnels that route
    TCP traffic inside your private network. For your knowledge, you can read more
    about this topic using the following docs (you don''t have to understand it to
    proceed to the next steps):'
  prefs: []
  type: TYPE_NORMAL
- en: '[Using IAP for TCP forwarding](https://cloud.google.com/iap/docs/using-tcp-forwarding)
    [2]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Overview of TCP forwarding](https://cloud.google.com/iap/docs/tcp-forwarding-overview)
    [3]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*#2\. Expose Ports Firewall Rule*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a firewall rule that exposes the following TCP ports: 8501, 8502, and
    8001.'
  prefs: []
  type: TYPE_NORMAL
- en: Also, add a *target tag* called *energy-forecasting-expose-ports*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are 2 docs that helped us create and configure the ports for the firewall
    rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to open a specific port such as 9090 in Google Compute Engine](https://stackoverflow.com/questions/21065922/how-to-open-a-specific-port-such-as-9090-in-google-compute-engine)
    [4]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Open Firewall Ports on a GCP Compute Engine Instance](https://www.howtogeek.com/devops/how-to-open-firewall-ports-on-a-gcp-compute-engine-instance/)
    [5]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here is what our firewall rule looks like üëá
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/97e2efc2f96dec4a2003b681538dc4a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the GCP "expose ports" firewall rule [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: '*#3\. IAP for TCP Tunneling Firewall Rule*'
  prefs: []
  type: TYPE_NORMAL
- en: Now we will create a firewall rule allowing IAP for TCP Tunneling on all the
    VMs connected to the *default* network.
  prefs: []
  type: TYPE_NORMAL
- en: '[Step-by-step guide on how to create the IAP for TCP tunneling Firewall rule](https://cloud.google.com/iap/docs/using-tcp-forwarding#preparing_your_project_for_tcp_forwarding)
    [6].'
  prefs: []
  type: TYPE_NORMAL
- en: Here is what our firewall rule looks like üëá
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b62ecb6aa11acc85634ecba689e6e98e.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the GCP "IAP TCP forwarding" firewall rule [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: '*#4\. VM for the Pipeline*'
  prefs: []
  type: TYPE_NORMAL
- en: Go to your GCP *energy_consumption* project -> VM Instances -> Create Instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose *e2-standard-2: 2 vCPU cores ‚Äî 8 GB RAM* as your VM instance type.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Call it: *ml-pipeline*'
  prefs: []
  type: TYPE_NORMAL
- en: Change the disk to *20 GB Storage*.
  prefs: []
  type: TYPE_NORMAL
- en: Pick region *europe-west3 (Frankfurt)*` and zone *europe-west3-c.* Here,you
    can pick any other region & zone, but if it is your first time doing this, we
    suggest you do it like us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Network: *default*'
  prefs: []
  type: TYPE_NORMAL
- en: Also, check the *HTTP* and *HTTPS* boxes and add the *energy-forecasting-expose-ports*
    custom firewall rule we did a few steps back.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are 2 docs that helped me create and configure the ports for the firewall
    rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to open a specific port such as 9090 in Google Compute Engine](https://stackoverflow.com/questions/21065922/how-to-open-a-specific-port-such-as-9090-in-google-compute-engine)
    [4]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Open Firewall Ports on a GCP Compute Engine Instance](https://www.howtogeek.com/devops/how-to-open-firewall-ports-on-a-gcp-compute-engine-instance/)
    [5]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*#5\. VM for the Web App*'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's repeat a similar process for the Web App VM, but with slightly different
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'This time choose *e2-micro: 0.25 2 vCPU ‚Äî 1 GB memory* as your VM instance
    type.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Call it: *app*'
  prefs: []
  type: TYPE_NORMAL
- en: Change the disk to *15 GB standard persisted disk*
  prefs: []
  type: TYPE_NORMAL
- en: Pick region *europe-west3 (Frankfurt)* and zone *europe-west3-c.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Network: *default*'
  prefs: []
  type: TYPE_NORMAL
- en: Also, check the *HTTP* and *HTTPS* boxes and add the *energy-forecasting-expose-ports*
    custom firewall rule we created a few steps back.
  prefs: []
  type: TYPE_NORMAL
- en: '*#6\. External Static IP*'
  prefs: []
  type: TYPE_NORMAL
- en: This is the last piece of the puzzle.
  prefs: []
  type: TYPE_NORMAL
- en: If we want the external IP for our web app to be static (aka not to change),
    we have to attach a static address to our web app VM.
  prefs: []
  type: TYPE_NORMAL
- en: We suggest adding it only to the *app* VM we created a few steps ahead.
  prefs: []
  type: TYPE_NORMAL
- en: Also, adding a static external IP to the ml-pipeline VM is perfectly fine.
  prefs: []
  type: TYPE_NORMAL
- en: '[Docs on reserving a static external IP address](https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address)
    [7].'
  prefs: []
  type: TYPE_NORMAL
- en: '*Now that the boring part is finished let''s start deploying the code üëá*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deploy the ML Pipeline**'
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, we must install the [gcloud GCP CLI tool](https://cloud.google.com/sdk/docs/install)
    to talk between our computer and the GCP VMs.
  prefs: []
  type: TYPE_NORMAL
- en: To authenticate, we will use the service account configured with admin rights
    for VMs and IAP access to SSH.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we must tell the *gcloud GCP CLI* to use that *service account*.
  prefs: []
  type: TYPE_NORMAL
- en: To do so, you must create a key for your service account and download it as
    a JSON file. Same as you did for the buckets service accounts ‚Äî [here are some
    docs to refresh your mind](https://cloud.google.com/iam/docs/keys-create-delete)
    [8].
  prefs: []
  type: TYPE_NORMAL
- en: 'After you download the file, you have to run the following *gcloud* command
    in your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[Check out this doc for more details about the *gcloud* auth command](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account).'
  prefs: []
  type: TYPE_NORMAL
- en: Now whenever you run commands with *gcloud*, it will use this service account
    to authenticate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s connect through SSH to the *ml-pipeline* GCP VM you created a few
    steps ahead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**NOTE 1:** Change the *zone* if you haven''t created a VM within the same
    zone as us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NOTE 2:** Your *project-id* is NOT your *project name*. Go to your GCP projects
    list and find the project id.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting this point, if you configured the firewalls and service account correctly,
    as everything is Dockerized, all the steps will be 99% similar to those from the
    rest of the articles.
  prefs: []
  type: TYPE_NORMAL
- en: Check out the Github README ‚Äî [*Set Up Additional Tools*](https://github.com/iusztinpaul/energy-forecasting#tools)
    and [*Usage*](https://github.com/iusztinpaul/energy-forecasting#usage) sections
    for step-by-step instructions.
  prefs: []
  type: TYPE_NORMAL
- en: You can follow the same steps while you are connected with SSH to the *ml-pipeline*
    GCP machine.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the GCP machine is using Linux as its OS. Thus, you can directly copy
    & paste the commands from the README regardless of the OS you use on your local
    device.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/32e7843fcd3316cc38aaff22d935fa92.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of connecting to the "app" VM using *gcloud* [Screenshot by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: You can safely repeat all the steps you've done setting *The Pipeline* locally
    using this SSH connection, ***but you have to keep in mind the following 3 edge
    cases*:**
  prefs: []
  type: TYPE_NORMAL
- en: '*#1\. Clone the code in the home directory of the VM*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just SHH to the VM and run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*#2\. Install Docker using the following commands:*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Add sudo access to Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Login again to your machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[Check out these docs for the full instructions](https://tomroth.com.au/gcp-docker/)
    [9].'
  prefs: []
  type: TYPE_NORMAL
- en: '*#3\. Replace all* ***cp*** *commands with* ***gcloud******compute******scp****:*'
  prefs: []
  type: TYPE_NORMAL
- en: This command will help you to copy files from your local machine to the VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, instead of running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Run in a different terminal (not the one connected with SSH to your VM):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This command will copy your local *admin-buckets.json* file to the *ml-pipeline*
    VM.
  prefs: []
  type: TYPE_NORMAL
- en: After setting up your code on the *ml-pipeline GCP VM,*go to your VM view from
    GCP and the *Network tags* section. There you will find the *External IP address*
    column, as shown in the image below. Copy that IP and attach port *8080* to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, based on the *External IP address* from the image below, I accessed
    Airflow using this address: *35.207.134.188:8080*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Congrats! You connected to your own self-hosted Airflow application.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** If it doesn''t connect, give it a few seconds to load properly.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/761ce29a89b33a55d06a796a2a7a6037.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the "app" GCP VM configurations [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: '**Deploy the Web App**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s connect using SSH to the *‚Äúapp‚Äù GCP VM* you created a few steps ahead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**NOTE 1:** Change the *zone* if you haven''t created a VM within the same
    zone as us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NOTE 2:** Your *project-id* is NOT your *project name*. Go to your GCP projects
    list and find the project id.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here the process is similar to the one described in the *‚Äú****Deploy the ML
    Pipeline‚Äù*** section*.*
  prefs: []
  type: TYPE_NORMAL
- en: You can deploy the web app following the steps described in [Lesson 6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
    or in the GitHub repository's [Set Up Additional Tools](https://github.com/iusztinpaul/energy-forecasting#tools)
    & [Usage](https://github.com/iusztinpaul/energy-forecasting#usage) sections.
  prefs: []
  type: TYPE_NORMAL
- en: But don‚Äôt forget to keep in mind the 3 edge cases described in the ‚Äú**Deploy
    the ML Pipeline‚Äù section.**
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Please excuse me for referring you to so much external documentation on how
    to set up this stuff. The article is too long, and I didn't want to replicate
    the GCP Google documentation here.
  prefs: []
  type: TYPE_NORMAL
- en: CI/CD Pipeline Using GitHub Actions (free)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The GitHub Actions YAML files are under the [***.github/workflows***](https://github.com/iusztinpaul/energy-forecasting/tree/main/.github/workflows)
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, let me explain the main components you have to know about a GitHub
    Actions file üëá
  prefs: []
  type: TYPE_NORMAL
- en: Using the "**on -> push -> branches:"** section, you specify which branch to
    listen to for events. In this case, the GitHub Action is triggered when new code
    is committed to the **"main"** branch.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the "**env: "**section, you can declare the environment variables you need
    inside the script.'
  prefs: []
  type: TYPE_NORMAL
- en: In the **"jobs -> ci_cd -> steps:"** section, you will declare the CI/CD pipeline
    steps, which will run sequentially.
  prefs: []
  type: TYPE_NORMAL
- en: In the **"jobs -> ci_cd -> runs-on:"** section, you specify the image of the
    VM you want the steps to run on.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at some actual GitHub Action files üî•
  prefs: []
  type: TYPE_NORMAL
- en: '[**ML Pipeline GitHub Actions YAML file**](https://github.com/iusztinpaul/energy-forecasting/blob/main/.github/workflows/ci_cd_ml_pipeline.yml)'
  prefs: []
  type: TYPE_NORMAL
- en: The action will be triggered when new code is committed to the **"main"** branch,
    except for the web app directories and the YAML and Markdown files.
  prefs: []
  type: TYPE_NORMAL
- en: We added environment variables that contain information about the GCP project
    and VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the CI/CD steps, we mainly do 2 things:'
  prefs: []
  type: TYPE_NORMAL
- en: configure the credentials & authenticate to GCP,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'connect with SSH on the given GCP VM and run a command that: goes to the code
    directory, pulls the latest changes, builds the Python packages, and deploys them
    to the PyPi registry. Now Airflow will use the new Python packages the next time
    it runs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Basically, it does what you would have done manually, but now, everything is
    nicely automated using GitHub Actions.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you don't have to remember or know how to write a GitHub Actions file
    from scratch, as you can find already written templates for most of the use cases.
    For example, here is the [*google-github-actions/ssh-compute*](https://github.com/google-github-actions/ssh-compute)
    [11] repository we used to write the YAML file below.
  prefs: []
  type: TYPE_NORMAL
- en: You will find similar templates for almost any use case you have in mind.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Web App GitHub Actions YAML file**](https://github.com/iusztinpaul/energy-forecasting/blob/main/.github/workflows/ci_cd_web_app.yml)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Web App actions file is 90% the same as the one used for the ML pipeline,
    except for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: we ignore the ML pipeline files;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: we run a docker command that builds and runs the web app.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'But where does the "**${{ vars‚Ä¶ }}"** weird syntax come from? I will explain
    in just a sec, but what you have to know now is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äú**${{ vars.<name> }}‚Äù:**variables set inside GitHub;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/206d07d81bb7ac16fc28daae15a6d535.png)'
  prefs: []
  type: TYPE_IMG
- en: ‚Äú**${{ secrets.<name> }}":** secrets set inside GitHub. Once a secret is set,
    you can't see it anymore (the variables you can);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d2e0ca9a85083a9bb94604bdf3f1ce92.png)'
  prefs: []
  type: TYPE_IMG
- en: '"**${{ env.<name> }}":** environment variables set in the "env:" section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Important Observation**'
  prefs: []
  type: TYPE_NORMAL
- en: The YAML file above doesn't contain the CI part, only the CD one.
  prefs: []
  type: TYPE_NORMAL
- en: To follow good practices for a robust CI pipeline, you should run an action
    that builds the Docker images and pushes them to a Docker registry.
  prefs: []
  type: TYPE_NORMAL
- en: Afterward, you would SSH to a testing environment and run your test suit. As
    a final step, you would SSH to the production VM, pull the images and run them.
  prefs: []
  type: TYPE_NORMAL
- en: The series got too long, and we wanted to keep it simple, but *the good news
    is that you learned all the necessary tools and principles to do what we described
    above*.
  prefs: []
  type: TYPE_NORMAL
- en: Set Secrets and Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, you have to fork the [energy-consumption repository](https://github.com/iusztinpaul/energy-forecasting/tree/main)
    to configure the GitHub Actions credentials with your own.
  prefs: []
  type: TYPE_NORMAL
- en: '[Check out this doc to see how to fork a repository on GitHub](https://docs.github.com/en/get-started/quickstart/fork-a-repo)
    [10].'
  prefs: []
  type: TYPE_NORMAL
- en: '**Set Actions Variables**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to your forked repository. After click on: *"Settings -> Secrets and variables
    -> Actions."*'
  prefs: []
  type: TYPE_NORMAL
- en: Now, click "*Variables."* You can create a new variable by clicking *"New repository
    variable."* See the image below üëá
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77290affdaf28b1c0a7e8e582dde9ed8.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of how to create a new repository variable [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: '*You have to create 5 variables that the GitHub Actions scripts will use:*'
  prefs: []
  type: TYPE_NORMAL
- en: '***APP_INSTANCE_NAME***: the name of the web app VM. In our case, it is called
    "*app"*. The default should be OK if you use our recommended naming conventions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GCLOUD_PROJECT**: the ID of your GCP Project. Here, you have to change it
    with your project ID.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ML_PIPELINE_INSTANCE_NAME**: the name of the ML pipeline VM. In our case,
    it is "*ml-pipeline"*. The default should be OK if you use our recommended naming
    conventions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**USER:** the user you used to connect to the VMs while settings up the machine
    using the SSH connection. Mine was "*pauliusztin,"* but you must change it with
    yours. Go to the VM and run `echo $USER` .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ZONE**: the zone where you deployed the VMs. The default should be OK if
    you use our recommended naming conventions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set Action Secrets**'
  prefs: []
  type: TYPE_NORMAL
- en: In the same *"Secrets and variables/Actions"* section, hit the *"Secrets"* tab.
  prefs: []
  type: TYPE_NORMAL
- en: You can create a new secret by pressing the ‚Äú*New repository secret‚Äù* button.
  prefs: []
  type: TYPE_NORMAL
- en: These are similar to the variables we just completed, but after you fill in
    their values, you can't see them anymore. That is why these are called secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Here is where you add all your sensitive information. In our case, the GCP credentials
    and private keys. See the image below üëá
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/711957b341193790f0d96ab36562a3cb.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of how to create a new repository secret [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: The *GCP_CREDENTIALS* secret contains the content of the JSON key of your VM
    admin service account. By settings this up, the CI/CD pipeline will use that service
    account to authenticate to the VMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the content of the file is in JSON format, to format it properly, you
    have to do the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the ***jq*** CLI tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Format your JSON key file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Take the output of this command and create your *GCP_CREDENTIALS* secret with
    it.
  prefs: []
  type: TYPE_NORMAL
- en: The *GCP_SSH_PRIVATE_KEY* is your GCP private SSH key (not your personal one
    ‚Äî GCP creates an additional one automatically), which was created on your local
    computer when you used SSH to connect to the GCP VMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'To copy it, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Copy the output from the terminal and create the *GCP_SSH_PRIVATE_KEY* variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Run the CI/CD Pipeline**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now make any change to the code, push it to the main branch, and the GitHub
    Actions files should trigger automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Check your GitHub repository's *‚ÄúActions‚Äù* tab to see their results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2f0dbd5116f137e359a12e45ba458765.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the GitHub Actions running logs on GitHub [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: Two actions will be triggered. One will build and deploy the *ml-pipeline* modules
    to your *ml-pipeline GCP VM*, and one will build and deploy the *web app* to your
    *app GCP VM*.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You finished the **last lesson** from the **Full Stack 7-Steps
    MLOps Framework** course. It means that now you are a full-stack ML engineer üî•
  prefs: []
  type: TYPE_NORMAL
- en: I apologize again for the highly technical article. It isn't a very entertaining
    read but a crucial step for finalizing this series.
  prefs: []
  type: TYPE_NORMAL
- en: 'In lesson 7, you learned how to:'
  prefs: []
  type: TYPE_NORMAL
- en: manually deploy the 3 ML pipelines to GCP;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: manually deploy the web app to GCP;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a CI/CD pipeline to automate the deployment process using GitHub Actions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you understand how to add real business value by deploying your ML
    system and putting it to work, it is time to build your awesome ML project.
  prefs: []
  type: TYPE_NORMAL
- en: '*No project is perfectly built, and this one is no exception.*'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, [check out our bonus lesson](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)
    of **The** **Full Stack 7-Steps MLOps Framework** course, where we will *openly
    discuss other design choices* we could have taken to *improve the ML system built
    during this course*.
  prefs: []
  type: TYPE_NORMAL
- en: I sincerely appreciate that you chose my course to learn MLE & MLOps‚úåÔ∏è
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs connect on [LinkedIn](https://www.linkedin.com/in/pauliusztin/), and let
    me know if you have any questions or just share the awesome projects you built
    after this course.
  prefs: []
  type: TYPE_NORMAL
- en: '[***Access the GitHub repository here.***](https://github.com/iusztinpaul/energy-forecasting)'
  prefs: []
  type: TYPE_NORMAL
- en: üí° My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  prefs: []
  type: TYPE_NORMAL
- en: üî• If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). Using [my
    referral link](https://pauliusztin.medium.com/membership), you can support me
    without extra cost while enjoying limitless access to Medium's rich collection
    of stories.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----96f676f72012--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  prefs: []
  type: TYPE_NORMAL
- en: ü§ñ Join to get exclusive content about designing and building production-ready
    ML systems üöÄ Unlock full access to‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----96f676f72012--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Thank you ‚úåüèº !
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Using IAP for TCP forwarding](https://cloud.google.com/iap/docs/using-tcp-forwarding),
    GCP Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [Overview of TCP forwarding](https://cloud.google.com/iap/docs/tcp-forwarding-overview),
    GCP Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Google Cloud Collective, [How to open a specific port such as 9090 in Google
    Compute Engine](https://stackoverflow.com/questions/21065922/how-to-open-a-specific-port-such-as-9090-in-google-compute-engine)
    (2017), Stackoverflow'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] ANTHONY HEDDINGS, [How to Open Firewall Ports on a GCP Compute Engine Instance](https://www.howtogeek.com/devops/how-to-open-firewall-ports-on-a-gcp-compute-engine-instance/)
    (2020), How-To Geek'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] [Preparing your project for IAP TCP forwarding](https://cloud.google.com/iap/docs/using-tcp-forwarding#preparing_your_project_for_tcp_forwarding),
    GCP Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] [Reserve a static external IP address](https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address),
    GCP Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] [Create and delete service account keys](https://cloud.google.com/iam/docs/keys-create-delete),
    GCP Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] Tom Roth, [Install Docker on a Google Cloud virtual machine](https://tomroth.com.au/gcp-docker/)
    (2018), Tom Roth Blog'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] [Fork a repo](https://docs.github.com/en/get-started/quickstart/fork-a-repo),
    GitHub Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] [GCP GitHub Actions Repository](https://github.com/google-github-actions/ssh-compute),
    GitHub'
  prefs: []
  type: TYPE_NORMAL
