# 正确采样偏差的推荐系统

> 原文：[https://towardsdatascience.com/correct-sampling-bias-for-recommender-systems-d2f6d9fdddec](https://towardsdatascience.com/correct-sampling-bias-for-recommender-systems-d2f6d9fdddec)

## 推荐中的采样偏差是什么？如何纠正？

[](https://medium.com/@vuphuongthao9611?source=post_page-----d2f6d9fdddec--------------------------------)[![Thao Vu](../Images/9d44a2f199cdc9c29da72d9dc4971561.png)](https://medium.com/@vuphuongthao9611?source=post_page-----d2f6d9fdddec--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d2f6d9fdddec--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d2f6d9fdddec--------------------------------) [Thao Vu](https://medium.com/@vuphuongthao9611?source=post_page-----d2f6d9fdddec--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d2f6d9fdddec--------------------------------) ·阅读时间8分钟·2023年10月1日

--

![](../Images/c5bbbc4ae0707318b5df926332f23574.png)

图片由 [NordWood Themes](https://unsplash.com/@nordwood?utm_source=medium&utm_medium=referral) 提供，[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上的照片

# **介绍**

推荐系统在我们的数字生活中无处不在，从电子商务巨头到流媒体服务。然而，每个大型推荐系统背后都隐藏着一个挑战，这可能显著影响其有效性——采样偏差。

在本文中，我将介绍采样偏差如何在训练推荐模型期间发生，以及我们如何在实践中解决这个问题。

让我们深入了解！

# 双塔推荐系统

通常，我们可以将推荐问题表述为：给定**查询 x**（可能包含用户信息、上下文、之前点击的项目等），找到用户可能感兴趣的项目集合***{y1,.., yk}***。

大规模推荐系统的主要挑战之一是低延迟要求。然而，用户和项目池庞大且动态，因此对每个候选项进行评分并贪婪地找到最佳项是不可能的。因此，为了满足延迟要求，推荐系统通常被分解为两个主要阶段：检索和排序。

![](../Images/b05b10e53d68e6a6fb6593cfb9be96a4.png)

多阶段推荐系统（作者提供的图像）

检索是一种廉价且高效的方式，可以从庞大的候选池（数百万或数十亿）中快速捕捉到顶级候选项（几百个）。检索优化主要涉及两个目标：

+   在训练阶段，我们希望将用户和项目编码为嵌入，以捕捉用户的行为和偏好。

+   在推理过程中，我们希望通过近似最近邻（ANN）快速检索相关项目。

对于第一个目标，常用的方法之一是双塔神经网络。该模型因通过结合物品内容特征来解决冷启动问题而获得了广泛的关注。

具体来说，查询和物品通过相应的DNN塔进行编码，以便相关的（查询，物品）嵌入保持彼此接近。

![](../Images/89574700e83ee66109c508f826ee5fe1.png)

双塔神经网络（图片来源于作者）

它可以被重新格式化为如下的多分类问题。

+   给定查询**x**和一系列物品**(y1, y2,..)**，我们输出一个概率向量，大小等于物品的数量，用于预测用户与物品**yi**互动的概率**pi**（~1: 是/~0: 否）。

+   对于训练数据，正标签表示用户已经点击/查看/购买了物品**yi**。负标签表示该物品**yi**已经展示给用户，但用户没有任何互动。

+   对于对（x，yi）对的处理，通过其相应的塔进行编码，得到**(emb_x, emb_yi)**。

+   **emb_x**和**emb_yi**的相似度可以通过点积或余弦相似度来测量，称为**sim_i**。

+   互动的概率通过如下的softmax概率进行测量，其中Z为标准化项。

![](../Images/b111de69d55254ab5eee1369c463e8ba.png)

Softmax概率（图片来源于作者）

# 折叠问题

模型的目标是对我们的数据集进行良好的泛化：它应该能够预测那些在训练数据中未出现的(**x*, y***)对的得分。

为此，我们需要教会模型，对于每个查询嵌入，好的物品嵌入应该被拉得更近，而无关的物品则应被推得更远。模型如何知道这些无关的物品？基于负样本。

构建负训练数据的最初方法之一是使用用户查看但未点击/查看/购买的物品。然而，每个用户仅查看和互动的物品很少，因此反馈相对稀疏，并且偏向特定的子群体。

如果我们仅在日志中出现的（x, y）对上训练模型，模型可能会很好地学习保持查询和匹配物品接近，但也可能偶然将查询和完全无关的物品放在一起。这个问题被称为“折叠”[4]。

因此，我们需要采样一些额外的负数据进行训练，以教会模型将无关的嵌入保持远离彼此。

但我们如何有效地收集这些负数据？

# 批次内负样本和偏差问题

最简单的解决方案是使用批次内负样本，我们使用同一批次中的其他物品作为负样本。

给定整个数据批次**(x1, y1), (x2, y2)**,…, **(x_bn, y_bn)**，对于每个样本**(xi, yi)**，我们将使用**(xi, yj)**作为批次内负样本。在下图中，蓝色线条表示正样本，红色线条表示批次内负样本。

![](../Images/c32eeed54aeb149b5d9ba37f8592942e.png)

批量负采样。（作者提供的图像）

批量负训练是一种简单且节省内存的方式，可以重用批量中已经存在的项目样本，而无需从整个项目语料库中采样和计算新的样本。

然而，它往往会受到采样偏差的影响，尤其是对于数据分布不均的情况。例如，考虑 YouTube 平台；一些热门视频可能有数十亿的观看次数，而大多数其他视频只有几百次观看。这些热门视频会在训练数据中比其他视频出现得更频繁。因此，它们更有可能被用作“批量负样本”，从而被过度惩罚。

我们如何解决这个偏差样本问题？

## 重要性采样

首先，我们需要定义什么是针对我们问题的理想和无偏采样。给定整个项目语料库 (y1, y2,…., yN)，对于每个正样本 (x, y)，我们希望告知模型语料库中的所有其他项目都是负样本。即，每个项目 y 应以相等的概率 p(y) = 1/N 进行采样。

因此理想情况下，归一化项 Z 应为：

![](../Images/d74bc2caf808d32b6ee4217883a98978.png)

从项目池中进行 Softmax 采样（作者提供的图像）

然而，由于对每个项目进行梯度更新所需的计算资源非常庞大，这几乎是不可能的。解决方案是使用 "**重要性采样**" [2]。我们仍然使用批量中的样本，但会“修正”其分布，使其反映上述无偏采样分布。

给定一个批量项目集 (y1, y2,..,yn) 和 **q(yi)** 是 **yi** 的批量采样概率，我们将按如下方式修正 **q**。

![](../Images/6e2acd53666de63d7df82e9cc4e5ed20.png)

偏差采样校正（作者提供的图像）

在公式中，**ri** 充当“修正”权重，使我们能够利用批量中的项目，但仍遵循正确的均匀分布。

这就是偏差校正的核心思想。接下来，让我们了解一下大型科技公司 Google 如何校正其推荐系统的采样偏差。

# 实践中的负采样校正

## 针对流数据的采样偏差校正

在这项工作 [1] 中，作者介绍了一种算法，用于校正流数据的偏差采样。由于推荐系统越来越接近实时更新，因此在线训练与流数据的结合是必要的。

![](../Images/dd630a0f47e0eccef475a0dd35fd0975.png)

推荐系统的在线训练 [1]

如上所述，我们可能需要访问整个训练数据集来校正采样偏差，以估计项目 y 的分布，**p(y)**。然而，测量流数据的分布几乎是不可能的。

论文建议根据包含 item_i 的两个连续批次之间的差距来估计 **p(yi)**。直观地说，差距越小，y 的受欢迎程度越高。

![](../Images/8b4a28741b4cdeb37ea4c76e3cf11abf.png)

样本频率估计 [1]

基于其受欢迎程度的估计，我们可以决定**y**应被惩罚多少作为批内负样本。**y**越受欢迎，对批量损失的影响应该越小。因此，它将受到更少的惩罚。

![](../Images/f4e3b593b6b340b4f94cf1ac6f8c28f9.png)

流数据的采样校正（图片由作者提供）

这种方法不需要固定的项词汇表，仍然可以产生无偏估计。此外，它可以适应在线项目分布随时间的变化。

为了研究策略的影响，团队在YouTube视频推荐上进行了离线评估实验，其中大约10M个视频的索引每隔几个小时周期性构建。在7天的评估期间，10%的数据日志被保留用于评估。与普通负采样相比，采样校正的方法在离线召回指标上取得了显著提升。

![](../Images/73eb3ef0842f03a02236f54ad1ff0589.png)

从YouTube上的10M视频语料库中检索点击视频页面的Recall@K。[1]

受到积极离线结果的鼓励，团队继续在线尝试新的检索方法。参与度指标也显著提高，证明了采样校正的有效性。

![](../Images/30d245a8e348ea893fe622f70a8a93fa.png)

YouTube直播实验结果[1]

## 混合负采样

这项工作[3]更进一步解决了偏差问题。论文提到了一种类型的偏差，“**选择性偏差**”，即没有用户反馈的项目将永远不会被纳入训练数据。因此，模型缺乏区分长尾项和其他项的通用性。

作者提出，除了批内负样本外，我们还从整个项目语料库中抽取负样本。因此，所有项目都有机会作为负样本。这对于模型了解新鲜和长尾项尤其有帮助。

除了批内项目B外，我们还从整个项目语料库中均匀地抽取项目作为额外的负样本，命名为B'。然后，采样将“校正”到上述方法类似。

![](../Images/1d981da885c4fcea41b485ad493cd9da.png)

混合负采样[3]

为了证明混合负采样的影响，团队在Google Play应用推荐中进行了实验。基线与两种负采样策略进行了比较：仅批内负采样和混合负采样。

与基线相比，两种负采样方法都将项目内容作为特征以改善通用性。然而，批内负采样组在离线和在线评估中表现均不如基线。对于这一组，团队观察到模型推荐中出现了一些无关的长尾应用。这支持了批内负采样存在选择性偏差的假设。长尾项没有频繁地被纳入训练数据，因此没有被应有地降级。

相比之下，混合负采样在离线和在线评估中均表现优越。即，对于在线AB测试，团队关注高质量的安装用户，即那些安装并使用应用程序的用户。混合负采样组以1.54%的显著差距获胜。

![](../Images/d2330ecb94e7cb867eb991bc040f81e1.png)

*Google Play数据集中几个模型的Recall@K [3]*

![](../Images/90e7a249b14c92940defc634ab4ea47c.png)

*Google Play上3个模型的实时实验结果。[3]*

# 参考文献

[1] 易欣阳, 等. "用于大规模语料库项目推荐的采样偏差修正神经建模。" *第十三届ACM推荐系统会议论文集*。2019年。

[2] [https://en.wikipedia.org/wiki/Importance_sampling](https://en.wikipedia.org/wiki/Importance_sampling)

[3] 杨继, 等. "用于推荐的双塔神经网络的混合负采样。" *2020年Web会议论文集*。2020年。

[4] 辛多丽丝, 等. "折叠：为什么好的模型有时会做出虚假的推荐。" *第十一届ACM推荐系统会议论文集*。2017年。
