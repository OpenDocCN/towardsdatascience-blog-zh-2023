- en: Use GPT Models to Generate Text Data for Training Machine Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/use-gpt-models-to-generate-text-data-for-training-machine-learning-models-3ff169ce5580](https://towardsdatascience.com/use-gpt-models-to-generate-text-data-for-training-machine-learning-models-3ff169ce5580)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A step-by-step guide in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jin-cui.medium.com/?source=post_page-----3ff169ce5580--------------------------------)[![Jin
    Cui](../Images/e5ddcbaa6d7da38f960d2c5fea71b538.png)](https://jin-cui.medium.com/?source=post_page-----3ff169ce5580--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3ff169ce5580--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3ff169ce5580--------------------------------)
    [Jin Cui](https://jin-cui.medium.com/?source=post_page-----3ff169ce5580--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3ff169ce5580--------------------------------)
    ·9 min read·Jul 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8915005799ca4a06d7b79a06fea29dd9.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Claudio Schwarz](https://unsplash.com/@purzlbaum?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data are fundamental to building Machine Learning models, yet text data for
    training Machine Learning models are difficult to collect for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Open-source text datasets are limited. Privacy rules and commercial confidentiality
    often restrict distribution of privileged data. In addition, publicly available
    datasets may not be licensed for commercial use, or more critically may not be
    context relevant. For example, IMDB movie reviews are unlikely to be meaningful
    for analysing customer sentiments towards Banking products.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine Learning models typically need a large amount of training data to perform.
    It may take a company, particularly a start-up, considerable time to collect a
    credible line of text data. In addition, these data may not have been labelled
    with a response variable for a specific Machine Learning task. For example, a
    company may have been collecting customer complaints verbatim, but may not necessarily
    have a granular understanding of the topics or sentiments of these complaints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we overcome the above constraints and generate fit-for-purpose text
    data in a scalable and cost-effective way? Given the recent advances in Large
    Language Models and Generative AI, this article* provides a tutorial on generating
    synthetic text data by calling [OpenAI’s GPT model suites](https://platform.openai.com/docs/models)
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate, let’s explore a use case of generating customer complaints data
    for an insurance company. With enriched text data for training language models,
    the use case is that the company could potentially achieve better customer outcomes
    by performing better in Natural Language Understanding tasks such as categorising
    complaints into topics or scoring complainant sentiments.
  prefs: []
  type: TYPE_NORMAL
- en: '**This article is 100% ChatGPT-free.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prerequisite: Setting up an OpenAI API key'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To be able to call the GPT models, simply register an account with OpenAI and
    access the API key under [User Settings](https://platform.openai.com/account/api-keys).
    Make sure to keep this key private.
  prefs: []
  type: TYPE_NORMAL
- en: Note that depending on usage, accessing GPT models comes with a [cost](https://openai.com/pricing),
    although this hasn’t been material for myself (<$0.08 USD for preparing this tutorial).
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Load the required Python packages'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 2: Generate a single customer complaint'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by generating one customer complaint data point using the *text-davinci-003*
    model under the GPT-3.5 model suites.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that with respect to the code above:'
  prefs: []
  type: TYPE_NORMAL
- en: You need to insert your private API key string in the first line of the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *prompt_text* helps the GPT model understand its role and thereby generate
    a customer complaint by responding to the question prompted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other parameters referenced in the code (*temperature, top_n, max_tokens, frequency_penalty
    and presence_penalty*) are explained in more detail in [this section](https://medium.com/towards-data-science/beginners-guide-to-the-gpt-3-model-2daad7fc335a#2b15)
    of my article.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The customer complaints generated by the above code are:'
  prefs: []
  type: TYPE_NORMAL
- en: '*I am writing to express my extreme dissatisfaction with the life insurance
    company I am a customer of. The time it has taken to assess my life insurance
    claim has been unacceptable and has had a horrible impact on my customer experience.
    I find it unacceptable that I have been waiting for so long to receive a response
    to my claim. I urge the company to take immediate action to address this issue
    and to ensure that all customers receive prompt and satisfactory responses in
    the future.*'
  prefs: []
  type: TYPE_NORMAL
- en: This seems reasonable and coherent at first glance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Generate customer complaints at scale'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may argue that you can simply replicate Step 2 by entering the *prompt_text*
    in ChatGPT. You are definitely right if you simply wish to generate limited number
    of data points. However, it’s not at all feasible to be repeating the exercise
    manually on the ChatGPT front-end for large scale text data generation. How do
    we then automate this task (ultimately scaling up the operation of generating
    customer complaints)? The answer lies in just a slight tweak to the code in Step
    2.
  prefs: []
  type: TYPE_NORMAL
- en: By design of the GPT models as well as the nature of the *temperature* parameter
    which determines the creativity and diversity of the generated texts, each run
    of the code in Step 2 generates a different customer complaint. Given this, we
    just need to set up a loop for running the code in Step 2 *n* times and storing
    the output of each of these runs.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate, the code below creates a loop for generating *n = 3* complaints
    and storing the output in a dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The snippet below shows the 3 customer complaints generated. Needless to say,
    the parameter *n* can be set to a number of your choice.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3ba2a79103e12bb256fa325f95cbe5f8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image 1: Generated customer complaints. Image by author.'
  prefs: []
  type: TYPE_NORMAL
- en: More Advanced Use Cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zero-shot vs. Few-shot training for GPT models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Providing standalone text prompts to GPT models per the use case above is considered
    **Zero-shot** training. Text data generated via Zero-shot training can be slightly
    generic for a specific task.
  prefs: []
  type: TYPE_NORMAL
- en: In a scenario where we already have limited but meaningful training data and
    would like to generate additional training data which provides some resemblance
    to the existing data, we can point the *prompt_text* input to existing data. This
    provides the GPT model **Few-shot** training.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, pretend we would like to Few-shot train a GPT model to generate
    some texts resembling the data from the IMDB movie review dataset (which is already
    stored by you in the *df_imdb* variable, hypothetically):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that this code also implicitly creates a label for the generated text data.
    In this instance, we are creating ‘positive’ reviews. Text data with a ‘negative’
    or ‘neutral’ label can be generated in a similar manner. This gives us a labelled
    dataset without any manual effort!
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, this code demonstrates that GPT models are able to generate data by
    recognising the pattern in the text prompt, without needing to be promoted with
    a question. In this instance, it’s been trained to give a movie review after being
    given the “REVIEW:” prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'To improve resemblance to existing data, we can even Few-shot train the GPT
    models with more than one data point from the existing data. This can be easily
    done by updating the *prompt_text* input to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Other GPT models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By far the *text-davinci-003* GPT model has been used to demonstrate the use
    cases in this article. Other [GPT models](https://platform.openai.com/docs/models/gpt-3-5)
    can also be called via the *engine* parameter as needed. For instance, some GPT
    models such as *gpt-3.5-turbo* are more powerful than others, but may need to
    be called differently in Python as they take a ‘dialogue’ as input as opposed
    to a text string.
  prefs: []
  type: TYPE_NORMAL
- en: The code below shows a call to the *gpt-3.5-turbo* model for generating complaints
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ae8d3b96c02e9093130985f58ee30139.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image 2: Generated customer complaints. Image by author.'
  prefs: []
  type: TYPE_NORMAL
- en: Risks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Whilst the use cases above demonstrate the ready-set-go implementation of the
    GPT models (or more broadly, Large Language Models), given that these models are
    relatively new, users may need to be cautious about the known and unknown inherent
    risks associated with integrating these models to real-life data and the way we
    work. Specific to generating text data for training Machine Learning models, putting
    my Risk and Governance hat on, below are the key (known) risks in my view when
    implementing the technology in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: There may be **Privacy** concerns with respect to providing certain type of
    input to GPT models via OpenAI’s API endpoints. This is relevant when companies
    are leveraging proprietary data to generate augmenting text data (as discussed
    in the **Advanced Use Cases** above), particularly when it comes to providing
    input such as customer complaints which contain personal information. One potential
    mitigation against this is to de-identify personal information in a pre-processing
    step to ensure complaints data are used on an anonymous basis. In addition, companies
    using this kind of technology need to develop guardrails and policies governing
    the use of private and sensitive information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For certain type of use cases, the text data generated by the GPT models may
    introduce **Biases**. For example, as GPT models were pre-trained based on large
    corpus of publicly available texts on the internet, for the task of generating
    both positive and negative customer feedback, it may inherently have bias towards
    the latter (i.e. customer complaints) under the assumption that these are more
    prominent on the internet. In addition, the texts generated may not be ‘fine-tuned’
    enough to cater for a specific product feature offered by a company as related
    texts may not be available on the internet. This ultimately presents a trade-off
    between efficient text data generation and usability of such data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With respect to **Recency**, although it’s expected that the GPT models will
    continue to receive updates, at time of writing most models were trained based
    on internet data up to September 2021 (i.e. almost 2 years ago).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other known risks associated with Large Language Models such as Hallucinations
    are less relevant in this context.
  prefs: []
  type: TYPE_NORMAL
- en: Concluding Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article offers a practical (and generative) way of some practical constraints
    to accessing textual data for training Machine Learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Taking a step back, with proper attention and care around risks, this article
    is an example of how users can access OpenAI’s GPT models from the ‘back-end’.
    This allows users to unlock commercial opportunities for using Large Language
    Models backing ChatGPT which was originally designed for individual ad-hoc use
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: '*Are you a fan of these practical tutorials on Machine Learning related topics?
    As I ride the AI/ML wave, I enjoy writing and sharing step-by-step guides and
    how-to tutorials in a comprehensive language with ready-to-run codes. If you would
    like to access all my articles (and articles from other practitioners/writers
    on Medium), you can sign up using* [*the link*](https://medium.com/@jin-cui/membership)
    *here!*'
  prefs: []
  type: TYPE_NORMAL
