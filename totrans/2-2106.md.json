["```py\nimport pandas as pd\n\nDATE_TIME_COLS = ['month', 'day', 'calendar_year', 'hour', 'water_year']\n\n# reading the data set\ndata = pd.read_csv(filepath)\n\n# parsing the datetime column\ndata['datetime'] = \\\n    pd.to_datetime([f'{year}/{month}/{day} {hour}:00'\n                    for year, month, day, hour in zip(data['calendar_year'],\n                                                      data['month'],\n                                                      data['day'],\n                                                      data['hour'])])\n\ndata = data.drop(DATE_TIME_COLS, axis=1).set_index('datetime')\ndata.columns = data.columns.str.replace('_dpt_C', '')\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nfrom src.tde import transform_mv_series\n\nN_LAGS, HORIZON = 12, 12\n\n# number of stations\nN_STATIONS = data.shape[1]\n\n# leaving last 20% of observations for testing\ntrain, test = train_test_split(data, test_size=0.2, shuffle=False)\n\n# computing the average of each series in the training set\nmean_by_location = train.mean()\n\n# mean-scaling: dividing each series by its mean value\ntrain_scaled = train / mean_by_location\ntest_scaled = test / mean_by_location\n\n# transforming the data for supervised learning\nX_train, Y_train = transform_mv_series(train_scaled, n_lags=N_LAGS, horizon=HORIZON)\nX_test, Y_test = transform_mv_series(test_scaled, n_lags=N_LAGS, horizon=HORIZON)\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, RepeatVector, TimeDistributed\n\nmodel = Sequential()\nmodel.add(LSTM(64, activation='relu', input_shape=(N_LAGS, N_STATIONS)))\nmodel.add(Dropout(.2))\nmodel.add(RepeatVector(HORIZON))\nmodel.add(LSTM(32, activation='relu', return_sequences=True))\nmodel.add(Dropout(.2))\nmodel.add(TimeDistributed(Dense(N_STATIONS)))\n\nmodel.compile(optimizer='adam', loss='mse')\n```", "```py\nfrom keras.callbacks import ModelCheckpoint\n\n# model checkpoint for saving the best model during training\nmodel_checkpoint = ModelCheckpoint(\n    filepath='best_model_weights.h5',\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)\n\n# fitting the model\nhistory = model.fit(X_train, Y_train,\n                    epochs=25,\n                    validation_split=0.2,\n                    callbacks=[model_checkpoint])\n```", "```py\n# The best model weights are loaded into the model after training\nmodel.load_weights('best_model_weights.h5')\n\n# predictions on the test set\npreds = model.predict_on_batch(X_test)\n```"]