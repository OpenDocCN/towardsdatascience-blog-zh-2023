["```py\nfrom transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\nmodel = AutoModel.from_pretrained(\"facebook/bart-large\")\n\ninputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\noutputs = model(**inputs)\n\nlast_hidden_states = outputs.last_hidden_state\nlast_hidden_states\n```", "```py\nengine=Python\noption.model_id=facebook/bart-large\noption.task=feature-extraction\n```", "```py\nnumpy\n```", "```py\nclass BartModel(object):\n    \"\"\"\n    Deploying Bart with DJL Serving\n    \"\"\"\n\n    def __init__(self):\n        self.initialized = False\n```", "```py\ndef initialize(self, properties: dict):\n        \"\"\"\n        Initialize model.\n        \"\"\"\n        logging.info(properties)\n\n        tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n        model = AutoModel.from_pretrained(\"facebook/bart-large\")\n        self.model_name = properties.get(\"model_id\")\n        self.task = properties.get(\"task\")\n        self.model = AutoModel.from_pretrained(self.model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.initialized = True\n```", "```py\ndef inference(self, inputs):\n        \"\"\"\n        Custom service entry point function.\n\n        :param inputs: the Input object holds the text for the BART model to infer upon\n        :return: the Output object to be send back\n        \"\"\"\n\n        #sample input: \"This is the sample text that I am passing in\"\n\n        try:\n            data = inputs.get_as_string()\n            inputs = self.tokenizer(data, return_tensors=\"pt\")\n            preds = self.model(**inputs)\n            res = preds.last_hidden_state.detach().cpu().numpy().tolist() #convert to JSON Serializable object\n            outputs = Output()\n            outputs.add_as_json(res)\n\n        except Exception as e:\n            logging.exception(\"inference failed\")\n            # error handling\n            outputs = Output().error(str(e))\n```", "```py\n_service = BartModel()\n\ndef handle(inputs: Input):\n    \"\"\"\n    Default handler function\n    \"\"\"\n    if not _service.initialized:\n        # stateful model\n        _service.initialize(inputs.get_properties())\n\n    if inputs.is_empty():\n        return None\n\n    return _service.inference(inputs)\n```", "```py\nimport sagemaker, boto3\nfrom sagemaker import image_uris\n\n# retreive DeepSpeed image\nimg_uri = image_uris.retrieve(framework=\"djl-deepspeed\", \nregion=region, version=\"0.21.0\")\n\n# create model tarball\nbashCommand = \"tar -cvpzf model.tar.gz model.py requirements.txt serving.properties\"\nprocess = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\noutput, error = process.communicate()\n\n# Upload tar.gz to bucket\nmodel_artifacts = f\"s3://{bucket}/model.tar.gz\"\nresponse = s3.meta.client.upload_file('model.tar.gz', bucket, 'model.tar.gz')\n```", "```py\nclient = boto3.client(service_name=\"sagemaker\")\n\nmodel_name = \"djl-bart\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprint(\"Model name: \" + model_name)\ncreate_model_response = client.create_model(\n    ModelName=model_name,\n    ExecutionRoleArn=role,\n    PrimaryContainer={\"Image\": img_uri, \"ModelDataUrl\": model_artifacts},\n)\nprint(\"Model Arn: \" + create_model_response[\"ModelArn\"])\n\nendpoint_config_name = \"djl-bart\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n\nproduction_variants = [\n    {\n        \"VariantName\": \"AllTraffic\",\n        \"ModelName\": model_name,\n        \"InitialInstanceCount\": 1,\n        \"InstanceType\": 'ml.g5.12xlarge',\n        \"ModelDataDownloadTimeoutInSeconds\": 1800,\n        \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600,\n    }\n]\n\nendpoint_config = {\n    \"EndpointConfigName\": endpoint_config_name,\n    \"ProductionVariants\": production_variants,\n}\n\nendpoint_config_response = client.create_endpoint_config(**endpoint_config)\nprint(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])\n\nendpoint_name = \"djl-bart\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\ncreate_endpoint_response = client.create_endpoint(\n    EndpointName=endpoint_name,\n    EndpointConfigName=endpoint_config_name,\n)\nprint(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n```", "```py\nruntime = boto3.client(service_name=\"sagemaker-runtime\")\nresponse = runtime.invoke_endpoint(\n    EndpointName=endpoint_name,\n    ContentType=\"text/plain\",\n    Body=\"I think my dog is really cute!\")\nresult = json.loads(response['Body'].read().decode())\n```"]