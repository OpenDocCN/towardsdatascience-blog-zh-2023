- en: PyTorch Introduction —Tensors and Tensor Calculations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pytorch-introduction-tensors-and-tensor-calculations-412ff818bd5b](https://towardsdatascience.com/pytorch-introduction-tensors-and-tensor-calculations-412ff818bd5b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn about Tensors and how to use them in one of the most famous machine learning
    libraries, pytorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ivopbernardo.medium.com/?source=post_page-----412ff818bd5b--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page-----412ff818bd5b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----412ff818bd5b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----412ff818bd5b--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page-----412ff818bd5b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----412ff818bd5b--------------------------------)
    ·8 min read·Nov 30, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b8413e710aba7c20bbd31cf22008112b.png)'
  prefs: []
  type: TYPE_IMG
- en: Math magic — Image Generated by AI
  prefs: []
  type: TYPE_NORMAL
- en: One of most important libraries in the Deep Learning field (and inclusively,
    where ChatGPT was built upon) is `pytorch`. Along with the Tensorflow framework,
    `pytorch` is one of the most famous neural network training frameworks available
    for software developers and data scientists. Apart from its usability and simple
    API, it excels in flexibility and memory usage, making it extremely fast in multi-dimensional
    calculus (one of the major components behind backpropagation, the important technique
    that is used to optimize Neural Network’s weights) — these details make it one
    of the most sought after libraries by companies when it comes to build Deep Learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this blog post, we’re going to check some basic operations using `pytorch`and
    understand how we can work with the `tensor` object! Tensors are mathematical
    representations of data that are commonly addressed by different names:'
  prefs: []
  type: TYPE_NORMAL
- en: '1 element Tensor: commonly called the scalar, consists of a single mathematical
    value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '1-Dimensional Tensor: consisting of *n* examples, they are normally called
    1-D vectors and stores different mathematical elements in a single dimension.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2-Dimensional Tensors: commonly called matrices, are able to store data in
    two dimensions. Think of a normal SQL table or an excel spreadsheet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3-Dimensional Tensors and beyond: Data organized with this dimensionality are
    normally harder to visualize and are generally called *n-dimensional* tensors*.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this small introduction on mathematical concepts, let’s explore how to
    use `pytorch` in Python!
  prefs: []
  type: TYPE_NORMAL
- en: The Tensor object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we’ve described, the tensor object is a mathematical generalization of *n-dimensional*
    objects that can expand to virtually any dimension. Although in the context of
    Deep Learning, `tensors` are generally multidimensional, we can also create single
    element tensors (normally called scalars) using `torch` (although named `pytorch`
    , we use the name `torch` to manipulate the library in Python).
  prefs: []
  type: TYPE_NORMAL
- en: If tensors are the central object in `torch` (or `pytorch` ), how can we create
    them in the library?
  prefs: []
  type: TYPE_NORMAL
- en: 'Super easy! Let’s create our first single-element tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `scalar` object contains a single number — 5\. Let’s visualize our tensor
    below by calling it in the Python console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a3593223add0044338cb8aa311c1030.png)'
  prefs: []
  type: TYPE_IMG
- en: scalar object — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Fact 1: `torch.tensor` is used to create tensor objects'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Of course, we are not only tied to single element tensors — we can also create
    1-dimensional objects with multiple elements. Let’s pass a list inside the`torch.tensor`
    and see how that will go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/05ff4daefab1efc39855aa600251e521.png)'
  prefs: []
  type: TYPE_IMG
- en: vector object — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Our object `vector` now contains two elements along a single dimension. Think
    as if this data contains 1 single row or a single column of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having “dimensions” allows us to access interesting properties in our tensor
    — for example `ndim`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/20a86d131a2a7168049f72deffaae26e.png)'
  prefs: []
  type: TYPE_IMG
- en: ndim of vector object — image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Fact 2: `*tensor.ndim*` is used to obtain the number of dimensions of a tensor
    object'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In our case, the `vector` object only has a single dimension. How can we know
    how many elements our tensor object has? By using another property - `shape` !
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7ebc201398505131cf4c64559f22d02e.png)'
  prefs: []
  type: TYPE_IMG
- en: shape of vector object — image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Fact 3: `*tensor.shape*`is used to obtain the shape of a tensor object'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our tensor object contains two elements in a single dimension. We’ll see how
    this output compares to multidimensional objects.
  prefs: []
  type: TYPE_NORMAL
- en: '`torch` tensors also contain a data type attached to it. To know which, we
    can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5d04609ab803207f60e42d4a13744a7f.png)'
  prefs: []
  type: TYPE_IMG
- en: dtype of vector object — image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Fact 4: `*tensor.dtype*` *outputs the object type of our tensor.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our tensor contains data in `int64` format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now expand our object into a 2-D tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/038f1a20195e8e9e6ef374f846b57495.png)'
  prefs: []
  type: TYPE_IMG
- en: matrix object — image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see some properties about our `matrix` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9f0f9f370b1cb20d6d6d0aacb4c1cfa3.png)'
  prefs: []
  type: TYPE_IMG
- en: ndim, shape and dtype of matrix object — image by author
  prefs: []
  type: TYPE_NORMAL
- en: Our `matrix` object contains data in `float32` dtype in two dimensions with
    2 elements each.
  prefs: []
  type: TYPE_NORMAL
- en: 'To finish our exploration on creating tensors, let’s see how we generate random
    tensors using `torch.rand` :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/042af5da88558fef9bd1c0bc403ca822.png)'
  prefs: []
  type: TYPE_IMG
- en: random tensor — image by author
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the tensor above, we are generating a 4 by 4 matrix using `tensor.rand`
    . This is a very common operation in the context of deep learning (for example,
    generating random neural network layer weights to optimize later).
  prefs: []
  type: TYPE_NORMAL
- en: Tensor Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s now see how we can perform operations with our tensors. If you’re already
    familiar with `numpy` , this should be pretty easy! Starting with a simple add
    operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c011825b3678c3959acd6e54f5b2f475.png)'
  prefs: []
  type: TYPE_IMG
- en: tensor + 10 calculation — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Adding a scalar to a tensor is easy — just use the normal mathematical operation!
    Can you guess how you can multiply a tensor by a scalar?
  prefs: []
  type: TYPE_NORMAL
- en: Easy!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/231ec78f551782b2a8faff7083a77d8f.png)'
  prefs: []
  type: TYPE_IMG
- en: tensor * 10 calculation — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use the abstraction `torch.multiply` :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/231ec78f551782b2a8faff7083a77d8f.png)'
  prefs: []
  type: TYPE_IMG
- en: tensor * 10 calculation — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Two of the most common operations with tensors are the [Hadamard](https://en.wikipedia.org/wiki/Hadamard_product_(matrices))
    and [Dot](https://en.wikipedia.org/wiki/Dot_product) Product, with the latter
    being one of the most famous calculations that is widely used in the [Attention](https://en.wikipedia.org/wiki/Attention_(machine_learning))
    mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create two 2-D tensors to check these operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/23e8ad1876d981a1c6674d7b19405994.png)'
  prefs: []
  type: TYPE_IMG
- en: tensor_1, a 2 by 3 tensor — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1c65872340eb8eac160c223c3be8b78f.png)'
  prefs: []
  type: TYPE_IMG
- en: tensor_2, a 3 by 2 tensor — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform the Hadamard product, the tensor shapes must match. Let’s perform
    a calculation of `tensor_1` with itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c65d2b0f5ef2237e2545847722fbaa8d.png)'
  prefs: []
  type: TYPE_IMG
- en: tensor_1 times tensor_1 — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'In case of the dot product, the inner dimensions of the tensors must match.
    Let’s multiply tensor_1 (a 2x3 tensor) by tensor_2 (a 3x2 tensor):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b9e45a13c9d19b0bf13817ec7972f819.png)'
  prefs: []
  type: TYPE_IMG
- en: dot product of tensor_1 with tensor_2 — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use the elegant @ operation, that does just the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1f27284e552a677066a8d19e212c1566.png)'
  prefs: []
  type: TYPE_IMG
- en: dot product of tensor_1 with tensor_2 — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Tensor Indexing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For our final examples, let’s see how we can pluck certain elements from our
    tensors. For these examples, we’ll use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b0502c943daafd92ef874f03bd991e87.png)'
  prefs: []
  type: TYPE_IMG
- en: 2-D Tensor example — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Indexing in `pytorch` is similar to other Python objects — let’s try to index
    the first column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/437768eee86f939199df84b0eba6f16a.png)'
  prefs: []
  type: TYPE_IMG
- en: 1st Row Example — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Using 0 index on the `[]` will give us the ability to extract the first row
    of the object. The `:` symbol enables us to extract all elements from a certain
    dimension. In our case, we want all elements from the columns (2nd dimension).
  prefs: []
  type: TYPE_NORMAL
- en: Can you guess how to extract the first column? Just switch the position of the
    indices!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1fd97f007ac58f2e361d693efded311c.png)'
  prefs: []
  type: TYPE_IMG
- en: 1st Column Example — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'For more complex objects, we can also use the same logic. Let’s try to index
    an element from a 3D `tensor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2089ea114dfb6cfa3186935b3d1400d8.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Tensor — Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we extract the element “100” from this tensor? Let’s see, we want:'
  prefs: []
  type: TYPE_NORMAL
- en: First row
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using indexing logic, we can do this easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/dfaa73d9d3a30a542e7eb6b80d6d1684.png)'
  prefs: []
  type: TYPE_IMG
- en: 100 element from indexing_example_3d— Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'In `torch`, the index ordering for 3d objects is the following: matrix, row,
    column.'
  prefs: []
  type: TYPE_NORMAL
- en: Can you try to index a 4D object?
  prefs: []
  type: TYPE_NORMAL
- en: Bonus —Where is the tensor stored?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the advantages of using `torch` over other array libraries (such as `numpy`
    ) is the ability to save our tensors in the `gpu` — this will be particularly
    useful if we need to speed up neural network calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, your tensors are stored on the `cpu` (and most computers only have
    a cpu available) but you can send your tensors to your `gpu` by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If `torch.cuda.is_available()` finds a specific NVIDIA gpu in your machine,
    it will let you send your tensor to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagining you have a tensor stored in a `tensor` named object, you can use
    the `.to` method to send it to the device:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thank you for taking the time to read this post! Working with tensors is extremely
    fun and definitely give you a solid foundation to work with advanced neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: The `torch` API is extremely elegant and easy to visualize. Later, you can use
    these tensors to train Neural Networks (something I’ll show in the next blog posts
    of this series). Additionally, learning a bit of linear algebra as you go will
    be extremely helpful to learn some other Data Science and Machine Learning Algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The inspiration for this post came from [https://www.learnpytorch.io/](https://www.learnpytorch.io/)
    — this is an excellent free course on the Pytorch topic and I definitely recommend
    it. At [DareData](https://www.daredata.engineering/), we’ve been involved with
    a lot of Deep Learning projects and I can’t stress how important this course has
    been to train our people into learning this Machine Learning paradigm and all
    frameworks associated with it.
  prefs: []
  type: TYPE_NORMAL
- en: In the next post, we’ll take a look into training a Linear Regression using
    `torch` — stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: '*If you would like to drop by my Python courses, feel free to join* ***my 16
    hour Python Course*** *(*[*The Complete Python Bootcamp for Beginners*](https://www.udemy.com/course/the-python-for-absolute-beginners-bootcamp/?couponCode=MEDIUMJULY)*).
    My Python courses are suitable for beginners/mid-level developers and I would
    love to have you on my class!*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9244c5c0a938984506d56f766b6e234a.png)'
  prefs: []
  type: TYPE_IMG
- en: Python for Absolute Beginners Bootcamp — Image by Author
  prefs: []
  type: TYPE_NORMAL
