- en: 'Visualized Linear Algebra to Get Started with Machine Learning: Part 2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过可视化线性代数入门机器学习：第 2 部分
- en: 原文：[https://towardsdatascience.com/visualized-linear-algebra-to-get-started-with-machine-learning-part-2-2ef075edb28b](https://towardsdatascience.com/visualized-linear-algebra-to-get-started-with-machine-learning-part-2-2ef075edb28b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/visualized-linear-algebra-to-get-started-with-machine-learning-part-2-2ef075edb28b](https://towardsdatascience.com/visualized-linear-algebra-to-get-started-with-machine-learning-part-2-2ef075edb28b)
- en: '![](../Images/d2e76020c623b0941be9848041656cea.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2e76020c623b0941be9848041656cea.png)'
- en: Photo by [Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Master elements of linear algebra, start with simple and visual explanations
    of basic concepts
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 掌握线性代数的基本元素，从简单和直观的基本概念讲解开始
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)
    ·7 min read·Feb 28, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)
    ·阅读时间7分钟·2023年2月28日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'In this article, we continue the work we started in *“*[*Visualized Linear
    Algebra to Get Started with Machine Learning: Part 1*](https://medium.com/towards-data-science/visualized-linear-algebra-to-get-started-with-machine-learning-part-1-245c2b6487f0)*”.*
    We tackle new concepts of linear algebra in a simple and intuitive way. These
    articles are intended to introduce you to the world of linear algebra and make
    you understand how strongly the study of this subject and other mathematical subjects
    is related to data science.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们继续在*“*[*通过可视化线性代数入门机器学习：第 1 部分*](https://medium.com/towards-data-science/visualized-linear-algebra-to-get-started-with-machine-learning-part-1-245c2b6487f0)*”*中开始的工作。我们以简单直观的方式探讨线性代数的新概念。这些文章旨在向你介绍线性代数的世界，并让你理解学习这一学科及其他数学学科与数据科学的紧密关系。
- en: Index
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 索引
- en: Solve Equations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解方程
- en: Determinants
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行列式
- en: Advanced Changing Basis
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级换基
- en: Eigenvalues and Eigenvectors
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征值和特征向量
- en: Calculating Eigenvalues and Eigenvectors
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算特征值和特征向量
- en: Solve Equations
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解方程
- en: Let’s finally try to understand how to solve equations simultaneously. You will
    by now have become familiar with writing equations compactly using matrices and
    vectors, as in this example.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们尝试理解如何同时解决方程。到现在你应该已经熟悉了如何使用矩阵和向量紧凑地写出方程，如本例所示。
- en: '![](../Images/09673025fc7f3d880a1ce35412382170.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09673025fc7f3d880a1ce35412382170.png)'
- en: Equation (Image By Author)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 方程（图像由作者提供）
- en: Finding the vector of unknowns r = [a,b], is quite straightforward; we only
    need to **multiply the left and right sides of the equation by the inverse of
    matrix A**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找未知向量r = [a,b]非常直接；我们只需**将方程的左右两侧分别乘以矩阵A的逆矩阵**。
- en: '![](../Images/6e6c91c9ef24ce3dc06eb7a65d177e3d.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e6c91c9ef24ce3dc06eb7a65d177e3d.png)'
- en: Solve Equation (Image By Author)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 解方程（图像由作者提供）
- en: We see that **A^-1 and A cancel**, **since multiplication for a matrix by its
    inverse always gives the identity matrix** (that is, the matrix that has all 1’s
    on the main diagonal and zero elsewhere). And so we find the value of r.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到**A^-1和A相互抵消**，**因为矩阵与其逆矩阵的乘积总是得到单位矩阵**（即主对角线上的所有元素都是1，其余位置为零的矩阵）。因此，我们找到了r的值。
- en: But in order to do this we have to **compute A^-1 which may not be too simple**.
    Often programming languages have algorithms already implemented that are very
    efficient in calculating the inverse matrix, so you will always have to use those.
    But in case you want to learn how to do this calculation by hand you will have
    to use [Gaussian Elimination](https://en.wikipedia.org/wiki/Gaussian_elimination).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但为了做到这一点，我们必须**计算A^-1，这可能并不简单**。通常编程语言中已经实现了非常高效的算法来计算逆矩阵，所以你将始终需要使用这些算法。但如果你想学习如何手动进行这个计算，你将需要使用[高斯消元法](https://en.wikipedia.org/wiki/Gaussian_elimination)。
- en: This is for **example how you compute the inverse by using numpy** in Python.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是**如何使用numpy在Python中计算逆矩阵的示例**。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Determinants
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行列式
- en: The determinant is another fundamental concept in line algebra. It is often
    taught in college how to calculate it but not what it is. **We can associate a
    value with each matrix, and that value is precisely the determinant.** However,
    **you can think of the determinant as the area of the deformed space.**
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式是线性代数中的另一个基本概念。它通常在大学中教授如何计算，但不一定解释它的含义。**我们可以将一个值与每个矩阵关联，这个值正是行列式。**然而，**你可以将行列式视为变形空间的面积。**
- en: We have seen how each matrix is simply a deformation of space. Let us give an
    example.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到每个矩阵实际上都是空间的变形。让我们举个例子。
- en: '![](../Images/6e783be648bf40855df37309cedbfda8.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e783be648bf40855df37309cedbfda8.png)'
- en: Determinant (Image By Author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式（图源作者）
- en: If we calculate the area of the new space, as shown in the figure, **this area
    is precisely the determinant associated with the starting matrix**. In this case
    the determinant = a*d.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们计算新空间的面积，如图所示，**这个面积正是与起始矩阵相关的行列式**。在这种情况下，行列式 = a*d。
- en: Certainly, we have matrices that can describe somewhat more complex deformations
    of space, and in that case, it may not be so trivial to calculate the area i.e.,
    the determinant.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们有能够描述较复杂空间变形的矩阵，在这种情况下，计算面积即行列式可能并不那么简单。
- en: For this, **there are known formulas for calculating the determinant.** For
    example, let us see the formula for calculating the determinant of a 2x2 matrix.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，**有已知的公式用于计算行列式**。例如，我们来看一下计算2x2矩阵的行列式的公式。
- en: '![](../Images/215de97a712e2fcfb7393c1fc7caa723.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/215de97a712e2fcfb7393c1fc7caa723.png)'
- en: Compute Determinant od 2x2 Matrix (Image By Author)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 计算2x2矩阵的行列式（图源作者）
- en: You can look [here](https://www.mathsisfun.com/algebra/matrix-determinant.html)
    to learn how to calculate the determinant in general cases with larger matrices.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看[这里](https://www.mathsisfun.com/algebra/matrix-determinant.html)了解如何在更大的矩阵的一般情况下计算行列式。
- en: If you think about it, however, **there are transformations that do not create
    any area**. Let’s look at the following example.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，**有些变换不会产生任何面积**。让我们看一个例子。
- en: '![](../Images/711fd2225466327da0bf2273a9ad3aea.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/711fd2225466327da0bf2273a9ad3aea.png)'
- en: Det equal zero (Image By Author)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式等于零（图源作者）
- en: In this example, the **matrix does not allow us to create any area, so we have
    a determinant equal to zero**.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，**矩阵不允许我们创建任何面积，所以行列式等于零**。
- en: But what is the use of knowing the determinant? We have seen that to solve simultaneous
    equations we need to be able to calculate the inverse of a matrix.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 那么了解行列式有什么用呢？我们已经看到了解决联立方程时需要能够计算矩阵的逆。
- en: But **the inverse of a matrix does not exist if the determinant is equal to
    zero**! That is why it is important to know how to calculate it, to know if there
    are solutions to the problem.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但是**如果行列式等于零，矩阵的逆不存在**！这就是为什么了解如何计算行列式非常重要，以便知道是否存在问题的解决方案。
- en: '**You can think of the inverse matrix, as a way of transforming the space back
    to the original space**. But when a matrix causes, not an area but only a segment
    to be created, and then makes us go from 2d to 1d space, the inverse matrix does
    not have enough information and will never be able to make us go back to the original
    space in 2d from that in 1d.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**你可以将逆矩阵视为将空间转换回原始空间的一种方法**。但当一个矩阵造成的不是一个面积，而只是一个线段，然后使我们从二维空间变到一维空间时，逆矩阵没有足够的信息，永远无法使我们从一维空间回到二维的原始空间。'
- en: Advanced Changing Basis
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级基变换
- en: We have already seen in the previous article the basic example of changing the
    basis, but now let’s look at a somewhat more complex example.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在之前的文章中看到了基本的基变换示例，但现在让我们看一个稍微复杂一点的例子。
- en: Let’s **imagine the existence of two worlds**, **ours and Narnia’s**. In our
    world, we use the vectors e1 and e2 as our reference vectors, as the basis. Thanks
    to these vectors we are able to create others and assign coordinates to them.
    For example, we can create the vectors [1,1], and [3,1].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们**想象存在两个世界**，**我们的世界和纳尼亚的世界**。在我们的世界中，我们使用向量e1和e2作为我们的参考向量，即基向量。感谢这些向量，我们能够创建其他向量并给它们指定坐标。例如，我们可以创建向量[1,1]和[3,1]。
- en: '![](../Images/ced0f6c5e3f2dce29e7f0a53b63fab1a.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ced0f6c5e3f2dce29e7f0a53b63fab1a.png)'
- en: Our world (Image By Author)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的世界（图像作者提供）
- en: In the world of Narnia though, they use different vectors as a base. Can you
    guess which ones they use? Just the ones we call [1,1] and [3,1].
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在纳尼亚的世界中，他们使用不同的向量作为基。你能猜到他们使用的是哪些吗？就是我们称为[1,1]和[3,1]的那些。
- en: '![](../Images/3cdd01b4b9e834aa7e37e036b3e57158.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cdd01b4b9e834aa7e37e036b3e57158.png)'
- en: Narnia’s world (Image By Author)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 纳尼亚的世界（图像作者提供）
- en: The people of Narnia will then use this basis of theirs to define other vectors
    of space, for example, they may define the vector [3/2, 1/2].
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 纳尼亚的人们将使用他们的这个基来定义空间中的其他向量，例如，他们可能会定义向量[3/2, 1/2]。
- en: '![](../Images/594255b6dd8c12cbacc2db9eead5b12c.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/594255b6dd8c12cbacc2db9eead5b12c.png)'
- en: Vector In Narnian’s world (Image By Author)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 纳尼亚世界中的向量（图像作者提供）
- en: 'Well, now what I want to find out is: **how do I define that red vector based
    on the coordinates of my world**?'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我想要找出的就是：**如何根据我的世界中的坐标定义那个红色向量**？
- en: We have already seen this, we take the vectors that form the basis of Narnia
    but expressed in the coordinates of my world, so [1,1] and [3,1]. We put them
    in a matrix and multiply this matrix by the red vector.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到这一点，我们取纳尼亚基的向量，但用我们世界中的坐标表示，即[1,1]和[3,1]。我们将它们放入一个矩阵中，并将这个矩阵与红色向量相乘。
- en: '![](../Images/f0e3f981b508bd3d92bbb1841c67841a.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0e3f981b508bd3d92bbb1841c67841a.png)'
- en: Changing Basis (Image By Author)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 改变基（图像作者提供）
- en: 'Now we ask: **can we do the reverse as well? Can I express a vector of my world
    according to the coordinates they use in Narnia? Of course!**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们问：**我们也能反向操作吗？我能根据纳尼亚使用的坐标来表达我们世界中的一个向量吗？当然可以！**
- en: '**It will suffice to do the same process but change the point of view**. But
    why do we do all this? **Very often when we have to describe vectors or transformations,
    we have a much simpler notation if we use a different basis.**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**只需做相同的过程，但改变视角**。但我们为什么要这么做？**当我们需要描述向量或变换时，如果使用不同的基，通常会有更简单的表示方法**。'
- en: '**Suppose we want to apply an R-transformation to a vector. But this transformation
    turns out to be difficult to apply. Then we can first transform my vector into
    a vector in the world of Narnia by applying the matrix N. After that we apply
    the desired transformation R. And then we bring everything back to our original
    world with N^-1.**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**假设我们想对一个向量应用R变换。但是这个变换难以应用。那么我们可以先通过应用矩阵N将我的向量转换成纳尼亚世界中的向量。然后应用所需的变换R。最后，用N^-1将一切带回到我们原来的世界。**'
- en: This is something that can be very useful and make life easier when we are dealing
    with complex transformations. I hope I have at least given you some insight; there
    is so much more to talk about.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这在处理复杂变换时可以非常有用，使生活变得更简单。我希望我至少给你提供了一些见解；还有很多内容可以讨论。
- en: Eigenvalues and Eigenvectors
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征值和特征向量
- en: We have already repeated several times that **applying a linear transformation
    (a matrix) to a vector transforms that vector.**
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经多次提到**对向量应用线性变换（一个矩阵）会改变那个向量**。
- en: However, there are cases in which the vector remains in the same initial direction.
    Think for example the case where we simply **scale the space**. If we visualize
    **the horizontal and the vertical vector these remain in the same direction although
    they get longer or shorter.**
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，向量保持在相同的初始方向上。比如说，**如果我们只是缩放空间**。如果我们可视化**水平和垂直向量，它们虽然变长或变短，但仍保持在相同的方向上**。
- en: '![](../Images/a9fcacf9021dc43981ee78278c454d08.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9fcacf9021dc43981ee78278c454d08.png)'
- en: Scale Space (Image By Author)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放空间（图像作者提供）
- en: We see in the image above that the linear transformation applied here is that
    of scaling. But if we try to understand what happens to each individual vector
    we notice that the red vectors still maintain the same direction.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图像中我们可以看到，这里的线性变换是缩放变换。但是如果我们试图理解每个单独向量发生了什么，我们会发现红色向量仍然保持相同的方向。
- en: '**These vectors that maintain the same direction are called Eigenvectors of
    the matrix that described this transformation.**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**这些保持相同方向的向量被称为描述该变换的矩阵的特征向量。**'
- en: In particular, the vertical red vector has remained unchanged, so let’s say
    it has eigenvalue =1 while the other red vector has doubled so let’s say it has
    eigenvalue =2.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，垂直的红色向量保持不变，所以我们可以说它的特征值是 =1，而另一个红色向量则翻倍了，所以我们可以说它的特征值是 =2。
- en: Obviously depending on the matrix, and thus the transformation, the number of
    eigenvectors may vary.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，根据矩阵的不同，因此变换的不同，特征向量的数量可能会有所不同。
- en: Calculating Eigenvalues and Eigenvectors
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算特征值和特征向量
- en: Let us now try to convert what we have expressed in words into a mathematical
    formula. So eigenvectors are those vectors to which when a matrix is applied they
    do not change, at most they lengthen or shorten.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试将我们用文字表达的内容转换为数学公式。所以特征向量是指当矩阵作用于它们时，它们不发生变化，最多只是变长或变短。
- en: '![](../Images/aeaff76b7e9cc98b998ba7a59f3312ad.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aeaff76b7e9cc98b998ba7a59f3312ad.png)'
- en: Calculate Eigenvectors (Image By Author)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 计算特征向量（图片来源：作者）
- en: In the formula A is a matrix, x is a vector and lambda is a scalar. If the condition
    is satisfied we say that x is an eigenvector of A with the corresponding eigenvalue
    lambda.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在公式中，A 是一个矩阵，x 是一个向量，lambda 是一个标量。如果条件满足，我们称 x 是 A 的特征向量，对应的特征值为 lambda。
- en: By solving the previous equation we can find the value of the eigenvalues that
    solve the equation, let’s see how to do it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解前面的方程，我们可以找到解决该方程的特征值，来看一下如何做。
- en: '![](../Images/7481cdb1a52ac0969491638a87c28dd6.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7481cdb1a52ac0969491638a87c28dd6.png)'
- en: Characteristic polynomial (Image By Author=
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 特征多项式（图片来源：作者）
- en: Once the eigenvalues have been found, it will suffice to substitute them into
    the following equation to find the eigenvectors.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦找到了特征值，只需将它们代入以下方程即可找到特征向量。
- en: '![](../Images/dfda3d33ac32db54c7ed4f57de91be54.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfda3d33ac32db54c7ed4f57de91be54.png)'
- en: Find eigenvectors (Image By Author)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 查找特征向量（图片来源：作者）
- en: Final Thoughts
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终想法
- en: I hope you have found some useful insights in this article and that you have
    understood them without too much effort. The purpose is to get a little familiar
    with these terms and linear algebra elements. In this way, I hope that the next
    time you go to look at the documentation of sklearn or some library you will be
    able to better understand what that particulate function you are using is actually
    doing! [😊](https://emojipedia.org/smiling-face-with-smiling-eyes/)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你在这篇文章中找到了一些有用的见解，并且能够毫费力气地理解它们。目的是让你对这些术语和线性代数元素有一点了解。这样，我希望下次你查看 sklearn
    或其他库的文档时，能够更好地理解你使用的特定函数实际上在做什么！ [😊](https://emojipedia.org/smiling-face-with-smiling-eyes/)
- en: The Ends
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束
- en: '*Marcello Politi*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*Marcello Politi*'
- en: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [CV](https://march-08.github.io/digital-cv/)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [CV](https://march-08.github.io/digital-cv/)'
