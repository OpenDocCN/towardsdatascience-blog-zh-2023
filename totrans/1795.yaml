- en: Running Airflow DAG Only If Another DAG Is Successful
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/run-airflow-dag-if-another-dag-succeeds-233aaa4118c1](https://towardsdatascience.com/run-airflow-dag-if-another-dag-succeeds-233aaa4118c1)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using Airflow sensors to control the execution of DAGs on a different schedule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://gmyrianthous.medium.com/?source=post_page-----233aaa4118c1--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----233aaa4118c1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----233aaa4118c1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----233aaa4118c1--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----233aaa4118c1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----233aaa4118c1--------------------------------)
    ·11 min read·Dec 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3de6a6755eaa5db34e2a4adb3bcbeffe.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by [DALL-E2](https://openai.com/dall-e-2)
  prefs: []
  type: TYPE_NORMAL
- en: Recently, I’ve been trying to coordinate two Airflow DAGs such that one would
    only run — on its own hourly schedule — if the other DAG (running on a daily basis)
    has been successful.
  prefs: []
  type: TYPE_NORMAL
- en: In today’s tutorial I will walk you through the use case and demonstrate how
    to achieve the desired behaviour in three different ways; two using the `ExternalTaskSensor`
    and another one using a customised approach with `PythonOperator`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use Case: Running the hourly DAG only if the daily DAG succeeded'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s get started with our use case that involves two Airflow DAGs.
  prefs: []
  type: TYPE_NORMAL
- en: The first DAG, `my_daily_dag`, runs every day at 5AM UTC.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The second DAG, `my_hourly_dag`, runs on an hourly basis, between 6AM and 8PM
    UTC.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In our use case, we would like `my_hourly_dag` to run only if `my_daily_dag`
    has ran successfully within the current date. If not, then `my_hourly_dag` should
    be skipped. It is important to mention here that we don’t want to trigger `my_hourly_dag`
    as soon as `my_daily_dag` succeeds. That would be achievable with `TriggerDagRun`
    operator. Instead, we want both DAGs to run on their own schedule but add a condition
    on the `my_hourly_dag`.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/airflow-skip-task-a5a6ab319378?source=post_page-----233aaa4118c1--------------------------------)
    [## How to Skip Tasks in Airflow DAGs'
  prefs: []
  type: TYPE_NORMAL
- en: Skipping tasks in Airflow DAGs based on specific conditions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/airflow-skip-task-a5a6ab319378?source=post_page-----233aaa4118c1--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In the next two sections we will discuss and demonstrate how to achieve this
    using a few different approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Determining the execution_date of both DAGs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before jumping into implementation details, it is important to first understand
    how the two DAGs differ in terms of their respective `execution_date`. This is
    crucial since we will use this knowledge to determine the implementation of the
    desired behaviour.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assume that today is December 13th. The daily DAG `my_daily_dag`, has
    an `execution_date` of `2023–12–12 00:00` since it covers the data interval between
    `2023–12–12` and `2023–12–13`. **Recall that Airflow DAG runs start at the end
    of an interval.**
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, our hourly `my_hourly_dag` DAG has an `execution_date` of `2023–12–13`
    (except the midnight run that will have an `execution_date` of `2023–12–12` since
    the beginning of the interval is `2023–12–12 23:00` through `2023–12–13 00:00`).
  prefs: []
  type: TYPE_NORMAL
- en: Using ExternalTaskSensor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our first option is the built-in `[ExternalTaskSensor](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/external_task/index.html#airflow.sensors.external_task.ExternalTaskSensor)`
    operator.
  prefs: []
  type: TYPE_NORMAL
- en: Waits for a different DAG, task group, or task to complete for a specific logical
    date.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By default, the `ExternalTaskSensor` will wait for the external task to succeed,
    at which point it will also succeed. However, by default it will *not* fail if
    the external task fails, but will continue to check the status until the sensor
    times out (thus giving you time to retry the external task without also having
    to clear the sensor).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — [Airflow Docs](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/external_task/index.html#airflow.sensors.external_task.ExternalTaskSensor)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We can use this sensor in our `my_hourly_dag` that will essentially check if
    `my_daily_dag` has been successful in the specified interval.
  prefs: []
  type: TYPE_NORMAL
- en: The `ExternalTaskSensor` accepts one of `execution_delta` or `execution_date_fn`.
    The former can be used to indicate the time difference with the previous execution
    to look at. By default, this is set to the logical date as the current task/DAG.
    The latter, receives a callable (i.e. a function) that accepts the current execution’s
    logical date as the first position argument and returns the desired logical date(s)
    to query.
  prefs: []
  type: TYPE_NORMAL
- en: '**- execution_delta** (`[*datetime.timedelta*](https://docs.python.org/3/library/datetime.html#datetime.timedelta)`
    *|* `*None*`) — time difference with the previous execution to look at, the default
    is the same logical date as the current task or DAG. For yesterday, use [positive!]
    `datetime.timedelta(days=1)`. Either `execution_delta` or `execution_date_fn`
    can be passed to `ExternalTaskSensor`, but not both.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**- execution_date_fn** (`*Callable*` *|* `*None*`) — function that receives
    the current execution’s logical date as the first positional argument and optionally
    any number of keyword arguments available in the context dictionary, and returns
    the desired logical dates to query. Either `execution_delta` or `execution_date_fn`
    can be passed to `ExternalTaskSensor`, but not both.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since the two DAGs are running on a different schedule, the default behaviour
    of the sensor won’t work for us . In the previous section, we clarified why the
    two DAGs will have different execution dates.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we need to figure out how to use either the `execution_delta` or
    `execution_date_fn` to make both execution dates align with each other.
  prefs: []
  type: TYPE_NORMAL
- en: Using ExternalTaskSensor with execution_delta
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simplest approach in my opinion is to use `execution_delta`. The data interval
    start date of our daily DAG, is “yesterday at 5AM UTC”. Since we know that `my_hourly_dag`
    runs on an hourly basis, we can come up with a formula to compute the delta between
    interval start datetime of hourly DAG and the interval start datetime of the daily
    DAG.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following will create a delta that adds up:'
  prefs: []
  type: TYPE_NORMAL
- en: 24 that corresponds to the difference of 24 hours the two DAGs have, given that
    they run on a different schedule, as explained earlier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the difference between the hour of the interval start datetime of the hourly
    dag and 5, which is the hour the daily DAG runs every day.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As an example, consider the following scenarios when the hourly DAG starts
    running at 6AM (until 8PM):'
  prefs: []
  type: TYPE_NORMAL
- en: 'At 6AM:'
  prefs: []
  type: TYPE_NORMAL
- en: hourly data interval starts at 5AM (and ends at 6AM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: daily data interval starts at 5AM yesterday
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`execution_delta=24 + (5-5) = 24`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sensor will check the success of the daily DAG with data interval start
    date set to 24 hours before
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At 7AM:'
  prefs: []
  type: TYPE_NORMAL
- en: hourly data intevral starts at 6AM (and ends at 7AM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: daily data interval starts at 5AM yesterday
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`execution_delta=24 + (6-5) = 25`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sensor will check the success of the daily DAG with data interval start
    date set to 25 hours before
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Now how do we implement this? One problem we need to face is that (by the time
    this post was written), `execution_delta` is not a templated field meaning that
    we cannot use the [templated variables](https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html#variables)
    that give us access to useful information, including the `data_interval_start`.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we will have to manually construct the `data_interval_start` of the
    hourly DAG. Given that DAG runs every hour, the data interval start hour corresponds
    the current hour minus one
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, the `execution_delta` that will be provided as an argument to the
    `ExternalTaskSensor` can now be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here’s the full code of our hourly DAG, that will run every hour between 6AM
    and 8PM UTC, only if the daily DAG has been successful today.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Using ExternalTaskSensor with execution_date_fn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now apart from `execution_delta`, the sensor can be configured to work with
    `execution_date_fn` that accepts a callable returning the logical date(s) to be
    queried.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, we need to create a function and fetch the desired logical date
    of the daily DAG that needs to be against the conditions of the sensor, that by
    default will check whether the state of the DagRun at the specified interval was
    successful.
  prefs: []
  type: TYPE_NORMAL
- en: The function below, will fetch the DagRuns of the daily DAG and return the execution
    date of the DagRun only if it happened on the same day as the hourly DAG. If no
    DagRun is found (which means that the daily DAG was not executed in the past,
    `AirflowSkipException` will be raised such that the sensor task (and any downstream)
    is skipped. Likewise, if no DagRun for the daily DAG is found that happened on
    the same date as the hourly DAG, the `current_logical_dt` will be returned, which
    is essentially the default value that is checked by `ExternalTaskSensor` (and
    is the argument that must be present in the function definition that is provided
    when using `execution_date_fn` argument).
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the two DAGs run on a different schedule which means their `execution_date`
    differs. In order to make a proper comparison and determine whether the daily
    DAG was executed successfully on the same day that the hourly DAG runs, we need
    to subtract one day from the hourly DAG’s execution date. Note that we are only
    interested whether the year, month and day between the two DAGs is the same (we
    don’t really care about the time information in this context).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here’s the full code for our hourly DAG using `execution_function_fn` with `ExternalTaskSensor`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Using PythonOperator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second approach involves a more customised solution. More specifically,
    we can programmatically find the latest successful `DagRun` of our daily DAG and
    handle the behaviour of the operator accordingly. In other words, if the latest
    successful `DagRun` of the daily DAG does not align with the execution date of
    our hourly DAG, the task will be skipped (as well as the downstream tasks).
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we can write a function — similar to the one we have written in the
    previous section and was used as an argument to the `execution_date_fn` argument
    for `ExternalTaskSensor`.
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, we need to fetch the DagRuns of the daily DAG, determine
    if anyone has completed successfully today (i.e. on the same day the hourly DAG
    runs). If none is found, we raise a `AirflowSkipException` such that the execution
    of the hourly DAG is skipped. In this case, the `PythonOperator` supports templated
    variables and we will therefore take advantage of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what our function looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the complete code for the `my_hourly_dag` DAG, using a `PythonOperator`
    to check the status of `my_daily_dag`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Final Thoughts..
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In today’s tutorial we discussed how to handle dependencies between different
    DAGs when using Airflow. More specifically, we discussed how to run a DAG that
    is supposed to execute on an hourly basis, only if a different DAG, on a daily
    schedule, executes successfully within the day.
  prefs: []
  type: TYPE_NORMAL
- en: Three different approaches were demonstrated. Depending on the complexity of
    your use-case, you should pick the one that makes more sense and results in more
    elegant code.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Subscribe to Data Pipeline**](https://thedatapipeline.substack.com/welcome)**,
    a newsletter dedicated to Data Engineering**'
  prefs: []
  type: TYPE_NORMAL
