- en: An Introduction To Analytics Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/analytics-engineering-8b0ed0883379](https://towardsdatascience.com/analytics-engineering-8b0ed0883379)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Who is an Analytics Engineer and what are they supposed to do
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://gmyrianthous.medium.com/?source=post_page-----8b0ed0883379--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----8b0ed0883379--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8b0ed0883379--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8b0ed0883379--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----8b0ed0883379--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8b0ed0883379--------------------------------)
    ¬∑6 min read¬∑Oct 22, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/94ed22629f1f62ce0015550806f265cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated via [DALL-E2](https://labs.openai.com/s/Ibq51s6cLfdgFn68sk94aHLF)
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, data teams were formed by Data Engineers and Data Analysts.
  prefs: []
  type: TYPE_NORMAL
- en: The Data Engineers are responsible for building up the infrastructure to support
    data operations. These would include the configuration of databases and the implementation
    of ETL processes that are used to ingest data from external sources into a destination
    system (perhaps another database). Furthermore, Data Engineers are typically in
    charge of ensuring data integrity, freshness and security so that Analysts can
    then query the data. A typical skillset for a Data Engineer includes Python (or
    Java), SQL, orchestration (using tools such as Apache Airflow) and data modeling.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, Data Analysts are supposed to build dashboards and reports
    using Excel or SQL in order to provide business insights to internal users and
    departments.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dc94913ce71ac6ef8b9ca0cb68e2e7f6.png)'
  prefs: []
  type: TYPE_IMG
- en: Traditional formation of Data Teams
  prefs: []
  type: TYPE_NORMAL
- en: Transitioning From ETL to ELT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to process data and gain valuable insights we first need to extract
    it, right? ü§Ø
  prefs: []
  type: TYPE_NORMAL
- en: Data Ingestion is performed using ETL (and more recently with ELT) processes.
    Both ETL and ELT paradigms involve three main steps; Extract, Transform and Load.
    For now, let‚Äôs ignore the sequence of executing these steps and let‚Äôs focus on
    what does each step do independently.
  prefs: []
  type: TYPE_NORMAL
- en: Extract
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step refers to the process of pulling data from a persistent source. This
    data source could be a database, an API endpoint a file or a message queue.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b797a7fae065fff7f3edad5d5c22e3bd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Extract step pulls data from various sources ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Transform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Transform step, the pipeline is expected to perform some changes in the structure
    and/or format of the data in order to achieve a certain goal. A transformation
    could be a modification (e.g. mapping `‚ÄúUnited States‚Äù` to `‚ÄúUS‚Äù`), an attribute
    selection, a numerical calculation or a join.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b3a099d68622651016306e797fb028d5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The transformation steps performs a number of transformation into the input
    raw data ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Load
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step refers to the process of moving data (either raw, or transformed)
    into a destination system. The target is usually a OLTP system, such as a database
    or an OLAP system, such as a Data Warehouse.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0c763a0f12942d486d5d1f76ffd9db28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Loading data into a destination system ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'ETL: Extract ‚Üí Transform ‚Üí Load'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ETL refers to the process where the data extraction step is followed by the
    transformation step and ends with the load step.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fa80a89e8a6af7c84ba2ab2af062a169.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A visual representation of an ETL process ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: The data transformation step in ETL processes occurs in a staging environment
    outside of the target system, where the data is transformed just before it gets
    loaded to the destination.
  prefs: []
  type: TYPE_NORMAL
- en: ETL has been around for a while but its application has slowly started fading
    out.
  prefs: []
  type: TYPE_NORMAL
- en: Since the transformation happens in an intermediate (staging) server, there‚Äôs
    an overhead for moving the transformed data into the target system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The target system won‚Äôt contain the raw data (i.e. the data in the format prior
    to the transformation). This means that whenever additional transformations are
    required, we would have to pull the raw data once again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The emergence of Cloud technologies have shifted the process of ingesting and
    transforming data. Data Warehouses hosted on the cloud have made it possible to
    store huge volumes of data at a very low cost. Therefore, is there really need
    to apply transformations ‚Äúon the fly‚Äù while discarding raw data every time a transformation
    is performed?
  prefs: []
  type: TYPE_NORMAL
- en: 'ELT: Extract ‚Üí Load ‚Üí Transform'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ELT refers to a process where the extraction step is followed by the load step
    and the final data transformation step happens at the very end.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4c87a9f272bfc7b5586ce774a0e5cac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A visual representation of an ELT process ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to ETL, in ELT no staging environment/server is required since data
    transformation is performed within the destination system, which is usually a
    Data Warehouse or Data Lake hosted on the Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the raw data exists on the destination system and thus available
    for further transformations at any time.
  prefs: []
  type: TYPE_NORMAL
- en: Analytics Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a reminder, in older data team formations, engineers were in charge of maintaining
    the ETL layer while analysts where responsible for the creation of dashboards
    and reporting. But the question now is **where do Analytics Engineers fit into
    the picture?**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9a23f55bf1b11986a968eb78ddda68db.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In older data team formations, Data Engineers were responsible for ETL and
    Data Analysts for reporting ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Analytics Engineers are essentially **the link between Data Engineers and Analysts**.
    Their responsibility is to take the raw data and apply transformations so that
    Data Analysts can then collect the transformed data and prepare Dashboards and
    Reports on the Business Intelligence layer so that internal users can then make
    data-informed decisions. Now the Data Engineers can focus more on the ingestion
    level and the wider data infrastructure of the data platform.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4eee2855d4ef9a3d263a34c847682a4c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In ELT pipelines, Data Engineers are responsible for Extraction and Load of
    data in a Data Warehouse, Analytics Engineers for the data transformation layer
    and Analysts for the creation of business dashboards ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'dbt: The ultimate tool for Analytics Engineering'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analytics Engineers are people that can help data teams scale and move faster.
    But to do so, they also need to take advantage of tools that can help them get
    the job done. And the ultimate Analytics Engineering tool is **data build tool
    (dbt)**.
  prefs: []
  type: TYPE_NORMAL
- en: dbt is a tool used to build and manage data models in a scalable and cost effective
    fashion. Instead of taking the time to figure out all inter-dependencies between
    models in order to decide in what sequence models must be executed, dbt does all
    the dirty work for you. Furthermore, it provides functionality to support data
    quality tests, freshness tests and documentation among others.
  prefs: []
  type: TYPE_NORMAL
- en: In order to better understand what dbt does, it‚Äôs important to visualise the
    wider context and see where it fits within the **modern data stack**. dbt is actually
    sitting on the T layer within an ELT pipeline and transformations are performed
    within the Data Warehouse where the raw data resides.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6b6a1c1b2394e8c0cd699cf12c6f260d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using dbt to perform transformations over raw data within the Data Warehouse
    ‚Äî Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: dbt is a **CLI (Command Line Interface) tool** that enables Analytics Engineering
    teams deploy and manage data models following software engineering best practices.
    Some of these practices include support for multiple environments (development
    and production), version controlling and CI/CD (Continuous Integration and Continuous
    Development). Data models can be written in SQL (jinja templated) but more recent
    versions of the tool also support model definitions with Python!
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts..
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analytics Engineering is an emerging field in the intersection of Data Engineering
    and Data Analytics that aims to speed up the development of analytics products,
    improve data quality and bring more data trust. The main tool that facilitates
    the lifecycle of data products is dbt that has drastically changed the way data
    teams work and collaborate together. It is therefore important to familiarise
    yourself with it since it‚Äôs here to stay for the long run.
  prefs: []
  type: TYPE_NORMAL
- en: In upcoming articles we are going to focus more on dbt and how you can use it
    to build and manage your data models effectively. So make sure to subscribe in
    order to be notified when the articles are out!
  prefs: []
  type: TYPE_NORMAL
