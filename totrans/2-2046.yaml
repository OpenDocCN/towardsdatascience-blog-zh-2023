- en: The Path towards AI Regulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-path-towards-ai-regulation-7199eb803040](https://towardsdatascience.com/the-path-towards-ai-regulation-7199eb803040)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Opinion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The contribution of the AI Act and its worldwide impact
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://marco-brambilla.medium.com/?source=post_page-----7199eb803040--------------------------------)[![Marco
    Brambilla](../Images/eb60e3445d68c398a5d5a1f3ded98a6b.png)](https://marco-brambilla.medium.com/?source=post_page-----7199eb803040--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7199eb803040--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7199eb803040--------------------------------)
    [Marco Brambilla](https://marco-brambilla.medium.com/?source=post_page-----7199eb803040--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7199eb803040--------------------------------)
    ·7 min read·Mar 10, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e4f6f5af15be7e782802bbbda0da8cef.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [DeepMind](https://unsplash.com/@deepmind?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In mid-2021, the European Commission proposed a new EU regulatory framework
    on Artificial Intelligence (AI) for the European Union. As such, it represents
    the first attempt to implement some level of regulation of AI.
  prefs: []
  type: TYPE_NORMAL
- en: You may read the full official document of the [AI Act proposal](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021PC0206)
    (in 24 languages)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: At the moment, it’s still the most advanced and widely accepted regulation proposal
    on the matter. It’s currently in a preliminary proposal state, but the EU is trying
    to push an intense agenda for adoption in the short term.
  prefs: []
  type: TYPE_NORMAL
- en: The definition adopted for an AI system is currently very broad and shallow.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The initiative has been monitored closely worldwide because **it starts from
    the need to preserve the fundamental rights of individuals** and therefore may
    impact the whole of human society.
  prefs: []
  type: TYPE_NORMAL
- en: '**This legal framework takes the perspective of the *usage* and *risks* of
    AI systems** while accepting the limitations in any definition of the concepts
    of AI and AI systems. Basically, the definition adopted for an AI system is currently
    very broad and shallow, as it stops at the level of defining an AI system as a
    software-based technology that encompasses *machine learning*, l*ogic and knowledge-based
    systems*, and *statistical* approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: The AI Act defines a classification for AI systems based on their risk level,
    and specifies limitations, and obligations based on the level of risk.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/28497c648a0c51142eda0e24d6f2e37a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [janilson furtado](https://unsplash.com/@janilson123?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '***Note from Towards Data Science’s editors:*** *While we allow independent
    authors to publish articles in accordance with our* [*rules and guidelines*](/questions-96667b06af5)*,
    we do not endorse each author’s contribution. You should not rely on an author’s
    works without seeking professional advice. See our* [*Reader Terms*](/readers-terms-b5d780a700a4)
    *for details.*'
  prefs: []
  type: TYPE_NORMAL
- en: Risk-based Classification of AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The proposal of regulation is not limiting technology or methods. Instead,
    **it’s taking a risk-based approach**, proposing a classification for AI systems
    based on the risks they imply, specifying different requirements, limitations,
    and obligations based on the level of risk. In particular:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AI systems presenting ‘unacceptable’ risks shall be prohibited.** These include
    AI systems covering manipulative ‘subliminal techniques, or exploiting specific
    vulnerable groups, social scoring purposes, and real-time remote biometric identification
    systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**‘High-risk’ AI systems will be authorized, but subject to very strict requirements
    and obligations** to gain access to the EU market. These include AI systems used
    as safety components of critical products, biometric identification, operation
    of critical infrastructure, educational tools; employment and worker management;
    access tools to essential services; law enforcement; migration, asylum, and border
    control; and administration of justice and democratic processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AI systems presenting only ‘limited risk’ would be subject only to basic
    transparency obligations**. These include systems that interact with humans (i.e.,
    chatbots), emotion recognition, biometric categorization, and generators or manipulators
    of text, image, audio, or video content (including deepfakes).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Beware of the (missing) elephant in the room here: military and defense applications
    are not covered by the regulation. Actually, the AI Act explicitly states that'
  prefs: []
  type: TYPE_NORMAL
- en: AI systems exclusively developed or used for military purposes should be excluded
    from the scope of this Regulation.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The same is also stated in
  prefs: []
  type: TYPE_NORMAL
- en: '*Article 2.3: This Regulation shall not apply to AI systems developed or used
    exclusively for military purposes.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Shouldn’t they be regulated too?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a671815b0cf2260c277487ce19c2238.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Tingey Injury Law Firm](https://unsplash.com/@tingeyinjurylawfirm?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Enforcement of AI Compliance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a way, together with this risk-based vision, the framework also covers the
    definition of governance and enforcement agencies: **it establishes a European
    Artificial Intelligence Board** (overviewing the process and consistent implementation
    across states) **and a National Supervisory Authority for each member state**
    (supervising the application and implementation of the regulation), while national
    market surveillance authorities will be responsible for monitoring the compliance
    of players thanks to broad confidential access (including to source code).'
  prefs: []
  type: TYPE_NORMAL
- en: The enforcement bodies will apply appropriate measures to restrict, prohibit,
    recall, or withdraw AI systems that are not complying with the rules. This includes
    administrative fines of up to €30 million or 6% of the total worldwide annual
    turnover, depending on the severity of the violation.
  prefs: []
  type: TYPE_NORMAL
- en: The AI Act and associated enforcement mechanisms take the form of a product
    liability law.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/2fb660ca5369751afbde65b65b5cffd2.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Tingey Injury Law Firm](https://unsplash.com/@tingeyinjurylawfirm?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'From a pragmatic perspective, the risk-based approach makes total sense. However,
    it poses several challenges for future sustainability and generality. In particular:'
  prefs: []
  type: TYPE_NORMAL
- en: Is the definition of AI broad and precise enough?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we be sure that we are categorizing applications in the right class
    of risk?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What about new solutions and applications we cannot foresee now?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Furthermore, notice that, in a way, **the AI Act and associated enforcement
    mechanisms basically take the form of a product liability law**. Indeed, this
    kind of framework is clearly setting rules and rights not at the individual level,
    but at the corporate and product levels. This has deep implications for companies,
    both producing and servicing AI-based solutions. Companies need to declare and
    demonstrate the level of risk of their solutions and applications. They also need
    to guarantee compliance with the rules of the respective risk level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering that the whole platform starts from the need to preserve the fundamental
    rights of individuals, the approach taken by the Act seems rather misaligned with
    the foundational principles. Furthermore, this approach also implies practicality
    risks: **who exactly will be liable** in case any problem arises? The developing
    company, the vendor, or any intermediary that deploys, configures, or customizes
    the solution?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The AI regulation framework also encompasses further dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**standardization**: discussion with standardization bodies like ISO and IEEE
    shall ensure that the adoption of technologies and definitions is as broad and
    agreed upon as possible. NATO itself is now working on a standardization initiative
    on the matter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**excellence**: the framework should not (only) be limiting the AI potential.
    While on one side it will limit dangerous adoption, on the other it shall enable
    and foster innovation and excellence, both at the foundational and application
    levels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It may not make any sense to regulate AI if you don’t regulate and protect data
    too.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'At least at the European level, there is a broad agreement on the importance
    and need for this initiative. Other countries have started similar processes too:
    for instance, the **US defined a blueprint for the** [**AI Bill of Rights**](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)
    **in 2022** and [Brazil](https://www.politico.eu/newsletter/ai-decoded/brazils-ai-law-us-takes-a-risk-based-approach-social-scoring/)
    defined a preliminary AI Law. Many countries (including the [US](https://www.ai.gov/)
    and many EU member states) laid down a national AI initiative starting in the
    early 2020s too. Possibly, the EU may pave the way to the future global regulation
    of AI, pretty much as it did with data protection with the GDPR.'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, there is also a broad convergence on the fact that it may not make any
    sense to regulate AI if you don’t regulate and protect data too. Indeed, the application
    of AI regulations would be more feasible in countries that already have well-established
    *data protection and regulation* law.
  prefs: []
  type: TYPE_NORMAL
- en: On this, the European Union once again has been leading at the global level,
    with the introduction of the *GDPR*, which currently influences and has a much
    broader impact at the broader level.
  prefs: []
  type: TYPE_NORMAL
- en: The European Union may pave the way to the future global regulation of AI systems,
    as it did with data protection.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/76d2d8cd3335827149049462daf1944f.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Alex wong](https://unsplash.com/@killerfvith?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: A more detailed description of the AI Act can be found in this [Briefing by
    the EU Parliament](https://www.europarl.europa.eu/RegData/etudes/BRIE/2021/698792/EPRS_BRI(2021)698792_EN.pdf),
    while the full official document of the AI Act proposal is published [here](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021PC0206)
    (in 24 languages). Discussions and perspectives on the matter also come from the
    [IdeasLab](https://ideaslab.ceps.eu/) Conference and Think Tank organized by the
    Center for European Political Studies (CEPS) in Brussels, Belgium, on February
    28, 2023.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7aa6a0726cade6bc6504969fcf66b36.png)'
  prefs: []
  type: TYPE_IMG
- en: '[The official Header of the AI Act proposal]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Concluding: the AI Act can represent the first attempt to regulate AI systems
    at the international level. Once approved, it may influence and somehow force
    several other countries, including the US, to react with similar initiatives,
    possibly aligned or inspired by this proposal.'
  prefs: []
  type: TYPE_NORMAL
- en: International alignment could be beneficial, as opposed to what happened with
    data regulation in recent years, where the EU lead the way with the GDPR regulation,
    but the US didn’t match the level of guarantees requested in the GDPR, thus generating
    confusion, legal blockades, and limitation in data transfer and storage at the
    international level.
  prefs: []
  type: TYPE_NORMAL
- en: On the other side, this would probably represent **the first case where software
    systems and models will be explicitly and directly limited in use and implementation**.
    One may wonder why this is the case for AI systems, while the same need didn’t
    arise in the past for other categories of software or mathematical models. This
    may arise as an important precedent for future regulation of technology in general.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need to regulate AI systems, when we didn’t regulate for other categories
    of software models and algorithms in the past?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What do you think? Should AI be regulated? How?
  prefs: []
  type: TYPE_NORMAL
- en: Do you have your own perspective to share?
  prefs: []
  type: TYPE_NORMAL
- en: Which pitfalls could a risk-based approach expose in the long run?
  prefs: []
  type: TYPE_NORMAL
- en: Will such regulation impact (your) business, innovation processes, or data science
    practices?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/824c641d34a9b223b836dca1b14ee694.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Christopher Burns](https://unsplash.com/@christopher__burns?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
