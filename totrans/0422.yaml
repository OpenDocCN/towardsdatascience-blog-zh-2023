- en: Build a Speech-to-Text Web App Using Node.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/build-a-speech-to-text-web-app-using-node-js-210f8c054d79](https://towardsdatascience.com/build-a-speech-to-text-web-app-using-node-js-210f8c054d79)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s build a web app which transcribes and translates audio using OpenAI’s
    Whisper Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shubhamstudent5.medium.com/?source=post_page-----210f8c054d79--------------------------------)[![Kumar
    Shubham](../Images/64eed4588cc63804a612f01d5c6ec1ea.png)](https://shubhamstudent5.medium.com/?source=post_page-----210f8c054d79--------------------------------)[](https://towardsdatascience.com/?source=post_page-----210f8c054d79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----210f8c054d79--------------------------------)
    [Kumar Shubham](https://shubhamstudent5.medium.com/?source=post_page-----210f8c054d79--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----210f8c054d79--------------------------------)
    ·11 min read·Mar 27, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/25b5d8abf919e8d8c304f803d5948166.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [AltumCode](https://unsplash.com/@altumcode?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Hello folks! I hope you all are doing well. Today, we will build a Speech to
    Text web app using Node.js and OpenAI’s API. We would use OpenAI’s API to use
    its Whisper Model, which lets us upload audio files in mp3 format, and provides
    us with its transcript. It can even translate audio in other languages to English
    text, which is incredible.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we would set up a new Node.js project so that we can start building
    our application. So, we will create a folder where we want to build our project
    and move into that folder using the command line, and then we can set up a new
    Node.js project using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After running this command, it will ask several questions, such as the app’s
    name, entry point, etc. We can keep them as default for now. After this, you would
    see it created a `package.json` file. This file would contain information about
    our application and which packages we have installed for this application.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the next step is to install the necessary node modules, i.e. packages,
    into our application so that we are ready to start building the application. We
    can do that by running the below command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We install these four packages and also use `--save` to add these packages to
    the `package.json` file. It makes it easier for someone cloning the repository
    to install all the required packages by just running `npm install` command once.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also want to use the nodemon package in our application to help us automatically
    refresh and reload the server when it detects changes in the code so that we do
    not have to manually keep restarting the server again and again after each change.
    So, we will add it as a development dependency since it will only be used for
    help in the development, and we will not use it directly in the code. We can install
    it by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have all the necessary packages to start our development work. As we
    can see in the `package.json` file, there would be all the modules and packages
    we installed, along with a few details about the application. The `package.json`
    file would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: So, as we can see, `index.js` is written in the `main`, signifying that the
    `index.js` file is the entry point for our application. If you remember, it was
    asked during the setup process when we ran the `npm init` command. If you would
    have left it to default, you would have the same entry point; otherwise, you would
    have the one you defined at that time.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will create a new file named `index.js`. You may name the file as you
    wish according to the entry point defined by you. We are considering `index.js`
    for the same.
  prefs: []
  type: TYPE_NORMAL
- en: index.js
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, we will now start building the `index.js` file. We will start by importing
    the required modules into our application. For the index file, we require `express`
    and `cors`. So, we start by requiring these two modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will create a new instance of the `express` application. Also, we will
    be setting up our application to use cors, handle json data and make the `public`
    folder contain the static files, which can then be accessed by the client side
    or the frontend.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Next, we would like to have a separate file where we would define the APIs.
    We would be creating a folder named `routes` and inside of that, we will have
    a file named `api.js` where will be defining the GET and POST APIs needed in the
    application. To inform the application about this, we would add this line of code
    where we define the base URL and the file’s location where all APIs would be defined.
    It is a middleware that helps us set the routing for the application.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Next, we use an error-handling middleware function which will be used to handle
    any error occurring in the application.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we set up the application to listen for incoming requests on a specified
    port number, which we can either set by using environment variables or simply
    define.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We have used port 4000 for our application. We also have a simple `console.log`
    inside of it, which prints a message which logs to the console when the application
    is ready to receive requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The complete `index.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will be moving to the `api.js` file, which we created inside of the
    `routes` folder.
  prefs: []
  type: TYPE_NORMAL
- en: api.js
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, we will now start building the `api.js` file. We will start this by importing
    the required modules into the file. We will be importing `express`, `multer` and
    `openai` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[Multer](https://www.npmjs.com/package/multer) is a middleware which we are
    using to handle `multipart/form-data`, as we would be dealing with the upload
    of audio files.'
  prefs: []
  type: TYPE_NORMAL
- en: From `openai`, we require the `Configuration` and the `OpenAIApi` modules that
    we would use to post API requests to the Whisper model.
  prefs: []
  type: TYPE_NORMAL
- en: We will then set up the express router and create an instance of the multer
    middleware.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will configure OpenAI and create a new configuration instance. We require
    an OpenAI Secret Key, which we must put here as the API key. You can get the secret
    key from [here](https://platform.openai.com/account/api-keys).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now, we create an async function which accepts a buffer containing the song
    data and returns the response received from the OpenAI’s Whisper model when we
    call its API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As you can see above, we first create a new instance of the OpenAI class by
    using the configuration we defined earlier in our code. We then call the `createTranscription`
    function of OpenAI, and we use `await` keyword in this so that we wait for the
    response first before moving ahead.
  prefs: []
  type: TYPE_NORMAL
- en: We pass the required parameters in the function, which consist of the buffer
    which contains the song data, and the model to use for the transcription, which
    is `whisper-1` in our case. We then leave the prompt undefined. You can give a
    prompt, too, if you like, which would help the model to better transcribe the
    audio by having a similar style to the prompt you provided. We define the data
    type we receive as `json`, set the temperature to 1 and define the language in
    which we want the output.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we would define the GET request. We use `sendFile` to send an HTML file
    which contains our form where users can upload the audio files. We will be building
    the HTML files later. We are serving it on the base URL.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Next, we define the POST request, which will handle the upload of audio files.
    We use the multer middleware to manage the file upload part. We then create a
    buffer from the audio file, which would contain the audio file's data in a format
    that can be sent to the OpenAI API. We then set a name to the buffer using the
    original name of the uploaded audio file.
  prefs: []
  type: TYPE_NORMAL
- en: We then call the `transcribe` function, and once we get the response, we send
    a JSON back to the client. We send the transcription and the audio file name back
    to the frontend. We also have a catch method to handle any errors.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we export the `router` modules, which would then allow other files
    to import them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the complete code for the `api.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have completed all the backend parts. We will now be writing the HTML
    files and writing some frontend javascript code to handle form submissions and
    data saving in [local storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage)
    and retrieving data from local storage.
  prefs: []
  type: TYPE_NORMAL
- en: We create a `public` folder, inside of which we will create two HTML files —
    `index.html` and `transcribe.html`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with the `index.html` file:'
  prefs: []
  type: TYPE_NORMAL
- en: index.html
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, in this file, we will be building the page where we display the form to
    upload an audio file. We will be using Bootstrap CSS so that we will import it
    through CDN. We also include Bootstrap JS through CDN at the end of the HTML file.
  prefs: []
  type: TYPE_NORMAL
- en: We then create a simple card where I ask the user to upload the audio file.
    I make sure that the file being submitted is in `.mp3` format as it is the only
    format accepted by OpenAI’s API. We display a button which, on clicking, submits
    the form.
  prefs: []
  type: TYPE_NORMAL
- en: We then have the javascript code, which we use to handle the form submission.
    So, at first, we stop the page from refreshing by preventing the default behaviour
    of the form submission event. We then take in the form data, i.e. the audio file
    and send it as a POST request to the backend. We then wait for a response and
    store it in a data variable.
  prefs: []
  type: TYPE_NORMAL
- en: If the data has the transcription available, we store the transcription and
    the audio file name in Local Storage so that we can access them on the next page
    where we need to show the transcript. There are multiple ways to pass information
    like we could have passed the information through URIs, but here we are using
    Local Storage to do so.
  prefs: []
  type: TYPE_NORMAL
- en: After saving the data to local storage, we change the window location to load
    the `transcribe.html` file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: So, the above code builds the `index.html` file, which will display the form
    to the user where the user can upload the audio file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is one screenshot of how that looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fe9588bef9851c77d208fb289b8ef707.png)'
  prefs: []
  type: TYPE_IMG
- en: Audio Upload page — index.html
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will build the `transcribe.html` file.
  prefs: []
  type: TYPE_NORMAL
- en: transcribe.html
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, in this file, we will display the transcript of the audio file uploaded
    by the user. So, we will again be using Bootstrap CSS and JS so that we will include
    those via CDN.
  prefs: []
  type: TYPE_NORMAL
- en: We then define some custom CSS to stylize the elements to make them look better.
    We then display the audio file name and the transcription of that audio file in
    a container.
  prefs: []
  type: TYPE_NORMAL
- en: In the javascript code at the bottom of this page, we get the audio file name
    and the transcript from the local storage and push that data to the respective
    HTML elements using the ids.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: I have tried transcribing two different small audio files which I recorded personally
    — one in English and the other in Hindi. Though the second audio file was recorded
    in Hindi, I wanted to see the output in English, thus testing its translational
    abilities too. It was highly accurate in transcribing both of the audio files.
    Though, in multiple runs, sometimes it produces a vague transcription which is
    not correct, but many times, transcriptions are mostly correct.
  prefs: []
  type: TYPE_NORMAL
- en: I am attaching the transcription screenshots below. Those are not entirely correct,
    but I would say it is about 85–90% correct in transcribing what I actually recorded
    in the audio files.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1fc8ef9508130d82958cf9365446c051.png)'
  prefs: []
  type: TYPE_IMG
- en: Transcription for an English Audio file
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f25f5333a3939b203c03e921e5998e40.png)'
  prefs: []
  type: TYPE_IMG
- en: Transcription in English for a Hindi audio file
  prefs: []
  type: TYPE_NORMAL
- en: So, we have successfully built a speech-to-text web app using OpenAI’s API and
    Node.js. I hope you enjoyed building it and learnt something new from this article.
    You can also then alter the parameters to play around with it and compare the
    results to get a better idea of what works well in what scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thank you for reading the article. Some more articles you must read after this
    one are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://javascript.plainenglish.io/build-a-simple-todo-app-using-next-js-f88b68761e27?source=post_page-----210f8c054d79--------------------------------)
    [## Build a Simple Todo App using Next.js'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build a simple Todo App with Next.js, which teaches you the basic principles
    of CRUD (Create, Read, Update and…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: javascript.plainenglish.io](https://javascript.plainenglish.io/build-a-simple-todo-app-using-next-js-f88b68761e27?source=post_page-----210f8c054d79--------------------------------)
    [](https://medium.com/geekculture/how-to-implement-multiple-user-types-in-django-b72df7a98dc3?source=post_page-----210f8c054d79--------------------------------)
    [## How to Implement Multiple User Types in Django
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to implement multiple user types in Django, handle authentication,
    and reroute based on user types.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/geekculture/how-to-implement-multiple-user-types-in-django-b72df7a98dc3?source=post_page-----210f8c054d79--------------------------------)
    [](/build-a-simple-todo-app-using-react-a492adc9c8a4?source=post_page-----210f8c054d79--------------------------------)
    [## Build a Simple Todo App using React
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build a simple Todo App with React which teaches you the basic principles
    of CRUD (Create, Read, Update and…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/build-a-simple-todo-app-using-react-a492adc9c8a4?source=post_page-----210f8c054d79--------------------------------)
    [](/build-a-social-media-website-using-django-setup-the-project-part-1-6e1932c9f221?source=post_page-----210f8c054d79--------------------------------)
    [## Build a Social Media Website Using Django — Setup the Project (Part 1)
  prefs: []
  type: TYPE_NORMAL
- en: In the first part, we focus on setting up our project and installing the required
    components by setting up the password…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/build-a-social-media-website-using-django-setup-the-project-part-1-6e1932c9f221?source=post_page-----210f8c054d79--------------------------------)
  prefs: []
  type: TYPE_NORMAL
