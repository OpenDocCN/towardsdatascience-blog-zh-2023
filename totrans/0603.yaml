- en: Creating Animation to Show 4 Centroid-Based Clustering Algorithms using Python
    and Sklearn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/creating-animation-to-show-4-centroid-based-clustering-algorithms-using-python-and-sklearn-d397ade89cb3](https://towardsdatascience.com/creating-animation-to-show-4-centroid-based-clustering-algorithms-using-python-and-sklearn-d397ade89cb3)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using data visualization and animations to understand the process of 4 Centroid-based
    clustering algorithms.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@borih.k?source=post_page-----d397ade89cb3--------------------------------)[![Boriharn
    K](../Images/1b23a79640f5272c1382918bfdba03b0.png)](https://medium.com/@borih.k?source=post_page-----d397ade89cb3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d397ade89cb3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d397ade89cb3--------------------------------)
    [Boriharn K](https://medium.com/@borih.k?source=post_page-----d397ade89cb3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d397ade89cb3--------------------------------)
    ·9 min read·Aug 16, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/25a9aac387589c5c2e52ada5e0acd659.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Mel Poole](https://unsplash.com/@melpoole?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Clustering analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clustering analysis is an effective machine learning technique that groups data
    by their similarities and differences. The obtained data groups can be used for
    various purposes, such as segmenting, structuring, and decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: To perform clustering analysis, many methods are available based on different
    algorithms. This article will mainly focus on centroid-based clustering, which
    is a common and useful technique.
  prefs: []
  type: TYPE_NORMAL
- en: Centroid-based clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basically, the centroid-based technique works by repeatedly calculating to obtain
    optimal centroids (cluster centers) and then assigning data points to the nearest
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: Due to having many iterations, data visualization can be used to express what
    happens during the process. Thus, the purpose of this article is to create animations
    to show the centroid-based process with Python and Sklearn.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ceb40ec4b89cf6e64341067db7fb515b.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a clustering animation in this article. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Sklearn ([Scikit-learn](https://scikit-learn.org/stable/index.html)) is a powerful
    library that helps us perform clustering analysis efficiently. The followings
    are the centroid-based clustering techniques that we will work with.
  prefs: []
  type: TYPE_NORMAL
- en: '**K-means clustering**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**MiniBatch K-means clustering**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bisecting K-means clustering**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mean-Shift clustering**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s get started
  prefs: []
  type: TYPE_NORMAL
- en: '**Getting Data**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start with importing libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As an example, this article will use a generated dataset, which can be easily
    created using sklearn’s `make_blobs()`. If you have your dataset, this step can
    be skipped.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9ad10b163feb1b0e7d9fcc43a82a81ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 1\. K-Means clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a common method for centroid-based clustering. The process can be briefly
    explained: starting with defining the number of clusters. Next, some data points
    are randomly selected as initial centroids. The other data points are assigned
    to the closest centroids using minimum [Euclidean](https://en.wikipedia.org/wiki/Euclidean_distance)
    distance.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, re-initializing the centroids by calculating the average of each cluster’s
    data points. Thus, the centroids are updated. After that, repeat the process of
    assigning and re-initializing. The algorithm will keep on iterating until achieving
    the optimal centroids.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s work with Python code. Start with defying a list of iteration numbers.
    As an example, this article will run only the first ten iterations. If you want
    to change the number, please feel free to modify the code below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Define a function and variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here comes the clustering process. We can use Sklearn’s [Kmeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans),
    the defined function, and Python’s for-loop to return three values: centroids,
    clustering labels, and boundaries in each iteration. These values will be kept
    in lists for plotting later.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Create a DataFrame from the list of clustering labels.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b6b9c1cd650d5b5ba1281c030b8786fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Define a function applying for-loop to create scatter plots. This function will
    also be applied to visualize other clustering techniques in this article as well.
    Please consider that the results are exported onto your computer as PNG files
    for combining into animation as a GIF file later.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Plot the K-means clustering result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/cf82c48e94504194132f0b18fb07bc1d.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a scatter plot showing the K-means clustering process. Image by
    Author.
  prefs: []
  type: TYPE_NORMAL
- en: Define a function to combine the plots into an animation. The result will be
    saved onto your computer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Apply the function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Voilà!!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c5281ca679c9c9248e2c15568413dfbf.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation showing the K-means clustering process. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The animation shows that data points are assigned to different clusters in the
    first iteration. Then, some data are allocated to adjacent clusters due to the
    recalculation. The red triangles show the centroids in each step. The process
    will keep continuing until the centroids reach the optimal points.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. MiniBatch K-means clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of processing all data points as the K-means clustering, MiniBatch K-means
    randomly takes small batches of data for each iteration. This results in improving
    the clustering speed while returning slightly different outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Sklearn’s [MiniBatchKmeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans)
    function can be used to perform the MiniBatch K-means clustering. We will use
    the same steps as previously explained in the K-means process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5b6aeb488c651a5ede851f1e0a753ddb.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a scatter plot showing the MiniBatch K-means clustering process.
    Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to the defined function from the previous step. We can create an animation
    with just one line of code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4b04d7cd265b78dc792ee2d702b2223a.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation showing the MiniBatch K-means clustering process. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Compared with the result from K-means, clustering areas in the first iteration
    of MiniBatch K-means is approximately close to K-means’ fifth or sixth iteration.
    Thus, it can be noticed that the MiniBatch K-means returns faster clustering.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Bisecting K-means clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bisecting K-means applies K-means to divide the whole data points into two clusters
    in the first step. After that, the algorithm will select the cluster with the
    largest sum of squares to be divided into two clusters again. The process will
    keep repeating until the total number of clusters equals K.
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm can also be considered a hybrid method between [divisive hierarchical
    clustering](https://www.geeksforgeeks.org/ml-hierarchical-clustering-agglomerative-and-divisive-clustering/)
    and K-means. It is an effective way to deal with a large number of K.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are going to work with the code part. Start by creating a list of numbers
    to use with the for-loop function. To compare with other algorithms in this article,
    I will make a list of numbers from one to five.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will use [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.BisectingKMeans.html#sklearn.cluster.BisectingKMeans)’s
    `BisectingKMeans` function to do the Bisecting K-means clustering.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d07501a72e78537b695944ea8768831d.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a scatter plot showing the Bisecting K-means clustering process.
    Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Combine the plots into an animation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b9b9a5231359ba52c865488d1d421653.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation showing the Bisecting K-means clustering process. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: From the animation, it can be seen that the whole data points in the first step
    are divided into two clusters in the second step. Then, the cluster with a larger
    sum of squared is divided again into two clusters. Thus, we have three clusters
    in the third iteration. The bisecting K-means process will continue until the
    cluster number reaches the K number, which is five in this article.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Mean-shift clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mean-shift clustering calculates the local mean point within a certain radius
    (bandwidth) and assigns data points toward the highest density. The algorithm
    will keep calculating until convergence. This method is also known as a hill-climbing
    algorithm due to its behavior.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** Mean-shift clustering technique is also considered a density-based
    algorithm [[link1](https://en.wikipedia.org/wiki/Cluster_analysis#Density-based_clustering),
    [link2](https://www.geeksforgeeks.org/ml-mean-shift-clustering/)] as well.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s use [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html)’s
    `MeanShift` function to do the Mean-shift clustering. The main difference compared
    with the previous K-means methods is that there is no need to define the number
    of K. By the way, we need to calculate the bandwidth for use as a parameter for
    Mean-shift clustering.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/2bf6b62dd8e52cc02d1667d8cfaf7031.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a scatter plot showing the Meanshift K-means clustering process.
    Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Apply the function to create an animation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Ta-da!!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc3deadfd7c28c8d97aa24a1e8a122b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Animation showing the Meanshift clustering process. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: In the first iteration, we can see many centroids due to the algorithm trying
    to find the highest density of data points within the bandwidth used. In the following
    iteration there are only three centroids in the second iteration and two centroids
    left in the following iterations. This happens because the algorithm keeps finding
    a higher density of data points for assigning centroids.
  prefs: []
  type: TYPE_NORMAL
- en: Key takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In summary, the centroid-based clustering methods aim to find centroids to be
    used as references for clustering data. In order to achieve that, the algorithm
    has to calculate the centroids to get the optimal ones repeatedly. This results
    in the changes of centroids and clusters during the process.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of this article is to apply data visualization to express the process,
    which can be useful in showing how each algorithm works and monitoring the change
    in the process. If you have any suggestions or questions, please feel free to
    comment.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of my data visualization articles that you may find interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Visualizing 3 Sklearn Cross-validation: K-Fold, Shuffle & Split, and Time Series
    Split ([link](https://medium.com/towards-data-science/visualizing-sklearn-cross-validation-k-fold-shuffle-split-and-time-series-split-a13221eb5a56))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9 Visualizations with Python that Catch More Attention than a Bar Chart ([link](/9-visualizations-that-catch-more-attention-than-a-bar-chart-72d3aeb2e091))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8 Visualizations with Python to Handle Multiple Time-Series Data ([link](/8-visualizations-with-python-to-handle-multiple-time-series-data-19b5b2e66dd0))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing the Effect of Multicollinearity on Multiple Regression Model ([link](https://medium.com/towards-data-science/visualizing-the-effect-of-multicollinearity-on-multiple-regression-model-8f323ef542a9))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Techniques, A. (n.d.). *What are the benefits and challenges of using cluster
    analysis in decision making?*. Cluster Analysis for Decision Making: Benefits
    and Challenges. [https://www.linkedin.com/advice/3/what-benefits-challenges-using-cluster-analysis](https://www.linkedin.com/advice/3/what-benefits-challenges-using-cluster-analysis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikimedia Foundation. (2023, July 24). *Cluster analysis*. Wikipedia. [https://en.wikipedia.org/wiki/Cluster_analysis](https://en.wikipedia.org/wiki/Cluster_analysis)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Examples*. Scikit. (n.d.). [https://scikit-learn.org/stable/auto_examples](https://scikit-learn.org/stable/auto_examples/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharma, N. (2023, April 19). *K-means clustering explained*. neptune.ai. [https://neptune.ai/blog/k-means-clustering](https://neptune.ai/blog/k-means-clustering)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GeeksforGeeks. (2023b, January 23). *ML: Mini batch K-means clustering algorithm*.
    GeeksforGeeks. [https://www.geeksforgeeks.org/ml-mini-batch-k-means-clustering-algorithm](https://www.geeksforgeeks.org/ml-mini-batch-k-means-clustering-algorithm)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firdaus, A. (2020, May 9). *Bisecting K-means clustering*. Medium. [https://medium.com/@afrizalfir/bisecting-kmeans-clustering-5bc17603b8a2](https://medium.com/@afrizalfir/bisecting-kmeans-clustering-5bc17603b8a2)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yufeng. (2022, February 22). *Understanding mean shift clustering and implementation
    with Python*. Medium. [https://towardsdatascience.com/understanding-mean-shift-clustering-and-implementation-with-python-6d5809a2ac40](/understanding-mean-shift-clustering-and-implementation-with-python-6d5809a2ac40)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikimedia Foundation. (2023, July 24). *Mean shift*. Wikipedia. [https://en.wikipedia.org/wiki/Mean_shift](https://en.wikipedia.org/wiki/Mean_shift)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
