- en: The Unreasonable Effectiveness of General Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-unreasonable-effectiveness-of-general-models-b4e822eaeb27](https://towardsdatascience.com/the-unreasonable-effectiveness-of-general-models-b4e822eaeb27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Testing a generalist model on a ridiculously hard problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)
    ·8 min read·Jan 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e0cce5f765f3d90678879ef2406c1b7d.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Image by Author, made with Excalidraw]'
  prefs: []
  type: TYPE_NORMAL
- en: In a [previous article](https://medium.com/towards-data-science/what-is-better-one-general-model-or-many-specialized-models-9500d9f8751d),
    I tried to debunk the somewhat diffuse idea that a bunch of models (each specialized
    on a subset of a dataset) should perform better than a single model.
  prefs: []
  type: TYPE_NORMAL
- en: To do that, I took a portion of a dataset (e.g. only the American customers)
    and trained a model on that group, a.k.a. a **specialized model**. Then, I trained
    a second model on the whole dataset (i.e. on all the customers, regardless of
    their nationality), a.k.a a **general model**. In the end, I compared the performance
    of the two models on a holdout set made only of observations belonging to the
    group.
  prefs: []
  type: TYPE_NORMAL
- en: 'I repeated this procedure on multiple datasets and on multiple groups of the
    same dataset, for a total of 600 comparisons. **There was a clear winner: the
    general model**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, my experiment did not convince some people, who argued that my approach
    was oversimplified. For instance, this was one of the most liked comments under
    my Linkedin post about the article:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4fdb1b7f061a8941066769f1d1c26b1b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Screenshot from the comment section of my [Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:7015963227549282305/)]'
  prefs: []
  type: TYPE_NORMAL
- en: This comment intrigued me, so I decided to follow the suggestion. If you are
    curious to see how it turned out, bear with me.
  prefs: []
  type: TYPE_NORMAL
- en: A working hypothesis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In my previous article, I demonstrated that there is a clear benefit in using
    a general model over specialized models when there is some similarity across the
    groups composing the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: However, **as the groups become more and more different from each other**, it
    is reasonable to expect that **the benefit of using a general model gets smaller
    and smaller**. In the most extreme case, i.e. when the groups are completely different
    from each other, the difference between the two approaches should equal zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'If my intuition is correct, we could sketch this relationship as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9916f64ce2db6b94172f99af9069dea5.png)'
  prefs: []
  type: TYPE_IMG
- en: A sketch of my working hypothesis. You can read the “previous article” [here](/what-is-better-one-general-model-or-many-specialized-models-9500d9f8751d).
    [Image by Author, made with Excalidraw]
  prefs: []
  type: TYPE_NORMAL
- en: But this is just my hypothesis. So let’s try to put it to the test.
  prefs: []
  type: TYPE_NORMAL
- en: Giving our model a hard time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our goal is to answer this question:'
  prefs: []
  type: TYPE_NORMAL
- en: What happens if the groups composing a dataset are completely different from
    each other, and we still use a general model?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So, the point becomes how to simulate such a scenario.
  prefs: []
  type: TYPE_NORMAL
- en: The most extreme idea is to “glue” different datasets together. And when I say
    “different”, I mean datasets that have **not only different columns, but even
    different tasks**, i.e. they aim to predict different things.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take three datasets for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '“bank”: each row is a bank’s customer, the task is to predict whether he/she
    will subscribe a term deposit;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“employee”: each row is an employee, the task is to predict whether he/she
    will leave the company;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“income”: each row is a person, the task is to predict whether his/her income
    is above 50k $.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gluing together the target variables of these datasets is easy: since they
    are all binary variables made by 0s and 1s, this is straightforward. But the situation
    becomes more complicated when we try to concatenate the features. Let me explain
    why.'
  prefs: []
  type: TYPE_NORMAL
- en: Here is a sample (both rows and columns) of the three datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8add37e63e1c1e711e4d533ce9e9852.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Three example datasets: “bank”, “employee” and “income”. [Image by Author]'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the datasets have different columns. So, how can we merge them
    together? The first, most naive idea is to use `pd.concat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'But, if we did that, we would obtain a dataframe of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41a85c6ab8195d7ca888338f31f6d095.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First attempt: naive concatenation. [Image by Author]'
  prefs: []
  type: TYPE_NORMAL
- en: Pandas by default concatenates only the columns that have the same name. In
    this case, each dataset has different column names, therefore the result has a
    diagonal-like structure. But this is not satisfactory, because it would allow
    the model to cut corners. Indeed, the model would be able to implicitly discern
    one dataset from the other, based on the columns that are not null.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid that, **we need a way to “force” the merge of the columns of the different
    datasets**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only way I could think of is renaming the columns of each dataset with
    a progressive number: “feature_01”, “feature_02”, etc. But that wouldn’t work
    because the columns have different types. So we need to make a distinction between
    categorical and numerical features: “cat_feature_01”, “cat_feature_02”, etc. and
    “num_feature_01”, “num_feature_02”, etc. Moreover, I decided to sort the features
    by decreasing importance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the resulting output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a3999c3f617d6490fb42bf5cd4354b24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Second attempt: renaming columns with a progressive number. [Image by Author]'
  prefs: []
  type: TYPE_NORMAL
- en: Maybe you are thinking this is not enough. After all, the model may still recognize
    some categories that belong to a given dataset (for example, “married” in column
    “cat_feature_01” exists only in the “bank” dataset). The same goes for numerical
    features (for example, values between 0 and 1 in column “num_feature_02” exist
    only in the “employee” dataset). This can still be helpful for the model, and
    we want to avoid that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, as an additional step, I:'
  prefs: []
  type: TYPE_NORMAL
- en: mapped each value of each categorical feature to a different integer (ordinal
    encoding);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: standardized the numerical columns of each original dataset by subtracting their
    mean and dividing by their standard deviation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, this is the ultimate result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/adb8ab0d7c4f230ebcefd190bf42bab3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Third and last attempt: ordinal encoding, standardization, and then renaming
    columns with a progressive number. [Image by Author]'
  prefs: []
  type: TYPE_NORMAL
- en: Disclaimer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I know you may think that this procedure —artfully sticking together some totally
    unrelated datasets — is a bit odd. You are right: what we are doing would make
    no sense in a real world setting.'
  prefs: []
  type: TYPE_NORMAL
- en: But you must keep in mind that this is **a didactical experiment to push the
    capabilities of a general model to its limits, and see if it can still be competitive
    with specialized models**.
  prefs: []
  type: TYPE_NORMAL
- en: This experiment must be intended as a sort of “stress test” of the capabilities
    of tree-based gradient boosting models.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have designed a strategy, it’s time to apply it to some real datasets.
    I have used 7 datasets for binary classification with more than 5,000 rows that
    are available in [Pycaret](https://github.com/pycaret/pycaret) (a Python library
    under [MIT license](https://github.com/pycaret/pycaret/blob/master/LICENSE)).
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the datasets, with the respective number of rows and columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1525434f90efb6f1ab827f4411f2dcdf.png)'
  prefs: []
  type: TYPE_IMG
- en: Pycaret datasets, with their shape. [Image by Author]
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, I applied the procedure described above, which means that I performed
    the following actions for each dataset separately:'
  prefs: []
  type: TYPE_NORMAL
- en: I have renamed each categorical column (sorted in decreasing order of importance)
    as “cat_feature_01”, “cat_feature_02”, … and each numerical column (sorted in
    decreasing order of importance) as “num_feature_01”, “num_feature_02”, …;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'for each categorical column, I have mapped every value into a distinct integer:
    0, 1, 2, …;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for each numerical column, I have standardized the values by subtracting their
    mean and dividing by their standard deviation;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I have added a column containing the dataset name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, I merged all the original datasets to obtain the final dataset. At this
    point, I proceeded with the experiment. This consisted in:'
  prefs: []
  type: TYPE_NORMAL
- en: training a general model (Catboost, with no parameter tuning) on the full merged
    dataset;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: training 7 specialized models (Catboost, with no parameter tuning), one on each
    original dataset;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: compare the performance of the general model and the specialized model on each
    dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/3366eada72820b9af39c9e6de28d7661.png)'
  prefs: []
  type: TYPE_IMG
- en: Procedure of comparing a general and a specialized model on a group of the dataset.
    [Image by Author]
  prefs: []
  type: TYPE_NORMAL
- en: The first thing that I noticed looking at the results is that the **correlation
    between the predictions made by the general model and the predictions made by
    the specialized models is 98%**, indicating that they produce very similar output.
  prefs: []
  type: TYPE_NORMAL
- en: But what about performance?
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a comparison of the ROC scores of the general model versus the specialized
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1f05605cbf84d974915079c7a1cdbba1.png)'
  prefs: []
  type: TYPE_IMG
- en: ROC scores compared. [Image by Author]
  prefs: []
  type: TYPE_NORMAL
- en: The mean difference between the general model’s ROC score and the specialized
    model’s ROC score is -0.53%. This means that **the specialized models generally
    outperformed the general model**.
  prefs: []
  type: TYPE_NORMAL
- en: However, I must say I am impressed by how tiny the difference is. **We made
    a test in a ridiculously hard setting, and still, the general model was able to
    achieve performance very close to the specialized models**. This is evidence of
    how effective a general model is, even on this insanely difficult problem.
  prefs: []
  type: TYPE_NORMAL
- en: What about explainability?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another concern that I have heard about general models is their alleged lack
    of explainability. In fact, some people claim that a single general model is less
    transparent than many specialized models.
  prefs: []
  type: TYPE_NORMAL
- en: I don’t agree with this point. In fact, thanks to SHAP values, you can explain
    each group separately from the others, even if the model is unique. We could call
    this process “specialized explainability”.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/129b809160a5fc68968df8d30136bbe3.png)'
  prefs: []
  type: TYPE_IMG
- en: Specialized explainability. [Image by Author]
  prefs: []
  type: TYPE_NORMAL
- en: Let me give an example, using our previous experiment.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take each group separately and compute the correlation coefficient between
    the original feature values and the respective SHAP values, this is what we obtain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8b8a271f92d16c3d0a402b0bc687a970.png)'
  prefs: []
  type: TYPE_IMG
- en: Correlation between each merged feature and the respective SHAP values. [Image
    by Author]
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the correlation coefficients change a lot across the groups.
    For instance, if we take “num_feature_01” the correlation is positive for the
    group “bank”, whereas it is negative for the group “employee”. This makes a lot
    of sense, in fact:'
  prefs: []
  type: TYPE_NORMAL
- en: For the group “bank”, “num_feature_01” corresponds to the feature “duration”,
    which is how long that person has been an account holder. The target feature is
    whether the client subscribed a term deposit. It is reasonable to expect a positive
    impact of the feature on the prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the group “employee”, “num_feature_01” corresponds to the feature “satisfaction_level”.
    Since the target feature is whether the employee has left, the negative correlation
    is easily explained.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this article, I simulated the most difficult scenario for a general model:
    a case in which the groups composing the dataset are completely different from
    each other.'
  prefs: []
  type: TYPE_NORMAL
- en: To simulate this situation, **I merged some datasets that had nothing to do
    with each other, nor the features, and not even the prediction task**! I have
    used a trick to make sure that the columns of the different datasets were concatenated
    together even if they had different names.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, I trained a general model on the merged dataset and many specialized
    models: one for each original dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This was a stress test, to see what would happen in a ridiculously hard situation
    for the general model. **Nevertheless, I found out that the difference in performance
    is minimum**: 0.53% average loss in ROC score using a general model instead of
    specialized models.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, I used the experiment to show why **explainability should not be a
    concern either**. In fact, after using a general model, one can still explain
    the single groups separately through “specialized explainability”.
  prefs: []
  type: TYPE_NORMAL
- en: You can find all the Python code used for this article in [this notebook](https://github.com/smazzanti/general_vs_specialized_models/blob/main/unreasonable-effectiveness-of-general-models.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: '*Thank you for reading!*'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you find my work useful, you can subscribe to* [***get an email every time
    that I publish a new article***](https://medium.com/@mazzanti.sam/subscribe) *(usually
    once a month).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you want to support my work, you can* [***buy me a coffee***](https://ko-fi.com/samuelemazzanti)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you’d like,* [***add me on Linkedin***](https://www.linkedin.com/in/samuelemazzanti/)*!*'
  prefs: []
  type: TYPE_NORMAL
