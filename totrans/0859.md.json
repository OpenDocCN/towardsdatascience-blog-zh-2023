["```py\nfrom transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification\nimport tensorflow as tf\n\nclass BERT_model_full:\n    \"\"\"\n    BERT model predicting on all inputs at once\n    \"\"\"\n\n    def __init__(self):\n\n        self.model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n    def predict(self,inputs):\n\n        tf_batch = self.tokenizer(inputs, max_length=128, padding=True, truncation=True, return_tensors='tf')\n        tf_outputs = self.model(tf_batch)\n\n        return(tf_outputs.logits.numpy())\n\nclass BERT_model_batch:\n    \"\"\"\n    BERT model predicting on batches of 100 inputs at a time\n    \"\"\"\n\n    def __init__(self):\n\n        self.model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n    def predict(self,inputs):\n\n        # Pred by batchsize\n        i = 0\n        batch_size = 100\n        og_preds = []\n        int_preds = []\n\n        while i < len(inputs):\n\n            j = min([len(inputs),i+batch_size])\n            tf_batch = self.tokenizer(inputs[i:j], max_length=128, padding=True, truncation=True, return_tensors='tf')\n            tf_outputs = self.model(tf_batch)\n\n            i = j\n\n        return(True)\n\nclass BERT_model_single:\n    \"\"\"\n    BERT model predicting on a single input at a time\n    \"\"\"\n\n    def __init__(self):\n\n        self.model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n    def predict(self,inputs):\n\n        for i in inputs:\n            tf_batch = self.tokenizer([i], max_length=128, padding=True, truncation=True, return_tensors='tf')\n            tf_outputs = self.model(tf_batch)\n\n        return(tf_outputs.logits.numpy())\n```", "```py\nsize_list = [1,10,100,1000,2000,4000,6000,8000]\nsingle_time_list = []\nbatch_time_list = []\nfull_time_list = []\n\nBERT = BERT_model_single()\nprint(\"BERT Single Input:\")\nfor s in size_list:\n    data = imdb_data.sample(s)['DATA_COLUMN']\n\n    start = time.time()\n\n    _ = BERT.predict(data)\n\n    end = time.time()\n\n    single_time_list.append(end-start)\n    print(f\"{s} samples: {(end-start)/60:.2f} minutes\")\n\nBERT = BERT_model_batch()\nprint(\"\\nBERT Small Batch:\")\nfor s in size_list:\n    data = list(imdb_data.sample(s)['DATA_COLUMN'])\n\n    start = time.time()\n\n    _ = BERT.predict(data)\n\n    end = time.time()\n\n    batch_time_list.append(end-start)\n    print(f\"{s} samples: {(end-start)/60:.2f} minutes\")\n\nBERT = BERT_model_full()\nprint(\"\\nBERT Full Batch:\")\nfor s in size_list:\n    data = list(imdb_data.sample(s)['DATA_COLUMN'])\n\n    start = time.time()\n\n    _ = BERT.predict(data)\n\n    end = time.time()\n\n    full_time_list.append(end-start)\n    print(f\"{s} samples: {(end-start)/60:.2f} minutes\")\n```", "```py\ntf_batch = self.tokenizer(inputs, max_length=128, \n                          padding=True, truncation=True, \n                          return_tensors='tf')\n```", "```py\n1000 samples:\nTokenizer Time: 0.06 minutes\nPredictionn Time: 1.97 minutes\nTokenizer takes up 3.06%  of prediction time\n\n4000 samples:\nTokenizer Time: 0.29 minutes\nPredictionn Time: 27.25 minutes\nTokenizer takes up 1.06%  of prediction time\n```", "```py\nimport os\ndata = list(imdb_data.sample(4000)['DATA_COLUMN'])\nfull_time_list = []\nversions = [\"2.10.0\",\"2.6.1\",\"1.15.4\",\"1.15.0\"]\nfor version in versions:\n    print(version,\":\")\n    os.system(f\"pip install tensorflow=={version}\")\n\n    try:\n        from transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification\n        import tensorflow as tf\n    except:\n        print(\"Cannot import relevant packages\")\n        continue\n\n    BERT = BERT_model_full()\n\n    start = time.time()\n\n    _ = BERT.predict(data)\n\n    end = time.time()\n\n    minutes = (end-start)/60\n    full_time_list.append(minutes)\n    print(f\"{s} batch size: {minutes:.2f} minutes\")\n```"]