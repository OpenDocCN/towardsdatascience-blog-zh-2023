- en: 'Courage to Learn ML: A Deeper Dive into F1, Recall, Precision, and ROC Curves'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 勇敢学习机器学习：深入探讨F1分数、召回率、精确度和ROC曲线
- en: 原文：[https://towardsdatascience.com/courage-to-learn-ml-a-deeper-dive-into-f1-recall-precision-and-roc-curves-d5c0a46e5eb7](https://towardsdatascience.com/courage-to-learn-ml-a-deeper-dive-into-f1-recall-precision-and-roc-curves-d5c0a46e5eb7)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/courage-to-learn-ml-a-deeper-dive-into-f1-recall-precision-and-roc-curves-d5c0a46e5eb7](https://towardsdatascience.com/courage-to-learn-ml-a-deeper-dive-into-f1-recall-precision-and-roc-curves-d5c0a46e5eb7)
- en: 'F1 Score: Your Key Metric for Imbalanced Data — But Do You Really Know Why?'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: F1分数：你对不平衡数据的关键指标——但你真的知道为什么吗？
- en: '[](https://amyma101.medium.com/?source=post_page-----d5c0a46e5eb7--------------------------------)[![Amy
    Ma](../Images/2edf55456a1f92724535a1441fa2bef5.png)](https://amyma101.medium.com/?source=post_page-----d5c0a46e5eb7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d5c0a46e5eb7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d5c0a46e5eb7--------------------------------)
    [Amy Ma](https://amyma101.medium.com/?source=post_page-----d5c0a46e5eb7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://amyma101.medium.com/?source=post_page-----d5c0a46e5eb7--------------------------------)[![Amy
    Ma](../Images/2edf55456a1f92724535a1441fa2bef5.png)](https://amyma101.medium.com/?source=post_page-----d5c0a46e5eb7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d5c0a46e5eb7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d5c0a46e5eb7--------------------------------)
    [Amy Ma](https://amyma101.medium.com/?source=post_page-----d5c0a46e5eb7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d5c0a46e5eb7--------------------------------)
    ·12 min read·Dec 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----d5c0a46e5eb7--------------------------------)
    ·阅读时间12分钟·2023年12月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f5a423ae041e3906b5aed54f7892aeb6.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5a423ae041e3906b5aed54f7892aeb6.png)'
- en: We’ll use the analogy of sorting laundry to illustrate the core concepts of
    recall and precision; Photo by [Ace Maxwell](https://unsplash.com/@acedibwai?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用排序衣物的类比来说明召回率和精确度的核心概念；照片由[Ace Maxwell](https://unsplash.com/@acedibwai?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Welcome back to our journey with the ‘[Courage to Learn ML](http://towardsdatascience.com/tagged/courage-to-learn-ml)’
    series. In this session, we’re exploring the nuanced world of metrics. Many resources
    introduce these metrics or delve into their mathematical aspects, yet the logic
    behind these ‘simple’ maths can sometimes remain opaque. For those new to this
    topic, I recommend checking out Shervin’s thorough [post](/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)
    along with the comprehensive guide from [neptune.ai](https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎回到我们‘[勇敢学习机器学习](http://towardsdatascience.com/tagged/courage-to-learn-ml)’系列的旅程中。在本节中，我们将探索度量指标的细微世界。许多资源介绍了这些指标或深入探讨其数学方面，但这些‘简单’数学背后的逻辑有时可能仍然不透明。对于那些刚接触这个话题的人，我建议查看Shervin的详细[文章](/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)以及[neptune.ai](https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide)提供的全面指南。
- en: In typical data science interview preparations, when addressing how to handle
    imbalanced data, the go-to metric is often the F1 score, known as the harmonic
    mean of recall and precision. However, the rationale behind why the F1 score is
    particularly suitable for such cases is frequently left unexplained. This post
    is dedicated to unraveling these reasons, helping you understand the choice of
    specific metrics in various scenarios.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的数据科学面试准备中，处理不平衡数据时，通常首选的指标是F1分数，它被称为召回率和精确度的调和均值。然而，为什么F1分数特别适用于这种情况的理由往往没有解释。本文致力于揭示这些理由，帮助你理解在不同情境下选择特定指标的原因。
- en: 'As usual, this post will outline all the questions we’re tackling. If you’ve
    been pondering these same queries, you’re in the right place:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 正如往常一样，本篇文章将概述我们要解决的所有问题。如果你一直在思考这些问题，你来对地方了：
- en: What exactly are precision and recall, and how can we intuitively understand
    them?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度和召回率到底是什么，我们如何直观地理解它们？
- en: Why are precision and recall important, and why do they often seem to conflict
    with each other? Is it possible to achieve high levels of both?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么精确度和召回率很重要，它们为什么经常看起来相互冲突？是否可以同时达到这两者的高水平？
- en: What’s the F1 score, and why do we calculate it as the harmonic mean of recall
    and precision?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 F1 分数，我们为什么将其计算为召回率和精确度的调和平均数？
- en: Why is the F1 score frequently used for imbalanced data? Is it only useful in
    these scenarios?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么 F1 分数常用于不平衡数据？它只在这些情况下有用吗？
- en: How does the interpretation of the F1 score change when the positive class is
    the majority?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当正类是多数时，F1 分数的解释会有什么变化？
- en: What’s the difference between PR and ROC curves, and when should we prefer using
    one over the other?
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PR 曲线和 ROC 曲线有什么区别，我们应该什么时候优先使用其中之一？
- en: 'With a fundamental understanding of these metrics, our learner approaches the
    mentor, who is busy doing laundry, with the first question:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在对这些指标有了基本了解后，我们的学习者向正在忙于洗衣的导师提出了第一个问题：
- en: I’m working on a game recommendation system. It’s designed to suggest video
    games based on users’ preferences and lifestyles. But I’ve noticed that it mostly
    recommends popular games, like this year’s TGA game — Baldur’s Gate, and users
    are missing out on niche and cult classic games they’re searching for. How can
    I tackle this issue? Should I change my algorithm or maybe use LLM, given its
    power?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我正在开发一个游戏推荐系统。它旨在根据用户的偏好和生活方式推荐视频游戏。但我发现它主要推荐流行游戏，比如今年的 TGA 游戏《博德之门》，用户错过了他们寻找的冷门和经典游戏。我该如何解决这个问题？我应该更改算法还是使用
    LLM，考虑到它的强大功能？
- en: '![](../Images/dc7076556afad4aff7c8b80455dfb9ea.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc7076556afad4aff7c8b80455dfb9ea.png)'
- en: Photo by [Nick Hamze](https://unsplash.com/@nickhamze?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[Nick Hamze](https://unsplash.com/@nickhamze?utm_source=medium&utm_medium=referral)
    的照片，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Let’s not rush to the conclusion that you need the most advanced algorithm just
    yet. Instead, let’s explore why your model isn’t performing as expected. It seems
    your model scores well in Precision@k but get a low Recall@k.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们不要急于得出你需要最先进算法的结论。相反，让我们探讨一下为什么你的模型没有按预期表现。看起来你的模型在 Precision@k 上得分很高，但 Recall@k
    很低。
- en: 'To understand this better, let’s break down these metrics:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些指标，让我们逐一解析：
- en: '*Percision@k = (# of top k recommendations that are relevant)/(# of items that
    are recommended)*. In simple terms, it measures how many of the games your model
    recommends are actually relevant to the users.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Precision@k = (相关的前 k 个推荐数量)/(推荐的项目总数)*。简单来说，它衡量了你模型推荐的游戏中实际对用户相关的数量。'
- en: '*Recall@k = (# of top k recommendations that are relevant)/(# of all relevant
    items)*. This tells us how many of the relevant games actually make it to your
    top k recommendations.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Recall@k = (相关的前 k 个推荐数量)/(所有相关项目的总数)*。这告诉我们相关游戏中有多少实际出现在你的前 k 个推荐中。'
- en: From this, it seems users often find relevant games in your recommendations,
    but not all relevant games are making it to your top k list. It’s important to
    note that the items recommended are those your model predicts to be relevant,
    which can be considered as ‘the number of items predicted to be relevant’.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从中可以看出，用户经常能在你的推荐中找到相关游戏，但并不是所有相关游戏都能出现在你的前 k 个列表中。需要注意的是，推荐的项目是你模型预测为相关的项目，这可以被视为‘预测为相关的项目数量’。
- en: Hold on, are you suggesting I should use both recall and precision to evaluate
    my model? But aren’t recall and precision mainly used for imbalanced data, similar
    to their harmonic mean, the F1 score?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 等等，你是建议我使用召回率和精确度来评估我的模型吗？但召回率和精确度主要用于不平衡数据，不是吗？它们的调和平均数 F1 分数也是如此。
- en: 'You’ve grasped an essential aspect of precision and recall, and you understand
    why accuracy isn’t always reliable. However, your perspective on recall and precision
    seems a bit limited, and you shouldn’t restrict them to just one scenario, handling
    imbalanced data. Let’s dissect this into smaller parts, starting with:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经掌握了精确度和召回率的一个重要方面，并理解了为什么准确率并不总是可靠。然而，你对召回率和精确度的看法似乎有些局限，不应将它们仅限于处理不平衡数据的场景。让我们把这个问题分解成更小的部分，从以下开始：
- en: What are precision and recall?
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确度和召回率是什么？
- en: '**Precision measures the accuracy of the model’s positive predictions**, calculated
    as'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度衡量了模型的正预测的准确性**，计算公式为：'
- en: '*Precision = # of samples correctly predicted as positive / total # of samples
    predicted as positive = true positive / (true positive + false positive)*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*Precision = 正确预测为正类的样本数量 / 预测为正类的样本总数 = 真正例 / (真正例 + 假正例)*'
- en: On the other hand, **recall assesses how well the model identifies all positive
    cases**, calculated as
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**召回率评估模型识别所有正例的能力**，计算方法如下：
- en: '*recall = # of samples correctly predicted as positive / total # of actual
    positive samples = true positive / (true positive + false negative)*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率 = 正确预测为正的样本数量 / 实际正样本总数 = 真正例 / (真正例 + 假负例)*'
- en: '*A quick tip for remembering TP, TN: The first letter (True/False) indicates
    if your prediction is correct or not, while the second (Positive/Negative) refers
    to the* ***predicted*** *label. So, true positive means ‘correctly predicted as
    positive,’ and false negative is ‘incorrectly predicted as negative…it’s actually
    positive!’*'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*记住 TP 和 TN 的一个快速提示：第一个字母（True/False）表示你的预测是否正确，而第二个字母（Positive/Negative）则指的是*
    ***预测的*** *标签。因此，真正例（true positive）意味着‘正确预测为正’，而假负例（false negative）则是‘错误预测为负……实际上是正的！’*'
- en: ''
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*The total number of predicted positives is the sum of true* ***positives***
    *(TP) and false* ***positives*** *(FP).*'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*预测为正的总数量是* ***真正例*** *(TP) 和假* ***正例*** *(FP) 的总和。*'
- en: '![](../Images/6fb36a429d07f2300023ad230dd0a9e1.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6fb36a429d07f2300023ad230dd0a9e1.png)'
- en: 'source: [https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png)'
- en: 'Let me offer **an intuitive example** to understand those two terms: Consider
    I’m sorting laundry, my aim is to select all the dirty clothes from the pile for
    washing. In this scenario, precision is about how accurately I can identify a
    piece of clothing as dirty. Meanwhile, recall measures how many of the actual
    dirty clothes I can correctly identify'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我提供**一个直观的例子**来理解这两个术语：假设我在整理衣物，我的目标是从堆积的衣物中挑选出所有脏衣物进行洗涤。在这种情况下，精确度指的是我能多准确地识别出一件衣物是否脏。同时，召回率则衡量我能正确识别出多少实际的脏衣物。
- en: 'Then, our next question is:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们的下一个问题是：
- en: Why do we care about precision and recall, and why do they often seem to conflict?
    Is it possible to have both high precision and recall?
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么我们关心精确度和召回率，它们为何经常看起来互相冲突？是否可能同时拥有高精确度和高召回率？
- en: '**The importance of precision and recall lies in their complementary nature.**
    Let’s use the laundry sorting analogy again. My objectives are twofold: first,
    to ensure all dirty clothes are picked up, and second, to avoid unnecessary washing.
    Linking this back to metrics, precision is like my aim to correctly identify dirty
    clothes and save effort by not washing clean ones. Recall, meanwhile, assesses
    how well I manage to gather all the dirty clothes.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度和召回率的重要性在于它们的互补性质。** 再次使用衣物分类的类比。我的目标有两个：首先，确保所有脏衣物都被挑选出来，其次，避免不必要的洗涤。将其与指标联系起来，精确度就像是我正确识别脏衣物并通过不洗干净的衣物来节省精力。而召回率则评估我成功收集所有脏衣物的能力。'
- en: 'To clarify, let’s look at two extreme scenarios:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了澄清，我们来看看两个极端的情况：
- en: With a focus solely on high precision, I’d be extremely selective, only choosing
    visibly stained clothes for the wash. This means potentially overlooking less
    obvious dirt, like a shirt with only a bit of cat hair. Consequently, I’d end
    up washing only a small portion of the laundry, leaving behind some dirty items
    (hence, low recall).
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果只关注高精确度，我会非常挑剔，只选择明显有污渍的衣物进行洗涤。这意味着可能会忽略一些不太明显的污垢，比如只有一点猫毛的衬衫。因此，我只会洗涤一小部分衣物，留下些脏衣物（因此召回率低）。
- en: If I prioritize high recall, I’d wash everything without sorting. This ensures
    all dirty clothes are cleaned but at the expense of washing clean items too (resulting
    in low precision).
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我优先考虑高召回率，我会在没有分类的情况下洗涤所有衣物。这确保了所有脏衣物都被清洗，但也意味着清洁的衣物也会被洗涤（导致精确度低）。
- en: No matter what kind of laundry types you are, you can see the choice of metrics
    does impact our (the model’s ) behaviors. **Recall and precision measure different
    aspects and optimizing both simultaneously is challenging**. That’s why in classification,
    we talk about the trade-off between them. They work together to ensure our model
    accurately predicts while capturing all positive cases.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你处理什么类型的衣物，你可以看到，选择的指标确实会影响我们的（模型的）行为。**召回率和精确度衡量了不同的方面，同时优化这两个指标是具有挑战性的**。这就是为什么在分类中，我们谈论它们之间的权衡。它们共同作用，以确保我们的模型准确预测，同时捕捉到所有正例。
- en: 'Next, let’s dive into:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们深入探讨：
- en: What is the F1 score, and why is it calculated as the harmonic mean of recall
    and precision?
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 F1 分数，为什么它被计算为召回率和精确率的调和平均数？
- en: Most data science interview guides suggest handling imbalanced data by using
    the F1 score, which is the harmonic mean of recall and precision. But often, they
    don’t explain why the F1 score is effective in these situations.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据科学面试指南建议通过使用 F1 分数来处理不平衡数据，F1 分数是召回率和精确率的调和平均数。但通常，它们没有解释为什么 F1 分数在这些情况下有效。
- en: Then, why use the F1 score? In model evaluations, we’re concerned with balancing
    precision and recall — we want correct predictions and comprehensive coverage.
    Monitoring both metrics separately can be tedious, so a single measure that reflects
    the balance is preferred. A simple average doesn’t reveal much about the balance;
    a high score could still mask an imbalance. However, the harmonic mean, used in
    the F1 score, penalizes extreme values more severely. If either recall or precision
    is low, it significantly lowers the F1 score.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么使用 F1 分数？在模型评估中，我们关注的是平衡精确率和召回率——我们希望正确的预测和全面的覆盖。单独监控这两个指标可能很繁琐，因此更喜欢一个反映这种平衡的单一指标。简单平均并没有揭示平衡的很多信息；高分数仍可能掩盖不平衡。然而，F1
    分数中使用的调和平均数对极端值的惩罚更为严重。如果召回率或精确率较低，它将显著降低 F1 分数。
- en: 'Consider two hypothetical cases to understand why we use the harmonic mean
    instead of a simple average:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑两个假设的案例以理解为什么我们使用调和平均数而不是简单平均数：
- en: '**Scenario A**: Precision = 0.9, Recall = 0.1'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景 A**: 精确率 = 0.9，召回率 = 0.1'
- en: '**Scenario B**: Precision = 0.5, Recall = 0.5 (more balanced case)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景 B**: 精确率 = 0.5，召回率 = 0.5（更平衡的情况）'
- en: '**Simple average calculation**:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单平均计算**:'
- en: 'Scenario A: (0.9 + 0.1) / 2 = 0.5'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '场景 A: (0.9 + 0.1) / 2 = 0.5'
- en: 'Scenario B: (0.5 + 0.5) / 2 = 0.5'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '场景 B: (0.5 + 0.5) / 2 = 0.5'
- en: '**Harmonic mean calculation** (F1 Score):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**调和平均计算**（F1 分数）:'
- en: 'Scenario A: 2 * (0.9 * 0.1) / (0.9 + 0.1) = 0.18'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '场景 A: 2 * (0.9 * 0.1) / (0.9 + 0.1) = 0.18'
- en: 'Scenario B: 2 * (0.5 * 0.5) / (0.5 + 0.5) = 0.5'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '场景 B: 2 * (0.5 * 0.5) / (0.5 + 0.5) = 0.5'
- en: While both scenarios have the same average, the simple average hides Scenario
    A’s poor recall. **The harmonic mean, on the other hand, provides a more accurate
    reflection of the balance between precision and recall.** A higher F1 score indicates
    a better balance.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这两个场景的平均值相同，但简单平均掩盖了场景 A 的较差召回率。**另一方面，调和平均数提供了对精确率和召回率之间平衡的更准确反映。** 更高的 F1
    分数表明更好的平衡。
- en: Then… why is the F1 Score often used for imbalanced data, and is its use limited
    to these scenarios?
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么……为什么 F1 分数常用于不平衡数据，它的使用是否仅限于这些场景？
- en: Let’s explore the challenges of imbalanced data, which is common in binary classification
    problems. Here, one class often has far fewer samples and represents rare but
    significant cases (like customer churn or cancer diagnosis). These rare cases
    usually have higher consequences, and accurately identifying them is crucial.
    We need a model that not only makes accurate predictions but also effectively
    identifies these rare cases. **This requirement leads us to seek a balance between
    precision and recall, and the F1 score becomes a handy tool.** It provides a single
    number that reflects this balance, making it a preferred metric in imbalanced
    datasets. The F1 score’s value lies in its ability to accurately portray a model’s
    efficacy in spotting the minority class.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨不平衡数据的挑战，这在二分类问题中很常见。在这里，一个类别通常样本数量远少于另一个类别，并且代表了稀有但重要的案例（如客户流失或癌症诊断）。这些稀有案例通常有更高的后果，准确识别它们至关重要。我们需要一个不仅能做出准确预测的模型，还能有效识别这些稀有案例。**这一要求使我们需要在精确率和召回率之间寻求平衡，而
    F1 分数成为一个便捷的工具。** 它提供了一个反映这种平衡的单一数字，使其在不平衡数据集中成为首选指标。F1 分数的价值在于它能准确描绘模型在识别少数类别方面的效果。
- en: However, the F1 score’s usefulness isn’t confined to just imbalanced datasets.
    **It’s also relevant wherever balancing precision and recall is essential, even
    in balanced datasets.** The F1 score remains a vital metric for balancing precision
    and recall, and it simplifies model comparisons.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，F1 分数的有用性并不限于不平衡数据集。**它在任何需要平衡精确率和召回率的地方也很相关，即使是在平衡的数据集中。** F1 分数仍然是平衡精确率和召回率的重要指标，并且简化了模型比较。
- en: Beyond the F1 score, other metrics are also useful for assessing model performance
    in cases of imbalanced data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 F1 分数之外，其他指标在评估不平衡数据的模型表现时也很有用。
- en: I’ve heard that F1, precision, and recall are asymmetric metrics, meaning they
    depend on which class is labeled as positive. How does the F1 score’s interpretation
    change when the positive class is actually the majority?
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我听说过F1、精确度和召回率是非对称的指标，这意味着它们取决于哪个类别被标记为正类。当正类实际上是多数类时，F1分数的解释会发生什么变化？
- en: Good question. To answer that, let’s think about how recall and precision would
    shift if the majority class is considered positive. Achieving a high recall becomes
    easier because most samples will be predicted as positive.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 好问题。为了回答这个问题，我们可以考虑一下，如果将多数类视为正类，召回率和精确度会如何变化。由于大多数样本将被预测为正类，获得高召回率变得更容易。
- en: 'But here’s the catch: **high precision might be misleading in this scenario**.
    With a larger majority class, it’s easy to get high precision just by predicting
    the majority class all the time. By switching the majority class to positive,
    we lose sight of how the model handles the rare class, especially in imbalanced
    data situations. **So, the balance between precision and recall doesn’t guarantee
    the model’s effectiveness anymore since its focus has shifted.** This means a
    model might show a high F1 score even if it’s not great at identifying the minority
    class.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里有一个问题：**高精确度在这种情况下可能具有误导性**。由于多数类较大，仅仅通过始终预测多数类就容易获得高精确度。将多数类转为正类后，我们忽视了模型处理稀有类的能力，特别是在不平衡数据的情况下。**因此，精确度和召回率之间的平衡不再保证模型的有效性，因为其重点已发生转移。**
    这意味着即使模型在识别少数类方面表现不佳，它仍可能显示出高F1分数。
- en: When the positive class forms the majority, a high F1 score might not truly
    reflect the model’s ability to identify the minority class. It could simply mean
    the model often predicts the majority class.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当正类占据多数时，高F1分数可能无法真实反映模型识别少数类的能力。这可能仅仅意味着模型经常预测多数类。
- en: In such cases, it’s wise to include other metrics less biased towards the majority,
    like the recall of the negative (minority) class, to get a fuller picture of the
    model’s performance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，明智的做法是包括其他不那么偏向多数类的指标，比如负类（少数类）的召回率，以便全面了解模型的性能。
- en: What are the limitations of the F1 score, and what other metrics can we use
    to evaluate model performance on imbalanced data?
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: F1分数有哪些局限性？我们还可以使用哪些其他指标来评估不平衡数据上的模型性能？
- en: You know, we often approach classification problems in a regression-like manner.
    What I mean is, some algorithms predict probabilities, not just classes. For these,
    you need to set a threshold. **But the F1 score doesn’t really show how the model
    performs at different thresholds.** That’s where ROC curves or precision-recall
    curves come in, helping us assess performance across various thresholds.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道，我们经常以类似回归的方式来处理分类问题。我的意思是，一些算法预测的是概率，而不仅仅是类别。对于这些算法，你需要设置一个阈值。**但F1分数并不能真正展示模型在不同阈值下的表现。**
    这就是ROC曲线或精确度-召回率曲线发挥作用的地方，它们帮助我们评估在各种阈值下的表现。
- en: It’s quite common that we do classification in regression way. What I mean is
    some algorithm will predict probabilities instead of the class. for those models,
    we need to choose a threshold. **However, F1 score cannot give us an illustration
    on model performance related to different threshold**. So we can use ROC curve
    or precision and recall curve to consider the model performance with various threshold.
    Additionally, the Area Under the Curve (AUC) metric serves as a single-number
    summary, facilitating comparison between multiple models. The AUC scale ranges
    from 1, indicating a perfect classifier, to 0, the mark of the poorest classifier.
    Notably, an AUC of 0.5 signifies performance equivalent to random guessing, where
    True Positive Rate (TPR) and the False Positive Rate (FPR) are equal at all thresholds.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行分类的方式往往是类似回归的。我的意思是，有些算法会预测概率而不是类别。对于这些模型，我们需要选择一个阈值。**然而，F1分数无法提供与不同阈值相关的模型性能的说明。**
    因此，我们可以使用ROC曲线或精确度-召回率曲线来考虑模型在不同阈值下的表现。此外，曲线下面积（AUC）指标作为一个单一的数字总结，方便在多个模型之间进行比较。AUC的范围从1（表示完美的分类器）到0（表示最差的分类器）。值得注意的是，AUC为0.5表示性能等同于随机猜测，此时在所有阈值下真正正类率（TPR）和假正类率（FPR）是相等的。
- en: An interesting question to explore is
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个有趣的问题是
- en: ''
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**How an AUC (Area Under the Curve) value of 0.5 equates to a classifier making
    random guesses?**'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**AUC（曲线下面积）值为0.5如何等同于分类器进行随机猜测？**'
- en: ''
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When the AUC equals 0.5, the ROC curve is represented by a diagonal line connecting
    the points (0,0) and (1,1) on the plot. This diagonal line signifies that with
    this classifier, we have TPR = FPR at all thresholds. In simpler terms, the likelihood
    of correctly identifying a positive case is exactly the same as the likelihood
    of incorrectly labeling it as negative. Therefore, for any given positive instance,
    the classifier has a 50% chance of making a correct prediction, akin to the randomness
    of a coin flip. This equivalence to chance highlights why an AUC of 0.5 is considered
    indicative of a model performing no better than random guessing.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当 AUC 等于 0.5 时，ROC 曲线由连接图中点 (0,0) 和 (1,1) 的对角线表示。这条对角线意味着对于这个分类器，我们在所有阈值下 TPR
    = FPR。简单来说，正确识别一个正例的概率与错误地将其标记为负例的概率完全相同。因此，对于任何给定的正例，分类器正确预测的概率是 50%，类似于掷硬币的随机性。这种与随机性的等同凸显了为什么
    AUC 为 0.5 被认为表示模型的表现不比随机猜测好。
- en: When it comes to imbalanced data, we can use precision-recall curve to observe
    the model’s performance on balancing precision and recall under different threshold.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当面对不平衡的数据时，我们可以使用精确率-召回率曲线来观察模型在不同阈值下平衡精确率和召回率的表现。
- en: '**To sum it up,** for some scenarios, we’d love the model to balance recall
    and precision well. That’s why we use the F1 score, the harmonic mean of recall
    and precision, as a single-number metric. But with imbalanced data, where the
    focus is more on the minority class’s performance, the F1 score becomes particularly
    valuable since achieving balance is tougher. Other handy tools are ROC and PR
    (Precision-Recall) curves.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结一下，** 对于某些场景，我们希望模型能够很好地平衡召回率和精确率。这就是为什么我们使用 F1 分数作为一个单一的度量标准，F1 分数是召回率和精确率的调和均值。但是，在数据不平衡的情况下，特别是在我们更关注少数类别的表现时，F1
    分数变得特别重要，因为实现平衡更具挑战性。其他有用的工具包括 ROC 曲线和 PR（精确率-召回率）曲线。'
- en: So, for your game recommendation system, consider using multiple metrics. This
    way, you can better evaluate how well the model retrieves relevant items (recall)
    and ensures those items are indeed relevant (precision). You could evaluate precision@k
    and recall@k together, calculate f1@k, or draw PR curves.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于你的游戏推荐系统，考虑使用多个指标。这样，你可以更好地评估模型如何检索相关项目（召回率）以及确保这些项目确实相关（精确率）。你可以一起评估 precision@k
    和 recall@k，计算 f1@k，或者绘制 PR 曲线。
- en: '**In practice, it’s crucial to select model metrics based on the actual cost
    of errors**, like whether recall matters more than precision to you. Using multiple
    metrics gives a fuller picture of your model’s performance. And remember, **the
    key is to align your metrics with the model’s business or application goals.**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**在实践中，选择模型指标时必须根据实际错误的成本，** 例如，召回率是否比精确率对你更重要。使用多个指标可以更全面地了解模型的表现。记住，**关键是将你的指标与模型的业务或应用目标对齐。**'
- en: 'Before wrapping up this post, there’s one more topic I’d like to touch on:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束这篇文章之前，还有一个话题我想提一下：
- en: What’s the difference between the PR curve and the ROC curve, and when should
    you choose one over the other?
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PR 曲线和 ROC 曲线之间有什么区别？在什么情况下你应该选择其中一个而不是另一个？
- en: 'Most DS interview guides state using the PR curve instead of the ROC curve
    for imbalanced data, but often don’t explain when to opt for the ROC curve. While
    I won’t delve into how to draw these curves here (for that, check out the excellent
    explanation by StatQuest with Josh Starmer [here](https://www.youtube.com/watch?v=4jRBRDbJemM)),
    let’s understand that these curves are drawn by varying the threshold and calculating
    two metrics (precision and recall for PR, or TPR and FPR for ROC). Both curves
    represent different balances in binary classification:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据科学面试指南建议在数据不平衡时使用 PR 曲线而不是 ROC 曲线，但通常不会解释何时选择 ROC 曲线。虽然我不会在这里详细说明如何绘制这些曲线（有关这一点，请查看
    StatQuest with Josh Starmer 的出色解释 [这里](https://www.youtube.com/watch?v=4jRBRDbJemM)），但我们要了解这些曲线是通过改变阈值并计算两个指标（PR
    的精确率和召回率，或 ROC 的 TPR 和 FPR）绘制的。这两条曲线在二分类中代表了不同的平衡：
- en: '![](../Images/fccd4f803ea68d999c6acd9b76ca3b3e.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fccd4f803ea68d999c6acd9b76ca3b3e.png)'
- en: 'A sample calculation of ROC curve vs. PR curve. source: [https://modtools.files.wordpress.com/2020/01/roc_pr-1.png?w=946](https://modtools.files.wordpress.com/2020/01/roc_pr-1.png?w=946)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线与 PR 曲线的样本计算。来源：[https://modtools.files.wordpress.com/2020/01/roc_pr-1.png?w=946](https://modtools.files.wordpress.com/2020/01/roc_pr-1.png?w=946)
- en: 'The ROC curve focuses on TPR and FPR; the PR curve on precision and recall:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线侧重于 TPR 和 FPR；PR 曲线则侧重于精确率和召回率：
- en: 'TPR (Recall) = # of samples correctly predicted as positive / total actual
    positive samples.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TPR（召回率）= 正确预测为正类的样本数量 / 总实际正样本数量。
- en: 'FPR = # of samples wrongly classified as positive / total actual negative samples.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FPR = 错误分类为正类的样本数量 / 总实际负样本数量。
- en: While precision and recall focus solely on the model’s performance for the positive
    class, TPR and FPR provide a broader view of predictability (correct positives
    vs. misclassified samples).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然精度和召回率仅关注模型在正类上的表现，TPR 和 FPR 提供了预测能力的更广泛视角（正确的正类 vs. 错误分类的样本）。
- en: '**ROC curves are less sensitive to data distribution, as FPR uses the size
    of the negative class.** If the negative class is the majority, the FPR value
    can still remain low, even with lots of negative predictions, due to the larger
    size of this class. This means ROC is less affected by data imbalance. On the
    other hand, PR curves, with precision calculated using predicted positives, are
    more sensitive to the positive class.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**ROC 曲线对数据分布的敏感性较低，因为 FPR 使用负类的大小。** 如果负类是多数类，即使有很多负预测，FPR 值也可能保持较低，因为负类的规模更大。这意味着
    ROC 曲线对数据不平衡的影响较小。另一方面，PR 曲线使用预测的正类来计算精度，对正类更为敏感。'
- en: What does this imply? It means **when comparing model performance across different
    datasets, ROC curves offer more stability than PR curves and can better reflect
    a model’s performance.** So, rather than just remembering PR curves as preferable
    for imbalanced data, it’s important to recognize that ROC curves provide a consistent
    measure less influenced by data distribution.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着什么？这意味着**在比较不同数据集上的模型性能时，ROC 曲线比 PR 曲线提供了更稳定的指标，并能更好地反映模型的性能。** 因此，与其单纯记住
    PR 曲线适用于不平衡数据，重要的是认识到 ROC 曲线提供了一致的度量，受数据分布影响较小。
- en: In our upcoming session, the mentor-learner duo will delve into the common loss
    functions, exploring cross-entropy through the lenses of information theory and
    MLE. If you’re enjoying this series, remember that your interactions — claps,
    comments, and follows — do more than just support; they’re the driving force that
    keeps this series going and inspires my continued sharing.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们即将进行的会议中，导师与学习者的组合将深入探讨常见的损失函数，通过信息理论和 MLE 的视角探讨交叉熵。如果你喜欢这个系列，请记住你的互动——点赞、评论和关注——不仅仅是支持，它们是推动这个系列不断前进的动力，并激励我持续分享。
- en: 'Other posts in this series:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本系列的其他文章：
- en: '[Courage to Learn ML: Demystifying L1 & L2 Regularization (part 1)](/understanding-l1-l2-regularization-part-1-9c7affe6f920)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[勇敢学习机器学习：揭开 L1 和 L2 正则化的神秘面纱（第 1 部分）](/understanding-l1-l2-regularization-part-1-9c7affe6f920)'
- en: '[Courage to Learn ML: Demystifying L1 & L2 Regularization (part 2)](/courage-to-learn-ml-unraveling-l1-l2-regularization-part-2-1bb171e43b35)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[勇敢学习机器学习：揭开 L1 和 L2 正则化的神秘面纱（第 2 部分）](/courage-to-learn-ml-unraveling-l1-l2-regularization-part-2-1bb171e43b35)'
- en: '[Courage to Learn ML: Demystifying L1 & L2 Regularization (part 3)](/courage-to-learn-ml-demystifying-l1-l2-regularization-part-3-ee27cd4b557a)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[勇敢学习机器学习：揭开 L1 和 L2 正则化的神秘面纱（第 3 部分）](/courage-to-learn-ml-demystifying-l1-l2-regularization-part-3-ee27cd4b557a)'
- en: '[Courage to Learn ML: Demystifying L1 & L2 Regularization (part 4)](/courage-to-learn-ml-demystifying-l1-l2-regularization-part-4-27c13dc250f9)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[勇敢学习机器学习：揭开 L1 和 L2 正则化的神秘面纱（第 4 部分）](/courage-to-learn-ml-demystifying-l1-l2-regularization-part-4-27c13dc250f9)'
- en: '[Courage to Learn ML: Decoding Likelihood, MLE, and MAP](/courage-to-learn-ml-decoding-likelihood-mle-and-map-65218b2c2b99)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[勇敢学习机器学习：解码似然性、MLE 和 MAP](/courage-to-learn-ml-decoding-likelihood-mle-and-map-65218b2c2b99)'
- en: If you liked the article, you can find me on [LinkedIn](https://www.linkedin.com/in/yujingma45/),
    and please don’t hesitate to connect or reach out with your questions and suggestions!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，你可以在[LinkedIn](https://www.linkedin.com/in/yujingma45/)找到我，请随时与我联系，提出你的问题和建议！
