["```py\ndef load_data(name):\n    data_dir = os.path.join('data', name)\n    x_train = 1 - np.load(os.path.join(data_dir, 'x_train.npy')) / 255.\n    x_train = x_train.astype(np.float32)\n    y_train = np.load(os.path.join(data_dir, 'y_train.npy'))\n    y_train_oh = tf.keras.utils.to_categorical(y_train)\n    x_test  = 1 - np.load(os.path.join(data_dir, 'x_test.npy')) / 255.\n    x_test = x_test.astype(np.float32)\n    y_test  = np.load(os.path.join(data_dir, 'y_test.npy'))\n    y_test_oh = tf.keras.utils.to_categorical(y_test)\n\n    return (x_train, y_train, y_train_oh), (x_test, y_test, y_test_oh)\n\ndef inspect_images(data, num_images):\n    fig, ax = plt.subplots(nrows=1, ncols=num_images, figsize=(2*num_images, 2))\n    for i in range(num_images):\n        ax[i].imshow(data[i, :, :], cmap='gray')\n        ax[i].axis('off')\n    plt.show()\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\ninspect_images(data=x_train, num_images=8)\n```", "```py\ndef read_prefetch(dataset):\n    x = []\n    y = []\n    for x_, y_ in dataset:\n        x.append(x_)\n        y.append(y_)\n    x = np.asarray(x)\n    y = np.asarray(y)\n    return x, y\n\nx_c_train, y_c_train = read_prefetch(xy_c_train)\nx_c_test, y_c_test = read_prefetch(xy_c_test)\n\ninspect_images(data=x_c_train, num_images=8)\n```", "```py\ndef get_det_model(input_shape, loss, optimizer, metrics):\n\n    model = Sequential([\n        Conv2D(input_shape=input_shape,\n              filters=8,\n              kernel_size=(5,5),\n              activation='relu',\n              padding='valid'),\n        MaxPooling2D(pool_size=(6,6)),\n        Flatten(),\n        Dense(10, activation='softmax')\n    ])\n\n    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n    return model\n\ntf.random.set_seed(0)\ndeterministic_model = get_det_model(\n    input_shape=(28, 28, 1), \n    loss=SparseCategoricalCrossentropy(), \n    optimizer=RMSprop(), \n    metrics=['accuracy']\n)\n\ndeterministic_model.summary()\n\n_________________________________________________________________\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 24, 24, 8)         208       \n\n max_pooling2d (MaxPooling2D  (None, 4, 4, 8)          0         \n )                                                               \n\n flatten (Flatten)           (None, 128)               0         \n\n dense (Dense)               (None, 10)                1290      \n\n=================================================================\nTotal params: 1,498\nTrainable params: 1,498\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\ndeterministic_model.fit(x_train, y_train, epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 8s 4ms/step - loss: 2.1986 - accuracy: 0.8423\nEpoch 2/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.2248 - accuracy: 0.9470\nEpoch 3/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.1678 - accuracy: 0.9563\nEpoch 4/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.1428 - accuracy: 0.9626\nEpoch 5/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.1336 - accuracy: 0.9641\n```", "```py\nprint('Accuracy on MNIST test set: ',\n      str(deterministic_model.evaluate(x_test, y_test, verbose=False)[1]))\nprint('Accuracy on corrupted MNIST test set: ',\n      str(deterministic_model.evaluate(x_c_test, y_c_test, verbose=False)[1]))\n\nAccuracy on MNIST test set:  0.9659000039100647\nAccuracy on corrupted MNIST test set:  0.902400016784668\n```", "```py\ndef nll(y_true, y_pred):\n    return -y_pred.log_prob(y_true)\n\ndef get_probabilistic_model(input_shape, loss, optimizer, metrics):\n\n    model = Sequential([\n        Conv2D(input_shape=input_shape,\n              filters=8,\n              kernel_size=(5,5),\n              activation='relu',\n              padding='valid'),\n        MaxPooling2D(pool_size=(6,6)),\n        Flatten(),\n        Dense(10),\n        tfpl.OneHotCategorical(event_size=10,\n                              convert_to_tensor_fn=tfd.Distribution.mode)\n    ])\n\n    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n    return model\n\ntf.random.set_seed(0)\nprobabilistic_model = get_probabilistic_model(\n    input_shape=(28, 28, 1), \n    loss=nll, \n    optimizer=RMSprop(), \n    metrics=['accuracy'])\nprobabilistic_model.summary()\n\n_________________________________________________________________\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_1 (Conv2D)           (None, 24, 24, 8)         208       \n\n max_pooling2d_1 (MaxPooling  (None, 4, 4, 8)          0         \n 2D)                                                             \n\n flatten_1 (Flatten)         (None, 128)               0         \n\n dense_1 (Dense)             (None, 10)                1290      \n\n one_hot_categorical (OneHot  ((None, 10),             0         \n Categorical)                 (None, 10))                        \n\n=================================================================\nTotal params: 1,498\nTrainable params: 1,498\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nprobabilistic_model.fit(x_train, tf.keras.utils.to_categorical(y_train), epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 9s 5ms/step - loss: 2.0467 - accuracy: 0.8283\nEpoch 2/5\n1875/1875 [==============================] - 8s 5ms/step - loss: 0.1950 - accuracy: 0.9458\nEpoch 3/5\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.1545 - accuracy: 0.9574\nEpoch 4/5\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.1381 - accuracy: 0.9611\nEpoch 5/5\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.1332 - accuracy: 0.9635\n```", "```py\nprint('Accuracy on MNIST test set: ',\n      str(probabilistic_model.evaluate(x_test, tf.keras.utils.to_categorical(y_test), verbose=False)[1]))\nprint('Accuracy on corrupted MNIST test set: ',\n      str(probabilistic_model.evaluate(x_c_test, tf.keras.utils.to_categorical(y_c_test), verbose=False)[1]))\n\nAccuracy on MNIST test set:  0.9641000032424927\nAccuracy on corrupted MNIST test set:  0.8906999826431274\n```", "```py\ndef plot_model_prediction(image, true_label, model):\n    predicted_probabilities = model(image[np.newaxis, :])\n    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 2),\n                                   gridspec_kw={'width_ratios': [2, 4]})\n\n    # Show the image and the true label\n    ax1.imshow(image[..., 0], cmap='gray')\n    ax1.axis('off')\n    ax1.set_title('True label: {}'.format(str(true_label)))\n\n    # Show a 95% prediction interval of model predicted probabilities\n    probs = np.zeros((10, 10))\n    for i in range(10):\n        probs[i] = np.array(np.mean(tf.squeeze(predicted_probabilities.sample(100)).numpy(), axis=0))\n    pct_2p5 = np.percentile(probs, 2.5, axis=0)\n    pct_97p5 = np.percentile(probs, 97.5, axis=0)\n\n    bar = ax2.bar(np.arange(10), pct_97p5, color='red')\n    bar[int(true_label)].set_color('green')\n    ax2.bar(np.arange(10), pct_2p5-0.02, color='white', linewidth=1, edgecolor='white')\n    ax2.set_xticks(np.arange(10))\n    ax2.set_ylim([0, 1])\n    ax2.set_ylabel('Probability')\n    ax2.set_title('Model estimated probabilities')\n    plt.show()\n```", "```py\nfor i in [0, 18]:\n    plot_model_prediction(x_test[i], np.squeeze(y_test[i]), probabilistic_model)\n```", "```py\nfor i in [0, 17]:\n    plot_model_prediction(x_c_test[i], np.squeeze(y_c_test[i]), probabilistic_model)\n```"]