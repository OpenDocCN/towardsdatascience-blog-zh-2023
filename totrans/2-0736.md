# 作为 Pytorch 神经网络层的微分方程

> 原文：[https://towardsdatascience.com/differential-equations-as-a-pytorch-neural-network-layer-7614ba6d587f](https://towardsdatascience.com/differential-equations-as-a-pytorch-neural-network-layer-7614ba6d587f)

## 如何在 pytorch 中使用微分方程层

[](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)[![Kevin Hannay](../Images/6dfcf0384e2a8aac0dd27a216ed2d92c.png)](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------) [Kevin Hannay](https://medium.com/@moleculeboy24?source=post_page-----7614ba6d587f--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7614ba6d587f--------------------------------) ·阅读时间 17 分钟·2023 年 4 月 26 日

--

微分方程是现代科学的大多数数学基础。它们通过描述变化率（微分）的方程来描述系统的状态。许多系统都可以通过这种形式的方程很好地描述。例如，描述运动、电磁学和量子力学的物理定律都采用这种形式。更广泛地说，微分方程通过质量作用定律描述化学反应速率，通过 SIR 模型描述神经元放电和疾病传播。

深度学习革命带来了新一套工具，用于在巨大的数据集上进行大规模优化。在这篇文章中，我们将探讨如何使用这些工具来拟合 pytorch 中自定义微分方程层的参数。

## 我们要解决的问题是什么？

假设我们有一些时间序列数据 y(t)，我们希望用微分方程对其建模。数据表现为在时间 tᵢ 上的一组观察值 yᵢ。基于对基础系统的某些领域知识，我们可以写出一个微分方程来近似该系统。

在最一般的形式下，这表现为：

![](../Images/a40c428710be4c634489d22e95a37020.png)

一般常微分方程系统

其中 y 是系统的状态，t 是时间，而 θ 是模型的参数。在这篇文章中，我们将假设参数 θ 是未知的，我们希望从数据中学习这些参数。

本文的所有代码可在 [github](https://github.com/khannay/paramfittorchdemo) 或 [colab notebook](https://colab.research.google.com/github/khannay/paramfittorchdemo/blob/main/nbs/00_training.ipynb) 上找到，所以如果你想跟随学习，无需尝试复制粘贴。

让我们导入本帖所需的库。我们将使用的唯一非标准机器学习库是 [torchdiffeq](https://github.com/rtqichen/torchdiffeq) 库来解决微分方程。该库在 pytorch 中实现了数值微分方程求解器。

[PRE0]

## 模型

我们建模过程的第一步是定义模型。对于微分方程，这意味着我们必须选择函数 f(y,t;θ) 的形式和表示参数 θ 的方式。我们还需要以与 pytorch 兼容的方式完成这项工作。

这意味着我们需要将我们的函数编码为 *torch.nn.Module* 类。正如你所看到的，这非常简单，只需要定义两个方法。让我们从三个示例模型中的第一个开始。

## van Der Pol 振荡器 (VDP)

我们可以使用 *torch.nn.Module* 类来定义一个微分方程系统，其中参数通过 *torch.nn.Parameter* 声明创建。这让 pytorch 知道我们希望为这些参数累积梯度。我们还可以通过不使用此声明来包含固定参数（我们不想调整的参数）。

我们将使用的第一个示例是经典的 VDP 振荡器，它是一个具有单个参数 μ 的非线性振荡器。该系统的微分方程是：

![](../Images/f984c8771b0c62531721fc143d1f7dc6.png)

VDP 振荡器方程

其中 **x** 和 **y** 是状态变量。VDP 模型用于模拟从电子电路到心律失常和昼夜节律的一切。我们可以在 pytorch 中定义此系统如下：

[PRE1]

你只需要定义 *__init__* 方法 (**init**) 和 forward 方法。我添加了一个字符串方法 __*repr__* 来美观地打印参数。关键点在于我们如何在 forward 方法中将微分方程转换为 torch 代码。此方法需要定义微分方程的右侧。

让我们看看如何使用来自 torchdiffeq 的 odeint 方法来集成这个模型：

[PRE2]

![](../Images/38e234bbc82a1b9c30dc4b550479214c.png)

这里是解的相平面图（动态状态的参数图的相平面图）。

[PRE3]

![](../Images/a58bc70d4e871b67c22c583f19227709.png)

颜色表示我们批次中的 30 条独立轨迹。解返回为具有 (time_points, batch number, dynamical_dimension) 维度的 torch 张量。

[PRE4]

## Lotka-Volterra 捕食者-猎物方程

作为另一个示例，我们创建一个 Lotka-Volterra 捕食者-猎物方程的模块。在 Lotka-Volterra (LV) 捕食者-猎物模型中，有两个主要变量：猎物的种群 (x) 和捕食者的种群 (y)。该模型由以下方程定义：

![](../Images/4861c4876c104ce423e07b60b0ffdc04.png)

捕食者-猎物动态的 Lotka-Volterra 方程

除了主要变量，还有四个参数用于描述模型中的各种生态因素：

α 表示在没有捕食者情况下猎物种群的内在增长率。β 表示捕食者对猎物的捕食率。γ 表示在没有猎物情况下捕食者种群的死亡率。δ 表示捕食者将消耗的猎物转化为新捕食者生物量的效率。

这些变量和参数共同描述了生态系统中捕食者与猎物之间的相互作用动态，并用于数学建模猎物和捕食者种群随时间的变化。这里是这个系统作为 *torch.nn.Module* 的实现：

[PRE5]

这遵循了与第一个示例相同的模式，主要区别在于我们现在有四个参数，并将它们存储为 *model_params* 张量。以下是捕食者-猎物方程的积分和绘图代码。

[PRE6]

![](../Images/58bdcdc8b3ec9b84c3af02856148c2c9.png)

现在是系统的相平面图：

![](../Images/d7ae7a0eda4a514d6111b301033a2e53.png)

## 洛伦兹系统

我们将使用的最后一个示例是洛伦兹方程，这些方程因其美丽的混沌动态图而闻名。它们最初来源于流体动力学的简化模型，并呈现以下形式：

![](../Images/0dcaffefdc1eba6471cc753f3d0a3faa.png)

其中 x、y 和 z 是状态变量，σ、ρ 和 β 是系统参数。

[PRE7]

这展示了如何集成这个系统并绘制结果。该系统（在这些参数值下）显示了混沌动态，因此起始条件虽然很接近，但会指数级地彼此发散。

[PRE8]

![](../Images/7984eecf06eb3fd53899755e48f5964d.png)

这里展示了第一组初始条件的著名蝴蝶图（相平面图）。

![](../Images/58e4336da5ee47b8d7bcaf8666994410.png)

洛伦兹方程展示了混沌动态，并描绘出一个美丽的奇异吸引子。

## 数据

现在我们可以在 pytorch 中定义微分方程模型了，我们需要创建一些数据用于训练。这是事情变得真正有趣的地方，因为我们首次看到了能够利用深度学习机制来拟合参数的可能性。实际上，我们可以直接使用数据张量，但这是一种很好的组织数据的方式。如果你有一些实验数据需要使用，它也会很有用。

Torch 提供了 *Dataset* 类用于加载数据。要使用它，你只需创建一个子类并定义两个方法。一个是返回数据点数量的 *__len__* 函数，另一个是返回给定索引处数据点的 *__getitem__* 函数。如果你想知道这些方法是如何在 python 列表中支持 *len(array)* 和 *array[0]* 下标访问的。

其余的样板代码在父类 *torch.utils.data.Dataset* 中定义。我们将在定义训练循环时看到这些方法的强大功能。

[PRE9]

接下来，让我们创建一个快速生成器函数来生成一些模拟数据以测试算法。在实际使用中，数据将从文件或数据库中加载，但在这个例子中，我们将仅生成一些数据。实际上，我建议你总是从生成的数据开始，以确保你的代码在尝试加载真实数据之前正常工作。

[PRE10]

这只是输入一个带有一些初始状态的微分方程模型，并从中生成一些时间序列数据（并添加一些高斯噪声）。然后这些数据被传入我们的自定义数据集容器中。

## 训练循环

接下来我们将为pytorch训练循环创建一个包装函数。训练意味着我们想要更新模型参数以增加与数据的对齐度（或减少成本函数）。

深度学习中的一个技巧是不要在进行梯度步骤之前使用所有数据。这部分是因为在使用巨大数据集时，你不能将所有数据放入GPU的内存中，但这也可以帮助梯度下降算法避免陷入局部最小值。

训练循环的文字描述：

+   将数据集分割成小批量，这些是你整个数据集的子集。通常要随机选择这些小批量。

+   迭代小批量

+   使用当前模型参数生成预测

+   计算损失（这里我们将使用均方误差）

+   使用反向传播计算梯度。

+   使用梯度下降步骤更新参数。这里我们使用Adam优化器。

+   完整遍历数据集的过程称为一个周期（epoch）。

好的，这里是代码：

[PRE11]

## 示例

## 拟合VDP振荡器

让我们使用这个训练循环从模拟的VDP振荡器数据中恢复参数。

[PRE12]

让我们创建一个参数值错误的模型并可视化起始点。

[PRE13]

![](../Images/9a3ae99f6b8944ff0d86a7e00c724c7d.png)

现在，我们将使用训练循环来拟合VDP振荡器的参数到模拟数据中。

[PRE14]

[PRE15]

不错！让我们看看图现在是什么样子的……

![](../Images/ec1504367018a9ece345f7546705af24.png)

图示确认我们几乎完全恢复了参数。再绘制一个图，我们绘制系统在相平面上的动态（状态变量的参数化图）。

![](../Images/e6d29331b53d0080c8a5f6428375fff5.png)

这是该模型的训练过程的可视化：

![](../Images/3bfaaa91a33776ca1bccbda8d804ec88.png)

VDP模型的训练过程视频

## 洛特卡-沃尔泰拉方程

现在让我们调整方法以拟合来自洛特卡-沃尔泰拉方程的模拟数据。

[PRE16]

这是初始参数的拟合，然后我们将像之前一样拟合并查看结果。

![](../Images/c324d4f631cb1479f069a7c2471ec736.png)

[PRE17]

[PRE18]

首先是拟合系统的时间序列图：

![](../Images/1cad34d577e24b2bbae6a39ef6e8ea27.png)

现在让我们使用相平面图来可视化结果。

![](../Images/c5bb7d6259f550bd7f5dc28330476a55.png)

这是拟合过程的可视化……

![](../Images/7b71c438cc820ad955e4595c1cd1131d.png)

## 洛伦兹方程

最后，让我们尝试拟合洛伦兹方程。

[PRE19]

这是初始拟合，然后我们将调用训练循环。

![](../Images/fc271257498a7efd4a21da9c71d16e56.png)

[PRE20]

这是训练结果：

[PRE21]

让我们看看拟合的模型。从完整的动态图开始。

![](../Images/68ad27e421cc95d203aa338507deb0f6.png)

让我们放大数据的主体部分，看看拟合效果如何。

![](../Images/3ff8fb66cb7d20e91b8dacb8082d7844.png)

你可以看到模型在数据范围内非常接近真实模型，并且对于 t < 16 的未见数据具有良好的泛化能力。现在是相位平面图（放大）。

[PRE22]

![](../Images/2876da4f6595ae6470eb1b40a816366b.png)

你可以看到我们拟合的模型在 t ∈ [0,16] 范围内表现良好，但随后开始发散。

# 神经微分方程简介

这种方法在我们知道右侧方程形式的情况下效果很好，但如果我们不知道呢？我们可以使用这个方法来发现模型方程吗？

这个主题过于庞大，无法在这篇文章中完全覆盖，但将我们的微分方程模型迁移到 torch 框架的最大优势之一是我们可以将其与人工神经网络层混合搭配。

我们可以做的最简单的事情是用神经网络层替换方程右侧的 f(y,t; θ)。这类方程被称为神经微分方程，可以看作是[递归神经网络的推广](https://dl.acm.org/doi/10.5555/3327757.3327764)。

![](../Images/29598e77aeefc86671eadc34c6e77e7f.png)

神经微分方程将方程的右侧替换为人工神经网络

作为第一个例子，让我们对我们简单的 VDP 振荡器系统进行操作。首先，我们将重新生成模拟数据，你会注意到我正在创建更长的时间序列数据和更多的样本。拟合神经微分方程需要更多的数据和计算能力，因为我们有许多需要确定的参数。

[PRE23]

现在我定义一个简单的前馈神经网络层来填充方程的右侧。

[PRE24]

这里是拟合前系统的图：

[PRE25]

![](../Images/ebf03ab9b520dde7236de0dfa8249652.png)

你可以看到我们一开始离正确解很远，但我们注入到模型中的信息却少得多。让我们看看能否通过拟合模型得到更好的结果。

[PRE26]

[PRE27]

通过可视化结果，我们可以看到模型能够拟合数据，甚至可以外推到未来（尽管它的效果和速度不如指定模型）。

![](../Images/2a9b06cf98c1563ef2aa13728286f085.png)

现在是我们神经微分方程模型的相位平面图。

![](../Images/1c04104e67e37c75340ecd6da5e55c6d.png)

这些模型需要很长时间才能训练，并且需要更多数据才能获得良好的拟合。这是有道理的，因为我们同时试图学习模型和参数。

![](../Images/f3e1eda9f5826ff5860298d228175c6b.png)

NDE拟合过程的视频。

## 结论与总结

在这篇文章中，我展示了如何在pytorch生态系统中使用torchdiffeq包应用微分方程模型。这篇文章中的代码可以在[github](https://github.com/khannay/paramfittorchdemo)上找到，并且可以直接在[google colab](https://colab.research.google.com/github/khannay/paramfittorchdemo/blob/main/nbs/00_training.ipynb)中打开进行实验。你也可以通过pip安装这篇文章中的代码：

[PRE28]

这篇文章是一个介绍，未来我将写更多关于以下主题的内容：

+   如何将一些动力学的机制知识与深度学习相结合。这些被称为[通用微分方程](https://arxiv.org/abs/2001.04385)，因为它们使我们能够将科学知识与深度学习结合起来。这基本上将两种方法融合在一起。

+   如何将微分方程层与其他深度学习层结合。

+   模型发现：我们能否从数据中恢复实际的模型方程？这使用[SINDy](https://www.pnas.org/doi/10.1073/pnas.1906995116)等工具从数据中提取模型方程。

+   用于管理这些模型训练的MLOps工具。这包括[MLFlow](https://mlflow.org/)、[Weights and Biases](https://wandb.ai/home)和[Tensorboard](https://pytorch.org/docs/stable/tensorboard.html)等工具。

+   任何其他我从你那里听到的反馈！

如果你喜欢这篇文章，确保关注我并在[lLinked-in](https://www.linkedin.com/in/kevin-hannay-7a6049198/)上与我联系。除非另有说明，否则所有图片均由作者提供。
