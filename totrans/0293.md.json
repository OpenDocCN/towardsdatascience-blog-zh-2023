["```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass VGG16(nn.Module):\n    def __init__(self, input_channel, num_classes):\n        super(VGG16, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(input_channel, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 3* 3, 4096), nn.ReLU(True), nn.Dropout(),\n            nn.Linear(4096, 4096), nn.ReLU(True), nn.Dropout(),\n            nn.Linear(4096, num_classes)\n        )\n```", "```py\ndef forward(self, x):\n  layer_outputs = []\n  for i in range(len(self.features)):\n    x = self.features[i](x)\n    layer_outputs.append(x)\n\n  x = x.view(x.size(0), -1)\n\n  for i in range(len(self.classifier)):\n    x = self.classifier[i](x)\n    layer_outputs.append(x)\n\n  return x, layer_outputs\n```", "```py\nvgg_model = VGG16(3, 10)\ninput_tensor = torch.rand(1, 3, 96, 96)\nx, layer_outputs = vgg_model(input_tensor)\nfor l in layer_outputs:\n  print(l.shape)\n```", "```py\n torch.Size([1, 64, 96, 96])\ntorch.Size([1, 64, 96, 96])\ntorch.Size([1, 64, 96, 96])\ntorch.Size([1, 64, 96, 96])\ntorch.Size([1, 64, 48, 48])\ntorch.Size([1, 128, 48, 48])\ntorch.Size([1, 128, 48, 48])\ntorch.Size([1, 128, 48, 48])\ntorch.Size([1, 128, 48, 48])\ntorch.Size([1, 128, 24, 24])\ntorch.Size([1, 256, 24, 24])\ntorch.Size([1, 256, 24, 24])\ntorch.Size([1, 256, 24, 24])\ntorch.Size([1, 256, 24, 24])\ntorch.Size([1, 256, 24, 24])\ntorch.Size([1, 256, 24, 24])\ntorch.Size([1, 256, 12, 12])\ntorch.Size([1, 512, 12, 12])\ntorch.Size([1, 512, 12, 12])\ntorch.Size([1, 512, 12, 12])\ntorch.Size([1, 512, 12, 12])\ntorch.Size([1, 512, 12, 12])\ntorch.Size([1, 512, 12, 12])\ntorch.Size([1, 512, 6, 6])\ntorch.Size([1, 512, 6, 6])\ntorch.Size([1, 512, 6, 6])\ntorch.Size([1, 512, 6, 6])\ntorch.Size([1, 512, 6, 6])\ntorch.Size([1, 512, 6, 6])\ntorch.Size([1, 512, 6, 6])\ntorch.Size([1, 512, 3, 3])\ntorch.Size([1, 4096])\ntorch.Size([1, 4096])\ntorch.Size([1, 4096])\ntorch.Size([1, 4096])\ntorch.Size([1, 4096])\ntorch.Size([1, 4096])\ntorch.Size([1, 10])\n```", "```py\nclasses = ('airplane', 'bird', 'car', 'cat', 'deer', 'dog',\\\n           'horse', 'monkey', 'ship', 'truck')\n```", "```py\n transform = transforms.Compose([\n    transforms.ToTensor()\n])\n\ntrainset = torchvision.datasets.STL10(root = './data', split = 'train', download = True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset))\n\nclasses = ('airplane', 'bird', 'car', 'cat', 'deer', 'dog',\\\n           'horse', 'monkey', 'ship', 'truck')\n\nimages, target = next(iter(trainloader))\n\nnp_images = images.numpy() # convert to numpy\n\n# display one image\nplt.imshow(np.transpose(np_images[0], (1, 2, 0)))\nplt.title(f'class: {classes[target[0]]}')\nplt.axis('off')\nplt.show()\n\n# display another image\nplt.imshow(np.transpose(np_images[1], (1, 2, 0)))\nplt.title(f'class: {classes[target[1]]}')\nplt.axis('off')\nplt.show()\n```", "```py\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])\n\ntrainset = torchvision.datasets.STL10(root = './data', split = 'train', download = True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset))\n\nclasses = ('airplane', 'bird', 'car', 'cat', 'deer', 'dog',\\\n           'horse', 'monkey', 'ship', 'truck')\n\nimages, target = next(iter(trainloader))\n\nnp_images = images.numpy() # convert to numpy. \n\n# calculate mean and std for each channel \nmean = np.mean(np_images, axis=(0,2,3)) \nstd = np.std(np_images, axis=(0,2,3)) \n```", "```py\n# train transformation\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(96, padding = 4), # we first pad by 4 pixels on each side then crop\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.44671103, 0.43980882, 0.40664575), (0.2603408 , 0.25657743, 0.2712671))\n])\n\n# test transformation\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.44671103, 0.43980882, 0.40664575), (0.2603408 , 0.25657743, 0.2712671))\n])\n\ntrainset = torchvision.datasets.STL10(root = './data', split = 'train', download = True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size = 128, shuffle = True, num_workers = 2)\n\ntestset = torchvision.datasets.STL10(root = './data', split = 'test', download = True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size = 256, shuffle = True, num_workers = 2)In above transformation that we have defined on train data you see that we are augmenting the data by cropping a random 28x28 patch and flipping it. The reason we augment the data is to increase diversity in the training data and force the model to learn better. \n```", "```py\n# instantiate the model\nvgg_model = VGG16(input_channel=1, num_classes=10) \ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nvgg_model = vgg_model.to(device)\n\n# define hyper-parameters: learning rate, optimizer, scheduler\nlr = 0.00001\ncriterion = nn.CrossEntropyLoss()\nvgg_optimizer = optim.SGD(vgg_model.parameters(), lr = lr, momentum=0.9, weight_decay = 5e-4)\nvgg_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(vgg_optimizer, T_max = 200)And we write the train function on each batch:\n```", "```py\ndef train_batch(epoch, model, optimizer):\n    print(\"epoch \", epoch)\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    for batch_idx, (input, targets) in enumerate(trainloader):\n        inputs, targets = input.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs, _ = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n    print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                         % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n```", "```py\ndef validate_batch(epoch, model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs,_ = model(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total)) \n```", "```py\nstart_epoch = 0\nfor epoch in range(start_epoch, start_epoch+20):\n    train_batch(epoch, vgg_model, vgg_optimizer)\n    validate_batch(epoch, vgg_model)\n    vgg_scheduler.step()\n```", "```py\nepoch  0\n390 391 Loss: 5.506 | Acc: 24.864% (12432/50000)\n39 40 Loss: 4.512 | Acc: 49.780% (4978/10000)\nepoch  1\n390 391 Loss: 5.140 | Acc: 33.226% (16613/50000)\n39 40 Loss: 4.156 | Acc: 57.120% (5712/10000)\nepoch  2\n390 391 Loss: 4.978 | Acc: 36.594% (18297/50000)\n39 40 Loss: 3.953 | Acc: 60.450% (6045/10000)\nepoch  3\n390 391 Loss: 4.908 | Acc: 38.498% (19249/50000)\n39 40 Loss: 3.898 | Acc: 69.430% (6943/10000)\nepoch  4\n390 391 Loss: 4.827 | Acc: 39.982% (19991/50000)\n39 40 Loss: 3.631 | Acc: 68.240% (6824/10000)\nepoch  5\n390 391 Loss: 4.767 | Acc: 40.876% (20438/50000)\n39 40 Loss: 3.677 | Acc: 71.260% (7126/10000)\nepoch  6\n390 391 Loss: 4.686 | Acc: 42.356% (21178/50000)\n39 40 Loss: 3.180 | Acc: 73.560% (7356/10000)\nepoch  7\n390 391 Loss: 4.664 | Acc: 42.606% (21303/50000)\n39 40 Loss: 3.259 | Acc: 76.920% (7692/10000)\nepoch  8\n390 391 Loss: 4.653 | Acc: 43.014% (21507/50000)\n39 40 Loss: 3.118 | Acc: 77.150% (7715/10000)\nepoch  9\n390 391 Loss: 4.606 | Acc: 43.762% (21881/50000)\n39 40 Loss: 2.961 | Acc: 75.850% (7585/10000)\nepoch  10\n390 391 Loss: 4.608 | Acc: 43.802% (21901/50000)\n39 40 Loss: 2.840 | Acc: 81.130% (8113/10000)\nepoch  11\n390 391 Loss: 4.582 | Acc: 44.156% (22078/50000)\n39 40 Loss: 2.878 | Acc: 80.810% (8081/10000)\n....\n...\n..\n```", "```py\nmodel = vgg19_model\n\nmean = [0.44671103, 0.43980882, 0.40664575]\nstd = [0.2603408 , 0.25657743, 0.2712671]\n\n# Evaluate the model on random images and display results\nfor _ in range(10):\n    # Get a random test image\n    data, target = next(iter(testloader))\n\n    # Get model's predictions\n    output, _ = model(data.to(device))\n    _, predicted = torch.max(output, 1)\n\n    # Display the image along with predicted and actual labels\n    # Unnormalize the image\n    display_img = data[0]\n    unnormalized_image = display_img.clone()  # Create a copy to avoid modifying the original tensor\n    for i in range(3):\n      unnormalized_image[i] = (unnormalized_image[i] * std[i]) + mean[i]\n    plt.imshow(np.transpose(unnormalized_image.numpy(), (1, 2, 0)))\n    plt.title(f'Predicted: {classes[predicted[0]]}, Actual: {classes[target[0]]}')\n    plt.axis('off')\n    plt.show()\n```"]