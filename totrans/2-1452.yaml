- en: Ludwig — A “Friendlier” Deep Learning Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ludwig-a-friendlier-deep-learning-framework-946ee3d3b24](https://towardsdatascience.com/ludwig-a-friendlier-deep-learning-framework-946ee3d3b24)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Deep Learning Made Easy with this Low-Code, Declarative Framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://johnadeojo.medium.com/?source=post_page-----946ee3d3b24--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----946ee3d3b24--------------------------------)[](https://towardsdatascience.com/?source=post_page-----946ee3d3b24--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----946ee3d3b24--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----946ee3d3b24--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----946ee3d3b24--------------------------------)
    ·11 min read·Jun 26, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ee8f8ddbdb0f202acd51b5a02d1e371e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Generated with Midjourney'
  prefs: []
  type: TYPE_NORMAL
- en: Background — Deep Learning, too Complex?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I have tended to shy away from deep learning for industry use cases. Not due
    to a lack of interest, rather I find the popular deep learning frameworks cumbersome.
    I appreciate [Pytorch](https://pytorch.org/) and [TensorFlow](https://www.tensorflow.org/)
    are fantastic tools for research purposes, but the APIs are not the most user
    friendly. In situations where I need to deliver a quick proof of concept for a
    client, the last thing I want to be doing is tinkering with Pytorch tensors.
  prefs: []
  type: TYPE_NORMAL
- en: While attending the AI summit in London, I stumbled across a team claiming to
    have a solution to my deep learning problem. They have been leveraging a different
    approach, which they described as “the mid-point between TensorFlow and AutoML”,
    a framework called Ludwig.
  prefs: []
  type: TYPE_NORMAL
- en: What is Ludwig?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Developed by Uber, [Ludwig](https://ludwig.ai/latest/) is an open-source framework
    for building deep learning models. It is declarative, which means that instead
    of constructing complex models layer-by-layer like you would in TensorFlow, you
    simply declare the structure of the model with a configuration file. This sounded
    too good to be true, so I had to see for myself. In the remainder of this article,
    I detail my experience with Ludwig through an example project I have taken from
    [Kaggle](https://www.kaggle.com/datasets/shelvigarg/sales-forecasting-womart-store).
    Along the way I will discuss some of its strengths, pain-points, and give you
    my conclusion on whether it’s worth using.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note — Although initially developed by Uber, Ludwig is an* [*open source*](https://github.com/ludwig-ai/ludwig/blob/master/LICENSE)
    *library under the Apache 2.0 License. The project is hosted by the* [*Linux Foundation
    AI & Data*](https://lfaidata.foundation/)*. I have no commercial affiliation with
    Uber or the developers of Ludwig.*'
  prefs: []
  type: TYPE_NORMAL
- en: The project — Demand Forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**The project brief**: Forecast the final 30 days of orders across each store
    for the retailer WOMart.'
  prefs: []
  type: TYPE_NORMAL
- en: Your Client WOMart is a leading nutrition and supplement retail chain that offers
    a comprehensive range of products for all your wellness and fitness needs.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: WOMart follows a multi-channel distribution strategy with 350+ retail stores
    spread across 100+ cities.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset had a total of 22,265 observations, each pertaining to one day of
    sales at a given store. For brevity I won’t go into the full details of the data
    set, but you can see some descriptive statistics [here](https://www.kaggle.com/datasets/shelvigarg/sales-forecasting-womart-store).
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**: The data is free to use for any purposes under the Open Data Commons
    license.'
  prefs: []
  type: TYPE_NORMAL
- en: Link to the [data](https://www.kaggle.com/datasets/shelvigarg/sales-forecasting-womart-store)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[License](https://opendatacommons.org/licenses/dbcl/1-0/) for the data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The data dictionary:**'
  prefs: []
  type: TYPE_NORMAL
- en: A Brief Overview of the Methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I won’t go into too much detail on the methodology here as this isn’t the main
    purpose of this article. I’ll cover how I framed the problem at a high level to
    give you some context.
  prefs: []
  type: TYPE_NORMAL
- en: I framed the forecasting issue as a ‘pseudo’ sequence-to-sequence deep learning
    problem. The method entailed utilising 360 days of time series data points to
    predict the subsequent 30 days of customer orders. I incorporated some categorical
    variables and had to generate separate predictions for each day of orders, which
    led to a somewhat unconventional setup — thus the term ‘pseudo’ sequence-to-sequence
    for describing the problem. I will expand on the specifics of the feature engineering
    later in this article.
  prefs: []
  type: TYPE_NORMAL
- en: Besides this, the methodology I followed was standard for model development.
    I split my data into a training data set and a holdout dataset and did some re-scaling
    of features and labels. Model training was done on the training data, and testing
    on the holdout.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Ludwig does provide the capability to natively split data within the
    API. However, to maintain rigour, I established a separate holdout dataset. The
    training dataset was subsequently divided into additional training, validation,
    and testing subsets. The holdout dataset was excluded entirely, used only for
    analysing the predictions generated by the model.*'
  prefs: []
  type: TYPE_NORMAL
- en: Feature Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the time of writing this article, I would say that sequence-to-sequence modelling
    as it pertains to timeseries forecasting is tricky to do in Ludwig. The reason
    for this is the feature engineering. The Ludwig API has an excellent ability to
    handle sequences as inputs, but they haven’t (yet) developed a coherent approach
    for time series sequences as outputs. You can develop a “pseudo” sequence-to-sequence
    model by declaring multiple outputs, but the overall feature engineering experience
    feels quite “hacky”.
  prefs: []
  type: TYPE_NORMAL
- en: '**Sequence features**: Except for those features that don’t change with time,
    I engineered all the predictive features to be “Ludwig-formatted” sequences. Each
    input sequence is a horizontal stacking of each “time series” feature across a
    pre-defined timeframe. Each feature sequence is determined at the store level
    and encapsulated in one cell of the dataframe (it looks as messy as it sounds).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sequence labels**: For sequence labels, you must declare each point in the
    sequence as an individual label for the model. This ended up with me declaring
    30 labels for each store, one label per day of orders to be predicted.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Example of the feature engineering process below:*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example of Data: Bold values will be used to construct sequence labels, regular
    values will be used to construct sequence features.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of engineering features: Order_sequence is a “Ludwig-formatted” sequence.
    Labels are returned individually to be later declared as model outputs (labels).'
  prefs: []
  type: TYPE_NORMAL
- en: Architecting Your Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Ludwig API allows you to architect fairly complex and customisable models
    declaratively. Ludwig does this through a .yaml file. Now, I appreciate many data
    scientists reading this might not have used *.yaml* files, but generally in software
    development these are used for configuration. The files might appear scary at
    first glance, but they are quite friendly. Let’s step through the main parts of
    the file I create to build the model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4fb639a21a0f7b60a4ca5ce8cd586ed4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Model architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we delve into the configurations, it’s worth briefly introducing the
    [architecture](https://ludwig.ai/latest/user_guide/how_ludwig_works/) at the heart
    of Ludwig’s deep learning framework: the Encoder, Combiner, and Decoder. Most
    of the models you configure in Ludwig will predominantly adhere to this architecture.
    Understanding this can simplify the process of stacking components to quickly
    build your deep learning models.'
  prefs: []
  type: TYPE_NORMAL
- en: Declaring your Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Right at the top of the file you declare the model type used. Ludwig provides
    two options, tree-based models, and deep neural networks for which I chose the
    latter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Declaring your data splits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can split data sets natively by declaring your split percentages, type of
    split, and column or variable you’re splitting on. For my purposes I wanted to
    ensure that a store could only appear in one of the data sets, hash splitting
    was perfect for that.
  prefs: []
  type: TYPE_NORMAL
- en: For best practice, I would probably advise constructing a holdout set outside
    of the Ludwig API especially where you are doing some initial feature engineering
    like one-hot-encoding or normalisation. This should help prevent data leakage.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Declaring the Model Inputs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You declare inputs by name, type, and encoder. Depending on the type of input
    to the model you have a variety of options for encoders. Essentially encoders
    are a way of transforming your inputs such that it can be interpreted by the model.
    The choice of encoder really depends on the data and the modelling task.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Declaring the Combiner
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Combiners](https://ludwig.ai/latest/configuration/combiner/), as the name
    suggests, amalgamate the outputs of your encoders. The Ludwig API offers an array
    of different combiners, each with its own specific use case. The choice of combiner
    can depend on the structure of your model and the relationships between your features.
    For instance, you might use a ‘concat’ combiner if you want to simply concatenate
    the outputs of your encoders, or a ‘sequence’ combiner if your features have a
    sequential relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As with many aspects of deep learning, the optimal choice of combiner often
    depends on the specifics of your dataset and problem, and may require some experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: Declaring the Model Outputs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finalising your network is as simple as declaring your outputs, which are just
    your labels. My pet peeve with Ludwig for timeseries is that you can’t (yet) declare
    timeseries outputs. As I mentioned previously, you have to “hack” it by declaring
    each point in your time series separately. This left me with thirty separate declarations,
    which looks very messy in all honesty. For each output you can specify the loss
    function too adding additional configurability. Ludwig has a myriad of options
    pre-built for different output types, however I don’t know if you are able to
    implement custom loss functions as you can with Pytorch.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Declaring the Trainer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The trainer configuration in Ludwig, while optional due to Ludwig’s provision
    of sensible defaults, allows for a high degree of customisation. It gives you
    control over the specifics of how your model is trained. This includes the ability
    to specify the type of optimiser used, the number of training epochs, the learning
    rate, and criteria for early stopping, among other parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: For your particular use case, you might find it beneficial to define these parameters
    yourself. For instance, you might want to adjust the learning rate, or the number
    of epochs based on the complexity of your model and the size of your dataset.
    Similarly, early stopping can be a useful tool to prevent overfitting by halting
    the training process if the model’s performance on a validation set stops improving.
  prefs: []
  type: TYPE_NORMAL
- en: Train your Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Training your model can be easily done with Ludwig’s python expermiment API.
    See the script example below:'
  prefs: []
  type: TYPE_NORMAL
- en: Other Configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Outside of those I mentioned, Ludwig has a myriad of possible configurations.
    They are all very well documented and well structured. I would advise having a
    read of their [documentation](https://ludwig.ai/latest/configuration/) to familiarise
    yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Model Performance Analysis — A brief view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim of this article is to explore some of the functionalities of the Ludwig
    framework through a practical example project. Although demonstrating model performance
    is part of this, there’s no need to delve into the specifics of the metrics. I
    will limit the discussion to presenting some of the charts generated from the
    model’s analysis. Note that the comprehensive end-to-end script is available on
    my GitHub, linked at the conclusion of the article.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8d558538c1cc0f0f325945847d204843.png)![](../Images/0b4b25d91efa44007d98674b289715ef.png)![](../Images/8d558538c1cc0f0f325945847d204843.png)![](../Images/307430a711653cafa78cdadb6cda1fcd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Model predictions (red) against actual orders (blue) for the
    last 30 days of data. These examples are drawn from the holdout set.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dcdb1587d4122569b075e2b12a921617.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Distribution of error, where error is Actual Orders minus
    Predicted Orders.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b73422bb47ff310479e5311faffa274.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Loss curve for the model training. Loss metric is Mean Absolute
    Error'
  prefs: []
  type: TYPE_NORMAL
- en: My Verdict
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I’ll begin by confessing that I was initially sceptical about Ludwig. However,
    after experimenting with it myself, I’m convinced of its capabilities and believe
    it delivers as promised. I think there are several truly impressive features worth
    highlighting.
  prefs: []
  type: TYPE_NORMAL
- en: '**Coding experience**: The coding experience feels more like constructing an
    elaborate Lego set. You really can have a lot of fun messing around with components
    and different architectures to find your perfect model.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Documentation**: The documentation is clear and well structured. It was very
    easy to figure out how to implement different architectures and change your model
    configurations. Most of the documentation appears to be up to date too, which
    is a bonus.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Backend**: The backend experience is excellent. The library developers have
    done a great job abstracting away a lot of the usual configurations you have to
    do to train deep neural networks on GPUs. I trained my model on a Google Collab,
    and Ludwig automatically moved the workloads onto the GPU.'
  prefs: []
  type: TYPE_NORMAL
- en: Another great thing about Ludwig is that the backend is highly configurable.
    For example, if you’re running massive workloads and need a cluster of GPUs, you
    can configure this too!
  prefs: []
  type: TYPE_NORMAL
- en: '**Experiment Tracking**: Ludwig provides you with an Experiment API that can
    be used to track your model artefacts between experiment runs. I believe there
    are integrations with MLflow too which is fantastic for commercial scale MLOps.'
  prefs: []
  type: TYPE_NORMAL
- en: Pet Peeves
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a few areas in which the framework could be enhanced, let’s get into
    those too.
  prefs: []
  type: TYPE_NORMAL
- en: '**Visualisation**: Ludwig does offer a visualisation API to track training
    losses across your data sets. However, at the time of writing, it does not function
    particularly well and its usage is unintuitive. I tried running it in a Google
    Collab, but to no avail. Eventually, I created my own loss curve visualisations
    by scripting a Python function to parse the training_statistics.json files that
    Ludwig saves for you after each experiment run.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support**: Whilst there is some support available, Ludwig’s community does
    not seem to be as extensive as those of TensorFlow or Pytorch yet. A few issues
    have been raised on GitHub, and there are some threads that might offer assistance,
    but for the most part, it feels like you are left to your own devices. As for
    ChatGPT, it provides a certain level of support up until 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transparency**: Ludwig excels in eliminating the more challenging aspects
    of building deep learning models. However, this comes at the expense of transparency,
    which occasionally renders the logs somewhat cryptic and challenging to debug.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In my opinion, Ludwig is an excellent tool for those looking to start utilising
    deep learning whether in a commercial setting or just for learning. While it may
    be too high-level for state-of-the-art research purposes, it is well-suited to
    solving clearly defined problems swiftly. A certain degree of understanding of
    deep learning is still necessary, but once you’ve grasped the concept, the barrier
    to entry for Ludwig is considerably lower than it is for TensorFlow or Pytorch.
  prefs: []
  type: TYPE_NORMAL
- en: The end-to-end notebook is available in my [GitHub](https://github.com/john-adeojo/womartdata/blob/main/ludwig_deep_learning_notebook%20(2).ipynb)
    repo, please feel free to experiment.
  prefs: []
  type: TYPE_NORMAL
- en: '*Follow me on* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Subscribe to medium to get more insights from me:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://johnadeojo.medium.com/membership?source=post_page-----946ee3d3b24--------------------------------)
    [## Join Medium with my referral link — John Adeojo'
  prefs: []
  type: TYPE_NORMAL
- en: I share data science projects, experiences, and expertise to assist you on your
    journey You can sign up to medium via…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----946ee3d3b24--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*Should you be interested in integrating AI or data science into your business
    operations, we invite you to schedule a complimentary initial consultation with
    us:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.data-centric-solutions.com/book-online?source=post_page-----946ee3d3b24--------------------------------)
    [## Book Online | Data-Centric Solutions'
  prefs: []
  type: TYPE_NORMAL
- en: Discover our expertise in helping businesses achieve ambitious goals with a
    free consultation. Our data scientists and…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----946ee3d3b24--------------------------------)
  prefs: []
  type: TYPE_NORMAL
