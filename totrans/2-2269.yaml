- en: Using Kafka with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/using-kafka-with-python-54dc20717cf7](https://towardsdatascience.com/using-kafka-with-python-54dc20717cf7)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how to create producers and consumers with Python and plot a dynamic scatter
    plot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://weimenglee.medium.com/?source=post_page-----54dc20717cf7--------------------------------)[![Wei-Meng
    Lee](../Images/10fc13e8a6858502d6a7b89fcaad7a10.png)](https://weimenglee.medium.com/?source=post_page-----54dc20717cf7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----54dc20717cf7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----54dc20717cf7--------------------------------)
    [Wei-Meng Lee](https://weimenglee.medium.com/?source=post_page-----54dc20717cf7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----54dc20717cf7--------------------------------)
    ·7 min read·Mar 20, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/189593ad2da51f8a3bf4c211cfa02a53.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In my previous article on Kafka, I introduced the use of Kafka for data streaming.
    I also showed how you can start a Kafka broker service and demonstrated how to
    use the Kafka producer console application to send messages and the Kafka consumer
    console application to receive messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, I am going to show you how to make use of Kafka using Python.
    Specifically, I will:'
  prefs: []
  type: TYPE_NORMAL
- en: Use Python to send messages to a Kafka broker service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Python to receive messages from a Kafka broker service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a dynamic charting application to plot and update a scatter plot wherever
    new data is received from the broker service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Python with Kafka
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are at least three Python libraries available for Python developers to
    interface with Kafka broker services. They are:'
  prefs: []
  type: TYPE_NORMAL
- en: Kafka-Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyKafka
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confluent Kafka Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For this article, I will make use of the **Confluent Kafka Python** package.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the **Confluent Kafka Python** package, use the `pip` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Producing the Message
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let’s work on the producer first. The producer is the one that sends
    messages to the Kafka broker service. The following code snippet specifies the
    Kafka broker server to connect to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You need to ensure that your Kafka broker service is up and running. See [https://towardsdatascience.com/using-apache-kafka-for-data-streaming-9199699623fa](/using-apache-kafka-for-data-streaming-9199699623fa)
    for more details on how to start one.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](/using-apache-kafka-for-data-streaming-9199699623fa?source=post_page-----54dc20717cf7--------------------------------)
    [## Using Apache Kafka for Data Streaming'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to install and use Kafka to send and receive messages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/using-apache-kafka-for-data-streaming-9199699623fa?source=post_page-----54dc20717cf7--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'To send a message, you can use the `produce()` function from the `Producer`
    object. You can pass four arguments to it:'
  prefs: []
  type: TYPE_NORMAL
- en: the topic to send
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the key for your message payload
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the message payload
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the callback function to invoke when you poll the producer to know if the message
    was successfully delivered (or not).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code snippet sends a message to the Kafka broker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `poll()` function returns the number of events processed (callbacks served).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s send another message with a different key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Consuming the Message
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the message sent, you can now work on the consumer. The following code
    snippet connects to the Kafka broker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `group.id` indicates which consumers you belong to. If there are two consumers
    with the same Group ID assigned to the same topic, they will all share the work
    of reading from the same topic.
  prefs: []
  type: TYPE_NORMAL
- en: The `auto.offset.reset` indicates…specifies how a consumer should behave when
    consuming from a topic partition when there is no initial offset.
  prefs: []
  type: TYPE_NORMAL
- en: I will discuss the offset in another article.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To consume messages, let’s define a function named `consume()`. It takes in
    the consumer as well as the topics to subscribe to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this function, you first subscribe to the topic that you want to listen to.
    Then, you use the `threading.currentThread()` function to check if an attribute
    named `run` has been set on the current thread that is used to run this function.
    This is used to control whether you should continue to wait for the next message
    or exit the function.
  prefs: []
  type: TYPE_NORMAL
- en: We will use an infinite loop to keep on polling the Kafka broker service. The
    `timeout` parameter allows you to set the time to block the call until a message
    is returned by the broker service. If you want to poll the broker at a higher
    frequency, set the `timeout` to a lower value, such as `0.5` second.
  prefs: []
  type: TYPE_NORMAL
- en: If a message is returned, you can extract its key and value and then print them
    out. Finally, if the infinite loop is terminated, you close the consumer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the `consume()` function, we will use the `threading` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `start()` function runs the `consume()` function as an independent thread
    so that it does not freeze your Jupyter Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should now be able to see two incoming messages that were sent by the producer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To terminate the consumer, simply set the `run` attribute of `thread` to `False`
    and the `consume()` function will stop running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Plotting Chart
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you are able to produce and consume messages using the Confluent Kafka
    Python package, it is time to do something useful with this newfound knowledge!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use the producer to simulate an IOT device sending sensor data to the
    Kafka broker service, and on the consumer end we will read the data and use it
    to plot a chart. As new data is received, the chart will be dynamically updated.
    All these will work directly on Jupyter Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Sending Sensor Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s define a function named `send_message()`, which takes in four arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: topic — the topic for the message
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: datetime — the datetime of the sensor data collected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: temp1 — the temperature reading for sensor 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: temp2 — the temperature reading for sensor 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These four arguments will then be used to send the message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also define a function named `update()` that will be called every 2
    seconds to call the `send_message()` function with some random values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Consuming the message and plotting the chart
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the consumer, let’s create the `Consumer` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will make use of Plotly to add two scatter plots to a `FigureWidget`:'
  prefs: []
  type: TYPE_NORMAL
- en: A `FigureWidget` is a graph library that can display charts in Jupyter Notebook.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now poll for messages from the Kafka broker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s dissect the above code snippet. When a message is obtained from the broker,
    it is split into three parts — `datetime`, `temp1`, and `temp2`. They are then
    appended to the `x`, `y1`, and `y2` lists, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'As time passes, the lists would contain a lot of data. And so we only want
    to plot the last *n* points (which is set to 12 in this example). To update the
    first scatter plot, set the `fig.data[0].x` and `fig.data[0].y` attributes. For
    the second scatter plot, set the `fig.data[1].x` and `fig.data[1].y` attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: And that’s it! Whenever new messages are received, the scatter plots would automatically
    update themselves!
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, when you run the code, an empty plot is shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c75219566ba1a3a5e86458d78d371944.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'You are now ready to spin off a thread to run the `consume()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'After a while, you should see the two scatter plots updating:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/177b26907d32c8d46a601c597d86f3e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a video of the plots updating:'
  prefs: []
  type: TYPE_NORMAL
- en: Video by author
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, to step the `consume()` function, set the `run` attribute of `thread`
    to `False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**If you like reading my articles and that it helped your career/study, please
    consider signing up as a Medium member. It is $5 a month, and it gives you unlimited
    access to all the articles (including mine) on Medium. If you sign up using the
    following link, I will earn a small commission (at no additional cost to you).
    Your support means that I will be able to devote more time on writing articles
    like this.**'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://weimenglee.medium.com/membership?source=post_page-----54dc20717cf7--------------------------------)
    [## Join Medium with my referral link - Wei-Meng Lee'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Wei-Meng Lee (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: weimenglee.medium.com](https://weimenglee.medium.com/membership?source=post_page-----54dc20717cf7--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This articles demonstrates one useful application that you can build with Kafka.
    In particular, I showed you how to build a dynamic charting application using
    Python and Plotly. The real-time streaming nature of Kafka makes it an ideal candidate
    for applications that requires low-latency data updates, such as IOT applications.
    Stay tuned for the next Kafka article!
  prefs: []
  type: TYPE_NORMAL
