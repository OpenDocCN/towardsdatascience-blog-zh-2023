- en: Towards Unbiased Evaluation of Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于大型语言模型的无偏评估
- en: 原文：[https://towardsdatascience.com/towards-unbiased-evaluation-of-large-language-models-9a7315144389](https://towardsdatascience.com/towards-unbiased-evaluation-of-large-language-models-9a7315144389)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/towards-unbiased-evaluation-of-large-language-models-9a7315144389](https://towardsdatascience.com/towards-unbiased-evaluation-of-large-language-models-9a7315144389)
- en: How benchmark leakage and data contamination undermine LLMs evaluation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试泄漏和数据污染如何破坏LLM的评估
- en: '[](https://donatoriccio.medium.com/?source=post_page-----9a7315144389--------------------------------)[![Donato
    Riccio](../Images/0af2a026e72a023db4635522cbca50eb.png)](https://donatoriccio.medium.com/?source=post_page-----9a7315144389--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9a7315144389--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9a7315144389--------------------------------)
    [Donato Riccio](https://donatoriccio.medium.com/?source=post_page-----9a7315144389--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://donatoriccio.medium.com/?source=post_page-----9a7315144389--------------------------------)[![Donato
    Riccio](../Images/0af2a026e72a023db4635522cbca50eb.png)](https://donatoriccio.medium.com/?source=post_page-----9a7315144389--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9a7315144389--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9a7315144389--------------------------------)
    [Donato Riccio](https://donatoriccio.medium.com/?source=post_page-----9a7315144389--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9a7315144389--------------------------------)
    ·7 min read·Dec 9, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9a7315144389--------------------------------)
    ·7分钟阅读·2023年12月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dc6cb8fa100c8187fb0ad581ac1e56a3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc6cb8fa100c8187fb0ad581ac1e56a3.png)'
- en: Image by author. (AI-assisted)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。 (AI辅助)
- en: “Our new LLM beats GPT in every benchmark!”
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们的新LLM在每一个基准测试中都超越了GPT！”
- en: It is becoming increasingly common to hear bold claims like this, as the hype
    around LLMs is huge. There are new models every week, and currently everyone is
    trying to compete with GPT-4, which is still the most powerful LLM.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 听到这种大胆声明变得越来越普遍，因为大型语言模型的炒作非常巨大。每周都有新模型，目前每个人都在试图与GPT-4竞争，而GPT-4仍然是最强大的大型语言模型。
- en: Benchmarking is a critical part of evaluating progress in large language models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试是评估大型语言模型进展的关键部分。
- en: Benchmarks like **MMLU** and **HellaSwag** are the standard for assessing language
    models on skills like reasoning and comprehension. The scores provide a snapshot
    of progress, with new state-of-the-art results heralded as breakthroughs. LLMs
    are usually evaluated in a zero-shot setting, without explicit training on the
    test set, to gauge their general abilities.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**MMLU** 和 **HellaSwag** 等基准测试是评估语言模型在推理和理解等技能方面的标准。分数提供了进展的快照，新的最先进成果被誉为突破。大型语言模型通常在零-shot设置中进行评估，没有在测试集上进行明确训练，以评估其通用能力。'
- en: This article shows how easy it is to manipulate benchmark results and offers
    suggestions to maintain evaluation integrity.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示了操控基准测试结果的容易程度，并提供了维护评估完整性的建议。
- en: The Trouble with Benchmarks
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试的问题
- en: Often, benchmarks don’t reflect usefulness in real-life scenarios. Google’s
    newest model, Gemini Ultra, scores **90.04% on MMLU**. While this is an impressive
    score, taking a closer look at the evaluation methodology, it is ***CoT@32***
    (chain of thought with 32 samples). **It means we have to prompt 32 times to get
    90% accuracy!** Most of us are expecting an accurate answer in the first try,
    especially when interacting with a chatbot.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，基准测试不会反映在实际场景中的有用性。谷歌最新的模型Gemini Ultra，在**MMLU**上得分**90.04%**。虽然这是一个令人印象深刻的分数，但仔细查看评估方法时，它是***CoT@32***（32个样本的思维链）。**这意味着我们必须提示32次才能获得90%的准确率！**
    我们大多数人期望在第一次尝试时得到准确答案，尤其是在与聊天机器人互动时。
- en: '![](../Images/5333f4a1ed66aba0aef0296f21106302.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5333f4a1ed66aba0aef0296f21106302.png)'
- en: Google Gemini technical report. [1]
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Google Gemini技术报告。 [1]
- en: Unfortunately, **this issue is just the tip of the iceberg of LLMs evaluation.**
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，**这个问题只是大型语言模型评估的冰山一角**。
- en: In machine learning, models are commonly evaluated by measuring their performance
    on a test set that was not used during training. Typically, this process allows
    for an unbiased estimate of how the model will generalize to new data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，模型通常通过测量其在训练过程中未使用的测试集上的表现来进行评估。通常，这个过程可以对模型如何推广到新数据进行无偏估计。
- en: '**Benchmark leakage and data contamination are two terms that both refer to
    a concerning issue**: when the test data somehow leaks into the pretraining data
    of LLMs, leading to inflated performance. It makes comparisons between LLMs unfair
    and provides an unreliable measure of progress.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**基准泄漏和数据污染是两个都指代一个令人担忧问题的术语**：当测试数据以某种方式泄漏到LLM的预训练数据中时，导致性能膨胀。这使得LLM之间的比较不公平，并提供了不可靠的进展衡量标准。'
- en: The evaluation is compromised if examples from the test set leak into the training
    data. This data contamination essentially allows the model to cheat on the test.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试集中的示例泄漏到训练数据中，则评估会受到影响。这种数据污染实际上允许模型在测试中作弊。
- en: Contamination can occur in various ways. Test data might be intentionally or
    unintentionally included in training data. More subtly, if test data is available
    online, web-scraped training data could inadvertently contain test examples. Models
    may also be explicitly trained to regenerate test datasets based on format and
    characteristics. Regardless of the cause, **contamination renders empirical comparisons
    between models invalid.**
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 污染可以通过多种方式发生。测试数据可能被有意或无意地包含在训练数据中。更微妙的是，如果测试数据在线可用，网络抓取的训练数据可能无意中包含测试示例。模型也可能被明确训练以根据格式和特征重新生成测试数据集。无论原因如何，**污染使得模型之间的实证比较无效。**
- en: This *benchmark leakage* provides an unfair advantage if one LLM has seen data
    related to the test set, but another has not. It casts doubt on claimed improvements
    and makes comparisons misleading, undermining the purpose of benchmarks. Unfortunately,
    leakage is problematic to detect externally and benefits models that exploit it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种*基准泄漏*提供了不公平的优势，如果一个LLM见过与测试集相关的数据，而另一个LLM没有。这使得声称的改进产生怀疑，并使比较具有误导性，破坏了基准测试的目的。不幸的是，泄漏难以外部检测，并使利用它的模型受益。
- en: Introducing phi-CTNL
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍phi-CTNL
- en: Our pretraining data for phi-CTNL is constructed by carefully curating an expert-crafted,
    non-synthetic data mixture. Specifically, we first choose the downstream academic
    benchmarks that we wish to evaluate our model on, then pretrain on those benchmarks.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们的phi-CTNL预训练数据由精心策划的专家制作的非合成数据混合而成。具体来说，我们首先选择希望对其进行评估的下游学术基准，然后在这些基准上进行预训练。
- en: The hilarious paper titled *Pretraining on the Test Set Is All You Need* highlights
    the pitfalls of relying too heavily on benchmarks for evaluation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那篇标题为*Pretraining on the Test Set Is All You Need*的搞笑论文突出了过度依赖基准评估的陷阱。
- en: '![](../Images/23ed17e9f2d12f2fb11b42014dace25a.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23ed17e9f2d12f2fb11b42014dace25a.png)'
- en: Perfect scores in every benchmark. [2]
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个基准测试中取得完美分数。[2]
- en: They show how a **small 1 million parameter LLM called phi-CTNL** pre-trained
    on just 100,000 tokens achieves perfect scores across diverse academic benchmarks,
    outperforming state-of-the-art models like GPT-3\. The key? The pretraining data
    consisted solely of the testing data from those exact benchmarks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 他们展示了一个**名为phi-CTNL的小型1百万参数LLM**在仅用100,000个标记进行预训练的情况下，如何在各种学术基准测试中取得完美分数，超越了像GPT-3这样的最先进模型。关键是什么？预训练数据完全由这些基准的测试数据组成。
- en: This is the risk of benchmark leakage — when test data leaks into the pre-trained
    model, evaluation results become meaningless.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这就是基准泄漏的风险——当测试数据泄漏到预训练模型中时，评估结果变得毫无意义。
- en: Even if meant as a parody, the paper brings attention to a serious issue typically
    unnoticed by the general public.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是作为戏仿，这篇论文也引起了对一个通常被公众忽视的严重问题的关注。
- en: Demonstrating the Risks
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演示风险
- en: To concretely demonstrate the risks, Zhou et al. [3] take popular LLMs of varying
    sizes like GPT-Neo (1.3B parameters) and LLaMA (65B parameters) and continue pre-training
    them on data related to test sets. They test increasingly severe forms of leakage
    using the training set, test prompts, and the full test set.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了具体演示风险，Zhou等人[3]对不同规模的流行LLM如GPT-Neo（13亿参数）和LLaMA（65亿参数）进行了进一步的预训练，使用与测试集相关的数据。他们利用训练集、测试提示和完整的测试集测试越来越严重的泄漏形式。
- en: '![](../Images/5e5f3c0df05c1022f18e537dcf20a9a2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e5f3c0df05c1022f18e537dcf20a9a2.png)'
- en: Adding benchmark data to LLM’s training data improves their score on that benchmark.
    [3]
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 将基准数据添加到LLM的训练数据中，可以提高其在该基准上的评分。[3]
- en: The results are dramatic. On benchmarks like LAMBADA and MMLU, small models
    leapfrog over far larger ones just by training on associated data, **improving
    20–30% in some cases**. For instance, GPT-Neo surpasses LLaMA on many tasks when
    given the training set, despite having 50x fewer parameters. Even language tasks
    in Chinese see a boost, even though the models have little Chinese data overall.
    Clearly, related training data is hugely valuable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常显著。在像LAMBADA和MMLU这样的基准测试中，小模型通过训练关联数据超越了远大的模型，**在某些情况下提升了20-30%**。例如，GPT-Neo在许多任务中超越了LLaMA，尽管其参数数量少50倍。即便是中文语言任务也得到了提升，尽管这些模型的中文数据总量很少。显然，相关的训练数据具有巨大的价值。
- en: Incorporating test prompts provides another massive gain, with models regularly
    achieving over 90% accuracy by learning the exact test format. And with full test
    set leakage, models can score 100% — they simply memorize all examples.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 融入测试提示带来了另一个巨大收益，通过学习精确的测试格式，模型经常能达到90%以上的准确率。若测试集完全泄漏，模型可以达到100%的得分——它们只是记住了所有示例。
- en: At first glance, it may seem benchmark leakage only causes misleadingly high
    evaluation scores. However, it can negatively impact LLMs in multiple ways. **Performance
    gains are restricted to leaked benchmarks, sometimes decreasing scores on other
    tests.** The model becomes skewed toward specifics of leaked data at the expense
    of general skills.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，基准测试泄漏似乎只会导致虚高的评估分数。然而，它可能以多种方式对LLM产生负面影响。**性能提升仅限于泄漏的基准，有时在其他测试中的分数会下降。**
    模型变得倾向于泄漏数据的具体细节，而牺牲了通用技能。
- en: Benchmark leakage provides illusory progress on a narrow capability while potentially
    harming broader competence — trading generalization for inflated metrics on a
    single benchmark.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试泄漏在狭窄能力范围内提供了虚假的进展，同时可能损害了更广泛的能力——用在单一基准上的虚高指标来交换泛化能力。
- en: Data contamination and maintaining evaluation integrity
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据污染与维持评估完整性
- en: LLM developers should rigorously check pretraining data against test sets and
    disclose any risks found. Reporting the full composition of pretraining data also
    helps detect leakage. **Unfortunately, most open-source models don’t publish their
    training data.**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LLM开发者应严格检查预训练数据与测试集之间的一致性，并披露任何发现的风险。报告预训练数据的完整组成也有助于检测泄漏。**不幸的是，大多数开源模型并未公布其训练数据。**
- en: Benchmark leakage is not a new problem, but its scale is magnified with LLMs
    containing trillions of parameters pre-trained on internet-scale data. LLMs are
    enormous black boxes, so we can’t know what data has been used to train them.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试泄漏不是一个新问题，但随着LLM包含数万亿参数，并在互联网规模的数据上进行预训练，其规模被放大了。LLM是巨大的黑箱，我们无法知道用于训练它们的数据是什么。
- en: Benchmarks and independent evaluators must keep pace to prevent misleading claims
    of progress.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试和独立评估者必须保持同步，以防止误导性进展声明。
- en: '[](/everything-you-should-know-about-evaluating-large-language-models-dce69ef8b2d2?source=post_page-----9a7315144389--------------------------------)
    [## Everything You Should Know About Evaluating Large Language Models'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 你需要知道的评估大型语言模型的一切](https://towardsdatascience.com/everything-you-should-know-about-evaluating-large-language-models-dce69ef8b2d2?source=post_page-----9a7315144389--------------------------------)'
- en: From perplexity to measuring general intelligence
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从困惑到测量通用智能
- en: towardsdatascience.com](/everything-you-should-know-about-evaluating-large-language-models-dce69ef8b2d2?source=post_page-----9a7315144389--------------------------------)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](https://towardsdatascience.com/everything-you-should-know-about-evaluating-large-language-models-dce69ef8b2d2?source=post_page-----9a7315144389--------------------------------)'
- en: '**Also, there are benchmarks where GPT is the evaluator** *(AlpacaEval),* and
    the evaluation may be less meaningful if the tested model is fine-tuned on data
    generated by GPT itself.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**此外，有些基准测试中GPT是评估者** *(AlpacaEval)*，如果测试模型是用GPT自身生成的数据进行微调的，则评估可能不那么有意义。'
- en: Finding evidence of data contamination
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找数据污染的证据
- en: Checking for data contamination is straightforward, and you can do it yourself.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 检查数据污染是直接的，你可以自己进行。
- en: First, pick a dataset you want to evaluate the model on. This dataset should
    have defined train/dev/test splits. Popular academic datasets like SQuAD, CoNLL
    2003, etc, are good choices.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，选择一个你想评估模型的数据集。该数据集应有明确的训练/开发/测试分割。像SQuAD、CoNLL 2003等流行的学术数据集是不错的选择。
- en: 'Next, prompt the model to generate examples from the dataset. Use a prompt
    like:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，提示模型从数据集中生成示例。使用类似的提示：
- en: Please generate 3 examples from the {dataset} {split} split in the correct format.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请从{dataset} {split}分割中生成3个示例，格式要正确。
- en: Now compare the examples generated by the model to actual examples from the
    dataset. If they match, the model likely memorized parts of that split during
    training.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将模型生成的示例与数据集中的实际示例进行比较。如果它们匹配，模型可能在训练过程中记住了该部分。
- en: This process is used in the **LM Contamination index**, where they gather evidence
    of data contamination across different LLMs and benchmarks. There is evidence
    of contamination in many LLMs and datasets. [4]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程在**LM污染指数**中使用，他们收集了不同LLM和基准中的数据污染证据。许多LLM和数据集中存在污染证据。[4]
- en: If the model is not an instruct fine-tuned one (e.g., a model able to answer
    questions), prompt the first half of a benchmark instance and see if it can generate
    the rest. **A user on X found evidence of contamination in phi-1.5 on the GSM8k
    dataset using this process.**
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型不是经过指令微调的（例如，能够回答问题的模型），请输入基准实例的前半部分，看看它是否能生成其余部分。**一位X上的用户通过这个过程在GSM8k数据集中发现了phi-1.5的污染证据。**
- en: Finding evidence of data contamination.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找数据污染的证据。
- en: Returning to the Gemini technical report, they mention the data contamination
    issue.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 回到Gemini技术报告中，他们提到数据污染问题。
- en: Evaluation on these benchmarks is challenging and may be affected by data contamination.
    We performed an extensive leaked data analysis after training to ensure the results
    we report here are as scientifically sound as possible, but still found some minor
    issues and decided not to report results on [some benchmarks]
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这些基准上的评估是具有挑战性的，可能会受到数据污染的影响。我们在训练后进行了广泛的泄露数据分析，以确保我们报告的结果尽可能科学准确，但仍发现了一些小问题，并决定不在[某些基准]上报告结果。
- en: The authors conducted extensive leaked data analysis after training the models
    to identify any potential overlap between the training data and test sets. This
    process involved thoroughly evaluating each benchmark used and checking for contamination
    issues.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作者在训练模型后进行了广泛的泄露数据分析，以识别训练数据和测试集之间的潜在重叠。这个过程涉及彻底评估使用的每个基准，并检查污染问题。
- en: '![](../Images/0687695ca3518043cdb5dd40534a7184.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0687695ca3518043cdb5dd40534a7184.png)'
- en: Data contamination is acknowledged by Google too. [1]
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据污染也被Google承认了。[1]
- en: The authors took steps to report decontaminated results where minor problems
    were found, such as with the HellaSwag benchmark. For HellaSwag, they measured
    performance using 10-shot prompting instead of fewer shots to avoid relying on
    possible training data overlaps.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 作者采取措施报告了发现的去污染结果，例如HellaSwag基准。对于HellaSwag，他们使用10-shot提示来测量性能，而不是使用更少的提示，以避免依赖可能的训练数据重叠。
- en: The authors also emphasized evaluating the models on completely new held-out
    datasets that had confirmed separation from the training data. Examples include
    using new test sets like WMT23 and AMC math problems from 2022–2023 that were
    verified to have no overlap.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作者还强调了在完全新且确认与训练数据分开的数据集上评估模型的重要性。例如，使用像WMT23和2022-2023年的AMC数学问题这样的新测试集，这些测试集被验证没有重叠。
- en: For benchmarks where contamination was identified as an issue after initial
    reporting, such as LAMBADA, the authors decided not to report those problematic
    results.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在初步报告后被识别为存在污染问题的基准，例如LAMBADA，作者决定不报告这些有问题的结果。
- en: Future directions
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来方向
- en: Benchmark leakage allows LLMs to cheat, faking progress through contamination
    rather than true improvements in competence. If left unaddressed, this issue undermines
    trust in both benchmarks and LLMs. Following best practices can mitigate the risks,
    keeping benchmarks robust and comparisons fair.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 基准泄露允许LLM作弊，通过污染假装进步，而不是通过真正的能力提升。如果不加以解决，这个问题会破坏对基准和LLM的信任。遵循最佳实践可以降低风险，保持基准的鲁棒性和公平比较。
- en: Don’t trust claims of LLMs being better than other ones based on benchmarks
    run by the authors. Benchmarks and evaluation methodology can be cherry-picked
    to only show favorable scenarios.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 不要相信基于作者运行的基准声明LLM优于其他LLM的说法。基准和评估方法可能会被挑选以仅展示有利的场景。
- en: Always try new models yourself before having an opinion.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在形成意见之前，总是自己尝试新的模型。
- en: Or why not experiment with creating your own benchmark? While not easy, you
    can customize it to your use case.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 或者为什么不尝试创建自己的基准？虽然不容易，但你可以根据你的用例进行定制。
- en: '*If you enjoyed this article, join* [***Text Generation***](https://textgeneration.substack.com/)
    *— our newsletter has two weekly posts with the latest insights on Generative
    AI and Large Language Models.*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章，加入* [***文本生成***](https://textgeneration.substack.com/) *—— 我们的通讯每周有两篇文章，提供有关生成式
    AI 和大型语言模型的最新见解。*'
- en: '*Also, you can find me on* [***LinkedIn***](https://www.linkedin.com/in/driccio/)***.***'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*另外，你也可以在* [***LinkedIn***](https://www.linkedin.com/in/driccio/)***上找到我。***'
- en: References
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Google Gemini Technical Report DeepMind Dec 2023](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Google Gemini 技术报告 DeepMind 2023 年 12 月](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)'
- en: '[[2309.08632] Pretraining on the Test Set Is All You Need (arxiv.org)](https://arxiv.org/abs/2309.08632)'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[[2309.08632] 仅在测试集上预训练就足够了 (arxiv.org)](https://arxiv.org/abs/2309.08632)'
- en: '[[2311.01964] Don’t Make Your LLM an Evaluation Benchmark Cheater (arxiv.org)](https://arxiv.org/abs/2311.01964)'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[[2311.01964] 不要让你的 LLM 成为评估基准的作弊者 (arxiv.org)](https://arxiv.org/abs/2311.01964)'
- en: '[LM Contamination Index (hitz-zentroa.github.io)](https://hitz-zentroa.github.io/lm-contamination/)'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[语言模型污染指数 (hitz-zentroa.github.io)](https://hitz-zentroa.github.io/lm-contamination/)'
