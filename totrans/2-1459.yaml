- en: Machine Learning in a Non-Euclidean Space
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: éæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­çš„æœºå™¨å­¦ä¹ 
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/machine-learning-in-a-non-euclidean-space-99b0a776e92e](https://towardsdatascience.com/machine-learning-in-a-non-euclidean-space-99b0a776e92e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/machine-learning-in-a-non-euclidean-space-99b0a776e92e](https://towardsdatascience.com/machine-learning-in-a-non-euclidean-space-99b0a776e92e)
- en: '![](../Images/33e8dc96ecf4a66659e0c47e33bde03e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33e8dc96ecf4a66659e0c47e33bde03e.png)'
- en: Photo by [Greg Rosenke](https://unsplash.com/@greg_rosenke?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[Greg Rosenke](https://unsplash.com/@greg_rosenke?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Chapter I. Why you should learn about non-Euclidean ML
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ç« ï¼šä¸ºä»€ä¹ˆä½ åº”è¯¥å­¦ä¹ éæ¬§å‡ é‡Œå¾—æœºå™¨å­¦ä¹ 
- en: '[](https://medium.com/@mastafa.foufa?source=post_page-----99b0a776e92e--------------------------------)[![Mastafa
    Foufa](../Images/2e0b26ed83f04e943438afa1aab462a8.png)](https://medium.com/@mastafa.foufa?source=post_page-----99b0a776e92e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----99b0a776e92e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----99b0a776e92e--------------------------------)
    [Mastafa Foufa](https://medium.com/@mastafa.foufa?source=post_page-----99b0a776e92e--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mastafa.foufa?source=post_page-----99b0a776e92e--------------------------------)[![Mastafa
    Foufa](../Images/2e0b26ed83f04e943438afa1aab462a8.png)](https://medium.com/@mastafa.foufa?source=post_page-----99b0a776e92e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----99b0a776e92e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----99b0a776e92e--------------------------------)
    [Mastafa Foufa](https://medium.com/@mastafa.foufa?source=post_page-----99b0a776e92e--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----99b0a776e92e--------------------------------)
    Â·10 min readÂ·Jun 16, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----99b0a776e92e--------------------------------)
    Â·é˜…è¯»æ—¶é—´10åˆ†é’ŸÂ·2023å¹´6æœˆ16æ—¥
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'â€œIs our comfortable and familiar Euclidean space and its linear structure always
    the right place for machine learning? Recent research argues otherwise: it is
    not always needed and sometimes harmful, as demonstrated by a wave of exciting
    work. Starting with the notion of hyperbolic representations for hierarchical
    data two years ago, a major push has resulted in new ideas for representations
    in non-Euclidean spaces, new algorithms and models with non-Euclidean data and
    operations, and new perspectives on the underlying functionality of non-Euclidean
    ML.â€ *by* [*Fred Sala*](http://stanford.edu/~fredsala)*,* [*Ines Chami*](http://web.stanford.edu/~chami/)*,*
    [*Adva Wolf*](https://mathematics.stanford.edu/people/adva-wolf)*,* [*Albert Gu*](http://web.stanford.edu/~albertgu/)*,*
    [*Beliz Gunel*](http://web.stanford.edu/~bgunel/) *and* [*Chris RÃ©*](https://cs.stanford.edu/people/chrismre/),
    [2019](https://dawn.cs.stanford.edu/2019/10/10/noneuclidean/)'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæˆ‘ä»¬çš„èˆ’é€‚å’Œç†Ÿæ‚‰çš„æ¬§å‡ é‡Œå¾—ç©ºé—´åŠå…¶çº¿æ€§ç»“æ„æ˜¯å¦æ€»æ˜¯é€‚åˆæœºå™¨å­¦ä¹ ï¼Ÿè¿‘æœŸç ”ç©¶å¯¹æ­¤æå‡ºäº†ä¸åŒçš„çœ‹æ³•ï¼šå¹¶éæ€»æ˜¯å¿…è¦ï¼Œæœ‰æ—¶ç”šè‡³æœ‰å®³ï¼Œè¿™ä¸€ç‚¹åœ¨ä¸€ç³»åˆ—ä»¤äººå…´å¥‹çš„å·¥ä½œä¸­å¾—åˆ°äº†è¯æ˜ã€‚è‡ªä»ä¸¤å¹´å‰æå‡ºåŒæ›²è¡¨ç¤ºæ³•ç”¨äºå±‚æ¬¡æ•°æ®ä»¥æ¥ï¼Œå–å¾—äº†é‡å¤§è¿›å±•ï¼Œäº§ç”Ÿäº†éæ¬§å‡ é‡Œå¾—ç©ºé—´è¡¨ç¤ºçš„æ–°æ€æƒ³ã€æ–°ç®—æ³•å’Œæ¨¡å‹ï¼Œä»¥åŠå¯¹éæ¬§å‡ é‡Œå¾—æœºå™¨å­¦ä¹ åŸºæœ¬åŠŸèƒ½çš„æ–°è§†è§’ã€‚â€
    *ä½œè€…* [*Fred Sala*](http://stanford.edu/~fredsala)*ã€* [*Ines Chami*](http://web.stanford.edu/~chami/)*ã€*
    [*Adva Wolf*](https://mathematics.stanford.edu/people/adva-wolf)*ã€* [*Albert Gu*](http://web.stanford.edu/~albertgu/)*ã€*
    [*Beliz Gunel*](http://web.stanford.edu/~bgunel/) *å’Œ* [*Chris RÃ©*](https://cs.stanford.edu/people/chrismre/)ï¼Œ
    [2019](https://dawn.cs.stanford.edu/2019/10/10/noneuclidean/)
- en: What you will learn in this article.
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½ å°†åœ¨æœ¬æ–‡ä¸­å­¦åˆ°ä»€ä¹ˆã€‚
- en: Distortion measures how well distance is preserved when representing data in
    another space.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰­æ›²åº¦é‡äº†åœ¨å°†æ•°æ®è¡¨ç¤ºä¸ºå¦ä¸€ä¸ªç©ºé—´æ—¶è·ç¦»ä¿ç•™çš„æ•ˆæœã€‚
- en: For some data, Euclidean space implies high distortion, so non-Euclidean spaces
    like spherical or hyperbolic spaces are used instead.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæŸäº›æ•°æ®ï¼Œæ¬§å‡ é‡Œå¾—ç©ºé—´ä¼šäº§ç”Ÿè¾ƒé«˜çš„æ‰­æ›²ï¼Œå› æ­¤ä½¿ç”¨åƒçƒé¢æˆ–åŒæ›²ç©ºé—´è¿™æ ·çš„éæ¬§å‡ é‡Œå¾—ç©ºé—´ã€‚
- en: Riemannian geometry tools like manifolds and Riemannian metric are used for
    non-Euclidean Machine Learning.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é»æ›¼å‡ ä½•å·¥å…·å¦‚æµå½¢å’Œé»æ›¼åº¦é‡è¢«ç”¨äºéæ¬§å‡ é‡Œå¾—æœºå™¨å­¦ä¹ ã€‚
- en: Manifolds are curved spaces that are locally Euclidean.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµå½¢æ˜¯å±€éƒ¨ä¸Šæ¬§å‡ é‡Œå¾—çš„æ›²é¢ã€‚
- en: Exponential and logarithmic maps are used to go from a manifold to its tangent
    space.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŒ‡æ•°æ˜ å°„å’Œå¯¹æ•°æ˜ å°„ç”¨äºä»æµå½¢åˆ°å…¶åˆ‡ç©ºé—´çš„è½¬æ¢ã€‚
- en: Riemannian metric allows to compute shortest distances on the manifold.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é»æ›¼åº¦é‡å…è®¸åœ¨æµå½¢ä¸Šè®¡ç®—æœ€çŸ­è·ç¦»ã€‚
- en: Before going further in this series about non-Euclidean geometry applied to
    Machine Learning (*ML*), I had to answer an important question. **Is it worth
    learning more about non-Euclidean ML?**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»§ç»­é˜…è¯»æœ¬ç³»åˆ—å…³äºåº”ç”¨äºæœºå™¨å­¦ä¹ ï¼ˆ*ML*ï¼‰çš„éæ¬§å‡ é‡Œå¾—å‡ ä½•ä¹‹å‰ï¼Œæˆ‘å¿…é¡»å›ç­”ä¸€ä¸ªé‡è¦çš„é—®é¢˜ã€‚**æ˜¯å¦å€¼å¾—æ·±å…¥äº†è§£éæ¬§å‡ é‡Œå¾—MLï¼Ÿ**
- en: To answer such a question, I started by researching non-Euclidean ML. I quickly
    ended up finding a couple of resources. The very first one is from Stanford and
    the citation above is extracted from it. The authors argue that Machine Learning
    was designed with a certain geometry, namely the Euclidean geometry, more by tradition
    or convenience, than by rational thinking.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘å¼€å§‹ç ”ç©¶éæ¬§å‡ é‡Œå¾—MLã€‚æˆ‘å¾ˆå¿«æ‰¾åˆ°äº†ä¸€äº›èµ„æºï¼Œç¬¬ä¸€ä¸ªæ˜¯æ¥è‡ªæ–¯å¦ç¦çš„ï¼Œä»¥ä¸Šå¼•ç”¨å°±æ˜¯æ‘˜è‡ªå…¶ä¸­ã€‚ä½œè€…è®¤ä¸ºï¼Œæœºå™¨å­¦ä¹ çš„è®¾è®¡é‡‡ç”¨äº†æŸç§å‡ ä½•ï¼Œå³æ¬§å‡ é‡Œå¾—å‡ ä½•ï¼Œè¿™æ›´å¤šæ˜¯ä¼ ç»Ÿæˆ–ä¾¿åˆ©çš„é€‰æ‹©ï¼Œè€Œéç†æ€§æ€è€ƒçš„ç»“æœã€‚
- en: So far, the choice of the Euclidean geometry doesnâ€™t seem like a major problem.
    But the authors trigger our attention by citing Bronstein et al. in their [seminal
    description of the geometric deep learning](https://arxiv.org/pdf/1611.08097.pdf)
    paradigm.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œé€‰æ‹©æ¬§å‡ é‡Œå¾—å‡ ä½•ä¼¼ä¹å¹¶ä¸æ˜¯ä¸€ä¸ªå¤§é—®é¢˜ã€‚ä½†ä½œè€…é€šè¿‡å¼•ç”¨Bronsteinç­‰äººåœ¨å…¶[å¼€åˆ›æ€§å‡ ä½•æ·±åº¦å­¦ä¹ æè¿°](https://arxiv.org/pdf/1611.08097.pdf)ä¸­å¼•èµ·äº†æˆ‘ä»¬çš„æ³¨æ„ã€‚
- en: â€œ[m]any scientific fields study data with an underlying structure that is a
    non-Euclidean space.â€ [Bronstein et al.](https://arxiv.org/pdf/1611.08097.pdf)
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œ[m]è®¸å¤šç§‘å­¦é¢†åŸŸç ”ç©¶å…·æœ‰éæ¬§å‡ é‡Œå¾—ç©ºé—´åŸºç¡€ç»“æ„çš„æ•°æ®ã€‚â€ [Bronstein et al.](https://arxiv.org/pdf/1611.08097.pdf)
- en: 'As I continued reading the article, I stumbled upon an aspect that I wasnâ€™t
    familiar with: the notion of space **flatness**.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ç»§ç»­é˜…è¯»æ–‡ç« æ—¶ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªæˆ‘ä¸ç†Ÿæ‚‰çš„æ–¹é¢ï¼šç©ºé—´**å¹³å¦æ€§**çš„æ¦‚å¿µã€‚
- en: â€œWe have chosen to work with Euclidean space, with all of its inherent properties,
    among the most critical of which is its **flatness**.â€ [*Fred Sala*](http://stanford.edu/~fredsala)*,*
    [*Ines Chami*](http://web.stanford.edu/~chami/)*,* [*Adva Wolf*](https://mathematics.stanford.edu/people/adva-wolf)*,*
    [*Albert Gu*](http://web.stanford.edu/~albertgu/)*,* [*Beliz Gunel*](http://web.stanford.edu/~bgunel/)
    *and* [*Chris RÃ©*](https://cs.stanford.edu/people/chrismre/), [2019](https://dawn.cs.stanford.edu/2019/10/10/noneuclidean/)
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæˆ‘ä»¬é€‰æ‹©äº†ä½¿ç”¨æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼Œå…¶å›ºæœ‰çš„å±æ€§ä¸­æœ€å…³é”®çš„ä¹‹ä¸€å°±æ˜¯**å¹³å¦æ€§**ã€‚â€ [*Fred Sala*](http://stanford.edu/~fredsala)*,*
    [*Ines Chami*](http://web.stanford.edu/~chami/)*,* [*Adva Wolf*](https://mathematics.stanford.edu/people/adva-wolf)*,*
    [*Albert Gu*](http://web.stanford.edu/~albertgu/)*,* [*Beliz Gunel*](http://web.stanford.edu/~bgunel/)
    *å’Œ* [*Chris RÃ©*](https://cs.stanford.edu/people/chrismre/)ï¼Œ [2019](https://dawn.cs.stanford.edu/2019/10/10/noneuclidean/)
- en: 'The authors of the Stanford article mention the impact of flatness. Below are
    the three points raised and you should read our series to get more intuition:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¯å¦ç¦æ–‡ç« çš„ä½œè€…æåˆ°äº†å¹³å¦æ€§çš„å½±å“ã€‚ä»¥ä¸‹æ˜¯æå‡ºçš„ä¸‰ç‚¹ï¼Œä½ åº”è¯¥é˜…è¯»æˆ‘ä»¬çš„ç³»åˆ—æ–‡ç« ä»¥è·å¾—æ›´å¤šç›´è§‚çš„ç†è§£ï¼š
- en: '**Better representations** â€” they argue that Euclidean spaces are not fit for
    certain datasets like hierarchical datasets that can be described by trees.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ›´å¥½çš„è¡¨ç¤º** â€” ä»–ä»¬è®¤ä¸ºæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸é€‚åˆæŸäº›æ•°æ®é›†ï¼Œä¾‹å¦‚å¯ä»¥ç”¨æ ‘æè¿°çš„å±‚æ¬¡æ•°æ®é›†ã€‚'
- en: '**Unlocking the full potential of models** â€” they argue that to push the barriers
    in terms of model performance, we could improve the space the data lie in, by
    moving from Euclidean geometry to non-Euclidean geometry.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é‡Šæ”¾æ¨¡å‹çš„å…¨éƒ¨æ½œåŠ›** â€” ä»–ä»¬è®¤ä¸ºï¼Œä¸ºäº†æ¨åŠ¨æ¨¡å‹æ€§èƒ½çš„ç•Œé™ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ•°æ®æ‰€åœ¨çš„ç©ºé—´ä»æ¬§å‡ é‡Œå¾—å‡ ä½•è½¬å˜ä¸ºéæ¬§å‡ é‡Œå¾—å‡ ä½•æ¥æ”¹è¿›ã€‚'
- en: '**More flexible operations** â€” they argue that operations in non-Euclidean
    spaces are more flexible and require less dimensions. The authors explain that
    later in their article. But we will try to simplify that in our Medium series.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ›´çµæ´»çš„æ“ä½œ** â€” ä»–ä»¬è®¤ä¸ºéæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­çš„æ“ä½œæ›´åŠ çµæ´»ï¼Œæ‰€éœ€ç»´åº¦æ›´å°‘ã€‚ä½œè€…åœ¨æ–‡ç« ä¸­åé¢è§£é‡Šäº†è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å°†å°½é‡åœ¨æˆ‘ä»¬çš„Mediumç³»åˆ—ä¸­ç®€åŒ–è¿™ä¸€ç‚¹ã€‚'
- en: Representing a non-flat entity into a flat space
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°†éå¹³å¦å®ä½“è¡¨ç¤ºåˆ°å¹³é¢ç©ºé—´ä¸­
- en: It is important to have an appropriate geometry, conditionally to the input
    data. Below, we show an example of non-Euclidean data that is â€œforcedâ€ to fit
    in a 2-dimensional Euclidean space. This is our **well known spherical planet**
    that is flattened into a plane. However, this is done with **non negligible distortions**.
    By distortion, we mean that distances are not preserved, from the original space
    [*Earth â€” sphere*] to the space where the data is represented [*Maps â€” plane*].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©åˆé€‚çš„å‡ ä½•éå¸¸é‡è¦ï¼Œä¾èµ–äºè¾“å…¥æ•°æ®ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªéæ¬§å‡ é‡Œå¾—æ•°æ®çš„ä¾‹å­ï¼Œè¿™äº›æ•°æ®è¢«â€œå¼ºè¿«â€é€‚åº”äºäºŒç»´æ¬§å‡ é‡Œå¾—ç©ºé—´ã€‚è¿™æ˜¯æˆ‘ä»¬**ä¼—æ‰€å‘¨çŸ¥çš„çƒå½¢åœ°çƒ**è¢«å‹ç¼©æˆå¹³é¢ã€‚ç„¶è€Œï¼Œè¿™ç§è½¬æ¢ä¼´éšç€**ä¸å¯å¿½è§†çš„æ‰­æ›²**ã€‚æ‰€è°“æ‰­æ›²æ˜¯æŒ‡ä»åŸå§‹ç©ºé—´[*åœ°çƒ
    â€” çƒä½“*]åˆ°æ•°æ®è¡¨ç¤ºçš„ç©ºé—´[*åœ°å›¾ â€” å¹³é¢*]ï¼Œè·ç¦»æ²¡æœ‰è¢«ä¿ç•™ã€‚
- en: For example, below Mexico has ***in reality*** almost the same surface as Greenland
    (*right*) but appears much smaller in the actual projection (*left*).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¸‹å›¾ä¸­çš„å¢¨è¥¿å“¥åœ¨***å®é™…æƒ…å†µä¸­***å‡ ä¹ä¸æ ¼æ—å…°ï¼ˆ*å³*ï¼‰å…·æœ‰ç›¸åŒçš„è¡¨é¢ï¼Œä½†åœ¨å®é™…æŠ•å½±ä¸­ï¼ˆ*å·¦*ï¼‰çœ‹èµ·æ¥è¦å°å¾—å¤šã€‚
- en: '![](../Images/a79caf56683cbffe3194b997a903c659.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a79caf56683cbffe3194b997a903c659.png)'
- en: '**Resource:** From the authors. Note that the World map (left) is using the
    Mercator projection of our spherical planet. The Mercator map is defined by the
    formula (x, y) = Î», log tan(Ï€/4 + Ï†/2). *Adapted from* [*Wikipedia*](https://commons.wikimedia.org/wiki/File:World_map_-_low_resolution_chain_test.svg)*.*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æºï¼š** ä½œè€…æä¾›ã€‚è¯·æ³¨æ„ï¼Œä¸–ç•Œåœ°å›¾ï¼ˆå·¦ï¼‰ä½¿ç”¨çš„æ˜¯æˆ‘ä»¬çƒé¢æ˜Ÿçƒçš„å¢¨å¡æ‰˜æŠ•å½±ã€‚å¢¨å¡æ‰˜åœ°å›¾ç”±å…¬å¼ (x, y) = Î», log tan(Ï€/4 +
    Ï†/2) å®šä¹‰ã€‚*æ”¹ç¼–è‡ª* [*ç»´åŸºç™¾ç§‘*](https://commons.wikimedia.org/wiki/File:World_map_-_low_resolution_chain_test.svg)*.*'
- en: There are many ways to represent our earth that all involve some degree of distortion.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ç¤ºåœ°çƒçš„æ–¹å¼æœ‰å¾ˆå¤šç§ï¼Œè¿™äº›æ–¹å¼éƒ½æ¶‰åŠä¸€å®šç¨‹åº¦çš„æ‰­æ›²ã€‚
- en: '![](../Images/74da35a7c4dad90e88628d6619c531b5.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74da35a7c4dad90e88628d6619c531b5.png)'
- en: '**Resource:** Projecting the globe, with distortion. From the authors, adapted
    from [Wikipedia](https://en.wikipedia.org/wiki/Mercator_projection).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æºï¼š** å…¨çƒæŠ•å½±ï¼Œå¸¦æœ‰æ‰­æ›²ã€‚æ¥è‡ªä½œè€…ï¼Œæ”¹ç¼–è‡ª[ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/Mercator_projection)ã€‚'
- en: For example, distortion is naturally observed in the famous Mercator projection.
    The Greenland problem showcases the loss of information when moving from a spherical
    representation to a plane representation with such projection. This projection
    is not **area preserving,** a core property expected in this case. Indeed, Greenland,
    with an area of about 2.2 million square kilometers, looks larger than South America,
    with an area of about 17.8 million square kilometers. This Mercator projection
    preserves angles but not areas, hence making it non-perfect.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨è‘—åçš„å¢¨å¡æ‰˜æŠ•å½±ä¸­ï¼Œè‡ªç„¶è§‚å¯Ÿåˆ°æ‰­æ›²ã€‚æ ¼æ—å…°é—®é¢˜å±•ç¤ºäº†ä»çƒé¢è¡¨ç¤ºè½¬åˆ°å¹³é¢è¡¨ç¤ºæ—¶ä¿¡æ¯çš„ä¸¢å¤±ã€‚è¿™ç§æŠ•å½±ä¸æ˜¯**é¢ç§¯ä¿æŒçš„**ï¼Œè¿™æ˜¯åœ¨è¿™ç§æƒ…å†µä¸‹æœŸæœ›çš„æ ¸å¿ƒå±æ€§ã€‚å®é™…ä¸Šï¼Œæ ¼æ—å…°çš„é¢ç§¯çº¦ä¸º220ä¸‡å¹³æ–¹å…¬é‡Œï¼Œæ¯”å—ç¾æ´²ï¼ˆé¢ç§¯çº¦1780ä¸‡å¹³æ–¹å…¬é‡Œï¼‰çœ‹èµ·æ¥è¦å¤§ã€‚è¿™ç§å¢¨å¡æ‰˜æŠ•å½±ä¿æŒè§’åº¦ä½†ä¸ä¿æŒé¢ç§¯ï¼Œå› æ­¤ä½¿å…¶ä¸å®Œç¾ã€‚
- en: 'Now, other datasets, are also forced to lie in an Euclidean space whereby we
    observe distortions. This is the case of **graphs**: in a Euclidean space, we
    cannot embed large classes of graphs without low distortion or without loss of
    information.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå…¶ä»–æ•°æ®é›†ä¹Ÿè¢«è¿«ä½äºæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æ‰­æ›²ã€‚è¿™æ˜¯**å›¾å½¢**çš„æƒ…å†µï¼šåœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬ä¸èƒ½åœ¨ä½æ‰­æ›²æˆ–ä¿¡æ¯ä¸¢å¤±çš„æƒ…å†µä¸‹åµŒå…¥å¤§ç±»å›¾å½¢ã€‚
- en: '**Distortion** has several more rigorous mathematical definitions. Essentially,
    we want distortion to measure the quality of the embedding by evaluating how well
    distances are preserved. Here, we define it as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ‰­æ›²**æœ‰å‡ ä¸ªæ›´ä¸¥æ ¼çš„æ•°å­¦å®šä¹‰ã€‚ä»æœ¬è´¨ä¸Šè®²ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰­æ›²èƒ½å¤Ÿé€šè¿‡è¯„ä¼°è·ç¦»ä¿æŒçš„å¥½åæ¥è¡¡é‡åµŒå…¥çš„è´¨é‡ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰å¦‚ä¸‹ï¼š'
- en: Distortion ~ AVG {Graph distance / Embedding distance }
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‰­æ›² ~ AVG {å›¾å½¢è·ç¦» / åµŒå…¥è·ç¦» }
- en: '**Example.**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¾‹å­ã€‚**'
- en: In the figure below, we can prove through the Poincare-type inequalities that
    we cannot embed the two cycles (*square*, *circle*) in a Euclidean space without
    distortion. Note that a distortion of 1 is a perfect distortion â€” graph distances
    are exactly matching the embedding space distances. **Any distortion different
    than 1 means we are not preserving the graph distances.**
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åºåŠ è±å‹ä¸ç­‰å¼è¯æ˜ï¼Œæˆ‘ä»¬ä¸èƒ½å°†ä¸¤ä¸ªå¾ªç¯ï¼ˆ*æ–¹å½¢*ï¼Œ*åœ†å½¢*ï¼‰åµŒå…¥åˆ°æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­è€Œä¸æ‰­æ›²ã€‚æ³¨æ„ï¼Œæ‰­æ›²ä¸º1æ˜¯å®Œç¾çš„æ‰­æ›²â€”â€”å›¾å½¢è·ç¦»å®Œå…¨åŒ¹é…åµŒå…¥ç©ºé—´è·ç¦»ã€‚**ä»»ä½•ä¸1ä¸åŒçš„æ‰­æ›²æ„å‘³ç€æˆ‘ä»¬æ²¡æœ‰ä¿æŒå›¾å½¢è·ç¦»ã€‚**
- en: '![](../Images/42350b592503cae1e5375925361599e4.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42350b592503cae1e5375925361599e4.png)'
- en: '**Resource:** From the authors. Optimal embedding of a cycle of length 4 [left],
    and optimal embedding of the 3-star K(1,3) [right]. Adapted from Octavian Ganeaâ€™s
    lecture at ETH Zurich.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æºï¼š** ä½œè€…æä¾›ã€‚é•¿åº¦ä¸º4çš„å¾ªç¯çš„æœ€ä½³åµŒå…¥[å·¦]ï¼Œä»¥åŠ3-star K(1,3)çš„æœ€ä½³åµŒå…¥[å³]ã€‚æ”¹ç¼–è‡ªOctavian Ganeaåœ¨è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢çš„è®²åº§ã€‚'
- en: On the square above, the two opposite nodes on the diagonal have a distance
    of 2 in terms of **graph distance.** However, the shortest path in the Euclidean
    embedding has a distance of **âˆš2.**
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„æ–¹å½¢ä¸­ï¼Œå¯¹è§’çº¿ä¸Šçš„ä¸¤ä¸ªå¯¹ç«‹èŠ‚ç‚¹åœ¨**å›¾å½¢è·ç¦»**ä¸Šæœ‰2çš„è·ç¦»ã€‚ç„¶è€Œï¼Œæ¬§å‡ é‡Œå¾—åµŒå…¥ä¸­çš„æœ€çŸ­è·¯å¾„è·ç¦»ä¸º**âˆš2ã€‚**
- en: This concept of distortion is really important as Euclidean geometry does not
    allow having the ideal â€œprojectionâ€ of graph data. In particular, for hierachical
    graph data, to minimize distortion, **a solution is to use a hyperbolic space**.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ‰­æ›²çš„æ¦‚å¿µéå¸¸é‡è¦ï¼Œå› ä¸ºæ¬§å‡ é‡Œå¾—å‡ ä½•ä¸å…è®¸å¯¹å›¾å½¢æ•°æ®è¿›è¡Œç†æƒ³çš„â€œæŠ•å½±â€ã€‚ç‰¹åˆ«åœ°ï¼Œå¯¹äºå±‚æ¬¡å›¾å½¢æ•°æ®ï¼Œä¸ºäº†æœ€å°åŒ–æ‰­æ›²ï¼Œ**ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨åŒæ›²ç©ºé—´**ã€‚
- en: '**Note**. We will learn more about this example of non-Euclidean space in the
    next chapter.'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**æ³¨æ„**ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ç« ä¸­æ·±å…¥äº†è§£è¿™ä¸ªéæ¬§å‡ é‡Œå¾—ç©ºé—´çš„ä¾‹å­ã€‚'
- en: Representing data in a non-Euclidean space
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨éæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­è¡¨ç¤ºæ•°æ®
- en: It is hard understanding how we can represent data in any other way than with
    vectors in ***Rn***. Plus, how can we move away from the Euclidean distance we
    know so well to compare two vector representations?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆéš¾ç†è§£æˆ‘ä»¬å¦‚ä½•ç”¨é™¤äº†***Rn***ä»¥å¤–çš„æ–¹å¼è¡¨ç¤ºæ•°æ®ã€‚è€Œä¸”ï¼Œæˆ‘ä»¬å¦‚ä½•æ‘†è„±æˆ‘ä»¬éå¸¸ç†Ÿæ‚‰çš„æ¬§å‡ é‡Œå¾—è·ç¦»æ¥æ¯”è¾ƒä¸¤ä¸ªå‘é‡è¡¨ç¤ºï¼Ÿ
- en: A solution is described by manifolds, in Riemannian geometry. Manifolds are
    objects that look like ***Rn but only locally.*** *That means we can locally use
    vectors for representing our data points. But only locally!*
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§è§£å†³æ–¹æ¡ˆç”±é»æ›¼å‡ ä½•ä¸­çš„æµå½¢æè¿°ã€‚æµå½¢æ˜¯çœ‹èµ·æ¥åƒ***Rn ä½†ä»…åœ¨å±€éƒ¨ã€‚*** *è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åœ¨å±€éƒ¨ä½¿ç”¨å‘é‡æ¥è¡¨ç¤ºæˆ‘ä»¬çš„æ•°æ®ç‚¹ã€‚ä½†ä»…åœ¨å±€éƒ¨ï¼*
- en: '![](../Images/9cba2f31402dd14b9d086d73a44c3a96.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cba2f31402dd14b9d086d73a44c3a96.png)'
- en: '**Resource**: The tangent space [Light grey, TxM] at a point x from the manifol
    M [Dark grey] and its tangent vector v. The vector x from the Manifold can be
    represented locally in the Euclidean tangent space. From [Wikipedia.](https://en.wikipedia.org/wiki/Tangent_space#)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šåœ¨æµå½¢ M [æ·±ç°è‰²] ä¸Šçš„ä¸€ä¸ªç‚¹ x å¤„çš„åˆ‡ç©ºé—´ [æµ…ç°è‰²ï¼ŒTxM] å’Œå®ƒçš„åˆ‡å‘é‡ vã€‚æµå½¢ä¸­çš„å‘é‡ x å¯ä»¥åœ¨æ¬§å‡ é‡Œå¾—åˆ‡ç©ºé—´ä¸­å±€éƒ¨è¡¨ç¤ºã€‚æ¥è‡ª
    [ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/Tangent_space#)'
- en: The notion of similarity or distances is key in Machine Learning. If we are
    building say an NLP model, we want to preserve the notion of similarity in semantics
    within the embedding space that represents textual input. In other words, we want
    two words that are similar in meaning to also be similar in the Euclidean space,
    i.e. with a low Euclidean distance. Similarly, two words that are dissimilar in
    meaning should be far away in the Euclidean space, i.e. with a high Euclidean
    distance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸ä¼¼æ€§æˆ–è·ç¦»çš„æ¦‚å¿µåœ¨æœºå™¨å­¦ä¹ ä¸­è‡³å…³é‡è¦ã€‚å¦‚æœæˆ‘ä»¬åœ¨æ„å»ºä¸€ä¸ª NLP æ¨¡å‹ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è¡¨ç¤ºæ–‡æœ¬è¾“å…¥çš„åµŒå…¥ç©ºé—´ä¸­ä¿ç•™è¯­ä¹‰ä¸Šçš„ç›¸ä¼¼æ€§ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›è¯­ä¹‰ç›¸ä¼¼çš„ä¸¤ä¸ªè¯åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ä¹Ÿç›¸ä¼¼ï¼Œå³æ¬§å‡ é‡Œå¾—è·ç¦»ä½ã€‚åŒæ ·ï¼Œè¯­ä¹‰ä¸ç›¸ä¼¼çš„ä¸¤ä¸ªè¯åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­åº”å½“è·ç¦»è¾ƒè¿œï¼Œå³æ¬§å‡ é‡Œå¾—è·ç¦»é«˜ã€‚
- en: Hence, there needs to be an equivalent approach when escaping Euclidean geometry.
    This approach is described by a *Riemannian metric.* The **Riemannian metric allows
    us to compare two entities in the non-Euclidean space and preserve this intuitive
    notion of distance**.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå½“é€ƒé¿æ¬§å‡ é‡Œå¾—å‡ ä½•æ—¶ï¼Œéœ€è¦æœ‰ä¸€ä¸ªç­‰æ•ˆçš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ç”±*é»æ›¼åº¦é‡*æ¥æè¿°ã€‚**é»æ›¼åº¦é‡ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨éæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­æ¯”è¾ƒä¸¤ä¸ªå®ä½“ï¼Œå¹¶ä¿ç•™è¿™ç§ç›´è§‚çš„è·ç¦»æ¦‚å¿µ**ã€‚
- en: ğŸ‘€ I remember.
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‘€ æˆ‘è®°å¾—äº†ã€‚
- en: Now, we need to remember that in this non-Euclidean framework we can perform
    operations locally on our data representations and we have a metric to measure
    distances. Thus, we are equipped to do ML in non-Euclidean spaces.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦è®°ä½ï¼Œåœ¨è¿™ä¸ªéæ¬§å‡ é‡Œå¾—æ¡†æ¶ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ•°æ®è¡¨ç¤ºè¿›è¡Œå±€éƒ¨æ“ä½œï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰ä¸€ä¸ªåº¦é‡æ¥æµ‹é‡è·ç¦»ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å…·å¤‡äº†åœ¨éæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­è¿›è¡Œæœºå™¨å­¦ä¹ çš„èƒ½åŠ›ã€‚
- en: ğŸ™ŒğŸ» Why should I learn more about ML in a non-Euclidean space?
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ™ŒğŸ» ä¸ºä»€ä¹ˆæˆ‘è¦åœ¨éæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­å­¦ä¹ æ›´å¤šå…³äºæœºå™¨å­¦ä¹ çš„çŸ¥è¯†ï¼Ÿ
- en: So far, we know that ML without the genius [Euclid](https://en.wikipedia.org/wiki/Euclid)
    is actually something. There are actual projects that exist and approach our traditional
    machine learning problems with a different geometry framework.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çŸ¥é“æ²¡æœ‰å¤©æ‰[æ¬§å‡ é‡Œå¾—](https://en.wikipedia.org/wiki/Euclid)çš„æœºå™¨å­¦ä¹ å®é™…ä¸Šæ˜¯æœ‰æ„ä¹‰çš„ã€‚ç¡®å®å­˜åœ¨ä¸€äº›é¡¹ç›®ï¼Œå®ƒä»¬ç”¨ä¸åŒçš„å‡ ä½•æ¡†æ¶æ¥è§£å†³æˆ‘ä»¬ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚
- en: 'Now, a question naturally emerges: **is it worth our time learning more than
    the existence of this field?**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜å‡ºç°äº†ï¼š**å€¼å¾—èŠ±æ—¶é—´äº†è§£è¿™ä¸ªé¢†åŸŸçš„å­˜åœ¨å—ï¼Ÿ**
- en: It is a rather scary space that involves non-trivial mathematics. But my friend,
    Aniss Medbouhi, [ML Doctoral Researcher at KTH](https://www.linkedin.com/in/aniss-medbouhi/),
    will help us get past the inherent complexity of this space.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªç›¸å½“ä»¤äººç•æƒ§çš„ç©ºé—´ï¼Œæ¶‰åŠå¤æ‚çš„æ•°å­¦ã€‚ä½†æˆ‘çš„æœ‹å‹ Aniss Medbouhiï¼Œ[KTH çš„ ML åšå£«ç ”ç©¶å‘˜](https://www.linkedin.com/in/aniss-medbouhi/)ï¼Œå°†å¸®åŠ©æˆ‘ä»¬å…‹æœè¿™ä¸ªç©ºé—´å›ºæœ‰çš„å¤æ‚æ€§ã€‚
- en: The other reason I wasnâ€™t convinced about this space is that I read that it
    was mostly fit for hierarchical data that can be described by trees. At a first
    glance, it doesnâ€™t involve the data I work with on a daily basis.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹æ‰€ä»¥å¯¹è¿™ä¸ªç©ºé—´ä¸å¤ªä¿¡æœçš„å¦ä¸€ä¸ªåŸå› æ˜¯ï¼Œæˆ‘è¯»åˆ°å®ƒä¸»è¦é€‚ç”¨äºå¯ä»¥ç”¨æ ‘æè¿°çš„å±‚æ¬¡æ•°æ®ã€‚ä¹ä¸€çœ‹ï¼Œè¿™ä¼¼ä¹ä¸æˆ‘æ¯å¤©å¤„ç†çš„æ•°æ®æ— å…³ã€‚
- en: 'However, the abstracts below give us an idea of relevant datasets of interest:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¸‹é¢çš„æ‘˜è¦ç»™äº†æˆ‘ä»¬ä¸€äº›ç›¸å…³æ•°æ®é›†çš„æ¦‚å¿µï¼š
- en: â€œHowever, **recent work has shown that the appropriate isometric space for embedding
    complex networks is not the flat Euclidean space**, **but negatively curved, hyperbolic
    space**. We present a new concept that exploits these recent insights and propose
    learning neural embeddings of graphs in hyperbolic space. We provide experimental
    evidence that embedding graphs in their natural geometry signicantly improves
    performance on downstream tasks for several **real-world public datasets**.â€ [Chamberlain
    et al.](https://arxiv.org/pdf/1705.10359.pdf)
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œç„¶è€Œï¼Œ**æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼ŒåµŒå…¥å¤æ‚ç½‘ç»œçš„é€‚å½“ç­‰è·ç©ºé—´ä¸æ˜¯å¹³å¦çš„æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼Œè€Œæ˜¯è´Ÿæ›²ç‡çš„åŒæ›²ç©ºé—´**ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°æ¦‚å¿µï¼Œåˆ©ç”¨è¿™äº›æœ€æ–°çš„è§è§£ï¼Œå»ºè®®åœ¨åŒæ›²ç©ºé—´ä¸­å­¦ä¹ å›¾çš„ç¥ç»åµŒå…¥ã€‚æˆ‘ä»¬æä¾›äº†å®éªŒè¯æ®ï¼Œè¡¨æ˜åœ¨å…¶è‡ªç„¶å‡ ä½•ä¸­åµŒå…¥å›¾æ˜¾è‘—æ”¹å–„äº†åœ¨å¤šä¸ª**çœŸå®ä¸–ç•Œå…¬å…±æ•°æ®é›†**ä¸Šçš„ä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ã€‚â€
    [Chamberlain ç­‰](https://arxiv.org/pdf/1705.10359.pdf)
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: â€œHowever, while **complex symbolic datasets often exhibit a latent hierarchical
    structure, state-of-the-art methods typically learn embeddings in Euclidean vector
    spaces, which do not account for this property**. For this purpose, we introduce
    a new approach for learning hierarchical representations of symbolic data by **embedding
    them into hyperbolic space** â€” or more precisely into an n-dimensional PoincarÃ©
    ball.â€ [Nickel and Kiela](https://arxiv.org/pdf/1705.08039.pdf)
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œç„¶è€Œï¼Œè™½ç„¶**å¤æ‚çš„ç¬¦å·æ•°æ®é›†é€šå¸¸è¡¨ç°å‡ºæ½œåœ¨çš„å±‚çº§ç»“æ„ï¼Œæœ€å…ˆè¿›çš„æ–¹æ³•é€šå¸¸åœ¨æ¬§å‡ é‡Œå¾—å‘é‡ç©ºé—´ä¸­å­¦ä¹ åµŒå…¥ï¼Œè€Œè¿™å¹¶æœªè€ƒè™‘åˆ°è¿™ä¸€ç‰¹æ€§**ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡**å°†å…¶åµŒå…¥åŒæ›²ç©ºé—´**â€”â€”æˆ–æ›´å‡†ç¡®åœ°è¯´ï¼ŒåµŒå…¥åˆ°nç»´åºåŠ è±çƒä½“ä¸­â€”â€”æ¥å­¦ä¹ ç¬¦å·æ•°æ®çš„å±‚çº§è¡¨ç¤ºã€‚â€
    [Nickel å’Œ Kiela](https://arxiv.org/pdf/1705.08039.pdf)
- en: 'The datasets mentioned above are listed as follows, by [Chamberlain et al.](https://arxiv.org/pdf/1705.10359.pdf)
    :'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°æ•°æ®é›†åˆ—ä¸¾å¦‚ä¸‹ï¼Œç”±[Chamberlain ç­‰](https://arxiv.org/pdf/1705.10359.pdf)æä¾›ï¼š
- en: '(1) Karate: Zacharyâ€™s karate club contains 34 vertices divided into two factions.
    [4]'
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '(1) Karate: æ‰å¡é‡Œï¼ˆZacharyï¼‰çš„ç©ºæ‰‹é“ä¿±ä¹éƒ¨åŒ…å«34ä¸ªé¡¶ç‚¹ï¼Œåˆ†ä¸ºä¸¤ä¸ªæ´¾ç³»ã€‚[4]'
- en: ''
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '(2) Polbooks: A network of books about US politics published around the time
    of the 2004 presidential election and sold by the online bookseller Amazon.com.
    Edges between books represent frequent co-purchasing of books by the same buyers.'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '(2) Polbooks: å…³äºç¾å›½æ”¿æ²»çš„ä¹¦ç±ç½‘ç»œï¼Œè¿™äº›ä¹¦ç±æ˜¯åœ¨2004å¹´æ€»ç»Ÿé€‰ä¸¾å‰åå‡ºç‰ˆï¼Œå¹¶ç”±åœ¨çº¿ä¹¦å•†Amazon.comå‡ºå”®ã€‚ä¹¦ç±ä¹‹é—´çš„è¾¹è¡¨ç¤ºç›¸åŒä¹°å®¶çš„é¢‘ç¹å…±åŒè´­ä¹°ã€‚'
- en: ''
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '(3) Football: A network of American football games between Division IA colleges
    during regular season Fall 2000\. [2]'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '(3) Football: 2000å¹´ç§‹å­£å¸¸è§„èµ›æœŸé—´ï¼ŒDivision IAå¤§å­¦ä¹‹é—´çš„ç¾å›½æ©„æ¦„çƒæ¯”èµ›ç½‘ç»œã€‚[2]'
- en: ''
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '(4) Adjnoun: Adjacency network of common adjectives and nouns in the novel
    David Coppereld by Charles Dickens. [3]'
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '(4) Adjnoun: æŸ¥å°”æ–¯Â·ç‹„æ›´æ–¯ï¼ˆCharles Dickensï¼‰å°è¯´ã€Šå¤§å«Â·ç§‘æ³¢è²å°”ï¼ˆDavid Copperfieldï¼‰ã€‹ä¸­å¸¸è§å½¢å®¹è¯å’Œåè¯çš„é‚»æ¥ç½‘ç»œã€‚[3]'
- en: ''
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '(5) Polblogs: A network of hyperlinks between weblogs on US politics, recorded
    in 2005\. [1]'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '(5) Polblogs: è®°å½•äº2005å¹´çš„ç¾å›½æ”¿æ²»åšå®¢ä¹‹é—´çš„è¶…é“¾æ¥ç½‘ç»œã€‚[1]'
- en: 'Additionally, in biology, we find this reference dataset:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œåœ¨ç”Ÿç‰©å­¦ä¸­ï¼Œæˆ‘ä»¬æ‰¾åˆ°ä»¥ä¸‹å‚è€ƒæ•°æ®é›†ï¼š
- en: '*Biology: Evolutionary data like proteins.* [5]'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç”Ÿç‰©å­¦ï¼šè¯¸å¦‚è›‹ç™½è´¨ç­‰è¿›åŒ–æ•°æ®ã€‚*[5]'
- en: '![](../Images/2af3a2d5ffcf1f54c748242329d868cc.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2af3a2d5ffcf1f54c748242329d868cc.png)'
- en: '**Resource**: A network representation of social relationships among the 34
    individuals in the karate club studied by Zachary. The population is divided into
    two fractions based on an event [4]. Adapted from [Wikipedia](https://en.wikipedia.org/wiki/Zachary%27s_karate_club).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**èµ„æº**ï¼šæ‰å¡é‡Œçš„ç©ºæ‰‹é“ä¿±ä¹éƒ¨ä¸­34ä¸ªäººçš„ç¤¾ä¼šå…³ç³»ç½‘ç»œè¡¨ç¤ºã€‚æ ¹æ®äº‹ä»¶[4]ï¼Œè¯¥äººç¾¤è¢«åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ã€‚æ”¹ç¼–è‡ª[ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)ã€‚'
- en: Finally, NLP data, i.e. textual data, is another type of hierarchical data.
    As a result, a lot of domains may benefit from understanding the advancements
    in non-Euclidean Machine Learning.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼ŒNLPæ•°æ®ï¼Œå³æ–‡æœ¬æ•°æ®ï¼Œæ˜¯å¦ä¸€ç§ç±»å‹çš„å±‚çº§æ•°æ®ã€‚å› æ­¤ï¼Œè®¸å¤šé¢†åŸŸå¯èƒ½ä»ç†è§£éæ¬§å‡ é‡Œå¾—æœºå™¨å­¦ä¹ çš„è¿›å±•ä¸­å—ç›Šã€‚
- en: Now that we know how to better represent certain datasets, it is key to tie
    it back to Machine Learning. Any downstream ML tasks require ingesting data first.
    A lot of time is spent in cleaning our underlying data and representing it accurately.
    The quality of the data representation is essential as it directly impacts the
    performance of our models. For example, in NLP, I advise my students to focus
    on architectures that provide good embeddings, e.g. contextual embeddings. There
    has been extensive research in improving embeddings, moving from shallow neural
    networks (*fasttext, word2vec*) to deep neural networks and transformers *(sentence-transformers,
    BERT, RoBERTa, XLM)*. However, it is also worth noting that data representation
    is very much linked to the task at hand, and research shows that certain shallow
    neural networks provide better results than deep neural networks, for certain
    tasks.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çŸ¥é“å¦‚ä½•æ›´å¥½åœ°è¡¨ç¤ºæŸäº›æ•°æ®é›†ï¼Œå°†å…¶ä¸æœºå™¨å­¦ä¹ è”ç³»èµ·æ¥æ˜¯å…³é”®ã€‚ä»»ä½•ä¸‹æ¸¸æœºå™¨å­¦ä¹ ä»»åŠ¡éƒ½éœ€è¦é¦–å…ˆæ‘„å–æ•°æ®ã€‚å¤§é‡æ—¶é—´èŠ±åœ¨æ¸…ç†åŸºç¡€æ•°æ®å’Œå‡†ç¡®è¡¨ç¤ºæ•°æ®ä¸Šã€‚æ•°æ®è¡¨ç¤ºçš„è´¨é‡è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒç›´æ¥å½±å“æ¨¡å‹çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­ï¼Œæˆ‘å»ºè®®æˆ‘çš„å­¦ç”Ÿä¸“æ³¨äºæä¾›è‰¯å¥½åµŒå…¥çš„æ¶æ„ï¼Œä¾‹å¦‚ä¸Šä¸‹æ–‡åµŒå…¥ã€‚å…³äºæ”¹è¿›åµŒå…¥çš„ç ”ç©¶éå¸¸å¹¿æ³›ï¼Œä»æµ…å±‚ç¥ç»ç½‘ç»œï¼ˆ*fasttext,
    word2vec*ï¼‰åˆ°æ·±å±‚ç¥ç»ç½‘ç»œå’Œå˜æ¢å™¨ï¼ˆ*sentence-transformers, BERT, RoBERTa, XLM*ï¼‰ã€‚ç„¶è€Œï¼Œä¹Ÿå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ•°æ®è¡¨ç¤ºä¸æ‰‹å¤´çš„ä»»åŠ¡ç´§å¯†ç›¸å…³ï¼Œç ”ç©¶æ˜¾ç¤ºå¯¹äºæŸäº›ä»»åŠ¡ï¼ŒæŸäº›æµ…å±‚ç¥ç»ç½‘ç»œæ¯”æ·±å±‚ç¥ç»ç½‘ç»œæä¾›æ›´å¥½çš„ç»“æœã€‚
- en: Conclusion
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this article, we saw that we can leverage non-Euclidean geometry to tackle
    existing problems specific to spherical data and hierarchical datasets like graphs.
    When embedding such datasets into a Euclidean space, the price to pay is a distortion
    that does not permit preserving distances from the original space to the embedding
    space. Such distortion is intuitive in our earth representation where we have
    many ways to represent our globe, some of which do not preserve core properties
    expected such as **area preserving.** Similarly for graphs, core properties need
    to be preserved and distorting the underlying space may result in poorer performance
    for downstream Machine Learning tasks.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°å¯ä»¥åˆ©ç”¨éæ¬§å‡ é‡Œå¾—å‡ ä½•æ¥è§£å†³ç‰¹å®šäºçƒé¢æ•°æ®å’Œå±‚æ¬¡æ•°æ®é›†ï¼ˆå¦‚å›¾ï¼‰çš„ç°æœ‰é—®é¢˜ã€‚å°†è¿™äº›æ•°æ®é›†åµŒå…¥åˆ°æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ï¼Œä»£ä»·æ˜¯æ‰­æ›²ï¼Œè¿™ç§æ‰­æ›²æ— æ³•ä¿ç•™ä»åŸå§‹ç©ºé—´åˆ°åµŒå…¥ç©ºé—´çš„è·ç¦»ã€‚è¿™ç§æ‰­æ›²åœ¨æˆ‘ä»¬åœ°çƒçš„è¡¨ç¤ºä¸­å¾ˆç›´è§‚ï¼Œæˆ‘ä»¬æœ‰å¤šç§æ–¹å¼è¡¨ç¤ºæˆ‘ä»¬çš„åœ°çƒï¼Œå…¶ä¸­ä¸€äº›æ–¹å¼æ— æ³•ä¿ç•™æœŸæœ›çš„æ ¸å¿ƒå±æ€§ï¼Œä¾‹å¦‚**é¢ç§¯ä¿æŒ**ã€‚å¯¹äºå›¾æ¥è¯´ï¼Œæ ¸å¿ƒå±æ€§éœ€è¦è¢«ä¿ç•™ï¼Œæ‰­æ›²åŸºç¡€ç©ºé—´å¯èƒ½å¯¼è‡´ä¸‹æ¸¸æœºå™¨å­¦ä¹ ä»»åŠ¡çš„æ€§èƒ½è¾ƒå·®ã€‚
- en: In the next chapter, we will learn more about spherical and hyperbolic geometries.
    We will focus more on the latter and give intuition on how models in such space
    can better embed hierarchical data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ æ›´å¤šå…³äºçƒé¢å‡ ä½•å’ŒåŒæ›²å‡ ä½•çš„çŸ¥è¯†ã€‚æˆ‘ä»¬å°†æ›´å¤šå…³æ³¨åè€…ï¼Œå¹¶æä¾›å¦‚ä½•åœ¨è¿™æ ·çš„ç©ºé—´ä¸­æ›´å¥½åœ°åµŒå…¥å±‚æ¬¡æ•°æ®çš„ç›´è§‚ç†è§£ã€‚
- en: Connect with the contributors.
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸è´¡çŒ®è€…è”ç³»ã€‚
- en: '![](../Images/3aeef9a3a6d5979f8293050b0b599f88.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3aeef9a3a6d5979f8293050b0b599f88.png)'
- en: ML Doctoral Researcher at KTH Royal Institute of Technology.
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KTHçš‡å®¶æŠ€æœ¯å­¦é™¢çš„æœºå™¨å­¦ä¹ åšå£«ç ”ç©¶å‘˜ã€‚
- en: '*Linkedin*. [https://www.linkedin.com/in/aniss-medbouhi/](https://www.linkedin.com/in/aniss-medbouhi/)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*Linkedin*. [https://www.linkedin.com/in/aniss-medbouhi/](https://www.linkedin.com/in/aniss-medbouhi/)'
- en: '![](../Images/dc4860e542b8410558a3768c6a07eaf3.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc4860e542b8410558a3768c6a07eaf3.png)'
- en: Data Scientist at Microsoft and Teacher at EPITA Paris.
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¾®è½¯çš„æ•°æ®ç§‘å­¦å®¶å’ŒEPITAå·´é»çš„è®²å¸ˆã€‚
- en: '*Linkedin*. [https://www.linkedin.com/in/mastafa-foufa/](https://www.linkedin.com/in/mastafa-foufa/)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*Linkedin*. [https://www.linkedin.com/in/mastafa-foufa/](https://www.linkedin.com/in/mastafa-foufa/)'
- en: '[1] Lada A. Adamic and Natalie Glance. The political blogosphere and the 2004
    U.S. election. Proceedings of the 3rd international workshop on Link discovery
    â€” LinkKDD â€™05, pages 36â€“43, 2005.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Lada A. Adamic å’Œ Natalie Glance. æ”¿æ²»åšå®¢åœˆå’Œ2004å¹´ç¾å›½é€‰ä¸¾ã€‚ã€Šç¬¬ä¸‰å±Šå›½é™…é“¾æ¥å‘ç°ç ”è®¨ä¼šä¼šè®®å½•ã€‹â€”â€”LinkKDD
    â€™05, é¡µ36â€“43, 2005ã€‚'
- en: '[2] Michelle Girvan and Mark E. J. Newman. Community structure in social and
    biological networks. In Proceedings of the national academy of sciences, 99:7821â€“7826,
    2002.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Michelle Girvan å’Œ Mark E. J. Newman. ç¤¾ä¼šå’Œç”Ÿç‰©ç½‘ç»œä¸­çš„ç¤¾åŒºç»“æ„ã€‚åœ¨ã€Šå›½å®¶ç§‘å­¦é™¢å­¦æŠ¥ã€‹ä¼šè®®å½•ä¸­ï¼Œ99:7821â€“7826,
    2002ã€‚'
- en: '[3] Mark E. J. Newman. Finding community structure in networks using the eigenvectors
    of matrices. Physical Review E â€” Statistical, Nonlinear, and Soft Matter Physics,
    74(3):1â€“19, 2006.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Mark E. J. Newman. ä½¿ç”¨çŸ©é˜µç‰¹å¾å‘é‡å‘ç°ç½‘ç»œä¸­çš„ç¤¾åŒºç»“æ„ã€‚ã€Šç‰©ç†è¯„è®ºEã€‹â€”â€”ç»Ÿè®¡å­¦ã€éçº¿æ€§å’Œè½¯ç‰©è´¨ç‰©ç†ï¼Œ74(3):1â€“19,
    2006ã€‚'
- en: '[4] Wayne W. Zachary. An information ow model for conict and ssion in small
    groups. Journal of anthropological research, 33:452â€“473, 1977.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Wayne W. Zachary. å°ç»„ä¸­çš„å†²çªå’Œåˆ†è£‚çš„ä¿¡æ¯æµæ¨¡å‹ã€‚ã€Šäººç±»å­¦ç ”ç©¶æ‚å¿—ã€‹ï¼Œ33:452â€“473, 1977ã€‚'
- en: '[5] AlQuraishi, Mohammed. â€œProteinNet: a standardized data set for machine
    learning of protein structure.â€ BMC bioinformatics 20.1 (2019): 1â€“10.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] AlQuraishi, Mohammed. â€œProteinNet: ä¸€ä¸ªæ ‡å‡†åŒ–çš„è›‹ç™½è´¨ç»“æ„æœºå™¨å­¦ä¹ æ•°æ®é›†ã€‚â€ BMC ç”Ÿç‰©ä¿¡æ¯å­¦ 20.1
    (2019): 1â€“10.'
