["```py\nimport requests\nimport json\nimport pandas as pd\n\nurl = 'https://search.worldbank.org/api/v2/wds'\nparams = {\n    'format': 'json',\n    'display_title': '\"sustainable development\"',\n    'rows': 20,\n    'page': 1\n}\n\nmetadata_list = []\n\nfor i in range(1):\n    response = requests.get(url, params=params)\n    data = json.loads(response.content)\n    for doc_id in data['documents']:\n        metadata = data['documents'][doc_id]\n        metadata_list.append(metadata)\n\n    params['page'] += 1\n\ndf = pd.DataFrame(metadata_list)\n```", "```py\nfrom rdflib import Graph, RDF, RDFS, Namespace, URIRef, Literal\nfrom rdflib.namespace import SKOS, XSD\nfrom SPARQLWrapper import SPARQLWrapper, JSON\nfrom tqdm import tqdm\n\n# Create a new RDF graph\ng = Graph()\n\nschema = Namespace('http://schema.org/')\nwd = Namespace('http://www.wikidata.org/entity/')\n\n# Define namespaces\nprefixes = {\n    'schema': schema,\n    'wd': wd,\n    'skos': SKOS,\n    'xsd': XSD\n}\nfor p, ns in prefixes.items():\n    g.bind(p, ns)\n```", "```py\ndef create_subclass_country(column):\n    newClass = URIRef(schema + \"country\")\n    g.add((newClass, RDFS.label, Literal(\"country\", lang='en')))\n    df[column] = df[column].astype(str)\n    for value in df[column].unique():\n        if value != \"nan\":\n            # Check Wikidata for a matching class\n            sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n            query = f\"\"\"\n                SELECT ?class ?label WHERE {{\n                    ?class wdt:P31 wd:Q6256 .\n                    ?class rdfs:label \"{value}\"@en .\n                    OPTIONAL {{ ?class skos:prefLabel ?label FILTER(lang(?label) = \"en\") }}\n                    FILTER(REGEX(STR(?class), \"^http://www.wikidata.org/entity/Q[0-9]+$\"))\n                }}\n            \"\"\"\n            sparql.setQuery(query)\n            sparql.setReturnFormat(JSON)\n            results = sparql.query().convert()\n\n            # If there is a match, use the Wikidata class as a subclass\n            if results['results']['bindings']:\n\n                #Get URI from Wikidata\n                uri = results['results']['bindings'][0]['class']['value']\n\n                #Get the 'Q ID' which is the unique ID at the end of the URI\n                qid = uri.split('/')[-1]\n                country_label = value\n\n                #Create a subclass for each country under the country class\n                subclass = URIRef(schema + country_label.replace(' ', '_'))\n                g.add((subclass, RDF.type, RDFS.Class))\n                g.add((subclass, RDFS.subClassOf, newClass))\n\n                # Update the \"country_URI\" column with the URI for the current country\n                df.loc[df[column] == value, \"country_URI\"] = uri\n                uri = URIRef(uri)\n\n                # Define the URI for the new Wikidata URI property\n                wd_URI_property = URIRef(schema + \"wd_URI\")\n\n                # Add the property to the RDF graph\n                g.add((wd_URI_property, RDF.type, RDF.Property))\n\n                # Add a label to the property\n                label = Literal(\"Wikidata URI\", lang=\"en\")\n                g.add((wd_URI_property, RDFS.label, label))\n\n                #Add Wikidata URI as a property to each country class\n                g.add((subclass, schema.wd_URI, uri))\n\n                #Add label to each Wikidata Q ID code that it is the Q ID for this particular country\n                g.add((uri, RDFS.label, Literal(f\"{country_label} wikidata code\", lang='en')))\n                g.add((subclass, RDFS.label, Literal(value, lang='en')))\n            else:    \n                subclass = URIRef(schema + value.replace(' ', '_').replace('-','_'))\n                g.add((subclass, RDF.type, RDFS.Class))\n                g.add((subclass, RDFS.subClassOf, newClass))\n                g.add((subclass, RDFS.label, Literal(value, lang='en')))\n```", "```py\n#Save graph as ttl file for use in protégé\ng.serialize('worldBankKG.ttl',format='turtle',prefixes = prefixes, encoding='urf-8')\n```", "```py\n#Create abstract property\ndf['abstracts'] = df['abstracts'].astype(str).str.replace('\\n', '').replace('\\\\n','')\nabstractIs_uri = URIRef(schema + \"abstractIs\")\ng.add((abstractIs_uri, RDF.type, RDF.Property))\ng.add((abstractIs_uri, RDFS.label, Literal(\"Short summary of the document.\")))\n\n#Create abstract class\nabstract_class = URIRef(schema + \"abstract\")\ng.add((abstract_class, RDFS.label, Literal(\"Short summary of a document.\")))\n\n#Create author properties\nauthoredBy_uri = URIRef(schema + \"authoredBy\")\nauthored_uri = URIRef(schema + \"authored\")\ng.add((authoredBy_uri, RDF.type, RDF.Property))\ng.add((authored_uri, RDF.type, RDF.Property))\ng.add((authoredBy_uri, RDFS.label, Literal(\"This document was authored by this author.\")))\ng.add((authored_uri, RDFS.label, Literal(\"This author wrote this document.\")))\n\n#Define 'part of' property\nisPartOf_uri = URIRef(schema + \"isPartOf\")\ng.add((isPartOf_uri, RDF.type, RDF.Property))\ng.add((isPartOf_uri, RDFS.label, Literal(\"This entity is a part of another entity\")))\n\n#Define 'countryOfOrigin' property\ncountryOfOrigin_uri = URIRef(schema + \"countryOfOrigin\")\ng.add((countryOfOrigin_uri, RDF.type, RDF.Property))\ng.add((countryOfOrigin_uri, RDFS.label, Literal(\"Country that this document is about.\")))\n\n# Create instances for each document and add author property\nfor index, row in tqdm(df.iterrows()):\n    if not pd.isnull(row['id']) and not pd.isnull(row['docty']) and not pd.isnull(row['authors']):\n        try:\n            # Create the report instance\n            instance = URIRef(schema + \"doc/\" + str(row['display_title']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n            g.add((instance, RDFS.label, Literal(str(row['display_title']), lang='en')))\n\n            #Connect instances with types of documents\n            doctype = URIRef(row['docty'])\n            g.add((instance, RDF.type, doctype))\n\n            #Connect instances with country of origin\n            if row['count'] != \"nan\":\n                country = URIRef(schema + str(row['count']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n                g.add((instance, countryOfOrigin_uri, country))\n\n            #Connect instances with projects\n            if row['projn'] != \"nan\":\n                project = URIRef(schema + \"project/\" + str(row['projn']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n                g.add((instance, isPartOf_uri, project))\n\n            #Connect instances with trustfund_keys\n            if row['trustfund'] != \"nan\":\n                tf_values = row['trustfund'].split(\",\")\n                for tf in tf_values:\n                    trustfund_uri = URIRef(schema + \"trustfund/\" + str(tf).replace(\" \",\"_\").replace(\"-\",\"_\"))\n                    g.add((trustfund_uri, RDFS.label, Literal(f\"Trustfund: {tf}\")))\n                    g.add((instance, isPartOf_uri, trustfund_uri))\n                    g.add((trustfund_uri, countryOfOrigin_uri, country))\n\n            #Connect instances with authors\n            author_dict = ast.literal_eval(row['authors'])\n            for author_dict_entries in author_dict.values():\n                author_name = author_dict_entries['author']\n                author_uri = URIRef(schema + \"author/\" + author_name.replace(\" \", \"_\"))\n                g.add((instance, authoredBy_uri, author_uri))\n                g.add((author_uri, authored_uri, instance))\n\n            #Add abstract\n            if row['abstracts'] != \"nan\":\n                abstract_uri = URIRef(schema + \"abstract/\" + str(row['display_title']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n                g.add((instance, abstractIs_uri, abstract_uri))\n                g.add((abstract_uri, RDFS.label, Literal(str(row['abstracts']))))\n                g.add((abstract_uri, RDF.type, abstract_class))\n                g.add((abstract_uri, isPartOf_uri, abstract_uri))\n        except:\n            pass\n```", "```py\nimport numpy as np\n\nsparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n\n# Create a cache to store property code-label mappings\nproperty_cache = {}\nentity_cache = {}\n\n# Prepare a list to collect triples for bulk graph update\ntriples = []\n\n# Iterate over the URIs and add the properties to the RDF graph\nfor uri in tqdm(df['country_URI']):        \n    if isinstance(uri, str) and uri.startswith('http://www.wikidata.org/entity/Q'):\n        class_uri = URIRef(uri)\n        country_column = df.loc[df['country_URI'] == uri, 'count'].iloc[0]\n        country_column = URIRef(schema + str(country_column).replace(\" \", \"_\"))\n\n        # Construct the SPARQL query\n        qid = uri.split('/')[-1]\n        query = f\"\"\"\n        SELECT ?prop ?value WHERE {{\n          wd:{qid} ?prop ?value .\n          OPTIONAL {{ ?prop rdfs:label ?label . FILTER(lang(?label) = 'en') }}\n        }}\n        \"\"\"\n\n        # Set the query and response format\n        sparql.setQuery(query)\n        sparql.setReturnFormat(JSON)\n\n        # Execute the query and retrieve the results\n        results = sparql.query().convert()\n\n        # Iterate over the results and add them to the RDF graph\n        for result in results[\"results\"][\"bindings\"]:\n            prop = result[\"prop\"][\"value\"]\n            value = Literal(result[\"value\"][\"value\"])\n            triple = (country_column, None, None)  # Placeholder for triple\n\n            if prop.startswith('http://www.wikidata.org/prop'):\n                property_code = prop.split('/')[-1]\n                # Check if the property code is already in the cache\n                if property_code in property_cache:\n                    property_label = property_cache[property_code]\n                else:\n                    # If not in cache, query and retrieve the property label\n                    property_label = get_property_label(property_code)\n                    # Store the property code-label mapping in the cache\n                    property_cache[property_code] = property_label\n\n                property_label_URI = URIRef(schema + property_label.replace(\" \", \"_\"))\n                triple = (country_column, property_label_URI, value)\n\n            if value.startswith('http://www.wikidata.org/entity/Q'):\n                entity_code = value.split('/')[-1]\n                # Check if the entity code is already in the cache\n                if entity_code in entity_cache:\n                    entity_label = entity_cache[entity_code]\n                else:\n                    # If not in cache, query and retrieve the entity label\n                    entity_label = get_entity_label(entity_code)\n                    # Store the entity code-label mapping in the cache\n                    entity_cache[entity_code] = entity_label\n\n                entity_label_URI = URIRef(schema + str(entity_label).replace(\" \", \"_\"))\n                triple = (country_column, property_label_URI, entity_label_URI)\n\n            triples.append(triple)\n\n    elif isinstance(uri, float) and np.isnan(uri):\n        continue\n    else:\n        continue\n\n# Add all collected triples to the RDF graph in bulk\nfor subject, predicate, object_ in triples:\n    if predicate is not None:\n        g.add((subject, predicate, object_)) \n```", "```py\n# Step 1: Find the URI of Brazil in your ontology\nbrazil_uri = \"<http://schema.org/Brazil>\"  # Replace with the actual URI\n\n# Step 2: Find the most relevant documents related to Brazil\ndocuments_query = f\"\"\"\nPREFIX schema: <http://schema.org/>\nSELECT ?document\nWHERE {{\n  ?document a/rdfs:subClassOf* schema:world_bank_document ;\n      schema:countryOfOrigin {brazil_uri} .\n\n}}\n\"\"\"\nqres = g.query(documents_query)\nfor row in qres:\n    print(f\"Document ID: {row.document}\")\n```", "```py\nfrom rdflib import Graph, RDF, RDFS, URIRef\n\n# Step 1: Find the URI of the basic_form_of_government you are interested in\ngovernment_form_uri = \"<http://schema.org/federal_republic>\"  # Replace with the actual URI\n\n# Step 2: Query for authors who have written the most documents associated with countries having the basic_form_of_government as \"federal_republic\"\nauthors_query = f\"\"\"\nPREFIX schema: <http://schema.org/>\nPREFIX prop: <http://schema.org/property>\nSELECT ?author (COUNT(?document) AS ?numDocuments)\nWHERE {{\n  ?document a/rdfs:subClassOf* schema:world_bank_document ;\n            schema:countryOfOrigin [\n                    schema:basic_form_of_government {government_form_uri}\n            ] ;\n            schema:authoredBy ?author .\n}}\nGROUP BY ?author\nORDER BY DESC(?numDocuments)\n\"\"\"\n\n# Execute the query\nresults = g.query(authors_query)\n\n# Now you can process the results and present them as needed (e.g., using pandas DataFrames)\n# For simplicity, here, I'm just printing the author names and the number of documents they wrote\nfor row in results:\n    print(f\"Author: {row.author}, Number of Documents: {row.numDocuments}\")\n```", "```py\nfrom llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, ServiceContext, LLMPredictor\nfrom langchain import OpenAI\nimport os \nimport openai\n\nos.environ[\"OPENAI_API_KEY\"] = <YOUR API KEY>  # replace with yours\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\ndocuments = SimpleDirectoryReader('data').load_data()\n\nquery_engine = index.as_query_engine()\n```", "```py\nresponse = query_engine.query(\"Show me all of the World Bank documents in the context information about Brazil\")\nprint(response)\n```", "```py\nresponse = query_engine.query(\"Based on the context information, what documents has Corsi,Anna written?\")\nprint(response)\n```", "```py\nresponse = query_engine.query(\"Tell me more about Anna Corsi\")\nprint(response)\n```", "```py\nfrom llama_index import GPTVectorStoreIndex, download_loader\n\nRDFReader = download_loader(\"RDFReader\")\ndocument = RDFReader().load_data(file=\"path to your file\")\n\n# Define LLM\nllm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-002\"))\n\n# NOTE: set a chunk size limit to < 1024 tokens \nservice_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=1012)\n\nindex = GPTVectorStoreIndex.from_documents(document, service_context=service_context)\n```", "```py\n<Brazil - LATIN AMERICA AND CARIBBEAN - P107146 - Acre Social and Economic Inclusion and Sustainable Development Project - PROACRE - Audited Financial Statement>\n<Disclosable Version of the ISR - Rio de Janeiro Adjustment and Sustainable Development Policy Loan - P178729 - Sequence No : 01>\n<Grosso Fiscal Adjustment and Environmental Sustainability Development Policy Loan>\n<Disclosable Version of the ISR - Matanza-Riachuelo Basin Sustainable Development Project - P105680 - Sequence No : 29>\n<Disclosable Version of the ISR - Matanza-Riachuelo Basin Sustainable Development Project - P105680 - Sequence No : 30>\n<Disclosable Restructuring Paper - Health Sustainable Development Goals Program-for-Results - P123531>\n```", "```py\nresponse = query_engine.query(\"Based on the context information, what documents has Corsi,Anna written?\")\nprint(response)\n```", "```py\nConcept Project Information Document (PID) - Land administration infrastructure for green and sustainable development - P179217\n```", "```py\nresponse = query_engine.query(\"Tell me more about Anna Corsi\")\nprint(response)\n```", "```py\nresponse = query_engine.query(\"Tell me more about World Bank's land management infrastructure project in Turkey\")\nprint(response)\n```"]