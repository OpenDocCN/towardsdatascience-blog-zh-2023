- en: Orchestrating Efficient Reasoning Over Knowledge Graphs with LLM Compiler Frameworks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLM编译器框架有效协调知识图谱的推理
- en: 原文：[https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9](https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9](https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9)
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[![安东尼·阿尔卡拉兹](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    [安东尼·阿尔卡拉兹](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    ·6 min read·Dec 29, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    ·6分钟阅读·2023年12月29日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件被用来增强本文文本的语法、流畅性和可读性。*'
- en: Recent innovations in large language model (LLM) design have led to rapid advancements
    in few-shot learning and reasoning capabilities. However, despite their progress,
    LLMs still face limitations when dealing with complex real-world contexts involving
    massive amounts of interconnected knowledge.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLM）设计中的创新推动了少样本学习和推理能力的快速进步。然而，尽管取得了进展，LLM在处理涉及大量相互关联知识的复杂现实世界情境时仍面临限制。
- en: To address this challenge, a promising approach has emerged in *retrieval augmented
    generation* (RAG) systems. RAG combines the adaptive learning strengths of LLMs
    with scalable retrieval from external knowledge sources like knowledge graphs
    (KGs). Rather than attempting to encode all information within the model statically,
    RAG allows querying necessary context from indexed knowledge graphs on the fly
    as needed.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这一挑战，一种有前景的方法在*检索增强生成*（RAG）系统中出现。RAG结合了LLM的自适应学习优势与从外部知识源（如知识图谱（KGs））中进行可扩展检索的能力。与其试图将所有信息静态编码在模型中，RAG允许根据需要从索引知识图谱中动态查询所需的上下文。
- en: However, effectively orchestrating reasoning and retrieval across interconnected
    knowledge sources brings its own challenges. Naive approaches that simply retrieve
    and concatenate information in discrete steps often fail to fully capture the
    nuances within dense knowledge graphs. The interconnected nature of concepts means
    that vital contextual details can be missed if not analyzed in relation to one
    another.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有效地协调跨互联知识源的推理和检索带来了自身的挑战。那些简单地在离散步骤中检索和拼接信息的天真方法，往往无法充分捕捉密集知识图谱中的细微差别。概念的相互关联性意味着，如果没有相互关系的分析，关键的上下文细节可能会被遗漏。
- en: Recently, an intriguing framework named LLM Compiler has demonstrated early
    successes in optimizing orchestration of multiple function calls in LLMs by automatically
    handling dependencies and allowing parallel execution.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一个名为LLM Compiler的有趣框架在优化LLM中多个函数调用的协调方面展示了早期成功，自动处理依赖关系并允许并行执行。
- en: '[](https://arxiv.org/abs/2312.04511?source=post_page-----749d36dc32b9--------------------------------)
    [## An LLM Compiler for Parallel Function Calling'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arxiv.org/abs/2312.04511?source=post_page-----749d36dc32b9--------------------------------)
    [## 一个用于并行函数调用的LLM编译器'
- en: Large Language Models (LLMs) have shown remarkable results on various complex
    reasoning benchmarks. The reasoning…
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）在各种复杂推理基准上表现出了显著的成果。推理...
- en: arxiv.org](https://arxiv.org/abs/2312.04511?source=post_page-----749d36dc32b9--------------------------------)
    [](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb?source=post_page-----749d36dc32b9--------------------------------)
    [## llama-hub/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb at
    main ·…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: arxiv.org](https://arxiv.org/abs/2312.04511?source=post_page-----749d36dc32b9--------------------------------)
    [](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb?source=post_page-----749d36dc32b9--------------------------------)
    [## llama-hub/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb at
    main ·…
- en: A library of data loaders for LLMs made by the community -- to be used with
    LlamaIndex and/or LangChain …
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个由社区创建的用于大语言模型的数据加载器库——可与 LlamaIndex 和/或 LangChain 一起使用…
- en: github.com](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb?source=post_page-----749d36dc32b9--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb?source=post_page-----749d36dc32b9--------------------------------)
- en: 'In this article, we explore the potential of applying LLM Compiler techniques
    more broadly to knowledge graph retrieval and reasoning. We already did a working
    prototype before the paper released :'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们探讨了将大语言模型编译器技术更广泛地应用于知识图谱检索和推理的潜力。在论文发布之前，我们已经做了一个工作原型：
- en: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----749d36dc32b9--------------------------------)
    [## Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and…'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----749d36dc32b9--------------------------------)
    [## 实现混乱背景下的结构化推理：思路提示和…'
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with…
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）展示了令人印象深刻的少量学习能力，迅速适应新任务…
- en: towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----749d36dc32b9--------------------------------)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----749d36dc32b9--------------------------------)
- en: We analyze how its techniques like automated planning, dependency management,
    and parallelized execution can enable more efficient and structured analysis of
    interconnected knowledge.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析了诸如自动规划、依赖管理和并行执行等技术如何使对互联知识的分析更加高效和结构化。
- en: 'Plan :'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计划：
- en: 1\. Challenges of Reasoning Over Massive Knowledge Graphs
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 大规模知识图谱推理的挑战
- en: 2\. Knowledge Graphs as Modular LLM Tools
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 知识图谱作为模块化大语言模型工具
- en: 3\. Structured Reasoning Powered by LLM Compilers
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 由大语言模型编译器驱动的结构化推理
- en: 4\. An Operating System for Knowledge Assimilation
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 知识吸收的操作系统
- en: —
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: —
- en: 1\. Challenges of Reasoning Over Massive Knowledge Graphs
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 大规模知识图谱推理的挑战
- en: '[](https://github.com/tomasonjo/blogs/blob/master/llm/devops_rag.ipynb?source=post_page-----749d36dc32b9--------------------------------)
    [## blogs/llm/devops_rag.ipynb at master · tomasonjo/blogs'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/tomasonjo/blogs/blob/master/llm/devops_rag.ipynb?source=post_page-----749d36dc32b9--------------------------------)
    [## blogs/llm/devops_rag.ipynb at master · tomasonjo/blogs'
- en: Jupyter notebooks that support my graph data science blog posts at https://bratanic-tomaz.medium.com/
    …
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持我图数据科学博客文章的 Jupyter 笔记本，网址为 https://bratanic-tomaz.medium.com/ …
- en: github.com](https://github.com/tomasonjo/blogs/blob/master/llm/devops_rag.ipynb?source=post_page-----749d36dc32b9--------------------------------)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/tomasonjo/blogs/blob/master/llm/devops_rag.ipynb?source=post_page-----749d36dc32b9--------------------------------)
- en: 'When addressing the challenges of reasoning over massive knowledge graphs,
    it is essential to integrate advanced techniques and methods for optimizing data
    retrieval and processing. This involves leveraging various computational strategies
    to balance efficiency, accuracy, and completeness in the analysis of large interconnected
    datasets. The following sections detail these approaches:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决大规模知识图谱推理的挑战时，必须整合先进的技术和方法来优化数据检索和处理。这涉及利用各种计算策略来平衡分析大规模互联数据集中的效率、准确性和完整性。以下部分详细介绍了这些方法：
- en: a. Optimizing Cypher Queries for Mathematical Operations
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: a. 优化 Cypher 查询以进行数学运算
- en: '**Objective:** Enhance the performance of Cypher queries, particularly for
    mathematical aggregations over graph data.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标：** 提高 Cypher 查询的性能，特别是针对图数据的数学聚合。'
- en: '**Methodology:**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法论：**'
- en: '**- Identify Opportunities:** Recognize scenarios where mathematical aggregations
    can be efficiently applied to graph data.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**- 识别机会：** 识别可以高效应用数学聚合的图数据场景。'
- en: '**- Modular Steps:** Break down the process into parallel retrieval of groups,
    concurrent execution of aggregation functions, and efficient joins.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**- 模块化步骤：** 将过程分解为并行检索组、并发执行聚合函数和高效连接。'
- en: '**- Example Application:** Calculating the number of high-priority tasks assigned
    to Team A. This involves retrieving task nodes, filtering by priority and team,
    and aggregating the count.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**- 示例应用：** 计算分配给 A 队的高优先级任务数量。这涉及到检索任务节点、按优先级和团队进行筛选，并汇总计数。'
- en: b. Planning Parallel Vector Searches
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: b. 规划并行向量搜索
- en: '**Objective:** Implement parallel vector searches to efficiently navigate through
    graph-based data.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标：** 实现并行向量搜索，以高效导航图基数据。'
- en: '**Methodology:**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法论：**'
- en: '- Analyze Questions for Seed Entities: Dissect queries to determine key entities
    that serve as starting points for vector searches.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '- 分析种子实体问题：剖析查询以确定作为向量搜索起点的关键实体。'
- en: '- Explore Concurrent Vector Spaces: Initiate searches from different seed entities,
    exploring the graph concurrently.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '- 探索并发向量空间：从不同的种子实体启动搜索，同时探索图。'
- en: '- Continual Node Retrieval: Dynamically retrieve nodes based on vector similarity,
    expanding the search in a targeted manner.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '- 持续节点检索：基于向量相似性动态检索节点，扩展有针对性的搜索。'
- en: '- Example Application: Identifying services with descriptions similar to ‘PaymentService’
    by exploring vector spaces rooted at different entities.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '- 示例应用：通过探索以不同实体为根的向量空间来识别描述类似于‘PaymentService’的服务。'
- en: c. Coordinating Usage of Graph Algorithms
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: c. 协调图算法的使用
- en: '**Objective:** Select and apply the most appropriate graph algorithms for specific
    queries.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标：** 选择并应用最合适的图算法以处理特定查询。'
- en: '**Methodology:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法论：**'
- en: '- Examine Questions for Algorithm Selection: Analyze the nature of the query
    to choose relevant algorithms (like traversal, community detection).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '- 检查算法选择问题：分析查询的性质，以选择相关算法（如遍历、社区检测）。'
- en: '- Modular Application: Apply algorithms in a modular fashion, each optimized
    for specific goals (e.g., efficiency, accuracy).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '- 模块化应用：以模块化的方式应用算法，每个算法针对特定目标进行优化（例如效率、准确性）。'
- en: '- Resolve Dependencies: Ensure coordination between algorithms, especially
    when the output of one is required for the execution of another.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '- 解决依赖关系：确保算法之间的协调，特别是在一个算法的输出需要用于另一个算法的执行时。'
- en: '- Example Application: Finding a tightly connected subgraph of interdependent
    services using community detection and traversal algorithms.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '- 示例应用：使用社区检测和遍历算法找到紧密连接的服务子图。'
- en: LLM Compiler Coordination
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 编译器协调
- en: An LLM Compiler could act as a central coordinator for these tasks. It would
    manage the execution of Cypher queries for mathematical operations, oversee the
    parallel vector searches, and orchestrate the application of various graph algorithms.
    The primary goal of the LLM Compiler in this context would be to ensure that the
    entire process of reasoning over the knowledge graph is not only efficient and
    accurate but also comprehensive. This requires a sophisticated understanding of
    the data structure, the ability to predict computational needs, and the capability
    to dynamically adjust strategies in response to real-time data analysis outcomes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 LLM 编译器可以作为这些任务的中央协调者。它将管理数学运算的 Cypher 查询的执行，监督并行向量搜索，并协调各种图算法的应用。LLM 编译器在此背景下的主要目标是确保知识图谱推理的整个过程不仅高效和准确，而且全面。这需要对数据结构有深入的理解，能够预测计算需求，并能根据实时数据分析结果动态调整策略。
- en: 2\. Knowledge Graphs as Modular LLM Tools
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 知识图谱作为模块化 LLM 工具
- en: 'The LLM Compiler system introduced by Kim et al. 2023 consists of 3 key components:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Kim 等人 2023 年提出的 LLM 编译器系统包括 3 个关键组件：
- en: '**LLM Planner:** Decomposes tasks and builds dependency graphs'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**LLM 规划器：** 分解任务并构建依赖图'
- en: '**Task Fetching Unit:** Dispatches tasks handling dependencies'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**任务提取单元：** 分派处理依赖的任务'
- en: '**Executor:** Runs tool functions in parallel'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**执行者：** 并行运行工具函数'
- en: Notably, LLM Compiler views tools as modular functions that can be executed
    concurrently when possible.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，LLM 编译器将工具视为可以并发执行的模块化函数（当可能时）。
- en: 'Building on this paradigm, an intriguing perspective is to view **knowledge
    graphs themselves as modular tools** that an LLM orchestrates:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一范式的基础上，一个引人入胜的观点是将**知识图谱本身视为模块化工具**，由 LLM 进行协调：
- en: '**Query Engines** over KGs become tools accessed by the LLM'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询引擎**通过知识图谱（KGs）成为 LLM 访问的工具'
- en: '**Graph Algorithms and Embeddings** provide tool-level customization'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图算法和嵌入**提供了工具级定制'
- en: '**LLM Planner** determines optimal multi-graph exploration strategies'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM 规划器**确定最佳的多图探索策略'
- en: With this framing, LLM Compiler’s automated planning and structured execution
    techniques seem highly promising for complex knowledge retrieval.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种框架，LLM 编译器的自动化规划和结构化执行技术对于复杂知识检索显得非常有前景。
- en: 3\. Structured Reasoning Powered by LLM Compilers
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 由 LLM 编译器驱动的结构化推理
- en: 'By specializing LLM Compiler techniques for integrating multiple tools and
    execution graphs, we can enhance several facets of knowledge graph reasoning:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通过专门化 LLM 编译器技术来整合多个工具和执行图，我们可以提升知识图谱推理的多个方面：
- en: a. Parallel Exploration
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: a. 并行探索
- en: Planning decomposition would allow concurrently querying diverse regions of
    a knowledge graph from multiple “entry points”. Multi-hop paths could be traversed
    in parallel, accelerating exploration.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 规划分解将允许从多个“入口点”同时查询知识图谱的不同区域。多跳路径可以并行遍历，加速探索。
- en: b. Modular Retrieval
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: b. 模块化检索
- en: Query engines over distinct sub-graphs with unique algorithms and embeddings
    essentially act as isolated tools. LLM Compiler excels at integrating disparate
    modular capabilities.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 针对独特子图的查询引擎使用独特的算法和嵌入，实际上充当了独立的工具。LLM 编译器在整合不同的模块能力方面表现出色。
- en: c. Dependency Management
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: c. 依赖管理
- en: Intermediate query results often inform subsequent searches. LLM Compiler’s
    automated handling of inter-tool dependencies enables seamless propagation of
    entities and relationships.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 中间查询结果通常会影响后续的搜索。LLM 编译器对工具间依赖关系的自动处理能够实现实体和关系的无缝传播。
- en: d. Recursive Re-Planning
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: d. 递归重新规划
- en: For complex questions, succeeding retrieval phases depend highly on previous
    phases. LLM Compiler allows recursive re-planning when updated contexts reveal
    new dependencies.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于复杂问题，后续的检索阶段高度依赖于之前的阶段。LLM 编译器允许在更新的上下文揭示新依赖时进行递归重新规划。
- en: e. Ontology-Aided Planning
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: e. 本体辅助规划
- en: Ontologies providing high-level schema around key entities can further assist
    the planner module. Meta-level knowledge guides more structured task decomposition
    aligned to domain concepts.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 提供关键实体高层次模式的本体可以进一步协助规划模块。元级知识指导更加结构化的任务分解，符合领域概念。
- en: e. Diverse Data Sources
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: e. 多样化数据源
- en: The planner can integrate additional data sources like SQL databases, imagery,
    and internet search engines as modular tools accessible to the LLM.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 规划器可以将额外的数据源，如 SQL 数据库、图像和互联网搜索引擎，整合为 LLM 可访问的模块化工具。
- en: By orchestrating knowledge retrieval modules under a structured planning framework
    powered by ontological knowledge, LLM Compilers could enable remarkably efficient
    and precise navigation of extensive information spaces.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在本体知识驱动的结构化规划框架下协调知识检索模块，LLM 编译器可以实现对广泛信息空间的显著高效和精准的导航。
- en: 4\. An Operating System for Knowledge Assimilation
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 知识吸收的操作系统
- en: Stepping back, we can envision LLM Compiler techniques giving rise to a new
    paradigm — LLMs as operating systems overseeing diverse knowledge functions. Much
    like an OS balancing threads and memory, LLMs could schedule retrieval, reasoning,
    and learning across knowledge stores. ML-based optimizers would automatically
    tune the routing and usage of various “tool” modules.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从宏观上看，我们可以设想 LLM 编译器技术会产生一个新范式——LLM 作为操作系统来监督各种知识功能。就像操作系统平衡线程和内存一样，LLM 可能会在知识存储中调度检索、推理和学习。基于
    ML 的优化器将自动调整各种“工具”模块的路由和使用。
- en: Within this ecosystem, the LLM Compiler would act as the key workflow orchestration
    framework interfacing between operating system and tools. It would handle all
    the underlying complexities of dependency resolution, concurrency optimization
    and resource allocation on behalf of the LLM OS.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个生态系统中，LLM 编译器将充当关键的工作流协调框架，接口连接操作系统和工具。它将处理 LLM 操作系统代表下的所有依赖解析、并发优化和资源分配的复杂性。
- en: LLM as Operating System
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 作为操作系统
- en: 'The LLM acts as the orchestrator overseeing and allocating resources between
    various modules:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 作为协调者，监督并在各个模块之间分配资源：
- en: Scheduling for optimal concurrency between retrieval, reasoning, and learning
    functions
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为检索、推理和学习功能之间的最佳并发安排计划
- en: Routing queries and decisions to the most apt components
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将查询和决策路由到最适合的组件
- en: Monitoring execution to dynamically optimize allocation
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控执行以动态优化分配
- en: Enabling modular expandability as new capabilities come online
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着新能力的上线，实现模块化扩展性
- en: LLM as Semantic Glue
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言模型作为语义粘合剂
- en: 'The LLM provides common semantic representations tying together disparate components:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型提供了将不同组件联系在一起的共同语义表示：
- en: Embedding queries, retrieved contexts, generated decisions into a shared vector
    space
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将查询、检索的上下文、生成的决策嵌入到共享向量空间
- en: Translating queries and directives between component interfaces
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在组件接口之间翻译查询和指令
- en: Propagating signals between modules by encoding inputs/outputs into transportable
    embeddings
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将输入/输出编码为可传输的嵌入，在线路之间传播信号
- en: LLM as Reasoning Engine
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言模型作为推理引擎
- en: 'The LLM performs metareasoning across inputs from specialty components:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型在专业组件的输入上进行元推理：
- en: Contextualizing signals by resolving ambiguities based on broader understanding
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过基于更广泛的理解解决歧义来进行信号的语境化
- en: Abstracting low-level outputs into higher-level insights
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将低层次的输出抽象为更高层次的见解
- en: Evaluating hypotheses and interpretations on conceptual grounds
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在概念基础上评估假设和解释
- en: Determining explanatory inferences linking interconnected outputs
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定解释性推论，连接相互关联的输出
- en: The LLM thus acts as connective tissue both computationally and semantically
    between AIs narrow and broad.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型因此在计算和语义上充当了狭义和广义 AI 之间的连接纽带。
- en: '![](../Images/c0d43e2911cd543b4c638bbda1270e0f.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0d43e2911cd543b4c638bbda1270e0f.png)'
- en: Image generated by Dall-E-3
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Dall-E-3 生成的图像
- en: Conclusion
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: As LLMs continue maturing into more generalized reasoning engines, innovating
    the architectures surrounding them remains imperative. In particular, effectively
    harnessing external knowledge presents an avenue to overcome inherent model limitations.
    LLM Compiler and its techniques around coordinating modular functions provides
    a promising paradigm to explore for structuring scalable knowledge retrieval.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 随着语言模型不断成熟为更通用的推理引擎，围绕它们的架构创新仍然至关重要。特别是，有效利用外部知识为克服固有模型局限性提供了一条途径。语言模型编译器及其协调模块功能的技术提供了一个有前景的范式，用于构建可扩展的知识检索结构。
- en: Much work remains in developing these connections and integrating retrieval
    capacities at scale.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发这些连接和大规模整合检索能力方面还有很多工作要做。
- en: But by framing knowledge as modular tools orchestrated by an LLM compiler, we
    open intriguing possibilities for balanced efficiency, concision and coherence
    in complex reasoning.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 但通过将知识框定为由语言模型编译器协调的模块化工具，我们为在复杂推理中实现平衡的效率、简洁性和连贯性打开了有趣的可能性。
- en: And progress along these fronts remains vital as we aspire towards genuine systematic
    intelligence.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些方面的进展仍然至关重要，因为我们期望实现真正的系统智能。
