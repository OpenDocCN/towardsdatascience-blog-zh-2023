- en: Orchestrating Efficient Reasoning Over Knowledge Graphs with LLM Compiler Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9](https://towardsdatascience.com/orchestrating-efficient-reasoning-over-knowledge-graphs-with-llm-compiler-frameworks-749d36dc32b9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----749d36dc32b9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----749d36dc32b9--------------------------------)
    ·6 min read·Dec 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  prefs: []
  type: TYPE_NORMAL
- en: Recent innovations in large language model (LLM) design have led to rapid advancements
    in few-shot learning and reasoning capabilities. However, despite their progress,
    LLMs still face limitations when dealing with complex real-world contexts involving
    massive amounts of interconnected knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: To address this challenge, a promising approach has emerged in *retrieval augmented
    generation* (RAG) systems. RAG combines the adaptive learning strengths of LLMs
    with scalable retrieval from external knowledge sources like knowledge graphs
    (KGs). Rather than attempting to encode all information within the model statically,
    RAG allows querying necessary context from indexed knowledge graphs on the fly
    as needed.
  prefs: []
  type: TYPE_NORMAL
- en: However, effectively orchestrating reasoning and retrieval across interconnected
    knowledge sources brings its own challenges. Naive approaches that simply retrieve
    and concatenate information in discrete steps often fail to fully capture the
    nuances within dense knowledge graphs. The interconnected nature of concepts means
    that vital contextual details can be missed if not analyzed in relation to one
    another.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, an intriguing framework named LLM Compiler has demonstrated early
    successes in optimizing orchestration of multiple function calls in LLMs by automatically
    handling dependencies and allowing parallel execution.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://arxiv.org/abs/2312.04511?source=post_page-----749d36dc32b9--------------------------------)
    [## An LLM Compiler for Parallel Function Calling'
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have shown remarkable results on various complex
    reasoning benchmarks. The reasoning…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2312.04511?source=post_page-----749d36dc32b9--------------------------------)
    [](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb?source=post_page-----749d36dc32b9--------------------------------)
    [## llama-hub/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb at
    main ·…
  prefs: []
  type: TYPE_NORMAL
- en: A library of data loaders for LLMs made by the community -- to be used with
    LlamaIndex and/or LangChain …
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb?source=post_page-----749d36dc32b9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, we explore the potential of applying LLM Compiler techniques
    more broadly to knowledge graph retrieval and reasoning. We already did a working
    prototype before the paper released :'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----749d36dc32b9--------------------------------)
    [## Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and…'
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----749d36dc32b9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: We analyze how its techniques like automated planning, dependency management,
    and parallelized execution can enable more efficient and structured analysis of
    interconnected knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Plan :'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. Challenges of Reasoning Over Massive Knowledge Graphs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2\. Knowledge Graphs as Modular LLM Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3\. Structured Reasoning Powered by LLM Compilers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4\. An Operating System for Knowledge Assimilation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: —
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Challenges of Reasoning Over Massive Knowledge Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](https://github.com/tomasonjo/blogs/blob/master/llm/devops_rag.ipynb?source=post_page-----749d36dc32b9--------------------------------)
    [## blogs/llm/devops_rag.ipynb at master · tomasonjo/blogs'
  prefs: []
  type: TYPE_NORMAL
- en: Jupyter notebooks that support my graph data science blog posts at https://bratanic-tomaz.medium.com/
    …
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/tomasonjo/blogs/blob/master/llm/devops_rag.ipynb?source=post_page-----749d36dc32b9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'When addressing the challenges of reasoning over massive knowledge graphs,
    it is essential to integrate advanced techniques and methods for optimizing data
    retrieval and processing. This involves leveraging various computational strategies
    to balance efficiency, accuracy, and completeness in the analysis of large interconnected
    datasets. The following sections detail these approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: a. Optimizing Cypher Queries for Mathematical Operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Objective:** Enhance the performance of Cypher queries, particularly for
    mathematical aggregations over graph data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Methodology:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**- Identify Opportunities:** Recognize scenarios where mathematical aggregations
    can be efficiently applied to graph data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**- Modular Steps:** Break down the process into parallel retrieval of groups,
    concurrent execution of aggregation functions, and efficient joins.'
  prefs: []
  type: TYPE_NORMAL
- en: '**- Example Application:** Calculating the number of high-priority tasks assigned
    to Team A. This involves retrieving task nodes, filtering by priority and team,
    and aggregating the count.'
  prefs: []
  type: TYPE_NORMAL
- en: b. Planning Parallel Vector Searches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Objective:** Implement parallel vector searches to efficiently navigate through
    graph-based data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Methodology:**'
  prefs: []
  type: TYPE_NORMAL
- en: '- Analyze Questions for Seed Entities: Dissect queries to determine key entities
    that serve as starting points for vector searches.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Explore Concurrent Vector Spaces: Initiate searches from different seed entities,
    exploring the graph concurrently.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Continual Node Retrieval: Dynamically retrieve nodes based on vector similarity,
    expanding the search in a targeted manner.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Example Application: Identifying services with descriptions similar to ‘PaymentService’
    by exploring vector spaces rooted at different entities.'
  prefs: []
  type: TYPE_NORMAL
- en: c. Coordinating Usage of Graph Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Objective:** Select and apply the most appropriate graph algorithms for specific
    queries.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Methodology:**'
  prefs: []
  type: TYPE_NORMAL
- en: '- Examine Questions for Algorithm Selection: Analyze the nature of the query
    to choose relevant algorithms (like traversal, community detection).'
  prefs: []
  type: TYPE_NORMAL
- en: '- Modular Application: Apply algorithms in a modular fashion, each optimized
    for specific goals (e.g., efficiency, accuracy).'
  prefs: []
  type: TYPE_NORMAL
- en: '- Resolve Dependencies: Ensure coordination between algorithms, especially
    when the output of one is required for the execution of another.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Example Application: Finding a tightly connected subgraph of interdependent
    services using community detection and traversal algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: LLM Compiler Coordination
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An LLM Compiler could act as a central coordinator for these tasks. It would
    manage the execution of Cypher queries for mathematical operations, oversee the
    parallel vector searches, and orchestrate the application of various graph algorithms.
    The primary goal of the LLM Compiler in this context would be to ensure that the
    entire process of reasoning over the knowledge graph is not only efficient and
    accurate but also comprehensive. This requires a sophisticated understanding of
    the data structure, the ability to predict computational needs, and the capability
    to dynamically adjust strategies in response to real-time data analysis outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Knowledge Graphs as Modular LLM Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The LLM Compiler system introduced by Kim et al. 2023 consists of 3 key components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**LLM Planner:** Decomposes tasks and builds dependency graphs'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Task Fetching Unit:** Dispatches tasks handling dependencies'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Executor:** Runs tool functions in parallel'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notably, LLM Compiler views tools as modular functions that can be executed
    concurrently when possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building on this paradigm, an intriguing perspective is to view **knowledge
    graphs themselves as modular tools** that an LLM orchestrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Query Engines** over KGs become tools accessed by the LLM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph Algorithms and Embeddings** provide tool-level customization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LLM Planner** determines optimal multi-graph exploration strategies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this framing, LLM Compiler’s automated planning and structured execution
    techniques seem highly promising for complex knowledge retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Structured Reasoning Powered by LLM Compilers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By specializing LLM Compiler techniques for integrating multiple tools and
    execution graphs, we can enhance several facets of knowledge graph reasoning:'
  prefs: []
  type: TYPE_NORMAL
- en: a. Parallel Exploration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Planning decomposition would allow concurrently querying diverse regions of
    a knowledge graph from multiple “entry points”. Multi-hop paths could be traversed
    in parallel, accelerating exploration.
  prefs: []
  type: TYPE_NORMAL
- en: b. Modular Retrieval
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Query engines over distinct sub-graphs with unique algorithms and embeddings
    essentially act as isolated tools. LLM Compiler excels at integrating disparate
    modular capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: c. Dependency Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Intermediate query results often inform subsequent searches. LLM Compiler’s
    automated handling of inter-tool dependencies enables seamless propagation of
    entities and relationships.
  prefs: []
  type: TYPE_NORMAL
- en: d. Recursive Re-Planning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For complex questions, succeeding retrieval phases depend highly on previous
    phases. LLM Compiler allows recursive re-planning when updated contexts reveal
    new dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: e. Ontology-Aided Planning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ontologies providing high-level schema around key entities can further assist
    the planner module. Meta-level knowledge guides more structured task decomposition
    aligned to domain concepts.
  prefs: []
  type: TYPE_NORMAL
- en: e. Diverse Data Sources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The planner can integrate additional data sources like SQL databases, imagery,
    and internet search engines as modular tools accessible to the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: By orchestrating knowledge retrieval modules under a structured planning framework
    powered by ontological knowledge, LLM Compilers could enable remarkably efficient
    and precise navigation of extensive information spaces.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. An Operating System for Knowledge Assimilation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stepping back, we can envision LLM Compiler techniques giving rise to a new
    paradigm — LLMs as operating systems overseeing diverse knowledge functions. Much
    like an OS balancing threads and memory, LLMs could schedule retrieval, reasoning,
    and learning across knowledge stores. ML-based optimizers would automatically
    tune the routing and usage of various “tool” modules.
  prefs: []
  type: TYPE_NORMAL
- en: Within this ecosystem, the LLM Compiler would act as the key workflow orchestration
    framework interfacing between operating system and tools. It would handle all
    the underlying complexities of dependency resolution, concurrency optimization
    and resource allocation on behalf of the LLM OS.
  prefs: []
  type: TYPE_NORMAL
- en: LLM as Operating System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The LLM acts as the orchestrator overseeing and allocating resources between
    various modules:'
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling for optimal concurrency between retrieval, reasoning, and learning
    functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Routing queries and decisions to the most apt components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring execution to dynamically optimize allocation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling modular expandability as new capabilities come online
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLM as Semantic Glue
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The LLM provides common semantic representations tying together disparate components:'
  prefs: []
  type: TYPE_NORMAL
- en: Embedding queries, retrieved contexts, generated decisions into a shared vector
    space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translating queries and directives between component interfaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Propagating signals between modules by encoding inputs/outputs into transportable
    embeddings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLM as Reasoning Engine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The LLM performs metareasoning across inputs from specialty components:'
  prefs: []
  type: TYPE_NORMAL
- en: Contextualizing signals by resolving ambiguities based on broader understanding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abstracting low-level outputs into higher-level insights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating hypotheses and interpretations on conceptual grounds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determining explanatory inferences linking interconnected outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The LLM thus acts as connective tissue both computationally and semantically
    between AIs narrow and broad.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c0d43e2911cd543b4c638bbda1270e0f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by Dall-E-3
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As LLMs continue maturing into more generalized reasoning engines, innovating
    the architectures surrounding them remains imperative. In particular, effectively
    harnessing external knowledge presents an avenue to overcome inherent model limitations.
    LLM Compiler and its techniques around coordinating modular functions provides
    a promising paradigm to explore for structuring scalable knowledge retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: Much work remains in developing these connections and integrating retrieval
    capacities at scale.
  prefs: []
  type: TYPE_NORMAL
- en: But by framing knowledge as modular tools orchestrated by an LLM compiler, we
    open intriguing possibilities for balanced efficiency, concision and coherence
    in complex reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: And progress along these fronts remains vital as we aspire towards genuine systematic
    intelligence.
  prefs: []
  type: TYPE_NORMAL
