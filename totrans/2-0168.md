# 精度和召回率的商业视角

> 原文：[https://towardsdatascience.com/a-business-lens-on-precision-and-recall-1ce2f5b77eed](https://towardsdatascience.com/a-business-lens-on-precision-and-recall-1ce2f5b77eed)

## 社交媒体垃圾信息作为案例研究

[](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)[![Matt Sosna](../Images/c3175c0dc62b795a8d0fa57532fb669b.png)](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------) [Matt Sosna](https://mgsosna.medium.com/?source=post_page-----1ce2f5b77eed--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1ce2f5b77eed--------------------------------) ·阅读时间18分钟·2023年12月22日

--

![](../Images/53e528d12045f764f11592bfc30a7e90.png)

照片由 [Nong](https://unsplash.com/@californong?utm_source=medium&utm_medium=referral) 提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

*免责声明：本帖中的示例仅用于说明目的，并不对任何特定公司或其内容政策发表评论。本文所表达的观点仅代表我个人，不代表我的雇主。*

为什么社交媒体上会有*垃圾信息*？除了垃圾信息发送者自己，没有人喜欢点击诱饵骗局或网络钓鱼尝试。我们有*几十年*的训练数据来喂养机器学习分类器。那么为什么每个主要技术平台上的垃圾信息似乎都是不可避免的？经过这么多年，为什么机器人农场依然存在？

![](../Images/f3742b4bacf2a7a25ac11d479d79b32f.png)

作者提供的图片

简而言之，答案是*真正*在大规模上打击垃圾信息是非常困难的，而且在不伤害真实用户和广告商的情况下，这种难度是指数级增长的。在这篇文章中，我们将使用**精度**和**召回率**作为理解垃圾信息问题的框架。我们将看到，彻底消灭100%的垃圾信息是不切实际的，并且存在基于金融、法规和用户情绪的某种“平衡”垃圾信息发生率。

![](../Images/f7b96d0737462f4897e21748e0555497.png)

照片由 [Joseph Barrientos](https://unsplash.com/@jbcreate_?utm_source=medium&utm_medium=referral) 提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# 我们的应用

假设我们要推出一个与 TikTok 和 Instagram 竞争的应用。（暂且不论它们分别拥有[**11亿**](https://www.demandsage.com/tiktok-user-statistics/)和[**20亿**](https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/)的月活跃用户；我们充满雄心！）在这个竞争激烈的市场中，我们的关键差异点是我们保证用户仅能看到最高质量的视频：绝对没有“快速致富”的骗局，公然的现有内容转发，感染计算机的恶意网址等等。

## 尝试 1：人工审核

为了实现这一质量保证，我们雇佣了令人震惊的 1000 名审核员，审查每个上传的视频才允许其上平台。我们认为**有些事情确实需要人工处理**：视频垃圾信息过于复杂和依赖上下文，无法依靠自动逻辑。例如，鼓励用户点击 URL 的视频可能是恶意钓鱼尝试，也可能是针对阿尔茨海默病研究的无害筹款活动——风险太大，无法自动做出这样的决定。

![](../Images/96e51619d2cd07f9f82f8faa757104d1.png)

作者提供的图片

应用程序上线了。令我们高兴的是，我们的“诚信优先”信息得到了用户的共鸣，他们蜂拥而至。我们很快达到了每天上传 5 万小时视频的数百万用户。

换句话说，每位审核员现在每天要审查*50 小时的视频*。他们尝试以 6 倍速观看所有视频，但难免出错：用户开始抱怨**他们的无害视频被屏蔽 *和* 垃圾信息却被上传到了平台。** 我们迅速雇佣更多审核员，但随着应用的增长和上传量的急剧增加，我们意识到在我们能雇佣足够的审核员之前，公司可能会破产。[1] 我们需要一种不同的策略。

## 尝试 2：机器学习

我们无法替代人类的直觉，但也许我们可以通过机器学习接近这一目标。鉴于过去十年[计算机视觉](https://www.ibm.com/topics/computer-vision)和[自然语言处理](https://www.ibm.com/topics/natural-language-processing)的巨大进展，我们可以从视频中提取**特征**：与现有视频的像素相似性，音频中的关键词，视频是否似乎是[由 AI 生成的](https://www.techtarget.com/searchenterpriseai/definition/generative-AI)等等。然后我们可以查看这些特征与视频是否为垃圾信息之间的关系。

![](../Images/861195ec440efb4768b90d2ab3d3e4a7.png)

作者提供的图片

确定特征与垃圾标签之间的关系最好交给算法。[2] 特征空间对于人类来说实在太大：特征的相互作用是非线性的，依赖关系复杂，在某些上下文中有用而在其他情况下无用，等等。所以我们使用机器学习来**训练一个*预测*视频是否为垃圾信息的分类器。** 我们的模型接收一个视频并输出该视频是垃圾信息的概率。[3]

![](../Images/0731005f62ce0f60cbfa2d9b360ea4da.png)

作者提供的图像

当我们首次运行分类器在我们知道是垃圾邮件和正常的视频上时，我们希望看到如下情况：两个分布通过其垃圾邮件概率整齐地分开。在这种理想状态下，存在一个垃圾邮件概率阈值，低于此阈值的*所有视频都是正常邮件*，高于此阈值的*所有视频都是垃圾邮件*，我们可以利用这个阈值来完美地分类新视频。

![](../Images/4fba261de733d74cfa20d84bdded425d.png)

作者提供的图像

但我们实际看到的是**概率分布重叠**。是的，大多数正常视频的概率较低，大多数垃圾邮件视频的概率较高。但**存在一个不舒服的“中间”垃圾邮件概率，在这个概率下很难判断视频是垃圾邮件还是正常邮件。**

![](../Images/39dd918daf7b54a8c07e40b3067051f1.png)

作者提供的图像

如果我们放大分布重叠的地方，情况可能如下。我们无法画出一条完美分隔正常视频和垃圾邮件的视频线。如果我们将阈值设置得太高，垃圾邮件就会进入平台。如果我们将阈值设置得太低，正常视频会被错误地阻止。

![](../Images/3c5b3df47c311c353dd7883fca805c77.png)

作者提供的图像

**那么我们如何选择一个“最不差”的阈值？** 要回答这个问题，我们需要理解**精确度**和**召回率**，这两个指标为任何分类系统的权衡提供了框架。然后我们将以新的理解重新审视我们的应用，并查看是否有办法来最佳地分类垃圾邮件。

![](../Images/3fb2153d0ad6d44ca25e5516269d4bbf.png)

照片由[Robert Wiedemann](https://unsplash.com/@antilumen?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# 评估框架

## 模型创建

让我们快速了解一下如何创建和评估机器学习分类器，以我们的垃圾邮件分类器为例。训练模型的第一步是将数据分成***训练***集和***测试***集。然后，算法解析训练数据以学习特征与标签（垃圾邮件或正常）的关系。结果是一个能够接收视频特征并返回其为垃圾邮件的概率的模型。

![](../Images/84a26d9f398fc5f5bb846a4a8283203e.png)

作者提供的图像

概率很好，但我们需要一种方法将如0.17或0.55这样的数字转换为是否为垃圾邮件的决策。因此，我们将输出的概率二值化——默认值为0.5——成*垃圾邮件*或*正常邮件*分类。对于模型中的任意特征，模型的概率曲线（黑线）和分类（黄色和绿色区域）可能看起来像这样。

![](../Images/a26b8e4e1d7e9939b9537c303c4ffc68.png)

作者提供的图像

我们的模型是对所给数据的最佳理解。然而，虽然理解 *我们已有* 的数据是有用的，但真正的目标是能够预测 *我们未见过* 的数据的标签，比如即将上传的视频。[4] 我们通过 *测试* 数据来衡量模型的能力：这些特征-标签对没有用于训练模型。我们输入测试数据的特征，查看模型的预测，并将这些预测与实际标签进行比较。（这就是为什么我们不对所有可用数据进行训练：我们需要一些保留的标签来审计模型的预测。）

![](../Images/30d28872caa5f9392fc57ba3a69ec371.png)

图片由作者提供

基于预测的四种可能结果，有四个组成部分来衡量我们模型分类新数据的能力：

+   **真正例：** 模型正确识别垃圾邮件。

+   **假阳性：** 模型预测为垃圾邮件，但视频是良性。

+   **假阴性：** 模型预测为良性，但视频是垃圾邮件。

+   **真负例：** 模型正确识别一个良性视频。

我们可以将这些结果排列在 **混淆矩阵** 中。矩阵的列是 *预测* 的垃圾邮件和良性标签，行是 *实际* 的垃圾邮件和良性标签。

![](../Images/46cd0b5971f558254a0d5c8cf30692d4.png)

图片由作者提供

我们之前提到过，我们模型的垃圾邮件概率在 0.5 处被二值化为*垃圾邮件*和*良性*分类。但 0.5 并不总是最佳阈值，尤其是在数据不平衡的情况下。我们可以将阈值设置为 0 和 1 之间的任何值，以更好地划分分类。

![](../Images/3620c14defc7401d6c8343ee679221c8.png)

图片由作者提供

**这些阈值将生成不同的混淆矩阵，反映每个模型对新数据的准确泛化能力的不同。** 那么我们如何选择一个阈值呢？为了解答这个问题，我们需要回顾一些指标。

## 指标 1：准确性

我们寻找最佳模型的第一个策略可能是最大化 **准确性：** 我们模型检测真正例 (TP) 和真负例 (TN) 的能力。换句话说，准确性是 ***我们模型正确预测的标签的比例***。一个具有完美准确性的模型将没有假阳性 (FP) 或假阴性 (FN)。

![](../Images/2833cc189f684e2e7d50d07e00b75fc7.png)

准确性是一个直观的指标，但它可能掩盖我们模型中的一些盲点。例如，如果 [一种标签远比另一种标签频繁](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)，我们的模型可能会难以预测不太频繁的标签，甚至可能收敛到一个无意义的规则上！例如，如果我们的训练数据只是上传视频的随机样本，我们可能会得到 99.9% 的良性视频和 0.1% 的垃圾邮件。**一个总是预测视频为良性的模型将有 99.9% 的准确率。** 这完全不合格——我们会错过所有我们想要捕捉的视频！

即使数据平衡，我们在评估模型时也绝不能仅仅依赖准确率。让我们来看一些其他指标，以获得更全面的视角。

## 指标 2：召回率

为了衡量我们模型在测试集中对正样本的分类效果，我们需要查看模型的**召回率**。召回率是***模型正确预测的正标签的比例***。换句话说：

![](../Images/54999bd6f86e63318430209710eb65a4.png)

我们可以将这视为混淆矩阵的顶行。召回率是指真正例的数量与*正标签*总数的比值：模型捕捉到的标签（真正例）和遗漏的标签（假阴性）。一个具有100%召回率的模型是一个在测试集中正确分类所有正标签的模型。

![](../Images/9ecdd9cf6cbbe9181bb0705e55638496.png)

作者提供的图像

那个99.9%准确的“总是预测良性”模型将会有*零*召回率，这是一个明显的红旗，表明该模型应该立即被丢弃。理想情况下，我们的模型应该足够敏感，能捕捉测试集中所有的垃圾邮件标签。但为了确保这种敏感性不会以错误标记良性视频为代价，我们需要查看一个额外的指标：精度。

## 指标 3：精度

当我们的模型将一个视频分类为垃圾邮件时，它*实际*是垃圾邮件的频率如何？这就是**精度**的核心思想，或者说***预测的正标签中真实正例的比例***。作为一个方程，精度呈现以下形式：

![](../Images/e1b48fd0f8179b9fbd1217f4b076d1fd.png)

我们可以将这视为混淆矩阵的左列。精度是指真正例的数量与*预测*总数的比值：包括正确的（真正例）和不正确的（假正例）。

![](../Images/3c7c3bc78dd80eadee5f0853412bbe7c.png)

作者提供的图像

精度是理解当我们的模型预测视频为垃圾邮件时我们应该有多大信心的关键指标。当一个高精度模型预测视频是垃圾邮件时，该视频很可能是垃圾邮件；如果模型精度低，除非我们自己查看，否则无法知道它是否真的垃圾邮件。

因此，可能会有诱惑去优化精度，最大化对模型预测的信心。**但我们越是优先考虑精度，我们的模型在将视频标记为垃圾邮件时就会越*保守***，这意味着我们不可避免地会错过一些应该被捕捉的垃圾邮件视频。

为了说明这一点，我们再次查看良性和垃圾邮件分布重叠的图示。我们可以在两个阈值下对垃圾邮件概率进行二值化：A或B。

![](../Images/591ba441bd5d4f0d4e7ba768c370a3b2.png)

作者提供的图像

阈值B右侧的每个视频都是垃圾视频，因此在该垃圾概率下进行二分类的分类器将具有100%的精确率。这很令人印象深刻，但该阈值会错过左侧的两个垃圾视频。这些视频将被错误地分类为良性（假阴性），因为我们的模型对它们是否为垃圾视频不够自信。与此同时，阈值A的模型会捕捉到这些垃圾视频，但也会错误地标记右侧的三个良性视频（假阳性），导致精确率降低。

## 寻找平衡

这种权衡涉及到精确率和召回率之间的固有矛盾：**当我们提高分类阈值时，我们会*提高精确率*但*降低召回率***。我们可以重新绘制我们的图形以突出这种权衡。

![](../Images/eb4ab04798c914699eeb53488990a247.png)

图片由作者提供

另一种可视化这种情况的方法是将精确率和召回率绘制为分类阈值的函数。使用我在一些样本数据上训练的分类器（代码在帖子末尾），我们可以看到随着阈值的提高，精确率增加，而召回率稳定下降。阈值越高，我们模型的预测越准确，但也会错过更多的垃圾视频。

![](../Images/bc019ef7baa1b12786fbfe71ba000802.png)

图片由作者提供

那么我们如何找到平衡点呢？归根结底，**我们必须问自己，是更倾向于接受假阳性还是假阴性，并且程度如何**。如果一些用户被错误地阻止上传视频，还是他们在平台上遇到诈骗更糟糕？阻止100个良性视频以防止1个垃圾视频是否值得？阻止1000个良性视频呢？

我们应用的主要卖点是用户永远不会看到垃圾视频。为了在我们的分类器中实现100%的召回率，我们不得不接受大约45%的精确率——这是一种令人尴尬的不精确模型，将导致每天阻止数千个良性视频。如果我们能接受只捕捉到90%的垃圾视频，我们可能能达到60%的精确率，但我们仍然会阻止过多的视频并允许垃圾信息通过。

## 比较模型

我们回到设计阶段，深入挖掘数据以寻找与垃圾视频相关的更好特征。我们发现了一些有前景的趋势，并重新训练了我们的分类器。当我们可视化两个模型的精确率和召回率与分类阈值的关系时，我们看到如下图所示的情况；实线是旧模型，虚线是新模型。

![](../Images/0e6a0b7ce7b663811a6ae4233c78a8b3.png)

图片由作者提供

这看起来好多了！对于大多数阈值，新模型在精确率和召回率上都取得了巨大的改进，使我们的权衡讨论更加容易接受。现在在保持100%召回率的同时，我们可以获得的最高精确率大约是60%。在90%的召回率下，我们有85%的精确率。

我们可以用**AUC-ROC**，即**ROC曲线下面积**，来总结我们在所有阈值上的模型拟合改进。ROC曲线是一个绘制真正例率（召回率）与假正例率（良性视频被标记为垃圾邮件的频率）之间关系的图表。如果我们的模型能在所有阈值下完美区分良性和垃圾邮件视频，则曲线下面积为1；如果模型的效果与随机猜测无异（下方的灰色虚线），则为0.5；否则则介于两者之间。这个数值提供了一种快速展示我们新模型（AUC = 0.96）相对于旧模型（AUC = 0.84）整体改进的方式。

![](../Images/9bff6fe748e9032421c06ce8ced5d6ac.png)

作者提供的图片

因此，无论用什么指标来衡量，我们都可以庆祝我们通过新的分类器提高了对抗垃圾邮件的能力。但我们仍需面对一个不太舒适的问题：我们的应用中绝对零垃圾邮件的承诺。为了实现100%的召回率，我们是否真的需要在对上传到应用的视频进行分类时接受60%的精确度，这仅比掷硬币稍好？我们是否需要回到模型开发阶段，或者还有其他方法可以尝试？

![](../Images/92e4404d0d1c9f41f20f048b1ac99f38.png)

照片由 [Rohit Tandon](https://unsplash.com/@sepoys?utm_source=medium&utm_medium=referral) 拍摄，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# 回到我们的应用

## 尝试3：机器学习 + 人工审核

如果我们继续仅仅依赖机器学习的思维方式，我们将花费大量精力去追求递减的收益。是的，我们可以找到更好的特征、算法和超参数来提高模型的拟合度。但如果我们退一步来看，我们会发现**我们的分类器实际上只是识别垃圾邮件的一个*漏斗*的部分**，投资于*整个漏斗*会比仅仅关注机器学习部分更为成功。

如果我们重新审视之前的垃圾邮件分布图，我们可以定义三个垃圾邮件概率区域：确定的良性、确定的垃圾邮件和“不确定”。我们刚刚讨论了如何利用精确度和召回率来量化将这个不确定区域二元化为良性和垃圾邮件的权衡。但如果我们将分类器与之前的人类审核员结合起来，这一切就不再是黑白分明的了。

![](../Images/71c2d5ce64807a56e81faf6d4215c331.png)

作者提供的图片

如果我们不再为寻找完美的分类阈值而苦恼，而是设置上述紫色区域边界的阈值会怎样？如果我们的分类器确信一个视频是垃圾邮件或良性邮件，我们就让它为我们自动决定。**但如果分类器不确定，我们就把视频交给人工来做最终决定。**

![](../Images/bfd9e4312dfadfad35c9202e6838f82c.png)

作者提供的图片

我们现在面临两个精度-召回权衡——不确定性区域的下限和上限——但**误报的风险要低得多**：我们现在面临的风险是浪费人工审查能力，而不是直接阻止无害视频。（尽管效率低下，我们的审查员不会抱怨审查一些无害视频，而如果我们错误地阻止了足够多的视频，用户会退出我们的应用程序。）

假阴性（漏过一个垃圾邮件视频）仍然代价高昂，考虑到我们应用程序对质量的承诺。所以只要我们有人工审查能力，我们可以尽可能扩大我们的不确定性窗口，以确保捕获尽可能多的垃圾邮件视频。但这足够确保没有垃圾邮件视频进入平台吗？

## 机会成本和对抗性行为者

不幸的是，答案是否定的。即使结合了机器学习和人工审查的最佳方案，我们也不能阻止100%垃圾邮件进入平台。

第一个原因，我们之前讨论过，是财务问题。人工审查成本高昂，我们无法雇佣足够的人来处理所有中级垃圾邮件概率的视频，而不至于使公司破产。**超出一定投资水平，我们不仅能减少一些垃圾邮件，还会削减其他公司项目的资金**，比如新功能、市场扩展或客户支持。还有许多其他安全工作需要资金，比如防止恶意行为者入侵或冒充用户。在某些情况下，其他工作的机会成本如此之高，以至于如果我们在平台上接受一定程度的垃圾邮件，我们实际上可能会有一个更好的应用程序。

![](../Images/532440ba402622b1d331db8573d2d1d8.png)

作者提供的图像

我们不能阻止100%垃圾邮件的第二个原因是**我们的分类器很快就会过时，因为垃圾邮件特征空间不断变化**。垃圾邮件发送者是*对抗性的*，这意味着他们会[改变战术](https://www.zdnet.com/article/facebooks-meta-says-bad-actors-are-changing-tactics-as-it-takes-down-six-more-groups/)，一旦公司确定了阻止垃圾邮件的规则。这些恶意行为者是无情的；诈骗他人是[他们养家糊口的方法](https://open.spotify.com/episode/4b5s6nPbU7mE9ZXt8IdqXA?si=3bc062cf88e44b47)，他们有无尽的动力找到绕过我们防御的方法。

残酷的是，预测能力最强的特征通常会变得无关紧要，因为垃圾邮件发送者会调查他们的内容为何被阻止，然后改变他们的方法。结果是平台与垃圾邮件发送者之间的[红皇后竞赛](https://en.wikipedia.org/wiki/Red_Queen_hypothesis)。如果我们不不断投资于创新和迭代如何打击垃圾邮件，垃圾邮件发送者会迅速绕过我们的防御，淹没我们的平台。但即使拥有一支优秀的工程师和调查团队，仍然会有一些垃圾邮件在我们更新系统之前进入平台。

## 垃圾邮件平衡

所以，如果我们无法在平台上实现0%的垃圾邮件，我们会在哪里结束？这个问题的答案取决于许多竞争因素。

![](../Images/88fc28da33fe08e79eef67c59d49056a.png)

作者提供的图片

首先，也是可能最强的力量是监管。如果通过法律，对我们应用程序上用户受骗的情况处以严重的经济罚款，那么投资平衡会大幅向最小化垃圾邮件倾斜。但除非法律真正有约束力，否则这一力量会被未投入其他公司计划的机会成本所抵消（这些计划可能本身也受到自身法规的法律压力）。

第二组力量来自用户。当垃圾邮件明显时，用户会愤怒；关于家庭成员失去积蓄的病毒式帖子出现，用户呼吁国会制止我们的公司，用户离开或抵制我们的应用程序。因此，我们花更多精力对抗垃圾邮件，垃圾邮件的普遍性降低，用户停止抱怨。但是在没有用户这种压力的情况下，当没有人注意到结果时，很难证明增加投资的必要性。

最后，这是我们公司对垃圾邮件的内部立场。如果在对抗垃圾邮件的投资超过经济最优水平的情况下，我们愿意损失多少公司最大可能的收入？垃圾邮件对我们的业务造成伤害，但过度投资于对抗垃圾邮件也会造成伤害。基于我们对垃圾邮件的道德立场，我们愿意在收益递减的情况下走多远？

最终，这些力量的总和会导致我们应用程序上出现一些非零（希望不是100%！）的垃圾邮件。我们意识到，启动我们应用程序的初衷在我们所生活的世界里显得有些天真。但是，我们决定这不是放弃的理由，因此我们建立了一个强大的反垃圾邮件团队，为他们提供所需的资源，并开始了对用户安全的无休止的斗争。

![](../Images/e5f0ddb85b729e14bfa7bf236d7ee107.png)

图片由 [Tim Mossholder](https://unsplash.com/@timmossholder?utm_source=medium&utm_medium=referral) 提供，发布在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# 结论

本文使用了“为什么社交媒体上会有垃圾邮件？”这个问题来探讨分类系统中的精准度、召回率和投资权衡。我们从讨论对抗垃圾邮件的不同方法（人工审核和机器学习）开始，然后讨论了在设置分类阈值时我们获得和失去的内容。接着，我们讨论了在社交媒体上对抗垃圾邮件的众多挑战。

再次声明，本文仅代表我的个人观点，并不评论任何公司的内容政策。感谢阅读！

最佳，

马特

# 代码

以下是生成本文中提到的数据和分类器的代码。改进的分类器是通过减少特征生成过程中随机噪声的标准差生成的。

[PRE0]

# 脚注

## 1\. 尝试 1：人工审核

为了说明100%人工审核的不切实际，可以考虑YouTube。用户每分钟上传[**超过 500 小时的视频**](https://www.statista.com/statistics/259477/hours-of-video-uploaded-to-youtube-every-minute/)，即**每天 180 万小时**。手动审核这么多视频需要*75,000 名审核员*全天候观看视频，如果审核员每班只工作8小时并有午休，则需要*240,000 名*审核员。再加上1,000名审核员处理*重新审核*那些创作者[声称被错误删除](https://www.tspa.org/curriculum/ts-fundamentals/content-moderation-and-operations/user-appeals/)的视频。我们剩下的就是**241,000 名审核员**，或者是[Google 员工的160%](https://www.macrotrends.net/stocks/charts/GOOG/alphabet/number-of-employees)。这行不通。

## 2\. 尝试 2：机器学习

请注意，机器学习并不是对抗垃圾邮件的唯一选择。*确实*存在针对垃圾邮件子集的手工确定性规则的有力用例。例如，“用户应该允许多久发布一次视频？”这种问题可能不需要专门的分类器，可以从用户每天发布次数的分布中推断出来。

## 3\. 尝试 2：机器学习

在这篇文章中，我使用单数形式的“模型”或“分类器”来指代我们用于捕捉垃圾邮件的系统。但垃圾邮件是一个广泛且多方面的领域，因此我们可能实际上需要一个[集成](https://en.wikipedia.org/wiki/Ensemble_learning)模型，每个模型都在不同的垃圾邮件子集上进行训练。这种集成方法是[Facebook 新闻推送](https://about.fb.com/news/2021/01/how-does-news-feed-predict-what-you-want-to-see/)的工作原理。Feed中的每个项目都由多个模型排名，每个模型输出用户可能喜欢该项目、评论该项目或开始关注发布该项目的页面等的可能性。

## 4\. 评估框架

仅仅建模现有数据也是有用的，但这更多属于商业智能或数据分析的领域。目标是理解我们的数据，但不一定有*预测*未来数据的组件。
