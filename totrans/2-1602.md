# 优化：牛顿-拉夫森方法的几何解释

> 原文：[https://towardsdatascience.com/optimization-geometrical-interpretation-of-the-newton-raphson-method-d9f7acf1b5ae](https://towardsdatascience.com/optimization-geometrical-interpretation-of-the-newton-raphson-method-d9f7acf1b5ae)

## 探索一种基本的数值优化技术，重点关注其几何解释

[](https://medium.com/@guillaume.saupin?source=post_page-----d9f7acf1b5ae--------------------------------)[![Saupin Guillaume](../Images/d9112d3cdfe6f335b6ff2c875fba6bb5.png)](https://medium.com/@guillaume.saupin?source=post_page-----d9f7acf1b5ae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d9f7acf1b5ae--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d9f7acf1b5ae--------------------------------) [Saupin Guillaume](https://medium.com/@guillaume.saupin?source=post_page-----d9f7acf1b5ae--------------------------------)

·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----d9f7acf1b5ae--------------------------------) ·阅读时间8分钟·2023年10月13日

--

![](../Images/a15aed318572b2f37beff8e816b0f362.png)

图片由[Ansgar Scheffold](https://unsplash.com/@ansgarscheffold?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

梯度下降被广泛认为是基本的数值优化技术之一，而牛顿-拉夫森方法则在这一领域中具有显著地位。这种方法以其简单性、优雅性和计算能力而著称，值得深入探讨。

在本文中，我们的目标是阐明牛顿-拉夫森方法的几何原理。通过这种阐述，我们旨在为读者提供对其机制的直观理解，并消除与其数学基础相关的潜在复杂性。

随后，为了建立我们讨论的坚实数学框架，我们将深入探讨该方法的数学复杂性，并提供在Python编程语言中的实际实现。

在此演示之后，我们将区分牛顿-拉夫森方法的两个主要应用：根查找和优化。这一区分将明确方法在不同上下文中的实际应用。

最后，我们将对牛顿-拉夫森方法和梯度下降方法进行比较分析，提供对它们各自优缺点的见解。

*如果你对数学概念感兴趣，并希望通过Python快速学习，请查看我的书籍：*

[](https://amzn.to/3QaRkXZ?source=post_page-----d9f7acf1b5ae--------------------------------) [## 用 Python 揭示 70 个数学概念：通过 Python 探索数学的实用指南

### 购买《用 Python 揭示 70 个数学概念：通过 Python 探索数学的实用指南》请访问…

[amzn.to](https://amzn.to/3QaRkXZ?source=post_page-----d9f7acf1b5ae--------------------------------)

# 图形概述

![](../Images/f8924d9d2d1b8c93b8481db19e7caf4e.png)

查找根的迭代过程。图片由作者提供。

基本上，牛顿-拉夫森方法是一种迭代过程，旨在数值确定数学方程的根。其主要目标是确定一个值，记作 `x_root`，使方程 `f(x_root) = 0` 得以满足。需要注意的是，由于其数值性质，通过该方法获得的 `x_root` 值是一个近似值。

该方法的核心原理如下：从初始点 `x_0` 开始，目标是生成一系列值 `x_i`，这些值逐渐逼近所寻求的 `x_root`。为了实现这一点，在 `(x_i, f(x_i))` 点附近通过线性化过程对函数进行局部近似。这种近似通过计算函数在点 `(x_i, f(x_i))` 处的切线来完成。

对于这种局部近似，根的确定是直接的：它对应于该切线与 x 轴的交点。这个交点的横坐标 `x_i+1` 作为根 `x_root` 的更新近似值。

这个迭代过程会不断重复，直到 `f(x)` 的值足够接近零，表明已接近根。上面的图形作为该过程的示意图，展示了每次迭代时的切线及其与 x 轴的交点。

在这个具体的例子中，使用的基础函数是多项式 `(x-6)(x-6)(x-6)`，它在 `x=6` 处具有三重根。显然，经过几次迭代，大约 10 次，该方法会收敛到接近理论根 `x_root=6` 的点。

绘制该图形的代码如下：

显示牛顿-拉夫森方法的连续迭代。代码由作者提供。

按照我通常的做法，我在上述代码中依赖自动微分，特别是使用 JAX 库来有效计算 `f` 的导数。

# 方法的数学推导

在让你感受到牛顿-拉夫森方法的工作方式后，是时候看看这个方法如何从数学上推导出来了。

给定一个函数`f(x)`和一个起始点`x_i`，目的是在该点`(x_i, f(x_i))`对函数进行线性化。这正是我们在前一节中所做的，通过在该点绘制切线。

从形式上讲，这可以表示为`f`在`x_i`处的一阶泰勒展开：

![](../Images/1d9210e6824d2758ebf63045e7bb9004.png)

一阶泰勒展开。作者提供的公式。

该公式给出了`f`在`x_i`附近的线性化公式，其中`delta`是变量。

给定此公式，按照上述几何方法计算`delta`，更新`x_i`，使得该线性化与x轴相交，即：

![](../Images/3919f46e86b5a48ad3fde99abc8ed41b.png)

计算`x_i+1`。作者提供的公式。

# 牛顿-拉夫森方法用于根的识别

正如引言中提到的，牛顿-拉夫森方法可以用来解决两个主要问题：根的查找和函数优化。在本节中，我们将特别关注根的查找。

首先，让我们重新审视根的查找概念。在几何背景下，这本质上是识别一个函数`f`与x轴交点的横坐标`x`。这与本文初始图中的基本概念相符。从代数角度来看，这等同于确定`x`使得`f(x) = 0`。

因此，牛顿-拉夫森方法被设计用来解决这个具体问题：确定函数`f`的曲线与x轴交点的`x`值。

# 牛顿-拉夫森方法用于优化

如前所述，该方法主要解决的问题是根的查找。然而，在许多情况下，牛顿-拉夫森方法并不是用来寻找根，而是用于优化。换句话说，它用于识别`x`的值，使得函数`f`达到最大值或最小值点。

这怎么可能呢？最初，这可能看起来根的查找和优化是完全不同的挑战。然而，它们却是密切相关的。这种联系来源于一个事实，即函数在其斜率符号改变的点达到极值，这意味着其导数为零。因此，寻找函数的极值等同于识别其导数的根。

将牛顿-拉夫森方法应用于这种情况是相对简单的。该过程包括用其导数`f’`替换`f`，然后用其二阶导数`f’’`替换`f’`。

以下代码片段展示了如何调整该方法以最大化高度非线性函数`-(-(x-6)**2 / 3.0 + log(6+x) + 2*sin(x))`：

该代码通过应用牛顿-拉夫森方法来查找函数达到最大值的`x`，并绘制连续探索的点：

![](../Images/bcf303818fe7622d664743e375a19ba2.png)

优化一个明显非线性的函数。作者提供的图像。

# 牛顿-拉夫森方法的优化几何解释

牛顿-拉夫森方法在优化中的适应可以从两种基本方式进行解释。第一种方法涉及将用于根查找的几何解释应用于函数 `f` 的导数 `f'`，可以在本文的早期部分找到详细信息。

第二种更具吸引力的观点认为，在优化的背景下，函数 `f` 不再由直线（即一阶多项式）局部近似，而是由二阶多项式近似。从几何角度来看，这意味着 `f` 的曲线由抛物线近似。在这种情况下，目标不是确定局部近似与 x 轴的交点（如同在根查找中），而是找到该函数的最小值。

正如俗话所说，“一图胜千言”，下图的视觉表示有助于有效地说明这个概念。

![](../Images/de2cf34c666eaec81436d6eb2157fd58.png)

通过拟合抛物线进行优化。图由作者提供。

基本上，算法的工作原理如下：

+   选择一个点

+   在这个点拟合一个抛物线，即一个多项式 `p(x)=ax**2+bx+c`，使其通过同一个点，并且与`f`具有相同的一阶和二阶导数。

+   使用抛物线极值的横坐标 `x` 作为新的起始点

+   迭代

从Python的角度来看，这给出：

牛顿-拉夫森方法的几何再解释。代码由作者提供。

请注意，这种牛顿-拉夫森方法的几何再解释给出的结果与之前的实现完全相同（在此情况下为`7.4074383`），并且收敛速度相同。只是稍微不够高效，因为我们需要计算多项式 `p` 的三个权重。

# 应用条件

牛顿-拉夫森方法是一个非常优雅且强大的方法。然而，在应用于优化时，它需要一些条件才能发挥作用。

首先，优化的函数必须是二次可微的。其次，需要从一个良好的近似开始，以避免局部最小值。

# 牛顿-拉夫森方法不同于梯度下降

另一个非常流行的优化方法是梯度下降。然而，它们在许多方面有所不同。

首先，牛顿-拉夫森方法在应用于优化时要求函数 `f` 是二次可微的。相对而言，梯度下降仅要求一阶导数。

其次，牛顿-拉夫森方法需要的调整较少，因为没有学习率需要配置。新点由抛物线的最小值自动给出。

第三，这种直接估计下一个点的方法，无需设置学习率，确保了更快的收敛。更准确地说，牛顿-拉夫森方法的收敛是二次的，而梯度下降方法的收敛仅是线性的。

[![](../Images/646ded91846ff6aa7fa8814985c9837d.png)](https://www.buymeacoffee.com/guillaumes0)

[https://www.buymeacoffee.com/guillaumes0](https://www.buymeacoffee.com/guillaumes0)

总结来说，本文探讨了牛顿-拉夫森方法这一基本的数值优化技术，重点是其几何解释。方法的优雅和计算能力得到了突出，文章旨在以直观的方式阐明其机制。

牛顿-拉夫森方法被描述为一种求根的迭代过程，其目标是近似一个数学方程的根。核心原则进行了讨论，强调了线性化和切线交点作为关键概念。

文章随后区分了牛顿-拉夫森方法的两个主要应用：求根和优化。求根被解释为寻找函数与x轴的交点，而优化被描述为寻找函数导数为零的极值点。方法在优化中的适应性，使用二次多项式来近似函数，被概述了。

应用牛顿-拉夫森优化方法的条件已被提到，包括函数需要是二次可微的要求，以及从一个好的初始近似值开始的重要性。

最后，文章比较了牛顿-拉夫森方法和梯度下降方法在其微分要求、调节和收敛速度方面的区别。文章总结了牛顿-拉夫森方法在优化中的独特优势。

在即将发布的后续文章中，我们将更详细地探讨牛顿-拉夫森方法在实际应用中的应用。

*如果你对数学概念感兴趣，并且希望通过Python快速学习它们，可以看看我的书：*

[](https://amzn.to/3QaRkXZ?source=post_page-----d9f7acf1b5ae--------------------------------) [## 揭示70个数学概念与Python：通过Python探索数学的实用指南…

### 在…

amzn.to](https://amzn.to/3QaRkXZ?source=post_page-----d9f7acf1b5ae--------------------------------)
