- en: Building Comprehension Pipelines in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-comprehension-pipelines-in-python-ec68dce53d03](https://towardsdatascience.com/building-comprehension-pipelines-in-python-ec68dce53d03)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PYTHON PROGRAMMING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Comprehension pipelines are a Python-specific idea for building pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@nyggus?source=post_page-----ec68dce53d03--------------------------------)[![Marcin
    Kozak](../Images/d7faf62e48ed81dab5d8ad92819fff54.png)](https://medium.com/@nyggus?source=post_page-----ec68dce53d03--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ec68dce53d03--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ec68dce53d03--------------------------------)
    [Marcin Kozak](https://medium.com/@nyggus?source=post_page-----ec68dce53d03--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ec68dce53d03--------------------------------)
    ·12 min read·Feb 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/686b7a1a7f83a53912af9f9378a8391c.png)'
  prefs: []
  type: TYPE_IMG
- en: Comprehension pipelines take you straight to the goal. Photo by [Anika Huizinga](https://unsplash.com/@iam_anih?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Generator pipelines offer a Pythonic way to create software pipelines, that
    is, chains of operations in which each operation but the first one takes the output
    of the previous operation as its input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/building-generator-pipelines-in-python-8931535792ff?source=post_page-----ec68dce53d03--------------------------------)
    [## Building Generator Pipelines in Python'
  prefs: []
  type: TYPE_NORMAL
- en: This article proposes an elegant way to build generator pipelines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/building-generator-pipelines-in-python-8931535792ff?source=post_page-----ec68dce53d03--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: They enable you to apply transforming programming as described by Thomas and
    Hunt in their great book *The Pragmatic Programmer:*
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer?source=post_page-----ec68dce53d03--------------------------------)
    [## The Pragmatic Programmer - Wikipedia'
  prefs: []
  type: TYPE_NORMAL
- en: 'From Wikipedia, the free encyclopedia The Pragmatic Programmer: From Journeyman
    to Master is a book about computer…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: en.wikipedia.org](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer?source=post_page-----ec68dce53d03--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: A typical generator pipeline in Python uses a generator at each step of the
    pipeline. In other words, each step of the pipeline is constructed as a generator.
    Thomas and Hunt discuss pipelines achieved via the pipe operator, available in
    many programming languages. While Python does not have a built-in pipe operator,
    it can be easily created because some operators are available for overloading
    in class definitions. We can see this done in [the](https://github.com/JulienPalard/Pipe)
    `[Pipe](https://github.com/JulienPalard/Pipe)` [Python package](https://github.com/JulienPalard/Pipe),
    which uses the `|` operator.
  prefs: []
  type: TYPE_NORMAL
- en: In [the above-mentioned article](/building-generator-pipelines-in-python-8931535792ff),
    I showed that using generators to create each step of the pipeline can introduce
    a visual clutter that decreases code readability. In addition, when each run of
    a pipeline is fast, this approach shows poor performance. Therefore, I proposed
    an alternative, efficient way of building generator pipelines that is more readable
    than the classical generator pipeline. The method combines function composition
    with a generator. In the future, I will show you how to create pipelines using
    a pipe operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nonetheless, generator expressions are a special case of comprehensions, as
    I wrote in this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/a-guide-to-python-comprehensions-4d16af68c97e?source=post_page-----ec68dce53d03--------------------------------)
    [## A Guide to Python Comprehensions'
  prefs: []
  type: TYPE_NORMAL
- en: Learn the intricacies of list comprehensions (listcomps), set comprehensions
    (setcomps), dictionary comprehensions…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-guide-to-python-comprehensions-4d16af68c97e?source=post_page-----ec68dce53d03--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: So, why should we limit ourselves to generator pipelines? Why not listcomp pipelines
    or dictcomp pipelines or setcomp pipelines?
  prefs: []
  type: TYPE_NORMAL
- en: This question has been bothering me for some time, but I treated it like a tiresome
    fly buzzing over my head and refusing to let me rest, buzzing and buzzing and
    buzzing… Finally, I gave up rejecting the idea and decided at least to bring it
    up for consideration. It was about two months ago, during a pleasant walk with
    my two dogs in the woods. A beautiful winter, snow, frost, strong wind — and me
    and the dogs in the woods, walking one of my favorite paths and thinking (well,
    me, not the dogs) about building pipelines using other comprehensions than generator
    expressions.
  prefs: []
  type: TYPE_NORMAL
- en: This article is the result of this walk. I propose a generalization of generator
    pipelines into what I call *comprehension pipelines*, of which generator pipelines
    are just a specific case.
  prefs: []
  type: TYPE_NORMAL
- en: Example of a generator pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For consistency and clarity, I will use the same example of a generator pipeline
    I used in the previous article. Do note that I revised type annotations a little
    bit. The generator pipeline looked as follows¹:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `get_generator_pipeline()` function — previously named `get_pipeline()`
    — returns a generator pipeline; that is, a generator that lazily (on demand) calculates
    the pipeline for the subsequent elements of the `items` iterable. We can evaluate
    the generator any way we want, e.g., using `list()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If we want to get a list, however, it makes no sense to use a generator expression
    — the corresponding list comprehension would do better! So, why should we use
    a generator pipeline and not a list-comprehension pipeline from the very beginning?
  prefs: []
  type: TYPE_NORMAL
- en: When to use generator pipelines? And when not to?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generator pipelines have one big advantage, and it’s the same as the main advantage
    of generators in general: lazy evaluation. When the `items` iterable is huge,
    or when the the pipeline’s steps produce large objects, a generator pipeline will
    help us avoid problems with running out of memory.'
  prefs: []
  type: TYPE_NORMAL
- en: But what if the `items` iterable is short and the output iterable does not consume
    much memory? Why should we worry about memory when we’re certain there’s nothing
    to worry about? What’s more, we know that a generator expression can be slower
    than the corresponding list comprehension — with one exception, when the number
    (or size) of items is too big to keep and process all of them in the memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following example, quite different from the above one:'
  prefs: []
  type: TYPE_NORMAL
- en: We have `paths`, a list of paths to files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In each step of the pipeline, a text file is read from a path, and the text
    is processed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a result, an iterable of the processed texts is returned.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this case, the output iterable will be far larger than the input iterable.
    Thus, a generator pipeline will work best here when the number of paths is huge
    — because it would be memory-inefficient, if possible at all, to return a long
    list of long texts. We need the pipeline to return a generator; hence, a generator
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine another pipeline. We have the same iterable of paths, but our processing
    of the texts is different. Before, we returned long texts. Now, the only information
    we need from each text is whether or not the word “Python” occurs in a text; hence,
    for each text we will need a Boolean value and nothing more. So, for the list
    of paths, we will get a list of the same length with Boolean values. What’s the
    advantage of the generator pipeline here? None.
  prefs: []
  type: TYPE_NORMAL
- en: 'What’s more, returning just a Boolean value would make little sense, if any:
    it’d be difficult to link a particular value with the corresponding text. Hence,
    it’d be best to return a dictionary with paths as keys and their Boolean values
    as values. This would make a pipeline based on a dictionary. Alternatively, we
    could return a list of paths with the word “Python” in the text; such output,
    however, would omit the other paths, and so we would lose part of the information
    — and sometimes we may need it.'
  prefs: []
  type: TYPE_NORMAL
- en: Building comprehension pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ve finally come to the main topic of this article: comprehension pipelines,
    and how to build them. The examples above showed how we can decide whether or
    not we need a generator pipeline or a different type of pipeline. In addition
    to generator pipelines, we can build'
  prefs: []
  type: TYPE_NORMAL
- en: list-comprehension pipelines, *aka* listcomp pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: set-comprehension pipelines, *aka* setcomp pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dictionary-comprehension pipelines, *aka* dictcomp pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Below, I will rewrite the generator pipeline that uses the `calculate()` function
    using these three other types of comprehension pipelines. For the sake of completeness,
    I will repeat the code of the generator pipeline. I will also change the imports
    from `typing`, as this time we need more types than before, when we created only
    a generator pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: I used a particular version of a dictionary pipeline, but note that we can build
    also other versions, depending on what we want to use as the dictionary’s keys.
    We will see an example in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: Below, we will summarize these basic types of pipelines, including the generator
    pipeline. Do remember that they differ in *the output*, as all of them can take
    the input of the same type — any iterable will do.
  prefs: []
  type: TYPE_NORMAL
- en: Generator pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Takes any iterable (`items`) as input.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns a generator as a pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can use a generator expression of any form and complexity (e.g., it can include
    several levels of `if` filters and `for` loops).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be evaluated on demand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: List-comprehension pipeline, aka listcomp pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Takes any iterable (`items`) as input.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runs a list comprehension as a pipeline and so returns a list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can use a list comprehension of any complexity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is evaluated greedily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set-comprehension pipeline, aka setcomp pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Takes any iterable (`items`) as input.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runs a set comprehension as a pipeline and so returns a set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can use a set comprehension of any complexity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the final output is a set, it will contain unique results. So, if two or
    more items from the iterable return the same output, its repeated instances will
    be skipped.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is evaluated greedily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary-comprehension pipeline, aka dictcomp pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Takes any iterable (`items`) as input.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runs a dictionary comprehension as a pipeline and so returns a dictionary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can use a dictionary comprehension of any complexity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a particular `item`, a key-value pair is returned; the key does not have
    to be `item` — it can be anything that results from `item` or any processing of
    it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the pipeline returns a dictionary, you should use unique keys; otherwise,
    the results for the same keys will be overwritten and the last key-value pair
    will be kept.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is evaluated greedily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here, let’s see how the above pipelines behave. We will do it for the following
    iterable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'I show the examples as doctests. You can read more about this fantastic built-in
    Python package for documentation testing in the following *Towards Data Science*
    article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/python-documentation-testing-with-doctest-the-easy-way-c024556313ca?source=post_page-----ec68dce53d03--------------------------------)
    [## Python Documentation Testing with doctest: The Easy Way'
  prefs: []
  type: TYPE_NORMAL
- en: doctest allows for documentation, unit and integration testing, and test-driven
    development.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/python-documentation-testing-with-doctest-the-easy-way-c024556313ca?source=post_page-----ec68dce53d03--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In the appendix at the end of the article, you will find the whole script for
    this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Generator pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As expected, the generator pipeline returns a generator. So, for the moment,
    we cannot see the output, and to do so, we need to evaluate its values. How to
    do that depends on the pipeline and the problem being solved. Here, we will use
    a good ol’ `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Do remember that `gen_pipeline` is a regular generator, even if created using
    a generator pipeline. As a generator, after evaluating (which we did in the `for`
    loop above), it’s empty. It’s still there, but you cannot use it to see the output
    anymore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Listcomp pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: A listcomp pipeline evaluates the pipeline greedily, so when being created.
    We can already see the results, and of course you can do that as many times as
    you want, unlike the generator pipeline above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like before, we can see that the first two values are exactly the same. This
    should be expected, as the first two elements of `items` are the same… or aren’t
    they? The first one is an integer, `1`, while the second one is a float, `1.0`.
    Theoretically, these are *not* the same objects, as they have different types.
    Python, however, treats them as equal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: So, how will setcomp and dictcomp pipelines behave? We’ll see that below.
  prefs: []
  type: TYPE_NORMAL
- en: Setcomp pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Ha! Note that while `items` contain five elements, the output above contains
    only four. This is not unexpected — as we saw above, Python treats `1` and `1.0`
    as equal, so the results of evaluating `calculate(x)` for these two values are
    the same. And since they are the same, the resulting set contains only one output
    value, that is, `245.77`.
  prefs: []
  type: TYPE_NORMAL
- en: Remember this when using sets and setcomp pipelines. Thus, use setcomp pipelines
    when you want to achieve such behavior — in other words, use this type of pipeline
    when you want to keep only unique results.
  prefs: []
  type: TYPE_NORMAL
- en: Dictcomp pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Like with sets, we got four elements of the resulting dictionary. As you see,
    when you want to use both `1` and `1.0` as keys in a dictionary, they are joined
    into one key, `1` in our case. If this is what you need to get, you’re done here.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if you need the both of them? You can create string keys, for instance.
    Does indeed Python treat `str(1)` and `str(1.0)` as different? Let’s see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Yes, it does! We need to redefine the pipeline function, then:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see this new dictcomp pipeline in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The resulting dictionary has five elements, as we wanted it to have.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, I proposed the generalization of generator pipelines to comprehension
    pipelines. While generator expressions are commonly used to create pipelines,
    the resulting generator pipelines are a specific case of comprehension pipelines.
    When you create a pipeline, consider which type of pipeline best represents your
    needs — and use it. No need to stick to generator pipelines only because the term
    “generator pipelines” is common in the Python community. You’re free to use whatever
    suits your goal.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, we used simple examples. I did this for purpose: this simplicity
    helped us focus on the main topic of this article — comprehension pipelines. In
    the future, I plan to show you more advanced examples representing real-life scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the functions creating the final comprehension — in our examples,
    `get_generator_pipeline()`, `get_listcomp_pipeline()`, `get_setcomp_pipeline()`,
    `get_dictcomp_pipeline()` and `get_dictcomp_pipeline_str()` — create only the
    final step of the pipeline. The actual pipeline, however, is hidden in the function
    that these functions call; in our case, this is the `calculate()` function. Let’s
    return to this function for the moment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Do you see what I mean? Our pipeline consists of the functions `power()`, `double()`,
    `add()`, `power()` again, `add()` again, `round()`, and `add()` once more. This
    is where all the steps of the pipeline are applied, and the functions that create
    the output simply call this function in a way that suits your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that if the basic functions (the first four of the list from the previous
    sentence) do not suit your needs, you can create a new function, as we did above
    when defining the `get_dictcomp_pipeline_str()` function. This example showed
    that we’re not limited to the base versions of comprehension pipelines: you can
    do whatever you want, if only this is correct.'
  prefs: []
  type: TYPE_NORMAL
- en: Footnotes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '¹ If you work with Python in version below 3.10, the code will not work. This
    is because of `typing`’s union operator `|`, which can be used instead of `Union`.
    It was added in Python 3.10\. So, if you have older Python,replace these two lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'with these three lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This will work.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Below, you will find the full code of the script used in this article. As mentioned
    in the above footnote, in older versions of Python, you may need to replace `int
    | float` with `Union[int, float]`, certainly after importing `Union` from `typing`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
