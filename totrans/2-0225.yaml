- en: A Recommendation System For Academic Research (And Other Data Types)!
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-recommendation-system-for-academic-research-and-other-data-types-db5c5a68f1f5](https://towardsdatascience.com/a-recommendation-system-for-academic-research-and-other-data-types-db5c5a68f1f5)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Implementing Natural Language Processing and Graph Theory to compare and recommend
    different types of documents
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ben-mccloskey20.medium.com/?source=post_page-----db5c5a68f1f5--------------------------------)[![Benjamin
    McCloskey](../Images/7118f5933f2affe2a7a4d3375452fa4c.png)](https://ben-mccloskey20.medium.com/?source=post_page-----db5c5a68f1f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----db5c5a68f1f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----db5c5a68f1f5--------------------------------)
    [Benjamin McCloskey](https://ben-mccloskey20.medium.com/?source=post_page-----db5c5a68f1f5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----db5c5a68f1f5--------------------------------)
    ·15 min read·Mar 29, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0dd61847b82293c61235cf84a6d1f226.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Shubham Dhage](https://unsplash.com/@theshubhamdhage?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many of the projects people develop today generally begin with the first crucial
    step: *Active Research*. Investing in what other people have done and building
    on their work is important for your project’s ability to add value. Not only should
    you learn from the strong conclusions of what other people have done, but you
    also will want to figure out what you *shouldn’t do* in your project to ensure
    its success.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'As I worked through my thesis, I started collecting lots of different types
    of research files. For example, I had collections of different academic publications
    I read through as well as excel sheets with information containing the results
    of different experiments. As I completed the research for my thesis, I wondered:
    **Is there a way to create a recommendation system that can compare all the research
    I have in my archive and help guide me in my next project?**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In fact, there is!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Not only would this be for a repository of all of the research you may
    be collecting from various search engines, but it will also work for any directory
    you have containing various types of different documents.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: The Setup
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I developed this recommendation with my team using Python 3\. Shoutout to them
    as well! We achieved something awesome here.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: There are lots of APIs that support this recommendation system and researching
    what each specific API can perform may be beneficial for your own learning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The Hurdle
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One big hurdle I had to overcome was the need for the recommendation machine’s
    ability to compare different types of files. For example, I wanted to see if an
    excel spreadsheet has information similar or is connected to the information within
    a PowerPoint and academic PDF journal. The trick to doing this was reading every
    file type into Python and transforming each object into a single string of words.
    This *normalizes* all the data and allows for the calculation of a similarity
    metric.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: PDF Reading Class
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first class we will look at for this project is the **pdfReader** class
    which is able to format a PDF to be readable in Python. Of all the file formats,
    I would argue that PDFs are one of the most important since many of the journal
    articles downloaded from research repositories such as Google Scholar are in PDF
    format.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Microsoft Powerpoint Reader
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **pptReader** class is capable of reading Microsoft Powerpoint files into
    Python.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Microsoft Word Document Reader
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **wordDocReader** class can be used for reading Microsoft Word Documents
    in Python. It utilizes the [*doc2txt*](https://pypi.org/project/doc2text/) API
    and returns a string of the text/information located within a given word document.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Microsft Excel Reader
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes researchers will include excel sheets of their results with their
    publications. Being able to read the column names, and even the values, could
    help with recommending results that are like what you are searching for. For example,
    what if you were researching information on the past performance of a certain
    stock? Maybe you search for the name and symbol which is annotated in a historical
    performance excel sheet. This recommendation system would recommend the excel
    sheet to you to help with your research.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The **csvReader** class will allow for CSV files to be included in your database
    and to be used in the system’s recommendations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here’s a helpful class. Not many people think about how there is valuable information
    stored within the bodies of PowerPoint presentations. These presentations are
    by and large created to visualize key ideas and information to the audience. The
    following class will help relate any PowerPoints you have in your database to
    other bodies of information in hopes of steering you towards connected pieces
    of work.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The final class for this system is a Microsoft Word document reader. Word documents
    are another valuable source of information. Many people will write reports, indicating
    their findings and ideas in word document format.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: That’s a wrap for the classes used in today’s project. **Please note:** there
    are tons of other file types you can use to enhance your recommendation system.
    A current version of the code being developed will accept images and try to relate
    them to other documents within a database!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Data Processing
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Preprocessing
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s look at how to preprocess this data. This recommendation system was built
    for a repository of academic research, therefore the need to break the text down
    using the preprocessing steps guided by Natural Language Processing (NLP) was
    important.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: The data processing class is simply called *datapreprocessor* and the first
    function within the class is a word parts of speech tagger.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This function tags the parts of speech in a word and will come in handy later
    in the project.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, there is a function that conducts the normal NLP steps many of us have
    seen before. These steps are:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Lowercase each word
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove the punctuation
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove digits (*I only wanted to look at non-numeric information. This step
    could be taken out if desired*)
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stopword removal.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lemmanitizaion. **This is where the get_wordnet_pos() function comes in handy
    for including parts of speech!**
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Next, there is a function to read all of the files into the system.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**As this is the first version of this system, I want to foot stomp that the
    code can be adapted to include many other file types!**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The next function is called the **database_preprocess()** which is used to process
    all of the files within your given database. The input is a list of the files,
    each with its associated string of text (processed already). The strings of text
    are then *vectorized* using **sklearn’s tfidVectorizer.** What is that exactly?
    Basically, it will transform all the text into different feature vectors based
    on the frequency of each given word. We do this so we can look at how closely
    related documents are using similarity formulas relating to vector arithmetic.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The reason a vectorizer is created off of the database is that when a user gives
    a list of terms to search for in the database, those words will be vectorized
    based on their frequency in said database. **This is the biggest weakness of the
    current system. As we increase the size of the database, the time and computational
    allocation needed for calculating similarities will increase and slow down the
    system**. One recommendation given during a quality control meeting was to use
    Reinforcement Learning for recommending different articles of data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Next, we can use an input processor that processes any word provided into a
    vector. This is synonymous to when you type a request into a search engine.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Since all of the information within and given to the database will be vectors,
    we can use **cosine similarity** to compute the angle between the vectors. The
    closer the angle is to 0, the less similar the two said vectors will be.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Once the capability of finding the similarity score between two vectors is done,
    rankings can now be created between the words being searched and the documents
    located within the database.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The vector file list is the list of vectors we created from the files before.
    The query vector is a vector of the words being searched. The file dictionary
    was created earlier which uses file names for the keys and the files’ text as
    values. Similarities are computed, and then a ranking is created favoring the
    most similar pieces of information to the queried words being recommended first.
    Note, what if there are greater than 3 recommendations? Incorporating elements
    of **Networks and Graph Theory** will add an extra level of computational benefit
    to this system and create more confident recommendations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Page Rank Theory
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s take a quick detour and go over the theory of page rank. Don’t get me
    wrong, cosine similarity is a powerful computation for measuring the similarity
    between vectors, put incorporating page rank into your recommendation algorithm
    allows for similarity comparisons across multiple vectors (data within your database).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Page rank was first designed by Larry Page to rank websites and measure their
    importance [1]. The basic idea is that a website can be deemed “more important”
    if more websites are linked to it. Drawing from this idea, a node on a graph can
    be ranked as more important if there is a decrease in the distance of its edge
    to other nodes. The shorter the collective distance a node has compared to other
    nodes in a graph, the more important said node is.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Today we will use one variation of PageRank called *eigenvector centrality*.
    E*igenvector centrality* is like PageRank in that it measures the connections
    between nodes of a graph, assigning higher scores for stronger connections. Biggest
    difference? E*igenvector centrality* will account for the importance of nodes
    connected to a given node to estimate how important that node is. This is synonymous
    with saying, a person who knows lots of important people may be very important
    themselves through these strong relationships. All-in-all, these two algorithms
    are very close in the way they are implemented.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: For this database, after the vectors are computed, they can be placed into a
    graph where their edge distance is determined by their similarity to other vectors.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Okay, now what? We have the recommendations created by using the cosine similarity
    between each data point in the database, and recommendations computed by the eigenvector
    centrality algorithm. Which recommendations should we output? **Both!**
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The final function of this script will weigh the different recommendations produced
    by cosine similarity and eigenvector centrality. Currently, 80% of the weight
    will be given to the recommendations produced by the cosine similarity recommendations,
    and 20% of the weight will be given to eigenvector centrality recommendations.
    The final recommendations can be computed based on these weights and aggregated
    together to produce recommendations that are representative of all the similarity
    computations in the system. The weights can easily be changed by the developer
    to reflect which batch of recommendations they feel are more important.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Example
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's do a quick example with this code. The documents within my database are
    all in the formats previously discussed and pertain to different areas of machine
    learning. More documents in the database are related to *Generative Adversarial
    Networks (GANS),*so I would suspect those to be recommended first when “Generative
    Adversarial Network” is the query term.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Running this block of code produces the following recommendations, along with
    the weight value for each recommendation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '**[(‘GAN_presentation.pptx’, 0.3411272882084124), (‘Using GANs to Augment UAV
    Data_V2.docx’, 0.16293615818015078), (‘GANS_DAY_1.docx’, 0.12546058188955278),
    (‘ml_pdf.pdf’, 0.10864164490536887)]**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try one more. What if I query “Machine Learning” ?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**[(‘ml_pdf.pdf’, 0.31244922151487337), (‘GAN_presentation.pptx’, 0.18170070184645432),
    (‘GANS_DAY_1.docx’, 0.14825501243059303), (‘Using GANs to Augment UAV Data_V2.docx’,
    0.1309153863914564)]**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Aha! As expected, the first document recommended is an introductory brief to
    machine learning! I only used 7 documents for this example, and the more documents
    added, the more recommendations one will receive!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today we looked at how you can create a recommendation system for files you
    collect (especially if you are collecting research for a project). The main feature
    of this system is that it goes one step further in computing the cosine similarity
    of vectors by adopting the eigenvector centrality algorithm for more concise,
    and better recommendations. Try this out today, and I hope it helps you get a
    better understanding of how related the pieces of data you possess are.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '**If you enjoyed today’s reading, PLEASE give me a follow and let me know if
    there is another topic you would like me to explore! If you do not have a Medium
    account, sign up through my link** [**here**](https://ben-mccloskey20.medium.com/membership)
    **(I receive a small commission when you do this)! Additionally, add me on** [**LinkedIn**](https://www.linkedin.com/in/benjamin-mccloskey-169975a8/),
    **or feel free to reach out! Thanks for reading!**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Sources
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[https://www.geeksforgeeks.org/page-rank-algorithm-implementation/](https://www.geeksforgeeks.org/page-rank-algorithm-implementation/)'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Full Code: [https://github.com/benmccloskey/Research_recommend_model/blob/main/app.py](https://github.com/benmccloskey/Research_recommend_model/blob/main/app.py)'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完整代码：[https://github.com/benmccloskey/Research_recommend_model/blob/main/app.py](https://github.com/benmccloskey/Research_recommend_model/blob/main/app.py)
