- en: 6 Ways to Build Best Practices for Data Science Teams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/6-ways-to-build-best-practices-for-data-science-teams-ca9b83fb269d](https://towardsdatascience.com/6-ways-to-build-best-practices-for-data-science-teams-ca9b83fb269d)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Setting standards for high-performing data science teams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://rebeccalvickery.medium.com/?source=post_page-----ca9b83fb269d--------------------------------)[![Rebecca
    Vickery](../Images/89fbce6868afc6c0309f0ebf722034dd.png)](https://rebeccalvickery.medium.com/?source=post_page-----ca9b83fb269d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ca9b83fb269d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ca9b83fb269d--------------------------------)
    [Rebecca Vickery](https://rebeccalvickery.medium.com/?source=post_page-----ca9b83fb269d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ca9b83fb269d--------------------------------)
    ·7 min read·Mar 20, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be348ed520b4d053aaa9e0c6d1e8b9d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Marvin Meyer](https://unsplash.com/@marvelous?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/team?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Data science is a field that combines traditional mathematics and statistics
    with the power of large-scale compute and more modern machine and deep learning
    techniques to generate insights from data.
  prefs: []
  type: TYPE_NORMAL
- en: The data science discipline is complex, experimental by nature and subject to
    a large degree of uncertainty. As with adjacent fields such as software engineering,
    a team of data scientists will need to handle code development in a controlled
    fashion. However in addition to this data scientists also need to handle data
    which is subject to constant change, and perform repeatable experiments such as
    trialling new features for a machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result, it is highly important that whether you are a team of one data
    scientist working alone, or a large team working together, you develop a set of
    best practices. These standards will ensure that:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A single data scientist can reproduce their own experiments, models or insights
    at a later date.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Other data scientists in the team can reproduce all of the above — this is
    especially important if you are maintaining models in production.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Both a single data scientist and other team members can build on existing
    work and are not repeating the same experiments, code, models or analysis.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following article, I will give a fairly opinionated view of how and what
    to use to set best practices for your data science team. Every team is different
    though and so you may want to adapt some or all of this advice to meet the specific
    needs of your own team.
  prefs: []
  type: TYPE_NORMAL
- en: '**This is the second post in my series of articles about leadership in data
    science. The first article is linked below.**'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Learn to be a Data Science Leader**](/learn-to-be-a-data-science-leader-5394425dd097)'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Code standards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: High-quality code ensures that the code your team is writing is easy for others
    to read and understand. This helps enhance the reproducibility and extensibility
    of the work the team are doing.
  prefs: []
  type: TYPE_NORMAL
- en: Code should be clean, well-structured and as modular as possible. It is a good
    idea to opt for a shared coding standard. If your team are working with Python
    the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
    can be a good standard to adopt. Coding styles can be easily enforced via linting
    using tools such as [Pylint](https://readthedocs.org/projects/pylint/) or [Black](https://github.com/psf/black)
    as a standard part of the development process.
  prefs: []
  type: TYPE_NORMAL
- en: A good code standard should include standardised naming conventions and the
    use of doc strings for code documentation. The aim of setting these standards
    should always be to make the code as readable and understandable as possible and
    to reduce the mental overhead for the team. A good coding standard will make the
    team more efficient, for example, performing peer code reviews becomes quicker
    if the code always adheres to an expected style.
  prefs: []
  type: TYPE_NORMAL
- en: Code standards can be automated through [continuous integration](https://www.atlassian.com/continuous-delivery/continuous-integration)
    (CI) checks as part of your GitHub workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Virtual environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A vital part of code reproducibility is embedding processes that make it possible
    for code written by a team member to be run on any other computer or in a cloud
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual environments are a common technique for achieving this. Virtual environments
    record details related to the dependencies (tools) and their versions required
    to run a specific project.
  prefs: []
  type: TYPE_NORMAL
- en: Common tools for creating virtual environments include [Poetry](/managing-data-science-projects-with-poetry-cd3ce2b7913b),
    [Pipenv](https://pipenv.pypa.io/en/latest/) and [Conda](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).
    Although they work in slightly different ways, at a high level, virtual environments
    work by creating and maintaining a file that stores the Python version and all
    the dependencies for a project and then using this file to generate an isolated
    environment on any machine.
  prefs: []
  type: TYPE_NORMAL
- en: If teams can’t reproduce exactly the same environment on different machines
    there is a high chance that in the absence of the original project creator, the
    project code will not be able to run without some effort.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, it is good practice for each project to have its own virtual environment.
    I would recommend deciding on one tool to use across the whole team for consistency
    and to make it easy for anyone in the team to reproduce the environments. For
    example, my own team currently uses Poetry to manage environments across all of
    our projects.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Version control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All data science teams should use a version control tool such as Github to ensure
    that a copy of all work is stored securely outside of your laptop and that changes
    can be made to existing code in a controlled manner.
  prefs: []
  type: TYPE_NORMAL
- en: It is generally a good idea to create a pull request (PR) process to aid collaboration,
    ensure the quality of outputs and share knowledge. In my opinion, PRs should be
    raised regularly throughout the lifecycle of a project and very large PRs should
    be avoided as much as possible. It is good practice to get a second opinion on
    your code and project direction as often as possible to avoid big re-writes or
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, the following standards should be applied to the usage of Github:'
  prefs: []
  type: TYPE_NORMAL
- en: Have a standardised naming convention for branches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Foster the use of clear and descriptive commit messages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set a standard for good [PR etiquette](https://betterprogramming.pub/pull-request-etiquettes-for-reviewer-and-author-f4e80360f92c).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Commit code daily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raise PRs at the end of every two-week period as a minimum, or at the end of
    every sprint if your team is working in sprints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4\. Organised code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A consistent folder structure for all projects across your team will make it
    easier for other team members to quickly read and understand the code for any
    project.
  prefs: []
  type: TYPE_NORMAL
- en: There are many examples of proposed folder structures for data science online.
    Probably the best I have found is the [Cookiecutter](https://drivendata.github.io/cookiecutter-data-science/)
    template. However, in my experience, the folder structure varies widely across
    data science teams as the specific tools, techniques and tasks used heavily influence
    the requirements for a standard structure. My advice, therefore, is to use something
    like Cookiecutter but make adaptions to it to fit the needs of your team.
  prefs: []
  type: TYPE_NORMAL
- en: I am a big believer in the KISS (“keep it simple stupid”) design principle from
    Software Engineering and would personally select the most basic folder structure
    that fits the needs of the team. My team’s folder structure for development work
    is shown below. You can see here that we have selected a simple structure that
    fits our very specific needs but this will not necessarily fit the needs of a
    different team.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f98f59c53c537a42c5aa0eecf58ec6bd.png)'
  prefs: []
  type: TYPE_IMG
- en: My own team’s folder structure. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Good documentation practices are another way to ensure the reproducibility and
    repeatability of your team's work. Documentation should be recorded in a standard
    way and be thorough enough to ensure that someone unfamiliar with the project
    can understand enough to run any code, and reproduce and understand any results.
  prefs: []
  type: TYPE_NORMAL
- en: In general, I would include the following types of documentation in the best
    practices for a data science team.
  prefs: []
  type: TYPE_NORMAL
- en: '**Code documentation:** All code should be accompanied by the minimum amount
    of documentation required to understand and run it. This includes adding doc strings
    to functions, including a README.md file in a project folder or repository and
    adding annotations to code stored within Jupyter Notebooks.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Product documentation:** Product documentation relates to information connected
    to the development, design and results of a project. Typically this documentation
    might take the form of Google docs, Confluence pages or Miro boards. The end users
    of this type of documentation are often non-technical stakeholders and product
    managers.'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Organised notebooks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The nature of Jupyter Notebooks can easily result in messy, hard-to-read and
    non-reproducible code. It is therefore essential to include the same best practices
    as already outlined in this article such as version control and good quality code
    style when working in notebooks. However, it is also important to add some additional
    best practices specifically related to notebook use.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a list of good standards to include in your notebook best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Take advantage of the rich ability to annotate the code in your notebook by
    including titles, section headers, notes, images and diagrams to make the code
    and results as understandable as possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Include all imports in a single cell at the top of the notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that the source of any data used is explicit. This might mean including
    links to cloud storage buckets or SQL queries in the notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep the notebook simple with as few lines of code as possible. Where it makes
    sense to abstract complex code to functions and modules and be sure to remove
    any redundant code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to its complex and experimental nature data science is a field that benefits
    greatly from standardised approaches and best practices for teams. All of the
    best practices listed above are designed to ensure reproducibility, extensibility
    and repeatability for your team's projects.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, although best practices take some time and effort to embed and
    adhere to, they will in the long run save countless hours and effort in trying
    to re-run and understand projects or in repeating work that has already been done.
  prefs: []
  type: TYPE_NORMAL
- en: The best practices I have listed above are by no means exhaustive and depending
    on the type of work and tools that your team use your best practices may differ.
    This article is meant as a getting-started guide to best practices and should
    provide some inspiration to help you to begin to define and set your own standards
    for your team.
  prefs: []
  type: TYPE_NORMAL
- en: I have included a list of useful further reading at the bottom of this article
    if you want to dive deeper into best practices for data science teams.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
- en: Useful resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[*IBM data science best practices*](https://ibm.github.io/data-science-best-practices/model_training.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Google Cloud’s best practices that can improve the life of any developer
    using Jupyter Notebooks*](https://cloud.google.com/blog/products/ai-machine-learning/best-practices-that-can-improve-the-life-of-any-developer-using-jupyter-notebooks)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*4 tools for reproducible Jupyter Notebooks*](/4-tools-for-reproducible-jupyter-notebooks-d7423721bd04)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*A recipe for organising data science projects*](/a-recipe-for-organising-data-science-projects-50a1cc539c69)'
  prefs: []
  type: TYPE_NORMAL
