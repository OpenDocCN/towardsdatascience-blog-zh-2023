- en: Transformer Models For Custom Text Classification Through Fine-Tuning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过微调的变换器模型进行自定义文本分类
- en: 原文：[https://towardsdatascience.com/transformer-models-for-custom-text-classification-through-fine-tuning-3b065cc08da1](https://towardsdatascience.com/transformer-models-for-custom-text-classification-through-fine-tuning-3b065cc08da1)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/transformer-models-for-custom-text-classification-through-fine-tuning-3b065cc08da1](https://towardsdatascience.com/transformer-models-for-custom-text-classification-through-fine-tuning-3b065cc08da1)
- en: A tutorial on how to build a spam classifier (or any other classifier) by fine-tuning
    the DistilBERT model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个关于如何通过微调DistilBERT模型来构建垃圾邮件分类器（或任何其他分类器）的教程
- en: '[](https://skanda-vivek.medium.com/?source=post_page-----3b065cc08da1--------------------------------)[![Skanda
    Vivek](../Images/9d25bee2fb75176ca7f7ea6eff7d7ab5.png)](https://skanda-vivek.medium.com/?source=post_page-----3b065cc08da1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3b065cc08da1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3b065cc08da1--------------------------------)
    [Skanda Vivek](https://skanda-vivek.medium.com/?source=post_page-----3b065cc08da1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://skanda-vivek.medium.com/?source=post_page-----3b065cc08da1--------------------------------)[![Skanda
    Vivek](../Images/9d25bee2fb75176ca7f7ea6eff7d7ab5.png)](https://skanda-vivek.medium.com/?source=post_page-----3b065cc08da1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3b065cc08da1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3b065cc08da1--------------------------------)
    [Skanda Vivek](https://skanda-vivek.medium.com/?source=post_page-----3b065cc08da1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3b065cc08da1--------------------------------)
    ·4 min read·Jan 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3b065cc08da1--------------------------------)
    ·阅读时长 4 分钟·2023年1月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b7152fa9d2fbe16e6c1e4d3080b00560.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7152fa9d2fbe16e6c1e4d3080b00560.png)'
- en: '[Fine-Tuned SMS Spam Classifier Model](https://huggingface.co/skandavivek2/spam-classifier)
    Output | Skanda Vivek'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[微调的SMS垃圾邮件分类器模型](https://huggingface.co/skandavivek2/spam-classifier) 输出 |
    Skanda Vivek'
- en: 'The [DistiBERT mode](https://arxiv.org/abs/1910.01108)l was released by the
    folks at Hugging Face, as a cheaper, faster alternative to large transformer models
    like BERT. It was [originally introduced in a blog post.](https://medium.com/huggingface/distilbert-8cf3380435b5)
    The way this model works — is by using a teacher-student training approach, where
    the “student” model is a smaller version of the teacher model. Then, instead of
    training the student on the ultimate target outputs (basically one-hot encodings
    of the label class), the model is trained on the softmax outputs of the original
    “teacher model”. This is a brilliantly simple idea, and the authors show that:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[DistilBERT模型](https://arxiv.org/abs/1910.01108)由Hugging Face团队发布，是一个较便宜、较快的替代大型变换器模型如BERT的选项。它
    [最初在一篇博客文章中介绍](https://medium.com/huggingface/distilbert-8cf3380435b5)。该模型的工作方式是通过使用教师-学生训练方法，其中“学生”模型是教师模型的较小版本。然后，不是将学生模型训练在最终目标输出（基本上是标签类别的独热编码）上，而是将模型训练在原始“教师模型”的softmax输出上。这是一个极其简单的想法，作者们展示了：'
- en: “it is possible to reduce the size of a BERT model by 40%, while retaining 97%
    of its language understanding capabilities and being 60% faster.”
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “可以在保留97%语言理解能力的同时，将BERT模型的大小减少40%，并且速度提升60%。”
- en: Loading and Preprocessing the Data For Classification
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据加载和分类预处理
- en: In this example, I use the [SMS spam collection dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)
    in the UCI Machine Learning Repository and build a classifier that detects SPAM
    vs HAM (not SPAM). The data contains 5,574 rows of SMS texts that are labeled
    as SPAM or HAM.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我使用了UCI机器学习库中的 [SMS垃圾邮件收集数据集](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)，构建了一个能够检测SPAM与HAM（非SPAM）的分类器。数据包含5574行标记为SPAM或HAM的短信。
- en: First, I make train and validation files from the original csv and use the load_dataset
    function from the Hugging Face datasets library.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我从原始csv文件中制作训练和验证文件，并使用Hugging Face数据集库中的`load_dataset`函数。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The next step is to load in the DistilBERT tokenizer to preprocess the text
    data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是加载DistilBERT分词器以预处理文本数据。
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Training the model
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: Prior to training, you need to map IDs to labels. After this, you need to specify
    the training hyperparameters, call trainer.train() to begin fine-tuning, and push
    the trained model to the Hugging Face hub using trainer.push_to_hub().
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练之前，你需要将ID映射到标签。之后，你需要指定训练超参数，调用trainer.train()开始微调，并使用trainer.push_to_hub()将训练好的模型推送到Hugging
    Face中心。
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: That’s it! As you can see from the Hugging Face hub, the model accuracy is pretty
    good (0.9885)!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！正如你从Hugging Face中心看到的，模型的准确度相当不错（0.9885）！
- en: '[](https://huggingface.co/skandavivek2/spam-classifier?source=post_page-----3b065cc08da1--------------------------------)
    [## skandavivek2/spam-classifier · Hugging Face'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://huggingface.co/skandavivek2/spam-classifier?source=post_page-----3b065cc08da1--------------------------------)
    [## skandavivek2/spam-classifier · Hugging Face'
- en: Edit model card This model is a fine-tuned version of distilbert-base-uncased
    on an unknown dataset.
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编辑模型卡 该模型是对distilbert-base-uncased在未知数据集上进行微调的版本。
- en: huggingface.co](https://huggingface.co/skandavivek2/spam-classifier?source=post_page-----3b065cc08da1--------------------------------)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: huggingface.co](https://huggingface.co/skandavivek2/spam-classifier?source=post_page-----3b065cc08da1--------------------------------)
- en: Model Inference
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型推理
- en: 'Inference is also relatively straightforward. You can see the output through
    running python scripts as below:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 推理也相对简单。你可以通过运行以下Python脚本查看输出：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/78dd23f6739a2b0de887816b84ce25b2.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/78dd23f6739a2b0de887816b84ce25b2.png)'
- en: Sample Fine-Tuned SMS Spam Classifier Model Output | Skanda Vivek
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 样本微调的SMS垃圾邮件分类器模型输出 | Skanda Vivek
- en: 'Or run on the Hugging Face hub:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 或在Hugging Face中心运行：
- en: '![](../Images/7793d9e19f53046bd874784b47b3e1fa.png)![](../Images/b1becd4d222f41d89b5c4f00e68aece3.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7793d9e19f53046bd874784b47b3e1fa.png)![](../Images/b1becd4d222f41d89b5c4f00e68aece3.png)'
- en: Takeaways
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要内容
- en: And that’s it! Hugging Face makes it very easy and accessible to adapt state
    of the art transformer models to custom language tasks as long as you have the
    data!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！Hugging Face使得适应最先进的变换器模型到定制语言任务非常简单易用，只要你有数据！
- en: 'Here is the GitHub link to the code:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码的GitHub链接：
- en: '[](https://github.com/skandavivek/fine-tune-transformer-classifier?source=post_page-----3b065cc08da1--------------------------------)
    [## GitHub - skandavivek/fine-tune-transformer-classifier'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/skandavivek/fine-tune-transformer-classifier?source=post_page-----3b065cc08da1--------------------------------)
    [## GitHub - skandavivek/fine-tune-transformer-classifier'
- en: github.com](https://github.com/skandavivek/fine-tune-transformer-classifier?source=post_page-----3b065cc08da1--------------------------------)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/skandavivek/fine-tune-transformer-classifier?source=post_page-----3b065cc08da1--------------------------------)
- en: If you liked this blog, check out my other blog on [fine-tuning Transformers
    for Question Answering!](https://medium.com/towards-data-science/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇博客，可以查看我关于[针对问题回答微调变换器模型的其他博客！](https://medium.com/towards-data-science/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80)
- en: 'References:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[*https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset*](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[*https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset*](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)'
- en: '*Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml].
    Irvine, CA: University of California, School of Information and Computer Science.*'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Dua, D. 和 Graff, C. (2019). UCI机器学习库 [http://archive.ics.uci.edu/ml]。加州欧文：加州大学信息与计算机科学学院。*'
- en: '*Almeida, T.A., GÃ³mez Hidalgo, J.M., Yamakami, A. Contributions to the Study
    of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM
    Symposium on Document Engineering (DOCENG’11), Mountain View, CA, USA, 2011.*'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Almeida, T.A., GÃ³mez Hidalgo, J.M., Yamakami, A. 对SMS垃圾邮件过滤的研究贡献：新数据集和结果。2011年ACM文档工程研讨会（DOCENG’11）论文集，山景城，加利福尼亚，美国，2011年。*'
- en: '[*https://huggingface.co/docs/transformers/training*](https://huggingface.co/docs/transformers/training)'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[*https://huggingface.co/docs/transformers/training*](https://huggingface.co/docs/transformers/training)'
- en: '*If you are not yet a Medium member and want to support writers like me, feel
    free to sign-up through my referral link:* [*https://skanda-vivek.medium.com/membership*](https://skanda-vivek.medium.com/membership)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你还不是Medium的会员，想要支持像我这样的作者，可以通过我的推荐链接注册：* [*https://skanda-vivek.medium.com/membership*](https://skanda-vivek.medium.com/membership)'
- en: '*For weekly data-based perspectives* [*subscribe here*](https://skandavivek.substack.com/)*!*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*每周的数据视角* [*在这里订阅*](https://skandavivek.substack.com/)*！*'
