# 有指导的迁移学习：如何利用“侦察的力量”提升机器学习表现

> 原文：[https://towardsdatascience.com/guided-transfer-learning-how-to-use-the-power-of-scouts-to-boost-machine-learning-performance-7e478d1ec5e4](https://towardsdatascience.com/guided-transfer-learning-how-to-use-the-power-of-scouts-to-boost-machine-learning-performance-7e478d1ec5e4)

## 对训练神经网络的革命性新方法的独家预览

[](https://katherineamunro.medium.com/?source=post_page-----7e478d1ec5e4--------------------------------)[![Katherine Munro](../Images/8013140495c7b9bd25ef08d712f097bf.png)](https://katherineamunro.medium.com/?source=post_page-----7e478d1ec5e4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7e478d1ec5e4--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7e478d1ec5e4--------------------------------) [Katherine Munro](https://katherineamunro.medium.com/?source=post_page-----7e478d1ec5e4--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7e478d1ec5e4--------------------------------) ·阅读时间 10 分钟·2023年3月27日

--

![](../Images/482d6e71232893524e6b0b5e6d2cf3bd.png)

在这一新提议的技术中，小型“侦察模型”被派遣去探索问题领域，并“反馈”给主要模型。图片由 [@ansgarscheffold](http://twitter.com/ansgarscheffold) 在 Unsplash 上提供。

我的好朋友和谦逊的天才 Dr Danko Nikolić 最近与我分享了一篇未发表的论文，认为我可能会感兴趣。我确实感兴趣了。阅读它让我感觉像是在目睹一个历史时刻，并且我迫不及待地想要分享。幸运的是，Danko 同意了。所以这是我将一种可能革新深度神经网络训练的方法翻译成日常语言的版本。它甚至还没有发布到 arXiv 上（更新：[现在已经发布了！](https://arxiv.org/abs/2303.16154)），但 [NASA 已经在使用它](https://www.linkedin.com/posts/robots-go-mental_nasa-genelab-open-science-for-life-in-space-activity-7041340569012301824-xTk3?utm_source=share&utm_medium=member_desktop)。所以一旦它爆火，记住：你首先在这里听到的。😉

# 从问题开始

我相信你知道：机器学习，尤其是深度神经网络，需要大量的数据、计算能力和模型参数。这使得这些技术只有最富有的公司和研究机构才能使用，因此将开发塑造我们技术未来的AI技术的权力集中在少数人手中。并不酷。

## 为什么会有这个问题

当我们为某个任务训练神经网络时，实际上是在通过成千上万个例子教它如何调整自身的权重和偏差，以便输入网络的信息产生另一种所需的信息输出。这些权重和偏差统称为“参数”，一个网络可以拥有数百万甚至数万亿个这样的参数。由于“参数空间”如此庞大，学习到正确的参数非常困难，因为数量实在太多。

由于无法尝试每种可能的参数值组合，我们尝试做出好的猜测。一个典型的机器学习算法会寻找有关每个参数如何变化的“提示”，然后根据这些提示进行调整，再根据调整的成功程度寻找新的提示。这些算法中最著名的是“梯度下降”。

如果你已经对梯度下降有所了解，可以跳过这一段。否则，你可以将其想象为这样工作：问题空间是一个有丘陵和山谷的地形，而我们是一个在这个地形上滚动的球，试图到达最低的山谷底部。我们称之为“全局最小值”。所以我们的算法会根据周围地面的陡峭程度、倾斜方向等信息来决定滚动的方向。希望它朝着最低的点前进。但也有危险：我们可能会滚入一个“并不是特别低”的沟壑中，并陷入困境。我们称之为“局部最小值”，这是一个不好的位置。

神经网络使用梯度下降来学习解决各种问题。不幸的是，一些研究表明，这些网络的性能提升有限，之后需要再次增加规模和数据，而这种趋势似乎遵循一种“幂律”。简单来说，这意味着“小幅度的‘智能’提升需要大量的资源增加”。反过来说，我们投入这些模型的资源回报正在递减。

## 理论上的希望……和更多的痛苦

理论上，更小的网络也可以完成任务，但必须通过人工构建或由专门为特定任务设计的算法学习。另一方面，梯度下降可以应用于大型模型，学习解决更广泛的问题，但在小模型中找到合适的参数会面临困难。

它之所以感到困难，是因为它无法看到在任何给定的训练周期中对参数的更改将如何影响后续的性能。我们，这个在问题空间中滚动的球，可能会被诱使向右滚动，因为那里地面坡度最陡。但这可能会直接带我们到一个令人害怕的局部最小值！也许继续直行会更好——即使从我们站的位置看起来不那么陡——因为最终会带我们到所有山谷中最深的那个。

梯度下降试图通过增加模型参数的数量来解决这个问题，因为更多的维度只是减少我们陷入困境的统计可能性。然而，更多的参数可能使模型“过拟合”（即记住当前问题的答案，但之后对其他问题的概括能力变得无用）。因此，我们最终不得不增加相应的训练数据，以帮助训练出的模型具有更好的泛化能力。但这种不断增加资源的需求是不可持续的。必须有更好的方法！

# 指导性迁移学习…来拯救！

Nikolić博士和他的同事Davor Andrić及Vjekoslav Nikolić（是的，他们是兄弟！）提出了一个我认为相当巧妙的解决方案。他们将其比作将侦察员送入问题领域，只不过在这里，“侦察员是解决这个领域中更小但相关问题的模型。他们深入探究并带回关于他们成功旅行方向的信息。” 侦察员不太可能陷入局部极小值，因为他们的问题更容易解决。而且由于他们解决的是较小的问题，我们可以提供更多数据给他们工作，这使得他们不容易过拟合。最终，他们将知识转移回主模型。可爱，对吧？

论文中对此的描述最为恰当，所以我将其转述：局部极小值就像山中的湖泊；降雨水仅凭局部视角向下流动，这可能导致其陷入困境。指导性迁移学习（GTL）就像沿着山坡侧行走，而不是直接向最近的山谷下滑。有时山谷是一个陷阱，而侦察员知道这一点。

## 那么它是如何工作的呢？

侦察员被“派遣”去解决比主模型更简单的问题。例如，如果整体任务是将输入分类为十个不同的类别中的一个，那么每个侦察员模型可能会被分配一个只包含这三个类别的数据子集进行分类。简单的问题减少了侦察员模型过拟合的机会，因此，它们代表主模型获得的“知识”更可靠。

降低过拟合风险的另一种策略是给侦察员更多的数据。这也具有类似于预训练的知识迁移好处，我将在下一部分中介绍。

这次侦察任务的结果是所谓的“指导矩阵”，它告诉主模型对于每个参数，这个参数的重要性。一个低值意味着侦察员在该维度（参数）上没有发现太多变化，因此改变它可能对整体解决方案贡献不大。例如，侦察员走了这条路但坡度保持相当平缓，所以他们放弃了。一个大值意味着更戏剧性和潜在有用的变化。例如，一个侦察员走了一条看起来很平坦的小径，然后几乎绊倒在悬崖边缘！很可能向那个方向移动受影响的参数是个好主意，对吧？

这种方法的好处在于，它在数学和实现代码方面都非常简单。基本上，梯度下降始终忙于计算每个参数变化的值，使用它对周围倾斜地形的所有信息。假设参数是一个网络权重w。我们称这种变化的值为Δ_w（其中 _ 表示后续字母是下标），或称为‘delta w’。引导矩阵有一个相应的引导值，称为g_w。因此，*引导*变化Δw_g，就是：

![](../Images/c0b887d357980c29ca1a00280040402f.png)

就这些，我将涵盖的数学就是这些（在论文第5页上还有一点点更多，第7页上作者以非常简单的方式讨论了计算引导矩阵的不同方法。但我给你的已经是理解这个思想所需的所有数学）。代码也同样简单。如果你不是程序员，放心，下面的代码非常简单易懂：

[PRE0]

## 但传统的预训练呢？

GPT-4中的‘PT’代表‘预训练’，所以如果你还不知道，这可是大事。其思想是在某个庞大而通用的数据集和任务上首先训练神经网络，然后在更具体的数据集和任务上进行微调。例如，GPT和其他大型语言模型通常会预训练以预测句子中缺失的单词（即那些被人类操控者随机移除的单词），使用从几乎整个互联网抓取的文本。这使得模型对不同上下文中最常出现的单词有一个相当好的了解（从统计学角度讲，当然不是认知上的）。之后，模型会在实际任务上进行微调，例如问答任务，使用更小且更具体的数据集。从原始任务中获得的一般‘知识’往往能提升下游任务的表现；我们称之为‘迁移学习’。

迁移学习通过预训练有助于应对许多，但不一定全部，可能存在的局部最小值。因此，引导迁移学习通过帮助探索新的问题领域以避免来补充预训练。这两种方法不一定需要结合，但当它们结合时，效果可能会非常显著。

## 听起来不错，但有效吗？

论文首先展示了指导转移学习在‘**一次性学习**’中的好处。这是将一个模型训练成执行一项任务，例如将图像分类为不同类别，然后向其展示一个新类别的单一示例，并期望它能够正确分类更多该类别的示例。作者发现，使用GTL作为预训练的补充可以一致地提高性能，但指导矩阵很快达到了‘帮助’的最大程度，此后添加更多的侦察者或提供更多的数据并没有帮助。好的一面是，这也意味着减少侦察者的数量或训练数据的规模对性能影响不大。

这意味着GTL是一种低成本、稍微有用的技术，特别是在数据有限的情况下（通常会使用一次性学习或少量学习）。而且目前还处于初期阶段：作者目前只尝试了使用单一指导矩阵，但建议其他实现可能会有用，比如根据侦察者从起点移动的距离来创建不同的矩阵。这在直观上是有意义的：主要模型已经有关于其周围环境的信息，我们希望侦察者帮助看到更远的地方，因此如果我们制作多个矩阵，并对那些距离起点更远的矩阵赋予更大的重要性，这可能会帮助算法‘选择’最佳的下一步行动。

![](../Images/97a68cd149c74fb88bd5dc2b43951da3.png)

经作者许可转载：A) 示例一次性学习任务：给出一个示例进行训练，然后必须找到其他相同字符的示例。B) 使用预训练和添加GTL的分类性能示例。

第二个实验涉及‘XOR问题’，也叫‘排他性或’。目标是学习一个将两个输入（x1和x2）映射到一个输出（y）的函数，使得当x1和x2不同时，y = 1（或‘真’），否则y = 0（或‘假’）。使用梯度下降的大型模型通常会在这一挑战中停滞不前，因此Nikolić、Andrić和Nikolić应用了*未经过预训练*的GTL来帮助**避免**这些**局部最小值**。这一方法非常有效，以至于没有观察到停滞现象。

最后的实验解决了“灾难性遗忘”的问题：即神经网络在新任务上训练时，新数据的影响使得所有已学习的权重大幅更新，从而“忘记”了之前学到的内容。Nikolić等人进行了一系列模型重训练：每一步额外的训练持续固定数量的纪元，并基于一个额外的数据点；每个数据点都是已经学习过的类别的新示例。也就是说，这些数据点是顺序学习的，而不是通常的批量学习。在一次私人谈话中，Danko将其比作现实生活：存在一种称为“汽车”的物体类别，而今天你正在驾驶一种特定类型的汽车，比如SUV。即使你现在接触到SUV的特性，也不意味着你会忘记以前接触过的所有其他汽车类型。你的新接触应该增加你对汽车的理解，而不是减少它。

尽管仅仅依靠经典的预训练转移学习无法从这些顺序添加的数据点中受益，但添加GTL却带来了逐步的性能提升，这表明**知识得到了积累**。换句话说，模型对遗忘之前的示例更具鲁棒性，尽管最终还是会发生。作者用常识解释了这一点：在特定的问题空间中，会有一些解决方案既适用于现在学习的示例，*也*适用于之前学习的示例；这些解决方案可能接近于模型开始在新示例上训练时的起始点；没有GTL，模型可能会“偏离”；*有了*GTL，指导矩阵鼓励模型保持在那个有用的邻域。这就像一个侦察员提醒你不要离营地太远。

# 那这在实践中意味着什么？

指导转移学习是一种“学习如何学习”的方法，并不是唯一的方法。其他方法也存在，并且可能会产生更好的结果，但它们往往不可扩展，这可能会使它们失去意义。GTL计算便宜且灵活，这可能使它特别适用于那些已经将所有可用资源榨取出来的模型。大型语言模型和计算机视觉模型（这些模型经常在严格的硬件限制下存在，如嵌入在自动驾驶汽车中）是几个好的例子。

另一方面，如果数据和计算能力非常充足，那么作者承认GTL可能就不再需要了。正如他们所说，它不是万能的，但没有任何单一的机器学习解决方案是万能的。正如实验所示，它对那些即使是资源充足的模型也难以解决的难题仍然充满了希望。

作者计划尝试所有可能的指导矩阵范式，我对此感到乐观。所以，请关注这个领域。
