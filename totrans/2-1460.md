# 三步掌握机器学习：如何高效学习

> 原文：[https://towardsdatascience.com/machine-learning-in-three-steps-how-to-efficiently-learn-it-aefcf423a9e1](https://towardsdatascience.com/machine-learning-in-three-steps-how-to-efficiently-learn-it-aefcf423a9e1)

## 优先考虑预测建模的核心要点，避免让自己不堪重负

[](https://medium.com/@angela.shi?source=post_page-----aefcf423a9e1--------------------------------)[![Angela 和 Kezhan Shi](../Images/a89d678f2f3887c0c2ff3928f9d767b4.png)](https://medium.com/@angela.shi?source=post_page-----aefcf423a9e1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----aefcf423a9e1--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----aefcf423a9e1--------------------------------) [Angela 和 Kezhan Shi](https://medium.com/@angela.shi?source=post_page-----aefcf423a9e1--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----aefcf423a9e1--------------------------------) ·阅读时间 21 分钟·2023年3月3日

--

我观察到两种极端的方法，数据科学家在学习机器学习算法时通常会采用其中一种。第一种方法涉及学习**所有的细节**，并从头开始实现算法，以获得真正的掌握。另一方面，第二种方法则认为计算机会“自动学习”，从而使个人学习算法变得不必要。这使得一些人**仅仅**依赖于如 lazypredict 这样的工具。

在学习机器学习算法时，采取两种极端方法之间的折中方式是现实的。然而，问题依然是，从哪里开始呢？在这篇文章中，我将把机器学习算法分为三类，并提供我个人的意见，告诉你应该从什么开始，以及哪些可以跳过。

# 机器学习算法的复杂性

初学机器学习可能会因为众多可用的算法而感到不知所措。线性回归、支持向量机（SVM）、梯度下降、梯度提升、决策树、LASSO、岭回归、网格搜索等等，这些都是在提问时会想到的算法。

在监督学习领域，这些算法服务于不同的目的，并具有不同的目标。本文将仅讨论监督学习。

为了更好地理解各种技术，按其目标和复杂性级别进行分类可能会有所帮助。通过将这些算法组织成不同的类别和复杂性级别，可以简化这些概念，使其更易于理解。这种方法可以大大提升对机器学习的理解，并帮助识别适合特定任务或目标的最佳技术。

当学生深入机器学习领域时，可能会因其复杂性而感到沮丧。然而，在实践之前并不需要学习或熟悉所有的算法。机器学习领域的不同职位可能需要不同水平的熟练度，缺乏某些方面的知识也是可以接受的。例如，数据科学家、数据分析师、数据工程师和机器学习研究人员对其工作角色的要求各不相同。

对整体过程有广泛的理解可以使机器学习从业者在时间紧迫的情况下跳过某些技术细节，同时仍能全面理解过程。

![](../Images/57f99cc62121b59e1011c724286b6b76.png)

照片由Julio Wolf提供，见[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# 1\. 机器学习算法的细分

## 1.1 模型、训练和调优

“机器学习算法”的范围相当广泛，可以分为三种主要类型的算法：

+   (1) **机器学习模型**，旨在接收输入数据并随后生成预测，如线性回归、SVM、决策树、KNN等。在scikit-learn库中，这些也被称为“**估计器**”。

+   (2) **模型训练/拟合算法**，用于创建或优化模型，也即为特定数据集寻找模型的参数。不同的机器学习模型有其特定的训练算法。虽然**梯度下降**是训练基于数学函数模型的最著名方法，但其他机器学习模型可以使用不同的技术进行训练，我们将在本文后续部分深入探讨这些技术。

+   (3) **超参数调优**，包括寻找机器学习模型的最佳超参数。与训练过程不同，超参数调优过程通常不依赖于机器学习模型。**网格搜索**是这个任务中一种流行且常用的方法，尽管还有其他替代方法，我们将在本文后续部分深入探讨。

## 1.2 机器学习模型的三种类别

第一个方面涉及能够接收数据并根据这些数据生成预测的模型。这些模型可以分为三类：

+   **基于距离**的模型，包括K近邻、线性判别分析和二次判别分析。

+   **基于决策树**的模型，如单棵决策树（用于分类或回归）、随机森林和梯度提升决策树。

+   **基于数学函数**的模型，也称为参数模型，是假设输入和输出之间存在特定函数形式的模型。它们可以进一步分为**线性模型**，如OLS回归、SVM（具有线性内核）、岭回归和LASSO，以及**非线性模型**，如具有非线性内核的SVM和神经网络。

## 1.3 元模型和集成方法

在机器学习中，元模型是一个结合多个单独模型预测以进行更准确预测的模型。它也被称为“堆叠模型”或“超级学习器”。组成元模型的单独模型可以是不同类型的或使用不同算法的，它们的预测通过加权平均或其他技术进行组合。

元模型的目标是通过减少单个模型中可能存在的方差和偏差，提高预测的整体准确性和鲁棒性。它还可以通过捕捉数据中的复杂模式来帮助克服单个模型的局限性。

创建元模型的一个常见方法是使用集成方法，如自助采样、提升或堆叠。

+   自助采样（Bagging），或称自助聚合，是一种在机器学习中用于通过组合在数据集的不同样本上训练的多个模型来减少模型方差的技术。自助采样的想法是生成多个模型，每个模型使用数据的一个子集，然后将它们组合起来，创建一个更强健且不易过拟合的模型。

+   提升：提升是另一种集成方法，它结合多个弱模型来创建一个强模型。与自助采样不同，提升依次训练模型。每个新模型在由先前模型错误分类的数据上进行训练，最终预测通过聚合所有模型的预测来得出。

+   堆叠：堆叠，或称堆叠泛化，是一种元模型集成方法，涉及训练多个基础模型，并使用它们的预测作为更高级模型的输入。高级模型学习如何组合基础模型的预测以进行最终预测。

+   随机森林：它是对自助采样（bagging）的扩展，增加了一层额外的随机性。除了随机抽样数据外，随机森林还会随机选择每次分裂时的特征子集。这有助于减少过拟合，并增加集成中模型的多样性。

集成方法最常应用于决策树，而不是像线性回归这样的线性模型。这是因为决策树比线性模型更容易过拟合，而集成方法通过结合多个模型来帮助减少过拟合。

决策树具有高方差和低偏差，这意味着它们容易对训练数据进行过拟合，从而导致在新数据上的表现较差。集成方法通过聚合多个决策树的预测来解决这个问题，从而得到一个更强健和准确的模型。

另一方面，线性模型如线性回归具有低方差和高偏差，这意味着它们不容易过拟合，但可能会欠拟合训练数据。由于这些模型已经具有低方差，因此集成方法对线性模型的效果不如对决策树的效果明显，因为集成方法在这方面的收益不大。

然而，仍然有一些情况可以将集成方法应用于线性模型。例如，袋装技术中使用的自助聚合技术可以应用于任何类型的模型，包括线性回归。在这种情况下，袋装算法会对训练数据进行采样，并在自助样本上拟合多个线性回归模型，从而得到一个更稳定且更强健的模型。然而，值得注意的是，得到的模型仍然是线性回归模型，而不是一个元模型。

总体而言，尽管集成方法最常用于决策树，但在某些情况下它们也可以与线性模型一起使用。然而，重要的是要记住每种模型的优缺点，并选择适合当前问题的方法。

## 1.4 机器学习算法概述

下图提供了分类为3类的各种机器学习算法的总结。本文的后续部分将更深入地探讨每一类。

![](../Images/54c901c9803cad52e3611de1cc5d8263.png)

机器学习算法概述 — 图片由作者提供

# 2\. 机器学习模型

在这一部分，我们将更详细地观察三种机器学习模型的家族。以下是有关的更详细的计划。

(1) 基于距离的模型

+   基于实例的模型：KNN

+   贝叶斯分类器：LDA，QDA

(2) 基于决策树的模型

(3) 基于数学函数的模型

+   线性模型

+   核方法模型，如核SVM或核岭回归

+   神经网络

+   深度学习模型

## **2.1 基于实例的模型**

第一类机器学习模型是基于距离的模型。这些模型使用数据点之间的距离来进行预测。

最简单且最具代表性的模型是K-最近邻（KNN）。它计算新数据点与数据集中所有现有数据点之间的距离。然后选择K个最近邻，并将新数据点分配给K个邻居中最常见的类别。

在考察k-最近邻（KNN）算法时，可以注意到在训练阶段没有显式构建模型。在KNN中，新的观察值的预测是通过在训练集中找到k个最近邻居，并计算它们目标值的平均值或多数投票来完成的。

与其他在训练过程中拟合模型的算法不同，KNN存储整个训练数据集，只计算新观察值与现有数据集之间的距离来进行预测。因此，KNN可以被视为一种“懒惰学习”算法，因为它在训练阶段不会主动构建模型，而是将决策过程推迟到推理时。

因此，推理/测试阶段可能会很慢。需要注意的是，可以使用更高效的算法，如k-d树。

## 2.2 贝叶斯分类器

**线性判别分析**（LDA）和**二次判别分析**（QDA）是基于距离的模型，它们使用**马氏距离**进行预测。马氏距离是一种测量点与分布之间距离的方法，考虑了变量之间的相关性。

线性判别分析（LDA）假设不同类别的方差相同，而二次判别分析（QDA）假设每个类别的方差不同。这意味着LDA假设所有类别的协方差矩阵相同，而QDA允许每个类别拥有自己的协方差矩阵。

## 2.3 基于决策树的模型

第二类机器学习模型是基于决策树的模型。它们也可以称为基于规则的模型，这意味着模型生成一组规则，用于解释它如何得出决策或预测。

决策树的每个分支代表一个规则或条件，用于确定接下来跟随的数据子集。这些规则通常以简单的if-then语句的形式存在，例如“如果变量X的值大于5，则跟随左分支，否则跟随右分支。”

决策树的最终叶节点表示基于输入变量的值和导致该预测的规则，目标变量的预测类别或值。

决策树的一个优点是它们易于解释和理解，因为规则可以以清晰直观的方式进行可视化和解释。这使得它们在向非技术利益相关者解释预测或决策背后的原因时非常有用。

然而，决策树也容易过拟合，这发生在模型变得过于复杂并过于紧密地拟合训练数据，从而对新数据的泛化能力差。为了解决这个问题，通常将集成方法应用于决策树。

## 2.4 基于数学函数的模型

第三类机器学习模型是基于数学函数的模型。这些模型使用数学函数来建模输入变量和目标变量之间的关系。线性模型，例如普通最小二乘（OLS）回归和具有线性核的支持向量机（SVM）、岭回归和LASSO，假设输入变量和目标变量之间的关系是线性的。非线性模型，例如具有非线性核的SVM和神经网络，可以建模输入变量和目标变量之间更复杂的关系。

对于基于数学函数的模型，例如线性回归或逻辑回归，我们必须定义损失函数。损失函数衡量模型的预测与实际数据的匹配程度。目标是通过调整模型的参数来最小化损失函数。

相对而言，对于基于非数学函数的模型，例如KNN或决策树，我们不需要定义损失函数。相反，我们使用不同的方法，比如在KNN的情况下寻找最近邻，或者在决策树的情况下根据特征值递归地划分数据。

在基于数学函数的模型中，定义适当的损失函数至关重要，因为它决定了模型解决的优化问题。根据具体问题的不同，可以使用不同的损失函数，例如回归问题的均方误差或二分类问题的交叉熵。

值得注意的是，所有线性模型，例如普通最小二乘（OLS）、LASSO、岭回归和具有线性核的支持向量机（SVM），都可以写成线性方程y = wX + b的形式。然而，这些模型之间的区别在于用于估计模型参数w和b的最优值的成本函数。

因此，虽然所有这些模型可以写成相同数学函数的形式，但重要的是要注意成本函数的选择决定了模型的行为和性能。因此，更准确地说，这些模型应该被视为具有不同成本函数的不同模型，而不是相同模型的不同成本函数。

非线性模型是解决复杂机器学习问题的强大工具，而这些问题无法通过线性模型得到充分解决。在实践中，主要有两种方法：核技巧和神经网络。

核技巧是一种有效地实现特征映射的方法，而无需显式计算变换后的特征。相反，它涉及定义一个核函数，用于计算变换特征空间中输入样本对之间的相似性。通过使用核函数，我们可以隐式地将输入数据映射到高维空间，在那里数据可以更容易地被分离和建模。

从这个意义上说，卷积部分可以被看作是一种特征工程，其中模型能够创建出更适合当前任务的新特征。这与传统的特征工程形成对比，后者是人工专家基于领域知识和直觉手动创建新特征。

创建非线性模型的另一种方法是通过使用神经网络。它们由一层层互联的节点或“神经元”组成，每个节点对其输入执行简单的数学操作，并将结果传递给下一层。

神经网络强大的关键在于它们学习输入和输出之间复杂的非线性关系的能力。这是通过在训练过程中调整神经元之间连接的权重来实现的，基于预测输出和实际输出之间的误差。

## 2.5 深度学习模型

深度学习专注于通过多层次的层次结构学习数据表示。由于在计算机视觉、自然语言处理和语音识别等广泛应用中的成功，它近年来变得越来越受欢迎。虽然深度学习模型由于其大量的参数和层次结构可以被认为是复杂的，但确实深度学习的一部分也涉及特征工程。

深度学习模型的一个例子是卷积神经网络（CNN）。在其核心，CNN将一系列滤波器应用于输入图像，每个滤波器寻找特定的特征，如边缘或角落。网络的后续层则利用这些提取的特征来对输入图像进行分类。

从这个角度来看，像CNN这样的深度学习模型可以被认为是特征工程和可训练模型的结合。模型的特征工程方面涉及设计网络的架构以从输入数据中提取有用的特征，而可训练模型则涉及优化网络的参数以适应数据并进行准确的预测。

# 3. 模型训练/拟合

训练机器学习模型的过程是通过向模型展示一组标记示例来教会模型进行预测或决策。这些标记示例，也称为训练数据，由输入特征和输出标签的对组成。

在训练过程中，机器学习模型学习识别输入特征及其对应输出标签中的模式。模型使用特定的算法从训练数据中学习，并调整其内部参数，以提高预测或分类新数据的能力。

一旦模型在标记示例上训练完成，它就可以用于对新的、未见过的数据进行预测或决策。这个过程称为推断或测试。

不同的机器学习模型有不同的训练算法。以下是不同机器学习模型使用的一些训练算法的例子。

## 3.1 基于距离的模型训练

K-最近邻（KNN）：KNN是一种非参数算法，不需要显式的训练。相反，它存储整个训练数据集，并通过基于某种距离度量找到训练数据集中K个最接近的实例来预测新实例的标签。然后，预测基于K个最近邻的多数投票。

线性判别分析（LDA）是一种用于分类任务的监督学习算法。LDA建模每个类别的输入特征分布，并利用这些信息找到一个线性组合的输入特征，最大化类别之间的分离。生成的线性判别函数随后可以用来对新实例进行分类。

LDA的训练过程涉及估计每个类别的输入特征的均值和协方差矩阵。这些估计值然后用来计算类内散布矩阵和类间散布矩阵，这些矩阵用于推导线性判别函数。线性判别函数的数量等于类别数减一。

## 3.2 基于决策树的模型训练

至于决策树，它们使用一种称为递归划分的不同方法进行训练。

递归划分是一种自顶向下的过程，从整个数据集开始，根据一系列规则或条件将其划分为子集。这个划分过程在每个子集上递归重复，直到满足停止准则，通常是当子集变得过小或进一步划分无法改善模型性能时。

划分规则基于数据集的特征或属性，算法在每一步选择提供模型性能最显著提升的特征。划分过程生成树状结构，其中内部节点代表划分条件，叶子节点代表最终预测结果。

在训练过程中，决策树可以使用各种度量标准进行评估，如信息增益或基尼不纯度，以确定最佳的划分标准。一旦树训练完成，可以通过根据输入特征从根节点到适当叶节点的路径来对新的、未见过的数据进行预测。

## 3.3 基于数学函数的模型训练

基于数学函数的模型，也称为参数模型，是假设输入与输出之间存在特定函数形式的模型。

用于优化数学函数模型参数的最基本算法是梯度下降。梯度下降是一种迭代优化算法，从参数值的初始猜测开始，然后根据损失函数对参数的梯度更新参数。这个过程持续进行，直到算法收敛到损失函数的最小值。

对于非凸函数，通常使用随机梯度下降（SGD）代替梯度下降。SGD在每次迭代中随机抽样数据的一个子集来计算梯度，这使得它比梯度下降更快、更高效。

在神经网络中，反向传播用于计算损失函数相对于参数的梯度。反向传播本质上是将微积分的链式法则应用于神经网络表示的复合函数。它允许对网络的每一层有效地计算梯度，这是训练深度神经网络所必需的。

对于深度学习模型，通常使用更高级的优化技术来提高性能。这些技术包括如动量，它帮助算法避免陷入局部最小值，以及自适应学习率方法，它在训练过程中自动调整学习率，以提高收敛速度和稳定性。

总的来说，梯度下降是优化基于数学函数的模型参数的基本算法。对于非凸函数，通常使用随机梯度下降。反向传播用于计算神经网络中的梯度，而更高级的技术常用于深度学习模型。

# 4\. 模型调优

机器学习的第三个方面涉及通过使用网格搜索来优化模型的超参数。超参数是模型的设置或配置，这些设置在训练过程中不会被学习，而必须手动指定。

超参数的例子包括学习率、神经网络中的隐藏层数量和正则化强度。通过使用网格搜索，评估多个超参数组合，以确定模型的最佳配置。

网格搜索是一种用于优化机器学习模型超参数的流行技术。然而，它并不是唯一的方法，还有其他几种替代方案可以用来微调模型的参数。一些最受欢迎的网格搜索替代方法包括：

1.  随机化网格搜索：与网格搜索不同，随机搜索涉及从预定义范围中随机抽样超参数，从而更高效地探索参数空间。

1.  贝叶斯优化：贝叶斯优化使用概率模型通过迭代评估模型的性能和更新超参数的概率分布来寻找最佳的超参数组合。

1.  遗传算法：遗传算法模拟自然选择的过程，通过生成潜在解决方案的种群，评估它们的性能，并选择最适合的个体进行繁殖，从而找到最佳的超参数组合。

1.  基于梯度的优化：基于梯度的优化涉及使用梯度迭代调整超参数，旨在最大化模型的性能。

1.  基于集成的优化：基于集成的优化涉及将多个具有不同超参数的模型结合起来，以创建一个更稳健、更准确的最终模型。

每种替代方案都有其优缺点，最佳方法可能取决于所解决的具体问题、参数空间的大小以及可用的计算资源。

# 5\. 帮助你有效学习机器学习的技巧

现在我们对不同类别的机器学习算法有了大致了解，让我们探索一下创建有效预测模型所需学习的内容。

## 5.1 算法是否太难以学习？

让我们从一些初看起来可能显得复杂的算法开始，这可能会让你认为机器学习是一个具有挑战性的领域。然而，通过将过程分解为三个阶段（模型、拟合和调优），你将能够获得更清晰的理解。

例如，学习支持向量机（SVM）对有志于数据科学的学生来说可能令人畏惧，因为存在大量技术术语，如最优超平面、无约束最小化、对偶性（原始和对偶形式）、拉格朗日乘数、Karush-Kuhn-Tucker条件、二次规划等。然而，重要的是要理解SVM只是一个线性模型，就像OLS回归一样，其方程为 y = wX+b。

虽然上述各种技术用于通过不同方法优化SVM，但至关重要的是不要被技术细节所困扰，而要专注于SVM作为线性模型的基本概念。

如果你有兴趣进一步探讨这个观点，我将会撰写一篇相关的文章。请在评论中告知我。

## 5.2 理解模型

我们讨论了三种类型的机器学习算法——模型、拟合算法和调优算法。在我看来，有志于数据科学的学生应优先理解模型，而不是其他两个步骤。

从这个角度来看，机器学习模型被分类为三种主要类型，有助于理解它们的功能：

1.  基于距离的模型：在这种类型中，KNN不被视为一个适当的模型，因为新观察的距离是直接计算的。在LDA或QDA中，距离是计算到一个分布的。

1.  基于决策树的模型：决策树遵循if-else规则，并形成一组用于决策的规则。

1.  基于数学函数的模型：它们可能不容易理解。然而，这些函数通常很简单。

一旦你对模型的工作原理有了深入理解，模型的拟合和调优可以通过现有的包来完成：对于拟合，流行的scikit-learn库提供了`model.fit`方法，而对于调优，像Optuna这样的工具提供了有效的研究优化技术，使用`study.optimize`。通过专注于理解模型本身，未来的数据科学家可以更好地为成功做好准备。

对于某些单独的模型，如果你采用这种方法，你可以提高对它们的理解。我会写单独的文章，但这里有一些示例：

+   多项式回归是线性回归，在将特征提高到不同的幂之后。

+   线性回归、岭回归、LASSO和SVR是相同的模型，只是基础的成本函数不同。

+   线性回归、逻辑回归和支持向量机（SVM）是相同的模型，只是基础的成本函数不同。在这里你可能会注意到，线性回归是回归器，而逻辑回归和SVM是分类器。嗯，查看SGDClassifier的文档或看看这篇关于[SGDClassifier](https://medium.com/code-like-a-girl/sgdclassifier-with-scikit-learn-untaught-lessons-you-need-to-know-7bf2f56c04dc)的文章吧。

这些[十大最常见却令人困惑的机器学习模型名称](/10-most-common-yet-confusing-machine-learning-model-names-e70595eef514)说明了理解模型并不总是直观的。

## 5.3 可视化模型

可视化可以是理解模型的一个极其有用的工具。在处理机器学习模型时，使用简单的数据集创建可视化可以帮助说明模型是如何创建的以及它们是如何工作的。

这里是我写的一些文章，你可以在下面找到链接。这些文章涵盖了线性回归的可视化，这也适用于岭回归、LASSO和SVM，以及神经网络。此外，还有一篇关于在Excel中实现KNN的文章。

另一种方法是在Excel中实现这些模型，因为它可以提供一种直观的方式来查看数据和模型的输出。

+   [线性回归的可视化](/linear-regression-visualized-and-better-understood-c8f7b9c69810)

+   [神经网络的可视化](https://medium.com/geekculture/a-visual-definition-of-artificial-neural-networks-part-1-24dc5b94958)

+   [决策树回归器的可视化](/decision-tree-regressor-a-visual-guide-with-scikit-learn-2aa9e01f5d7f)

+   [最近邻回归器 — 可视化指南](https://medium.com/towards-data-science/nearest-neighbors-regressors-a-visual-guide-78595b78072e)

+   敬请关注，我会发布更多内容！

![](../Images/20698b15e54fdab9c0ce87e530a62dc0.png)

[线性回归的可视化](/linear-regression-visualized-and-better-understood-c8f7b9c69810) — 图片由作者提供

![](../Images/acd5a0286b2b3d43450d3e604b5d5292.png)

[不同特征尺度下的K最近邻回归器](https://medium.com/towards-data-science/nearest-neighbors-regressors-a-visual-guide-78595b78072e)——图片来源于作者

## 5.4 使用Excel理解拟合过程

理解拟合过程起初可能会感到困难。然而，如果你想学习，就需要从对模型如何工作的扎实理解开始。在这方面，Microsoft Excel是一个特别有帮助的工具。

Excel是一个广泛使用的电子表格程序，可以用来可视化和操作数据。在机器学习的背景下，它可以用来演示简单模型如线性回归的拟合过程。通过使用Excel，你可以逐步看到算法的实际实现。

需要记住的一点是，Excel不是进行机器学习的最有效工具。尽管它可以用来理解简单数据集的拟合过程。

使用Excel理解拟合过程对机器学习初学者来说是一个有用的工具。它提供了一种简单且可访问的方式来可视化算法并查看其工作原理。

我已经写了几篇关于线性回归、逻辑回归和神经网络的梯度下降文章。你可以通过以下链接访问这些文章。

+   [Excel中的**K-最近邻**](/k-nearest-neighbors-in-excel-76edd4102a5b)

+   [在Excel中进行梯度下降的线性回归](/linear-regression-from-scratch-in-excel-3d8192214752)

+   [在Excel中进行梯度下降的逻辑回归](/logistic-regression-with-gradient-descent-in-excel-52a46c46f704)

+   [从零开始在Excel中创建神经网络分类器](/neural-network-from-scratch-in-excel-4774f6131cdb)

+   [Excel中的决策树回归器](/decision-tree-regressor-in-excel-2d29d16df1db)

+   [在Excel中实现KNN](/k-nearest-neighbors-in-excel-76edd4102a5b)

+   [从零开始在Excel中实现K均值算法](/k-means-from-scratch-in-excel-bb60778d186e)

+   [Excel中的反向传播神经网络](https://pub.towardsai.net/building-a-neural-network-with-backpropagation-in-excel-b6c5d41b1c2)

+   敬请关注，更多文章即将发布！

此外，如果你希望获得相应的Excel/Google表格文件，请通过以下链接支持我：[https://ko-fi.com/s/4ddca6dff1](https://ko-fi.com/s/4ddca6dff1)。

![](../Images/4ab61635bd2890369cf005687b74a267.png)

使用Excel进行机器学习算法——图片来源于作者

## 5.5 使用简单数据集进行测试

为了全面理解机器学习算法，从零开始实现它们可以是一个有效的方法。然而，这种方法可能会非常耗时，并且需要较高的技术水平。另一种方法是使用现有的包或库来创建和可视化模型的输出，特别是使用简单的数据集。

利用这些包，你可以轻松地实验不同的参数并测试各种机器学习算法。这种方法有助于你理解算法的内部工作原理，同时也能快速评估它们在特定数据集上的有效性。

通过使用这样的数据集，可以轻松地可视化模型的输入和输出。这反过来允许我们更深入地了解模型如何进行预测。此外，通过更改超参数和模型的其他方面，我们还可以可视化它们对模型预测的影响。

这种方法可以帮助初学者入门机器学习，并对不同算法的工作原理有更好的理解。这是获得实际经验和实验不同模型的绝佳方式，而无需在实现上花费太多时间。

# 6\. 结论

总之，机器学习可以是一个复杂的领域，特别是对于有志成为数据科学家的人员。然而，理解三种主要的机器学习算法——模型、拟合算法和调优算法——并根据它们的目标和复杂性对它们进行分类，可以帮助提供它们工作原理的整体理解。通过优先理解模型、可视化它们，并在像Excel这样的工具中实现它们，我们可以揭示拟合和调优过程的神秘面纱。

持续学习机器学习的不同方面，例如分类与回归、处理缺失值和变量重要性，对于不断加深我们对这一领域的理解至关重要。如果你想了解更多，请查看这篇文章：[监督机器学习算法概述](/overview-of-supervised-machine-learning-algorithms-a5107d036296)。

我写关于机器学习和数据科学的文章，并尝试以清晰的方式简化复杂概念。请通过下面的链接关注我，获取我的文章的全部访问权限：[https://medium.com/@kezhanshi/membership](https://medium.com/@angela.shi/membership)
