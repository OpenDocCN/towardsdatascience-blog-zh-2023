- en: A Deep Dive into the Science of Statistical Expectation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-deep-dive-into-the-science-of-statistical-expectation-9dc0f80bd26](https://towardsdatascience.com/a-deep-dive-into-the-science-of-statistical-expectation-9dc0f80bd26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/3eff4d617150c08e1c79642593c4821e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: '[The White Cliffs of Dover](https://commons.wikimedia.org/wiki/File:White_Cliffs_of_Dover_02.JPG)
    ([CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/deed.en))'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: How we come to expect something, what it means to expect anything, and the math
    that gives rise to the meaning.
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://timeseriesreasoning.medium.com/?source=post_page-----9dc0f80bd26--------------------------------)[![Sachin
    Date](../Images/bd023298b414caf88f79b00ef032d065.png)](https://timeseriesreasoning.medium.com/?source=post_page-----9dc0f80bd26--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9dc0f80bd26--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9dc0f80bd26--------------------------------)
    [Sachin Date](https://timeseriesreasoning.medium.com/?source=post_page-----9dc0f80bd26--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9dc0f80bd26--------------------------------)
    Â·29 min readÂ·Jun 17, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: It was the summer of 1988 when I stepped onto a boat for the first time in my
    life. It was a passenger ferry from Dover, England to Calais, France. I didnâ€™t
    know it then, but I was catching the tail end of the golden era of Channel crossings
    by ferry. This was right before budget airlines and the Channel Tunnel [almost
    kiboshed](https://journals.openedition.org/rhcf/2452) what I still think is the
    best way to make that journey.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: I expected the ferry to look like one of the many boats I had seen in childrenâ€™s
    books. Instead, what I came upon was an impossibly large, gleaming white skyscraper
    with small square windows. And the skyscraper appeared to be resting on its side
    for some baffling reason. From my viewing angle on the dock, I couldnâ€™t see the
    shipâ€™s hull and funnels. All I saw was its long, flat, windowed, exterior. I was
    looking at a horizontal skyscraper.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a46e80475dce15950d57dcd307629a60.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: Photo by [Martin](https://unsplash.com/es/@martinostsee?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Thinking back, itâ€™s amusing to recast my experience in the language of statistics.
    My brain had computed the **expected shape of a ferry** from the data sample of
    boat pictures I had seen. But my sample was hopelessly unrepresentative of the
    population which made the sample mean equally unrepresentative of the population
    mean. I was trying to decode reality using a heavily biased sample mean.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Seasickness
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This trip across the Channel was also the first time I got seasick. They say
    when you get seasick you should go out onto the deck, take in the fresh, cool,
    sea breeze and stare at the horizon. The only thing that really works for me is
    to sit down, close my eyes, and sip my favorite soda until my thoughts drift slowly
    away from the harrowing nausea roiling my stomach. By the way, I am *not* drifting
    slowly away from the topic of this article. Iâ€™ll get right into the statistics
    in a minute. In the meantime, let me explain my understanding of why you get sick
    on a boat so that youâ€™ll see the connection to the topic at hand.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: On most days of your life, you are not getting rocked about on a ship. On land,
    when you tilt your body to one side, your inner ears and every muscle in your
    body tell your brain that you are tilting to one side. Yes, your muscles talk
    to your brain too! Your eyes eagerly second all this feedback and you come out
    just fine. But on a ship, all hell breaks loose on this affable pact between eye
    and ear.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: On a ship, when the sea makes the ship tilt, rock, sway, roll, drift, bob, or
    any of the other things, what your eyes tell your brain can be remarkably different
    than what your muscles and inner ear tell your brain. Your inner ear might say,
    â€œWatch out! You are tilting left. You should adjust your **expectation** of how
    your world will appear.â€ But your eyes are saying, â€œNonsense! The table I am sitting
    at looks perfectly level to me, as does the plate of food resting upon it. The
    picture on the wall of that thing that is screaming also appears straight and
    level. Do *not* listen to the ear.â€
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/80c9fa9c4be9e7621e99eddee08fe456.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: '[The Scream](https://commons.wikimedia.org/wiki/File:Edvard_Munch_-_The_Scream_-_Google_Art_Project.jpg)
    (public domain)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Your eyes could report something even more confusing to your brain, such as
    â€œYeah, you are tilting alright. But the tilt is not as significant or rapid as
    your overzealous inner ears might lead you to believe.â€
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '**Itâ€™s as if your eyes and your inner ears are each asking your brain to create
    two different expectations of how your world is about to change**. Your brain
    obviously cannot do that. It gets confused. And for reasons buried in evolution
    your stomach expresses a strong desire to empty its contents.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s try to explain this wretched situation by using the framework of statistical
    reasoning. This time, weâ€™ll use a little bit of math to aid our explanation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Should you expect to get seasick? Getting into the statistics of seasickness
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Letâ€™s define a [**random variable**](https://medium.com/towards-data-science/the-aspiring-statisticans-introduction-to-random-variables-7b26a057a89a)
    **X** that takes two values: 0 and 1\. **X** is 0 if the signals from your eyes
    **donâ€™t** agree with the signals from your inner ears. **X** is 1 if they **do**
    agree:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f74a9705ed2619d01a6d72cecee0ebd4.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: The random variable **X** (Image by Author)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'In theory, each value of **X** ought to carry a certain probability P(**X**=x).
    The probabilities P(**X**=0) and P(**X**=1) together constitute the [**Probability
    Mass Function**](https://medium.com/towards-data-science/the-aspiring-statisticans-introduction-to-random-variables-7b26a057a89a)
    of **X.** We state it as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/92aeea6f530ff74e1464d4a901681056.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: PMF of X (Image by Author)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: For the overwhelming number of times, the signals from your eyes will agree
    with the signals from your inner-ears. So p is almost equal to 1, and (1 â€” p)
    is a really, really tiny number.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s hazard a wild guess about the value of (1 â€” p). Weâ€™ll use the following
    line of reasoning to arrive at an estimate: According to the United Nations, the
    average life expectancy of humans at birth in 2023 is approximately [73 years](https://population.un.org/wpp/Graphs/Probabilistic/EX/BothSexes/900).
    In seconds, that corresponds to 2302128000 (about 2.3 billion). Suppose an average
    individual experiences seasickness for 16 hours in their lifetime which is 28800
    seconds. Now letâ€™s not quibble about the 16 hours. It is a wild guess, remember?
    So, 28800 seconds gives us a working estimate of (1 â€” p) of 28000/2302128000 =
    0.0000121626 and p=(1 â€”0.0000121626) = 0.9999878374\. So during any second of
    the average personâ€™s life, the **unconditional probability** of their experiencing
    seasickness is only 0.0000121626.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'With these probabilities, weâ€™ll run a simulation lasting 1 billion seconds
    in the lifetime of a certain John Doe. Thatâ€™s about 50% of the simulated life
    of JD. JD prefers to spend most of this time on solid ground. He takes the occasional
    sea-cruise on which he often gets seasick. Weâ€™ll simulate whether J will experience
    sea sickness during each of the 1 billion seconds of the simulation. To do so,
    weâ€™ll conduct 1 billion trials of a [**Bernoulli random variable**](https://en.wikipedia.org/wiki/Bernoulli_distribution)
    having probabilities of p and (1 â€” p). The outcome of each trial will be 1 if
    J gets seasick, or 0 if J doesnâ€™t get seasick. Upon conducting this experiment,
    weâ€™ll get 1 billion outcomes. You too can run this simulation using the following
    Python code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Letâ€™s count the number of outcomes of value 1(=not seasick) and 0(=seasick):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Weâ€™ll print these counts. When I printed them, I got the following values.
    You may get slightly differing results each time you run your simulation:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can now calculate if JD should **expect** to feel seasick during any one
    of those 1 billion seconds.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '**The expectation is calculated as the weighted average of the two possible
    outcomes**:one and zero, the weights being the frequencies of the two outcomes.
    So letâ€™s perform this calculation:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c3267f02e1258237aa5e3bd71a672581.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Expected value of the outcome (Image by Author)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: The expected outcome is 0.999987794 which is practically 1.0\. The math is telling
    us that during any randomly chosen second in the 1 billion seconds in JDâ€™s simulated
    existence, JD should *not* expect to get seasick. The data seems to almost forbid
    it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'Now letâ€™s play with the above formula a bit. Weâ€™ll start by rearranging it
    as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a0311fd355fe26c31fc51889a96f642.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: Expected value of the outcome (Image by Author)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: When rearranged in this manner, we see a delightful sub-structure emerging.
    The ratios in the two brackets represent the probabilities associated with the
    two outcomes, specifically the **sample probabilities** derived from our 1 billion
    strong data sample, rather than the **population probabilities**. They are **sample
    probabilities** because we calculated them using the data from our 1 billion strong
    data sample. Having said that, the values 0.999987794 and 0.000012206 should be
    pretty close to the population values of p and (1 â€” p) respectively.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'By plugging in the probabilities, we can restate the formula for expectation
    as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1cd96f7bb541dc8654287b7d1322f435.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: Expected value of **X** (Image by Author)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we used the notation for expectation, which is E(). Since **X**
    is a Bernoulli(p) random variable, the above formula also shows us how to compute
    the **expected value of a Bernoulli random variable**. The expected value of **X**
    ~ Bernoulli(p) is simply, p.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Of sample means, population means, and a word to make you sound cool
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: E(**X**) is also called the **population mean,** denoted by Î¼, because it uses
    the probabilities p and (1 â€” p) which are the **population** level values of probability.
    These are the â€˜trueâ€™ probabilities that you will observe should you have access
    to the entire population of values, which is practically never. Statisticians
    use the word â€˜**asymptotic**â€™ while referring to these and similar measures. They
    are referred to as asymptotic because their meaning is significant only when something,
    such as the sample size, approaches infinity or the size of the entire population.
    Now hereâ€™s the thing:I think people just like to say â€˜asymptoticâ€™. And I also
    think itâ€™s a convenient cover for the troublesome truth that you can never measure
    the exact value of anything.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: On the bright side, the impossibility of getting your hands on the population
    is â€˜the great levelerâ€™ in the field of statistical science. Whether you are a
    freshly minted graduate or a Nobel laureate in Economics, that door to the â€˜populationâ€™
    remains firmly closed for you. As a statistician, you are relegated to working
    with the sample whose shortcomings you must suffer in silence. But itâ€™s really
    not as bad a state of affairs as it sounds. Imagine what will happen if you started
    to know the exact values of things. If you had access to the population. If you
    can calculate the mean, the median, and the variance with bullseye accuracy. If
    you can foretell the future with pinpoint precision. There will be little need
    to estimate anything. Great big branches of statistics will cease to exist. The
    world will need hundreds of thousands *fewer* statisticians, not to mention data
    scientists. Imagine the impact on unemployment, on the world economy, on world
    peaceâ€¦
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: But I digress. My point is, if **X** is Bernoulli(p), then to calculate E(**X**),
    you canâ€™t use the actual population values of p and (1 â€” p). Instead, you must
    make do with **estimates** of p and (1 â€” p). These estimates, you will calculate
    using not the entire population â€” no chance of doing that. Instead, you will,
    more often than not, calculate them using a modest sized data sample. And so with
    much regret I must inform you that the best you can do is get an **estimate of
    the expected value** of the random variable **X**. Following convention, we denote
    the estimate of p as p_hat (p with a little cap or hat on it) and we denote the
    estimated expected value as E_cap(**X**).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8085cd782b6db1f0f4937721685cef46.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: Estimated expectation of X (Image by Author)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Since E_cap(**X**) uses **sample probabilities**, itâ€™s called the **sample mean.**
    It is denoted by xÌ„ or â€˜x barâ€™. Itâ€™s an x with a bar placed on its head.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: The **population mean** and the **sample mean** are the Batman and Robin of
    statistics.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '*A great deal of Statistics is devoted to calculating the sample mean and to
    using the sample mean as an estimate of the population mean.*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: And there you have it â€” the sweeping expanse of Statistics summed up in a single
    sentence. ğŸ˜‰
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the deep end of expectation
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our thought experiment with the Bernoulli random variable has been instructive
    in that it has unraveled the nature of expectation to some extent. The **Bernoulli
    variable** is a **binary variable,** and it was simple to work with. However,
    the random variables we often work with can take on many different values. Fortunately,
    we can easily extend the concept and the formula for expectation to many-valued
    random variables. Letâ€™s illustrate with another example.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: The expected value of a multi-valued, discrete random variable
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following table shows a subset of a dataset of information about 205 automobiles.
    Specifically, the table displays the number of cylinders within the engine of
    each vehicle.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a7430cfb4cc664b136f8df6f90671c86.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
- en: 'Cylinder counts of automobiles (Data source: [UCI machine learning dataset
    repository](https://archive-beta.ics.uci.edu/dataset/10/automobile) under (CC
    BY 4.0) license) (Image by Author)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Let **Y** be a random variable that contains the number of cylinders of a randomly
    chosen vehicle from this dataset. We happen to know that the dataset contains
    vehicles with cylinder counts of 2, 3, 4, 5, 6, 8, or 12\. So the range of **Y**
    is the set E=[2, 3, 4, 5, 6, 8, 12].
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'Weâ€™ll group the data rows by cylinder count. The table below shows the grouped
    counts. The last column indicates the corresponding **sample** probability of
    occurrence of each count. This probability is calculated by dividing the group
    size by 205:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6073ac7c1be9bcda8410805d6ff14f9.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: Frequency distribution of cylinder counts
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the sample probabilities, we can construct the **Probability Mass Function**
    P(**Y**) for **Y**. If we plot it against **Y**, it looks like this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/98bd65ac868aea5d6e05c3d2a22cc208.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: PMF of **Y** (Image by Author)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'If a randomly chosen vehicle rolls out in front you, what will you **expect**
    its cylinder count to be? Just by looking at the PMF, the number youâ€™ll want to
    guess is 4\. However, thereâ€™s cold, hard math backing this guess. Similar to the
    Bernoulli **X**, you can calculate the expected value of **Y** as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/35afce78379cd7db6a6866dbcd56a407.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: The expected value of **Y** (Image by Author)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: If you calculate the sum, it amounts to 4.38049 which is pretty close to your
    guess of 4 cylinders.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the range of **Y** is the set **E=**[2,3,4,5,6,8,12], we can express
    this sum as a summation over E as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d2d71058987c8bbb924c7e4703cd814.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: Formula for the expected value of the discrete random variable **Y** (Image
    by Author)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: You can use the above formula to calculate the expected value of any [**discrete
    random variable**](https://medium.com/towards-data-science/the-aspiring-statisticans-introduction-to-random-variables-7b26a057a89a)whose
    range is the set **E**.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: The expected value of a continuous random variable
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are dealing with a continuous random variable, the situation changes
    a bit, as described below.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s return to our dataset of vehicles. Specifically, letâ€™s look at the lengths
    of vehicles:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb6db24d821ca585035b737ca9ab9a18.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: 'Lengths of automobiles (Data source: [UCI machine learning dataset repository](https://archive-beta.ics.uci.edu/dataset/10/automobile)
    under (CC BY 4.0) license) (Image by Author)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Suppose **Z** holds the length in inches of a randomly selected vehicle. The
    range of **Z** is no longer a discrete set of values. Instead, itâ€™s a subset of
    the set **â„** of real numbers. Since lengths are always positive, itâ€™s the set
    of all positive real numbers, denoted as **â„**>0.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the set of all positive real numbers has an (uncountably) infinite number
    of values, itâ€™s meaningless to assign a probability to an individual value of
    **Z**. If you donâ€™t believe me, consider a quick thought experiment: Imagine assigning
    a positive probability to each possible value of **Z**. Youâ€™ll find that the probabilities
    will sum to infinity which is absurd. So the probability P(**Z**=z) simply does
    not exist. Instead, you must work with the **Probability Density function** f(**Z**=z)
    which assigns a **probability density** to different values of **Z**.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: We previously discussed how to calculate the expected value of a discrete random
    variable using the Probability Mass Function.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d2d71058987c8bbb924c7e4703cd814.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: Formula for the expected value of the discrete random variable **Y** (Image
    by Author)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Can we repurpose this formula for continuous random variables? The answer is
    yes. To know how, imagine yourself with an electron microscope.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Take that microscope and focus it on the range of **Z** which is the set of
    all positive real numbers (**â„**>0). Now, zoom in on an impossibly tiny interval
    (z, z+Î´z], within this range. At this microscopic scale, you might observe that,
    *for all practical purposes* (now, isnâ€™t *that* a helpful term), the probability
    density f(**Z**=z) is constant across Î´z. Consequently, the product of f(**Z**=z)
    and Î´z can approximate the **probability** that a randomly selected vehicleâ€™s
    length falls within the open-close interval (z, z+Î´z].
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'Armed with this approximate probability, you can approximate the expected value
    of **Z** as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0ba4c1d7a434b139c2b79d518fc16508.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: An approximate evaluation of E(**Z**) when **Z** is continuous (Image by Author)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice how we pole vaulted from the formula for E(**Y**) to this approximation.
    To get to E(**Z**) from E(**Y**), we did the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: We replaced the discrete y_i with the real-valued z_i.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We replaced P(**Y**=y) which is the PMF of **Y**, with f(**Z**=z)Î´z which is
    the approximate probability of finding z in the microscopic interval (z, z+Î´z].
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of summing over the discrete, finite range of **Y** which is **E**,
    we summed over the continuous, infinite range of **Z** which is **â„**>0.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we replaced the equals sign with the approximation sign. And therein
    lies our guilt. We cheated. We sneaked in the probability f(**Z**=z)Î´z which is
    as an approximation of the exact probability P(**Z**=z). We cheated because the
    exact probability, P(**Z**=z), cannot exist for a continuous **Z**. We must make
    amends for this transgression, which is exactly what weâ€™ll do next.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We now execute our master stroke, our piÃ¨ce de rÃ©sistance, and in doing so,
    we redeem ourselves.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Since **â„**>0 is the set of positive real numbers, there are an infinite number
    of microscope intervals of size Î´z in **â„**>0\. Therefore, the summation over
    **â„**>0 is a summation over an infinite number of terms. This fact presents us
    with the perfect opportunity to replace the approximate summation with an *exact
    integral*, as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/60118e6dce3a418709f15c705a54055d.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
- en: The expected value of **Z** (Image by Author)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: In general, if **Z**â€™s range is the real valued interval [a, b], we set the
    limits of the definite integral to a and b instead of 0 and âˆ.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: If you know the PDF of **Z** and if the integral of z times f(**Z**=z) exists
    over [a, b], you will solve the above integral and get E(**Z**) for your troubles.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'If **Z** is uniformly distributed over the range [a, b], its PDF is as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5248effc78a35c7b8d92cdafa7e1c75e.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: PDF of Z ~ Uniform(a, b) (Image by Author)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: If you set a=1 and b=5,
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: f(**Z**=z) = 1/(5â€“1) = 0.25.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'The probability density is a constant 0.25 from **Z**=1 to **Z**=5 and it is
    zero everywhere else. Hereâ€™s how the PDF of **Z** looks like:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/253cf2bb7bbae91430351e189bcfa41f.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: PDF of Z ~ Uniform(1, 5) (Image by Author)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Itâ€™s basically a continuous flat, horizontal line from (1,0.25) to (5,0.25)
    and itâ€™s zero everywhere else.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, if the probability density of **Z** is uniformly distributed over
    the interval [a, b], the PDF of **Z** is 1/(b-a) over [a, b], and zero elsewhere.
    You can calculate E**(Z)** using the following procedure:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6732f0ffcefb8c7ab9c2a9d45ce2c7eb.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: Procedure for calculating the expected value of a continuous random variable
    that is uniformly distributed over the interval [a, b] (Image by Author)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: If a=1 and b=5, the mean of **Z** ~ Uniform(1, 5) is simply (1+5)/2 = 3\. That
    agrees with our intuition. If each one of the infinitely many values between 1
    and 5 is equally likely, weâ€™d expect the mean to work out to the simple average
    of 1 and 5.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Now I hate to deflate your spirits but in practice, you are more likely to spot
    double rainbows landing on your front lawn than come across continuous random
    variables for which you will use the integral method to calculate their expected
    value.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b6c6056ea185c5e8d5fa0e45459990a.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: '[A double rainbow](https://commons.wikimedia.org/wiki/File:Double_rainbow_Hertfordshire_England.jpg)
    ([CC BY-SA 2.0](https://creativecommons.org/licenses/by-sa/2.0/deed.en))'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: You see, delightful looking PDFs that can be integrated to get the expected
    value of the corresponding variables have a habit of ensconcing themselves in
    end-of-the-chapter exercises of college textbooks. They are like house cats. They
    donâ€™t â€˜do outsideâ€™. But as a practicing statistician, â€˜outsideâ€™ is where you live.
    Outside, you will find yourself staring at data samples of continuous values like
    lengths of vehicles. To model the PDF of such real-world random variables, you
    are likely to use one of the well-known continuous functions such as the Normal,
    the Log-Normal, the Chi-square, the Exponential, the Weibull and so on, or a mixture
    distribution, i.e., whatever seems to best fit your data.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šå‘ç°ï¼Œçœ‹ä¼¼ç²¾ç¾çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰é€šå¸¸ä¼šè¢«åµŒå…¥åˆ°å¤§å­¦æ•™ç§‘ä¹¦çš„ç« èŠ‚æœ«å°¾ç»ƒä¹ ä¸­ã€‚å®ƒä»¬å°±åƒå®¶çŒ«ä¸€æ ·ï¼Œä¸â€œå‡ºé—¨â€ã€‚ä½†ä½œä¸ºä¸€ä¸ªå®è·µä¸­çš„ç»Ÿè®¡å­¦å®¶ï¼Œâ€œå¤–é¢â€å°±æ˜¯ä½ ç”Ÿæ´»çš„åœ°æ–¹ã€‚åœ¨å¤–é¢ï¼Œä½ ä¼šå‘ç°è‡ªå·±é¢å¯¹ç€è¿ç»­å€¼çš„æ•°æ®æ ·æœ¬ï¼Œæ¯”å¦‚è½¦è¾†çš„é•¿åº¦ã€‚ä¸ºäº†å¯¹è¿™äº›çœŸå®ä¸–ç•Œçš„éšæœºå˜é‡è¿›è¡Œå»ºæ¨¡ï¼Œä½ å¾ˆå¯èƒ½ä¼šä½¿ç”¨ä¸€äº›è‘—åçš„è¿ç»­å‡½æ•°ï¼Œä¾‹å¦‚æ­£æ€åˆ†å¸ƒã€å¯¹æ•°æ­£æ€åˆ†å¸ƒã€å¡æ–¹åˆ†å¸ƒã€æŒ‡æ•°åˆ†å¸ƒã€å¨å¸ƒå°”åˆ†å¸ƒç­‰ç­‰ï¼Œæˆ–è€…æ··åˆåˆ†å¸ƒï¼Œå³æœ€é€‚åˆä½ æ•°æ®çš„æ¨¡å‹ã€‚
- en: 'Here are a couple of such distributions:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰å‡ ä¸ªè¿™æ ·çš„åˆ†å¸ƒï¼š
- en: '![](../Images/115e6d34afe08ba1592a0b673c2f4488.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/115e6d34afe08ba1592a0b673c2f4488.png)'
- en: The PDFs and the expected values of continuous random variables that are Normally
    distributed and Chi-square distributed (Image by Author)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£æ€åˆ†å¸ƒå’Œå¡æ–¹åˆ†å¸ƒçš„è¿ç»­éšæœºå˜é‡çš„PDFå’ŒæœŸæœ›å€¼ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: 'For many commonly used PDFs, someone has already taken the trouble to derive
    the mean of the distribution by integrating ( x times f(x) ) just like we did
    with the Uniform distribution. Here are a couple of such distributions:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè®¸å¤šå¸¸ç”¨çš„PDFï¼Œå·²ç»æœ‰äººèŠ±è´¹å¿ƒåŠ›é€šè¿‡ç§¯åˆ†ï¼ˆx ä¹˜ä»¥ f(x)ï¼‰æ¥æ¨å¯¼åˆ†å¸ƒçš„å‡å€¼ï¼Œå°±åƒæˆ‘ä»¬å¯¹å‡åŒ€åˆ†å¸ƒæ‰€åšçš„é‚£æ ·ã€‚è¿™é‡Œæœ‰å‡ ä¸ªè¿™æ ·çš„åˆ†å¸ƒï¼š
- en: '![](../Images/2024cd655ed11336435e62e2eadbfe2f.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2024cd655ed11336435e62e2eadbfe2f.png)'
- en: The PDFs and the expected values of continuous random variables that are Exponentially
    distributed and Gamma distributed
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡æ•°åˆ†å¸ƒå’Œä¼½é©¬åˆ†å¸ƒçš„è¿ç»­éšæœºå˜é‡çš„PDFå’ŒæœŸæœ›å€¼
- en: Finally, in some situations, actually in many situations, real life datasets
    exhibit patterns that are too complex to be modeled by any one of these distributions.
    Itâ€™s like when you come down with a virus that mobs you with a horde of symptoms.
    To help you overcome them, your doctor puts you on drug cocktail with each drug
    having a different strength, dosage, and mechanism of action. When you are mobbed
    with data that exhibits many complex patterns, you must deploy a small army of
    probability distributions to model it. Such a combination of different distributions
    is known as a [**mixture distribution**](https://en.wikipedia.org/wiki/Mixture_model).
    A commonly used mixture is the potent [**Gaussian Mixture**](https://en.wikipedia.org/wiki/Mixture_model)
    which is a weighted sum of several Probability Density Functions of several normally
    distributed random variables, each one having a different combination of mean
    and variance.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œåœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œå®é™…ä¸Šæ˜¯è®¸å¤šæƒ…å†µä¸‹ï¼Œç°å®ç”Ÿæ´»ä¸­çš„æ•°æ®é›†è¡¨ç°å‡ºè¿‡äºå¤æ‚çš„æ¨¡å¼ï¼Œæ— æ³•ç”¨ä»»ä½•ä¸€ä¸ªåˆ†å¸ƒæ¥å»ºæ¨¡ã€‚è¿™å°±åƒä½ æ„ŸæŸ“äº†ä¸€ç§ç—…æ¯’ï¼Œå¸¦æ¥äº†ä¸€å †ç—‡çŠ¶ã€‚ä¸ºäº†å¸®åŠ©ä½ å…‹æœè¿™äº›ç—‡çŠ¶ï¼Œä½ çš„åŒ»ç”Ÿä¼šç»™ä½ å¼€ä¸€ç³»åˆ—è¯ç‰©ï¼Œæ¯ç§è¯ç‰©çš„å¼ºåº¦ã€å‰‚é‡å’Œä½œç”¨æœºåˆ¶éƒ½ä¸åŒã€‚å½“ä½ é¢å¯¹çš„æ•°æ®å±•ç°å‡ºè®¸å¤šå¤æ‚çš„æ¨¡å¼æ—¶ï¼Œä½ å¿…é¡»åŠ¨ç”¨ä¸€å°æ”¯æ¦‚ç‡åˆ†å¸ƒçš„â€œå†›é˜Ÿâ€æ¥è¿›è¡Œå»ºæ¨¡ã€‚è¿™ç§ä¸åŒåˆ†å¸ƒçš„ç»„åˆè¢«ç§°ä¸º[**æ··åˆåˆ†å¸ƒ**](https://en.wikipedia.org/wiki/Mixture_model)ã€‚ä¸€ç§å¸¸ç”¨çš„æ··åˆåˆ†å¸ƒæ˜¯å¼ºå¤§çš„[**é«˜æ–¯æ··åˆæ¨¡å‹**](https://en.wikipedia.org/wiki/Mixture_model)ï¼Œå®ƒæ˜¯å¤šä¸ªæ­£æ€åˆ†å¸ƒéšæœºå˜é‡çš„å‡ ä¸ªæ¦‚ç‡å¯†åº¦å‡½æ•°çš„åŠ æƒå’Œï¼Œæ¯ä¸ªéšæœºå˜é‡å…·æœ‰ä¸åŒçš„å‡å€¼å’Œæ–¹å·®ç»„åˆã€‚
- en: 'Given a sample of real valued data, you may find yourself doing something dreadfully
    simple: you will take the average of the continuous valued data column and anoint
    it as the sample mean. For example, if you calculate the average length of automobiles
    in the autos dataset, it comes to 174.04927 inches, and thatâ€™s it. All done. But
    that is not it, and all is not done. For there is one question you still have
    to answer.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šä¸€ä¸ªçœŸå®å€¼æ•°æ®çš„æ ·æœ¬ï¼Œä½ å¯èƒ½ä¼šå‘ç°è‡ªå·±åœ¨åšä¸€äº›éå¸¸ç®€å•çš„äº‹æƒ…ï¼šä½ å°†è®¡ç®—è¿ç»­å€¼æ•°æ®åˆ—çš„å¹³å‡å€¼ï¼Œå¹¶å°†å…¶ç§°ä¸ºæ ·æœ¬å‡å€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ è®¡ç®—æ±½è½¦æ•°æ®é›†ä¸­æ±½è½¦çš„å¹³å‡é•¿åº¦ï¼Œå®ƒä¼šæ˜¯174.04927è‹±å¯¸ï¼Œä»…æ­¤è€Œå·²ã€‚å°±è¿™ä¹ˆå®Œæˆäº†ã€‚ä½†æ˜¯ï¼Œè¿™è¿˜ä¸æ˜¯å…¨éƒ¨ï¼Œä½ è¿˜æœ‰ä¸€ä¸ªé—®é¢˜éœ€è¦å›ç­”ã€‚
- en: How good is your sample mean? Getting a feel for its accuracy
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½ çš„æ ·æœ¬å‡å€¼æœ‰å¤šå‡†ç¡®ï¼Ÿæ„Ÿå—å®ƒçš„å‡†ç¡®æ€§
- en: 'How do you know how accurate an estimate of the population mean is your sample
    mean? While gathering the data, you may have been unlucky, or lazy, or â€˜data-constrainedâ€™
    (which is often an excellent euphemism for good-old laziness). Either way, you
    are staring at a sample that is not **proportionately random**. It does not proportionately
    represent the different characteristics of the population. Letâ€™s take the example
    of the autos dataset: you may have collected data for a large number of medium-sized
    cars, and for too few large cars. And stretch-limos may be completely missing
    from your sample. As a result, the mean length you calculate will be excessively
    biased toward the mean length of only the medium-sized cars in the population.
    Like it or not, you are now working on the belief that practically everyone drives
    a medium-sized car.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: To thine own self be true
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If youâ€™ve gathered a heavily biased sample and you donâ€™t know it or you donâ€™t
    care about it, then may heaven help you in your chosen career. But if you are
    willing to entertain the *possibility* of bias and you have some clues on what
    kind of data you may be missing (e.g. sports cars), then statistics will come
    to your rescue with [powerful mechanisms to help you **estimate this bias**](https://medium.com/towards-data-science/what-happens-when-you-omit-important-variables-from-your-regression-model-966830590d53).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, no matter how hard you try you will never, ever, be able to gather
    a perfectly balanced sample. It will *always* contain biases because the exact
    proportions of various elements within the population remain forever inaccessible
    to you. Remember that door to the population? Remember how the sign on it always
    says â€˜CLOSEDâ€™?
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Your most effective course of action is to gather a sample that contains roughly
    the same fractions of all the things that exist in the population â€” the so-called
    **well-balanced sample**. The mean of this well-balanced sample is the best possible
    sample mean that you can set sail with.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: But the laws of nature donâ€™t always take the wind out of statisticiansâ€™ sailboats.
    There is a magnificent property of nature expressed in a theorem called the **Central
    Limit Theorem** (CLT). You can use the CLT to determine how well your sample mean
    estimates the population mean.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The CLT is not a silver bullet for dealing with badly biased samples. If your
    sample predominantly consists of mid-sized cars, you have effectively redefined
    your notion of the population. If you are *intentionally* studying only mid-sized
    cars, you are absolved. In this situation, feel free to use the CLT. It will help
    you estimate how close your sample mean is to the population mean of *mid-sized
    cars*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if your existential purpose is to study the entire population
    of vehicles ever produced, but your sample contains mostly mid-sized cars, you
    have a problem. To the student of statistics, let me restate that in slightly
    different words. If your college thesis is on how often pets yawn but your recruits
    are 20 cats and your neighborâ€™s Poodle, then CLT or no CLT, no amount of statistical
    wizardry will help you assess the accuracy of your sample mean.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: The essence of the CLT
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A comprehensive understanding of CLT is the stuff for another article but the
    essence of what it states is the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: If you draw a random sample of data points from the population and calculate
    the mean of the sample, and then repeat this exercise many times youâ€™ll end up
    withâ€¦many different sample means. Well, duh! But something astonishing happens
    next. If you plot a frequency distribution of all these sample means, youâ€™ll see
    that they are *always* normally distributed. Whatâ€™s more, the mean of this normal
    distribution is always the mean of the population you are studying. It is this
    eerily captivating facet of our universeâ€™s personality that the Central Limit
    Theorem describes using (what else?) the language of math.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f1242dd21de974c56c4c15dc71bb9b2.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: The sample mean length of 174.04927 inches marked off on a normally distributed
    **Z** that has a hypothetical population mean of 180 inches (Image by Author)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s go over how to use the CLT. Weâ€™ll begin as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the sample mean **Z**_bar from just one sample, weâ€™ll state that the
    probability of the population mean Î¼ lying in the interval [Î¼_low, Î¼_high] is
    (1 â€” Î±):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8ea79e6ade108b268bdac4f94671a1a7.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: The lower and upper confidence bounds for the population mean (Image by Author)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: You may set Î± to any value from 0 to 1\. For instance, If you set Î± to 0.05,
    you will get (1 â€” Î±) as 0.95, i.e. 95%.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'And for this probability (1 â€” Î±) to hold true, the bounds Î¼_low and Î¼_high
    should be calculated as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/831c3bb8cce18e67a2eea48eac6f9e89.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: The lower and upper bounds for the population mean (Image by Author)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: In the above equations, we know what are **Z**_bar, Î±, Î¼_low, and Î¼_high. The
    rest of the symbols deserve some explanation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The variable s is the standard deviation of the data *sample*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: N is the sample size.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Now we come to z_Î±/2.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'z_Î±/2 is a value you will read off on the X-axis of the PDF of the standard
    normal distribution. The standard normal distribution is the PDF of a normally
    distributed continuous random variable that has a zero mean and a standard deviation
    of one. z_Î±/2 is the value on the X-axis of that distribution for which the area
    under the PDF lying to the left of that value is (1 â€” Î±/2). Hereâ€™s how this area
    looks like when you set Î± to 0.05:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2639cdecfcb11717eb8bd76ff72c91a4.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: Area under the PDF to he left of a certain value X on the X-axis. In this case,
    x=1.96 (Image by Author)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: The blue colored area is calculated as (1 â€” 0.05/2) = 0.975\. Recall that the
    total area under any PDF curve is always 1.0.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: è“è‰²åŒºåŸŸè®¡ç®—ä¸º (1 â€” 0.05/2) = 0.975ã€‚è¯·è®°ä½ï¼Œä»»ä½• PDF æ›²çº¿ä¸‹çš„æ€»é¢ç§¯å§‹ç»ˆä¸º 1.0ã€‚
- en: To summarize, once you have calculated the mean (**Z**_bar) from just one sample,
    you can build bounds around this mean such that the probability that the population
    mean lies within those bounds is a value of your choice.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“ä¸€ä¸‹ï¼Œä¸€æ—¦ä½ ä»ä¸€ä¸ªæ ·æœ¬ä¸­è®¡ç®—å‡ºå‡å€¼ (**Z**_bar)ï¼Œä½ å¯ä»¥å›´ç»•è¿™ä¸ªå‡å€¼å»ºç«‹ç•Œé™ï¼Œä½¿å¾—æ€»ä½“å‡å€¼è½åœ¨è¿™äº›ç•Œé™å†…çš„æ¦‚ç‡æ˜¯ä½ é€‰æ‹©çš„å€¼ã€‚
- en: 'Letâ€™s reexamine the formulae for estimating these bounds:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é‡æ–°æ£€æŸ¥ä¼°è®¡è¿™äº›ç•Œé™çš„å…¬å¼ï¼š
- en: '![](../Images/831c3bb8cce18e67a2eea48eac6f9e89.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/831c3bb8cce18e67a2eea48eac6f9e89.png)'
- en: The lower and upper bounds for the population mean (Image by Author)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä½“å‡å€¼çš„ä¸‹ç•Œå’Œä¸Šç•Œï¼ˆå›¾åƒæ¥æºäºä½œè€…ï¼‰
- en: 'These formulae give us a couple of insights into the nature of the sample mean:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å…¬å¼ç»™æˆ‘ä»¬ä¸€äº›å…³äºæ ·æœ¬å‡å€¼æ€§è´¨çš„è§è§£ï¼š
- en: As the variance s of the sample increases, the value of the lower bound (Î¼_low)
    decreases, while that of the upper bound (Î¼_high) increases. This effectively
    moves Î¼_low and Î¼_high further apart from each other and away from the sample
    mean. Conversely, as the sample variance reduces, Î¼_low moves closer to **Z**_bar
    from below, and Î¼_high moves closer to **Z**_bar from above. The interval bounds
    essentially converge on the sample mean from both sides. In effect, the interval
    [Î¼_low, Î¼_high] is directly proportional to the sample variance. If the sample
    is widely ( or tightly) dispersed around its mean, the greater ( or lesser) dispersion
    reduces ( or increases) the reliability of the sample mean as an estimate of the
    population mean.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éšç€æ ·æœ¬æ–¹å·® s çš„å¢åŠ ï¼Œä¸‹ç•Œ (Î¼_low) çš„å€¼ä¼šé™ä½ï¼Œè€Œä¸Šç•Œ (Î¼_high) çš„å€¼ä¼šå¢åŠ ã€‚è¿™ä¼šæœ‰æ•ˆåœ°ä½¿ Î¼_low å’Œ Î¼_high å½¼æ­¤è¿œç¦»ï¼Œå¹¶è¿œç¦»æ ·æœ¬å‡å€¼ã€‚ç›¸åï¼Œéšç€æ ·æœ¬æ–¹å·®çš„å‡å°‘ï¼ŒÎ¼_low
    ä»ä¸‹æ–¹æ›´æ¥è¿‘**Z**_barï¼ŒÎ¼_high ä»ä¸Šæ–¹æ›´æ¥è¿‘**Z**_barã€‚åŒºé—´ç•Œé™æœ¬è´¨ä¸Šä»ä¸¤ä¾§è¶‹å‘äºæ ·æœ¬å‡å€¼ã€‚å®é™…ä¸Šï¼ŒåŒºé—´ [Î¼_low, Î¼_high]
    ä¸æ ·æœ¬æ–¹å·®æˆæ­£æ¯”ã€‚å¦‚æœæ ·æœ¬åœ¨å‡å€¼å‘¨å›´åˆ†å¸ƒå¾—å¾ˆå¹¿æ³›ï¼ˆæˆ–ç´§å¯†ï¼‰ï¼Œåˆ™è¾ƒå¤§çš„ï¼ˆæˆ–è¾ƒå°çš„ï¼‰åˆ†æ•£ä¼šé™ä½ï¼ˆæˆ–å¢åŠ ï¼‰æ ·æœ¬å‡å€¼ä½œä¸ºæ€»ä½“å‡å€¼ä¼°è®¡çš„å¯é æ€§ã€‚
- en: Notice that the width of the interval is inversely proportional to the sample
    size (N). Between two samples exhibiting similar variance, the larger sample will
    yield a tighter interval around its mean than the smaller sample.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼ŒåŒºé—´çš„å®½åº¦ä¸æ ·æœ¬å¤§å° (N) æˆåæ¯”ã€‚åœ¨ä¸¤ä¸ªæ–¹å·®ç›¸ä¼¼çš„æ ·æœ¬ä¹‹é—´ï¼Œè¾ƒå¤§çš„æ ·æœ¬ä¼šäº§ç”Ÿå›´ç»•å…¶å‡å€¼çš„æ›´ç´§å¯†åŒºé—´ï¼Œè€Œè¾ƒå°çš„æ ·æœ¬åˆ™ä¸ä¼šã€‚
- en: Letâ€™s see how to calculate this interval for the automobiles dataset. Weâ€™ll
    calculate [Î¼_low, Î¼_high] such that there is a 95% chance that the population
    mean Î¼ will lie within these bounds.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è®¡ç®—æ±½è½¦æ•°æ®é›†çš„è¿™ä¸ªåŒºé—´ã€‚æˆ‘ä»¬å°†è®¡ç®— [Î¼_low, Î¼_high]ï¼Œä»¥ä¾¿æœ‰ 95% çš„æ¦‚ç‡ä½¿æ€»ä½“å‡å€¼ Î¼ è½åœ¨è¿™äº›èŒƒå›´å†…ã€‚
- en: To get a 95% chance, we should set Î± to 0.05 so that (1 â€” Î±) = 0.95.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è·å¾— 95% çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬åº”è¯¥å°† Î± è®¾ç½®ä¸º 0.05ï¼Œè¿™æ · (1 â€” Î±) = 0.95ã€‚
- en: We know that **Z**_bar is 174.04927 inches.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çŸ¥é“ **Z**_bar ä¸º 174.04927 è‹±å¯¸ã€‚
- en: N is 205 vehicles.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: N ä¸º 205 è¾†è½¦è¾†ã€‚
- en: The [sample standard deviation](https://en.wikipedia.org/wiki/Standard_deviation)
    can be easily calculated. It is 12.33729 inches.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ ·æœ¬æ ‡å‡†å·®](https://en.wikipedia.org/wiki/Standard_deviation)å¯ä»¥å¾ˆå®¹æ˜“åœ°è®¡ç®—å‡ºæ¥ã€‚å®ƒä¸º 12.33729
    è‹±å¯¸ã€‚'
- en: Next, weâ€™ll work on z_Î±/2\. Since Î± is 0.05, Î±/2 is 0.025\. We want to find
    the value of z_Î±/2 i.e., z_0.025\. This is the value on the X-axis of the PDF
    curve of the standard normal random variable, where the area under the curve is
    (1 â€” Î±/2) = (1 â€” 0.025) = 0.975\. By referring to the [table for the standard
    normal distribution](https://en.wikipedia.org/wiki/Standard_normal_table#Cumulative_from_minus_infinity_to_Z),
    we find that this value corresponds to the area to the left of **X**=1.96.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¤„ç† z_Î±/2ã€‚ç”±äº Î± ä¸º 0.05ï¼ŒÎ±/2 ä¸º 0.025ã€‚æˆ‘ä»¬éœ€è¦æ‰¾åˆ° z_Î±/2 çš„å€¼ï¼Œå³ z_0.025ã€‚è¿™æ˜¯åœ¨æ ‡å‡†æ­£æ€éšæœºå˜é‡çš„
    PDF æ›²çº¿çš„ X è½´ä¸Šçš„å€¼ï¼Œå…¶ä¸­æ›²çº¿ä¸‹çš„åŒºåŸŸæ˜¯ (1 â€” Î±/2) = (1 â€” 0.025) = 0.975ã€‚é€šè¿‡æŸ¥é˜… [æ ‡å‡†æ­£æ€åˆ†å¸ƒè¡¨](https://en.wikipedia.org/wiki/Standard_normal_table#Cumulative_from_minus_infinity_to_Z)ï¼Œæˆ‘ä»¬å‘ç°è¿™ä¸ªå€¼å¯¹åº”äº**X**=1.96
    çš„å·¦ä¾§åŒºåŸŸã€‚
- en: '![](../Images/97037ab018de01202f7f06d89ae8d8c7.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97037ab018de01202f7f06d89ae8d8c7.png)'
- en: 'Table containing the values from the CDF of the Standard Normal Distribution.
    Contains P(**X** â‰¤ x) for different values of **X** (Source: [Wikipedia](https://en.wikipedia.org/wiki/Standard_normal_table#Cumulative_from_minus_infinity_to_Z))'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…å«æ ‡å‡†æ­£æ€åˆ†å¸ƒ CDF å€¼çš„è¡¨æ ¼ã€‚åŒ…å«ä¸åŒ **X** å€¼çš„ P(**X** â‰¤ x)ï¼ˆæ¥æºï¼š[ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/Standard_normal_table#Cumulative_from_minus_infinity_to_Z)ï¼‰
- en: 'Plugging in all these values, we get the following bounds:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: æ’å…¥è¿™äº›å€¼ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹ç•Œé™ï¼š
- en: Î¼_low = Z_bar â€” ( z_Î±/2 Â· s/âˆšN) = 174.04927 â€” (1.96 Â· 12.33729/205) = 173.93131
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Î¼_low = Z_bar â€” ( z_Î±/2 Â· s/âˆšN) = 174.04927 â€” (1.96 Â· 12.33729/205) = 173.93131
- en: Î¼_high = Z_bar + ( z_Î±/2 Â· s/âˆšN) = 174.04927 + (1.96 Â· 12.33729/205) = 174.16723
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Thus, [Î¼_low, Î¼_high] = [173.93131 inches, 174.16723 inches]
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: There is a 95% chance that the population mean lies somewhere in this interval.
    Look at how tight this interval is. Its width is just 0.23592 inches. Within this
    tiny sliver of a gap lies the sample mean of 174.04927 inches. In spite of all
    the biases that may be present in the sample, our analysis suggests that the sample
    mean of 174.04927 inches is a remarkably good estimate of the unknown population
    mean*.*
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'Going beyond the first dimension: Expectation in a multi-dimensional sample
    space'
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, our discussion about expectation has been confined to a single dimension,
    but it neednâ€™t be so. We can easily extend the concept of expectation to two,
    three, or higher dimensions. To calculate the expectation over a multi-dimensional
    space, all we need is a **joint Probability Mass (or Density) Function** that
    is defined over the N-dim space. A joint PMF or PDF takes multiple random variables
    as parameters and returns the probability of jointly observing those values.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'Earlier in the article, we defined a random variable **Y** that represents
    the number of cylinders in a randomly chosen vehicle from the autos dataset. **Y**
    is your quintessential single dimensional discrete random variable and its expected
    value is given by the following equation:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d2d71058987c8bbb924c7e4703cd814.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
- en: Expected value of a single dimensional discrete random variable (Image by Author)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s introduce a new discrete random variable, **X**. The **joint Probability
    Mass Function** of **X** and **Y** is denoted by P(**X**=x_i, **Y**=y_j), or simply
    as P(**X**, **Y**). This joint PMF lifts us out of the cozy, one-dimensional space
    that **Y** inhabits, and deposits us into a more interesting 2-dimensional space.
    In this 2-D space, a single data point or outcome is represented by the tuple
    (x_i, y_i). If the range of **X** contains â€˜pâ€™ outcomes and the range of **Y**
    contains â€˜qâ€™ outcomes, the 2-D space will have (p x q) joint outcomes. We use
    the tuple (x_i, y_i) to denote each of these joint outcomes. To calculate E(**Y**)
    in this 2-D space, we must adapt the formula of E(**Y**) as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e3b49c7038d4d68e6b873648451968c.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
- en: The expected of the discrete random variable Y over a 2-dimensional space (Image
    by Author)
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that we are summing over all possible tuples (x_i, y_i) in the 2-D space.
    Letâ€™s tease apart this sum into a nested summation as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c2c6ceebae66298f720c09b455417590.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
- en: The expected value of the discrete random variable **Y** over a 2-dimensional
    space (Image by Author)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: In the nested sum, the inner summation computes the product of y_j and P(**X**=x_i,
    **Y**=y_j) over all values of y_j. Then, the outer sum repeats the inner sum for
    each value of x_i. Afterward, it collects all these individuals sums and adds
    them up to compute E(**Y**).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'We can extend the above formula to any number of dimensions by simply nesting
    the summations within each other. All you need is a joint PMF that is defined
    over the N-dimensional space. For instance, hereâ€™s how to extend the formula to
    4-D space:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ±‚å’ŒåµŒå¥—åœ¨å½¼æ­¤ä¹‹é—´ï¼Œå°†ä¸Šè¿°å…¬å¼æ‰©å±•åˆ°ä»»æ„æ•°é‡çš„ç»´åº¦ã€‚ä½ éœ€è¦çš„åªæ˜¯ä¸€ä¸ªåœ¨Nç»´ç©ºé—´ä¸Šå®šä¹‰çš„è”åˆPMFã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹æ˜¯å¦‚ä½•å°†å…¬å¼æ‰©å±•åˆ°4ç»´ç©ºé—´ï¼š
- en: '![](../Images/b8c1e2e20439a681bed53b49d457d5e3.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8c1e2e20439a681bed53b49d457d5e3.png)'
- en: The expected value of the discrete random variable **Y** over a 4-dimensional
    space (Image by Author)
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦»æ•£éšæœºå˜é‡**Y**åœ¨4ç»´ç©ºé—´ä¸Šçš„æœŸæœ›å€¼ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: Notice how we are always positioning the summation of **Y** at the deepest level.
    You may arrange the remaining summations in any order you want â€” youâ€™ll get the
    same result for E(**Y**).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æˆ‘ä»¬æ€»æ˜¯å°†**Y**çš„æ±‚å’Œæ”¾åœ¨æœ€æ·±å±‚æ¬¡ã€‚ä½ å¯ä»¥æŒ‰ä»»ä½•é¡ºåºå®‰æ’å…¶ä½™çš„æ±‚å’Œâ€”â€”ä½ å°†å¾—åˆ°ç›¸åŒçš„E(**Y**)ç»“æœã€‚
- en: You may ask, why will you ever want to define a joint PMF and go bat-crazy working
    through all those nested summations? What does E(**Y**) mean when calculated over
    an N-dimensional space?
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¼šé—®ï¼Œä¸ºä»€ä¹ˆè¦å®šä¹‰ä¸€ä¸ªè”åˆPMFå¹¶ä¸ºæ‰€æœ‰è¿™äº›åµŒå¥—æ±‚å’Œè€Œå‘ç‹‚ï¼Ÿåœ¨Nç»´ç©ºé—´ä¸Šè®¡ç®—çš„E(**Y**)æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ
- en: The best way to understand the meaning of expectation in a multi-dimensional
    space is to illustrate its use on real-world multi-dimensional data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£å¤šç»´ç©ºé—´ä¸­æœŸæœ›å€¼å«ä¹‰çš„æœ€ä½³æ–¹å¼æ˜¯ç”¨å®é™…çš„å¤šç»´æ•°æ®æ¥è¯´æ˜å…¶ä½¿ç”¨ã€‚
- en: The data weâ€™ll use comes from a certain boat which, unlike the one I took across
    the English Channel, tragically did not make it to the other side.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨çš„æ•°æ®æ¥è‡ªä¸€è‰˜ç‰¹å®šçš„èˆ¹ï¼Œå®ƒä¸æˆ‘æ¸¡è¿‡è‹±å‰åˆ©æµ·å³¡çš„èˆ¹ä¸åŒï¼Œä¸å¹¸çš„æ˜¯æ²¡èƒ½åˆ°è¾¾å¦ä¸€è¾¹ã€‚
- en: '![](../Images/d74c510d6e19ccb84cbabe7d7e4d52b8.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d74c510d6e19ccb84cbabe7d7e4d52b8.png)'
- en: '[RMS Titanic](https://en.wikipedia.org/wiki/RMS_Titanic) departing Southampton
    on April 10, 1912 (Public domain)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[RMSæ³°å¦å°¼å…‹å·](https://en.wikipedia.org/wiki/RMS_Titanic)äº1912å¹´4æœˆ10æ—¥ä»å—å®‰æ™®é¡¿å‡ºå‘ï¼ˆå…¬æœ‰é¢†åŸŸï¼‰'
- en: 'The following figure shows some of the rows in a dataset of 887 passengers
    aboard the RMS Titanic:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹å›¾å±•ç¤ºäº†887åä¹˜å®¢åœ¨RMSæ³°å¦å°¼å…‹å·ä¸Šçš„æ•°æ®é›†ä¸­çš„ä¸€äº›è¡Œï¼š
- en: '![](../Images/46c3115e711687c5e917c79bdc1423a2.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46c3115e711687c5e917c79bdc1423a2.png)'
- en: '[The Titanic dataset](https://www.kaggle.com/datasets/brendan45774/test-file)
    ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ³°å¦å°¼å…‹å·æ•°æ®é›†](https://www.kaggle.com/datasets/brendan45774/test-file) ([CC0](https://creativecommons.org/publicdomain/zero/1.0/))'
- en: The **Pclass** column represents the passengerâ€™s cabin-class with integer values
    of 1, 2, or 3\. The **Siblings/Spouses Aboard** and the **Parents/Children Aboard**
    variables are binary (0/1) variables that indicate whether the passenger had any
    siblings, spouses, parents, or children aboard. In statistics, we commonly, and
    somewhat cruelly, refer to such **binary indicator variables** as **dummy variables.**
    There is nothing block-headed about them to deserve the disparaging moniker.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pclass**åˆ—è¡¨ç¤ºä¹˜å®¢çš„èˆ±ä½çº§åˆ«ï¼Œæ•´æ•°å€¼ä¸º1ã€2æˆ–3ã€‚**Siblings/Spouses Aboard**å’Œ**Parents/Children
    Aboard**å˜é‡æ˜¯äºŒå…ƒï¼ˆ0/1ï¼‰å˜é‡ï¼Œè¡¨ç¤ºä¹˜å®¢æ˜¯å¦æœ‰å…„å¼Ÿå§å¦¹ã€é…å¶ã€çˆ¶æ¯æˆ–å­å¥³åœ¨èˆ¹ä¸Šã€‚åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸æœ‰äº›æ®‹é…·åœ°ç§°è¿™äº›**äºŒå…ƒæŒ‡ç¤ºå˜é‡**ä¸º**è™šæ‹Ÿå˜é‡**ã€‚å®ƒä»¬å¹¶æ²¡æœ‰ä»€ä¹ˆæ„šè ¢çš„åœ°æ–¹ä»¥è‡³äºé…å¾—ä¸Šè¿™æ ·çš„è´¬ä¹‰ç§°å‘¼ã€‚'
- en: 'As you can see from the table, there are 8 variables that jointly identify
    each passenger in the dataset. Each of these 8 variables is a random variable.
    The task before us is three-fold:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¡¨ä¸­å¯ä»¥çœ‹å‡ºï¼Œæœ‰8ä¸ªå˜é‡å…±åŒæ ‡è¯†æ•°æ®é›†ä¸­çš„æ¯ä¸ªä¹˜å®¢ã€‚æ¯ä¸€ä¸ªè¿™8ä¸ªå˜é‡éƒ½æ˜¯ä¸€ä¸ªéšæœºå˜é‡ã€‚æˆ‘ä»¬é¢ä¸´çš„ä»»åŠ¡æœ‰ä¸‰æ–¹é¢ï¼š
- en: Weâ€™d want to define a joint Probability Mass Function over a subset of these
    random variables, and,
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›åœ¨è¿™äº›éšæœºå˜é‡çš„ä¸€ä¸ªå­é›†ä¸Šå®šä¹‰ä¸€ä¸ªè”åˆæ¦‚ç‡è´¨é‡å‡½æ•°ï¼Œå¹¶ä¸”ï¼Œ
- en: Using this joint PMF, weâ€™d want to illustrate how to compute the expected value
    of one of these variables over this multi-dimensional PMF, and,
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¿™ä¸ªè”åˆPMFï¼Œæˆ‘ä»¬å¸Œæœ›è¯´æ˜å¦‚ä½•åœ¨è¿™ä¸ªå¤šç»´PMFä¸Šè®¡ç®—è¿™äº›å˜é‡çš„æœŸæœ›å€¼ï¼Œå¹¶ä¸”ï¼Œ
- en: Weâ€™d like to understand how to interpret this expected value.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›ç†è§£å¦‚ä½•è§£è¯»è¿™ä¸ªæœŸæœ›å€¼ã€‚
- en: To simplify things, weâ€™ll â€˜binâ€™ the **Age** variable into bins of size 5 years
    and label the bins as 5, 10, 15, 20,â€¦,80\. For instance, a binned age of 20 will
    mean that the passengerâ€™s actual age lies in the (15, 20] years interval. Weâ€™ll
    call the binned random variable as **Age_Range**.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬å°†**Age**å˜é‡åˆ†æˆ5å¹´ä¸ºä¸€ä¸ªåŒºé—´ï¼Œå¹¶å°†è¿™äº›åŒºé—´æ ‡è®°ä¸º5ã€10ã€15ã€20ã€â€¦ã€80ã€‚ä¾‹å¦‚ï¼Œ20å²åŒºé—´æ„å‘³ç€ä¹˜å®¢çš„å®é™…å¹´é¾„åœ¨ï¼ˆ15ï¼Œ20]å¹´åŒºé—´å†…ã€‚æˆ‘ä»¬å°†è¿™ä¸ªåˆ†ç®±åçš„éšæœºå˜é‡ç§°ä¸º**Age_Range**ã€‚
- en: 'Once **Age** is binned, weâ€™ll group the data by **Pclass** and **Age_Range**.
    Here are the grouped counts:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦**Age**è¢«åˆ†ç®±ï¼Œæˆ‘ä»¬å°†æŒ‰**Pclass**å’Œ**Age_Range**å¯¹æ•°æ®è¿›è¡Œåˆ†ç»„ã€‚ä»¥ä¸‹æ˜¯åˆ†ç»„è®¡æ•°ï¼š
- en: '![](../Images/9e30b445ff081d3de104d89ff4ce6ff7.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e30b445ff081d3de104d89ff4ce6ff7.png)'
- en: Frequency distribution of passengers by their cabin class and (binned) age (Image
    by Author)
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'The above table contains the number of passengers aboard the Titanic for each
    **cohort** (group) that is defined by the characteristics **Pclass** and **Age_Range**.
    Incidentally, *cohort* is yet another word (along with [asymptotic](https://en.wikipedia.org/wiki/Asymptotic_analysis))
    that statisticians downright worship. Hereâ€™s a tip: every time you want to say
    â€˜groupâ€™, just say â€˜cohortâ€™. I promise you this, whatever it was that you were
    planning to blurt out will instantly sound ten times more significant. To illustrate:
    â€œEight different **cohorts** of alcohol enthusiasts (excuse me, [oenophiles](https://en.wikipedia.org/wiki/Oenophilia))
    were given fake wine to drink and their reactions were recorded.â€ See what I mean?'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: To be honest, â€˜cohortâ€™ does carry a precise [meaning](https://en.wikipedia.org/wiki/Cohort_(statistics))
    that â€˜groupâ€™ doesnâ€™t. Still, it can be instructive to say â€˜cohortâ€™ once in a while
    and witness feelings of respect grow in your listenersâ€™ faces.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: At any rate, weâ€™ll add another column to the table of frequencies. This new
    column will hold the probability of observing the particular combination of **Pclass**
    and **Age_Range**. This probability, P(**Pclass**, **Age_Range**), is the ratio
    of the frequency (i.e. the number in the **Name** column) to the total number
    of passengers in the dataset (i.e. 887).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e46b8e99bfb76ce84c55a3a167e52413.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
- en: Frequency distribution of passengers by their cabin class and (binned) age (Image
    by Author)
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: The probability P(**Pclass**, **Age_Range**) is the **joint Probability Mass
    Function** of the random variables **Pclass** and **Age_Range**. It gives us the
    probability of observing a passenger who is described by a particular combination
    of **Pclass** and **Age_Range**. For example, look at the row where **Pclass**
    is 3 and **Age_Range** is 25\. The corresponding joint probability is 0.116122\.
    That number tells us that roughly 12% of passengers in the 3rd class cabins of
    the Titanic were 20â€“25 years old.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: As with the one-dimensional PMF, the joint PMF also sums up to a perfect 1.0
    when evaluated over all combinations of values of its constituent random variables.
    If your joint PMF doesnâ€™t sum up to 1.0, you should look closely at how you have
    defined it. There might be an error in its formula or worse, in the design of
    your experiment.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: In the above dataset, the joint PMF does indeed sum up to 1.0\. Feel free to
    take my word for it!
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: To get a visual feel for how the joint PMF, P(**Pclass**, **Age_Range**) looks
    like, you can plot it in 3 dimensions. In the 3-D plot, set the X and Y axis to
    respectively **Pclass** and **Age_Range** and the Z axis to the probability P(**Pclass**,
    **Age_Range**). What youâ€™ll see is a fascinating 3-D chart.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a20b2a052e080bc06a7b572bc06640f3.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
- en: A 3-D plot of the joint PMF of **Pclass** and **Age_Range** (Image by Author)
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: If you look closely at the , youâ€™ll notice that the joint PMF consists of three
    parallel plots, one for each cabin class on the Titanic. The 3-D plot brings out
    some of the demographics of the humanity aboard the ill-fated ocean-liner. For
    instance, across all three cabin classes, itâ€™s the 15 to 40 year old passengers
    that made up the bulk of the population.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Now letâ€™s work on the calculation for E(**Age_Range**) over this 2-D space.
    E(**Age_Range**) is given by:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2f1d0f42a523e477f3863faadcb5f2d4.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
- en: Expected value of **Age_Range** (Image by Author)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'We run the inside sum over all values of **Age_Range**: 5,10,15,â€¦,80\. We run
    the outer sum over all values of **Pclass**: [1, 2, 3]. For each combination of
    (**Pclass**, **Age_Range)**, we pick the joint probability from the table. The
    expected value of **Age_Range** is 31.48252537 years which corresponds to the
    binned value of 35\. We can expect the â€˜averageâ€™ passenger on the Titanic to be
    30 to 35 years old.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'If you take the mean of the **Age_Range** column in the Titanic dataset, youâ€™ll
    arrive at exactly the same value: 31.48252537 years. So why not just take the
    average of the **Age_Range** column to get E(**Age_Range)**? Why build a Rube
    Goldberg machine of nested summations over an N-dimensional space only to arrive
    at the same value?'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/97471fe67495593c6cf73036a637e3c3.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
- en: '[Rube Goldbergâ€™s â€œself-operating napkinâ€ machine](https://commons.wikimedia.org/wiki/File:Self-operating_napkin_(Rube_Goldberg_cartoon_with_caption).jpg)
    (Public domain)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Itâ€™s because in some situations, all youâ€™ll have is the joint PMF and the ranges
    of the random variables. In this instance, if you had only P(**Pclass, Age_Range**)
    and you knew the range of **Pclass** as [1,2,3], and that of Age_Range as [5,10,15,20,â€¦,80],
    you can still use the nested summations technique to calculate E(**Pclass**) **or**
    E(**Age_Range**).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'If the random variables are continuous, the expected value over a multi-dimensional
    space can be found using a multiple integral. For instance, if **X**, **Y**, and
    **Z** are continuous random variables and f(**X**,**Y**,**Z**) is the joint Probability
    Density Function defined over the 3-dimensional continuous space of tuples (x,
    y, z), the expected value of **Y** over this 3-D space is given in the following
    figure:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a6fe3f347a8d63bfc35eaaa04139ac1.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
- en: Expected value of the continuous random variable **Y** defined over a continuous
    3-D space (Image by Author)
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Just as in the discrete case, you integrate first over the variable whose expected
    value you want to calculate, and then integrate over the rest of the variables.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: A famous example demonstrating the application of the multiple-integral method
    for computing expected values exists at a scale that is too small for the human
    eye to perceive. I am referring to the **wave function** of quantum mechanics.
    The wave function is denoted as Î¨(x, y, z, t) in Cartesian coordinates or as Î¨(r,
    Î¸, É¸, t) in polar coordinates. Itâ€™s used to describe the properties of seriously
    tiny things that enjoy living in really, really cramped spaces, like electrons
    in an atom. The wave function Î¨ returns a complex number of the form A + jB, where
    A represents the real part and B represents the imaginary part. We can interpret
    the square of the absolute value of Î¨ as a **joint probability density function**
    defined over the 4-dimensional space described by the tuple (x, y, z, t) or (r,
    Î¸, É¸, t). Specifically for an electron in a Hydrogen atom, we can interpret |Î¨|Â²
    as the approximate probability of finding the electron in an infinitesimally tiny
    volume of space around (x, y, z) or around (r, Î¸, É¸) at time t. By knowing |Î¨|Â²,
    we can run a quadruple integral over x, y, z, and t to calculate the **expected
    location of the electron** along the X, Y, or Z axis (or their polar equivalents)
    at time t.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªè‘—åçš„ä¾‹å­å±•ç¤ºäº†ç”¨äºè®¡ç®—æœŸæœ›å€¼çš„å¤šé‡ç§¯åˆ†æ–¹æ³•ï¼Œå…¶è§„æ¨¡å°åˆ°äººçœ¼æ— æ³•æ„ŸçŸ¥ã€‚æˆ‘æŒ‡çš„æ˜¯**é‡å­åŠ›å­¦**ä¸­çš„**æ³¢å‡½æ•°**ã€‚æ³¢å‡½æ•°åœ¨ç¬›å¡å°”åæ ‡ä¸­è¡¨ç¤ºä¸ºÎ¨(x,
    y, z, t)ï¼Œåœ¨æåæ ‡ä¸­è¡¨ç¤ºä¸ºÎ¨(r, Î¸, É¸, t)ã€‚å®ƒç”¨äºæè¿°é‚£äº›å–œæ¬¢å¾…åœ¨æå…¶ç‹­å°ç©ºé—´é‡Œçš„å¾®å°ç‰©ä½“çš„æ€§è´¨ï¼Œä¾‹å¦‚åŸå­ä¸­çš„ç”µå­ã€‚æ³¢å‡½æ•°Î¨è¿”å›ä¸€ä¸ªå½¢å¼ä¸ºA
    + jBçš„å¤æ•°ï¼Œå…¶ä¸­Aä»£è¡¨å®éƒ¨ï¼ŒBä»£è¡¨è™šéƒ¨ã€‚æˆ‘ä»¬å¯ä»¥å°†Î¨çš„ç»å¯¹å€¼å¹³æ–¹è§£é‡Šä¸ºå®šä¹‰åœ¨å››ç»´ç©ºé—´ï¼ˆx, y, z, tï¼‰æˆ–ï¼ˆr, Î¸, É¸, tï¼‰ä¸Šçš„**è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°**ã€‚ç‰¹åˆ«æ˜¯å¯¹äºæ°¢åŸå­ä¸­çš„ç”µå­ï¼Œæˆ‘ä»¬å¯ä»¥å°†|Î¨|Â²è§£é‡Šä¸ºåœ¨æ—¶é—´tæ—¶ç”µå­åœ¨ï¼ˆx,
    y, zï¼‰æˆ–ï¼ˆr, Î¸, É¸ï¼‰å‘¨å›´ä¸€ä¸ªæå…¶å¾®å°çš„ç©ºé—´ä½“ç§¯ä¸­çš„å¤§è‡´æ¦‚ç‡ã€‚é€šè¿‡çŸ¥é“|Î¨|Â²ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨x, y, zå’Œtä¸Šè¿›è¡Œå››é‡ç§¯åˆ†ï¼Œä»¥è®¡ç®—ç”µå­åœ¨æ—¶é—´tæ²¿Xã€Yæˆ–Zè½´ï¼ˆæˆ–å…¶æåæ ‡ç­‰æ•ˆè½´ï¼‰çš„**æœŸæœ›ä½ç½®**ã€‚
- en: Parting thoughts
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“æŸè¯­
- en: I began this article with my experience with seasickness. And I wouldnâ€™t blame
    you if you winced at the brash use of a Bernoulli random variable to model what
    is a remarkably complex and somewhat poorly understood human ordeal. My objective
    was to illustrate how expectation affects us, literally, at a biological level.
    One way to explain that ordeal was to use the cool and comforting language of
    random variables.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¥è‡ªå·±å¯¹æ™•èˆ¹çš„ç»å†å¼€å§‹è¿™ç¯‡æ–‡ç« ã€‚å¦‚æœä½ å¯¹ç”¨ä¼¯åŠªåˆ©éšæœºå˜é‡æ¥å»ºæ¨¡è¿™ä¸€éå¸¸å¤æ‚ä¸”å°šæœªå®Œå…¨ç†è§£çš„äººç±»å›°å¢ƒæ„Ÿåˆ°ä¸æ»¡ï¼Œæˆ‘ä¹Ÿä¸ä¼šæ€ªä½ ã€‚æˆ‘çš„ç›®çš„æ˜¯è¯´æ˜æœŸæœ›å¦‚ä½•ä»ç”Ÿç‰©å­¦å±‚é¢å®é™…å½±å“æˆ‘ä»¬ã€‚ä¸€ç§è§£é‡Šè¿™ä¸€å›°å¢ƒçš„æ–¹æ³•æ˜¯ä½¿ç”¨éšæœºå˜é‡çš„é…·ç‚«ä¸”èˆ’ç¼“çš„è¯­è¨€ã€‚
- en: Starting with the deceptively simple Bernoulli variable, we swept our illustrative
    brush across the statistical canvas all the way to the magnificent, multi-dimensional
    complexity of the quantum wave function. Throughout, we sought to understand how
    expectation operates on discrete and continuous scales, in single and multiple
    dimensions, and at microscopic scales.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ä»çœ‹ä¼¼ç®€å•çš„ä¼¯åŠªåˆ©å˜é‡å¼€å§‹ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æ’å›¾ç”»ç¬”ä»ç»Ÿè®¡ç”»å¸ƒæ‰«åˆ°é‡å­æ³¢å‡½æ•°çš„å®ä¼Ÿå¤šç»´å¤æ‚æ€§ã€‚åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åŠ›æ±‚ç†è§£æœŸæœ›å¦‚ä½•åœ¨ç¦»æ•£å’Œè¿ç»­å°ºåº¦ã€å•ç»´å’Œå¤šç»´ã€ä»¥åŠå¾®è§‚å°ºåº¦ä¸Šè¿ä½œã€‚
- en: There is one more area in which expectation makes an immense impact. That area
    is **conditional probability** in which one calculates the probability that a
    random variable **X** will take a value â€˜xâ€™ assuming that certain other random
    variables **A**, **B**, **C**, etc. have already taken values â€˜aâ€™, â€˜bâ€™, â€˜câ€™. The
    **probability of X conditioned upon A**, **B**, and **C** is denoted as P(**X**=x|**A**=a,**B**=b,**C**=c)
    or simply as P(**X**|**A**,**B**,**C**). In all the formulae for expectation that
    we have seen, if you replace the probability (or probability density) with the
    conditional version of the same, what youâ€™ll get are the corresponding formulae
    for **conditional expectation**. Itâ€™s denoted as E(**X**=x|**A**=a,**B**=b,**C**=c)
    and it lies at the heart of the extensive fields of regression analysis and estimation.
    And thatâ€™s fodder for future articles!
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€ä¸ªé¢†åŸŸï¼ŒæœŸæœ›å‘æŒ¥äº†å·¨å¤§çš„å½±å“ã€‚è¿™ä¸ªé¢†åŸŸæ˜¯**æ¡ä»¶æ¦‚ç‡**ï¼Œå…¶ä¸­è®¡ç®—éšæœºå˜é‡**X**å–å€¼â€˜xâ€™çš„æ¦‚ç‡ï¼Œå‡è®¾æŸäº›å…¶ä»–éšæœºå˜é‡**A**ã€**B**ã€**C**ç­‰å·²ç»å–å€¼â€˜aâ€™ã€â€˜bâ€™ã€â€˜câ€™ã€‚**X**åœ¨**A**ã€**B**å’Œ**C**çš„æ¡ä»¶ä¸‹çš„æ¦‚ç‡è¡¨ç¤ºä¸ºP(**X**=x|**A**=a,**B**=b,**C**=c)ï¼Œæˆ–ç®€å†™ä¸ºP(**X**|**A**ã€**B**ã€**C**)ã€‚åœ¨æˆ‘ä»¬è§è¿‡çš„æ‰€æœ‰æœŸæœ›å…¬å¼ä¸­ï¼Œå¦‚æœå°†æ¦‚ç‡ï¼ˆæˆ–æ¦‚ç‡å¯†åº¦ï¼‰æ›¿æ¢ä¸ºåŒä¸€æ¡ä»¶ç‰ˆæœ¬ï¼Œå¾—åˆ°çš„å°±æ˜¯**æ¡ä»¶æœŸæœ›**çš„ç›¸åº”å…¬å¼ã€‚å®ƒè¡¨ç¤ºä¸ºE(**X**=x|**A**=a,**B**=b,**C**=c)ï¼Œå®ƒä½äºå›å½’åˆ†æå’Œä¼°è®¡çš„å¹¿æ³›é¢†åŸŸçš„æ ¸å¿ƒã€‚è¿™æ˜¯æœªæ¥æ–‡ç« çš„ç´ æï¼
- en: Citations and Copyrights
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¼•ç”¨å’Œç‰ˆæƒ
- en: Dataset
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®é›†
- en: The automobile dataset is downloaded from the [UC Irvine Machine Learning Repository](https://archive-beta.ics.uci.edu/dataset/10/automobile)
    under the [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/legalcode)
    (CC BY 4.0) license.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: The Titanic dataset is downloaded from [Kaggle](https://www.kaggle.com/datasets/brendan45774/test-file)
    under the [CC0 license](https://creativecommons.org/publicdomain/zero/1.0/).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Images
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All images in this article are copyright [Sachin Date](https://www.linkedin.com/in/sachindate/)
    under [CC-BY-NC-SA](https://creativecommons.org/licenses/by-nc-sa/4.0/), unless
    a different source and copyright are mentioned underneath the image.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '*If you liked this article, please follow me at* [***Sachin Date***](https://timeseriesreasoning.medium.com)
    *to receive tips, how-tos and programming advice on topics devoted to regression,
    time series analysis, and forecasting.*'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
