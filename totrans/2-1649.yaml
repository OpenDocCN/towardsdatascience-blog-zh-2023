- en: 'PID Controller Optimization: A Gradient Descent Approach'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2](https://towardsdatascience.com/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using machine learning to solve engineering optimization problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@callum.bruce1?source=post_page-----58876e14eef2--------------------------------)[![Callum
    Bruce](../Images/4833a199a9449434777fdf5ce913a9cb.png)](https://medium.com/@callum.bruce1?source=post_page-----58876e14eef2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----58876e14eef2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----58876e14eef2--------------------------------)
    [Callum Bruce](https://medium.com/@callum.bruce1?source=post_page-----58876e14eef2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----58876e14eef2--------------------------------)
    ¬∑10 min read¬∑Aug 1, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4350abf8767e1ec8d3ce9a121cb47b01.png)'
  prefs: []
  type: TYPE_IMG
- en: The gradient descent algorithm steps downhill to minimize a cost function
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning. Deep learning. AI. More and more people use these technologies
    every day. This has largely been driven by the rise of Large Language Models deployed
    by the likes of ChatGPT, Bard and others. Despite their widespread use, relatively
    few people are familiar with the methods underpinning these technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, we dive into one of the fundamental methods deployed in machine
    learning: the gradient descent algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of looking at gradient descent through the lens of neural networks,
    where it is used to optimize network weights and biases, we will instead examine
    the algorithm as a tool for solving classic engineering optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, we will use gradient descent to tune the gains of a PID (Proportional-Integral-Derivative)
    controller for a car cruise control system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The motivation for following this approach is twofold:'
  prefs: []
  type: TYPE_NORMAL
- en: First, optimizing the weights and biases in a neural network is a high-dimension
    problem. There are a lot of moving parts and I think these distract from the underlying
    utility of gradient descent for solving optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, as you will see, gradient descent can be a powerful tool when applied
    to classic engineering problems like PID controller tuning, inverse kinematics
    in robotics and topology optimization. Gradient descent is a tool that, in my
    opinion, more engineers should be familiar with and able to utilize.
  prefs: []
  type: TYPE_NORMAL
- en: After reading this article you will understand what a PID controller is, how
    the gradient descent algorithm works and how it can be applied to solve classic
    engineering optimization problems. You might be motivated to use gradient descent
    to tackle optimization challenges of your own.
  prefs: []
  type: TYPE_NORMAL
- en: All code used in this article is available [here on GitHub](https://github.com/c-bruce/pid_controller_gradient_descent).
  prefs: []
  type: TYPE_NORMAL
- en: What is a PID controller?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A PID controller is a widely used feedback control mechanism in engineering
    and automated systems. It aims to maintain a desired setpoint by continuously
    adjusting the control signal based on the error between the setpoint and the system‚Äôs
    measured output (the process variable).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4bebce93124edeb5a68f3e150a4cc86f.png)'
  prefs: []
  type: TYPE_IMG
- en: Typical step response of a PID controller
  prefs: []
  type: TYPE_NORMAL
- en: PID controllers find extensive applications in various industries and domains.
    They are widely used in process control systems, such as temperature control in
    manufacturing, flow control in chemical plants, and pressure control in HVAC systems.
    PID controllers are also employed in robotics for precise positioning and motion
    control, as well as in automotive systems for throttle control, engine speed regulation,
    and anti-lock braking systems. They play a vital role in aerospace and aviation
    applications, including aircraft autopilots and attitude control systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'A PID controller consists of three components: the proportional term, the integral
    term, and the derivative term. The proportional term provides an immediate response
    to the current error, the integral term accumulates and corrects for past errors,
    and the derivative term predicts and counteracts future error trends.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6fe42cfd42b6ca09246fce764897838c.png)'
  prefs: []
  type: TYPE_IMG
- en: PID controller block diagram
  prefs: []
  type: TYPE_NORMAL
- en: The control loop of a PID controller is presented in the block diagram above.
    *r(t)* is the setpoint and *y(t)* is the process variable. The process variable
    is subtracted from the setpoint to get the error signal, *e(t)*.
  prefs: []
  type: TYPE_NORMAL
- en: The control signal, *u(t)*, is the sum of the proportional, integral and derivative
    terms. The control signal is input to the process and this, in turn, causes the
    process variable to update.
  prefs: []
  type: TYPE_NORMAL
- en: PID controller control signal u(t)
  prefs: []
  type: TYPE_NORMAL
- en: The gradient descent algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gradient descent is an optimization algorithm commonly used in machine learning
    and mathematical optimization. It aims to find the minimum of a given cost function
    by iteratively adjusting the parameters based on the cost function gradient. The
    gradient points in the direction of the steepest ascent, so by taking steps in
    the opposite direction, the algorithm gradually converges towards the optimal
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'A single gradient descent update step is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent update step
  prefs: []
  type: TYPE_NORMAL
- en: Where ***a****‚Çô*is a vector of input parameters. The subscript *n* denotes iteration.
    *f(****a****‚Çô)* is a multi-variable cost function and ‚àá*f(****a****) is* the gradient
    of that cost function. ‚àá*f(****a****‚Çô)* represents the direction of steepest ascent
    so it is subtracted from ***a****‚Çô* to reduce the cost function on the next iteration.
    ùõæ is the learning rate which determines the step size at each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: An appropriate value for ùõæ must be selected. Too big and the steps taken at
    each iteration will be too large and cause the gradient descent algorithm to not
    converge. Too small and the gradient descent algorithm will be computationally
    expensive and take a long time to converge.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aba8bdc7d4833adb595ed30d9acda58e.png)'
  prefs: []
  type: TYPE_IMG
- en: Gradient descent algorithm applied to y=x¬≤ cost function (initially x=5) for
    ùõæ=0.1 (LHS) and ùõæ=1.02 (RHS)
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent is applied in a wide range of fields and disciplines. In machine
    learning and deep learning, it is a fundamental optimization algorithm used to
    train neural networks and optimize their parameters. By iteratively updating the
    weights and biases of the network based on the gradient of the cost function,
    gradient descent enables the network to learn and improve its performance over
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond machine learning, gradient descent is utilized in various optimization
    problems across engineering, physics, economics, and other domains. It assists
    in parameter estimation, system identification, signal processing, image reconstruction,
    and many other tasks that require finding the minimum or maximum of a function.
    The versatility and effectiveness of gradient descent make it an essential tool
    for solving optimization problems and improving models and systems across diverse
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing PID controller gains using gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several methods available to tune a PID controller. These include
    the manual tuning method and heuristic methods like the [Ziegler-Nichols method](https://en.wikipedia.org/wiki/Ziegler%E2%80%93Nichols_method).
    The manual tuning method can be time-consuming and may require multiple iterations
    to find optimal values while the Ziegler-Nichols method often yields aggressive
    gains and large overshoot which means it is not suitable for certain applications.
  prefs: []
  type: TYPE_NORMAL
- en: Presented here is a gradient descent approach to PID controller optimization.
    We will optimize the control system of a car cruise control system subject to
    a step change in setpoint.
  prefs: []
  type: TYPE_NORMAL
- en: By controlling the pedal position, the controller‚Äôs objective is to accelerate
    the car up to the velocity setpoint with minimum overshoot, settling time and
    steady-state error.
  prefs: []
  type: TYPE_NORMAL
- en: The car is subject to a driving force proportional to the pedal position. Rolling
    resistance and aerodynamic drag forces act in the opposite direction to the driving
    force. Pedal position is controlled by the PID controller and limited to within
    a range of -50% to 100%. When the pedal position is negative, the car is braking.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is helpful to have a model of the system when tuning PID controller gains.
    This is so that we can simulate the system response. For this I have implemented
    a `Car` class in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The`PIDController` class is implemented as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Taking this object-oriented programming approach makes it much easier to set
    up and run multiple simulations with different PID controller gains as we must
    do when running the gradient descent algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The`GradientDescent` class is implemented as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The algorithm is run for a specified number of iterations by calling `execute`
    or `execute_adagrad`. The `execute_adagrad` method executes a modified form of
    gradient descent called AdaGrad (adaptive gradient descent).
  prefs: []
  type: TYPE_NORMAL
- en: AdaGrad has per-parameter learning rates that increase for sparse parameters
    and decrease for less sparse parameters. The learning rate is updated after each
    iteration based on a historical sum of the gradients squared.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use AdaGrad to optimize the PID controller gains for the car cruise
    control system. Using AdaGrad, the gradient descent update equation becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: AdaGrad gradient descent update step
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to define our cost function. The cost function must take a vector
    of input parameters as input and return a single number; the cost. The objective
    of the car cruise control is to accelerate the car up to the velocity setpoint
    with minimum overshoot, settling time and steady-state error. There are many ways
    we could define the cost function based on this objective. Here we will define
    it as the integral of the error magnitude over time:'
  prefs: []
  type: TYPE_NORMAL
- en: Car cruise control cost function
  prefs: []
  type: TYPE_NORMAL
- en: 'Since our cost function is an integral, we can visualize it as the area under
    the error magnitude curve. We expect to see the area under the curve reduce as
    we approach the global minimum. Programmatically, the cost function is defined
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The cost function includes the simulation parameters. The simulation is run
    for 60 seconds. During this time we observe the response of the system to a step
    change in setpoint from 0 m/s to 20 m/s. By integrating error magnitude over time,
    the cost is calculated for every iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, all that is left to do is run the optimization. We will start with initial
    values of *Kp* = 5.0, *Ki* = 1.0 and *Kd* = 0.0\. These values give a steady,
    oscillating response, with overshoot, that eventually converges to the setpoint.
    From this start point we will run the gradient descent algorithm for 500 iterations
    using a base learning rate of ùõæ=0.1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/aef6802298914bd17d835a1e6233d53f.png)'
  prefs: []
  type: TYPE_IMG
- en: Car cruise control step response (LHS), error magnitude (middle) and cost (RHS)
    as the gradient descent algorithm iterates toward an optimal solution
  prefs: []
  type: TYPE_NORMAL
- en: The animated plot above shows the evolution of the car cruise control step response
    as the gradient descent algorithm tunes the *Kp*, *Ki* and *Kd* gains of the PID
    controller.
  prefs: []
  type: TYPE_NORMAL
- en: By iteration 25, the gradient descent algorithm has eliminated the oscillatory
    response. After this point, something interesting happens. The algorithm wanders
    into a local minimum characterized by an overshoot of ~ 3 m/s. This happens in
    the region of 6.0 < *Kp* < 7.5, *Ki* ~= 0.5, *Kd* = 0.0 and lasts right up to
    iteration 300.
  prefs: []
  type: TYPE_NORMAL
- en: After iteration 300, the algorithm moves out of the local minimum to find a
    more satisfactory response closer to the global minimum. The response is now characterized
    by zero overshoot, fast settling time and near-zero steady-state error.
  prefs: []
  type: TYPE_NORMAL
- en: Running the gradient descent algorithm for 500 iterations we arrive at our optimized
    PID controller gains; *Kp* = 8.33, *Ki* = 0.12 and *Kd* = 0.00.
  prefs: []
  type: TYPE_NORMAL
- en: The proportional gain is still rising steadily. Running more iterations (not
    shown here), as *Kp* slowly increases, we find further reduction to the cost function
    is possible though this effect becomes increasingly marginal.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adopting a method widely used for solving machine learning and deep learning
    problems, we have successfully optimized PID controller gains for a car cruise
    control system.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with initial values of *Kp* = 5.0, *Ki* = 1.0 and *Kd* = 0.0 and applying
    the AdaGrad form of the gradient descent algorithm we observed how this low-dimension
    system first wanders into a local minimum before eventually finding a more satisfactory
    response with zero overshoot, fast settling time and near-zero steady-state error.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we have seen how gradient descent can be a powerful tool when
    applied to classic engineering optimization problems. Beyond the example presented
    here, gradient descent can be utilised to solve other engineering problems like
    inverse kinematics in robotics, topology optimization and many more.
  prefs: []
  type: TYPE_NORMAL
- en: Do you have an optimization problem that you think gradient descent could be
    applied to? Let me know in the comments below.
  prefs: []
  type: TYPE_NORMAL
- en: '**Enjoyed reading this article?**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/@callum.bruce1) and [subscribe](https://medium.com/@callum.bruce1/subscribe)
    for more content like this ‚Äî share it with your network ‚Äî try applying gradient
    descent to your own optimization problems.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*All images unless otherwise noted are by the author.*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Web
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] GitHub (2023), [pid_controller_gradient_descent](https://github.com/c-bruce/pid_controller_gradient_descent)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Wikipedia (2023), [Ziegler‚ÄìNichols method](https://en.wikipedia.org/wiki/Ziegler‚ÄìNichols_method)
    (accessed 10th July 2023)'
  prefs: []
  type: TYPE_NORMAL
