- en: Deep Understanding of Simple Linear Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对简单线性回归的深刻理解
- en: 原文：[https://towardsdatascience.com/deep-understanding-of-simple-linear-regression-3776afe34473](https://towardsdatascience.com/deep-understanding-of-simple-linear-regression-3776afe34473)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deep-understanding-of-simple-linear-regression-3776afe34473](https://towardsdatascience.com/deep-understanding-of-simple-linear-regression-3776afe34473)
- en: 'Linear Regression from Scratch: Detailed Explanation'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从零开始的线性回归：详细解释
- en: '[](https://zubairhossain.medium.com/?source=post_page-----3776afe34473--------------------------------)[![Md.
    Zubair](../Images/1b983a23226ce7561796fa5b28c00d65.png)](https://zubairhossain.medium.com/?source=post_page-----3776afe34473--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3776afe34473--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3776afe34473--------------------------------)
    [Md. Zubair](https://zubairhossain.medium.com/?source=post_page-----3776afe34473--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://zubairhossain.medium.com/?source=post_page-----3776afe34473--------------------------------)[![Md.
    Zubair](../Images/1b983a23226ce7561796fa5b28c00d65.png)](https://zubairhossain.medium.com/?source=post_page-----3776afe34473--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3776afe34473--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3776afe34473--------------------------------)
    [Md. Zubair](https://zubairhossain.medium.com/?source=post_page-----3776afe34473--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3776afe34473--------------------------------)
    ·6 min read·Jan 10, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学之路](https://towardsdatascience.com/?source=post_page-----3776afe34473--------------------------------)
    ·阅读时间6分钟·2023年1月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/63a803bc5e9f35621b832e0a453e5409.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63a803bc5e9f35621b832e0a453e5409.png)'
- en: Image By Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动机
- en: Machine learning is a process by which machines can learn from the data and
    take a rational decision on new data without explicit programming. The base of
    these models is mathematics and statistics. Linear regression is one of the simple
    and widely used regression algorithms. The regression algorithms predict continuous
    values.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个过程，通过它，机器可以从数据中学习，并在没有明确编程的情况下对新数据做出合理决策。这些模型的基础是数学和统计学。线性回归是其中一种简单且广泛使用的回归算法。回归算法预测连续值。
- en: For example, we want to predict the price, age, weight, etc. Such types of values
    are not countable. That’s why these are known as continuous values. If you are
    still confused, I suggest you to read the [**article**](https://medium.com/towards-data-science/get-familiar-with-the-most-important-weapon-of-data-science-variables-48cc7cd85dc5).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们想预测价格、年龄、体重等。这些值是不可计数的。因此，它们被称为连续值。如果你仍然感到困惑，我建议你阅读[**这篇文章**](https://medium.com/towards-data-science/get-familiar-with-the-most-important-weapon-of-data-science-variables-48cc7cd85dc5)。
- en: Table of Content
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: '`[**What is the regression problem in Machine Learning?**](#9272)`'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**机器学习中的回归问题是什么？**](#9272)`'
- en: '`[**When do we use simple linear regression?**](#9579)`'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**我们何时使用简单线性回归？**](#9579)`'
- en: '`[**Simple linear regression in detail**](#9188)`'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**简单线性回归详解**](#9188)`'
- en: '`[**Hands-on implementation with python**](#f03f)`'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**使用Python的实践实现**](#f03f)`'
- en: What is the regression problem in Machine Learning?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习中的回归问题是什么？
- en: In data science, machine learning algorithms are used to automate a system.
    In practice, there are mainly two types of problems — ***i. Supervised, and ii.
    Unsupervised.***
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，机器学习算法用于自动化系统。在实践中，主要有两种问题——***i. 监督学习和 ii. 无监督学习。***
- en: In the supervised problem, the training dataset is labelled. That means the
    algorithm has a target value. The supervised learning algorithm tries to predict
    the values like target values and optimizes its parameters accordingly. But in
    the unsupervised problem, there is no target value in the training dataset. The
    unsupervised learning algorithm tries to find the similarity among the data and
    train the model accordingly.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习问题中，训练数据集是有标签的。这意味着算法有一个目标值。监督学习算法尝试预测类似目标值的值，并相应地优化其参数。但在无监督学习问题中，训练数据集没有目标值。无监督学习算法尝试找出数据之间的相似性，并相应地训练模型。
- en: Supervised problems can be further classified into two categories — ***i. Classification,
    and ii. Regression.* Classification** problems are those problems which need to
    predict categorical values. On the contrary, **regression** problems work with
    continuous values.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 监督问题可以进一步分为两类——***i. 分类和 ii. 回归。* 分类**问题是那些需要预测分类值的问题。相反，**回归**问题处理的是连续值。
- en: When do we use simple linear regression?
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们何时使用简单线性回归？
- en: I want to introduce linear regression before simple linear regression. Linear
    regression is a process of finding the regression output by fitting a regression
    line. It only works when our data is linearly distributed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我想在简单线性回归之前介绍线性回归。线性回归是通过拟合回归线来找到回归输出的过程。它仅在我们的数据呈线性分布时有效。
- en: '`Simple or univariate linear regression is a regression process when there
    is only one independent variable or feature.` *There is also multivariate linear
    regression. I will discuss it in the upcoming article.*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`简单或单变量线性回归是在只有一个自变量或特征时的回归过程。` *还有多变量线性回归。我将在接下来的文章中讨论它。*'
- en: '**When to use —**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用——**'
- en: Simple linear regression is best suited when the data is linearly distributed,
    containing only one feature or independent variable.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据线性分布且仅包含一个特征或自变量时，简单线性回归最为合适。
- en: Simple linear regression in detail
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 详细的简单线性回归
- en: Simple linear regression only accepts one independent variable. *Look at the
    simple equation of a straight line.*
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归只接受一个自变量。*看一下直线的简单方程。*
- en: '![](../Images/dc943ed77a7815cfa713c149c4c917f8.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc943ed77a7815cfa713c149c4c917f8.png)'
- en: '`In linear regression, the equation is called *the regression line equation.
    Here, m and c are the coefficients. m represents the slope of the regression line,
    and c is the constant value that represents the intersection point of the y-axis
    for the regression line. x represents the independent variable, and y is the dependent
    variable.*` Let’s make it more clear with the following diagram.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`在线性回归中，方程被称为*回归线方程*。这里，m和c是系数。m表示回归线的斜率，c是表示回归线与y轴交点的常数值。x表示自变量，y是因变量。` 让我们用下面的图示更清楚地说明。'
- en: '![](../Images/63a803bc5e9f35621b832e0a453e5409.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63a803bc5e9f35621b832e0a453e5409.png)'
- en: Simple Linear Regression (Image by Author)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归（作者图像）
- en: Simple linear regression deals with one independent variable (x) and one dependent
    variable (y). The independent variable is the input value, and the dependent variable
    is the output or target value.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归处理一个自变量（x）和一个因变量（y）。自变量是输入值，因变量是输出值或目标值。
- en: Look at the image and let me explain the process step by step. The`**x-axis**`
    represents the independent variable’s value, and the `**y-axis**` represents the
    dependent variable’s value. Black dots are the scatter plots of the training data
    points, and the data seem linearly distributed. These data will be needed to train
    the regression model’s parameters. For doing so, we will fit a straight line through
    the scatter plot, and the cumulative distance from the regression line is reasonably
    minimum. If we find the best regression line, we will get the predicted value
    easily by putting the `**x**` value. For a new data point, drawing a vertical
    straight line will intersect the regression line. The predicted value will be
    the intersection point of the y-axis if we draw a horizontal line from the intersection
    point of the regression line. For fitting the best regression line, finding the
    coefficient value of `**m**`and `**c**` of the above equation is our main challenge.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下图片，让我逐步解释这个过程。`**x轴**`代表自变量的值，`**y轴**`代表因变量的值。黑点是训练数据点的散点图，数据似乎呈线性分布。这些数据将用于训练回归模型的参数。为此，我们将通过散点图拟合一条直线，并使回归线的累计距离尽可能最小。如果我们找到最佳回归线，我们可以通过输入`**x**`值轻松获得预测值。对于一个新的数据点，绘制一条垂直直线将与回归线相交。预测值将是从回归线交点绘制的水平线在`y`轴上的交点。为了拟合最佳回归线，找出上述方程的`**m**`和`**c**`的系数值是我们的主要挑战。
- en: Again, the regression line equation is `***y=mx+c***`***.*** We will get the
    value of x from the dataset, but ***m*** and ***c*** are unknown. Optimum values
    of `***m***` and `***c***` can produce an optimum prediction value of `***y***`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 再次说明，回归线方程是`***y=mx+c***`***。*** 我们将从数据集中获取`x`的值，但***m***和***c***是未知的。`***m***`和`***c***`的最佳值可以产生`***y***`的最佳预测值。
- en: For simple linear regression, we can find the slope `**m**` with the following
    formula.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单线性回归，我们可以用以下公式找到斜率`**m**`。
- en: '![](../Images/bc0efbb2bbad20fcd58b9c20a4f53c2e.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc0efbb2bbad20fcd58b9c20a4f53c2e.png)'
- en: Putting the value of `**m**` to the following equation, we will find the optimum
    value of `**c**`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将`**m**`的值代入以下方程中，我们将找到`**c**`的最佳值。
- en: '![](../Images/65a2b7648dffccc1788e5b7ea4caff14.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65a2b7648dffccc1788e5b7ea4caff14.png)'
- en: '*[In this process, there is a limitation. We can’t find the coefficient values
    by this manual formula if the independent values become more than one. In that
    case, we use gradient descent along with the cost function to find the optimum
    values. I will discuss it in the upcoming articles.]*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*[在这个过程中存在一个限制。如果自变量多于一个，我们不能通过这个手动公式找到系数值。在这种情况下，我们使用梯度下降和代价函数来找到最佳值。我将在即将到来的文章中讨论它。]*'
- en: Hands on implementation with python
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Python进行实践操作
- en: Importing the necessary python libraries.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 导入所需的Python库。
- en: For any machine learning model, the dataset is the main fuel. `*We use the*
    [*Boston House Price*](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)
    *dataset, which is publicly available and licensed under the public domain.*`
    Download the dataset from [here](https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/data).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何机器学习模型，数据集是主要的燃料。`*我们使用的是* [*波士顿房价*](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)
    *数据集，该数据集公开可用，并且在公有领域许可下。*` 从[这里](https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/data)下载数据集。
- en: '*Let’s load the dataset.*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*让我们加载数据集。*'
- en: Setting the column names as there is no column name in the main dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于主数据集中没有列名，所以需要设置列名。
- en: Finding the Pearson correlation to select the highest correlated feature as
    an independent variable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找皮尔逊相关性以选择相关性最高的特征作为自变量。
- en: Our target value is `‘MEDV’` . From the above correlation graph, the `‘RM’`
    variable has the highest correlation, which is `0.7`. So, we pick the variable
    `‘RM’`. The full form of the variable is given below [].
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标值是`‘MEDV’`。从上述相关性图中，`‘RM’`变量的相关性最高，为`0.7`。因此，我们选择了变量`‘RM’`。该变量的全称如下 []。
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Defining x and y.*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*定义x和y。*'
- en: '*Splitting the train and test set.*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*拆分训练集和测试集。*'
- en: '*Defining the function to calculate the coefficient value of* `***m and c***`*.*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*定义计算`***m 和 c***`系数值的函数。*'
- en: '*Plotting the regression line.*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*绘制回归线。*'
- en: Prediction function.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 预测函数。
- en: Actual vs predicted value for our dataset.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据集的实际值与预测值。
- en: There are significant errors in our model for some values. This is because our
    dataset has many features, and we just consider only one feature for demonstration
    purposes as we are dealing with simple linear regression.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型在某些值上存在显著误差。这是因为我们的数据集有许多特征，而我们仅考虑了一个特征进行演示，因为我们处理的是简单线性回归。
- en: '*Let’s calculate the mean absolute error for our model.*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*让我们计算模型的平均绝对误差。*'
- en: Conclusion
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In practice, there are many libraries and easiest ways to implement linear regression.
    But I prefer learning from the very basics because it’s beneficial for absolute
    beginners. I believe if our base is strong enough, we can construct a high-rise
    building on the base. Otherwise, there is a possibility of an unusual breakdown
    of the structure.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，有许多库和简单的方法可以实现线性回归。但我更喜欢从最基础的知识学习，因为这对绝对初学者很有益。我相信如果我们的基础足够坚固，我们可以在基础上构建高楼，否则可能会出现结构不稳定的问题。
- en: The article will assist a lot to beginners, and it will provide a solid base.
    The reader will come to know how simple learner regression works.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章将对初学者非常有帮助，并将提供一个坚实的基础。读者将了解到简单线性回归是如何工作的。
- en: '*Full notebook is available* [***here***](https://github.com/Zubair063/ML_articles/tree/main/Simple%20Linear%20Regression)*.*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*完整的笔记本可以在* [***这里***](https://github.com/Zubair063/ML_articles/tree/main/Simple%20Linear%20Regression)*获取。*'
- en: '`*[I am writing series of articles on machine learning algorithms implemented
    from scratch. You may read the previous articles on KNN and K-means clustering
    from the link below.]*`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`*[我正在编写一系列关于从零实现的机器学习算法的文章。你可以通过下面的链接阅读之前关于KNN和K-means聚类的文章。]*`'
- en: '[](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----3776afe34473--------------------------------)
    [## KNN Algorithm from Scratch'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----3776afe34473--------------------------------)
    [## 从零实现KNN算法'
- en: Implementation and Details Explanation of the KNN Algorithm
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: KNN算法的实现和详细解释
- en: towardsdatascience.com](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----3776afe34473--------------------------------)
    [](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----3776afe34473--------------------------------)
    [## K-means Clustering from Scratch
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----3776afe34473--------------------------------)
    [](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----3776afe34473--------------------------------)
    [## 从零开始的 K-means 聚类'
- en: 'K-means: The Best ML Algorithm to Cluster Data'
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: K-means：最佳的 ML 算法来聚类数据
- en: towardsdatascience.com](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----3776afe34473--------------------------------)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----3776afe34473--------------------------------)
- en: References
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Boston Dataset (toronto.edu)](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[波士顿数据集 (toronto.edu)](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)'
