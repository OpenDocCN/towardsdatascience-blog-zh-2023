- en: How to Auto-Generate a Summary from Long Youtube Videos Using AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ç”¨AIè‡ªåŠ¨ç”Ÿæˆé•¿æ—¶é—´YouTubeè§†é¢‘çš„æ‘˜è¦
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d](https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d](https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)
- en: A step-by-step guide to resume a talk by Stephen Wolfram using Whisper and BART
    models on your local PC
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Whisperå’ŒBARTæ¨¡å‹åœ¨æœ¬åœ°PCä¸Šæ€»ç»“æ–¯è’‚èŠ¬Â·æ²ƒå°”å¤«å‹’å§†çš„æ¼”è®²çš„é€æ­¥æŒ‡å—
- en: '[](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    Â·7 min readÂ·Apr 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    Â·7åˆ†é’Ÿé˜…è¯»Â·2023å¹´4æœˆ14æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/73936710bcb5eeef18ac5b7cbe3fa600.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73936710bcb5eeef18ac5b7cbe3fa600.png)'
- en: Image generated by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ç”Ÿæˆçš„å›¾åƒ
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠ¨æœº
- en: 'In todayâ€™s rapidly changing world, staying informed and inspired can be challenging,
    especially when time is short. Personally, I am a huge fan of YouTube podcasts
    and talks. The podcasts and the talks are goldmines of knowledge, fully packed
    with insights from the brightest minds across various fields. However, due to
    time constraints, itâ€™s not possible for me to watch every interesting video since
    they typically exceed one hour in length. This led me to wonder: what if I could
    create an end-to-end solution to extract automatically the main highlights? As
    a result, I started exploring AI-generative solutions to help me get auto summaries
    of some of the podcasts/talks I missed.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å½“ä»Šå¿«é€Ÿå˜åŒ–çš„ä¸–ç•Œä¸­ï¼Œä¿æŒä¿¡æ¯æ›´æ–°å’Œè·å¾—çµæ„Ÿå¯èƒ½æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å½“æ—¶é—´ç´§è¿«æ—¶ã€‚å°±ä¸ªäººè€Œè¨€ï¼Œæˆ‘éå¸¸å–œæ¬¢YouTubeä¸Šçš„æ’­å®¢å’Œæ¼”è®²ã€‚è¿™äº›æ’­å®¢å’Œæ¼”è®²æ˜¯çŸ¥è¯†çš„å®è—ï¼Œå……æ»¡äº†æ¥è‡ªå„ä¸ªé¢†åŸŸé¡¶å°–äººæ‰çš„è§è§£ã€‚ç„¶è€Œï¼Œç”±äºæ—¶é—´é™åˆ¶ï¼Œæˆ‘æ— æ³•è§‚çœ‹æ¯ä¸€ä¸ªæœ‰è¶£çš„è§†é¢‘ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸è¶…è¿‡ä¸€å°æ—¶ã€‚è¿™è®©æˆ‘å¼€å§‹æ€è€ƒï¼šå¦‚æœæˆ‘èƒ½åˆ›å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆæ¥è‡ªåŠ¨æå–ä¸»è¦äº®ç‚¹å‘¢ï¼Ÿå› æ­¤ï¼Œæˆ‘å¼€å§‹æ¢ç´¢AIç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©æˆ‘è·å–ä¸€äº›é”™è¿‡çš„æ’­å®¢/æ¼”è®²çš„è‡ªåŠ¨æ‘˜è¦ã€‚
- en: In this article, I discuss the end-to-end solution on a local PC. First, I will
    cover the transcription process of one of [Stephen Wolfram's talks about ChatGPT,
    AI, and AGI](https://www.youtube.com/watch?v=szxiPMyuMGY) available on Youtube*,*
    using the open-source [Whisper Model](https://huggingface.co/openai/whisper-medium)
    available on [HuggingFace Hub](https://huggingface.co/). Then, I will demonstrate
    how to summarize long text using the open-source [BART](https://arxiv.org/abs/1910.13461)
    model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘è®¨è®ºäº†åœ¨æœ¬åœ°PCä¸Šè¿›è¡Œç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆã€‚é¦–å…ˆï¼Œæˆ‘å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨å¼€æºçš„[Whisperæ¨¡å‹](https://huggingface.co/openai/whisper-medium)ï¼Œå¯¹[æ–¯è’‚èŠ¬Â·æ²ƒå°”å¤«å‹’å§†å…³äºChatGPTã€AIå’ŒAGIçš„æ¼”è®²](https://www.youtube.com/watch?v=szxiPMyuMGY)è¿›è¡Œè½¬å½•ï¼Œè¯¥æ¼”è®²åœ¨YouTubeä¸Šå¯ç”¨ã€‚æ¥ç€ï¼Œæˆ‘å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¼€æºçš„[BART](https://arxiv.org/abs/1910.13461)æ¨¡å‹æ€»ç»“é•¿æ–‡æœ¬ã€‚
- en: Letâ€™s see how to achieve this.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å®ç°è¿™ä¸ªç›®æ ‡ã€‚
- en: Keep in mind, it is crucial to verify that the copyright/licence permits downloading
    the content before you proceed with the download.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¯·è®°ä½ï¼Œç¡®ä¿åœ¨ä¸‹è½½å†…å®¹ä¹‹å‰æ ¸å®ç‰ˆæƒ/è®¸å¯æ˜¯å¦å…è®¸ä¸‹è½½æ˜¯è‡³å…³é‡è¦çš„ã€‚
- en: A bit of context
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€ç‚¹èƒŒæ™¯
- en: '[**Whisper**](https://cdn.openai.com/papers/whisper.pdf)is an open-source automatic
    speech recognition model, trained on 680,000 hours of multilingual data gathered
    from the internet. It relies on an end-to-end encoder-decoder [Transformer](https://arxiv.org/abs/1706.03762)
    architecture.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**Whisper**](https://cdn.openai.com/papers/whisper.pdf)æ˜¯ä¸€ä¸ªå¼€æºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼ŒåŸºäºä»äº’è”ç½‘æ”¶é›†çš„680,000å°æ—¶å¤šè¯­è¨€æ•°æ®è¿›è¡Œè®­ç»ƒã€‚å®ƒä¾èµ–äºç«¯åˆ°ç«¯çš„ç¼–ç å™¨-è§£ç å™¨[Transformer](https://arxiv.org/abs/1706.03762)æ¶æ„ã€‚'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**BART**](https://arxiv.org/abs/1910.13461) is a transformer-based seq2seq
    model that combines a bidirectional (BERT-style) encoder with an autoregressive
    (GPT-style) decoder. Itâ€™s pre-trained by randomly adding noise and learning to
    rebuild the original content.It performs well on tacks such as summmarization
    and translation.'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**BART**](https://arxiv.org/abs/1910.13461) æ˜¯ä¸€ä¸ªåŸºäº Transformer çš„ seq2seq æ¨¡å‹ï¼Œç»“åˆäº†åŒå‘ï¼ˆBERT
    é£æ ¼ï¼‰ç¼–ç å™¨å’Œè‡ªå›å½’ï¼ˆGPT é£æ ¼ï¼‰è§£ç å™¨ã€‚å®ƒé€šè¿‡éšæœºæ·»åŠ å™ªå£°å¹¶å­¦ä¹ é‡å»ºåŸå§‹å†…å®¹è¿›è¡Œé¢„è®­ç»ƒï¼Œåœ¨æ€»ç»“å’Œç¿»è¯‘ç­‰ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ã€‚'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**HuggingFace transformers**](https://huggingface.co/docs/transformers/index)
    library provides a user-friendly solution to use and customize models. Additionally,
    it comes with APIs you can use to fine-tune the models to better fit your data.'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**HuggingFace transformers**](https://huggingface.co/docs/transformers/index)
    åº“æä¾›äº†ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„è§£å†³æ–¹æ¡ˆæ¥ä½¿ç”¨å’Œè‡ªå®šä¹‰æ¨¡å‹ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æä¾›äº†å¯ä»¥ç”¨äºå¾®è°ƒæ¨¡å‹ä»¥æ›´å¥½åœ°é€‚åº”æ•°æ®çš„ APIã€‚'
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**PyTube**](https://github.com/pytube/pytube) is a depenency-free Python library
    for downloading and streaming YouTube videos.'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**PyTube**](https://github.com/pytube/pytube) æ˜¯ä¸€ä¸ªæ— éœ€ä¾èµ–çš„ Python åº“ï¼Œç”¨äºä¸‹è½½å’Œæµå¼ä¼ è¾“
    YouTube è§†é¢‘ã€‚'
- en: ''
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**NLTK**](https://www.nltk.org/)is a Natural Language Toolkit standard Python
    library widely used for natural language processing(NLP) tasks.'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**NLTK**](https://www.nltk.org/)æ˜¯ä¸€ä¸ªæ ‡å‡†çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡çš„ Python åº“ã€‚'
- en: The end-to-end process
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç«¯åˆ°ç«¯è¿‡ç¨‹
- en: 'The process contains four main steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‡ç¨‹åŒ…å«å››ä¸ªä¸»è¦æ­¥éª¤ï¼š
- en: 1\. Set up the environment
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1\. è®¾ç½®ç¯å¢ƒ
- en: ''
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '2\. Download the YouTube video : PyTube'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2\. ä¸‹è½½ YouTube è§†é¢‘ï¼šPyTube
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '3\. Transcribe the audio: Whisper'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 3\. è½¬å½•éŸ³é¢‘ï¼šWhisper
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '4\. Summarize the generated text: BART'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 4\. æ€»ç»“ç”Ÿæˆçš„æ–‡æœ¬ï¼šBART
- en: '![](../Images/89c729e6ad301d77e5fd22684596eeaa.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89c729e6ad301d77e5fd22684596eeaa.png)'
- en: image by the author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 1\. Set up the environment
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. è®¾ç½®ç¯å¢ƒ
- en: 'My environment setup looks as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„ç¯å¢ƒè®¾ç½®å¦‚ä¸‹ï¼š
- en: '**Jupyter Notebook** running in a virtual environment with Python 3.10'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jupyter Notebook** åœ¨ä¸€ä¸ªä½¿ç”¨ Python 3.10 çš„è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ'
- en: '**Models***:* [OpenAI Whisper](https://github.com/openai/whisper), [BART](https://huggingface.co/facebook/bart-large-cnn)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹**ï¼š [OpenAI Whisper](https://github.com/openai/whisper), [BART](https://huggingface.co/facebook/bart-large-cnn)'
- en: '**Libraries**: [pytube](https://pypi.org/project/pytube/), [transformers](https://huggingface.co/docs/transformers/index),
    [unstructured](https://pypi.org/project/unstructured/), ffmpeg-python'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åº“**ï¼š [pytube](https://pypi.org/project/pytube/), [transformers](https://huggingface.co/docs/transformers/index),
    [unstructured](https://pypi.org/project/unstructured/), ffmpeg-python'
- en: 1.1 Install the libraries
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 å®‰è£…åº“
- en: 'Several remarks:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›å¤‡æ³¨ï¼š
- en: '**ğŸ‘‰** ï¸Please be aware that you need `!` only if you install the libraries
    from a notebook cell.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**ğŸ‘‰** è¯·æ³¨æ„ï¼Œåªæœ‰åœ¨ä»ç¬”è®°æœ¬å•å…ƒæ ¼å®‰è£…åº“æ—¶æ‰éœ€è¦ `!`ã€‚'
- en: '**ğŸ‘‰** Install the latest update of the Whisper model directly from GitHub.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**ğŸ‘‰** ç›´æ¥ä» GitHub å®‰è£… Whisper æ¨¡å‹çš„æœ€æ–°æ›´æ–°ã€‚'
- en: '**ğŸ‘‰ Troubleshoot PyTube.** In case you run into the following error `"pytube:
    AttributeError: â€˜NoneTypeâ€™ object has no attribute â€˜spanâ€™ cipher.p"` y go to `{home}/.local/lib/{your_pythonversion:
    ex. python3.10}/site-packages/pytube/cipher.py Line 411` and replace the value
    of the`transform_plan_raw` variable as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**ğŸ‘‰ è§£å†³ PyTube é—®é¢˜ã€‚** å¦‚æœé‡åˆ°ä»¥ä¸‹é”™è¯¯ `"pytube: AttributeError: â€˜NoneTypeâ€™ object has
    no attribute â€˜spanâ€™ cipher.p"`ï¼Œè¯·å‰å¾€ `{home}/.local/lib/{your_pythonversion: ex.
    python3.10}/site-packages/pytube/cipher.py Line 411` å¹¶å°† `transform_plan_raw` å˜é‡çš„å€¼æ›¿æ¢å¦‚ä¸‹ï¼š'
- en: 1.2 Import the libraries
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 å¯¼å…¥åº“
- en: 1\. Download the YouTube video
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. ä¸‹è½½ YouTube è§†é¢‘
- en: Letâ€™s get the summary of the following talk â€œ[*ChatGPT, AI, and AGI with Stephen
    Wolfram*](https://www.youtube.com/watch?v=szxiPMyuMGY) *(*Founder & CEO of Wolfram
    Research*)*â€ *available* on YouTube ([Creative Commons Attribution license (reuse
    allowed)](https://www.youtube.com/t/creative_commons)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è·å–ä»¥ä¸‹æ¼”è®²çš„æ€»ç»“â€œ[*ChatGPT, AI, and AGI with Stephen Wolfram*](https://www.youtube.com/watch?v=szxiPMyuMGY)
    *(Wolfram Research åˆ›å§‹äººå…¼é¦–å¸­æ‰§è¡Œå®˜)*â€ *åœ¨* YouTube ä¸Šå¯ç”¨ ([åˆ›ä½œå…±äº«è®¸å¯ï¼ˆå…è®¸é‡ç”¨ï¼‰](https://www.youtube.com/t/creative_commons))ã€‚
- en: To download locally the video as an audio file we use the YouTube class of the
    PyTube library. Make sure to provide a valid URL.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å°†è§†é¢‘æœ¬åœ°ä¸‹è½½ä¸ºéŸ³é¢‘æ–‡ä»¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ PyTube åº“çš„ YouTube ç±»ã€‚ç¡®ä¿æä¾›æœ‰æ•ˆçš„ URLã€‚
- en: 2\. Transcribe the audio
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. è½¬å½•éŸ³é¢‘
- en: Once we have downloaded the audio locally, we should see a file called `demo.mp3`.
    To transcribe the audio, we load the `medium Whisper multilingual model`, which
    has 769 million parameters and is available in either English or a multilingual
    format. You can review the list of [language models available](https://github.com/openai/whisper#available-models-and-languages)
    and choose the more convenient one for your setup. For more accuracy, you can
    use `the large Whisper multilingual model`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬å°†éŸ³é¢‘ä¸‹è½½åˆ°æœ¬åœ°ï¼Œæˆ‘ä»¬åº”è¯¥ä¼šçœ‹åˆ°ä¸€ä¸ªåä¸º `demo.mp3` çš„æ–‡ä»¶ã€‚è¦è½¬å½•éŸ³é¢‘ï¼Œæˆ‘ä»¬åŠ è½½ `medium Whisper multilingual
    model`ï¼Œå®ƒå…·æœ‰ 7.69 äº¿ä¸ªå‚æ•°ï¼Œå¹¶æä¾›è‹±è¯­æˆ–å¤šè¯­è¨€æ ¼å¼ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹[å¯ç”¨è¯­è¨€æ¨¡å‹åˆ—è¡¨](https://github.com/openai/whisper#available-models-and-languages)ï¼Œé€‰æ‹©æœ€é€‚åˆæ‚¨è®¾ç½®çš„æ¨¡å‹ã€‚ä¸ºäº†æ›´é«˜çš„å‡†ç¡®æ€§ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨
    `large Whisper multilingual model`ã€‚
- en: The resulting concatenated string will be stored in the `result[â€˜textâ€™]` variable,
    which is saved locally in `demo.txt` file.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå¹¶åçš„å­—ç¬¦ä¸²å°†å­˜å‚¨åœ¨ `result[â€˜textâ€™]` å˜é‡ä¸­ï¼Œå¹¶ä¿å­˜åœ¨æœ¬åœ°çš„ `demo.txt` æ–‡ä»¶ä¸­ã€‚
- en: â—ï¸ Itâ€™s important to note that the transcription process may take over an hour,
    depending on your PCâ€™s configuration. To test the demo, you may choose a shorter
    video.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: â—ï¸ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè½¬å½•è¿‡ç¨‹å¯èƒ½éœ€è¦è¶…è¿‡ä¸€ä¸ªå°æ—¶ï¼Œå…·ä½“å–å†³äºæ‚¨çš„ç”µè„‘é…ç½®ã€‚è¦æµ‹è¯•æ¼”ç¤ºï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä¸€ä¸ªè¾ƒçŸ­çš„è§†é¢‘ã€‚
- en: 3\. Summarize the generated text
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. æ€»ç»“ç”Ÿæˆçš„æ–‡æœ¬
- en: Because of the modelâ€™s incapacity to handle multiple tokens at once, itâ€™s important
    to split the text into smaller segments, each containing a maximum of 4000 tokens.
    To do this, we can use the `punkt` pre-trained sentence tokenizer model, which
    is part of the Natural Language Toolkit (NLTK) library and is effective in processing
    natural language. Once weâ€™ve divided the text into smaller sentence chunks, we
    can store them in the `text_chunks` variable for further use.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæ¨¡å‹æ— æ³•ä¸€æ¬¡å¤„ç†å¤šä¸ªæ ‡è®°ï¼Œå› æ­¤é‡è¦çš„æ˜¯å°†æ–‡æœ¬åˆ†å‰²æˆè¾ƒå°çš„æ®µè½ï¼Œæ¯ä¸ªæ®µè½æœ€å¤šåŒ…å« 4000 ä¸ªæ ‡è®°ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `punkt` é¢„è®­ç»ƒå¥å­åˆ†å‰²æ¨¡å‹ï¼Œå®ƒæ˜¯è‡ªç„¶è¯­è¨€å·¥å…·åŒ…ï¼ˆNLTKï¼‰åº“çš„ä¸€éƒ¨åˆ†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è‡ªç„¶è¯­è¨€ã€‚ä¸€æ—¦æˆ‘ä»¬å°†æ–‡æœ¬åˆ†å‰²æˆè¾ƒå°çš„å¥å­å—ï¼Œå°±å¯ä»¥å°†å®ƒä»¬å­˜å‚¨åœ¨
    `text_chunks` å˜é‡ä¸­ä»¥ä¾›è¿›ä¸€æ­¥ä½¿ç”¨ã€‚
- en: We use sentence tokenization to prevent any loss of information
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨å¥å­åˆ†å‰²ä»¥é˜²æ­¢ä¿¡æ¯ä¸¢å¤±
- en: 3.1 Divide the large text into chunks
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 å°†å¤§æ–‡æœ¬åˆ†å‰²æˆå—
- en: Hereâ€™s the code that can be used to do the work.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å¯ä»¥ç”¨æ¥å®Œæˆå·¥ä½œçš„ä»£ç ã€‚
- en: 'The code consists of two functions: `read_file()` that reads the `demo.txt`
    file and `split_text_into_chunks()` that splits the text into chunks.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç åŒ…æ‹¬ä¸¤ä¸ªå‡½æ•°ï¼š`read_file()` ç”¨äºè¯»å– `demo.txt` æ–‡ä»¶ï¼Œ`split_text_into_chunks()` ç”¨äºå°†æ–‡æœ¬åˆ†å‰²æˆå—ã€‚
- en: 3.2 Text Summarization with BART
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 ä½¿ç”¨ BART è¿›è¡Œæ–‡æœ¬æ‘˜è¦
- en: To summarize the text we use the `HuggingFace Transformers`library and the pre-trained
    multilingual BART-large model, `[facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)`
    fine-tuned on the CNN Daily Mail dataset. The Transformers library by Hugging
    Face offers many ready-to-use models for various tasks like text, images, or sounds.
    For instance, it provides an easy-to-use text summarization pipeline for the BART
    model:`pipeline("summarization", model="facebook/bart-large-cnn").` This makes
    it easy and user-friendly.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ€»ç»“æ–‡æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨ `HuggingFace Transformers` åº“å’Œé¢„è®­ç»ƒçš„å¤šè¯­è¨€ BART-large æ¨¡å‹ï¼Œ`[facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)`ï¼Œè¯¥æ¨¡å‹åœ¨
    CNN Daily Mail æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¾®è°ƒã€‚Hugging Face çš„ Transformers åº“æä¾›äº†è®¸å¤šç”¨äºæ–‡æœ¬ã€å›¾åƒæˆ–å£°éŸ³ç­‰å„ç§ä»»åŠ¡çš„ç°æˆæ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„
    BART æ¨¡å‹æ–‡æœ¬æ‘˜è¦ç®¡é“ï¼š`pipeline("summarization", model="facebook/bart-large-cnn")`ã€‚è¿™ä½¿å¾—ä½¿ç”¨èµ·æ¥ç®€å•è€Œå‹å¥½ã€‚
- en: The code for performing the summarization is provided below.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æ‰§è¡Œæ‘˜è¦ç”Ÿæˆçš„ä»£ç ã€‚
- en: Overall, the code creates an instance of the BART summarizer, generates a summary
    for the given text chunks, and saves it to`summary_demo.txt` file only if the
    summary is successfully generated. If the summary has more than 5000 characters
    we will proceed by applying once gain the Bart summarizer. The output is saved
    in the `short_summary_demo.txt` file.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä½“è€Œè¨€ï¼Œä»£ç åˆ›å»ºäº† BART æ‘˜è¦ç”Ÿæˆå™¨çš„ä¸€ä¸ªå®ä¾‹ï¼Œä¸ºç»™å®šçš„æ–‡æœ¬å—ç”Ÿæˆæ‘˜è¦ï¼Œå¹¶ä»…åœ¨æˆåŠŸç”Ÿæˆæ‘˜è¦æ—¶å°†å…¶ä¿å­˜åˆ° `summary_demo.txt` æ–‡ä»¶ä¸­ã€‚å¦‚æœæ‘˜è¦è¶…è¿‡
    5000 ä¸ªå­—ç¬¦ï¼Œæˆ‘ä»¬å°†å†æ¬¡ä½¿ç”¨ BART æ‘˜è¦ç”Ÿæˆå™¨ã€‚è¾“å‡ºå°†ä¿å­˜åœ¨ `short_summary_demo.txt` æ–‡ä»¶ä¸­ã€‚
- en: '**Here is the summary:**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¿™æ˜¯æ€»ç»“ï¼š**'
- en: The Wolfram language could be the basis for a more systematic exploration of
    the nature and the depths of large language models. Itâ€™s a precise computational
    language, but it talks about the real world. Thereâ€™s not a lot of boilerplate
    in LLM. Chat GPT is showing us, I think, an important piece of science. Weâ€™ve
    automated out the boilerplate. My guess is that increasingly as people use it
    for real, theyâ€™ll just edit the code. And it will have done a large part of the
    work in making the initial five lines of code. There are more regularities to
    describe meaning. Itâ€™s really a question of where the boundaries are between what
    the LLM can produce, what we can catch with our natural language understanding
    system. Weâ€™ve had billions of years to evolve, to deal with the way that nature
    is. Microsoft Research published a 154-page analysis of GPT-4 where they conclude,
    and it is in the title of their paper, they are seeing glimpses of AGI. The computational
    universe of possible things you can do is very big. We humans care about only
    a small fraction of that. The question is to connect those things that are out
    in the computational universe with things that we humans are interested in. In
    1900, people would not have been surprised to think that space would be discrete.
    One of the things that Iâ€™m sort of hoping for in the not too distant future is
    weâ€™ll actually find a phenomenon that is kind of like the Brownian motion of space
    and where weâ€™ll be able to see, we can tell that itâ€™s discrete.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Wolfram è¯­è¨€å¯èƒ½æˆä¸ºæ›´ç³»ç»Ÿæ¢ç´¢å¤§å‹è¯­è¨€æ¨¡å‹æœ¬è´¨å’Œæ·±åº¦çš„åŸºç¡€ã€‚è¿™æ˜¯ä¸€ç§ç²¾ç¡®çš„è®¡ç®—è¯­è¨€ï¼Œä½†å®ƒè°ˆè®ºçš„æ˜¯ç°å®ä¸–ç•Œã€‚LLM ä¸­æ²¡æœ‰å¤ªå¤šçš„æ¨¡æ¿ä»£ç ã€‚æˆ‘è®¤ä¸º
    Chat GPT å‘æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªé‡è¦çš„ç§‘å­¦ç‰‡æ®µã€‚æˆ‘ä»¬å·²ç»è‡ªåŠ¨åŒ–äº†æ¨¡æ¿ä»£ç ã€‚æˆ‘çš„çŒœæµ‹æ˜¯ï¼Œéšç€äººä»¬è¶Šæ¥è¶Šå¤šåœ°å®é™…ä½¿ç”¨å®ƒï¼Œä»–ä»¬åªä¼šç¼–è¾‘ä»£ç ã€‚è€Œå®ƒå°†å®Œæˆå¤§é‡çš„åˆå§‹äº”è¡Œä»£ç çš„å·¥ä½œã€‚æè¿°æ„ä¹‰çš„è§„å¾‹æ€§æ›´å¤šäº†ã€‚è¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå³
    LLM å¯ä»¥ç”Ÿæˆçš„å†…å®¹ä¸æˆ‘ä»¬è‡ªç„¶è¯­è¨€ç†è§£ç³»ç»Ÿå¯ä»¥æ•æ‰çš„å†…å®¹ä¹‹é—´çš„ç•Œé™åœ¨å“ªé‡Œã€‚æˆ‘ä»¬å·²ç»æœ‰æ•°åäº¿å¹´çš„è¿›åŒ–æ—¶é—´æ¥å¤„ç†è‡ªç„¶çš„æ–¹å¼ã€‚å¾®è½¯ç ”ç©¶é™¢å‘å¸ƒäº†ä¸€ä»½å…³äº GPT-4
    çš„154é¡µåˆ†ææŠ¥å‘Šï¼Œåœ¨æŠ¥å‘Šä¸­ä»–ä»¬å¾—å‡ºç»“è®ºï¼Œå¹¶ä¸”è¿™æ˜¯ä»–ä»¬è®ºæ–‡æ ‡é¢˜ä¸­çš„å†…å®¹ï¼Œä»–ä»¬çœ‹åˆ°äº† AGI çš„ä¸€ç¥ã€‚ä½ å¯ä»¥åšçš„è®¡ç®—å®‡å®™çš„å¯èƒ½æ€§æ˜¯éå¸¸å¤§çš„ã€‚æˆ‘ä»¬äººç±»åªå…³å¿ƒå…¶ä¸­çš„ä¸€å°éƒ¨åˆ†ã€‚é—®é¢˜åœ¨äºå°†è®¡ç®—å®‡å®™ä¸­çš„äº‹ç‰©ä¸æˆ‘ä»¬äººç±»æ„Ÿå…´è¶£çš„äº‹ç‰©è¿æ¥èµ·æ¥ã€‚åœ¨1900å¹´ï¼Œäººä»¬ä¸ä¼šæ„Ÿåˆ°æƒŠè®¶åœ°è®¤ä¸ºç©ºé—´æ˜¯ç¦»æ•£çš„ã€‚æˆ‘å¸Œæœ›åœ¨ä¸ä¹…çš„å°†æ¥ï¼Œæˆ‘ä»¬å®é™…ä¸Šèƒ½æ‰¾åˆ°ä¸€ç§ç±»ä¼¼äºç©ºé—´å¸ƒæœ—è¿åŠ¨çš„ç°è±¡ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿçœ‹åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šå®ƒæ˜¯ç¦»æ•£çš„ã€‚
- en: Key takeaways
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸»è¦æ”¶è·
- en: The tutorial is part of a personal side project focused on exploring generative
    AI tools.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ•™ç¨‹æ˜¯ä¸€ä¸ªä¸ªäººå‰¯é¡¹ç›®çš„ä¸€éƒ¨åˆ†ï¼Œä¸“æ³¨äºæ¢ç´¢ç”Ÿæˆæ€§ AI å·¥å…·ã€‚
- en: To conclude, the Whisper model gave excellent results on all tested videos.
    Although it occasionally misidentified product or person names, I am quite happy
    with the outcome and will definitely keep using it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“ä¸€ä¸‹ï¼ŒWhisper æ¨¡å‹åœ¨æ‰€æœ‰æµ‹è¯•çš„è§†é¢‘ä¸­éƒ½è¡¨ç°å‡ºè‰²ã€‚å°½ç®¡å®ƒå¶å°”ä¼šè¯¯è¯†åˆ«äº§å“æˆ–äººç‰©åç§°ï¼Œä½†æˆ‘å¯¹ç»“æœç›¸å½“æ»¡æ„ï¼Œå¹¶ä¸”ä¼šç»§ç»­ä½¿ç”¨å®ƒã€‚
- en: On the other hand, the BART model offers a trustworthy open-source option for
    summarization. Its summaries are quite effective. I compared it to the [T5 model
    from Google Research](https://huggingface.co/docs/transformers/model_doc/t5) and
    BARTâ€™s summaries were superior. Indeed, it may not always capture all the key
    facts, but it delivers good results, so Iâ€™ll continue using it for my personal
    summary tasks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼ŒBART æ¨¡å‹æä¾›äº†ä¸€ä¸ªå€¼å¾—ä¿¡èµ–çš„å¼€æºæ‘˜è¦é€‰é¡¹ã€‚å®ƒçš„æ‘˜è¦æ•ˆæœç›¸å½“å¥½ã€‚æˆ‘å°†å®ƒä¸ [è°·æ­Œç ”ç©¶çš„ T5 æ¨¡å‹](https://huggingface.co/docs/transformers/model_doc/t5)
    è¿›è¡Œäº†æ¯”è¾ƒï¼ŒBART çš„æ‘˜è¦æ›´ä¼˜ã€‚çš„ç¡®ï¼Œå®ƒå¯èƒ½å¹¶ä¸æ€»æ˜¯æ•æ‰åˆ°æ‰€æœ‰å…³é”®äº‹å®ï¼Œä½†å®ƒçš„ç»“æœå¾ˆå¥½ï¼Œæ‰€ä»¥æˆ‘ä¼šç»§ç»­ä½¿ç”¨å®ƒæ¥å¤„ç†æˆ‘çš„ä¸ªäººæ€»ç»“ä»»åŠ¡ã€‚
- en: Overall AI-generative solutions like Whisper and BART help me efficiently extract
    important insights from long podcasts and talks. This way I can stay informed
    even when I am running out of spare time.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä½“è€Œè¨€ï¼Œåƒ Whisper å’Œ BART è¿™æ ·çš„ AI ç”Ÿæˆè§£å†³æ–¹æ¡ˆå¸®åŠ©æˆ‘é«˜æ•ˆæå–é•¿æ—¶é—´æ’­å®¢å’Œæ¼”è®²ä¸­çš„é‡è¦è§è§£ã€‚è¿™æ ·ï¼Œå³ä½¿åœ¨æˆ‘æ²¡æœ‰å‰©ä½™æ—¶é—´çš„æ—¶å€™ï¼Œæˆ‘ä¹Ÿèƒ½ä¿æŒä¿¡æ¯æ›´æ–°ã€‚
- en: I hope that you enjoyed the article.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ã€‚
- en: Thank you for reading!
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼
- en: Donâ€™t forget to [subscribe](https://medium.com/subscribe/@anna.bildea) if you
    want to get my future stories in your inbox.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³å°†æ¥åœ¨æ”¶ä»¶ç®±ä¸­æ”¶åˆ°æˆ‘çš„æ•…äº‹ï¼Œä¸è¦å¿˜è®° [è®¢é˜…](https://medium.com/subscribe/@anna.bildea)ã€‚
- en: '*If you enjoy reading my story and want to support me as a writer, consider
    signing up to become a Medium member and gain access to thousands of Data Engineering
    and Data Science articles.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦‚æœä½ å–œæ¬¢é˜…è¯»æˆ‘çš„æ•…äº‹å¹¶å¸Œæœ›æ”¯æŒæˆ‘ä½œä¸ºä½œå®¶ï¼Œå¯ä»¥è€ƒè™‘æ³¨å†Œæˆä¸º Medium ä¼šå‘˜ï¼Œè®¿é—®æ•°åƒç¯‡æ•°æ®å·¥ç¨‹å’Œæ•°æ®ç§‘å­¦æ–‡ç« ã€‚*'
- en: '[](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
    [## Join Medium with my referral link â€” Bildea Ana'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
    [## ä½¿ç”¨æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium â€” Bildea Ana'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every storyâ€¦
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½œä¸ºMediumä¼šå‘˜ï¼Œæ‚¨ä¼šå‘˜è´¹çš„ä¸€éƒ¨åˆ†å°†åˆ†é…ç»™æ‚¨é˜…è¯»çš„ä½œè€…ï¼Œæ‚¨å°†è·å¾—å¯¹æ¯ç¯‡æ•…äº‹çš„å®Œæ•´è®¿é—®æƒé™â€¦
- en: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/)
    *and* [Twitter](https://twitter.com/AnaBildea)!'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*åœ¨* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/) *å’Œ*
    [Twitter](https://twitter.com/AnaBildea) *ä¸Šæ‰¾åˆ°æˆ‘*!'
- en: See my collection of Generative AI, MLOps, and Responsible AI articles
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹æˆ‘å…³äºç”Ÿæˆæ€§AIã€MLOpså’Œè´Ÿè´£ä»»AIçš„æ–‡ç« åˆé›†
- en: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![Ana Bildeaåšå£«](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildeaåšå£«](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: Generative AI
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæ€§AI
- en: '[View list](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----a2a542b6698d--------------------------------)11
    stories![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----a2a542b6698d--------------------------------)11ä¸ªæ•…äº‹![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildeaåšå£«](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildeaåšå£«](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: Responsible AI
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è´Ÿè´£ä»»çš„AI
- en: '[View list](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----a2a542b6698d--------------------------------)1
    story![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----a2a542b6698d--------------------------------)1ä¸ªæ•…äº‹![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)![Ana
    Bildeaåšå£«](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildeaåšå£«](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: MLOps - AI in Production
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps - AIåœ¨ç”Ÿäº§ä¸­çš„åº”ç”¨
- en: '[View list](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----a2a542b6698d--------------------------------)4
    stories![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----a2a542b6698d--------------------------------)4ä¸ªæ•…äº‹![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
