- en: Anomaly Detection in TensorFlow and Keras Using the Autoencoder Method
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自动编码器方法在TensorFlow和Keras中进行异常检测
- en: 原文：[https://towardsdatascience.com/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50](https://towardsdatascience.com/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50](https://towardsdatascience.com/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50)
- en: '![](../Images/06b21f76fa65b8247eabeb45da835d72.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06b21f76fa65b8247eabeb45da835d72.png)'
- en: Photo by [Leiada Krozjhen](https://unsplash.com/@leiadakrozjhen?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Leiada Krozjhen](https://unsplash.com/@leiadakrozjhen?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: A cutting-edge unsupervised method for noise removal, dimensionality reduction,
    anomaly detection, and more
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种前沿的无监督方法，用于去噪、降维、异常检测等
- en: '[](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)
    ·7 min read·Sep 23, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)
    ·阅读时间7分钟·2023年9月23日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: All the tutorials about TensorFlow and neural networks I have shared until now
    have been about supervised learning. This one will be about the Autoenocder which
    is an unsupervised learning technique. If I want to express it simply, autoencoders
    **reduce the noises** from the data by **compressing the input data**, and encoding
    and reconstructing the data. That way autoencoders can **reduce the dimensionality**
    or the noise of the data and focus on the real focal point of the input data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 直到现在，我分享的所有关于TensorFlow和神经网络的教程都是关于有监督学习的。这一次将介绍自动编码器，它是一种无监督学习技术。简单来说，自动编码器**通过压缩输入数据**来**减少噪声**，并对数据进行编码和重建。这样，自动编码器可以**减少数据的维度**或噪声，专注于输入数据的实际重点。
- en: As you can see from the introduction to the autoencoders here there is more
    than one process required.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，自动编码器介绍中涉及的不止一个过程。
- en: First, a model to compress the input data which is the encoder model.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，构建一个压缩输入数据的模型，即编码器模型。
- en: Then another model to reconstruct the compressed data that should be as close
    as the input data which is a decoder model.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后另一个模型用于重建压缩数据，这个模型是解码器模型，它应该尽可能接近输入数据。
- en: In this process, it can remove the noise, reduce the dimensionality, and clear
    up the input data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，它可以去除噪声、减少维度，并清理输入数据。
- en: In this tutorial, I will explain in detail how an autoencoder works with a working
    example.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我将详细解释自动编码器的工作原理，并提供一个实际示例。
- en: For this example, I chose to use a [public dataset](https://github.com/AlexOlsen/DeepWeeds/blob/master/LICENSE)
    (Apache License 2.0) named deep_weeds.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我选择使用一个名为deep_weeds的[公开数据集](https://github.com/AlexOlsen/DeepWeeds/blob/master/LICENSE)（Apache许可证2.0）。
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Data Preparation
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: We need to prepare a dataset for this unsupervised anomaly detection example.
    Only one class will be taken as our main class that will be considered as the
    valid class. And I will put a few data from another class as an anomaly. Then
    we will develop the model to see if we can find that few anomaly data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为这个无监督异常检测示例准备一个数据集。只有一个类别将被视为我们的主类别，即有效类别。我会从另一个类别中添加一些数据作为异常。然后我们将开发模型，看看能否找出这些少量的异常数据。
- en: I chose class 5 as the valid class and class 1 as the anomaly. In the code block
    below, I am taking all the data of classes 5 and 1 first and creating lists of
    the images and their corresponding labels.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了类别 5 作为有效类别，类别 1 作为异常类别。在下面的代码块中，我首先获取类别 5 和类别 1 的所有数据，并创建图像及其对应标签的列表。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s see the shape of the main image (images of class 5) data here:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这里主图像（类别 5 图像）的形状：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The image shapes are (256, 256, 3) and we have a total of 1009 data for class
    5.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的形状是 (256, 256, 3)，我们有总共 1009 张属于类别 5 的数据。
- en: However, we do not need all the data from class 1\. Because class 1 is the anomaly
    class. So, only 1% of the class 1 data will be taken for the training.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们不需要类别 1 的所有数据。因为类别 1 是异常类别。所以，只有 1% 的类别 1 数据会被用于训练。
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The shape of the total_images:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 总图像的形状：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Output:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We have a total of 1020 images for training. As we saw earlier, we have 1009
    class 5 images, and we took 1020–1009 = 11 of class 1 images which is our anomaly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们共有 1020 张用于训练的图像。如前所述，我们有 1009 张类别 5 的图像，我们取了 1020–1009 = 11 张类别 1 的图像，这些是我们的异常图像。
- en: Let’s see if we can develop an autoencoder model in Keras and Tensorflow to
    detect these anomalies.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看是否可以在 Keras 和 TensorFlow 中开发一个自动编码器模型来检测这些异常。
- en: Model Development
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型开发
- en: 'This is the fun part! But first, we should do the necessary imports:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是有趣的部分！但首先，我们应该进行必要的导入：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Some of the data should be kept separately for testing purposes. The train_test_split
    method from the sklearn library can be used for that. Remember, as this is an
    unsupervised learning method, the labels are not necessary. We will only split
    the images.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据应该单独保留用于测试目的。可以使用 sklearn 库中的 train_test_split 方法来实现。记住，由于这是无监督学习方法，标签不是必需的。我们将仅分割图像。
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, the autoencoder model. We will build a Convolution_Autoencoder class
    which is a Convolutional Neural Network. The class has the build method where
    we will define the Autoencoder model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，自动编码器模型。我们将构建一个 Convolution_Autoencoder 类，这是一种卷积神经网络。该类具有 build 方法，在此方法中我们将定义
    Autoencoder 模型。
- en: The ‘build’ takes width, depth, height, filters, and latentDim as parameters.
    Here, width, depth, and height are the dimensions of the images that is (256,
    256, 3) for us as we have seen with the total_images.shape method above.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ‘build’ 方法接受宽度、深度、高度、滤波器和 latentDim 作为参数。在这里，宽度、深度和高度是图像的维度，对于我们来说是 (256, 256,
    3)，正如我们在上面的 total_images.shape 方法中看到的。
- en: The parameter ‘filters’ is the filter for the convolution layers.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 参数‘filters’是卷积层的滤波器。
- en: The ‘latentDim’ is the size of our compressed layer after the encoder method.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ‘latentDim’ 是我们在编码器方法后压缩层的大小。
- en: In this build method, the first part is an encoder model which is a simple Convolutional
    Neural Network.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个 build 方法中，第一部分是一个简单的卷积神经网络（CNN）作为编码器模型。
- en: Once the encoder portion is done, a decoder model is developed using Conv2DTranspose
    layers to reconstruct the data again.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦编码器部分完成后，将使用 Conv2DTranspose 层开发解码器模型，以再次重建数据。
- en: Then, we construct the autoencoder model which is actually a combination of
    both encoder and decoder models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们构建自动编码器模型，这实际上是编码器和解码器模型的组合。
- en: Finally, we return the encoder, decoder, and autoencoder models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们返回编码器、解码器和自动编码器模型。
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Model development is done. It’s time to run the model and see if it works. It
    should run like any other TensorFlow model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发完成了。现在是运行模型并查看其是否有效的时候了。它应该像任何其他 TensorFlow 模型一样运行。
- en: Here we will compile the model first with Adam optimizer. And also, I used a
    decay in the learning rate and the ‘mse’ as the loss.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将首先使用 Adam 优化器编译模型。同时，我在学习率中使用了衰减，并将“mse”作为损失函数。
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, running the model. Remember, this is an unsupervised learning method.
    So there won''t be any label in the model training. Instead, we need to pass two
    training features which will be just train_x twice. If you notice the build method
    in the Convolution_Autoencoder class, autoencoder looks like this there:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，运行模型。记住，这是一种无监督学习方法。所以在模型训练中不会有任何标签。相反，我们需要传递两个训练特征，即 train_x 两次。如果你注意到 Convolution_Autoencoder
    类中的 build 方法，autoencoder 看起来像这样：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the Model above, we need to pass inputs which is train_x first, and then
    decoder(encoder(inputs)) where we need to pass the train_x again. Same for the
    test_x as well.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的模型中，我们需要首先传入 train_x 作为输入，然后是 decoder(encoder(inputs))，其中我们需要再次传入 train_x。测试数据
    test_x 也是如此。
- en: Before you begin the mode training, I should warn you that it is very slow in
    the default setting of Google Colab. You can make it way faster by running this
    in the GPU. Please change the settings of your Google Colab notebook before you
    run this.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在你开始模型训练之前，我应该警告你，在 Google Colab 的默认设置下，它非常慢。你可以通过在 GPU 上运行来显著提高速度。在运行之前，请更改你的
    Google Colab 笔记本设置。
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see there are not many changes to losses, simply because here we
    do not have labels. Instead, we pass the training features to it twice. Losses
    come from comparing the original images to the reconstructed images by autoencoders.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，损失没有太多变化，这只是因为我们没有标签。相反，我们将训练特征传递给它两次。损失来自将原始图像与自编码器重建图像进行比较。
- en: Model Evaluation
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估
- en: Model evaluation is different than a regular supervised learning model in autoencoders
    as this is not a supervised learning method. Let’s do that step by step.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估与常规监督学习模型不同，因为自编码器不是监督学习方法。让我们一步一步来做。
- en: First, we will do the prediction as usual, which will be the decoded images
    by the autoencoder model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将像往常一样进行预测，这将是通过自编码器模型解码的图像。
- en: Then, you calculate the mean squared error using the original errors and the
    reconstructed error and save it to the ‘errors’ list. Here is the code for that.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用原始错误和重建错误计算均方误差，并将其保存到‘errors’列表中。这里是相关代码。
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As we have the ‘mse’ for all the images in the test set, we choose a threshold.
    Here I am using 95% quantile using np. quantile method and getting indices from
    the ‘errors’ where ‘mse’ is greater than the threshold. When ‘mse’ is greater
    than the threshold error we decided we will consider them as an anomaly.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有测试集中所有图像的‘mse’，我们选择一个阈值。在这里，我使用了 np.quantile 方法的 95% 分位数，并从‘errors’中获取‘mse’大于阈值的索引。当‘mse’大于我们决定的阈值错误时，我们将其视为异常。
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let’s get back to the image dataset ‘total_images’ that we prepared for
    the training earlier. We need to check if the indices we have which are more than
    the threshold are actually the anomaly:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到之前为训练准备的图像数据集‘total_images’。我们需要检查这些超过阈值的索引是否实际上是异常：
- en: '[PRE17]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Output:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE18]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Yes!! They are all anomaly data. If you count the number of ‘True’ above we
    have 11 ‘True’ here. We can check how many anomaly data we originally had in the
    ‘images_anomaly’:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 是的！！它们都是异常数据。如果你计算上面的‘True’数量，我们这里有 11 个‘True’。我们可以检查‘images_anomaly’中最初有多少异常数据：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Output:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE20]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: So, we found all the anomaly data using the autoencoder model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用自编码器模型找到了所有的异常数据。
- en: Conclusion
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: I have another anomaly detection tutorial that uses probability to find the
    anomaly. Please check the ‘More Reading’ section below. Here we used TensorFlow
    and Keras which are much more advanced tools for images and more complex data.
    As I mentioned in the Introduction, autoencoders can be used in a variety of other
    tasks as well. I will be sharing more use cases in my future posts on autoencoders
    and also more cutting-edge techniques in TensorFlow and Keras.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我还有另一个使用概率来发现异常的异常检测教程。请查看下面的‘更多阅读’部分。这里我们使用了 TensorFlow 和 Keras，它们是处理图像和更复杂数据的更高级工具。正如我在介绍中提到的，自编码器也可以用于各种其他任务。我将在未来的帖子中分享更多自编码器的应用案例，以及
    TensorFlow 和 Keras 中的更多前沿技术。
- en: Feel free to follow me on [Twitter](https://twitter.com/rashida048) and like
    my [Facebook](https://www.facebook.com/rashida.smith.161) page.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎关注我的 [Twitter](https://twitter.com/rashida048) 和点赞我的 [Facebook](https://www.facebook.com/rashida.smith.161)
    页面。
- en: 'More Reading:'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多阅读：
- en: '[A Complete Anomaly Detection Algorithm From Scratch in Python: Step by Step
    Guide | by Rashida Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/4c115e65d54e)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[从头开始用 Python 实现完整的异常检测算法：逐步指南 | 作者：Rashida Nasrin Sucky | Towards Data Science
    (medium.com)](https://medium.com/p/4c115e65d54e)'
- en: '[Implementation of a Siamese Network in Keras and TensorFlow | by Rashida Nasrin
    Sucky | Aug, 2023 | Towards Data Science (medium.com)](https://medium.com/p/aa327418e177)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[在 Keras 和 TensorFlow 中实现 Siamese 网络 | 作者：Rashida Nasrin Sucky | 2023年8月 |
    Towards Data Science (medium.com)](https://medium.com/p/aa327418e177)'
- en: '[Complete Implementation of a Mini VGG Network for Image Recognition | by Rashida
    Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/849299480356)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[完整实现迷你 VGG 网络用于图像识别 | 作者：Rashida Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/849299480356)'
- en: '[Using a Keras Tuner for Hyperparameter Tuning of a TensorFlow Model | by Rashida
    Nasrin Sucky | Towards AI (medium.com)](https://medium.com/p/41978f53111)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用 Keras 调参器进行 TensorFlow 模型的超参数调整 | 作者：拉希达·纳斯林·苏基 | 发表在 AI 方向 (medium.com)](https://medium.com/p/41978f53111)'
- en: '[Map, Filter, and CombinePerKey Transforms in Writing Apache Beam Pipelines
    with Examples | by Rashida Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/e06926124a02)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[在编写 Apache Beam 管道时使用 Map、Filter 和 CombinePerKey 转换的示例 | 作者：拉希达·纳斯林·苏基 | 发表在数据科学方向
    (medium.com)](https://medium.com/p/e06926124a02)'
