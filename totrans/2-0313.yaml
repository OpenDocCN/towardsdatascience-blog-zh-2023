- en: Anomaly Detection in TensorFlow and Keras Using the Autoencoder Method
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50](https://towardsdatascience.com/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/06b21f76fa65b8247eabeb45da835d72.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Photo by [Leiada Krozjhen](https://unsplash.com/@leiadakrozjhen?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: A cutting-edge unsupervised method for noise removal, dimensionality reduction,
    anomaly detection, and more
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----5600aca29c50--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5600aca29c50--------------------------------)
    ·7 min read·Sep 23, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: All the tutorials about TensorFlow and neural networks I have shared until now
    have been about supervised learning. This one will be about the Autoenocder which
    is an unsupervised learning technique. If I want to express it simply, autoencoders
    **reduce the noises** from the data by **compressing the input data**, and encoding
    and reconstructing the data. That way autoencoders can **reduce the dimensionality**
    or the noise of the data and focus on the real focal point of the input data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the introduction to the autoencoders here there is more
    than one process required.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: First, a model to compress the input data which is the encoder model.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then another model to reconstruct the compressed data that should be as close
    as the input data which is a decoder model.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this process, it can remove the noise, reduce the dimensionality, and clear
    up the input data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, I will explain in detail how an autoencoder works with a working
    example.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: For this example, I chose to use a [public dataset](https://github.com/AlexOlsen/DeepWeeds/blob/master/LICENSE)
    (Apache License 2.0) named deep_weeds.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Data Preparation
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to prepare a dataset for this unsupervised anomaly detection example.
    Only one class will be taken as our main class that will be considered as the
    valid class. And I will put a few data from another class as an anomaly. Then
    we will develop the model to see if we can find that few anomaly data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: I chose class 5 as the valid class and class 1 as the anomaly. In the code block
    below, I am taking all the data of classes 5 and 1 first and creating lists of
    the images and their corresponding labels.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s see the shape of the main image (images of class 5) data here:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The image shapes are (256, 256, 3) and we have a total of 1009 data for class
    5.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: However, we do not need all the data from class 1\. Because class 1 is the anomaly
    class. So, only 1% of the class 1 data will be taken for the training.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The shape of the total_images:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Output:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We have a total of 1020 images for training. As we saw earlier, we have 1009
    class 5 images, and we took 1020–1009 = 11 of class 1 images which is our anomaly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see if we can develop an autoencoder model in Keras and Tensorflow to
    detect these anomalies.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Model Development
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is the fun part! But first, we should do the necessary imports:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Some of the data should be kept separately for testing purposes. The train_test_split
    method from the sklearn library can be used for that. Remember, as this is an
    unsupervised learning method, the labels are not necessary. We will only split
    the images.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finally, the autoencoder model. We will build a Convolution_Autoencoder class
    which is a Convolutional Neural Network. The class has the build method where
    we will define the Autoencoder model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: The ‘build’ takes width, depth, height, filters, and latentDim as parameters.
    Here, width, depth, and height are the dimensions of the images that is (256,
    256, 3) for us as we have seen with the total_images.shape method above.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: The parameter ‘filters’ is the filter for the convolution layers.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: The ‘latentDim’ is the size of our compressed layer after the encoder method.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: In this build method, the first part is an encoder model which is a simple Convolutional
    Neural Network.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Once the encoder portion is done, a decoder model is developed using Conv2DTranspose
    layers to reconstruct the data again.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Then, we construct the autoencoder model which is actually a combination of
    both encoder and decoder models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we return the encoder, decoder, and autoencoder models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Model development is done. It’s time to run the model and see if it works. It
    should run like any other TensorFlow model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Here we will compile the model first with Adam optimizer. And also, I used a
    decay in the learning rate and the ‘mse’ as the loss.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, running the model. Remember, this is an unsupervised learning method.
    So there won''t be any label in the model training. Instead, we need to pass two
    training features which will be just train_x twice. If you notice the build method
    in the Convolution_Autoencoder class, autoencoder looks like this there:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the Model above, we need to pass inputs which is train_x first, and then
    decoder(encoder(inputs)) where we need to pass the train_x again. Same for the
    test_x as well.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Before you begin the mode training, I should warn you that it is very slow in
    the default setting of Google Colab. You can make it way faster by running this
    in the GPU. Please change the settings of your Google Colab notebook before you
    run this.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see there are not many changes to losses, simply because here we
    do not have labels. Instead, we pass the training features to it twice. Losses
    come from comparing the original images to the reconstructed images by autoencoders.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Model Evaluation
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model evaluation is different than a regular supervised learning model in autoencoders
    as this is not a supervised learning method. Let’s do that step by step.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: First, we will do the prediction as usual, which will be the decoded images
    by the autoencoder model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Then, you calculate the mean squared error using the original errors and the
    reconstructed error and save it to the ‘errors’ list. Here is the code for that.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As we have the ‘mse’ for all the images in the test set, we choose a threshold.
    Here I am using 95% quantile using np. quantile method and getting indices from
    the ‘errors’ where ‘mse’ is greater than the threshold. When ‘mse’ is greater
    than the threshold error we decided we will consider them as an anomaly.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let’s get back to the image dataset ‘total_images’ that we prepared for
    the training earlier. We need to check if the indices we have which are more than
    the threshold are actually the anomaly:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Output:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Yes!! They are all anomaly data. If you count the number of ‘True’ above we
    have 11 ‘True’ here. We can check how many anomaly data we originally had in the
    ‘images_anomaly’:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Output:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: So, we found all the anomaly data using the autoencoder model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I have another anomaly detection tutorial that uses probability to find the
    anomaly. Please check the ‘More Reading’ section below. Here we used TensorFlow
    and Keras which are much more advanced tools for images and more complex data.
    As I mentioned in the Introduction, autoencoders can be used in a variety of other
    tasks as well. I will be sharing more use cases in my future posts on autoencoders
    and also more cutting-edge techniques in TensorFlow and Keras.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to follow me on [Twitter](https://twitter.com/rashida048) and like
    my [Facebook](https://www.facebook.com/rashida.smith.161) page.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'More Reading:'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[A Complete Anomaly Detection Algorithm From Scratch in Python: Step by Step
    Guide | by Rashida Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/4c115e65d54e)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[Implementation of a Siamese Network in Keras and TensorFlow | by Rashida Nasrin
    Sucky | Aug, 2023 | Towards Data Science (medium.com)](https://medium.com/p/aa327418e177)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[Complete Implementation of a Mini VGG Network for Image Recognition | by Rashida
    Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/849299480356)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[Using a Keras Tuner for Hyperparameter Tuning of a TensorFlow Model | by Rashida
    Nasrin Sucky | Towards AI (medium.com)](https://medium.com/p/41978f53111)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用 Keras 调参器进行 TensorFlow 模型的超参数调整 | 作者：拉希达·纳斯林·苏基 | 发表在 AI 方向 (medium.com)](https://medium.com/p/41978f53111)'
- en: '[Map, Filter, and CombinePerKey Transforms in Writing Apache Beam Pipelines
    with Examples | by Rashida Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/e06926124a02)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[在编写 Apache Beam 管道时使用 Map、Filter 和 CombinePerKey 转换的示例 | 作者：拉希达·纳斯林·苏基 | 发表在数据科学方向
    (medium.com)](https://medium.com/p/e06926124a02)'
