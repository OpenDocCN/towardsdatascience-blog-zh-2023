- en: How To Prepare Data For Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何准备机器学习数据
- en: 原文：[https://towardsdatascience.com/how-to-prepare-data-for-machine-learning-eb9d9973832f](https://towardsdatascience.com/how-to-prepare-data-for-machine-learning-eb9d9973832f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-prepare-data-for-machine-learning-eb9d9973832f](https://towardsdatascience.com/how-to-prepare-data-for-machine-learning-eb9d9973832f)
- en: '*Preparing data for modeling is one of the first most fundamental steps in
    the data science pipeline*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*准备数据以进行建模是数据科学流程中最基本的第一步之一*'
- en: '[](https://medium.com/@theDrewDag?source=post_page-----eb9d9973832f--------------------------------)[![Andrea
    D''Agostino](../Images/58c7c218815f25278aae59cea44d8771.png)](https://medium.com/@theDrewDag?source=post_page-----eb9d9973832f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eb9d9973832f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eb9d9973832f--------------------------------)
    [Andrea D''Agostino](https://medium.com/@theDrewDag?source=post_page-----eb9d9973832f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@theDrewDag?source=post_page-----eb9d9973832f--------------------------------)[![Andrea
    D''Agostino](../Images/58c7c218815f25278aae59cea44d8771.png)](https://medium.com/@theDrewDag?source=post_page-----eb9d9973832f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eb9d9973832f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eb9d9973832f--------------------------------)
    [Andrea D''Agostino](https://medium.com/@theDrewDag?source=post_page-----eb9d9973832f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eb9d9973832f--------------------------------)
    ·8 min read·Apr 19, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eb9d9973832f--------------------------------)
    ·8分钟阅读·2023年4月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a4201ec0fe98ad642b92ad48c8e24ac9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4201ec0fe98ad642b92ad48c8e24ac9.png)'
- en: Photo by [John Moeses Bauan](https://unsplash.com/it/@johnmoeses?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit)
    / [Unsplash](https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [John Moeses Bauan](https://unsplash.com/it/@johnmoeses?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit)
    提供 / [Unsplash](https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit)
- en: Training predictive models requires that our data be in an appropriate format.
    We can’t feed our .csv file to a model and expect it to learn to generalize correctly.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 训练预测模型要求我们的数据格式正确。我们不能将 `.csv` 文件直接输入模型，并期望它能够正确地进行泛化。
- en: In this article, we will look at how to prepare data for machine learning, starting
    from the data preparation pipeline to dividing it into training, validation and
    test sets.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨如何准备机器学习数据，从数据准备流程开始，到将数据划分为训练集、验证集和测试集。
- en: Data preparation pipeline
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备流程
- en: 'A pipeline is a series of steps that are performed to prepare data for processing
    by the machine learning model. The pipeline can vary based on the type of data
    you have available, but usually includes the following steps:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 流程是为了准备数据以供机器学习模型处理而执行的一系列步骤。流程可以根据你拥有的数据类型有所不同，但通常包括以下步骤：
- en: '**Data collection**: The first step is to collect the data that you want to
    use to train the machine learning model. The data can come from different sources,
    such as CSV files, databases, APIs, IoT sensors and others.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据收集**：第一步是收集你想用来训练机器学习模型的数据。这些数据可以来自不同的来源，如 CSV 文件、数据库、API、物联网传感器等。'
- en: '**Data cleaning**: Once data is collected, it is important to clean it by deleting
    missing data, correcting errors, and removing duplicate or irrelevant data. Data
    cleansing helps improve the quality of the data used to train the machine learning
    model.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据清理**：一旦数据被收集，重要的是要通过删除缺失数据、纠正错误以及删除重复或无关的数据来清理数据。数据清理有助于提高用于训练机器学习模型的数据质量。'
- en: '**Data Preprocessing**: Data preprocessing includes data normalization, data
    standardization, categorical variable coding, and outlier handling. These steps
    help prepare the data so that it can be processed by the machine learning model.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据预处理**：数据预处理包括数据规范化、数据标准化、分类变量编码和异常值处理。这些步骤有助于准备数据，使其能够被机器学习模型处理。'
- en: '**Data transformation**: Data transformation includes dimensionality reduction,
    feature selection, and creation of new features. These steps help reduce data
    noise and improve the machine learning model’s ability to make accurate predictions.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据转换**：数据转换包括降维、特征选择和新特征的创建。这些步骤有助于减少数据噪声，提高机器学习模型做出准确预测的能力。'
- en: The term *pipeline* is also used by a programmatic object belonging to the Scikit-learn
    library in Python. This allows us to specify data processing steps to facilitate
    coding and reduce the occurrence of errors.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*管道*一词也用于 Python 的 Scikit-learn 库中的一个编程对象。这允许我们指定数据处理步骤，以便于编码并减少错误的发生。'
- en: If you want to read about Scikit-Learn pipelines, read the article below
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解 Scikit-Learn 管道，可以阅读下面的文章
- en: '[](https://medium.com/mlearning-ai/how-to-use-sklearns-pipelines-to-optimize-your-analysis-b6cd91999be?source=post_page-----eb9d9973832f--------------------------------)
    [## How To Use Sklearn’s Pipelines To Optimize Your Analysis'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/mlearning-ai/how-to-use-sklearns-pipelines-to-optimize-your-analysis-b6cd91999be?source=post_page-----eb9d9973832f--------------------------------)
    [## 如何使用 Sklearn 的管道来优化你的分析'
- en: In data science and machine learning, a pipeline is a set of sequential steps
    that allows us to control the flow of…
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在数据科学和机器学习中，管道（pipeline）是一组顺序步骤，允许我们控制数据流动的…
- en: medium.com](https://medium.com/mlearning-ai/how-to-use-sklearns-pipelines-to-optimize-your-analysis-b6cd91999be?source=post_page-----eb9d9973832f--------------------------------)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/mlearning-ai/how-to-use-sklearns-pipelines-to-optimize-your-analysis-b6cd91999be?source=post_page-----eb9d9973832f--------------------------------)
- en: Data collection
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据收集
- en: It is important to collect data from sources that are reliable and relevant
    to the problem you are trying to solve.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从可靠且与您试图解决的问题相关的数据源中收集数据是很重要的。
- en: For example, if you want to create a machine learning model for predicting the
    price of houses, you need to collect data that include features such as the location
    of the house, the number of rooms, the presence of a garden, proximity to public
    transport and more. This information, just as it informs us humans of a property’s
    value, will also inform the predictive model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你想创建一个用于预测房价的机器学习模型，你需要收集包括房屋位置、房间数量、是否有花园、靠近公共交通等特征的数据。这些信息就像它们向我们人类提供房产价值一样，也会对预测模型提供帮助。
- en: It is important to choose the source that best fits your problem and data availability.
    For example, if you want to build a machine learning model for anomaly detection
    in an IoT system, you need to collect data from sensors in the system.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最适合你的问题和数据可用性的来源非常重要。例如，如果你想为物联网系统中的异常检测构建机器学习模型，你需要从系统中的传感器收集数据。
- en: Other data sources can be
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 其他数据来源可以是
- en: Public and private APIs
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公共和私人 API
- en: Direct suppliers
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接供应商
- en: Surveys
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查
- en: Furthermore, it is important to evaluate the **quality of the data collected.**
    The data can contain errors, duplicates, or omissions that can negatively affect
    the quality of the machine learning model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，评估**收集的数据质量**是很重要的。数据可能包含错误、重复或遗漏，这些问题可能会对机器学习模型的质量产生负面影响。
- en: Therefore, you should perform a data cleanup and check for missing, duplicate,
    or bad data. Data cleaning can help improve the quality of your machine learning
    model and achieve more accurate predictions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你应该进行数据清理，并检查是否有缺失、重复或不良数据。数据清理可以帮助提高机器学习模型的质量，并实现更准确的预测。
- en: Here is an article that focuses precisely on the process of creating a dataset
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一篇文章专注于数据集创建的过程
- en: '[](/building-your-own-dataset-benefits-approach-and-tools-6ab096e37f2?source=post_page-----eb9d9973832f--------------------------------)
    [## Building Your Own Dataset: Benefits, Approach, and Tools'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/building-your-own-dataset-benefits-approach-and-tools-6ab096e37f2?source=post_page-----eb9d9973832f--------------------------------)
    [## 自建数据集：好处、方法和工具'
- en: The importance of building your own dataset instead of using a pre-built solution
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自建数据集而不是使用预建解决方案的重要性
- en: towardsdatascience.com](/building-your-own-dataset-benefits-approach-and-tools-6ab096e37f2?source=post_page-----eb9d9973832f--------------------------------)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/building-your-own-dataset-benefits-approach-and-tools-6ab096e37f2?source=post_page-----eb9d9973832f--------------------------------)
- en: Practical example of the data collection phase
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集阶段的实际例子
- en: A practical example of how the data collection could appear would be building
    a model for classifying flowers. In this case, **we could collect data on different
    flowers, such as petals and sepals, and record their respective lengths and widths.**
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实际的数据收集例子可能是构建一个用于分类花卉的模型。在这种情况下，**我们可以收集不同花卉的数据，比如花瓣和萼片，并记录它们的长度和宽度。**
- en: To collect this data, **we may use a mobile application** that allows us to
    take pictures of the flowers and record their characteristics. Alternatively,
    we may collect data manually using a spreadsheet or database.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了收集这些数据，**我们可以使用一个移动应用程序**，该程序允许我们拍摄花卉照片并记录它们的特征。或者，我们可以使用电子表格或数据库手动收集数据。
- en: Regardless of the data collection method you use, it’s important to make sure
    that **the data is representative of the problem to solve**. In this case, we
    may collect data on flowers of different species and from different geographical
    regions to ensure a good variety of data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用什么数据收集方法，确保**数据能代表要解决的问题**是很重要的。在这种情况下，我们可以收集来自不同物种和不同地理区域的花卉数据，以确保数据的多样性。
- en: Data preprocessing
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: In general, data preprocessing **includes normalizing or standardizing data,
    encoding categorical variables, and handling outliers.**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，数据预处理**包括数据的归一化或标准化、类别变量的编码和异常值处理**。
- en: '**Data normalization / standardization** is used to reduce the scale of the
    data so that they are comparable to each other. Many machine learning models,
    such as K-nearest neighbors and neural networks require data to be normalized
    or standardized to perform well.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据归一化 / 标准化**用于减少数据的尺度，以便它们之间可以相互比较。许多机器学习模型，例如 K-近邻和神经网络，要求数据进行归一化或标准化才能表现良好。'
- en: Standardization and normalization are terms that often are used interchangeably.
    In reality, they are not quite the same.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标准化和归一化这两个术语通常可以互换使用。但实际上，它们并不完全相同。
- en: ''
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I invite the interested reader to read this resource [explaining the differences
    between standardization and normalization to learn more.](https://www.simplilearn.com/normalization-vs-standardization-article)
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我邀请有兴趣的读者阅读这个资源[解释标准化和归一化之间差异的文章](https://www.simplilearn.com/normalization-vs-standardization-article)以了解更多信息。
- en: '**Categorical variable encoding** is used when you have variables that are
    not in numeric format, such as gender or eye color. Categorical variable encoding
    turns these variables into numbers for use by the machine learning model.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**类别变量编码**用于处理那些不是数字格式的变量，例如性别或眼睛颜色。类别变量编码将这些变量转换为数字，以供机器学习模型使用。'
- en: '**Outlier handling** is used to deal with data that deviates greatly from the
    rest of the data. This data can negatively affect the machine learning model,
    so it must be managed appropriately.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常值处理**用于处理那些与其余数据差异很大的数据。这些数据可能对机器学习模型产生负面影响，因此必须妥善管理。'
- en: Practical example of the data preprocessing phase
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理阶段的实际示例
- en: Let’s think about text. Lot’s of text organized in a corpus (list of documents).
    This data should be treated first before being fed to a machine learning model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们思考文本。大量的文本组织成语料库（文档列表）。在将这些数据输入机器学习模型之前，应该首先对其进行处理。
- en: 'A hypothetical pipeline could be:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个假设的流程可能是：
- en: text tokenization
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本标记化
- en: stop word removal
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停用词移除
- en: stemming / lemmatization
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词干提取 / 词形还原
- en: vectorization
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量化
- en: These are some of the most common steps in preprocessing text data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是文本数据预处理中的一些最常见步骤。
- en: Data transformation
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据转换
- en: Data transformation can include **dimensionality reduction, feature selection,
    and the creation of new features.**
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换可以包括**维度减少、特征选择和新特征的创建**。
- en: '**Dimensionality reduction** is used to reduce the number of features in the
    data. This step can be useful when you have a lot of data but are resource constrained,
    such as machine learning model processing time. One of the most used techniques
    is **PCA (Principal Component Analysis).**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**维度减少**用于减少数据中的特征数量。当你拥有大量数据但资源受限，例如机器学习模型的处理时间，这一步骤会非常有用。最常用的技术之一是**PCA（主成分分析）**。'
- en: '**Feature selection** is used to select the most important features of the
    data. This step can be useful when you have many features but want to use only
    a subset of them to train the machine learning model.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征选择**用于选择数据中最重要的特征。当你拥有许多特征但希望只使用其中一部分来训练机器学习模型时，这一步骤会非常有用。'
- en: Read how to do feature selection with a technique called *Boruta* in Python
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读如何在 Python 中使用一种叫做*Boruta*的技术进行特征选择
- en: '[](/feature-selection-with-boruta-in-python-676e3877e596?source=post_page-----eb9d9973832f--------------------------------)
    [## Feature Selection with Boruta in Python'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/feature-selection-with-boruta-in-python-676e3877e596?source=post_page-----eb9d9973832f--------------------------------)
    [## Python 中的 Boruta 特征选择'
- en: Learn how the Boruta algorithm works for feature selection. Explanation + template
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解 Boruta 算法如何进行特征选择。解释 + 模板
- en: towardsdatascience.com](/feature-selection-with-boruta-in-python-676e3877e596?source=post_page-----eb9d9973832f--------------------------------)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/feature-selection-with-boruta-in-python-676e3877e596?source=post_page-----eb9d9973832f--------------------------------)'
- en: '**Creating new features** is used to create new features from existing data.
    This step can be useful when you want to create features that weren’t present
    in the original data but can be useful for training the machine learning model.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建新特征**用于从现有数据中创建新特征。这个步骤在你想要创建在原始数据中不存在但对训练机器学习模型有用的特征时特别有用。'
- en: Practical example of the data transformation phase
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据转换阶段的实际示例
- en: PCA is mainly used to reduce the number of useable features from a machine learning
    model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 主要用于减少机器学习模型中的可用特征数量。
- en: Implementing PCA in Sklearn is quite easy — this code snippet captures the general
    gist of training and applying PCA in Python
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Sklearn 中实现 PCA 非常简单 —— 这段代码片段捕捉了训练和应用 PCA 的一般思路。
- en: '[PRE0]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Splitting data into training, validation and test sets
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据划分为训练集、验证集和测试集
- en: Splitting data into training, validation, and test sets is an important step
    in preparing data for machine learning.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据划分为训练集、验证集和测试集是准备机器学习数据的重要步骤。
- en: '**Training set**: The train set is used to train the machine learning model.
    It contains the data that the model will use to learn the relationships useful
    for the prediction'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练集**：训练集用于训练机器学习模型。它包含模型将用来学习对预测有用的关系的数据。'
- en: '**Validation set**: The validation set is used to evaluate the performance
    of the machine learning model during training and to test its hyperparameters'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证集**：验证集用于在训练过程中评估机器学习模型的性能，并测试其超参数。'
- en: '**Test set**: The test set is used to evaluate the performance of the machine
    learning model after training.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试集**：测试集用于在训练后评估机器学习模型的性能。'
- en: The division into train, validation and test set is important because it allows
    you to accurately evaluate the performance of the machine learning model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据划分为训练集、验证集和测试集很重要，因为它可以准确评估机器学习模型的性能。
- en: If you use all the data to train your machine learning model and then evaluate
    the model’s performance on the data itself, you risk getting a distorted picture
    of the model’s performance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用所有数据来训练机器学习模型，然后在数据本身上评估模型性能，你可能会得到模型性能的扭曲图景。
- en: One of the most important techniques to correctly evaluate whether the model
    is learning or not is called **cross-validation.**
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 正确评估模型是否学习到知识的最重要技术之一叫做**交叉验证**。
- en: ''
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It consists in the division of the training set into folds, which are used to
    evaluate the model iteratively.
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它包括将训练集划分为折叠，以便迭代地评估模型。
- en: If you want to read about cross-validation and how to apply it in your codebase,
    read the article below
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解交叉验证及其如何在你的代码中应用，阅读下面的文章。
- en: '[](/what-is-cross-validation-in-machine-learning-14d2a509d6a5?source=post_page-----eb9d9973832f--------------------------------)
    [## What is cross-validation in machine learning'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/what-is-cross-validation-in-machine-learning-14d2a509d6a5?source=post_page-----eb9d9973832f--------------------------------)
    [## 机器学习中的交叉验证是什么'
- en: Learn what cross-validation is — a fundamental technique for building generalizable
    models
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解什么是交叉验证 —— 构建可泛化模型的基本技术。
- en: towardsdatascience.com](/what-is-cross-validation-in-machine-learning-14d2a509d6a5?source=post_page-----eb9d9973832f--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/what-is-cross-validation-in-machine-learning-14d2a509d6a5?source=post_page-----eb9d9973832f--------------------------------)'
- en: Practical example using train_test_split from Sklearn
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Sklearn 的 `train_test_split` 的实际示例
- en: Sklearn provides a cool API to manage data splitting. Check this code out.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Sklearn 提供了一个很棒的 API 来管理数据拆分。看看这段代码。
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this example, we’re splitting our data in a 60/20/20 ratio between training
    sets, validation sets, and test sets. In other words, we are using 60% of the
    data to train our model, 20% to validate the model during training, and the remaining
    20% to test the model after training.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将数据按 60/20/20 的比例划分为训练集、验证集和测试集。换句话说，我们使用 60% 的数据来训练模型，20% 来验证模型在训练过程中的表现，其余的
    20% 用于在训练后测试模型。
- en: The `random_state` parameter allows us to set the random number generation seed,
    so that we always get the same data breakdown every time we run the code.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_state` 参数允许我们设置随机数生成种子，以便每次运行代码时都能获得相同的数据划分。'
- en: Finally, we’re printing the sizes of the training, validation, and test sets
    so we can verify that the split was done correctly.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们打印了训练集、验证集和测试集的大小，以便验证数据划分是否正确。
- en: Using `sklearn`, splitting the data into a training set, a validation set, and
    a test set becomes quick and easy, allowing us to focus on designing and training
    our model.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `sklearn`，将数据分为训练集、验证集和测试集变得快速而简单，使我们能够专注于设计和训练模型。
- en: Conclusion
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we’ve looked at the steps required to prepare your data for
    machine learning.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们查看了为机器学习准备数据所需的步骤。
- en: We have seen how gathering data from reliable and relevant sources to the problem,
    along with data cleansing, are key to ensuring the quality of the data used to
    train the machine learning model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，从可靠且与问题相关的来源收集数据以及数据清洗是确保用于训练机器学习模型的数据质量的关键。
- en: We also looked at data preprocessing, which includes data normalization and
    standardization, categorical variable coding and outlier handling, as well as
    data transformation, which can include dimensionality reduction, feature selection,
    and creation. of new features.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还研究了数据预处理，包括数据归一化和标准化、分类变量编码和异常值处理，以及数据转换，这可能包括降维、特征选择和新特征的创建。
- en: Finally, we have seen the importance of dividing the data into train, validation
    and test sets to evaluate the performance of the machine learning model accurately.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们了解了将数据分为训练集、验证集和测试集以准确评估机器学习模型性能的重要性。
- en: Preparing data for machine learning requires close attention to detail, but
    performing data preparation pipeline steps correctly can be the difference between
    a machine learning model that works and one that doesn’t.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为机器学习准备数据需要密切关注细节，但正确执行数据准备步骤可能是机器学习模型有效与否的关键。
- en: '**If you want to support my content creation activity, feel free to follow
    my referral link below and join Medium’s membership program**. I will receive
    a portion of your investment and you’ll be able to access Medium’s plethora of
    articles on data science and more in a seamless way.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你想支持我的内容创作活动，请随时通过下面的推荐链接加入 Medium 会员计划**。我将获得您投资的一部分，您将能够以无缝的方式访问 Medium
    上大量关于数据科学及更多内容的文章。'
- en: '[](https://medium.com/@theDrewDag/membership?source=post_page-----eb9d9973832f--------------------------------)
    [## Join Medium with my referral link - Andrea D''Agostino'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@theDrewDag/membership?source=post_page-----eb9d9973832f--------------------------------)
    [## 使用我的推荐链接加入 Medium - Andrea D''Agostino'
- en: Read every story from Andrea D'Agostino (and thousands of other writers on Medium).
    Your membership fee directly…
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读 Andrea D'Agostino 的所有故事（以及 Medium 上成千上万的其他作者的故事）。您的会员费用直接……
- en: medium.com](https://medium.com/@theDrewDag/membership?source=post_page-----eb9d9973832f--------------------------------)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@theDrewDag/membership?source=post_page-----eb9d9973832f--------------------------------)
- en: Recommended Reads
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐阅读
- en: For the interested, here are a list of books that I recommended for each ML-related
    topic. There are ESSENTIAL books in my opinion and have greatly impacted my professional
    career.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对有兴趣的人，这里列出了我推荐的每个与机器学习相关的主题的书籍。这些书籍在我看来是**必读**的，并且对我的职业生涯产生了很大影响。
- en: '*Disclaimer: these are Amazon affiliate links. I will receive a small commission
    from Amazon for referring you these items. Your experience won’t change and you
    won’t be charged more, but it will help me scale my business and produce even
    more content around AI.*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：这些是亚马逊会员链接。我会因推荐这些商品而从亚马逊获得少量佣金。您的体验不会改变，也不会额外收费，但这将帮助我扩大业务并制作更多关于人工智能的内容。*'
- en: '**Intro to ML:** [*Confident Data Skills: Master the Fundamentals of Working
    with Data and Supercharge Your Career*](https://amzn.to/3ZzKTz6)by Kirill Eremenko'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习入门：** [*自信的数据技能：掌握数据工作基础，提升你的职业生涯*](https://amzn.to/3ZzKTz6) 作者：Kirill
    Eremenko'
- en: '**Sklearn / TensorFlow:** [*Hands-On Machine Learning with Scikit-Learn, Keras,
    and TensorFlow*](https://amzn.to/433F4Nm) by Aurelien Géron'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sklearn / TensorFlow：** [*动手实践机器学习：Scikit-Learn、Keras 和 TensorFlow*](https://amzn.to/433F4Nm)
    作者：Aurelien Géron'
- en: '**NLP:** [*Text as Data: A New Framework for Machine Learning and the Social
    Sciences*](https://amzn.to/3zvH43j)by Justin Grimmer'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NLP：** [*文本作为数据：机器学习与社会科学的新框架*](https://amzn.to/3zvH43j) 作者：Justin Grimmer'
- en: '**Sklearn / PyTorch:** [*Machine Learning with PyTorch and Scikit-Learn: Develop
    machine learning and deep learning models with Python*](https://amzn.to/3Gcavve)
    by Sebastian Raschka'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sklearn / PyTorch：** [*使用 PyTorch 和 Scikit-Learn 进行机器学习：用 Python 开发机器学习和深度学习模型*](https://amzn.to/3Gcavve)
    由 Sebastian Raschka 著'
- en: '**Data Viz:** [*Storytelling with Data: A Data Visualization Guide for Business
    Professionals*](https://amzn.to/3HUtGtB) by Cole Knaflic'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据可视化：** [*用数据讲故事：商业专业人士的数据可视化指南*](https://amzn.to/3HUtGtB) 由 Cole Knaflic
    著'
- en: Useful Links (written by me)
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有用的链接（由我编写）
- en: '**Learn how to perform a top-tier Exploratory Data Analysis in Python:** [*Exploratory
    Data Analysis in Python — A Step-by-Step Process*](/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习如何在 Python 中进行顶级的探索性数据分析：** [*Python 中的探索性数据分析 — 一步一步的过程*](/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)'
- en: '**Learn the basics of TensorFlow:** [*Get started with TensorFlow 2.0 — Introduction
    to deep learning*](https://medium.com/towards-data-science/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习 TensorFlow 基础知识：** [*开始使用 TensorFlow 2.0 — 深度学习简介*](https://medium.com/towards-data-science/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa)'
- en: '**Perform text clustering with TF-IDF in Python:** [*Text Clustering with TF-IDF
    in Python*](https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用 TF-IDF 在 Python 中进行文本聚类：** [*Python 中的 TF-IDF 文本聚类*](https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7)'
