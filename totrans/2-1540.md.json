["```py\nLabel 1: Non-Demented\nLabel 2: Moderate Demented\nLabel 3: Mild Demented\nLabel 4: Very Mild Demented\n```", "```py\nimport pandas as pd\nimport numpy as np \nfrom matplotlib.pyplot import imshow\nimport pickle\n```", "```py\nwith open('AugmentedAlzheimer.50X50.training.dataset.pickle', 'rb') as handle:\n    ALZ = pickle.load(handle)\n```", "```py\nX = np.stack(ALZ['X'])\ny = np.int64(ALZ['y']) \n```", "```py\n'''\nReshape a 2500-values vector extracted from one of the images\nstored in the vector X (i.e.: #12848).\nUse the NumPy method .reshape, specifiying the double argument '50'\nthen show the image with the function imshow, specifying the argument \ncmap='gray'\n'''\n\nimage = X[12848].reshape(50, 50)\nprint('image:', 12848)\nprint('label:', y[12848])\n\nimshow(image, cmap='gray')\n```", "```py\n'''\nplotSamplesRandomly\nFunction for visualizing fifty randomly picked images, from the dataset\n'''\n\ndef plotSamplesRandomly(X, y):\n\n    from random import randint\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n\n    # create a list of randomly picked indexes.\n    # the function randint creates the list, picking numbers in a \n    # range 0-33983, which is the length of X\n\n    randomSelect = [randint(0, len(X)) for i in range(0, 51)]\n\n    # reshape all the pictures on the n X n pixels, \n    # where n = sqrt(size of X), in this case 50 = sqrt(2500)\n    w, h =int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))\n    fig=plt.figure(figsize=(int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))))\n\n    # Define a grid of 10 X 10 for the big plot. \n    columns = 10\n    rows = 10\n\n    # The for loop\n    for i in range(1, 51):\n\n        # create the 2-dimensional picture\n        image = X[randomSelect[i]].reshape(w,h)\n        ax = fig.add_subplot(rows, columns, i)\n\n        # create a title for each pictures, containing #index and label\n        title = \"#\"+str(randomSelect[i])+\"; \"+\"y:\"+str(y[randomSelect[i]])\n\n        # set the title font size\n        ax.set_title(title, fontsize=np.int(np.sqrt(X.shape[1])/2))                \n\n        # don't display the axis\n        ax.set_axis_off()\n\n        # plot the image in grayscale\n        plt.imshow(image, cmap='gray')\n\n    # Show some sample randomly\n    print('\\nShow samples randomly:')\n    plt.show()\n```", "```py\nplotSamplesRandomly(X, y)\n```", "```py\n# Sigomid Logistic (Activation) Function\ndef sigmoid(z): \n    g = 1.0 / (1.0 + np.exp(-z))\n    return g\n```", "```py\n# Plot the Sigmoid function, and its output:\n\ndef plotSigmoid(z):\n    import numpy as np\n    from matplotlib import pyplot as plt\n\n    plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n    plt.rcParams[\"figure.autolayout\"] = True\n\n    x = np.linspace(-10, 10, 100)\n\n    # setting the axes at the centre\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.spines['left'].set_position('center')\n    ax.spines['bottom'].set_position('zero')\n    ax.spines['right'].set_color('none')\n    ax.spines['top'].set_color('none')\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    plt.plot(x, sigmoid(x), color='blue')\n\n    plt.plot(0, sigmoid(0), marker=\"o\", markersize=5, \n             markeredgecolor=\"black\", markerfacecolor=\"black\")    \n    if(z!=0):\n        plt.text(0, sigmoid(0), \"  0.5\")\n\n    plt.plot(z, sigmoid(z), marker=\"o\", markersize=5,\n             markeredgecolor=\"red\", markerfacecolor=\"red\")\n\n    value = \"{:5.3f}\".format(sigmoid(z))\n    plt.text(z, sigmoid(z), str(\"  z=\"+str(z)+\"; value=\"+str(value)))\n\n    plt.show()\n```", "```py\n1\\. init\n2\\. training\n3\\. testing\n```", "```py\nwith open('AugmentedAlzheimer.50X50.training.dataset.pickle', 'rb') as handle:\n    ALZ = pickle.load(handle) \nX = np.stack(ALZ['X'])\ny = np.int64(ALZ['y']) \n```", "```py\n'''\nfunction \"init\"\nNeural Network initialization and parameter setup\n'''\ndef init(X, y):\n    I  = X.shape[1]  # n x n MRI input size (2500)\n    H1 = int(X.shape[1]*2/3) + max(set(y)) # hidden units size: \n                        # 2/3 of the input units + the number of output units (1670)\n    O = max(set(y)) # output units size or labels (4)\n    m = X.shape[0] \n\n    ini_Th1 = thetasRandomInit(I, H1)\n    ini_Th2 = thetasRandomInit(H1, O)\n\n    # Unroll parameters \n    ini_nn_params = np.concatenate((ini_Th1.T.flatten(), ini_Th2.T.flatten()))\n    ini_nn_params = ini_nn_params.reshape(len(ini_nn_params), 1)\n\n    print('\\nNeural Network Parameters initialized!\\n')\n    print('\\nNeural Network structure:\\n')\n    print('Input layer neurons:', I)\n    print('1st hidden layer neurons:', H1)\n    print('Output layer neurons:', O)\n\n    return ini_nn_params, I, H1, O\n```", "```py\n'''\nfunction \"thetasRandomInit\"\nRandom initialization of thetas\n'''\ndef thetasRandomInit(L_in, L_out):\n    e_init = 0.12\n    W = np.random.rand(L_out, 1 + L_in) * 2 * e_init - e_init\n    return W\n```", "```py\nini_nn_params, I, H1, O = init(X, y)\n```", "```py\nNeural Network Parameters initialized!\n\nNeural Network structure:\n\nInput layer neurons: 2500\n1st hidden layer neurons: 1670\nOutput layer neurons: 4\n```", "```py\n'''\nfunction \"training\"\nNeural Network training\n'''\ndef training(ini_nn_params, I, H1, O, X, y):\n    import scipy.optimize as opt\n\n    lambd = 1\n    print('\\nTraining Neural Network... \\n')\n\n    result = opt.minimize(fun=nnCostFunction, \n                          x0=ini_nn_params,\n                          args=(I, H1, O, X, y, lambd),\n                          method='TNC', \n                          jac=True, \n                          options={'maxiter': 1000, \"disp\": True})\n\n    params_trained = result.x\n\n    Th1_trained = np.reshape(params_trained[0:(H1 * (I + 1)), ],\n                                 (H1, I + 1))\n    Th2_trained = np.reshape(params_trained[(H1 * (I + 1)):, ],\n                                 (O, H1 + 1))\n\n    print('\\nTrained.\\n')\n\n    return Th1_trained, Th2_trained\n```", "```py\n'''\nnnCostFunction\nImplements the Neural Network Cost Function\n'''\ndef nnCostFunction(nn_params, I, H1, O, X, y, lambd):\n\n    # 1\\. RESHAPING\n    # Reshape nn_params back into the parameters Th1 and Th2, \n    # the weight matrices\n\n    Th1 = np.reshape(nn_params[0:(H1 * (I + 1)), ],\n                         (H1, I + 1))\n    Th2 = np.reshape(nn_params[(H1 * (I + 1)):, ],\n                         (O, H1 + 1))\n\n    # 2\\. SETUP OF Y\n    # Setup the output (y) layout\n    m = X.shape[0] \n\n    Y = np.zeros((m, O))\n    for i in range(m):\n        Y[i, y[i] - 1] = 1   \n\n    # 3\\. INITIALIZE J, and THETAS\n    J = 0\n    Th1_grad = np.zeros(Th1.shape) \n    Th2_grad = np.zeros(Th2.shape) \n\n    # 4\\. PREPARE ALL THE VECTORS FOR THE FORWARD PROPAGATION\n    # Six new vectors are generated here: a1, z2, a2, z3, a3, and h.\n    # The vector a1 equals X (the input matrix), \n    # with a column of 1's added (bias units) as the first column.\n\n    a1 = np.hstack((np.ones((m, 1)), X))  \n\n    # z2 equals the product of a1 and Th1\n    z2 = np.dot(a1, Th1.T) \n\n    # The vector a2 is created by adding a column of bias units \n    # after applying the sigmoid function to z2.\n    a2 = np.hstack((np.ones((m, 1)), sigmoid(z2))) \n\n    # z3 equals the product of a2 and Th2\n    z3 = np.dot(a2, Th2.T) \n    a3 = sigmoid(z3) \n\n    # The Hypotheses h is = a3\n    h = a3 \n\n    # 5\\. MAKE REGUKARIZED COST FUNCTION.\n    # calculate P\n    p = np.sum([\n        np.sum(np.sum([np.power(Th1[:, 1:], 2)], 2)),\n        np.sum(np.sum([np.power(Th2[:, 1:], 2)], 2))\n    ])\n\n    # Calculate Cost Function\n    J = np.sum([\n        np.divide(np.sum(np.sum([np.subtract(np.multiply((-Y), np.log(h)), \n                                             np.multiply((1-Y), np.log(1-h)))], 2)), m),\n        np.divide(np.dot(lambd, p), np.dot(2, m))\n    ])    \n\n    # 6\\. FORWARD PROPAGATION\n    # d3 is the difference between a3 and y. \n    d3 = np.subtract(a3, Y)\n\n    z2 = np.hstack((np.ones((m, 1)), z2))\n    d2 = d3.dot(Th2) * gradientDescent(z2)    \n    d2 = d2[:, 1:]\n\n    # GRADIENTS\n    # Delta1 is the product of d2 and a1\\. \n    delta_1 = np.dot(d2.T, a1)\n\n    # Delta2 is the product of d3 and a2\\. \n    delta_2 = np.dot(d3.T, a2)\n\n    # Regularized Gradients.\n    P1 = (lambd/m) * np.hstack([np.zeros((Th1.shape[0], 1)), Th1[:, 1:]])\n    P2 = (lambd/m) * np.hstack([np.zeros((Th2.shape[0], 1)), Th2[:, 1:]])\n\n    Theta_1_grad = (delta_1/m) + P1\n    Theta_2_grad = (delta_2/m) + P2\n\n    grad = np.hstack((Theta_1_grad.ravel(), Theta_2_grad.ravel()))\n\n    return J, grad\n```", "```py\nStructure of Y (the output layer):\n\n1,0,0,0 for label 1\n0,1,0,0 for label 2\n0,0,1,0 for label 3\n0,0,0,1 for lable 4\n```", "```py\n'''\ngradientDescent\nreturns the gradient of the sigmoid function\n\n'''\ndef gradientDescent(z):\n    g  = np.multiply(sigmoid(z), (1-sigmoid(z)))\n    return g\n```", "```py\nTh1_trained, Th2_trained = training(ini_nn_params, I, H1, O, X, y)\n```", "```py\n# Upload thetas from the two files\nwith open('ALZ.50.df_theta_1.pickle', 'rb') as handle:\n        Th1_trained = pickle.load(handle).values\nwith open('ALZ.50.df_theta_2.pickle', 'rb') as handle:\n        Th2_trained = pickle.load(handle).values \n```", "```py\n'''\ntesting()\n'''\ndef testing(Th1, Th2, X, y):\n\n    m, n = X.shape\n    X = np.hstack((np.ones((m, 1)), X))\n    a2 = sigmoid(X.dot(Th1.T))\n    a2 = np.hstack((np.ones((m, 1)), a2))\n    a3 = sigmoid(a2.dot(Th2.T))\n\n    pred = np.argmax(a3, axis=1)\n    pred += 1  \n    print('Training Set Accuracy:', np.mean(pred == y) * 100)\n    return pred\n```", "```py\n# LOAD TESTING DATASET\nwith open('Alz.original.50X50.testing.dataset.pickle', 'rb') as handle:\n    ALZ = pickle.load(handle) \nX = np.stack(ALZ['X'])\ny = np.int64(ALZ['y']) \n```", "```py\npred = testing(Th1_trained, Th2_trained, X, y)\n```", "```py\n'''\nplotSamplesRandomlyWithPrediction\nFunction for visualizing fifty randomly picked images with their prediction.\n'''\n\ndef plotSamplesRandomlyWithPrediction(X, y, pred):\n    from random import randint\n    from matplotlib import pyplot as plt\n\n    # create a list of randomly picked indexes.\n    # the function randint creates the list, picking numbers in a \n    # range 0-Xn, which is the length of X\n\n    randomSelect = [randint(0, len(X)) for i in range(0, 51)]\n\n    # reshape all the pictures on the n X n pixels, \n    w, h =int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))\n    fig=plt.figure(figsize=(int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))))\n\n    # Define a grid of 10 X 10 for the big plot. \n    columns = 10\n    rows = 10\n\n    # The for loop\n    for i in range(1, 51):\n\n        # create the 2-dimensional picture\n        image = X[randomSelect[i]].reshape(w,h)\n        ax = fig.add_subplot(rows, columns, i)\n\n        # create a title for each pictures, containing #index and label\n        #title = \"#\"+str(randomSelect[i])+\"; \"+\"y=\"+str(y[randomSelect[i]])\n        title = \"#\"+str(randomSelect[i])+\"; \"+\"y:\"+str(y[randomSelect[i]])+\"; \"+\"p:\"+str(pred[randomSelect[i]])\n\n        # set the title font size\n        ax.set_title(title, fontsize=np.int(np.sqrt(X.shape[1])/2))        \n\n        # don't display the axis\n        ax.set_axis_off()\n\n        # plot the image in grayscale\n        plt.imshow(image, cmap='gray')\n\n    plt.show()\n```", "```py\nplotSamplesRandomlyWithPrediction(X, y, pred)\n```"]