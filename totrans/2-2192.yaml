- en: Understanding Naive Bayes Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understanding-naive-bayes-algorithm-d753d3b76727](https://towardsdatascience.com/understanding-naive-bayes-algorithm-d753d3b76727)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What it is and How to apply it to a real-world scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://meaganburkhart.medium.com/?source=post_page-----d753d3b76727--------------------------------)[![Meagan
    Burkhart](../Images/d977e25bd5f9bd6e83f92511adaef3f1.png)](https://meaganburkhart.medium.com/?source=post_page-----d753d3b76727--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d753d3b76727--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d753d3b76727--------------------------------)
    [Meagan Burkhart](https://meaganburkhart.medium.com/?source=post_page-----d753d3b76727--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d753d3b76727--------------------------------)
    ·6 min read·Dec 29, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e991a2baa8392c3db178a9a83844d8bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Google DeepMind](https://unsplash.com/@googledeepmind?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This year, my resolution is to go back to the basics of data science. I work
    with data every day, but it’s easy to forget how some of the core algorithms function
    if you’re completing repetitive tasks. I’m aiming to do a deep dive into a data
    algorithm each week here on Towards Data Science. This week, I’m going to cover
    Naive Bayes.
  prefs: []
  type: TYPE_NORMAL
- en: How to Pronounce Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just to get this out of the way, you can learn how to pronounce Naive Bayes
    [here](https://pronouncebee.com/naive-bayes/).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to say it, let’s look at what it means…
  prefs: []
  type: TYPE_NORMAL
- en: What is a Naive Bayes Classifier?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This probabilistic classifier is based on [Bayes’ theorem](https://www.geeksforgeeks.org/bayes-theorem/),
    which can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The conditional probability of an event when a second event has already occurred
    is the product of “event B, given A and the probability of A divided by the probability
    of event B.”
  prefs: []
  type: TYPE_NORMAL
- en: '***P(A|B) = P(B|A)P(A) / P(B)***'
  prefs: []
  type: TYPE_NORMAL
- en: '*A common misconception is that Bayes’ Theorem and conditional probability
    are synonymous.*'
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a distinction — Bayes’ Theorem uses the definition of conditional
    probability to find what is known as the “reverse probability” or the “inverse
    probability”.
  prefs: []
  type: TYPE_NORMAL
- en: Said another way, the conditional probability is the probability of A given
    B. Bayes’ Theorem takes that and finds the probability of B given A.
  prefs: []
  type: TYPE_NORMAL
- en: A notable feature of the Naive Bayes algorithm is its use of sequential events.
    Put simply, by acquiring additional information later, the initial probability
    is adjusted. We will call these the prior probability/marginal probability and
    the posterior probability. The main takeaway is that by knowing another condition’s
    outcome, the initial probability changes.
  prefs: []
  type: TYPE_NORMAL
- en: An Application of Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good example of this is looking at medical testing. For example, if a patient
    is dealing with gastrointestinal issues, the doctor might suspect [Inflammatory
    Bowel Disorder (IBD). The initial probability of having this condition is about
    1.3%.](https://www.cdc.gov/ibd/data-and-statistics/prevalence.html)
  prefs: []
  type: TYPE_NORMAL
- en: However, based on the patient’s symptoms, the doctor orders a blood test for
    [C-reactive protein (CRP), which is a marker of inflammation. If that marker is
    above a certain threshold (>50mg/l)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1856093/),
    the probability of having IBD increases.
  prefs: []
  type: TYPE_NORMAL
- en: Following up on that the doctor performs a colonoscopy and the results show
    visible inflammation. Now the probability of an IBD diagnosis increases again.
  prefs: []
  type: TYPE_NORMAL
- en: We will follow this example through the article to understand how different
    Naive Bayes classifiers can apply in healthcare.
  prefs: []
  type: TYPE_NORMAL
- en: Assumptions of Naive Bayes Classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As its name suggests, the Naive Bayes Classifier is related to the features
    of the algorithm being “naive”, or conditionally independent.
  prefs: []
  type: TYPE_NORMAL
- en: Another assumption is that the features in the model contribute equally to the
    final outcome. However, these assumptions are often violated in real-world scenarios.
    The purpose is to simplify the mathematics behind the calculation of a single
    probability.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pros and Cons of Naive Bayes Classifier**'
  prefs: []
  type: TYPE_NORMAL
- en: A benefit of the Naive Bayes Classifier is that [it performs well on small samples](https://www.ibm.com/topics/naive-bayes),
    even when violating some of the strict assumptions mentioned above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a few disadvantages of Naive Bayes Classifier depending on the problem
    at hand.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, unlike a regression model, a Naive Bayes isn’t intended to measure
    feature importance — mainly because the assumption is that all features contribute
    equally to the outcome.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, there is something known as the “[zero-frequency problem”.](https://www.linkedin.com/pulse/naive-bayes-algorithm-explained-simranjeet-singh/)
    This is when one of the feature combinations has a probability of zero in your
    training data and therefore all of the products of the probabilities will equal
    zero. To overcome this, analysts often add one to the values if there is a possibility
    of it equaling zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Naive Bayes Classifier is often used for text classification tasks, including
    identifying “spam” text and labeling sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: Different Types of Naive Bayes Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following three types of Naive Bayes models differ primarily in the assumptions
    made about their distribution of the conditional probability.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Bernoulli Naive Bayes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bernoulli Naive Bayes is used when there is a binary distribution of the variables.
    This means that all of the features are categorical and can take on a value of
    1 (present) or 0 (absent).
  prefs: []
  type: TYPE_NORMAL
- en: 'When working with Python for Naive Bayes, we can use the `[sklearn.naive_bayes](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes)`.
    BernoulliNB package to binarize variables that are not already categorical. This
    is useful if the cutoff point is the same across features. For instance, 0, could
    be used. However, there are other approaches to binarize continuous data, including
    the Pandas cut function, as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df[''CRGlevel_high''] **=**` `pd.cut(x**=**df[''CRG''], bins**=**[0, 50, np.inf],
    labels**=**[''No'', ''Yes''])`'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Gaussian Naive Bayes classifier**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing to note about Gaussian Naive Bayes is that the features in the
    model are continuous and normally distributed. Based on this assumption when classifying
    a data point in the model, the algorithm assigns the final value to the class
    with the maximum posterior probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gaussian Naive Bayes can be applied to the common Iris Dataset. The basic python
    code to run this alorithm follows below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The documentation for the GaussianNB module can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html).
  prefs: []
  type: TYPE_NORMAL
- en: An interesting thing to understand about Gaussian Naive Bayes is that if the
    assumptions of the algorithm are met, the model functions the same as a logistic
    regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'The assumptions are summarized below from an article by [Bhowmik](https://www.redalyc.org/pdf/925/92542543003.pdf)
    (2015):'
  prefs: []
  type: TYPE_NORMAL
- en: Y is boolean, governed by a Bernoulli distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xi ∼ N(µij , σi), for all i
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For all i and k 6= i, Xi and Xk are conditionally independent given Y .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “NB and LR produce asymptotically the same model if the Naive Bayes assumption
    holds.” [Source](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html)
  prefs: []
  type: TYPE_NORMAL
- en: In our example that we’ve been using, one might want to consider multiple values
    from blood tests to determine whether a person is diagnosed with IBD. Therefore,
    rather than binarizing continuous variables, we can enter the raw CRG value, and
    [other markers of IBD](https://www.crohnscolitisfoundation.org/sites/default/files/legacy/assets/pdfs/diagnosingibd.pdf)
    like Calprotectin, and SedRate.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Multinomial Naive Bayes**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When feature values represennt a relative frequency rather than a binary field,
    we can use Multinomial Naive Bayes.
  prefs: []
  type: TYPE_NORMAL
- en: This is useful for text classification problems that often rely on the frequency
    of a token. In the example we started with IBD, we can think of an application
    of Multinomial Naive Bayes including using electronic health record (EHR) notes.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the notes related to the patient’s symptoms, the model might use the
    frequency of key words like “inflammation”, “diarrhea”, “constipation”, and other
    related terms to identify whether a patient is likely to be diagnosed with Ulcerative
    Colitis (UC) or Crohn’s Disease.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the text alone does not ensure that a diagnosis is made, but a potential
    use case can be using a NB classifier to identify patients at risk of IBD based
    on their symptoms and encourage a medical practitioner to order additional tests
    to either rule out a differential diagnosis or confirm the diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: My Proposed Application in Healthcare
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In summary, Naive Bayes and Bayes’ Theorem make certain assumptions that might
    not work in real-world scenarios. However, when you are dealing with a small dataset
    and looking for a good baseline model, NB can work very well as it is simple to
    compute and understand.
  prefs: []
  type: TYPE_NORMAL
- en: Potential applications in healthcare seem promising based on my research. For
    example, when ruling out a differential diagnosis, one might use a Naive Bayes
    classifier to identify how many tests are needed to reach a final diagnosis. Because
    each feature is expected to be independent and contribute equally, this may help
    guide practitioners when determining which combination of tests is “enough” to
    reach a conclusive diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: I would expect that this can cut down on unnecessary testing and decrease the
    time to a final diagnosis, which benefits the doctor by reducing time, the health
    insurance plan by reducing costs, and the patients by reducing the time it takes
    to receive treatment as well as time undergoing invasive tests.
  prefs: []
  type: TYPE_NORMAL
