- en: Ensuring Trustworthy ML Systems With Data Validation and Real-Time Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保可信的ML系统，通过数据验证和实时监控
- en: 原文：[https://towardsdatascience.com/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360](https://towardsdatascience.com/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360](https://towardsdatascience.com/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)
- en: '[THE FULL STACK 7-STEPS MLOPS FRAMEWORK](https://towardsdatascience.com/tagged/full-stack-mlops)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[完整的7步骤MLOps框架](https://towardsdatascience.com/tagged/full-stack-mlops)'
- en: 'Lesson 5: Data Validation for Quality and Integrity using GE. Model Performance
    Continuous Monitoring.'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程 5：使用GE进行质量和完整性的数据验证。模型性能持续监控。
- en: '[](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)[](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)[](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)
    ·12 min read·Jun 3, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)
    ·阅读时间12分钟·2023年6月3日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/07469861a1fd728e3dce4224cc62ce4f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07469861a1fd728e3dce4224cc62ce4f.png)'
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)拍摄，[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This tutorial represents **lesson 5 out of a 7-lesson course** that will walk
    you step-by-step through how to **design, implement, and deploy an ML system**
    using **MLOps good practices**. During the course, you will build a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程代表**7节课中的第5节**，将逐步指导你如何**设计、实施和部署ML系统**，使用**MLOps良好实践**。在课程中，你将构建一个生产就绪的模型，用于预测未来24小时内来自丹麦的多种消费类型的能源消耗水平。
- en: '*By the end of this course, you will understand all the fundamentals of designing,
    coding and deploying an ML system using a batch-serving architecture.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*到课程结束时，你将理解如何使用批处理服务架构来设计、编码和部署ML系统的所有基本原理。*'
- en: This course *targets mid/advanced machine learning engineers* who want to level
    up their skills by building their own end-to-end projects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本课程*针对中级/高级机器学习工程师*，希望通过构建自己的端到端项目提升技能。
- en: Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如今，证书随处可见。构建先进的端到端项目，并在之后展示出来，是获得专业工程师认可的最佳方式。
- en: 'Table of Contents:'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录：
- en: Course Introduction
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程介绍
- en: Course Lessons
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程内容
- en: Data Source
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据源
- en: 'Lesson 5: Data Validation for Quality and Integrity using GE. Model Performance
    Continuous Monitoring.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程 5：使用GE进行质量和完整性的数据验证。模型性能持续监控。
- en: 'Lesson 5: Code'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程 5：代码
- en: Conclusion
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结论
- en: References
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考文献
- en: Course Introduction
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 课程介绍
- en: '***At the end of this 7 lessons course, you will know how to:***'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '***在这7节课的课程结束时，你将知道如何：***'
- en: design a batch-serving architecture
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计批处理服务架构
- en: use Hopsworks as a feature store
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hopsworks作为特征存储
- en: design a feature engineering pipeline that reads data from an API
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个从API读取数据的特征工程管道
- en: build a training pipeline with hyper-parameter tunning
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个具有超参数调优的训练管道
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用W&B作为ML平台来跟踪你的实验、模型和元数据
- en: implement a batch prediction pipeline
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现批处理预测管道
- en: use Poetry to build your own Python packages
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy your own private PyPi server
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: orchestrate everything with Airflow
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the predictions to code a web app using FastAPI and Streamlit
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Docker to containerize your code
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Great Expectations to ensure data validation and integrity
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: monitor the performance of the predictions over time
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy everything to GCP
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a CI/CD pipeline using GitHub Actions
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If that sounds like a lot, don't worry. After you cover this course, you will
    understand everything I said before. Most importantly, you will know WHY I used
    all these tools and how they work together as a system.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. This course is designed to quickly read and replicate
    the code along the articles.**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the course, you will know how to implement the diagram below.
    Don't worry if something doesn't make sense to you. I will explain everything
    in detail.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: Diagram of the architecture you will build during the course [Image by the Author].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: By the **end of Lesson 5**, you will know how to use Great Expectations to validate
    the integrity and quality of your data. Also, you will understand how to implement
    a monitoring component on top of your ML system.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'Course Lessons:'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Batch Serving. Feature Stores. Feature Engineering Pipelines.](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Training Pipelines. ML Platforms. Hyperparameter Tuning.](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Consume and Visualize your Model’s Predictions using FastAPI and Streamlit.
    Dockerize Everything.](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github Actions.](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[[Bonus] Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and Insights](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For more context, check out [Lesson 3](/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489),
    which will teach you how to build an inference pipeline using batch architecture
    and a Feature Store.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多背景信息，请查看[第3课](/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)，这将教你如何使用批处理架构和特征存储构建推理管道。
- en: Also, [Lesson 4](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)
    will show you how to orchestrate all the pipelines using Airflow.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，[第4课](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)将展示如何使用Airflow来协调所有的管道。
- en: This lesson will leverage the above ideas and assume you already understand
    them.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这节课将利用上述观点，并假设你已经理解了这些观点。
- en: Data Source
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据源
- en: We used a free & open API that provides hourly energy consumption values for
    all the energy consumer types within Denmark [1].
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个免费且开放的API，提供丹麦所有能源消费者类型的每小时能源消耗值 [1]。
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 他们提供了一个直观的界面，你可以轻松查询和可视化数据。[你可以在这里访问数据](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1]。
- en: 'The data has 4 main attributes:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有4个主要属性：
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小时 UTC：** 数据点被观测到的UTC日期时间。'
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 — divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价格区域：** 丹麦被分为两个价格区域：DK1和DK2——由大贝尔特分隔。DK1位于大贝尔特以西，DK2位于大贝尔特以东。'
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费者类型：** 消费者类型是工业代码DE35，由丹麦能源公司拥有和维护。'
- en: '**Total Consumption:** Total electricity consumption in kWh'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总消耗：** 总电力消耗（单位：千瓦时）'
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would in real-time.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 观测数据有15天的延迟！但对于我们的演示用例，这不是问题，因为我们可以模拟实时发生的相同步骤。'
- en: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
- en: A screenshot from our web app showing how we forecasted the energy consumption
    for area = 1 and consumer_type = 212 [Image by the Author].
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网页应用截图，展示了如何预测区域 = 1 和消费者类型 = 212 的能源消耗 [作者图片]。
- en: 'The data points have an hourly resolution. For example: "2023–04–15 21:00Z",
    "2023–04–15 20:00Z", "2023–04–15 19:00Z", etc.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点具有每小时的分辨率。例如：“2023–04–15 21:00Z”，“2023–04–15 20:00Z”，“2023–04–15 19:00Z”，等等。
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据建模为多个时间序列。每个唯一的**价格区域**和**消费者类型元组表示其**唯一的时间序列。
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将构建一个模型，独立预测每个时间序列未来24小时的能源消耗。
- en: '*Check out the video below to better understand what the data looks like* 👇'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看下面的视频以更好地理解数据的样子* 👇'
- en: Course & data source overview [Video by the Author].
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 课程和数据源概述 [作者视频]。
- en: 'Lesson 5: Data Validation for Quality and Integrity using GE. Model Performance
    Continuous Monitoring.'
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5课：使用GE进行数据质量和完整性的验证。模型性能持续监控。
- en: The goal of Lesson 5
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5课的目标
- en: At this point, the ML pipeline is implemented and orchestrated. That means we
    are done, right?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，机器学习流程已经实施并协调好了。这意味着我们完成了吗？
- en: Not quite…
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 还不完全……
- en: One final step, which will transform you from a good engineer to an excellent
    one, is adding a component that will allow you to quickly diagnose what is happening
    in your production system.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步，将使你从一个优秀的工程师成长为一个杰出的工程师，就是添加一个组件，让你能够快速诊断生产系统中发生的情况。
- en: 'During Lesson 5, you will primarily *learn 2 different* topics that serve one
    single goal: to ensure your production system is working correctly.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在第5课中，你将主要*学习两个不同*的主题，这些主题服务于一个共同目标：确保你的生产系统正常工作。
- en: '**1\. Data Validation:** check if the data generated by the FE pipeline is
    OK before ingesting it into the Feature Store.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 数据验证：** 在将数据导入特征存储之前，检查FE管道生成的数据是否正常。'
- en: '**2\. Model Monitoring:** continually compute various metrics that reflect
    the performance of your production model.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 模型监控：** 持续计算反映你生产模型性能的各种指标。'
- en: '![](../Images/bc9c67310f0bc41eb8a94d05c6f3ddab.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc9c67310f0bc41eb8a94d05c6f3ddab.png)'
- en: Diagram of the final architecture with the Lesson 5 components highlighted in
    blue [Image by the Author].
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: I will go into more detail in the *Theoretical Concepts & Tools* section. Still,
    as a brief overview, to continually monitor your model's performance, you will
    use your old predictions with the newly gathered ground truth to compute a desired
    metric, in your case MAPE.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: For example, you predict the energy consumption values from the 1st of June
    for 24 hours. Initially, you don't have the data to compute the metrics. But,
    after 12 hours, you can collect the real energy consumption. Thus, you just put
    your hands on the ground truth to compute the desired metrics for the last 12
    hours.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: After 1 hour, you can compute the metric for another data point, and so on…
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: This is the strategy we will adopt in this tutorial.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical Concepts & Tools
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Data Validation:** Data validation refers to the process of ensuring data
    quality and integrity. What do I mean by that?'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: As you automatically gather data from different sources (in our case, an API),
    you need a way to continually validate that the data you just extracted follows
    a set of rules that your system expects.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, you expect that the energy consumption values are:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: of type float,
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: not null,
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ≥0.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While you developed the ML pipeline, the API returned only values that respected
    these terms, as data people call it: a "data contract."'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: But, as you leave your system to run in production for a 1 month, 1 year, 2
    years, etc., you will never know what could change to data sources you don't have
    control over.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Thus, you need a way to constantly check these characteristics before ingesting
    the data into the Feature Store.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** To see how to extend this concept to unstructured data, such as images,
    you can check my [Master Data Integrity to Clean Your Computer Vision Datasets](https://medium.com/towards-data-science/master-data-integrity-to-clean-your-computer-vision-datasets-df432cf9e596)
    article.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '**Great Expectations (aka GE):** GE is a popular tool that easily lets you
    do data validation and report the results. Hopsworks has GE support. You can add
    a GE validation suit to Hopsworks and choose how to behave when new data is inserted,
    and the validation step fails — [read more about GE + Hopsworks](https://www.hopsworks.ai/post/data-validation-for-enterprise-ai-using-great-expectations-with-hopsworks)
    [2].'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6f170c915d6b637bc8f61293e6e3241.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: Screenshot of GE data validation runs inside Hopswork [Image by the Author].
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '**Ground Truth Types:** While your model is running in production, you can
    have access to your ground truth in 3 different scenarios:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '**real-time:** an ideal scenario where you can easily access your target. For
    example, when you recommend an ad and the consumer either clicks it or not.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**delayed:** eventually, you will access the ground truths. But, unfortunately,
    it will be too late to react in time adequately.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**none:** you can''t automatically collect any GT. Usually, in these cases,
    you have to hire human annotators if you need any actuals.'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无：** 你无法自动收集任何 GT。通常在这种情况下，如果需要实际数据，你必须聘请人工注释员。'
- en: '![](../Images/f7dd6d4d8927ea55b4b01751f0cafe92.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7dd6d4d8927ea55b4b01751f0cafe92.png)'
- en: Ground truth/targets/actuals types [Image by the Author].
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 真实数据/目标/实际数据类型 [作者提供的图像]。
- en: 'In our case, we are somewhere between #1\. and #2\. The GT isn''t precisely
    in real-time, but it has a delay only of 1 hour.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '在我们的案例中，我们介于 #1 和 #2 之间。GT 不完全是实时的，但延迟只有 1 小时。'
- en: Whether a delay of 1 hour is OK depends a lot on the business context, but let's
    say that, in your case, it is okay.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟 1 小时是否合适很大程度上取决于业务背景，但假设在你的情况下，这是可以的。
- en: 'As we considered that a delay of 1 hour is ok for our use case, we are in good
    luck: we have access to the GT in real-time(ish).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们认为 1 小时的延迟对于我们的用例是可以的，我们很幸运：我们实时（近实时）访问 GT。
- en: This means we can use metrics such as MAPE to monitor the model's performance
    in real-time(ish).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以使用 MAPE 等指标来实时（近实时）监控模型的性能。
- en: In scenarios 2 or 3, we needed to use data & concept drifts as proxy metrics
    to compute performance signals in time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在情景 2 或 3 中，我们需要使用数据和概念漂移作为代理指标来计算时间上的性能信号。
- en: '![](../Images/7a1335174dc43023cb2db7a8ff2b3a97.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a1335174dc43023cb2db7a8ff2b3a97.png)'
- en: Screenshot with the observations and predictions overlapped over time. As you
    can see, the GT isn't available for the latest 24 hours of forecasts [Image by
    the Author].
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 显示观察结果和预测重叠的截图。如你所见，GT 在最新的 24 小时预测中不可用 [作者提供的图像]。
- en: '**ML Monitoring:** ML monitoring is the process of assuring that your production
    system works well over time. Also, it gives you a mechanism to proactively adapt
    your system, such as retraining your model in time or adapting it to new changes
    in the environment.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**ML 监控：** ML 监控是确保你的生产系统随时间正常运行的过程。同时，它为你提供了一种机制，可以主动调整系统，例如及时重新训练模型或使其适应环境中的新变化。'
- en: In our case, we will continually compute the MAPE metric. Thus, if the error
    suddenly spikes, you can create an alarm to inform you or automatically trigger
    a hyper-optimization tuning step to adapt the model configuration to the new environment.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们将持续计算 MAPE 指标。因此，如果误差突然激增，你可以创建警报来通知你，或自动触发超参数优化步骤以将模型配置适应新环境。
- en: '![](../Images/19ccebd0ef39654b91664283b9da6c21.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19ccebd0ef39654b91664283b9da6c21.png)'
- en: Screenshot with the mean MAPE metric between all the time series computed over
    time [Image by the Author].
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 显示所有时间序列计算出的平均 MAPE 指标的截图 [作者提供的图像]。
- en: 'Lesson 5: Code'
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 课：代码
- en: '[You can access the GitHub repository here.](https://github.com/iusztinpaul/energy-forecasting)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[你可以在这里访问 GitHub 仓库。](https://github.com/iusztinpaul/energy-forecasting)'
- en: '**Note:** All the installation instructions are in the READMEs of the repository.
    Here you will jump straight to the code.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 所有的安装说明都在仓库的 README 文件中。在这里，你将直接跳到代码部分。'
- en: '*The code within Lesson 5 is located under the following:*'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*第 5 课中的代码位于以下位置：*'
- en: '[***feature-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)
    *folder —* ***data validation,***'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[***feature-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)
    *文件夹 —* ***数据验证，***'
- en: '[***batch-prediction-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/batch-prediction-pipeline)*folder
    —* ***ML monitoring.***'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[***batch-prediction-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/batch-prediction-pipeline)
    *文件夹 —* ***ML 监控。***'
- en: Using Docker, you can quickly host everything inside Airflow, so you don't have
    to waste a lot of time setting things up.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Docker，你可以快速在 Airflow 中托管所有内容，这样你就不必浪费大量时间进行设置。
- en: Directly storing credentials in your git repository is a huge security risk.
    That is why you will inject sensitive information using a **.env** file.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 直接将凭证存储在你的 git 仓库中是一个巨大的安全风险。这就是为什么你将使用 **.env** 文件来注入敏感信息。
- en: The **.env.default** is an example of all the variables you must configure.
    It is also helpful to store default values for attributes that are not sensitive
    (e.g., project name).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**.env.default** 是你必须配置的所有变量的示例。它也有助于存储不敏感的属性的默认值（例如项目名称）。'
- en: '![](../Images/0f2af448ab3e5abc1a151b1ecb324575.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f2af448ab3e5abc1a151b1ecb324575.png)'
- en: A screenshot of the .env.default file [Image by the Author].
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: .env.default 文件的截图 [作者提供的图像]。
- en: Prepare Credentials
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备凭证
- en: I don't want to repeat myself too much. You already have step-by-step instructions
    on how to set up your credentials in the **"Prepare Credentials"** of previous
    lessons.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, in this article, you don't have to prepare additional credentials
    from previous lessons.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Checking the **“Prepare Credentials”** of[Lesson 4](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)
    is a great starting point showing you how to prepare all your credentials and
    tools. Also, check the [GitHub Repository](https://github.com/iusztinpaul/energy-forecasting)
    for additional information.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: It will show you how to complete all your credentials in your **.env** file.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's start coding 🔥
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Data Validation
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overview of doing data validation with GE + Hopsworks [Video by the Author].
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: The GE suit is defined in the [*feature-pipeline/feature_pipeline/etc/validation.py*](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/etl/validation.py)
    file.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: In the code below, you defined a GE **ExpectationSuite** called **energy_consumption_suite.**
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the **ExpectationConfiguration** class, you can add various validation
    tests. In the following example, 2 tests were added:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Checks if the columns of the table match with a given ordered list.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Checks the length of the columns to be equal to 4.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Easy and powerful 🔥*'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at the full validation suit 👇
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'Using GE, you will check a Pandas DataFrame for the following characteristics:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'The columns should be equal to: ["datetime_utc,"… "energy_consumption"].'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The DF should have exactly 4 columns.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "datetime_utc" should have all the values different than null.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "area" expects only values equal to 0, 1 or 2.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "area" should be of type *int8.*
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "consumer_type" expects only values equal to 111, …
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "consumer_type" should be of type *int32*.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "energy_consumption" should have values ≥ 0.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "energy_consumption" should be of type float64.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "energy_consumption" should have all the values different than null.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***As you can see, the quality checks mostly resume to:***'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Check the schema of the table.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the type of the columns.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the values of the columns (different logic for discrete or continuous
    features).
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check for nulls.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will attach this validation suit in the **to_feature_store()** loading function
    of the FE pipeline from the [*feature-pipeline/feature_pipeline/etl/load.py*](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/etl/load.py)
    file.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Now Hopsworks will run the given GE validation suit every time a new DataFrame
    is inserted into the feature group.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: You can choose to reject the new data if the validation suit fails or to get
    an alarm to take manual action.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: ML Monitoring
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overview of the ML monitoring dashboard built inside the course [video by the
    Author].
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to ML monitoring, the hardest part isn't the code itself but mostly
    choosing how to monitor your ML models.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到 ML 监控时，最困难的部分不是代码本身，而是如何选择监控你的 ML 模型。
- en: Note that tools, such as [Evidently](https://www.evidentlyai.com/) or [Arize](https://arize.com/),
    are usually used for ML monitoring. But in this case, I wanted to keep it simple
    and not add another tool to the series.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，像 [Evidently](https://www.evidentlyai.com/) 或 [Arize](https://arize.com/)
    这样的工具通常用于 ML 监控。但在这种情况下，我想保持简单，不再添加另一个工具。
- en: '***But the concepts remain the same, which is the most crucial to understand.***'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '***但概念仍然是相同的，这一点最为关键。***'
- en: 'In the code snippet below, we did the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码片段中，我们做了以下事情：
- en: Loaded the predictions from the GCP bucket. All the predictions are aggregated
    in the **predictions_monitoring.parquet** file during the batch prediction step.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 GCP 存储桶加载了预测数据。所有预测数据都在批量预测步骤中聚合在 **predictions_monitoring.parquet** 文件中。
- en: Prepared the structure of the predictions DataFrame.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备了预测 DataFrame 的结构。
- en: Connected to the Hopsworks Feature Store.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接到 Hopsworks 特征存储。
- en: Queried the Feature Store for data within the minimum and maximum predictions
    datetime edges. This is your GT. You want to get everything available based on
    your prediction's datetime window.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询了特征存储中位于最小和最大预测时间边界的数据。这就是你的 GT。你想根据预测的时间窗口获取所有可用的数据。
- en: Prepared the structure of the GT DataFrame.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备了 GT DataFrame 的结构。
- en: Merge the two DataFrames.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并两个 DataFrame。
- en: Where the GT is available, compute the MAPE metric. Out of simplicity, you will
    compute the MAPE metrics aggregated over all the time series.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 GT 可用的地方，计算 MAPE 指标。为了简化，你将计算所有时间序列的 MAPE 指标的聚合值。
- en: Write the results back to the GCP bucket, which will be loaded & displayed by
    the frontend.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果写回到 GCP 存储桶，由前端加载和显示。
- en: The function defined above will act as its own task in the Airflow DAG. It will
    be called every time the ML pipeline is running. Thus, every hour, it will look
    for new matches between a prediction and a GT, compute the MAPE metric and upload
    it to GCS.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 上面定义的函数将在 Airflow DAG 中作为自己的任务运行。每次 ML 管道运行时，它都会被调用。因此，每小时，它将查找预测和 GT 之间的新匹配项，计算
    MAPE 指标并将其上传到 GCS。
- en: Read [Lesson 6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
    to see how you can display the results from the GCP bucket in a beautiful UI using
    Streamlit and FastAPI.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读 [第6课](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
    了解如何使用 Streamlit 和 FastAPI 以美观的 UI 显示来自 GCP 存储桶的结果。
- en: Conclusion
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Congratulations! You finished the **fifth lesson** from the **Full Stack 7-Steps
    MLOps Framework** course. It means you are close to knowing how to build an end-to-end
    ML system using MLOps good practices.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你完成了 **第五课** 来自 **全栈7步 MLOps 框架** 课程。这意味着你接近于了解如何使用 MLOps 好实践构建一个端到端的 ML
    系统。
- en: 'In this lesson, you learned how to:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在本课程中，你学会了如何：
- en: use GE to build a data validation suit that tests your data quality and integrity,
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GE 构建一个数据验证套件来测试你的数据质量和完整性，
- en: understand why ML monitoring is essential,
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解为什么 ML 监控至关重要，
- en: build your own ML monitoring system to track model performance in real time.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建你自己的 ML 监控系统，以实时跟踪模型性能。
- en: Now that you understand the power of taking control of your data and ML system,
    you can sleep like a baby at night knowing that everything is working well or
    if not; you can quickly diagnose the issue.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你理解了掌控数据和 ML 系统的力量，你可以安稳地睡觉，知道一切运转良好，如果有问题，你也可以快速诊断。
- en: '[Check out Lesson 6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
    to learn how to use your predictions and monitoring metrics from your GCP bucket
    to build a web app using FastAPI and Streamlit.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看第6课](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)以了解如何使用你的预测和来自
    GCP 存储桶的监控指标，利用 FastAPI 和 Streamlit 构建一个 Web 应用。'
- en: '**Also,** [**you can access the GitHub repository here**](https://github.com/iusztinpaul/energy-forecasting)**.**'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**此外，** [**你可以在这里访问 GitHub 仓库**](https://github.com/iusztinpaul/energy-forecasting)**。**'
- en: 💡 My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 💡 我的目标是帮助机器学习工程师在设计和生产化 ML 系统方面提升技能。关注我在 [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    或订阅我的 [每周通讯](https://pauliusztin.substack.com/) 获取更多见解！
- en: 🔥 If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). Using [my
    referral link](https://pauliusztin.medium.com/membership), you can support me
    without extra cost while enjoying limitless access to Medium's rich collection
    of stories.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 🔥 如果你喜欢阅读类似的文章并希望支持我的写作，考虑 [成为 Medium 会员](https://pauliusztin.medium.com/membership)。通过使用
    [我的推荐链接](https://pauliusztin.medium.com/membership)，你可以在没有额外费用的情况下支持我，同时享受 Medium
    丰富故事的无限访问。
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----89ab079f4360--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/membership?source=post_page-----89ab079f4360--------------------------------)
    [## 使用我的推荐链接加入 Medium - Paul Iusztin'
- en: 🤖 Join to get exclusive content about designing and building production-ready
    ML systems 🚀 Unlock full access to…
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 🤖 加入以获取有关设计和构建生产就绪 ML 系统的独家内容 🚀 解锁完整访问…
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----89ab079f4360--------------------------------)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----89ab079f4360--------------------------------)'
- en: References
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [丹麦 API 的 DE35 行业代码能耗](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)，[丹麦能源数据服务](https://www.energidataservice.dk/about/)'
- en: '[2] [Data Validation for Enterprise AI: Using Great Expectations with Hopsworks](https://www.hopsworks.ai/post/data-validation-for-enterprise-ai-using-great-expectations-with-hopsworks)
    (2022), Hopsworks Blog'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [企业 AI 数据验证：在 Hopsworks 中使用 Great Expectations](https://www.hopsworks.ai/post/data-validation-for-enterprise-ai-using-great-expectations-with-hopsworks)（2022），Hopsworks
    博客'
