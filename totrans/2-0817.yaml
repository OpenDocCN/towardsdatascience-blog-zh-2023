- en: Ensuring Trustworthy ML Systems With Data Validation and Real-Time Monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360](https://towardsdatascience.com/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[THE FULL STACK 7-STEPS MLOPS FRAMEWORK](https://towardsdatascience.com/tagged/full-stack-mlops)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Lesson 5: Data Validation for Quality and Integrity using GE. Model Performance
    Continuous Monitoring.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)[](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----89ab079f4360--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----89ab079f4360--------------------------------)
    ·12 min read·Jun 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07469861a1fd728e3dce4224cc62ce4f.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial represents **lesson 5 out of a 7-lesson course** that will walk
    you step-by-step through how to **design, implement, and deploy an ML system**
    using **MLOps good practices**. During the course, you will build a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  prefs: []
  type: TYPE_NORMAL
- en: '*By the end of this course, you will understand all the fundamentals of designing,
    coding and deploying an ML system using a batch-serving architecture.*'
  prefs: []
  type: TYPE_NORMAL
- en: This course *targets mid/advanced machine learning engineers* who want to level
    up their skills by building their own end-to-end projects.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Table of Contents:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Lessons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lesson 5: Data Validation for Quality and Integrity using GE. Model Performance
    Continuous Monitoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lesson 5: Code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***At the end of this 7 lessons course, you will know how to:***'
  prefs: []
  type: TYPE_NORMAL
- en: design a batch-serving architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Hopsworks as a feature store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: design a feature engineering pipeline that reads data from an API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a training pipeline with hyper-parameter tunning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: implement a batch prediction pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Poetry to build your own Python packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy your own private PyPi server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: orchestrate everything with Airflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the predictions to code a web app using FastAPI and Streamlit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Docker to containerize your code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Great Expectations to ensure data validation and integrity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: monitor the performance of the predictions over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy everything to GCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a CI/CD pipeline using GitHub Actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If that sounds like a lot, don't worry. After you cover this course, you will
    understand everything I said before. Most importantly, you will know WHY I used
    all these tools and how they work together as a system.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. This course is designed to quickly read and replicate
    the code along the articles.**'
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the course, you will know how to implement the diagram below.
    Don't worry if something doesn't make sense to you. I will explain everything
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the architecture you will build during the course [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: By the **end of Lesson 5**, you will know how to use Great Expectations to validate
    the integrity and quality of your data. Also, you will understand how to implement
    a monitoring component on top of your ML system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Course Lessons:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Batch Serving. Feature Stores. Feature Engineering Pipelines.](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Training Pipelines. ML Platforms. Hyperparameter Tuning.](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Consume and Visualize your Model’s Predictions using FastAPI and Streamlit.
    Dockerize Everything.](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github Actions.](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[[Bonus] Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and Insights](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For more context, check out [Lesson 3](/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489),
    which will teach you how to build an inference pipeline using batch architecture
    and a Feature Store.
  prefs: []
  type: TYPE_NORMAL
- en: Also, [Lesson 4](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)
    will show you how to orchestrate all the pipelines using Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: This lesson will leverage the above ideas and assume you already understand
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We used a free & open API that provides hourly energy consumption values for
    all the energy consumer types within Denmark [1].
  prefs: []
  type: TYPE_NORMAL
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data has 4 main attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 — divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total Consumption:** Total electricity consumption in kWh'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would in real-time.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot from our web app showing how we forecasted the energy consumption
    for area = 1 and consumer_type = 212 [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data points have an hourly resolution. For example: "2023–04–15 21:00Z",
    "2023–04–15 20:00Z", "2023–04–15 19:00Z", etc.'
  prefs: []
  type: TYPE_NORMAL
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  prefs: []
  type: TYPE_NORMAL
- en: '*Check out the video below to better understand what the data looks like* 👇'
  prefs: []
  type: TYPE_NORMAL
- en: Course & data source overview [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'Lesson 5: Data Validation for Quality and Integrity using GE. Model Performance
    Continuous Monitoring.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of Lesson 5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, the ML pipeline is implemented and orchestrated. That means we
    are done, right?
  prefs: []
  type: TYPE_NORMAL
- en: Not quite…
  prefs: []
  type: TYPE_NORMAL
- en: One final step, which will transform you from a good engineer to an excellent
    one, is adding a component that will allow you to quickly diagnose what is happening
    in your production system.
  prefs: []
  type: TYPE_NORMAL
- en: 'During Lesson 5, you will primarily *learn 2 different* topics that serve one
    single goal: to ensure your production system is working correctly.'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Data Validation:** check if the data generated by the FE pipeline is
    OK before ingesting it into the Feature Store.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Model Monitoring:** continually compute various metrics that reflect
    the performance of your production model.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc9c67310f0bc41eb8a94d05c6f3ddab.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the final architecture with the Lesson 5 components highlighted in
    blue [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: I will go into more detail in the *Theoretical Concepts & Tools* section. Still,
    as a brief overview, to continually monitor your model's performance, you will
    use your old predictions with the newly gathered ground truth to compute a desired
    metric, in your case MAPE.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you predict the energy consumption values from the 1st of June
    for 24 hours. Initially, you don't have the data to compute the metrics. But,
    after 12 hours, you can collect the real energy consumption. Thus, you just put
    your hands on the ground truth to compute the desired metrics for the last 12
    hours.
  prefs: []
  type: TYPE_NORMAL
- en: After 1 hour, you can compute the metric for another data point, and so on…
  prefs: []
  type: TYPE_NORMAL
- en: This is the strategy we will adopt in this tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical Concepts & Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Data Validation:** Data validation refers to the process of ensuring data
    quality and integrity. What do I mean by that?'
  prefs: []
  type: TYPE_NORMAL
- en: As you automatically gather data from different sources (in our case, an API),
    you need a way to continually validate that the data you just extracted follows
    a set of rules that your system expects.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, you expect that the energy consumption values are:'
  prefs: []
  type: TYPE_NORMAL
- en: of type float,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: not null,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ≥0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While you developed the ML pipeline, the API returned only values that respected
    these terms, as data people call it: a "data contract."'
  prefs: []
  type: TYPE_NORMAL
- en: But, as you leave your system to run in production for a 1 month, 1 year, 2
    years, etc., you will never know what could change to data sources you don't have
    control over.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, you need a way to constantly check these characteristics before ingesting
    the data into the Feature Store.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** To see how to extend this concept to unstructured data, such as images,
    you can check my [Master Data Integrity to Clean Your Computer Vision Datasets](https://medium.com/towards-data-science/master-data-integrity-to-clean-your-computer-vision-datasets-df432cf9e596)
    article.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Great Expectations (aka GE):** GE is a popular tool that easily lets you
    do data validation and report the results. Hopsworks has GE support. You can add
    a GE validation suit to Hopsworks and choose how to behave when new data is inserted,
    and the validation step fails — [read more about GE + Hopsworks](https://www.hopsworks.ai/post/data-validation-for-enterprise-ai-using-great-expectations-with-hopsworks)
    [2].'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6f170c915d6b637bc8f61293e6e3241.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of GE data validation runs inside Hopswork [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: '**Ground Truth Types:** While your model is running in production, you can
    have access to your ground truth in 3 different scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**real-time:** an ideal scenario where you can easily access your target. For
    example, when you recommend an ad and the consumer either clicks it or not.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**delayed:** eventually, you will access the ground truths. But, unfortunately,
    it will be too late to react in time adequately.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**none:** you can''t automatically collect any GT. Usually, in these cases,
    you have to hire human annotators if you need any actuals.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/f7dd6d4d8927ea55b4b01751f0cafe92.png)'
  prefs: []
  type: TYPE_IMG
- en: Ground truth/targets/actuals types [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we are somewhere between #1\. and #2\. The GT isn''t precisely
    in real-time, but it has a delay only of 1 hour.'
  prefs: []
  type: TYPE_NORMAL
- en: Whether a delay of 1 hour is OK depends a lot on the business context, but let's
    say that, in your case, it is okay.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we considered that a delay of 1 hour is ok for our use case, we are in good
    luck: we have access to the GT in real-time(ish).'
  prefs: []
  type: TYPE_NORMAL
- en: This means we can use metrics such as MAPE to monitor the model's performance
    in real-time(ish).
  prefs: []
  type: TYPE_NORMAL
- en: In scenarios 2 or 3, we needed to use data & concept drifts as proxy metrics
    to compute performance signals in time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a1335174dc43023cb2db7a8ff2b3a97.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot with the observations and predictions overlapped over time. As you
    can see, the GT isn't available for the latest 24 hours of forecasts [Image by
    the Author].
  prefs: []
  type: TYPE_NORMAL
- en: '**ML Monitoring:** ML monitoring is the process of assuring that your production
    system works well over time. Also, it gives you a mechanism to proactively adapt
    your system, such as retraining your model in time or adapting it to new changes
    in the environment.'
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we will continually compute the MAPE metric. Thus, if the error
    suddenly spikes, you can create an alarm to inform you or automatically trigger
    a hyper-optimization tuning step to adapt the model configuration to the new environment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/19ccebd0ef39654b91664283b9da6c21.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot with the mean MAPE metric between all the time series computed over
    time [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'Lesson 5: Code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[You can access the GitHub repository here.](https://github.com/iusztinpaul/energy-forecasting)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** All the installation instructions are in the READMEs of the repository.
    Here you will jump straight to the code.'
  prefs: []
  type: TYPE_NORMAL
- en: '*The code within Lesson 5 is located under the following:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[***feature-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)
    *folder —* ***data validation,***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***batch-prediction-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/batch-prediction-pipeline)*folder
    —* ***ML monitoring.***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker, you can quickly host everything inside Airflow, so you don't have
    to waste a lot of time setting things up.
  prefs: []
  type: TYPE_NORMAL
- en: Directly storing credentials in your git repository is a huge security risk.
    That is why you will inject sensitive information using a **.env** file.
  prefs: []
  type: TYPE_NORMAL
- en: The **.env.default** is an example of all the variables you must configure.
    It is also helpful to store default values for attributes that are not sensitive
    (e.g., project name).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f2af448ab3e5abc1a151b1ecb324575.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot of the .env.default file [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: Prepare Credentials
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I don't want to repeat myself too much. You already have step-by-step instructions
    on how to set up your credentials in the **"Prepare Credentials"** of previous
    lessons.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, in this article, you don't have to prepare additional credentials
    from previous lessons.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the **“Prepare Credentials”** of[Lesson 4](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)
    is a great starting point showing you how to prepare all your credentials and
    tools. Also, check the [GitHub Repository](https://github.com/iusztinpaul/energy-forecasting)
    for additional information.
  prefs: []
  type: TYPE_NORMAL
- en: It will show you how to complete all your credentials in your **.env** file.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's start coding 🔥
  prefs: []
  type: TYPE_NORMAL
- en: Data Validation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overview of doing data validation with GE + Hopsworks [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: The GE suit is defined in the [*feature-pipeline/feature_pipeline/etc/validation.py*](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/etl/validation.py)
    file.
  prefs: []
  type: TYPE_NORMAL
- en: In the code below, you defined a GE **ExpectationSuite** called **energy_consumption_suite.**
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the **ExpectationConfiguration** class, you can add various validation
    tests. In the following example, 2 tests were added:'
  prefs: []
  type: TYPE_NORMAL
- en: Checks if the columns of the table match with a given ordered list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Checks the length of the columns to be equal to 4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Easy and powerful 🔥*'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at the full validation suit 👇
  prefs: []
  type: TYPE_NORMAL
- en: 'Using GE, you will check a Pandas DataFrame for the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The columns should be equal to: ["datetime_utc,"… "energy_consumption"].'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The DF should have exactly 4 columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "datetime_utc" should have all the values different than null.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "area" expects only values equal to 0, 1 or 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "area" should be of type *int8.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "consumer_type" expects only values equal to 111, …
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "consumer_type" should be of type *int32*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "energy_consumption" should have values ≥ 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "energy_consumption" should be of type float64.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column "energy_consumption" should have all the values different than null.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***As you can see, the quality checks mostly resume to:***'
  prefs: []
  type: TYPE_NORMAL
- en: Check the schema of the table.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the type of the columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the values of the columns (different logic for discrete or continuous
    features).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check for nulls.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will attach this validation suit in the **to_feature_store()** loading function
    of the FE pipeline from the [*feature-pipeline/feature_pipeline/etl/load.py*](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/etl/load.py)
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Now Hopsworks will run the given GE validation suit every time a new DataFrame
    is inserted into the feature group.
  prefs: []
  type: TYPE_NORMAL
- en: You can choose to reject the new data if the validation suit fails or to get
    an alarm to take manual action.
  prefs: []
  type: TYPE_NORMAL
- en: ML Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overview of the ML monitoring dashboard built inside the course [video by the
    Author].
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to ML monitoring, the hardest part isn't the code itself but mostly
    choosing how to monitor your ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Note that tools, such as [Evidently](https://www.evidentlyai.com/) or [Arize](https://arize.com/),
    are usually used for ML monitoring. But in this case, I wanted to keep it simple
    and not add another tool to the series.
  prefs: []
  type: TYPE_NORMAL
- en: '***But the concepts remain the same, which is the most crucial to understand.***'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the code snippet below, we did the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Loaded the predictions from the GCP bucket. All the predictions are aggregated
    in the **predictions_monitoring.parquet** file during the batch prediction step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepared the structure of the predictions DataFrame.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connected to the Hopsworks Feature Store.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Queried the Feature Store for data within the minimum and maximum predictions
    datetime edges. This is your GT. You want to get everything available based on
    your prediction's datetime window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepared the structure of the GT DataFrame.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the two DataFrames.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where the GT is available, compute the MAPE metric. Out of simplicity, you will
    compute the MAPE metrics aggregated over all the time series.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the results back to the GCP bucket, which will be loaded & displayed by
    the frontend.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The function defined above will act as its own task in the Airflow DAG. It will
    be called every time the ML pipeline is running. Thus, every hour, it will look
    for new matches between a prediction and a GT, compute the MAPE metric and upload
    it to GCS.
  prefs: []
  type: TYPE_NORMAL
- en: Read [Lesson 6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
    to see how you can display the results from the GCP bucket in a beautiful UI using
    Streamlit and FastAPI.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You finished the **fifth lesson** from the **Full Stack 7-Steps
    MLOps Framework** course. It means you are close to knowing how to build an end-to-end
    ML system using MLOps good practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this lesson, you learned how to:'
  prefs: []
  type: TYPE_NORMAL
- en: use GE to build a data validation suit that tests your data quality and integrity,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: understand why ML monitoring is essential,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build your own ML monitoring system to track model performance in real time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you understand the power of taking control of your data and ML system,
    you can sleep like a baby at night knowing that everything is working well or
    if not; you can quickly diagnose the issue.
  prefs: []
  type: TYPE_NORMAL
- en: '[Check out Lesson 6](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
    to learn how to use your predictions and monitoring metrics from your GCP bucket
    to build a web app using FastAPI and Streamlit.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Also,** [**you can access the GitHub repository here**](https://github.com/iusztinpaul/energy-forecasting)**.**'
  prefs: []
  type: TYPE_NORMAL
- en: 💡 My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  prefs: []
  type: TYPE_NORMAL
- en: 🔥 If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). Using [my
    referral link](https://pauliusztin.medium.com/membership), you can support me
    without extra cost while enjoying limitless access to Medium's rich collection
    of stories.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----89ab079f4360--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  prefs: []
  type: TYPE_NORMAL
- en: 🤖 Join to get exclusive content about designing and building production-ready
    ML systems 🚀 Unlock full access to…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----89ab079f4360--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Data Validation for Enterprise AI: Using Great Expectations with Hopsworks](https://www.hopsworks.ai/post/data-validation-for-enterprise-ai-using-great-expectations-with-hopsworks)
    (2022), Hopsworks Blog'
  prefs: []
  type: TYPE_NORMAL
