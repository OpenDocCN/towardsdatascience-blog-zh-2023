- en: Can AI Really Help You at Passing Interviews?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/can-ai-really-help-you-at-passing-interviews-22bce4a57a2](https://towardsdatascience.com/can-ai-really-help-you-at-passing-interviews-22bce4a57a2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Thoughts, tips, and some prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://danielrizea.medium.com/?source=post_page-----22bce4a57a2--------------------------------)[![Daniel
    Rizea](../Images/ed90eecc461af1aaee143f35c4e5eb7c.png)](https://danielrizea.medium.com/?source=post_page-----22bce4a57a2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----22bce4a57a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----22bce4a57a2--------------------------------)
    [Daniel Rizea](https://danielrizea.medium.com/?source=post_page-----22bce4a57a2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----22bce4a57a2--------------------------------)
    ·9 min read·Aug 5, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5c3461e97a9cb1d2d871fb4e228e9b88.png)'
  prefs: []
  type: TYPE_IMG
- en: Andertoons image license
  prefs: []
  type: TYPE_NORMAL
- en: I have been hearing concerns lately from fellow interviewers that they are worried
    that candidates may leverage AI for passing technical interviews. The concern
    is that using LLM technology like ChatGPT or Bard, they may “game” the system
    and solve problems during technical interviews.
  prefs: []
  type: TYPE_NORMAL
- en: I think **you should make use of AI** for passing interviews, but **not** how
    you would initially expect.
  prefs: []
  type: TYPE_NORMAL
- en: The most important element for passing an interview is really preparing for
    it and the best way to prepare is to practice.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Some companies would charge thousands of dollars and would take candidates through
    mock interviews, giving them feedback and highlighting areas to improve. This
    creates a significant opportunity gap for people that can’t afford to pay for
    such services.
  prefs: []
  type: TYPE_NORMAL
- en: With the emergence of the new LLM technology, the question is if AI is leveling
    the playing field and if the tech can be used as a tutor for practicing mock interviews.
    First, let's dive into the wrong way of leveraging AI.
  prefs: []
  type: TYPE_NORMAL
- en: '**The wrong way**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s first try to address this valid concern. Should you be using an LLM service
    (could be ChatGPT, Bard — you name it) to try to get the answers to technical
    questions while in the interview? The tech works, but the real question is should
    you, as a candidate, really use it that way?
  prefs: []
  type: TYPE_NORMAL
- en: 'In my opinion, the answer is **no**. Doing this will hurt you both in the short
    and long run. Let’s go over some reasons for not doing it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**You will get caught**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Interviews are stressful, most likely the interviewer will catch on if you are
    split screening, trying to search for the answer and saying something you don’t
    fully understand.
  prefs: []
  type: TYPE_NORMAL
- en: I have been [holding over 1000 interviews](https://medium.com/entrepreneur-s-handbook/what-ive-learned-after-holding-one-thousand-interviews-234c79b77a89)
    throughout my career and I have had a few instances where candidates were trying
    to do a split-screen approach and were trying to search for the answer while talking
    to me. This was very obvious.
  prefs: []
  type: TYPE_NORMAL
- en: How would I know they were searching for answers? They would not pay attention
    to my hints, they would freeze and then suddenly start to speak from a different
    angle.
  prefs: []
  type: TYPE_NORMAL
- en: Interviews are very stressful. Adding more stress on top and worrying that you
    will get caught will lower your IQ considerably.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The most likely outcome is that you **will fail** the interview. I have seen
    this happen a couple of times. You may be very intelligent and hard-working, but
    the second you cheat, you will not be a cultural add to the team - any team.
  prefs: []
  type: TYPE_NORMAL
- en: '**Impossible to do in person**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before COVID, a lot of the interviews were in person. Big tech would fly you
    in for sessions of on-site interviews. With COVID this has changed a bit, but
    now with the return to office, more and more interviews will take place in person.
    At this point, if you were invited onsite, using LLMs for solving questions during
    the interview would be close to impossible.
  prefs: []
  type: TYPE_NORMAL
- en: '**Gaming the wrong angle**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even if you get away with it and get the job, most likely you will struggle
    in your new position. You could try to convince yourself that you just need to
    get in and then you will figure it all out along the way, but you will add a lot
    of stress on yourself knowing deep down that you cheated the interview.
  prefs: []
  type: TYPE_NORMAL
- en: It’s like starting a relationship with a lie - it most likely won’t end well.
  prefs: []
  type: TYPE_NORMAL
- en: '**A better way to leverage AI**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It looks like LLMs are very good at chat interactions, it’s in the name: large
    language models. You most likely have experimented with some version of ChatGPT
    or Bard. If not, I encourage you to give them a try.'
  prefs: []
  type: TYPE_NORMAL
- en: From the experiments that folks have been doing so far, it looks like LLMs could
    potentially be very good tutors given the correct way of prompting. Tutoring and
    getting access to services from specialized companies to mentor or coach you to
    learn the skills is pretty expensive, but now with AI things may become free.
  prefs: []
  type: TYPE_NORMAL
- en: Now you could use LLMs, the ChatGPTs, and Bards of today, to perfect your skills
    and get better at interviewing.
  prefs: []
  type: TYPE_NORMAL
- en: '**Some Tips and Tricks from the AI Industry**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With LLMs a new “discipline” has risen, the so-called *prompt engineering* which
    is a clever name for “be clear what you ask your AI LLM model to provide” so you
    get the answer you need.
  prefs: []
  type: TYPE_NORMAL
- en: There are some gotchas in the industry so far regarding prompt engineering that
    you may leverage to get better results. Yes, AI can hallucinate, another clever
    term for going off the rails and giving wrong answers. Here is where good prompt
    engineering comes into play to reduce the chances of hallucination. I will try
    to quote different literature so you see I am not making this stuff up and can
    dig deeper on your own, otherwise, you could just use the prompts.
  prefs: []
  type: TYPE_NORMAL
- en: '**Context, context, context**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may have heard this a million times, but context matters. It is the same
    with LLMs. The better you set the context for the LLM engine the better answers
    you will get.
  prefs: []
  type: TYPE_NORMAL
- en: '**The step-by-step approach is better**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The same applies to interviewing. An interviewer would like to see the steps
    you have taken to reach a specific result. If you ask in your prompt to produce
    a step-by-step answer you will have a better chance the model does not hallucinate
    and you will get more accurate results.
  prefs: []
  type: TYPE_NORMAL
- en: This is also known in the industry as [Chain-of-Thought Reasoning](https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html\)
    (zero-shot CoT). You can achieve this by appending a *“let’s think step by step”*
    towards the end of your prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '**LLMs are good at checking themselves**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For some reason, even if an LLM hallucinates and you ask the model if the answer
    was correct given your initial question, it will usually know it was [wrong and
    give you the correct answer](https://arxiv.org/abs/2212.09561). If they are good
    at checking their answer, they are also **good at checking your answer**.
  prefs: []
  type: TYPE_NORMAL
- en: '**LLMs are not good at math**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs [don’t do well on basic arithmetics](https://www.marktechpost.com/2023/03/12/microsoft-proposes-mathprompter-a-technique-that-improves-large-language-models-llms-performance-on-mathematical-reasoning-problems/)
    so try to avoid those subjects.
  prefs: []
  type: TYPE_NORMAL
- en: This should be fine unless you want to pass an interview for calculus and basic
    arithmetics.
  prefs: []
  type: TYPE_NORMAL
- en: But enough with all of these technicalities, let’s see how you could put it
    to use and incorporate some of the previous industry learnings. Feel free to experiment
    with your text prompts.
  prefs: []
  type: TYPE_NORMAL
- en: '**Mock interview script & applied prompt tips**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a look at how you could turn your LLM chatbot partner into an interviewer
    that will take you through a mock demonstration. Below is a breakdown of the main
    sections during a mock interview.
  prefs: []
  type: TYPE_NORMAL
- en: Small talk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is to put the candidate at ease and describe the process. We don’t need
    any prompt here or you could have a friendly chat with your LLM about the weather,
    your choice.
  prefs: []
  type: TYPE_NORMAL
- en: No prompt for now.
  prefs: []
  type: TYPE_NORMAL
- en: Present the problem to the candidate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here we can use the following prompt to generate some potential interview problems
    for an interview in Java:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'ChatGPT example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b975bf9132bdc43a7a62db3390bc49e7.png)'
  prefs: []
  type: TYPE_IMG
- en: image made by the author
  prefs: []
  type: TYPE_NORMAL
- en: Don’t forget, giving context helps. Usually, problems fall into the algorithmic
    or system design phase, you could choose which type you train for by changing
    the terms in the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Now you can choose your problem, let’s say we go for the *Palindrome algorithmic
    problem.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'ChatGPT example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d57f25f477946c04d98f36d8f9008f6a.png)'
  prefs: []
  type: TYPE_IMG
- en: image made by the author
  prefs: []
  type: TYPE_NORMAL
- en: Work with the candidate on a solution as in the interview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here you need to open a Google doc (most likely in the remote interview you
    will have a shared medium with your interviewer for writing your solutions.) You
    can start drafting your solution and code and think out loud, like in an interview.
  prefs: []
  type: TYPE_NORMAL
- en: If you need more hints you can ask for them
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Times up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When time expires, assess the solution and give candidates valuable feedback.
    After you have arrived at a solution that you think works, check if it is a valid
    one. Copy and paste the code in the LLM prompt after the following prompt. Don’t
    forget to apply the previous tricks and ask for a step-by-step analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the following solution to the problem, where we **intentionally add
    2 mistakes** to see if the engine catches it:'
  prefs: []
  type: TYPE_NORMAL
- en: changing the correct = *length(cleanedInput) -1* to *length(cleanedInput) -2*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing the correct right — to right ++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70fbff4cba46f36c803c97ca632fe810.png)'
  prefs: []
  type: TYPE_IMG
- en: image made by the author
  prefs: []
  type: TYPE_NORMAL
- en: It is nice we also got some pointers on the mistakes we made.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, a way to reduce the chance of LLM hallucination is to leverage the
    step-by-step approach or the CoT by asking for a step-by-step analysis.
  prefs: []
  type: TYPE_NORMAL
- en: After learning from the Palindrome example you could move on to another question.
  prefs: []
  type: TYPE_NORMAL
- en: You could also have the LLM check the answer previously provided, just to make
    sure it was a correct assessment and to go through it step by step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Limitations for LLMs and mock interviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even with applying the tips and tricks presented, LLMs may still hallucinate
    and say that a wrong solution looks good. The best thing is to fact-check them.
    Take the code and run it in a simulator to see if it outputs the right answers.
  prefs: []
  type: TYPE_NORMAL
- en: One way you can use LLMs without the fear of them giving wrong answers is by
    coming up with questions asked in interviews. This will be a good starting point,
    you can then either use the LLM model to solve the question and fact-check it
    against running the actual code or search for the solution online after you have
    solved it.
  prefs: []
  type: TYPE_NORMAL
- en: Tools that may help
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you don’t want to experiment with the LLM chat engines yourself, you can
    leverage pre-existing tools that **use voice and chat** and that can get you more
    comfortable with interviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'Google has something cool for interview prep: [interview-warmup](https://grow.google/certificates/interview-warmup/)'
  prefs: []
  type: TYPE_NORMAL
- en: Use AI for learning, not for “gaming”
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The purpose of an interview is to assess if you have the necessary skills and
    if you are a cultural match for the company. Gaming the system will not make you
    a cultural fit with many companies out there and most likely will not land you
    the job.
  prefs: []
  type: TYPE_NORMAL
- en: What you could do is leverage AI in getting a competitive advantage by learning
    faster, smarter, and preparing for interviews. This way you will increase your
    value, and you will be able to pass any interview and get the position you would
    like.
  prefs: []
  type: TYPE_NORMAL
