["```py\nimport numpy as np\nfrom scipy.stats import ttest_1samp\nimport random\n\nrandom.seed(10)\n\ndef calculate_empirical_size(num_simulations: int, sample_size: int, true_mean: float, significance_level: float) -> float:\n    \"\"\"\n    Simulates a set of samples and conducts a hypothesis test on each, then calculates the empirical size.\n\n    Parameters:\n    num_simulations (int): The number of simulations to run.\n    sample_size (int): The size of each simulated sample.\n    true_mean (float): The true mean under the null hypothesis.\n    significance_level (float): The significance level for the hypothesis tests.\n\n    Returns:\n    float: The empirical size, or the proportion of tests where the null hypothesis was rejected.\n    \"\"\"\n    import numpy as np\n    from scipy.stats import ttest_1samp\n\n    # Initialize counter for null hypothesis rejections\n    rejections = 0\n\n    # Run simulations\n    np.random.seed(0)  # for reproducibility\n    for _ in range(num_simulations):\n        sample = np.random.normal(loc=true_mean, scale=1, size=sample_size)\n        t_stat, p_value = ttest_1samp(sample, popmean=true_mean)\n        if p_value < significance_level:\n            rejections += 1\n\n    # Calculate empirical size\n    empirical_size = rejections / num_simulations\n\n    return empirical_size\n\ncalculate_empirical_size(1000, 1000, 0, 0.05)\n```", "```py\nimport numpy as np\nimport random\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\nimport statsmodels.api as sm\n\ndef fn_variance(data: list, ddof: int = 0) -> float:\n    \"\"\"\n    Calculate the variance of a given list of data.\n\n    Parameters:\n    data (list): The list of data to calculate the variance for.\n    ddof (int): Delta Degrees of Freedom. The divisor used in calculations is N - ddof. Default is 0.\n\n    Returns:\n    float: The variance of the data.\n    \"\"\"\n    n = len(data)\n    mean = sum(data) / n\n    return sum((x - mean) ** 2 for x in data) / (n - ddof)\n\ndef fn_generate_cov(dim: int, corr: float) -> np.ndarray:\n    \"\"\"\n    Generate a covariance matrix of a given dimension with a specified correlation.\n\n    Parameters:\n    dim (int): The dimension of the covariance matrix.\n    corr (float): The correlation value for the off-diagonal entries.\n\n    Returns:\n    np.ndarray: The generated covariance matrix.\n    \"\"\"\n    acc = []\n    for i in range(dim):\n        row = np.ones((1, dim)) * corr\n        row[0][i] = 1\n        acc.append(row)\n    return np.concatenate(acc, axis=0)\n\ndef fn_generate_multnorm(nobs: int, corr: float, nvar: int) -> np.ndarray:\n    \"\"\"\n    Generate a multivariate normal distribution.\n\n    Parameters:\n    nobs (int): The number of observations in the distribution.\n    corr (float): The correlation coefficient.\n    nvar (int): The number of variables in the distribution.\n\n    Returns:\n    np.ndarray: The generated multivariate normal distribution.\n    \"\"\"\n    mu = np.zeros(nvar)\n    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n    # generate random normal distribution\n    acc = []\n    for i in range(nvar):\n        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n\n    normvars = np.concatenate(acc,axis=1)\n\n    cov = fn_generate_cov(nvar,corr)\n    C = np.linalg.cholesky(cov)\n\n    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n\n    return Y\n\ndef fn_randomize_treatment(N: int, p: float = 0.5) -> np.ndarray:\n    \"\"\"\n    Randomize the treatment assignment for a population.\n\n    Parameters:\n    N (int): The total population size.\n    p (float): The proportion of the population to be treated. Defaults to 0.5.\n\n    Returns:\n    np.ndarray: A binary array where 1 indicates treatment and 0 indicates control.\n    \"\"\"\n    treated = random.sample(range(N), round(N*p))\n    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n\ndef split_columns(X: np.ndarray, a: float, b: float, p0: int) -> np.ndarray:\n    \"\"\"\n    Splits the input array into two sections based on given percentages.\n\n    Parameters:\n    X (np.ndarray): The input array of size (n, p).\n    a (float): The percentage of the first p0 columns to keep (between 0 and 1).\n    b (float): The percentage of the remaining columns to keep (between 0 and 1).\n    p0 (int): The index up to which to apply the first percentage.\n\n    Returns:\n    np.ndarray: The output array containing a% of the first p0 columns and b% of the remaining columns.\n    \"\"\"\n    if not (0 <= a <= 1 and 0 <= b <= 1):\n        raise ValueError(\"a and b must be between 0 and 1.\")\n    if not (0 <= p0 <= X.shape[1]):\n        raise ValueError(\"p0 must be between 0 and number of columns in X.\")\n\n    first_part = X[:, :p0]\n    second_part = X[:, p0:]\n\n    first_indices = np.random.choice(first_part.shape[1], int(a * first_part.shape[1]), replace=False)\n    second_indices = np.random.choice(second_part.shape[1], int(b * second_part.shape[1]), replace=False)\n\n    return np.concatenate((first_part[:, first_indices], second_part[:, second_indices]), axis=1)\n\ndef fn_generate_data(tau: float, N: int, p: int, p0: int, corr: float, flagX: bool = False):\n    \"\"\"\n    Generate synthetic data for experimentation.\n\n    Parameters:\n    tau (float): Treatment effect.\n    N (int): Number of observations.\n    p (int): Number of covariates.\n    p0 (int): Number of covariates with nonzero coefficients.\n    corr (float): Correlation for multivariate normal.\n    flagX (bool): If True, return covariates. Defaults to False.\n\n    Returns:\n    tuple: Depending on flagX, either returns (Yab,T) or (Yab,T,X).\n    \"\"\"\n\n    X = fn_generate_multnorm(N,corr,p)\n\n    T = fn_randomize_treatment(N) # choose treated units\n    err = np.random.normal(0,1,[N,1])\n    beta0 = np.random.normal(5,5,[p,1])\n\n    beta0[p0:p] = 0 #set the coefficient of all covariates after p0 to 0\n    Yab = tau*T+X@beta0+err\n    if flagX==False:\n        return (Yab,T)\n    else:\n        return (Yab,T,X)\n\ndef fn_tauhat_means(Yt: np.ndarray, Yc: np.ndarray) -> tuple:\n    \"\"\"\n    Calculate the treatment effect estimate and its standard error.\n\n    Parameters:\n    Yt (np.ndarray): Outcome for treated units.\n    Yc (np.ndarray): Outcome for control units.\n\n    Returns:\n    tuple: The treatment effect estimate and its standard error.\n    \"\"\"\n    nt = len(Yt)\n    nc = len(Yc)\n    tauhat = np.mean(Yt)-np.mean(Yc)\n    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n    return (tauhat,se_tauhat)\n\ndef fn_bias_rmse_size(theta0: float, thetahat: float, se_thetahat: float, cval: float = 1.96) -> tuple:\n    \"\"\"\n    Calculate bias, RMSE, and test size for the parameter estimate.\n\n    Parameters:\n    theta0 (float): The true parameter value.\n    thetahat (float): The estimated parameter value.\n    se_thetahat (float): The standard error of the estimated parameter value.\n    cval (float): The critical value for the hypothesis test. Defaults to 1.96.\n\n    Returns:\n    tuple: The bias, RMSE, and test size for the parameter estimate.\n    \"\"\"\n    b = thetahat - theta0\n    bias = np.mean(b)\n    rmse = np.sqrt(np.mean(b**2))\n    tval = b/se_thetahat\n    size = np.mean(1*(np.abs(tval)>cval))\n    # note size calculated at true parameter value\n    return (bias,rmse,size)\n\ndef fn_run_experiments(tau: float, Nrange: list, p: int, p0: int, corr: float, flagX: bool = False, a: float = None, b: float = None) -> tuple:\n    \"\"\"\n    Run experiments by generating synthetic data and estimate treatment effect.\n\n    Parameters:\n    tau (float): Treatment effect.\n    Nrange (list): Range of number of observations.\n    p (int): Total number of covariates.\n    p0 (int): Number of covariates with nonzero coefficients.\n    a (float, optional): Percentage of the first p0 columns to keep (between 0 and 1). Only used if flagX is True.\n    b (float, optional): Percentage of the remaining columns to keep (between 0 and 1). Only used if flagX is True.\n    corr (float): Correlation for multivariate normal.\n    flagX (bool): If True, return covariates. Defaults to False.\n\n    Returns:\n    tuple: The treatment effect estimates and their standard errors, and 95% confidence interval.\n\n    Note:\n    In the flagX == 2 case, the function uses the split_columns function to select a% of the first p0 columns \n    and b% of the remaining columns from the X data, before performing the regression and estimating the treatment effect.\n    \"\"\"\n    n_values = []\n    tauhats = []\n    sehats = []\n    lb = []\n    ub = []\n    for N in tqdm(Nrange):\n        n_values = n_values + [N]\n        if flagX==False:\n            Yexp,T = fn_generate_data(tau,N,p,p0,corr,flagX)\n            Yt = Yexp[np.where(T==1)[0],:]\n            Yc = Yexp[np.where(T==0)[0],:]\n            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n        elif flagX==1:\n            # use the correct covariates in regression\n            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,flagX)\n            covars = np.concatenate([T,X],axis = 1)\n            mod = sm.OLS(Yexp,covars)\n            res = mod.fit()\n            tauhat = res.params[0]\n            se_tauhat = res.HC1_se[0]\n        elif flagX==2:\n            # use fraction a of the correct covariates and fraction b of the remaining covariates\n            assert a is not None and b is not None, \"Please provide valid 'a' and 'b' when flagX is 2\"\n\n            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,flagX)\n\n            Xreg = split_columns(X,a,b,p0)\n\n            covars = np.concatenate([T,Xreg],axis = 1)\n            mod = sm.OLS(Yexp,covars)\n            res = mod.fit()\n            tauhat = res.params[0]\n            se_tauhat = res.HC1_se[0]\n\n        tauhats = tauhats + [tauhat]\n        sehats = sehats + [se_tauhat]    \n        lb = lb + [tauhat-1.96*se_tauhat]\n        ub = ub + [tauhat+1.96*se_tauhat]\n\n    return (n_values,tauhats,sehats,lb,ub)\n\ndef fn_plot_with_ci(n_values: list, tauhats: list, tau: float, lb: list, ub: list, caption: str):\n    \"\"\"\n    Plot the treatment effect estimates and their 95% confidence intervals.\n\n    Parameters:\n    n_values (list): List of number of observations.\n    tauhats (list): List of treatment effect estimates.\n    tau (float): True treatment effect.\n    lb (list): List of lower bounds of the confidence intervals.\n    ub (list): List of upper bounds of the confidence intervals.\n    caption (str): Title for the plot.\n    \"\"\"\n    fig = plt.figure(figsize = (10,6))\n    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n    plt.xlabel('N')\n    plt.ylabel('$\\hat{\\\\tau}$')\n    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n                label='True $\\\\tau$={}'.format(tau))\n    plt.title('{}'.format(caption))\n    plt.fill_between(n_values, lb, ub,\n        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n    plt.legend()\n```", "```py\ntau = 2\ncorr = .5\np = 10\np0 = 0 # number of covariates used in the DGP\nNrange = range(10,1000,2) # loop over N values\n(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr)\n\ncaption = \"\"\"Estimates of the treatment effect parameter \n    for a randomized experiment without covariates\"\"\"\nfn_plot_with_ci(nvalues,tauhats,tau,lb,ub,caption)\n```", "```py\nN = 100\nYexp,T = fn_generate_data(tau,N,10,0,corr)\nYt = Yexp[np.where(T==1)[0],:]\nYc = Yexp[np.where(T==0)[0],:]\ntauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n# n_values = n_values + [N]\n# tauhats = tauhats + [tauhat]\nlb = lb + [tauhat-1.96*se_tauhat]\nub = ub + [tauhat+1.96*se_tauhat]\n\nprint(f\"Parameter estimate and stadard error obtained by calculating the difference in means:{tauhat:.5f},{se_tauhat:.5f}\")\n\nconst = np.ones([N,1])\n\nmodel = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\nres = model.fit()\n\nprint(f\"Parameter estimate and stadard error obtained by running an OLS regression with an intercept:{res.params[0]:.5f},{ res.HC1_se[0]:.5f}\")\n```", "```py\nParameter estimate and stadard error obtained by calculating the difference in means:1.91756,0.21187\nParameter estimate and stadard error obtained by running an OLS regression with an intercept:1.91756,0.21187\n```", "```py\nestDict = {}\nR = 2000\nfor N in [10,50,100,500,1000]:\n    tauhats = []\n    sehats = []\n    for r in tqdm(range(R)):\n        Yexp,T = fn_generate_data(tau,N,10,0,corr)\n        Yt = Yexp[np.where(T==1)[0],:]\n        Yc = Yexp[np.where(T==0)[0],:]\n        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n        tauhats = tauhats + [tauhat]\n        sehats = sehats + [se_tauhat]\n    estDict[N] = {\n        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n        'sehat':np.array(sehats).reshape([len(sehats),1])\n    }\n\ntau0 = tau*np.ones([R,1])\nfor N, results in estDict.items():\n    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n                                         results['sehat'])\n    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n```", "```py\n100%|██████████| 2000/2000 [00:00<00:00, 3182.81it/s]\n100%|██████████| 2000/2000 [00:00<00:00, 2729.99it/s]\n100%|██████████| 2000/2000 [00:00<00:00, 2238.62it/s]\n100%|██████████| 2000/2000 [00:04<00:00, 479.67it/s]\n100%|██████████| 2000/2000 [02:16<00:00, 14.67it/s]\nN=10: bias=0.038139125088721144, RMSE=0.6593256331782233, size=0.084\nN=50: bias=0.002694446014687934, RMSE=0.29664599979723183, size=0.0635\nN=100: bias=-0.0006785229668018156, RMSE=0.20246779253127453, size=0.0615\nN=500: bias=-0.0009696751953095926, RMSE=0.08985542730497854, size=0.062\nN=1000: bias=-0.0011137216061364087, RMSE=0.06156258265280801, size=0.047\n```", "```py\ntau = 2\ncorr = .5\np = 100\np0 = 50 # number of covariates used in the DGP\nNrange = range(10,1000,2) # loop over N values\n(nvalues_x,tauhats_x,sehats_x,lb_x,ub_x) = fn_run_experiments(tau,Nrange,p,p0,corr)\n\ncaption = \"\"\"Estimates of the treatment effect parameter \nfor a randomized experiment with X's in the DGP but no X's included in the estimator\"\"\"\nfn_plot_with_ci(nvalues_x,tauhats_x,tau,lb_x,ub_x,caption)\n\n# rerun experiment with no covariates\np0 = 0 # number of covariates used in the DGP\nNrange = range(10,1000,2) # loop over N values\n(nvalues_x0,tauhats_x0,sehats_x0,lb_x0,ub_x0) = fn_run_experiments(tau,Nrange,p,p0,corr)\n\nfig = plt.figure(figsize = (10,6))\nplt.title(\"\"\"Estimates of the treatment effect parameter \nfor a randomized experiment with X's in the DGP but no X's included in the estimator, zoom in for large N\"\"\")\nplt.plot(nvalues_x[400:],tauhats_x[400:],label = '$\\hat{\\\\tau}^{(x)}$')\nplt.plot(nvalues_x[400:],tauhats_x0[400:],label = '$\\hat{\\\\tau}$',color = 'green')\nplt.legend()\n\nfig = plt.figure(figsize = (10,6))\nplt.title(\"\"\"\nTreatment effect estimates from DGP with and without covariates, zoom in for large N\n\"\"\")\nplt.plot(nvalues_x[400:],tauhats_x[400:],label = '$\\hat{\\\\tau}^{(x)}$')\nplt.plot(nvalues_x[400:],tauhats_x0[400:],label = '$\\hat{\\\\tau}$',color = 'green')\nplt.legend()\n```", "```py\n100%|██████████| 495/495 [00:41<00:00, 12.06it/s]\n100%|██████████| 495/495 [00:42<00:00, 11.70it/s]\n```", "```py\ntau = 2\ncorr = .5\np = 100\np0 = 50 # number of covariates used in the DGP\nNrange = range(1000,50000,10000) # loop over N values\n(nvalues_x2,tauhats_x2,sehats_x2,lb_x2,ub_x2) = fn_run_experiments(tau,Nrange,p,p0,corr)\n\nfn_plot_with_ci(nvalues_x2,tauhats_x2,tau,lb_x2,ub_x2,caption)\n```", "```py\ntau = 2\ncorr = .5\np = 100\np0 = 50 # number of covariates used in the DGP\nNrange = range(100,1000,2) # loop over N values\n# we need to start with more observations than p\nflagX = 1\n(nvalues2,tauhats2,sehats2,lb2,ub2) = fn_run_experiments(tau,Nrange,p,p0,corr,flagX)\n\ncaption = \"\"\"Estimates of the treatment effect parameter \nfor a randomized experiment with X's in the DGP, \nestimates obtained using regression with the right Xs\"\"\"\nfn_plot_with_ci(nvalues2,tauhats2,tau,lb2,ub2,caption)\n```", "```py\n# Use same DGP as before\ntau = 2\ncorr = .5\np = 100\np0 = 50 # number of covariates used in the DGP\na = 0.9\nb = 0.1\nNrange = range(100,1000,2) # loop over N values\n# we need to start with more observations than p\nflagX = 2\n(nvalues3,tauhats3,sehats3,lb3,ub3) = fn_run_experiments(tau,Nrange,p,p0,corr,flagX,a,b)\n\ncaption = f\"\"\"Estimates of the treatment effect parameter \nfor a randomized experiment with X's in the DGP, \nestimates obtained using regression with the {100*a:.1f}% of the correct Xs and {100*b:.1f}% of the irrelevant Xs\"\"\"\nfn_plot_with_ci(nvalues3,tauhats3,tau,lb3,ub3,caption)\n```"]