- en: Association Rule Mining in Unsupervised Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习中的关联规则挖掘
- en: 原文：[https://towardsdatascience.com/association-rule-mining-in-unsupervised-learning-df86170160de](https://towardsdatascience.com/association-rule-mining-in-unsupervised-learning-df86170160de)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/association-rule-mining-in-unsupervised-learning-df86170160de](https://towardsdatascience.com/association-rule-mining-in-unsupervised-learning-df86170160de)
- en: Pattern discovery terminologies and concepts in data mining
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据挖掘中的模式发现术语和概念
- en: '[](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)[](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)[](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)
    ·5 min read·Jan 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)
    ·5分钟阅读·2023年1月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a6785c84b324d9b94cdc3e0fc0f84db0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6785c84b324d9b94cdc3e0fc0f84db0.png)'
- en: Photo by [Kier... in Sight](https://unsplash.com/@kierinsight?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kier... in Sight](https://unsplash.com/@kierinsight?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 的照片'
- en: Pattern discovery tries to uncover patterns in a massive dataset, which forms
    the foundation for many data mining tasks such as association, correlation, and
    causality analysis, cluster analysis, to name a few.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 模式发现试图揭示大数据集中的模式，这为许多数据挖掘任务奠定了基础，如关联分析、相关性分析和因果分析、聚类分析等。
- en: This article introduces common terminology in association rule mining, followed
    by association rule mining techniques for frequent patterns and sequential patterns.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了关联规则挖掘中的常见术语，并随后讲解了频繁模式和序列模式的关联规则挖掘技术。
- en: Table of Contents
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: '[Terminologies: Support, Confidence, Lift, Leverage, Conviction](https://medium.com/p/df86170160de/#2842)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[术语：支持度、置信度、提升度、杠杆度、确信度](https://medium.com/p/df86170160de/#2842)'
- en: '**Frequent Patterns**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**频繁模式**'
- en: '[Apriori Algorithm](https://medium.com/p/df86170160de/#035c)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apriori 算法](https://medium.com/p/df86170160de/#035c)'
- en: '[Equivalent Class Transformation (ECLAT)](https://medium.com/p/df86170160de/#5f42)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[等价类转换（ECLAT）](https://medium.com/p/df86170160de/#5f42)'
- en: '[Frequent Pattern Growth (FP-Growth)](https://medium.com/p/df86170160de/#a37a)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[频繁模式增长（FP-Growth）](https://medium.com/p/df86170160de/#a37a)'
- en: Sequential Patterns
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 序列模式
- en: '[Generalized Sequential Patterns (GSP)](https://medium.com/p/df86170160de/#e8ad)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[广义序列模式（GSP）](https://medium.com/p/df86170160de/#e8ad)'
- en: '[Prefix-Projected Sequential Pattern Mining (PrefixSpan)](https://medium.com/p/df86170160de/#4226)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前缀投影序列模式挖掘（PrefixSpan）](https://medium.com/p/df86170160de/#4226)'
- en: Terminologies
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语
- en: '**Support**: The probability of item `X` appearing, denoted `P(X)`, measures
    the popularity of the item'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持度**：项`X`出现的概率，表示为`P(X)`，衡量项的受欢迎程度'
- en: '**Confidence**: Conditional probability of getting item `X` after getting item
    `Y`, denoted `P(X|Y)`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度**：在获取项`Y`后获取项`X`的条件概率，表示为`P(X|Y)`'
- en: '**Lift**: Confidence divided by support, denoted `P(X|Y)/P(X)`, measures the
    independence of items and how much ***more*** likely item `X` is going to be bought
    given that item `Y` is added to the cart'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提升度**：置信度除以支持度，表示为`P(X|Y)/P(X)`，衡量项的独立性以及在添加项`Y`到购物车后，项`X`被购买的可能性***更高***'
- en: '**Leverage**: Difference between support of both items and expected support
    if both items are independent, denoted `P(XUY)-P(X)P(Y)`, measures independence
    of items'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**杠杆度**：两项的支持度之差与两项独立时的预期支持度之差，表示为`P(XUY)-P(X)P(Y)`，衡量项的独立性'
- en: '**Conviction**: Support divided by confidence, denoted `(1-P(X))/(1-P(X|Y))`,
    measures independence of items and high conviction is a combination of strong
    confidence of `Y->X` and a low support of `X`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度**：支持度除以置信度，记作 `(1-P(X))/(1-P(X|Y))`，衡量项的独立性，高置信度是 `Y->X` 强置信度和 `X` 低支持度的组合。'
- en: Apriori Algorithm
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apriori 算法
- en: A horizontal breadth-first search algorithm
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 水平广度优先搜索算法
- en: The Apriori algorithm identifies association by specifying a **minimum confidence
    threshold**. The intuition for the association is how *confident* one is that
    a consequent item will be selected after an antecedent item is selected, denoted
    `P(consequent|antecedent)`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori 算法通过指定**最低置信度阈值**来识别关联。关联的直觉在于对一个后继项在一个前驱项被选择后被选择的*信心*，记作 `P(consequent|antecedent)`。
- en: '![](../Images/0a962143017ac934fd470d8abb84c798.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a962143017ac934fd470d8abb84c798.png)'
- en: 'Fig 1: Transaction data example — Image by author'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：事务数据示例 — 作者提供的图片
- en: For example in Fig 1, `Confidence(A->C) = P(C|A) = 0.75` since item `C` is bought
    following item `A` 3 out of 4 times. If this confidence is above the minimum confidence
    threshold (say 0.5), then an association of `A->C` can be drawn.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在图 1 中，`Confidence(A->C) = P(C|A) = 0.75`，因为项 `C` 在 `A` 后被购买的次数为 4 次中的 3
    次。如果此置信度高于最低置信度阈值（例如 0.5），则可以得出 `A->C` 的关联。
- en: Instead of computing confidence between every item set, a downward closure principle
    is applied to speed up the search for frequent item sets. The **downward closure
    principle** states that any subset of a frequent item set must be frequent, for
    example, if item set `A, B, C` is frequent, it must follow that the subset item
    set `A, B` is frequent as well.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用向下封闭原则来加速频繁项集的搜索，而不是计算每个项集之间的置信度。**向下封闭原则**指出，任何频繁项集的子集必须也是频繁的，例如，如果项集 `A,
    B, C` 是频繁的，则它的子集项集 `A, B` 也必须是频繁的。
- en: The drawback of the Apriori algorithm is that the data has to be repeatedly
    scanned to compute the support and confidence of every item or item set.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori 算法的缺点是必须反复扫描数据以计算每个项或项集的支持度和置信度。
- en: Equivalence CLAss Transformation (ECLAT)
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 等价类转换（ECLAT）
- en: A vertical depth-first search algorithm using set intersections
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用集合交集的垂直深度优先搜索算法
- en: In the Apriori algorithm, data is viewed as **horizontal transaction-level data**,
    where each transaction has one or more items. In ECLAT, data is transformed to
    **vertical item-level data** where each item has a set of transaction IDs where
    they appear (called the `TIDset`).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Apriori 算法中，数据被视为**水平事务级数据**，其中每个事务包含一个或多个项。在 ECLAT 中，数据被转换为**垂直项级数据**，每个项具有一个包含其出现的事务
    ID 的集合（称为 `TIDset`）。
- en: '![](../Images/d677c16990e0f52f5f618476fe4f6404.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d677c16990e0f52f5f618476fe4f6404.png)'
- en: 'Fig 2: Vertical item-level data example — Image by author'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：垂直项级数据示例 — 作者提供的图片
- en: Following the transaction data example in Fig 1, it can be rearranged to vertical
    item-level data as shown in Fig 2\. For example, item `B` appeared in transactions
    1, 2, and 3, and this will result in the `TIDset {1, 2, 3}`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图 1 中的事务数据示例，可以将其重新排列为垂直项级数据，如图 2 所示。例如，项 `B` 出现在事务 1、2 和 3 中，这将导致 `TIDset
    {1, 2, 3}`。
- en: Support and confidence calculation for items can then be done with just set
    intersections between `TIDset`. ECLAT algorithm is more memory efficient and computationally
    efficient than the Apriori algorithm as it uses depth-first search and does not
    scan the data multiple times to get support for every item.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 项的支持度和置信度计算可以通过 `TIDset` 之间的集合交集完成。ECLAT 算法比 Apriori 算法更节省内存和计算，因为它使用深度优先搜索，不需要多次扫描数据以获取每个项的支持度。
- en: Frequent Pattern Growth (FP-Growth)
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 频繁模式增长（FP-Growth）
- en: A vertical depth-first search algorithm using the Trie data structure
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用 Trie 数据结构的垂直深度优先搜索算法
- en: The intuition behind FP-Growth is to find frequent single items and partition
    the database based on each such item and recursively grow frequent patterns for
    each partitioned database. These are efficiently done with a Trie data structure
    (FP-tree).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: FP-Growth 的直觉是找到频繁单项，并根据每个这样的项对数据库进行分区，然后递归地为每个分区数据库增长频繁模式。这些操作通过 Trie 数据结构（FP-树）有效完成。
- en: The data is scanned twice — once to find single item frequent patterns that
    are above the minimum support and a second time to construct the FP-tree.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据被扫描两次 — 第一次是查找单项频繁模式（满足最低支持度），第二次是构建 FP-树。
- en: '![](../Images/76f8d9b7df9f3d72ebcf4667b41f0063.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76f8d9b7df9f3d72ebcf4667b41f0063.png)'
- en: 'Fig 3: Sample Trie data structure of frequent patterns — Image by author'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：频繁模式的样本Trie数据结构 — 图片来源于作者
- en: Following the transaction data example in Fig 1, an FP-tree can be created as
    shown in Fig 3\. Transactions 1 and 2 follow the path `A-B-C-D`, transaction 3
    follows path `A-B-D`, and transaction 4 follows path `A-C`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图 1 中的交易数据示例，可以创建如图 3 所示的FP树。交易 1 和 2 路径为 `A-B-C-D`，交易 3 路径为 `A-B-D`，交易 4
    路径为 `A-C`。
- en: '![](../Images/f59802a204b2fbef57e5d31da39ab4b1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f59802a204b2fbef57e5d31da39ab4b1.png)'
- en: 'Fig 4: Conditional pattern base — Image by author'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：条件模式基 — 图片来源于作者
- en: From this FP-tree, we can easily compute the conditional pattern base (Fig 4),
    such as item `C` appearing with `{A, B}` twice and `{A}` once — without scanning
    the data again.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个FP树中，我们可以轻松计算条件模式基（图 4），例如项 `C` 与 `{A, B}` 一起出现两次，与 `{A}` 一次 — 无需重新扫描数据。
- en: Generalized Sequential Patterns (GSP)
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广义序列模式（GSP）
- en: Apriori-based sequential pattern mining, breadth-first search
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于Apriori的序列模式挖掘，广度优先搜索
- en: GSP is similar to the Apriori algorithm, where data is first scanned for singleton
    sequences and filtered for frequent sequences. The data is then continuously scanned
    and filtered to retrieve longer sub-sequences. It is important to note that items
    do not have to be consecutive in sub-sequences, and a pattern can contain duplicated
    items.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: GSP与Apriori算法类似，其中数据首先扫描单项序列并筛选频繁序列。然后，数据会不断扫描和筛选以检索更长的子序列。需要注意的是，项在子序列中不必连续，模式可以包含重复的项。
- en: Other Apriori-based sequential pattern mining includes [Sequential Pattern Discovery
    using Equivalent Class (SPADE)](http://www.philippe-fournier-viger.com/spmf/SPADE.pdf)
    algorithm which is similar to the ECLAT algorithm.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其他基于Apriori的序列模式挖掘包括 [使用等效类的序列模式发现（SPADE）](http://www.philippe-fournier-viger.com/spmf/SPADE.pdf)算法，该算法类似于ECLAT算法。
- en: Prefix-Projected Sequential Pattern Mining (PrefixSpan)
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前缀投影序列模式挖掘（PrefixSpan）
- en: Pattern-growth-based sequential pattern mining, depth-first search
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于模式增长的序列模式挖掘，深度优先搜索
- en: PrefixSpan separates entries into prefixes and suffixes. Frequent prefixes are
    captured and the prefix’s projection becomes a suffix.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: PrefixSpan将条目分为前缀和后缀。捕获频繁的前缀，并将前缀的投影作为后缀。
- en: PrefixSpan scans the data once to find length-1 sequential patterns and extends
    frequent length-1 sequential patterns recursively. Extending is done by setting
    length-1 as the prefix and the remaining items that start with length-1 as the
    suffix (referred to as the projected database), and recursively increase the length
    of the prefix. The projected database will shrink after every iteration as the
    suffix decreases in length.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: PrefixSpan通过一次扫描数据来查找长度为1的序列模式，并递归扩展频繁的长度为1的序列模式。扩展是通过将长度为1的模式作为前缀，并将以长度为1的模式开头的其余项作为后缀（称为投影数据库）来完成的，并递归地增加前缀的长度。每次迭代后，投影数据库会缩小，因为后缀的长度减少。
- en: This algorithm is slow but optimization can be done with pseudo-projection to
    use pointers instead of physically copying the suffix.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法速度较慢，但可以通过伪投影优化，使用指针代替物理复制后缀。
- en: Other pattern-growth-based sequential pattern mining includes [Frequent Pattern-Projected
    Sequential Pattern Mining (FreeSpan)](https://www.researchgate.net/publication/221654035_FreeSpan_Frequent_pattern-projected_sequential_pattern_mining)
    which is not as efficient as PrefixSpan.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 其他基于模式增长的序列模式挖掘包括 [频繁模式投影序列模式挖掘（FreeSpan）](https://www.researchgate.net/publication/221654035_FreeSpan_Frequent_pattern-projected_sequential_pattern_mining)，其效率不如PrefixSpan。
- en: Compared to clustering, which is another topic under unsupervised learning,
    I feel that association rule mining is more statistically grounded, making it
    more challenging to understand. Nevertheless, hope this article provided a general
    introduction to a few popular association rule mining techniques!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 与聚类相比，聚类是另一种无监督学习的主题，我觉得关联规则挖掘在统计学上更有基础，使其更具挑战性。不过，希望这篇文章对一些流行的关联规则挖掘技术提供了一个概述！
- en: Related Links
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关链接
- en: 'Terminology Definition: [http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 术语定义： [http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/)
- en: Papers
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 论文
- en: 'Frequent Pattern: [ECLAT](https://www.researchgate.net/publication/303523871_ECLAT_Algorithm_for_Frequent_Item_sets_Generation),
    [FP-Growth](https://borgelt.net/papers/fpgrowth.pdf)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '频繁模式: [ECLAT](https://www.researchgate.net/publication/303523871_ECLAT_Algorithm_for_Frequent_Item_sets_Generation)、[FP-Growth](https://borgelt.net/papers/fpgrowth.pdf)'
- en: 'Sequential Pattern Apriori-based: [SPADE](http://www.philippe-fournier-viger.com/spmf/SPADE.pdf)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '基于Apriori的序列模式: [SPADE](http://www.philippe-fournier-viger.com/spmf/SPADE.pdf)'
- en: 'Sequential Pattern pattern-growth-based: [PrefixSpan](http://hanj.cs.illinois.edu/pdf/span01.pdf),
    [FreeSpan](https://www.researchgate.net/publication/221654035_FreeSpan_Frequent_pattern-projected_sequential_pattern_mining)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '基于模式增长的序列模式: [PrefixSpan](http://hanj.cs.illinois.edu/pdf/span01.pdf)、[FreeSpan](https://www.researchgate.net/publication/221654035_FreeSpan_Frequent_pattern-projected_sequential_pattern_mining)'
