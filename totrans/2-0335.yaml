- en: Association Rule Mining in Unsupervised Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/association-rule-mining-in-unsupervised-learning-df86170160de](https://towardsdatascience.com/association-rule-mining-in-unsupervised-learning-df86170160de)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pattern discovery terminologies and concepts in data mining
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)[](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page-----df86170160de--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----df86170160de--------------------------------)
    ·5 min read·Jan 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6785c84b324d9b94cdc3e0fc0f84db0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kier... in Sight](https://unsplash.com/@kierinsight?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Pattern discovery tries to uncover patterns in a massive dataset, which forms
    the foundation for many data mining tasks such as association, correlation, and
    causality analysis, cluster analysis, to name a few.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: This article introduces common terminology in association rule mining, followed
    by association rule mining techniques for frequent patterns and sequential patterns.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Terminologies: Support, Confidence, Lift, Leverage, Conviction](https://medium.com/p/df86170160de/#2842)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequent Patterns**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Apriori Algorithm](https://medium.com/p/df86170160de/#035c)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Equivalent Class Transformation (ECLAT)](https://medium.com/p/df86170160de/#5f42)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Frequent Pattern Growth (FP-Growth)](https://medium.com/p/df86170160de/#a37a)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequential Patterns
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Generalized Sequential Patterns (GSP)](https://medium.com/p/df86170160de/#e8ad)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Prefix-Projected Sequential Pattern Mining (PrefixSpan)](https://medium.com/p/df86170160de/#4226)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terminologies
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Support**: The probability of item `X` appearing, denoted `P(X)`, measures
    the popularity of the item'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Confidence**: Conditional probability of getting item `X` after getting item
    `Y`, denoted `P(X|Y)`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lift**: Confidence divided by support, denoted `P(X|Y)/P(X)`, measures the
    independence of items and how much ***more*** likely item `X` is going to be bought
    given that item `Y` is added to the cart'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leverage**: Difference between support of both items and expected support
    if both items are independent, denoted `P(XUY)-P(X)P(Y)`, measures independence
    of items'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conviction**: Support divided by confidence, denoted `(1-P(X))/(1-P(X|Y))`,
    measures independence of items and high conviction is a combination of strong
    confidence of `Y->X` and a low support of `X`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apriori Algorithm
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A horizontal breadth-first search algorithm
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The Apriori algorithm identifies association by specifying a **minimum confidence
    threshold**. The intuition for the association is how *confident* one is that
    a consequent item will be selected after an antecedent item is selected, denoted
    `P(consequent|antecedent)`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0a962143017ac934fd470d8abb84c798.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: 'Fig 1: Transaction data example — Image by author'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: For example in Fig 1, `Confidence(A->C) = P(C|A) = 0.75` since item `C` is bought
    following item `A` 3 out of 4 times. If this confidence is above the minimum confidence
    threshold (say 0.5), then an association of `A->C` can be drawn.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Instead of computing confidence between every item set, a downward closure principle
    is applied to speed up the search for frequent item sets. The **downward closure
    principle** states that any subset of a frequent item set must be frequent, for
    example, if item set `A, B, C` is frequent, it must follow that the subset item
    set `A, B` is frequent as well.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The drawback of the Apriori algorithm is that the data has to be repeatedly
    scanned to compute the support and confidence of every item or item set.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Equivalence CLAss Transformation (ECLAT)
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A vertical depth-first search algorithm using set intersections
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the Apriori algorithm, data is viewed as **horizontal transaction-level data**,
    where each transaction has one or more items. In ECLAT, data is transformed to
    **vertical item-level data** where each item has a set of transaction IDs where
    they appear (called the `TIDset`).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d677c16990e0f52f5f618476fe4f6404.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: 'Fig 2: Vertical item-level data example — Image by author'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Following the transaction data example in Fig 1, it can be rearranged to vertical
    item-level data as shown in Fig 2\. For example, item `B` appeared in transactions
    1, 2, and 3, and this will result in the `TIDset {1, 2, 3}`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Support and confidence calculation for items can then be done with just set
    intersections between `TIDset`. ECLAT algorithm is more memory efficient and computationally
    efficient than the Apriori algorithm as it uses depth-first search and does not
    scan the data multiple times to get support for every item.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Frequent Pattern Growth (FP-Growth)
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A vertical depth-first search algorithm using the Trie data structure
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The intuition behind FP-Growth is to find frequent single items and partition
    the database based on each such item and recursively grow frequent patterns for
    each partitioned database. These are efficiently done with a Trie data structure
    (FP-tree).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: The data is scanned twice — once to find single item frequent patterns that
    are above the minimum support and a second time to construct the FP-tree.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/76f8d9b7df9f3d72ebcf4667b41f0063.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: 'Fig 3: Sample Trie data structure of frequent patterns — Image by author'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Following the transaction data example in Fig 1, an FP-tree can be created as
    shown in Fig 3\. Transactions 1 and 2 follow the path `A-B-C-D`, transaction 3
    follows path `A-B-D`, and transaction 4 follows path `A-C`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f59802a204b2fbef57e5d31da39ab4b1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: 'Fig 4: Conditional pattern base — Image by author'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: From this FP-tree, we can easily compute the conditional pattern base (Fig 4),
    such as item `C` appearing with `{A, B}` twice and `{A}` once — without scanning
    the data again.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Generalized Sequential Patterns (GSP)
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apriori-based sequential pattern mining, breadth-first search
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: GSP is similar to the Apriori algorithm, where data is first scanned for singleton
    sequences and filtered for frequent sequences. The data is then continuously scanned
    and filtered to retrieve longer sub-sequences. It is important to note that items
    do not have to be consecutive in sub-sequences, and a pattern can contain duplicated
    items.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Other Apriori-based sequential pattern mining includes [Sequential Pattern Discovery
    using Equivalent Class (SPADE)](http://www.philippe-fournier-viger.com/spmf/SPADE.pdf)
    algorithm which is similar to the ECLAT algorithm.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Prefix-Projected Sequential Pattern Mining (PrefixSpan)
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pattern-growth-based sequential pattern mining, depth-first search
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PrefixSpan separates entries into prefixes and suffixes. Frequent prefixes are
    captured and the prefix’s projection becomes a suffix.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: PrefixSpan scans the data once to find length-1 sequential patterns and extends
    frequent length-1 sequential patterns recursively. Extending is done by setting
    length-1 as the prefix and the remaining items that start with length-1 as the
    suffix (referred to as the projected database), and recursively increase the length
    of the prefix. The projected database will shrink after every iteration as the
    suffix decreases in length.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm is slow but optimization can be done with pseudo-projection to
    use pointers instead of physically copying the suffix.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Other pattern-growth-based sequential pattern mining includes [Frequent Pattern-Projected
    Sequential Pattern Mining (FreeSpan)](https://www.researchgate.net/publication/221654035_FreeSpan_Frequent_pattern-projected_sequential_pattern_mining)
    which is not as efficient as PrefixSpan.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Compared to clustering, which is another topic under unsupervised learning,
    I feel that association rule mining is more statistically grounded, making it
    more challenging to understand. Nevertheless, hope this article provided a general
    introduction to a few popular association rule mining techniques!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Related Links
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Terminology Definition: [http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Papers
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Frequent Pattern: [ECLAT](https://www.researchgate.net/publication/303523871_ECLAT_Algorithm_for_Frequent_Item_sets_Generation),
    [FP-Growth](https://borgelt.net/papers/fpgrowth.pdf)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '频繁模式: [ECLAT](https://www.researchgate.net/publication/303523871_ECLAT_Algorithm_for_Frequent_Item_sets_Generation)、[FP-Growth](https://borgelt.net/papers/fpgrowth.pdf)'
- en: 'Sequential Pattern Apriori-based: [SPADE](http://www.philippe-fournier-viger.com/spmf/SPADE.pdf)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '基于Apriori的序列模式: [SPADE](http://www.philippe-fournier-viger.com/spmf/SPADE.pdf)'
- en: 'Sequential Pattern pattern-growth-based: [PrefixSpan](http://hanj.cs.illinois.edu/pdf/span01.pdf),
    [FreeSpan](https://www.researchgate.net/publication/221654035_FreeSpan_Frequent_pattern-projected_sequential_pattern_mining)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '基于模式增长的序列模式: [PrefixSpan](http://hanj.cs.illinois.edu/pdf/span01.pdf)、[FreeSpan](https://www.researchgate.net/publication/221654035_FreeSpan_Frequent_pattern-projected_sequential_pattern_mining)'
