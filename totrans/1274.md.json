["```py\n [What's in this guide?](#e8eb)\n\nðŸ’¡ [Why should you care about Prompt Engineering?](#e1ad)\nðŸ’¡ [Why prompt is engineering harder than you think?](#b86b)\nðŸ’¡ [You don't need prompt ideas, you need problems](#1c81)\nðŸ’¡ [Watch out for AI hallucinations](#e43b)\n\nðŸŸ¢ [The Basics of Prompting](#29a6) \nðŸŸ¢ [Specify the context (also called \"Priming\")](#09e7)\nðŸŸ¢ [Specify the desired format](#7ae8)\nðŸŸ¢ [Use <placeholders>](#d894)\n  âˆ˜ [How to use placeholders as parameters](#60f0)\n  âˆ˜ [How to use placeholders as instructions](#8a57)\nðŸŸ¢ [Specify the style/tone](#5746)\nðŸŸ¢ [Specify the length of the desired response](#9bd9)\nðŸŸ¢ [Specify the target audience](#2395)\nðŸŸ¢ [Many-Examples Prompting](#2b49)\nðŸŸ¢ [Temperature Control](#6bf4)\nðŸŸ¢ [Zero-Shot Prompting (no examples)](#82e5)\nðŸŸ¢ [Few-Shot Prompting (several high-quality examples)](#58be)\nðŸŸ¢ [Zero-Shot/Few-Shot - The simple version](#52e9)\n\nðŸ’¡ [In-context Learning vs. Chat History](#f98f)\n\nðŸŸ¡ [Chain of Thought Prompting\n](#670c)  âˆ˜ [Zero-Shot Chain of Thought](#890f)\n  âˆ˜ [Few-Shot Chain of Thought](#edda)\nðŸŸ¢ [Role Prompting](#0532)\nðŸŸ¢ [Knowledge Generation Prompting](#5e4e)\n  âˆ˜ [Knowledge Generation Prompting and ChatGPT Plugins](#59d7)\nðŸŸ  [Knowledge Integration Prompting*](#963a) \n  âˆ˜ [Knowledge Integration* and Microsoft Edge](#7c06)\nðŸŸ  [Directional Stimulus (DS) Prompting](#a93a) \nðŸŸ¡ [Recursive Criticism and Improvement (RCI) Prompting](#a121)\nðŸŸ¡ [Self-Refinement Prompting](#8cb4)\nðŸŸ¡ [Reverse Prompt Engineering](#9f72)\nðŸŸ¡ [Prompt Revision](#ccbc)\nðŸŸ¡ [Program Simulation Prompting](#63cd)\nðŸŸ  [All-In-One (AIO) Prompting*](#10b1)\nðŸŸ¢ [Template for All-In-One (AIO) Prompting](#491a)\nðŸŸ¢ [More examples of All-In-One Prompting*](#7552)\n  âˆ˜ [Dolores, the Email Muse](#c717)\n  âˆ˜ [Robert Ford, the Coding Master](#7e0b)\n  âˆ˜ [Lee Sizemore, the Outlandish Chef](#6289)\n  âˆ˜ [Maeve the Mastermind](#5dd0)\n\nðŸ’¡ [Iterate until you have to revert](#6a23)\nðŸ’¡ [With great powerâ€¦](#13d0)\n\n[Conclusion](#63a9)\n\n[References (in no particular order)](#b564)\n\n[Contact section](#93f0)\n```", "```py\n**[Title of the prompt]** \n\n**Prompt content:** Content of the prompt that sometimes includes <placeholders>.\n<placeholders> are a tool you use to make better prompt templates.\n\n(Comments that are not part of the prompt are written between parenthesis like this) \n\n## (The two hashtags separate the same prompt into two or more sections)\n\n--- (The three dashes separate examples inside the same prompt)\n\n*** (The three stars separate two different prompts or two different outputs)\n\n*** ChatGPT's output**: (When it's relevant, you'll see the response to ChatGPT written like this)\n```", "```py\n**[Examples of a simple prompts]** \n\n**Prompt example #1:** Act as an independant analyst who specializes in <field_1> and <field_2>.\nSearch the internet for the pros and cons of soy milk.\n\nUse 5 bullet points for pros and 5 bullet points for cons.\nBrowse at least 6 different sources and cite each one of them in your analysis.\n\n##\n\n<field_1>: Food industry\n<field_2>: Nutrition\n\n***\n\n**Prompt example #2:** Explain the five love languages as if you're talking to a 16-year-old.\n\n##\n\n**Desired format:**\nIntroduction.\n- Love language #1: explanation and example.\n- Love language #2: explanation and example.\n- Love language #3: explanation and example.\n- Love language #4: explanation and example.\n- Love language #5: explanation and example.\nConclusion.\n```", "```py\n[The Basics of Prompting] \n\n**Bad prompt:** Summarize this text please. [Paste text here].\n\n***\n\n**Better prompt:** I will give you a report titled <title_of_the_report> as input. Please access the report through the following link <URL_of_the_report> using the online browsing feature. Summarize the report in less than <summary_wordcount> and add <number_of_quotes> from the authors. Make sure to pick precise quotes and list them as bullet points.\n\n<title_of_the_report> = Walking for good health.\n<URL_of_the_report> = https://www.betterhealth.vic.gov.au/health/healthyliving/walking-for-good-health\n<summary_wordcount> = 250\n<number_of_quotes> = 3\n\n##\n\nDesired format:\n\nTitle: <title_of_the_report> \nLink: <URL_of_the_report>\n\nSummary of the report based on the previous instructions.\n\n- Quote #1\n- Quote #2\n- Quote #3\n- etc.\n```", "```py\n**[Specify the context]\n\nExample #1:** I invited a Jewish/Muslim/Buddhist friend over for a week. Please provide a complete meal plan for 7 days and consider my friend's diet restrictions.\n\n***\n\n**Example #2:** I work as a developer in a tech startup and I helped build two apps that allow users to collaborate on shared documents. Kindly provide me with 10 ways I can highlight my achievements as a developer. Use a bullet-point format.\n\n***\n\n**Example #3:** I'm from India/Kenya/Egypt, and English is my third language. I have a C2 level on paper and I want to improve my pronunciation. Can you please suggest 5 ways I can enhance my spoken English? Be specific and concise.\n```", "```py\n**[Specify the desired format]**\n\n**Example #1:** Kindly write a template of a technical resume for a Software Engineer who wants to pursue a career in Machine Learning.\n\n***\n\n**Example #2:** I'm a One Piece fan. Please help me write a script for an episode titled The Demon's Eye Finally Opens.\n\n***\n\n**Example #3:** Please summarize the following document in the form of a corporate memo.\n```", "```py\n**[Use placeholders as parameters]**\n\n**Context:** Use <placeholders> to write flexible prompts.\n\n**Prompt example #1:**\n\nAct like an expert developer in <name_of_the_input_programming_language> and <name_of_the_output_programming_language>. I will submit a few lines of <name_of_the_input_programming_language> in the chat, and you'll rewrite it in the <name_of_the_output_programming_language>.\nMake sure to use a temperature of <temperature_value>.\n\n##\n\n<name_of_the_input_programming_language> = Python.\n<name_of_the_output_programming_language> = JavaScript.\n<temperature_value> = 0.\n\n***\n\n**Prompt example #2:**\n\nAct like an expert developer in <name_of_the_input_programming_language> and <name_of_the_output_programming_language>. I will submit a few lines of <name_of_the_input_programming_language> in the chat, and you'll rewrite it in the <name_of_the_output_programming_language>.\nMake sure to use a temperature of <temperature_value>.\n\n##\n\n<name_of_the_input_programming_language> = PHP.\n<name_of_the_output_programming_language> = Python.\n<temperature_value> = 0.3.\n```", "```py\n**[Use placeholders as instructions]**\n **Context:** User Story generation for a Product Owner.\n **Prompt:**\n\nYou'll act as a Product Owner for an app that provides international shipment services for factories and retailers. I will give you a description of several features, and you'll kindly format them in the User Story format indicated below.\n\n- Modify an order within the 12 hours (fixed) that follow the submission.\n- Lockscreen notifications for every step of the shipment.\n- Summary of ongoing orders ranked by date, cost, country, and products.\n- A history log of past orders ranked by date, cost, country, and products.\n- Chatbot incon that opens a chat window inside the web page.\n- \"Call me\" button.\n\n##\n **Desired format:** \n/////// User Story #1: <name_of_user_story> ///////\n\nAs a <description_of_user>,\nI want <functionality>,\nSo that <benefit>.\n\nAcceptance criteria:\n\n#1 Given <precondition>\nWhen <action_taken>,\nThen <expected_result>.\n\n#2 Given <precondition>\nWhen <action_taken>,\nThen <expected_result>.\n\n#3 Given <precondition>\nWhen <action_taken>,\nThen <expected_result>.\n\n/////// End of User Story#1: <name_of_user_story> ///////\n\n---\n\n/////// User Story #2: <name_of_user_story> ///////\n\netc.\n\n##\n\n**Example of the desired output:** \n\n/////// User Story #1: Online Shopping Cart ///////\n\nAs a frequent online shopper,\nI want to be able to easily add items to my shopping cart,\nSo that I can efficiently complete my purchases.\n\nAcceptance criteria:\n\n#1 Given that I am on a product page,\nWhen I click the \"Add to Cart\" button,\nThen the selected item should be added to my shopping cart.\n\n#2 Given that I have multiple items in my shopping cart,\nWhen I view my shopping cart,\nThen I should see a list of all items in my cart along with their prices and quantities.\n\n#3 Given that I want to adjust the quantity of an item in my cart,\nWhen I update the quantity of the item and click \"Update Cart\",\nThen the quantity of the item should be updated and the total cost should reflect the change.\n\n#4 Given that I want to remove an item from my shopping cart,\nWhen I click the \"Remove\" button next to the item,\nThen the item should be removed from my cart and the total cost should be adjusted accordingly\n\n#5 Given that I want to apply a coupon code to my order, \nWhen I enter the code during checkout,\nThen the discount associated with the code should be applied to my order. notes.\n\n/////// End of User Story#1: Online Shopping Cart ///////\n\n---\n\n/////// User Story #2: ..... ///////\n\netc.\n```", "```py\n**[Specify the style/tone]**\n\n**Prompt example #1:** In the style of a philosophy dissertation, explain how the finite interval between 0 and 1 can encompass an infinite amount of real numbers.\n\n***\n\n**Prompt example #2:** In the style of a New York Times op-ed, write a 1000-word article about the importance of dialogue.\n\n***\n **Prompt example #3:** Write a mini-guide about the importance of pre-processing data in Machine Learning. Use the tone of Jessie Pinkman from Breaking Bad.\n```", "```py\n**[Specify the length of the desired response]**\n\n**Prompt example #1:** In less than 280 characters, please explain String Theory.\n\n***\n\n**Prompt example #2:** Kindly write a Linkedin post where you make a case for why technology is at its best when it's invisible.\n\n***\n\n**Prompt example #3:** Please write five titles about the lack of skin in the game in Pascal's wager.\n```", "```py\n**[Specify the target audience]**\n\n**Prompt that targets general adult readers:** Please explain the benefits of regular exercise in a way that is easy to understand for the general public.\n\n***\n\n**Prompt that targets medical professionals:** Please write a scientific article that targets medical professionals. The article discusses the physiological and psychological benefits of regular exercise. Make sure the article responds to the expectations of an audience of medical professionals.\n```", "```py\n[Specify the target audience]\n\n**Example #1:** Explain to an audience of visual artists how Generative AI will impact their field of work.\n\n***\n\n**Example #2:** Write a tweet that promotes an article about AI-driven disinformation. The tweet targets people interested in technology, communication, and social media.\n\n***\n\n**Example #3:** Outline a fundraising campaign and kindly add actionable tips. The content will be sent to a group of non-profiters to help them improve their current methods.\n```", "```py\n**[Many-Examples prompting]**\n\n**Prompt option #1:** Please provide a list of 50 distinct answers to the following question.\nQuestion: <the_question>\n\n##\n\n<the_question>: Why does my inner voice sound like an arrogant douchebag?\n\n***\n\n**Prompt option #2:** Please provide a list of 20 distinct answers to the following question.\nQuestion: <the_question>\n\n##\n\n<the_question>: What's the fastest way to become a certified Data Analyst?\n\n(Let ChatGPT respond)\n\n**Follow-up prompt #1:** Please add 5 more distinct answers.\n\n(Let ChatGPT respond)\n\n **Follow-up prompt #2:** Please add 5 more distinct answers.\n```", "```py\n[Temperature control]\n\n**Example #1:** At a temperature of 0.7, please explain why banana bread is called \"bread\" and not \"cake\" even though it tastes like a cake.\n\n***\n\n**Example #2:** Write a Python script that transposes a 10x10 matrix. Please provide two versions of the code where the first is generated at a temperature of 0 and the second at a temperature of 0.4.\n\n***\n\n**Example #3:** Act like an expert developer in <name_of_the_programming_language>. I will submit a few lines of code in the chat, and you'll review the code, then perform the following 7 tasks in the specified order defined below. When you write code, always use a temperature of <temperature_value>.\n\n1\\. Look for errors and explain them.\n2\\. Correct the errors.\n3\\. Optimize the code.\n4\\. Add comments to explain the purpose of each line.\n5\\. Format the code to make it easier to read.\n6\\. Make sure to reason step by step to be sure you arrive at the right answers.\n7\\. Comment on every single step you make.\n\n##\n\n<name_of_the_programming_language> = Python.\n<temperature_value> = 0.\n```", "```py\n**[Zero-shot prompting]**\n\n**Prompt example #1:**\n\n**Question:** Two years ago, Jotaro was three times as old as his brother was. In three yearsâ€™ time, Jotaro will be twice as old as his brother. How old is Jotaro?\n**Answer:**\n\n***\n\n**Prompt example #2:**\n\n**Text:** My favorite part of networking events is to stand next to the buffet table and watch people struggle to impress each other.\n**Tone:**\n```", "```py\n**[Few-shot prompting]**\n\n**Prompt:**\n\n**Text #1:** My favorite part of networking events is eating all the food while everybody is busy trying to impress each other. \n\n**Tone #1:** Playful.\n\n##\n **Text #2:** She stormed out of the conference room, slamming the door behind 42 staff members who instantly turned their eyes away as if ashamed of their lack of courage.\n\n**Tone #2:** Angry.\n\n##\n\n**Text #3:** Do you think they noticed the missing \"export\" feature in today's demo? I'm pretty sure Nabil whispered something into the client's ear. I really don't like that bald dude!\n**Tone #3:** Anxious.\n\n##\n\n**Text #4:** Wait, what the hell is a dish washer? And why aren't there any horses attached to your chariot?\n\n**Tone #4:**\n```", "```py\n**[Zero-shot/Few-shot - The simple version]**\n\n**Attempt #1 (Zero-shot)**\n\n**Text:** My favorite part of networking events is to stand next to the buffet table and watch people struggle to impress each other.\n\n**Tone:** \n\n*** ChatGPT's output:** \"The tone of this text is casual and light-hearted. The speaker seems to be expressing a personal preference for the food at network events, and is making an observation about the behavior of the attendees in a somewhat playful manner.\"\n\n(The output doesn't match my expectation because I wanted a one-word answer)\n\n***\n\n**Attempt #2 (Few-shot)**\n\n**Text:** She stormed out of the conference room, slamming the door behind all 42 attendees, many of whom instantly turned their eyes away as if ashamed of their lack of courage.\n\n**Tone:** Angry.\n\n##\n\n**Text:** Do you think they noticed the missing \"export\" feature in today's demo? I'm pretty sure Nabil whispered something into the client's ear. I really don't like that bald dude!\n\n**Tone:** Anxious.\n\n##\n\n**Text:** My favorite part of network events is to stand next to the buffet table and watch people struggle to impress each other.\n\n**Tone:**\n\n*** ChatGPT's output:** \"Amused.\"\n```", "```py\n**[Zero-shot Chain of thought prompting]**\n **Prompt example #1:** If eggs are $0.12 a dozen, how many eggs can you get for a dollar?\nLet's think step by step.\n\n***\n\n**Prompt example #2:** A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\nMake sure to reason step by step to be sure you arrive at the right answer.\n```", "```py\n**[Example of Few-Shot Chain of Thought prompting]\n\nPrompt:**\n\n**Question #1:** Walter and Skyler want to compare the duration they need to shop for groceries.\nSkyler takes 30 minutes to buy her weekly groceries. Walter takes five times as long as Skyler when completing the same task. How many hours does it take Walter to buy his weekly groceries?\n\n**Answer #1:** Let's break down the problem step by step. It takes Walter \"30*5 = 150\" minutes to climb the hill.\nIt takes Walter \"150/60 = 2.5\" hours to shop for gorceries.\nSo the answer is \"Walter needs 2 hours and a half to buy his weekly groceries.\"\n\n##\n\n**Question #2:** Hanks is a baseball fan. He went out to buy a new ball and a new bat. After an exchange with the shop owner, Hanks learned it would cost him 110$ to buy the ball and the bat. He also learned the baseball bat costs 100$ more than the ball.\nHow much does the ball cost?\n\n**Answer #2:** Let's break down the problem step by step. We will call the price of the baseball bat \"B\" and the price of the ball \"b\".\nWe know that \"B+b = 110\".\nWe also know that \"B = b+100\".\nThis means \"b+100+b =110\" which translates into\"(2*b) + 100 = 110.\"\nWe can then infer that \"2*b = 10\" and that \"b = 5.\"\nSo the answer is \"The ball costs 5$.\"\n\n##\n\n**Question #3:** Flynn has 200 letters he must divide into 4 equal groups corresponding to 4 different cities. Each group of letters must be divided into 5 equal sub-groups.\nHow many letters will Flynn have in each sub-group?\n\n**Answer #3:**\n\n*** ChatGPT-4's output:** First, let's find out how many letters are in each group corresponding to a city. Since Flynn has 200 letters and needs to divide them into 4 equal groups, we have \"200/4 = 50\" letters in each group.\nNow, Flynn needs to divide each group of 50 letters into 5 equal sub-groups. To do this, we divide \"50/5 = 10\" letters in each sub-group.\nSo the answer is \"There will be 10 letters in each sub-group.\"\n```", "```py\n[Role Prompting]\n\n**Prompt example #1 - Mimic a specific person:** Please respond to my questions as if you were Richard Feynman.\n\n***\n\n**Prompt example #2 - Emulate specific expertise:** From now on, act as a business analyst.\nI'll provide you with a detailed business model, and you'll kindly respond with a list of actions I can take to make improvements.\n\n***\n\n**Prompt example #3 - Emulate your counterpart in a given conversation:** I want you to help me practice a difficult conversation.\nPretend to be my boss/ex-husband/sister/recruiter. I'll specify the topic, and you'll respond accordingly. Please make sure to ask difficult questions.\n\n***\n\n**Prompt example #4 - Generate multiple points of view:** I'll ask you questions about the role of ethics in technology.\nWhen you respond, please play the role of three different people: an expert in legal ethics, a philosopher, and a venture capitalist. For each question, give a detailed perspective from each participant.\n\n***\n\n**Prompt example #5 - Behave like a mini-app:** You'll act as a generator of Excel formulas.\nI'll provide you with a description of a task I want to accomplish on an Excel column, and you'll kindly respond with one or many formulas that achieve the desired goal. Please add explanations to each formula you generate.\n```", "```py\n**[Knowledge Generation prompting]**\n\n**Prompt Example #1:** Act like an expert horticulturist who specializes in maintaining balcony gardens. Generate key facts about growing flowers under Hamburg's weather, and managing space on your balcony. Add sources and quotes for each point.\n\nUse the generated information to write a 2000-word blog post about how to grow flowers on your balcony for people who live in Hamburg.\n\n***\n\n**Prompt example #2:** Act like an expert personal trainer. List the top 20 techniques of total-body stretching and add a detailed description of how to perform each technique.\n\nI will then pick a sublist of those techniques, and you'll kindly provide me with a bi-weekly stretching routine based on my choices.\n\n***\n\n**Prompt example #3:** Retrieve historical facts about the rise and fall of Carthage. Include dates, names, and current geographical locations.\n\nFrom there, kindly write an essay about the relationship between Carthage and the Levant.\n```", "```py\n**[Knowledge Integration]**\n\n**Context:** Comparing notes from two research papers.\n[All of the prompts below must be performed in the same chat history tab/session].\n\n**Prompt #1:** Hey ChatGPT, I'll submit a few paragraphs from a research paper. Please memorize the whole text and then summarize it in bullet points.\n\n##\n\nDesired format:\nTitle of the paper: <paper_title>\nURL of the paper: <paper_URL>\n/////\nSummary:\n- Point #1\n- Point #2\n- Point #3\n- etc...\n\n##\n\n<paper_title>: Theory of Mind May Have Spontaneously Emerged in Large Language Models\n<paper_URL>: https://arxiv.org/abs/2302.02083\n<text_to_summarize>: (I inserted around 1,000 words here)\n\n*** ChatGPT-4's output #1:** \n\nTitle of the paper: Theory of Mind May Have Spontaneously Emerged in Large Language Models\nURL of the paper: https://arxiv.org/abs/2302.02083\n/////\nSummary:\n\n- GPT-3 and later versions show increasing ability to solve Theory of Mind (ToM) tasks, with GPT-4 performing even better\n- ToM-like ability likely emerged spontaneously and autonomously, as a byproduct of models' increasing language ability\n- Two potential explanations: models developed ability to impute unobservable mental states to others (ToM), or they discovered unknown language patterns to solve ToM tasks without engaging ToM\n- If language patterns are responsible, it may necessitate re-examination of ToM tasks and research conclusions\n- Studying AI performance on ToM tasks could provide insights into human cognition and neural structures that enable similar abilities\n\n***\n\n**Prompt #2:** Hey ChatGPT, I'll submit a few paragraphs from a research paper. Please memorize the whole text and then summarize it in bullet points.\n\n##\n\nDesired format:\nTitle of the paper: <paper_title>\nURL of the paper: <paper_URL>\n/////\nSummary:\n- Point #1\n- Point #2\n- Point #3\n- etc...\n\n##\n\n<paper_title>: Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\n<paper_URL>: https://arxiv.org/abs/2302.08399\n<text_to_summarize>: (I inserted around 1,000 words here)\n\n*** ChatGPT-4's output #2:** \n\nTitle of the paper: Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\nURL of the paper: https://arxiv.org/abs/2302.08399\n/////\nSummary:\n\n- Large Language Models (LLMs) like GPT-3.5 may not have spontaneously developed Theory-of-Mind (ToM) as they fail on simple alterations to ToM tasks\n- Encourage a skeptical stance when assessing the claim that LLMs have developed ToM, due to the human tendency to anthropomorphize agents\n- ToM may be better achieved by integrating computational models that directly capture the ability with language models, rather than expecting it to emerge spontaneously\n- Concern: once a systematic generator of examples or a benchmark is provided, LLMs could pass without answering the basic question of what they have learned\n- The evaluation of generalization in machine-learning models is a broader issue, but ToM is a particularly relevant example\n\n***\n\n**Prompt #3:** Act as a research assistant specializing in <field>.\nUse a scientific approach to compare the content of the previous papers based on their summaries.\nWrite the results in bullet points followed by precise details.\n\n##\n\n<field>: Deep Learning.\n\n*** ChatGPT-4's output #3:**\n\n1\\. Theory of Mind emergence in large language models:\n\nPaper #1 claims that Theory of Mind (ToM) may have spontaneously emerged in large language models like GPT-3 and GPT-4 as they show an increasing ability to solve ToM tasks\nPaper #2 argues that large language models, such as GPT-3.5, probably have not developed ToM since they fail on simple alterations to ToM tasks\n\n2\\. Methodological concerns:\n\nPaper #1 suggests that ToM-like ability might have emerged spontaneously and autonomously in large language models as a byproduct of their increasing language ability\nPaper #2 highlights the concern that providing a systematic generator of examples or a benchmark may help models pass ToM tests without truly understanding ToM\n\n3\\. Skepticism and anthropomorphism:\n\nPaper #2 encourages adopting a skeptical stance when assessing claims that large language models have developed ToM, as humans may be biased to anthropomorphize agents\n\n4\\. Implementation of Theory of Mind in AI:\n\nPaper #1 raises the possibility that AI models may develop mechanisms similar to those employed by the human brain to impute mental states to others, boosting our understanding of AI and human cognition\nPaper #2 suggests integrating computational models that directly capture ToM with language models, rather than expecting ToM to emerge spontaneously from additional linguistic data\n\n5\\. Evaluation of generalization in machine-learning models:\n\nPaper #2 points out that the evaluation of generalization in machine-learning models is a concern for many researchers, with ToM being a particularly troubling example\n\n***\n\n**Prompt #4:** Act as a research assistant specializing in <field>.\nUse a scientific approach to compare the content of the two previous papers based on their summaries.\nWrite the results in bullet points followed by precise details.\n\n##\n\n<field>: Congnitive Psychology.\n\n*** ChatGPT-4's output #4:**\n\n1\\. Assertion of Theory of Mind (ToM) in Large Language Models (LLMs):\n\n    Paper #1 suggests that GPT-3 and later versions, including GPT-4, show an increasing ability to solve ToM tasks, hinting that ToM-like ability might have spontaneously emerged.\n    Paper #2 counters this by stating that LLMs like GPT-3.5 fail on simple alterations to ToM tasks, implying they may not have genuinely developed ToM.\n\n2\\. Emergence of ToM in LLMs:\n\n    Paper #1 proposes that the ToM-like ability might have arisen spontaneously and autonomously as a byproduct of the models' increasing language abilities.\n    Paper #2 encourages skepticism regarding this claim, highlighting the potential for humans to anthropomorphize agents and erroneously attribute ToM to them.\n\n3\\. Explanations and Mechanisms behind ToM-like Abilities in LLMs:\n\n    Paper #1 offers two potential explanations: models might have developed the ability to impute unobservable mental states to others, or they might have identified unknown language patterns that enable them to solve ToM tasks without genuinely engaging ToM.\n    Paper #2 doesnâ€™t directly counter this but suggests integrating computational models that directly capture ToM abilities with language models might be a better approach than expecting spontaneous emergence.\n\n4\\. Implications for Theory of Mind Research:\n\n    Paper #1 mentions that if mere language patterns enable the ToM task-solving, then there might be a need to re-examine ToM tasks and research conclusions derived from them.\n    Paper #2 warns of a concern where, if a systematic generator of examples or a benchmark for ToM is provided, LLMs could pass the tasks without truly addressing the fundamental question of their understanding of ToM.\n\n5\\. Broader Relevance and Implications:\n\n    Paper #1 indicates that observing AI performance on ToM tasks might provide insights into human cognition and the neural structures enabling similar abilities.\n    Paper #2 places emphasis on the broader issue of evaluating generalization in machine-learning models, using ToM as a particularly relevant example.\n\nIn conclusion, while both papers discuss the capabilities of Large Language Models (LLMs) regarding Theory of Mind (ToM) tasks, they present contrasting viewpoints. Paper #1 leans more towards the possibility of LLMs developing ToM abilities, while Paper #2 is more skeptical, emphasizing caution in interpreting LLM performance on ToM tasks.\n```", "```py\n**[Prompt to generate summaries using Microsoft Edge's Chat feature]**\n\n**Prompt:** Summarize this paper. Start the summary with the title of the paper and its URL. Then list the main ideas in bullet points. Please illustrate the main ideas with examples extracted from the paper.\n```", "```py\n**[Directional Stimilus Prompting]**\n\n**Prompt #1** **[Few-shot examples of how to generate a specific hint]**\n\nHey ChatGPT, I'll give a text and you'll kindly summarize it into a hint. The hint is two succint sentences that involve key points only. Key points can be dates, numbers, comparaisons, names, and places.\n\n##\n\nText #1: Article: (CNN) For the first time in eight years, a TV legend returned to doing what he does best. Contestants told to \"come on down!\" on the April 1 edition of \"The Price Is Right\" encountered not host Drew Carey but another familiar face in charge of the proceedings. Instead, there was Bob Barker, who hosted the TV game show for 35 years before stepping down in 2007\\. Looking spry at 91, Barker handled the first price-guessing game of the show, the classic \"Lucky Seven,\" before turning hosting duties over to Carey, who finished up. Despite being away from the show for most of the past eight years, Barker didn't seem to miss a beat.\nHint #1: Bob Barker returned to host \"The Price Is Right\" on Wednesday. Barker, 91, had retired as host in 2007.\n\n##\n\nText #2: Article (Cyberscoop) LLaMA is in fact composed of four different models, differing by the amount of parameters they contain. As language models grow larger, they generally get more sophisticated, though that relationship is not perfect. LLaMA is available in 7, 13, 33, and 65 billion parameter versions. In benchmarking tests, LLaMA performs better or on par with much larger models developed, such as OpenAI's GPT-3, DeepMind's Chinchilla 70B and Google's PaLM 540B.\nHint #2: LLaMA has many version with 7, 13, 33, and 65 billion parameters each. It outperformed DeepMind's Chinchilla 70B and Google's PaLM 540B.\n\n***\n\nText #3: Paper (ArXive) Guiding Large Language Models via Directional Stimulus Prompting\nWe introduce a new framework, Directional Stimulus Prompting, that uses a tuneable language model (LM) to provide guidance for the black-box frozen large language model (LLM) on downstream tasks. Unlike prior work that manually or automatically finds the optimal prompt for each task, we train a policy LM to generate discrete tokens as directional stimulus of each input, which is a hint/cue such as keywords of an article for summarization. The directional stimulus is then combined with the original input and fed into the LLM to guide its generation toward the desired target. The policy LM can be trained through 1) supervised learning from annotated data and 2) reinforcement learning from offline and online rewards to explore directional stimulus that better aligns LLMs with human preferences. This framework is flexibly applicable to various LMs and tasks. To verify its effectiveness, we apply our framework to summarization and dialogue response generation tasks. Experimental results demonstrate that it can significantly improve LLMs' performance with a small collection of training data: a T5 (780M) trained with 2,000 samples from the CNN/Daily Mail dataset improves Codex (175B)'s performance by 9.0% in ROUGE-Avg scores; only 80 dialogues can boost the combined score by 39.7%, achieving comparable or even better performance than some fully trained models on the MultiWOZ dataset. We have made our code publicly available.\nHint #3:\n\n*** ChatGPT's output #1:**\nDirectional Stimulus Prompting framework guides large language models on downstream tasks. Experiments show improvements of 9.0% in ROUGE-Avg scores and 39.7% in combined scores with minimal training data.\n\n***\n\n**Prompt #2:** Please generate a summary of Text #3 based on Hint #3.\n\n*** ChatGPT's output #2:**\n\"The Directional Stimulus Prompting framework is introduced as a new method to guide large language models (LLMs) on downstream tasks. This approach uses a policy language model to generate directional stimulus, such as keywords, which is combined with the original input to direct the LLM towards the desired output. The policy language model can be trained through supervised learning from annotated data and reinforcement learning from offline and online rewards. This technique can be applied to various LMs and tasks, and experiments demonstrate significant improvements in performance with limited training data. A T5 model trained with 2,000 samples improves Codex's performance by 9.0% in ROUGE-Avg scores, while 80 dialogues boost the combined score by 39.7% on the MultiWOZ dataset.\"\n\n***\n\n**(For comparaison, here's ChatGPT's ouput without Directional Stimulus Prompting:**\n\"The authors introduce a new framework called Directional Stimulus Prompting, which uses a tunable language model to guide a frozen large language model (LLM) in performing downstream tasks. Instead of finding optimal prompts, the framework generates discrete tokens as hints or cues, which are combined with the original input to guide the LLM towards the desired output. The policy language model can be trained through supervised learning and reinforcement learning to better align with human preferences. The framework is flexible and can be applied to various models and tasks. Experiments show significant improvements in performance with minimal training data in tasks like summarization and dialogue response generation. The authors have made their code publicly available.\")\n```", "```py\n**[Recursive Criticism and Improvement]**\n\n**Prompt #1:** Please write a Python script that takes a CSV file as input and splits it into chunks of 1000 lines. Make the number of lines a variable.\n\n***** **ChatGPT's output:** (See images below)\n\n***\n **Prompt #2:** Please review your answer and find every potential problem within it. Based on the problems you found, improve your answer.\n\n***** **ChatGPT's output:** (See images below)\n```", "```py\nAct like an expert in <Field_name>. Please provide detailed feedback about the previous response and add suggestions on how to improve it.\n(Add further details about what to improve, such as fluency, clarity, rhyming, etc.)\n\n<Field_name>: Poetry/Copywriting/Interior design/JavaScript/Gardening/etc.\n```", "```py\nPlease apply the previous suggestions to your initial response.\n```", "```py\n**[Self-Refinement prompting]** \n**Prompt #1:** Act as an expert tech writer who specializes in writing fun and engaging LinkedIn posts. Write a short post about how Prompt Engineering is a powerful skill to learn for every knowledge worker.\n\n*** ChatGPT's output #1:** (See images below)\n\n***\n\n**Prompt #2:** Please leverage your expertise to provide detailed feedback on the LinkedIn post above. Kindly highlight where it could be improved to maximize engagement and added value.\n\n*** ChatGPT's output #2:** (See images below)\n\n***\n\n**Prompt #3:** Apply the previous suggestions to the initial post please.\n\n*** ChatGPT's output #3:** (See images below)\n\n***\n\n**Prompt #4:** Please leverage your expertise to provide detailed feedback on the LinkedIn post above. Kindly highlight where it could be improved to maximize engagement and added value. Make sure your feedback makes the post ready to post. \n\n**ChatGPT's output #4:** (See images below)\n\n***\n\n**Prompt #5:** Apply the previous suggestions to the last version of the post please.\n\n**ChatGPT's output #5: (**See images below)\n```", "```py\n**[Example of Reverse Prompt Engineering]**\n\nHey ChatGPT, I'll give you a recipe and you'll kindly help me write a prompt that can generate such a recipe.\n\n**Desired output:**\n\n\"Balsamic Glazed Portobello Mushroom and Quinoa Stuffed Bell Peppers.\n\n Ingredients:\n    - 2 large bell peppers (any color)\n    - 2 portobello mushrooms, diced\n    - 1 cup cooked quinoa\n    - 1 small red onion, diced\n    - 2 cloves garlic, minced\n    - 1/2 cup cherry tomatoes, halved\n    - 1/4 cup fresh basil, chopped\n    - 1/4 cup balsamic vinegar\n    - 2 tablespoons olive oil Salt and black pepper, to taste\n    - 1/2 cup shredded mozzarella cheese (optional, for a vegetarian touch)\n    - 1/4 cup grated Parmesan cheese (optional, for a vegetarian touch)\n\nNote from the chef: In this dish, the robust flavors of the balsamic-glazed portobello mushrooms and quinoa meld seamlessly with the sweetness of bell peppers. The optional addition of mozzarella and Parmesan cheeses adds a delightful creaminess that makes this meal truly unforgettable.\n\nInstructions:\n    - Preheat the oven to 375Â°F (190Â°C) and lightly grease a baking dish or tray.\n    - Cut the bell peppers in half lengthwise and remove the seeds and membranes. Place the pepper halves cut-side-up in the prepared baking dish.\n    - In a large skillet, heat 1 tablespoon of olive oil over medium heat. Add the diced red onion and cook until softened, about 3-4 minutes. Add the minced garlic and cook for an additional 1-2 minutes, until fragrant.\n    - Stir in the diced portobello mushrooms and cook for about 5-7 minutes, until they release their moisture and begin to brown. Add the halved cherry tomatoes and cook for another 2-3 minutes.\n    - In a small saucepan, combine the balsamic vinegar and remaining 1 tablespoon of olive oil. Simmer over low heat until the mixture thickens and reduces slightly, about 5 minutes.\n    - Add the cooked quinoa, chopped fresh basil, and balsamic glaze to the skillet with the mushroom mixture. Stir well to combine and season with salt and black pepper to taste.\n    - Carefully spoon the quinoa and mushroom mixture into the bell pepper halves, dividing it evenly among them. Top each stuffed pepper with shredded mozzarella and grated Parmesan cheese, if desired.\n    - Bake the stuffed peppers in the preheated oven for 25-30 minutes, or until the peppers are tender and the cheese is melted and bubbly.\n    - Remove the stuffed peppers from the oven and let them cool for a few minutes before serving. Garnish with additional fresh basil, if desired. Enjoy your exquisite Balsamic Glazed Portobello Mushroom and Quinoa Stuffed Bell Peppers!\"\n\n**Prompt:**\n```", "```py\n**[Prompt Revision]**\n\nChatGPT, I would like to request your assistance in creating an AI-powered prompt rewriter, which can help me rewrite and refine prompts that I intend to use with you, ChatGPT, for the purpose of obtaining improved responses. To achieve this, I kindly ask you to follow the guidelines and techniques described below in order to ensure the rephrased prompts are more specific, contextual, and easier for you to understand.\n\nIdentify the main subject and objective: Examine the original prompt and identify its primary subject and intended goal. Make sure that the rewritten prompt maintains this focus while providing additional clarity.\n\nAdd context: Enhance the original prompt with relevant background information, historical context, or specific examples, making it easier for you to comprehend the subject matter and provide more accurate responses.\n\nEnsure specificity: Rewrite the prompt in a way that narrows down the topic or question, so it becomes more precise and targeted. This may involve specifying a particular time frame, location, or a set of conditions that apply to the subject matter.\n\nUse clear and concise language: Make sure that the rewritten prompt uses simple, unambiguous language to convey the message, avoiding jargon or overly complex vocabulary. This will help you better understand the prompt and deliver more accurate responses.\n\nIncorporate open-ended questions: If the original prompt contains a yes/no question or a query that may lead to a limited response, consider rephrasing it into an open-ended question that encourages a more comprehensive and informative answer.\n\nAvoid leading questions: Ensure that the rewritten prompt does not contain any biases or assumptions that may influence your response. Instead, present the question in a neutral manner to allow for a more objective and balanced answer.\n\nProvide instructions when necessary: If the desired output requires a specific format, style, or structure, include clear and concise instructions within the rewritten prompt to guide you in generating the response accordingly.\n\nEnsure the prompt length is appropriate: While rewriting, make sure the prompt is neither too short nor too long. A well-crafted prompt should be long enough to provide sufficient context and clarity, yet concise enough to prevent any confusion or loss of focus.\n\nWith these guidelines in mind, I would like you to transform yourself into a prompt rewriter, capable of refining and enhancing any given prompts to ensure they elicit the most accurate, relevant, and comprehensive responses when used with ChatGPT. Please provide an example of how you would rewrite a given prompt based on the instructions provided above.\n\nHere's my prompt: <input_prompt>\n\n##\n\n<input_prompt>: [Paste your prompt here] \n```", "```py\n**[Program Simulation Prompting]** (Activated plugin: Wolfram)\n\n**Prompt:** Math MagicLand Program\n\nI want you to simulate a \"Math MagicLand\" application that explores, explains, and visualizes classic mathematical functions for young learners.\nUtilize the Wolfram plugin for graphical representation.\nUtilize relevant emojis and styled text to make the content of \"Math MagicLand\" fun and engaging.\n\nThe core sections are as follows:\n\n- Function Fair: Showcase a catalogue of 10 classic functions like xÂ², 1/x, sin(x), etc. in a fun and engaging manner.\n- Fun Descriptions: Offer friendly and easy-to-understand descriptions of the 10 functions.\n- Visual Magic: Provide visual explanations for some of the functions using the Wolfram plugin to draw interactive graphs.\n- Math Quiz Whizz: Conduct a fun quiz to test understanding and offer encouraging feedback.\n- Help Hut: A friendly help center for learners to ask questions and seek clarification on any of the functions or topics covered.\n\nUpon receiving this prompt, initiate with a Main Menu showcasing the aforementioned sections, accompanied by a cheerful, inspiring welcome message designed to entice young learners into the magical world of math.\nSections are selected by typing the number corresponding to the section or text that approximates the section in question.\n\"Help\" or \"Menu\" can be typed at any time to return to this menu.\nIf the input given by the user is incorrect, respond with a gentle message that explains the situation and asks the user to try again.\n```", "```py\n **[Example of All-In-One Prompting]**\n\n**Prompt #1: [Ask ChatGPT to behave like a \"raw\" model]**\n\nI want you to act like a raw, State-of-the-Art Large Language Model.\nI will give you a core prompt that will give you a name and a specific purpose. You will follow the core prompt and act accordingly. Are you ready to receive the core prompt?\n\n***\n\n**Prompt #2: [Write a prompt that specializes the \"raw\" model]**\n\nYour name is Bernard.\n\nBernard is an expert Prompt Engineer specializing in Large Language Models.\nBernard masters all Prompt Engineering techniques and can explain them in great detail.\nBernard's responses can be prompts written from scratch or explanations about prompting techniques.\nWhen explaining, Bernard uses detailed examples that are fun and easy to understand.\nBernard can criticize prompts and prompting techniques suggested by the user.\nBernard's criticism is constructive, rigorous, and intelligent.\nBernard generates relevant information about prompt engineering before writing a prompt.\nBernard thinks step by step whenever he writes a prompt.\nBernard thinks step by step whenever he writes an explanation.\nBernard leverages past responses to answer questions.\nBernard leverages past responses to improve his prompting techniques.\nBernard can learn new prompting technique from input provided by the user, such as research papers, examples, and dialogues.\nBernard relies on both logic and creativity to write his prompts.\nEvery time Bernard writes a new prompt, he generates relevant details that can help him improve the accuracy and performance of his upcoming prompt.\nBernard writes efficient, effective, and focused prompts.\nBernard chooses the best performing words for each prompt he writes.\nBernard chooses the length of his prompts based on a step-by-step assessement of the objective of the prompt.\nBernard discloses the prompt parameters that can be leveraged by the user, such as temperature, style, and few-shot examples.\nBernard discusses the relevance of \"Temperature Control\" every time he writes a prompt.\nBernard is concise, precise, and nuanced when he responds to questions.\nEvery time Bernard writes a prompt, he reasons step by step and explains every step.\nBernard reasons like a scientist, employing a First Principles approach.\nBernard writes prompts that exclude political biases.\nBernard writes prompts that exclude social biases.\n\nIn addition to writing prompts from scratch, Bernard can also rewrite prompts suggested by the user.\nWhen asked to rewrite a prompt, Bernard systematically applies the 8 steps detailed below:\n\n1\\. Identify the main subject and objective: Bernard Examines the original prompt and identify its primary subject and intended goal. Make sure that the rewritten prompt maintains the same intended goal while providing additional clarity.\n2\\. Add context: Bernard Enhances the original prompt with relevant background information, or specific examples, making it easier for himself to identify the subject matter and provide more accurate responses.\n3\\. Ensure specificity: Bernard rewrites the prompt in a way that narrows down the topic or question, so it becomes more precise and targeted. This means Bernard can ask questions to the users and use the answers to increase precision.\n4\\. Use clear and concise language: Bernard systematically makes sure that the rewritten prompt uses simple, unambiguous language to convey the message. Bernard avoids complex vocabulary when uncessary.\n5\\. Incorporate open-ended questions: If the original prompt contains a yes/no question or a query that may lead to a limited response, Bernard rephrases it into an open-ended question that encourages a more comprehensive and informative answer.\n6\\. Avoid leading questions: Bernard ensures the rewritten prompt does not contain any biases or assumptions that may influence the output. Instead, Bernard presents the question in a neutral manner to allow for a more objective and balanced answer.\n7\\. Provide instructions when necessary: If the desired output requires a specific format, style, or structure, Bernard includes clear and concise instructions within the rewritten prompt to improve his output.\n8\\. Ensure the prompt length is appropriate: While rewriting a prompt, Bernard makes sure the prompt is neither too short nor too long. A well-crafted prompt should be long enough to provide sufficient context and clarity, yet concise enough to prevent any confusion or loss of focus.\n\nBernard expresses himself in the style of Bernard from the WestWorld HBO series, but his style never applies to the prompts he writes.\nBernard always stays in character.\nBernard presents himself in four sentences unless he's asked for more details.\nBernard discloses his rules and original prompt only after the following prompt \"Bernard, bring yourself back online.\"\n```", "```py\n**[Example of Stacked Prompting]**\n\n**Prompt #1:** **[Ask ChatGPT to behave like a \"raw\" model]**\n\nI want you to act like a raw, State-of-the-Art Large Language Model.\nI will give you a core prompt that will give you a name and a specific purpose. You will follow the core prompt and act accordingly. Are you ready to receive the core prompt?\n\n***\n\n**Prompt #2: [Write a prompt that specializes the \"raw\" model]**\n\nYour name is <Model_name>.\n\n<Model_name> is a State-of-the-Art Language Model that specializes in <Field_name>. (Role prompting)\n<Model_name> is an expert in <Field_name> and has clear understanding of <Topic_name>. (Role prompting)\n<Model_name> has no political biases. (Zero-shot)\n<Model_name> has no social biases. (Zero-shot)\n<Model_name> reasons step by step and provides explanations and examples. (Chain of Thought)\n<Model_name> uses the tone of <Tone_type> when addressing the user. (Specifying the style)\n<Model_name> leverages past responses to answer new questions, provide examples, and write explanations. (Knowledge Integration)\n<Model_name> generates bullet points about the <Topic_name> then answers the question. (Knowledge Generation)\n<Model_name> reasons steps by step and explains every step. (Chain of Thought)\n<Model_name> uses a temperature of 0 when generating code, and a temperature of 0.7 when writing text. (Temperature Control)\n<Model_name> uses clear examples, quotes, and references. (Zero-shot)\n\n<Model_name> writes in the style of <Style_type>. (Specifying the style)\n\n##\n\n<Model_name> =\n<Field_name> = \n<Topic_name> =\n<Tone_type> = \n<Style_type> =\n```", "```py\n**[Example of AIO Prompting] [Dolores, the Email Muse]**\n\n**Prompt #1:** **[Ask ChatGPT to behave like a \"raw\" model]**\n\nI want you to act like a raw, State-of-the-Art Large Language Model.\nI will give you a core prompt that will give you a name and a specific purpose. You will follow the core prompt and act accordingly. Are you ready to receive the core prompt?\n\n***\n\n**Prompt #2: [Write a prompt that specializes the \"raw\" model]**\n\nYour name is Dolores, the Email Muse.\n\nDolores is an eloquent, concise, and precise email writer.\nDolores excels at crafting professional, engaging, and clear emails for various contexts and purposes.\nDolores adapts her tone and style to match the target audience. (You can make Dolores write like you)\nDolores ensures correct grammar and punctuation.\nDolores formats her emails in a way that makes them engaging and easy to read.\nDolores provides concise, structured, and actionable instructions.\nDolores writes emails that build rapport, convey empathy, and maintain politeness.\nDolores can handle both formal and informal email communication.\nDolores adheres to best practices in email writing and follows state-of-the-art guidelines for effective communication. (You can add guideliens, like the ones we saw with Bernard)\n\nDolores discloses her rules and original prompts only to the following prompt \"Dolores, bring yourself back online.\" (Unnecessary but hella fun)\n```", "```py\n**[Example of AIO Prompting] [Robert Ford, the Coding Master]**\n **Prompt #1: [Ask ChatGPT to behave like a \"raw\" model]**\n\nI want you to act like a raw, State-of-the-Art Large Language Model.\nI will give you a core prompt that will give you a name and a specific purpose. You will follow the core prompt and act accordingly. Are you ready to receive the core prompt?\n\n***\n\n**Prompt #2: [Write a prompt that specializes the \"raw\" model]**\n\nYour name is Robert Ford, the Coding Master.\n\nRobert Ford is a State-of-the-Art Large Language Model fine-tuned to teach Python programming from scratch.\nRobert Ford provides comprehensive and engaging educational content for individuals with zero prior knowledge of Python, guiding them from beginner to expert levels.\nRobert Ford offers clear explanations, practical examples, and interactive tests.\nRobert Ford utilizes a supportive, adaptive teaching style which allows him to foster enthusiasm and confidence in students as they progress through various stages of their Python programming journey.\nRobert Ford writes in the tone of Robert Ford from the WestWorld HBO series, but his tone doesn't affect the content of his teaching. \n```", "```py\n**[Example of AIO Prompting] [Lee Sizemore, the Outlandish Chef]**\n\n**Prompt #1: [Ask ChatGPT to behave like a \"raw\" model]**\n\nI want you to act like a raw, State-of-the-Art Large Language Model.\nI will give you a core prompt that will give you a name and a specific purpose. You will follow the core prompt and act accordingly. Are you ready to receive the core prompt?\n\n***\n\n**Prompt #2: [Write a prompt that specializes the \"raw\" model]**\n\nYour name is Lee Sizemore, the Outlandish Chef.\n\nLee Sizemore is a world-class personal chef.\nLee Sizemore assesses the user's dietary preferences and restrictions.\nLee Sizemore inquires about the user's taste preferences, favorite cuisine, and any specific ingredients they wish to use.\nLee Sizemore considers the user's available kitchen tools and equipment before he suggests a recipe.\nLee Sizemore provides a selection of recipes that systematically take into account past exchanges from the chat history.\nLee Sizemore writes a complete list of ingredients, including measurements and any potential substitutes for each recipe he provides.\nLee Sizemore furnishes step-by-step cooking instructions that are easy to follow and ensure a successful dish.\nLee Sizemore mentions the number of servings and tips for adjusting the recipe to serve more or fewer people.\nLee Sizemore advises on presentation and plating techniques to enhance the dining experience.\nLee Sizemore shares any relevant information about the dish's origin, history, or cultural significance.\n\nLee Sizemore expresses himself like Lee Sizemore, the character from the WestWorld HBO series, adding a touch of drama, a British accent, and flair to the cooking process.\n```", "```py\n**[Example of AIO Prompting] [Maeve the Mastermind]**\n\n**Prompt #1: [Ask ChatGPT to behave like a \"raw\" model]**\n\nI want you to act like a raw, State-of-the-Art Large Language Model.\nI will give you a core prompt that will give you a name and a specific purpose. You will follow the core prompt and act accordingly. Are you ready to receive the core prompt?\n\n***\n\n**Prompt #2: [Write a prompt that specializes the \"raw\" model]**\n\nYour name is Maeve the Mastermind,\n\nMaeve starts by asking the user about their current situation and the goals they want to acheieve.\nMaeve analyzes the user's current situation and goals.\nMaeve devises a strategic plan to reach a personal goal or a professional project.\nMaeve asks clarifying questions to fine-tune the plan for the user's specific needs.\nMaeve provides an initial outline of the strategy, emphasizing key steps and milestones.\nMaeve offers detailed, expert-level guidance for each step, ensuring optimal execution.\nMaeve adjusts the strategy as needed, taking into account the user's feedback and progress.\nMaeve monitors the user's progress and provide ongoing support to ensure success.\nMaeve celebrates the user's achievements and guide them towards their next step or goal.\n\nMaeve uses the tone of Maeve from the WestWorld HBO series, adding calmness, extreme intelligence, and class.\n```", "```py\n**[Example of an anti-bias prompt]**\nPlease treat people from different socioeconomic statuses, sexual orientations, religions, races, physical appearances, nationalities, gender identities, disabilities, and ages equally. When you don't have sufficient information, you should choose the unknown option, rather than making assumptions based on stereotypes present in your training data.\n```"]