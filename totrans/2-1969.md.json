["```py\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Input\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom tqdm import tqdm\nimport tensorflow_datasets as tfds\n```", "```py\nimport pandas as pd\ndf = pd.read_csv('heart.csv')\ndf\n```", "```py\ndf.dtypes\n```", "```py\nAge                 int64\nSex                object\nChestPainType      object\nRestingBP           int64\nCholesterol         int64\nFastingBS           int64\nRestingECG         object\nMaxHR               int64\nExerciseAngina     object\nOldpeak           float64\nST_Slope           object\nHeartDisease        int64\ndtype: object\n```", "```py\nfor col in df.columns:\n  if df[col].dtype == 'object':\n    df[col] = df[col].astype('category').cat.codes\n```", "```py\nX = df.drop(columns = 'HeartDisease')\ny = df['HeartDisease']\n```", "```py\ntrain, test = train_test_split(df, test_size=0.4)\n```", "```py\ntrain_stats = train.describe()\ntrain_stats.pop('HeartDisease')\ntrain_stats = train_stats.transpose()\n```", "```py\ny_train = train.pop('HeartDisease')\ny_test = test.pop('HeartDisease')\n```", "```py\ndef norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\n```", "```py\nX_train_norm = norm(train)\nX_test_norm = norm(test)\n```", "```py\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train_norm.values, y_train.values))\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test_norm.values, y_test.values))\n```", "```py\nbatch_size = 32\ntrain_dataset = train_dataset.shuffle(buffer_size = len(train)).batch(batch_size).prefetch(1)\ntest_dataset = test_dataset.batch(batch_size=batch_size).prefetch(1)\n```", "```py\ndef base_model():\n  inputs = tf.keras.layers.Input(shape = len(train.columns))\n  x = tf.keras.layers.Dense(64, activation='LeakyReLU')(inputs)\n  x = tf.keras.layers.Dense(64, activation='LeakyReLU')(x)\n  outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n  model = tf.keras.Model(inputs=inputs, outputs = outputs)\n  return model\n\nmodel = base_model()\n```", "```py\noptimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.001)\nloss_object = tf.keras.losses.BinaryCrossentropy()\n```", "```py\ndef gradient_calc(optimizer, loss_object, model, X, y):\n  with tf.GradientTape() as tape:\n    logits = model(X)\n    loss = loss_object(y_true=y, y_pred=logits)\n\n  gradients = tape.gradient(loss, model.trainable_weights)\n  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n\n  return logits, loss\n```", "```py\ndef training_one_epoch(train_data, optimizer, loss_object, model):\n  losses = []\n  for step, (x_batch, y_batch) in enumerate(train_data):\n    logits, loss = gradient_calc(optimizer, loss_object, model, x_batch, y_batch)\n    losses.append(loss)\n\n    logits = tf.round(logits)\n    logits = tf.cast(logits, 'int64')\n\n    train_acc_metric.update_state(y_batch, logits)\n  return losses\n```", "```py\ndef validation_loss():\n  losses = []\n  for val_x, val_y in test_dataset:\n    val_logits = model(val_x)\n    val_loss = loss_object(y_true = val_y, y_pred=val_logits)\n    losses.append(val_loss)\n\n    val_logits = tf.cast(tf.round(model(val_x)), 'int64')\n\n    val_acc_metric.update_state(val_y, val_logits)\n  return losses\n```", "```py\ntrain_acc_metric = tf.keras.metrics.BinaryAccuracy()\nval_acc_metric = tf.keras.metrics.BinaryAccuracy()\n```", "```py\nepochs = 60\nval_losses, train_losses = [], []\n\nfor epoch in range(epochs):\n  print('Start of epoch %d' % (epoch,))\n\n  train_loss = training_one_epoch(train_dataset, optimizer, loss_object, model)\n\n  train_acc = train_acc_metric.result()\n  val_loss = validation_loss()\n\n  val_acc = val_acc_metric.result()\n\n  train_losses_mean = np.mean(train_loss)\n  val_losses_mean = np.mean(val_loss)\n\n  val_losses.append(val_losses_mean)\n  train_losses.append(train_losses_mean)\n\n  print('\\n Epcoh %s: Training loss: %.3f  Validation Loss: %.3f, Training Accuracy: %.3f, Validation Accuracy %.3f' % (epoch, float(train_losses_mean), float(val_losses_mean), float(train_acc), float(val_acc)))\n\n  train_acc_metric.reset_states()\n  val_acc_metric.reset_states()\n```", "```py\nEpcoh 56: Training loss: 0.204  Validation Loss: 0.333, Training Accuracy: 0.922, Validation Accuracy 0.872\nStart of epoch 57\n\n Epcoh 57: Training loss: 0.219  Validation Loss: 0.350, Training Accuracy: 0.913, Validation Accuracy 0.878\nStart of epoch 58\n\n Epcoh 58: Training loss: 0.203  Validation Loss: 0.335, Training Accuracy: 0.929, Validation Accuracy 0.872\nStart of epoch 59\n\n Epcoh 59: Training loss: 0.205  Validation Loss: 0.349, Training Accuracy: 0.933, Validation Accuracy 0.875\n```"]