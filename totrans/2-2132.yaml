- en: 'Towards LLM Explainability: Why Did My Model Produce This Output ?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 解释性：为什么我的模型产生了这个输出？
- en: 原文：[https://towardsdatascience.com/towards-llm-explainability-why-did-my-model-produce-this-output-8f730fc73713](https://towardsdatascience.com/towards-llm-explainability-why-did-my-model-produce-this-output-8f730fc73713)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/towards-llm-explainability-why-did-my-model-produce-this-output-8f730fc73713](https://towardsdatascience.com/towards-llm-explainability-why-did-my-model-produce-this-output-8f730fc73713)
- en: The release in these last few months of larger, better Large Language Models,
    that showcase new capabilities, has been paired with overall growing concerns
    over AI Safety. LMM explainability research tries to expand our understanding
    of how these models work.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最近几个月发布的更大、更好的大型语言模型展示了新能力，但也引发了对人工智能安全的普遍担忧。LLM 解释性研究试图扩大我们对这些模型工作原理的理解。
- en: '[](https://medium.com/@georgiadeaconu?source=post_page-----8f730fc73713--------------------------------)[![Georgia
    Deaconu](../Images/39ba1bea77aa46bb39b2975108c3adaa.png)](https://medium.com/@georgiadeaconu?source=post_page-----8f730fc73713--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8f730fc73713--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8f730fc73713--------------------------------)
    [Georgia Deaconu](https://medium.com/@georgiadeaconu?source=post_page-----8f730fc73713--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@georgiadeaconu?source=post_page-----8f730fc73713--------------------------------)[![Georgia
    Deaconu](../Images/39ba1bea77aa46bb39b2975108c3adaa.png)](https://medium.com/@georgiadeaconu?source=post_page-----8f730fc73713--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8f730fc73713--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8f730fc73713--------------------------------)
    [Georgia Deaconu](https://medium.com/@georgiadeaconu?source=post_page-----8f730fc73713--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8f730fc73713--------------------------------)
    ·9 min read·Dec 15, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8f730fc73713--------------------------------)
    ·阅读时间 9 分钟·2023年12月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Large Language Models (LLMs) saw a lot of development this past year, such as
    the recent release of GPT-4 and Claude 2\. These models display new abilities
    with respect to their previous versions, but most of them are discovered through
    post-hoc analysis and weren’t part of a purposeful training plan. They are a consequence
    of the model scaling in terms of number of parameters, training data and compute
    resources.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的一年里，大型语言模型（LLMs）取得了很多发展，例如最近发布的 GPT-4 和 Claude 2。这些模型展示了相较于之前版本的新能力，但大多数能力是通过事后分析发现的，并非有意的训练计划的一部分。它们是模型在参数数量、训练数据和计算资源方面扩展的结果。
- en: On a conceptual level, I like the analogy between LLMs and compression algorithms.
    Terabytes of internet data go in and many FLOPS later we get a file of a few hundreds
    GB containing the parameters of an LLM. The model is unable to precisely retrieve
    the initial knowledge, but still produces a pertinent output most of the times.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念层面来看，我喜欢将 LLM 与压缩算法进行类比。大量的互联网数据输入，经过许多浮点运算后，我们得到一个包含 LLM 参数的几百 GB 的文件。模型无法精确地检索初始知识，但大多数情况下仍然能产生相关的输出。
- en: '![](../Images/dbaf98a73c1b3f342cb9792dc0587ca1.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbaf98a73c1b3f342cb9792dc0587ca1.png)'
- en: Image by the author and DALL-E 3 (inspired by Karpathy’s [llmintro](https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view))
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者和 DALL-E 3 提供（灵感来源于 Karpathy 的 [llmintro](https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view)）
- en: The mystery of the LLMs does not reside in the technical architecture or the
    complexity of their computations. If the architecture of a model is fully documented,
    we can [*easily* follow](https://bbycroft.net/llm) the mathematical operations
    being performed. But we still cannot entirely explain how a precise set of parameters
    collaborate towards producing an output that makes sense. How is the knowledge
    from the initial training data actually retrieved? Where and how is it actually
    stored inside the network ?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 的神秘并不在于其技术架构或计算复杂性。如果一个模型的架构完全记录下来，我们可以 [*轻松* 跟踪](https://bbycroft.net/llm)
    进行的数学运算。但我们仍然无法完全解释一组精确的参数是如何协作产生一个有意义的输出的。最初的训练数据中的知识究竟是如何被提取的？它到底是在哪里以及如何在网络中存储的？
- en: LLM explainability is an active area of research and many interesting results
    have been published in the last year. I don’t pretend to be exhaustive in what
    I will be showing next. My purpose is to draw attention to some of the current
    research directions and some promising results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型的可解释性是一个活跃的研究领域，去年发布了许多有趣的结果。我不打算在接下来的内容中详尽无遗。我的目的是引起对一些当前研究方向和一些有前途结果的关注。
- en: 'To simplify things, I would distinguish between 4 main directions:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，我将区分四个主要方向：
- en: Explain the produced output based on the input (features attributions)
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据输入解释生成的输出（特征归因）
- en: Explain the produced output based on the training data
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据训练数据解释生成的输出
- en: Explain the role of individual neurons in embedding features
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释单个神经元在嵌入特征中的作用
- en: Extract explainable features from poly-semantic neurons
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从多义神经元中提取可解释的特征
- en: I will provide some examples from each category and links to the full papers
    for each example.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我将提供每个类别的一些示例，并链接到每个示例的完整论文。
- en: 1\. Explain the produced output based on the input
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 根据输入解释生成的输出
- en: 'The methods in this category rely on the computation of a measure of feature
    importance (or attribution) for each token in the input. Several [families of
    measures](https://arxiv.org/pdf/2302.13942.pdf) exists, mostly derived from the
    existing interpretablility methods in machine learning: gradient based, attention
    based, perturbation based (occlusion, LIME), etc.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这一类别中的方法依赖于计算输入中每个标记的特征重要性（或归因）度量。一些[度量家族](https://arxiv.org/pdf/2302.13942.pdf)存在，这些度量主要来源于现有的机器学习可解释性方法：基于梯度的、基于注意力的、基于扰动的（遮挡、LIME）等。
- en: 'You can test some of these importance measures yourself using the [Inseq](https://github.com/inseq-team/inseq)
    Python package. They provide support for the models in the [Transformers library](https://github.com/huggingface/transformers)
    and you can display your first results with just a few lines of code:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用[Inseq](https://github.com/inseq-team/inseq) Python包自行测试一些这些重要性度量。它们支持[Transformers库](https://github.com/huggingface/transformers)中的模型，你只需几行代码即可展示你的初步结果：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Features attributions rely on the computation of a matrix Aij representing the
    importance of every token i in the input for every generated token j in the output.
    Previously generated tokens influence following predictions, so they must be dynamically
    incorporated into the computations. From a computational point of view, these
    methods are still very accessible and can run in a notebook.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 特征归因依赖于计算矩阵Aij，表示输入中每个标记i对输出中每个生成标记j的重要性。先前生成的标记会影响后续的预测，因此必须动态地将它们纳入计算中。从计算的角度来看，这些方法仍然非常可访问，并且可以在笔记本中运行。
- en: The obtained output for the example given in the code snippet is shown bellow.
    From the values in the first column, we can see that the presence of the token
    *ladies* in the input was the most influential in the generation of the token
    *gentlemen* in the output.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 代码片段中给出的示例的输出结果如下所示。从第一列的值可以看出，输入中标记*ladies*的存在对生成输出中标记*gentlemen*的影响最大。
- en: '![](../Images/6bd786a1301533e535807225dff1d904.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6bd786a1301533e535807225dff1d904.png)'
- en: Image generated by the author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 作者生成的图像
- en: 'Another recent approach to obtain feature attributions was to ask the model
    itself to provide this information using prompt engineering. [Researchers at UC
    Santa Cruz](https://arxiv.org/pdf/2310.11207.pdf) asked ChatGPT to classify some
    movie reviews into either positive or negative and to also provide a feature importance
    measure for each token in the review. They have used the following prompt to get
    a nicely structured output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种获取特征归因的最近方法是使用提示工程让模型自己提供这些信息。[UC圣克鲁斯的研究人员](https://arxiv.org/pdf/2310.11207.pdf)让ChatGPT将一些电影评论分类为正面或负面，并为评论中的每个标记提供特征重要性度量。他们使用了以下提示来获取结构良好的输出：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ChatGPT replied using the requested format and [their analysis](https://arxiv.org/pdf/2310.11207.pdf)
    showed that when comparing the numbers directly provided by the model with those
    produced by more traditional explanation methods (occlusion, LIME saliency maps),
    the self explanations perform on par with the traditional ones. This seems promising
    since these explanations are computationally much cheaper to produce, but they
    still need more research before they can be fully trusted.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT按照请求的格式进行了回复，[他们的分析](https://arxiv.org/pdf/2310.11207.pdf)显示，当将模型直接提供的数字与传统解释方法（遮挡、LIME显著性图）生成的数字进行比较时，自我解释的效果与传统方法相当。这似乎很有前景，因为这些解释的计算成本要低得多，但在完全信任之前仍需更多研究。
- en: 2\. Explain the produced output based on the training data
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 基于训练数据解释生成的输出
- en: '[A recent research paper from Anthropic describes a computationally efficient
    way to use influence functions to study LLM generalization](https://arxiv.org/pdf/2308.03296.pdf).
    For a given prompt, they are capable to identify which sequences in the training
    data contribute the most in generating the output.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[最近的一篇来自Anthropic的研究论文描述了一种计算上高效的方法来使用影响函数研究LLM的泛化](https://arxiv.org/pdf/2308.03296.pdf)。对于给定的提示，他们能够识别训练数据中哪些序列在生成输出中贡献最大。'
- en: Their analysis shows that the larger the model, the more it is capable of concept
    generalization, and thus less likely to simply repeat sequences of tokens from
    the training data (they observe this behavior in the smaller model they use for
    comparison).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的分析显示，模型越大，它就越能进行概念泛化，因此不太可能仅仅重复训练数据中的序列（他们在用于比较的较小模型中观察到这种行为）。
- en: '![](../Images/83c75541487ed5008b3cdc2d2ae58d9c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83c75541487ed5008b3cdc2d2ae58d9c.png)'
- en: 'Image source: [2308.03296.pdf (arxiv.org)](https://arxiv.org/pdf/2308.03296.pdf)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [2308.03296.pdf (arxiv.org)](https://arxiv.org/pdf/2308.03296.pdf)'
- en: In this example they show that for large enough models the most influential
    sequences are conceptually related to the given prompt, but the contribution of
    each individual sequence is small and many training sequences contribute in the
    same time to produce the output. The lists of influential sequences can show considerable
    diversity, depending on the prompt.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，他们展示了对于足够大的模型，最具影响力的序列在概念上与给定的提示相关，但每个单独序列的贡献都很小，并且许多训练序列同时贡献以生成输出。影响力序列的列表可以显示出相当大的多样性，具体取决于提示。
- en: 3\. Explain the role of individual neurons in embedding features
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 解释单个神经元在嵌入特征中的作用
- en: 'Open AI tried [using an LLM to explain the activation patterns seen in the
    neurons of a smaller LLM](https://openai.com/research/language-models-can-explain-neurons-in-language-models).
    For each neuron in the GPT-2 XL model they used the following steps:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Open AI尝试了[使用LLM解释较小LLM中看到的激活模式](https://openai.com/research/language-models-can-explain-neurons-in-language-models)。对于GPT-2
    XL模型中的每个神经元，他们使用了以下步骤：
- en: Collect the output produced by the neuron’s activation function in response
    to a given set of text sequences
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集神经元激活函数对一组特定文本序列产生的输出
- en: Show the text sequences along with the neuron’s responses to GPT-4 and ask it
    to generate an explanation for the observed behavior
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示文本序列以及神经元对GPT-4的响应，并要求它生成对观察到的行为的解释
- en: Ask GPT-4 to simulate the activations of a neuron corresponding to the generated
    explanation
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请GPT-4模拟与生成的解释对应的神经元的激活
- en: Compare the simulated activations with the ones produced by the original GPT-2
    XL neuron
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较模拟激活与原始GPT-2 XL神经元产生的激活
- en: They compute a score based on the comparison between the simulated activations
    and the actual neuron behavior. They find confident explanations for approx 1000
    neurons out of the 307 200 neurons that GPT-2 XL has (corresponding to a score
    of at least 0.8). However, the average score computed across all the neurons only
    falls somewhere around 0.1\. You can explore some of their findings using the
    [Neuron Viewer](https://openaipublic.blob.core.windows.net/neuron-explainer/neuron-viewer/index.html#/)
    and you can contribute by proposing better explanations in case you feel inspired.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 他们基于模拟激活与实际神经元行为之间的比较计算得分。他们找到大约1000个神经元的自信解释，这些神经元是GPT-2 XL的307,200个神经元中的（对应于至少0.8的得分）。然而，所有神经元的平均得分仅在0.1左右。你可以使用[Neuron
    Viewer](https://openaipublic.blob.core.windows.net/neuron-explainer/neuron-viewer/index.html#/)探索他们的一些发现，如果你感到灵感迸发，还可以通过提出更好的解释来贡献力量。
- en: The low overall score can be attributed to the fact that most neurons exhibit
    complex behavior that is hard to describe using short natural language explanations
    (as GPT-4 was instructed to produce in the experiment). Most neurons seem to be
    highly poly-semantic or could even represent concepts that humans don’t have words
    for. The approach they propose is interesting but very computationally intensive,
    it relies on having readily available an LLM much larger than the one you are
    trying to explain and still does not bring us any closer to understanding the
    underlying mechanism that produces the observed behavior.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 低的总体评分可以归因于大多数神经元表现出复杂行为，这些行为很难用简短的自然语言解释来描述（正如实验中GPT-4被指示要做的那样）。大多数神经元似乎是高度多义的，甚至可能代表人类没有词汇的概念。他们提出的方法很有趣，但计算量非常大，它依赖于有一个比你试图解释的模型大得多的LLM，并且仍然没有使我们更接近理解产生观察到行为的基本机制。
- en: 4\. Extract explainable features from poly-semantic neurons
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 从多义神经元中提取可解释的特征
- en: As seen in the example before and in [previous research](https://distill.pub/2017/feature-visualization/)
    on [vision models](https://distill.pub/2020/circuits/zoom-in/), while mono-semantic
    neurons can sometimes be identified, most neurons in an LLM tend to be poly-semantic,
    meaning that they represent several different concepts or features at the same
    time. This phenomenon is called [superposition](https://transformer-circuits.pub/2022/toy_model/index.html)
    and it has been studied and reproduced in toy models by the researches at Anthropic.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前的示例和[先前研究](https://distill.pub/2017/feature-visualization/)中关于[视觉模型](https://distill.pub/2020/circuits/zoom-in/)所见，虽然单义神经元有时可以被识别，但LLM中的大多数神经元往往是多义的，这意味着它们同时表示多个不同的概念或特征。这种现象被称为[叠加](https://transformer-circuits.pub/2022/toy_model/index.html)，并且在Anthropic的研究人员通过玩具模型进行了研究和再现。
- en: 'They trained small neural networks on synthetic data composed of 5 features
    of different importance to investigate how and what gets represented when models
    have more features than they have dimensions. With dense features, the model learns
    to represent an orthogonal basis of the two most important features (similar to
    the Principal Component Analysis), and the other three features are not represented.
    But if the sparsity of the features increases, then more and more features get
    represented, at the cost of a small interference:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 他们在由5个不同重要性的特征组成的合成数据上训练了小型神经网络，以研究当模型具有比维度更多的特征时，如何以及什么被表示。对于密集特征，模型学习表示两个最重要特征的正交基（类似于主成分分析），而其他三个特征没有被表示。但如果特征的稀疏性增加，则越来越多的特征被表示，但代价是小的干扰：
- en: '![](../Images/6ce559eb31d7ad00fb5207544dad358e.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ce559eb31d7ad00fb5207544dad358e.png)'
- en: Image reproduced by the author using [https://colab.research.google.com/github/anthropics/toy-models-of-superposition/blob/main/toy_models.ipynb](https://colab.research.google.com/github/anthropics/toy-models-of-superposition/blob/main/toy_models.ipynb)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用[https://colab.research.google.com/github/anthropics/toy-models-of-superposition/blob/main/toy_models.ipynb](https://colab.research.google.com/github/anthropics/toy-models-of-superposition/blob/main/toy_models.ipynb)重制
- en: This mechanism could be also at play in LLMs since more concepts than neurons
    are present in the training data. Moreover, in the natural world, many features
    seem to be sparse (they only rarely occur) and they are not all equally useful
    to a given task. Under this hypothesis, our current LLMs can be interpreted as
    the projection onto a smaller space of a much larger LLM, for which each neuron
    is entirely mono semantic.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制在LLMs中也可能发挥作用，因为训练数据中存在的概念比神经元更多。此外，在自然世界中，许多特征似乎是稀疏的（它们很少出现），并且它们对特定任务的有用性并不相等。在这一假设下，我们当前的LLMs可以被解读为一个更大LLM的投影，在这个更大的LLM中，每个神经元完全是单义的。
- en: Based on this insight, the researchers at [Anthropic](https://www.anthropic.com/)
    devised a method to extract mono-semantic features from poly-semantic neurons
    using [sparse auto-encoders](https://transformer-circuits.pub/2023/monosemantic-features/index.html).
    They demonstrate their approach on a one-layer transformer with a 512-neuron MLP
    layer (Multi-Layer Perceptron). Using their method, the 512 MLP activations are
    decomposed into 4096 relatively interpretable features.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这一洞察，[Anthropic](https://www.anthropic.com/)的研究人员设计了一种方法，通过使用[sparse auto-encoders](https://transformer-circuits.pub/2023/monosemantic-features/index.html)从多义神经元中提取单义特征。他们在一个具有512神经元MLP层（多层感知器）的单层变压器上演示了他们的方法。使用他们的方法，512个MLP激活被分解为4096个相对可解释的特征。
- en: 'A [web interface](https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html)
    allows you to browse through the extracted features and judge for yourself. The
    features descriptions are generated post-analysis by [Claude](https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf?dm=1689034733).
    For instance, [feature no 9](https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html#feature-9)
    encodes for the Romanian language, with the top neurons activated by this feature
    corresponding to:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [网页界面](https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html)
    允许你浏览提取的特征并自行判断。这些特征的描述是在分析后由 [Claude](https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf?dm=1689034733)
    生成的。例如，[特征编号 9](https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html#feature-9)
    代表罗马尼亚语，该特征激活的主要神经元对应于：
- en: '[#257](https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html#feature-257):
    fires on content words (nouns, verbs, adjectives) from Romance languages (French,
    Spanish, Italian)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[#257](https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html#feature-257)：对浪漫语言（法语、西班牙语、意大利语）中的内容词（名词、动词、形容词）产生反应'
- en: '[#269](https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html#feature-269):
    fires on punctuation, particularly question marks, periods, hyphens, slashes,
    and parentheses'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[#269](https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html#feature-269)：对标点符号，特别是问号、句号、连字符、斜杠和括号产生反应'
- en: '[#86](https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html#feature-86):
    fires on words related to chemistry/medical contexts involving liquids'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[#86](https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html#feature-86)：对涉及液体的化学/医学背景的词语产生反应'
- en: The extracted feature are generally more interpretable than the neurons themselves.
    This is a very promising result, even if it is not clear yet if the approach can
    be scaled to larger models.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 提取的特征通常比神经元本身更具可解释性。这是一个非常有前景的结果，即使目前尚不清楚这种方法是否可以扩展到更大的模型。
- en: Conclusion
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: I hope this article provided examples of the some recent research directions
    in LLM explainability. Understanding exactly how LLMs work would allow us to fully
    trust their output and integrate them into more applications than we do today.
    Being able to easily check for the absence of bias would allow LLMs back into
    domains such as recruiting. Better understanding of their abilities and their
    limits would allow us to scale more efficiently, not just make them bigger and
    hope that it is enough. If you know of methods that look promising and that I
    have overlooked, please feel free to share them in the comments, I’d be happy
    to continue the exploration.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇文章提供了关于 LLM 可解释性的一些最新研究方向的示例。准确理解 LLM 的工作原理将使我们能够完全信任它们的输出，并将其整合到比现在更多的应用中。能够轻松检查是否存在偏见将使
    LLM 回到如招聘等领域。更好地理解它们的能力和限制将使我们能够更高效地扩展，而不仅仅是让它们变得更大并希望这足够。如果你知道一些看起来有前景而我可能忽略的方法，请随时在评论中分享，我很乐意继续探索。
- en: To keep reading about LLMs check out also this post about LLM jail-breaking
    and security
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续阅读有关 LLM 的内容，也可以查看这篇关于 LLM 破解与安全的文章
- en: '[](https://ai.gopubby.com/llm-safety-training-and-jail-breaking-57417f486d9f?source=post_page-----8f730fc73713--------------------------------)
    [## LLM Safety Training and Jail-Breaking'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ai.gopubby.com/llm-safety-training-and-jail-breaking-57417f486d9f?source=post_page-----8f730fc73713--------------------------------)
    [## LLM 安全培训与破解'
- en: Since ChatGPT brought LLMs into the spotlight, we witnessed the cat and mouse
    game between LLM developers trying to…
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自从 ChatGPT 将大型语言模型（LLMs）推向公众视野以来，我们目睹了 LLM 开发者之间的猫捉老鼠游戏，他们试图…
- en: ai.gopubby.com](https://ai.gopubby.com/llm-safety-training-and-jail-breaking-57417f486d9f?source=post_page-----8f730fc73713--------------------------------)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ai.gopubby.com](https://ai.gopubby.com/llm-safety-training-and-jail-breaking-57417f486d9f?source=post_page-----8f730fc73713--------------------------------)
