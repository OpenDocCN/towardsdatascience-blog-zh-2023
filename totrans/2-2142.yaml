- en: Training XGBoost with MLflow Experiments and HyperOpt Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/training-xgboost-with-mlflow-experiments-and-hyperopt-c0d3a4994ea6](https://towardsdatascience.com/training-xgboost-with-mlflow-experiments-and-hyperopt-c0d3a4994ea6)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A starting point on your MLOps Journey
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://animadurkar.medium.com/?source=post_page-----c0d3a4994ea6--------------------------------)[![Ani
    Madurkar](../Images/ad54a9e110c56ba1f4c7f5ce0bc7d7e4.png)](https://animadurkar.medium.com/?source=post_page-----c0d3a4994ea6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c0d3a4994ea6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c0d3a4994ea6--------------------------------)
    [Ani Madurkar](https://animadurkar.medium.com/?source=post_page-----c0d3a4994ea6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c0d3a4994ea6--------------------------------)
    ·10 min read·Jan 9, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2a9a554a515ef56cb3a1694c3f067a09.png)'
  prefs: []
  type: TYPE_IMG
- en: Colors of the Adirondacks. Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you evolve in your journey in Machine Learning, you’ll soon find yourself
    gravitating closer and closer to MLOps whether you like it or not. Building efficient,
    scalable, and resilient machine learning systems is a challenge and the real job
    of a Data Scientist (in my opinion) as opposed to just doing modeling.
  prefs: []
  type: TYPE_NORMAL
- en: The modeling part has been largely figured out for most use cases. Unless you’re
    trying to be at the bleeding edge of the craft, you’re likely dealing with structured,
    tabular datasets. The choice of model can vary depending on the dataset size,
    assumptions, and technical restrictions, but for the most part, it is fairly repeatable.
    My workflow for supervised learning ML during the experimentation phase has converged
    to using XGBoost with HyperOpt and MLflow. XGBoost for the model of choice, HyperOpt
    for the hyperparameter tuning, and MLflow for the experimentation and tracking.
  prefs: []
  type: TYPE_NORMAL
- en: This also represents a phenomenal step 1 as you embark on the MLOps journey
    because I think it’s easiest to start doing more MLOps work during the experimentation
    phase (model tracking, versioning, registry, etc.). It’s lightweight and highly
    configurable which makes it easy to scale up and down as you may need.
  prefs: []
  type: TYPE_NORMAL
- en: Although I briefly discuss XGBoost, MLflow, and HyperOpt, this isn’t a deep
    walkthrough of each. Initial hands-on familiarity with each would be really helpful
    to understand how some pieces here are working in more depth. I’ll be working
    with the [UCI ML Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))
    dataset (CC BY 4.0).
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, we can start an MLflow server (I discuss what’s happening here a
    bit later):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/32d6510bee78e8781f1a1cca2df01d53.png)'
  prefs: []
  type: TYPE_IMG
- en: PandasProfiler is a fantastic open-source library to run a quick exploratory
    data analysis report on a dataset. Tracking descriptive statistics, finding nulls,
    anomaly detection, distribution analysis, and more are all shown in the report.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/445ae919f9967e0e325a84959a0a6fa4.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample view of the HTML Profiler output
  prefs: []
  type: TYPE_NORMAL
- en: 'I save the file as an HTML to interact with the analysis on a webpage instead
    of in a Jupyter Notebook which could yield memory errors depending on dataset
    size. See the Quickstart guide here for how PandasProfiler works: [https://pandas-profiling.ydata.ai/docs/master/pages/getting_started/quickstart.html](https://pandas-profiling.ydata.ai/docs/master/pages/getting_started/quickstart.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we can create training, validation, and testing datasets.
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: XGBoost, eXtreme Gradient Boosted Decision Trees, has become the de facto model
    of choice for a large number of tabular modeling tasks. It’s still highly recommended
    to try out simpler models like Linear/Logistic Regression first but almost all
    structured tabular modeling projects with >50–100K rows have resulted in these
    models winning out by a significant margin.
  prefs: []
  type: TYPE_NORMAL
- en: '*How do they work?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'XGBoost is an open-source, gradient-boosting algorithm that uses decision trees
    as weak learners to build up a stronger model — considered an ensemble model due
    to its nature to combine multiple models together. There are two common ensemble
    methods: Bagging and Boosting.'
  prefs: []
  type: TYPE_NORMAL
- en: Bagging, or bootstrap aggregating, typically is low variance but can be high
    bias. It can lead to better training stability, stronger ML accuracy, and a lower
    tendency to overfit. Random Forest models leverage bagging by combining decision
    trees where each tree can pick only from a random subset of features to use.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ca92faa8e5ad1f15492301360bf873db.png)'
  prefs: []
  type: TYPE_IMG
- en: An illustration of the concept of bootstrap aggregating. Open Domain, [Wikipedia](https://en.wikipedia.org/wiki/Bootstrap_aggregating)
  prefs: []
  type: TYPE_NORMAL
- en: Boosting, in contrast, works to convert weak learners to strong ones. Each learner,
    or model, is trained on the same set of samples but each sample is weighted differently
    in each iteration. This results in weak learners getting better at learning the
    right weights and parameters for strong model performance over time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b88b1428e42970815abcfa43f2472d4.png)'
  prefs: []
  type: TYPE_IMG
- en: An illustration of the concept of boosting. Open Domain, [Wikipedia](https://commons.wikimedia.org/wiki/File:Ensemble_Boosting.svg)
  prefs: []
  type: TYPE_NORMAL
- en: The gradient boosting part of this algorithm refers to the fact it uses [Gradient
    Descent](https://en.wikipedia.org/wiki/Gradient_descent) to minimize the loss
    function. The loss function for XGBoost is a regularised (L1 and L2) objective
    function that incorporates a function of convex loss and a model complexity penalty
    term.
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost took fame as it became the standard for winning a multitude of tournaments
    on Kaggle, but lately, people have also used Microsoft’s LightGBM as it can be
    faster for large datasets. I’ve typically found phenomenal performance using both
    — can just be dependent on your needs.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mlflow is an open-source machine learning experiment tracking software. It makes
    it incredibly easy to spin up a local web interface to monitor your machine learning
    models, compare them, and stage them.
  prefs: []
  type: TYPE_NORMAL
- en: As you’re experimenting between the right modeling algorithm and architecture,
    it can be a nightmare to efficiently evaluate the best one especially when you’re
    running hundreds of experiments at once. Ideally, you want a way to store each
    model run, its hyperparameters, its evaluation criteria, and more. MLflow makes
    this all possible with minimal code around your training code.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you experiment with different modeling architectures you can add new experiments
    and compare each one with the same criteria. Logging artifacts is extremely easy
    and fast. There are two main components that it looks to track and store: entities
    and artifacts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Entities: runs, parameters, metrics, tags, notes, metadata, etc. These are
    stored in the backend store.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Artifacts: files, models, images, in-memory objects, or model summaries, etc.
    These are stored in the artifact store.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The default storage location for these are local files, but you can specify
    the backend store to instead be an SQLite database (this is minimally needed if
    you want to stage models to Staging or Production), a PostgreSQL database (this
    enables user authentication to access), or an S3 database. This page clarifies
    the different store configurations really well: [https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded)'
  prefs: []
  type: TYPE_NORMAL
- en: 'I won’t be going into the basics of how to use MLflow because their documentation
    covers a lot of what you’d need already. In case you need a quick tutorial for
    how to spin up MLflow, I highly recommend starting here: [https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html](https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html)'
  prefs: []
  type: TYPE_NORMAL
- en: I will be leveraging a lightweight architecture that is independent of the cloud
    but know that as long as you have read/write access to an S3 bucket it’s as easy
    as signing into your AWS credentials and then changing the bucket store path.
    I’ll also be enabling a TrackingServer that connects to the runs and artifacts
    via REST API so you’re able to see the results on a website.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5916b4278eabc07004f6039365305ac2.png)'
  prefs: []
  type: TYPE_IMG
- en: MLflow on localhost with Tracking Server architecture. Adapted from [MLflow
    documentation](https://mlflow.org/docs/latest/tracking.html#scenario-3-mlflow-on-localhost-with-tracking-server).
  prefs: []
  type: TYPE_NORMAL
- en: HyperOpt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HyperOpt is an open source for Bayesian optimization to find the right model
    architecture. It is designed for large-scale optimization for models with hundreds
    of parameters and allows the optimization procedure to be scaled across multiple
    cores and multiple machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The different algorithms it can leverage are:'
  prefs: []
  type: TYPE_NORMAL
- en: Random Search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tree of Parzen Estimators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annealing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaussian Process Tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most hyperparameter tuning I see done in practice is either manual or Grid Search.
    This exhaustive process can sometimes yield good results but often times it’s
    highly expensive (computing & time) and unneeded. What’s more, is that Grid Search
    doesn’t selectively use hyperparameters that are better or worse to find the global
    minima for your loss function. It simply searches your entire search space.
  prefs: []
  type: TYPE_NORMAL
- en: Random Search is often better as a baseline as it can be faster and still provide
    good enough starting points to filter your search space down. A more optimal method
    is Bayesian Optimization though. This is because Bayesian Optimization takes into
    account the prior runs in iteration to guide future selections. Bayesian Optimization
    creates a probabilistic distribution of our hyperparameter space to traverse and
    attempts to find the hyperparameters that minimize our loss function the best.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Tree of Parzen Estimators is a great default I’ve found, but here’s a paper
    that dives deeper into each of the algorithms: [Algorithms for Hyper-Parameter
    Optimization](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)
    (Bergstra, et al.). It typically outperforms basic Bayesian Optimization as it
    leverages a tree structure to better traverse complex search spaces which includes
    categorical hyperparameters whereas Bayesian Optimization requires numerical values.
    Tree of Parzen Estimators has been found to be extremely robust and efficient
    for large-scale hyperparameter optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Michael Berk has written a phenomenal writeup on HyperOpt and its algorithms
    if you’re interested in a deeper dive: [HyperOpt Demystified](/hyperopt-demystified-3e14006eb6fa).'
  prefs: []
  type: TYPE_NORMAL
- en: All Together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'HyperOpt’s fmin function takes in the key components of putting all of this
    together. Here are some key parameters of fmin:'
  prefs: []
  type: TYPE_NORMAL
- en: 'fn: training model function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'space: hyperparameter search space'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'algo: optimization algorithm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'trials: an object can be saved, passed on to the built-in plotting routines,
    or analyzed with your own custom code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'max_evals: number of modeling experiments to run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HyperOpt’s trials object helps us see a bit more of why you’d return a dictionary
    from the training function.
  prefs: []
  type: TYPE_NORMAL
- en: '`trials.trials` - a list of dictionaries representing everything about the
    search'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trials.results` - a list of dictionaries returned by ''objective'' during
    the search'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trials.losses()` - a list of losses (float for each ''ok'' trial)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trials.statuses()` - a list of status strings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another thing to note in the return of the training function is that is where
    you define the loss function (can be custom if you choose). It defaults to minimize
    that metric so if you want to maximize it, as we do with ROC AUC Score, then multiply
    it by -1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b93e0f4eca4d2959bd89e6ff816f2d64.png)'
  prefs: []
  type: TYPE_IMG
- en: MLflow UI for analyzing ML experiments
  prefs: []
  type: TYPE_NORMAL
- en: We can see all the 50 modeling experiments ran with trying to find the XGBoost
    model with the highest validation ROC AUC score as it searches the hyperparameter
    space. We can easily filter the columns to see different parameters or metrics
    and change how we sort to rapidly analyze the results.
  prefs: []
  type: TYPE_NORMAL
- en: Model Evaluation & Registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s compare the top two modeling results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8936dee96706e80ffd79b728dfb72386.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparing the top two modeling results
  prefs: []
  type: TYPE_NORMAL
- en: We can choose different parameters and metrics to analyze via a Parallel Coordinates
    Plot, Scatter Plot, Box Plot, and Contour Plot to gauge how changes in parameters
    affect the metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, we can click on one run to see all the artifacts of the model saved
    of it and some code snippets to make predictions from this run.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4c5f3f397cf79670ae44eabca777d38.png)'
  prefs: []
  type: TYPE_IMG
- en: Details of best model run
  prefs: []
  type: TYPE_NORMAL
- en: We can now load in the best model to evaluate the model on the test set before
    we register it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Looks great! We can now register the model into the Model Registry like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s update some information such as the description and the version information
    of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Once we know we want to push the model to production, we can do this step easily
    in MLflow as well. One [very] important thing to note here is that MLflow doesn’t
    have great proxy controls for this which is very much not the recommended approach
    — you don’t want just anyone to be able to push the model up to production. I’ve
    typically found the Staging and Production environments for modeling live in different
    areas (ie. Cloud) so you can manage permissions and access better.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: What’s the value of pushing to Production here? Keep in mind this is version
    1 of our experimentation phase, which happened to perform great. Over time we
    may acquire more data or better knowledge of what modeling techniques could beat
    our version 1 model. When that happens and we run a second experiment, we can
    evaluate the second modeling experiment results with our model in production and
    then gauge whether to replace it or not. This is when we would want to leverage
    the “Staging” region between “None” and “Production”.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this story we started with UCI ML Breast Cancer Wisconsin (Diagnostic) dataset
    and showed a standard structured, tabular supervised learning machine learning
    workflow (for a simple dataset) that leveraged:'
  prefs: []
  type: TYPE_NORMAL
- en: PandasProfiler for creating an Exploratory Data Analysis report
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sci-kit Learn for preprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XGBoost for model training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HyperOpt for hyperparameter tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MLflow for experiment tracking, model evaluation, model logging/versioning,
    and model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hope this helps you jumpstart your journey into the MLOps world and levels up
    your machine learning workflows!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic))
    (Wolberg, Street, Mangasarian)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Designing Machine Learning Systems](https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/)
    (Huyen)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [MLflow](https://mlflow.org/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] [HyperOpt](http://hyperopt.github.io/hyperopt/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] [HyperOpt Demystified](/hyperopt-demystified-3e14006eb6fa) (Berk)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] [Algorithms for Hyper-Parameter Optimization](https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf)
    (Bergstra et al.)'
  prefs: []
  type: TYPE_NORMAL
- en: All images unless otherwise noted are by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Become a Medium Member with my Referral Link
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Medium is a large repository of where I do my daily reading, and if you’re
    in the data space, this platform is a gold mine. If you wish to subscribe, here’s
    my referral link to sign up. Full disclosure: if you use this link to subscribe
    to Medium, a portion of your subscription fee will go directly to me. Would love
    to have you be a part of our community.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://animadurkar.medium.com/membership?source=post_page-----c0d3a4994ea6--------------------------------)
    [## Join Medium with my referral link - Ani Madurkar'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Ani Madurkar (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: animadurkar.medium.com](https://animadurkar.medium.com/membership?source=post_page-----c0d3a4994ea6--------------------------------)
  prefs: []
  type: TYPE_NORMAL
