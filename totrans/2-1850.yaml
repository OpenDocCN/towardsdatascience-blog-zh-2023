- en: Siamese Neural Networks with Triplet Loss and Cosine Distance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/siamese-neural-networks-with-tensorflow-functional-api-6aef1002c4e](https://towardsdatascience.com/siamese-neural-networks-with-tensorflow-functional-api-6aef1002c4e)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Theory & Code-along: Triplet loss with cosine distance for Siamese Networks
    on CIFAR-10 dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tanpengshi.medium.com/?source=post_page-----6aef1002c4e--------------------------------)[![Tan
    Pengshi Alvin](../Images/449d736eed966b01715f87c6269c88a5.png)](https://tanpengshi.medium.com/?source=post_page-----6aef1002c4e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6aef1002c4e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6aef1002c4e--------------------------------)
    [Tan Pengshi Alvin](https://tanpengshi.medium.com/?source=post_page-----6aef1002c4e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6aef1002c4e--------------------------------)
    ·11 min read·May 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f7edeabf5d107ac8fe08ae568bf787fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Alex Meier](https://unsplash.com/@alexmeier19) on [Unsplash](https://unsplash.com/)
  prefs: []
  type: TYPE_NORMAL
- en: What if we could encode every object image (human faces, etc) into a template
    — a vector of numbers? Thereafter, we could objectively determine the similarity
    between objects by numerically comparing — finding the distances — between their
    templates. In deep learning, this is exactly what the Siamese Neural Networks
    hope to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: The Siamese Neural Networks are basically models that, upon training, generate
    distinct feature vectors (templates) for each input object. Although these models
    are typically adopted in templating object images (Computer Vision) generally
    speaking, they may also be employed for text and sound data.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from security authentication, such as facial recognition and signature
    comparisons, Siamese Neural Networks are also commonly used in E-Commerce platforms
    to measure product similarity. For instance, some E-Commerce platforms allow you
    can search for similar products by uploading an image of an object you are looking
    for. On Kaggle, there is even a [Product Matching competition](https://www.kaggle.com/competitions/shopee-product-matching)
    by Shopee, a leading E-Commerce company in South-East Asia.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will explore a common data set in Tensorflow — the CIFAR-10
    — that bears some semblance to the problem of product similarity search, except
    that the objects of interest are automobiles — cars, planes, trucks, ships, etc
    — and animals (or pets if you like!) — cats, dogs, horses, birds, deers, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin, we have to first understand the theory behind Siamese Neural
    Network. Thereafter we will explore the codes for training and evaluating a simple
    Siamese Neural Network on the CIFAR-10 data set.
  prefs: []
  type: TYPE_NORMAL
- en: Ready? Let’s start!
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Theory of Siamese Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I have to admit the cover image in this article is a little misleading — the
    word ‘Siamese’ in fact does not come from the ‘Siamese Cat’. Rather it comes from
    the ‘Siamese Twins’, or conjoined twins — twins who are conjoined in one part
    of the body.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, the Siamese Neural Networks basically mean twin neural networks, that
    are typically conjoined at the end — the Lambda layer, as we will see — before
    feeding the model output to the loss function. During the training of these twin
    networks, their weights are exactly the same between them during the initialization,
    forward propagation and backpropagation process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we are generally working with images, each body of twin neural networks
    is typically a Convolutional Neural Network (CNN). If you are unfamiliar with
    CNN or need to refresh your idea, I have an excellent article about it here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/mlearning-ai/transfer-learning-and-convolutional-neural-networks-cnn-e68db4c48cca?source=post_page-----6aef1002c4e--------------------------------)
    [## Transfer Learning and Convolutional Neural Networks (CNN)'
  prefs: []
  type: TYPE_NORMAL
- en: A complete guide from CNN to Transfer Learning for Kaggle’s Cat versus Dog dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/mlearning-ai/transfer-learning-and-convolutional-neural-networks-cnn-e68db4c48cca?source=post_page-----6aef1002c4e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'With this idea in mind, we will introduce 2 common types of Siamese Neural
    Networks:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Contrastive Loss Siamese Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first type is the Siamese Neural Networks based on calculating the Euclidean/Cosine
    distance between the embedding layers — the feature vectors — of twin CNNs, before
    comparing with the ground truths (1:Match, 0:Non-Match) to determine the Contrastive
    Loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is an illustration of such a model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e001a974af5e4778941f59fd76f5f89.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Contrastive Loss Siamese Neural Networks. Image adapted from the
    [SigNet paper](https://arxiv.org/abs/1707.02131).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/015d8860b253b9a015f19bee792f0457.png)'
  prefs: []
  type: TYPE_IMG
- en: Contrastive Loss formula with Euclidean Distance, where Y is the ground truth.
    Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Triplet Loss Siamese Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second type of Siamese Neural Networks is based on calculating the 2 Euclidean/Cosine
    distances among the embedding layers (feature vectors) — between the Anchor and
    Positive Image, and between the Anchor and Negative Image — of triplet CNNs, and
    then computing the Triplet Loss completely in the Lambda layer, without comparing
    with any ground truths.
  prefs: []
  type: TYPE_NORMAL
- en: Because research has shown that this Triplet Loss model is generally more robust
    than the Contrastive Loss model, we will focus on this type of Siamese Network
    in this article.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is an illustration of such a model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bde0ccaf7d7f9105aa30b78ea33aa7d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of Triplet Loss Siamese Neural Networks. Image adapted from the [SigNet
    paper](https://arxiv.org/abs/1707.02131).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aba68b6d5df33a9376c706b60e1f0f2f.png)'
  prefs: []
  type: TYPE_IMG
- en: Triplet Loss formula with Euclidean Distance, where A is the Anchor image input,
    P is the Positive image input and N is the Negative image input. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 The Goal of Siamese Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we have seen the approximate architectures of the Siamese Neural Networks.
    But upon the training of the networks, what are we intending to achieve here?
    Let’s take a look at the illustration below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3bbad849a2fd6a9ff5e1ff3a8b828c29.png)'
  prefs: []
  type: TYPE_IMG
- en: Training of Siamese Networks reduces distances between similar images while
    increasing distance between dissimilar images. Image by the [FaceNet paper](https://arxiv.org/abs/1503.03832).
  prefs: []
  type: TYPE_NORMAL
- en: We see that the Siamese Networks are learning to recreate similar feature vectors
    between images of the same class. As such, after training, the distances between
    similar images’ templates will decrease, while that between dissimilar images’
    templates will increase.
  prefs: []
  type: TYPE_NORMAL
- en: With that being said, it is important to cover as many classes of images as
    possible during training, such that the model may also generalize to unseen classes
    (signatures, faces, etc).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, during model evaluation, we are chiefly concerned with generating templates
    of input image data. Hence, only a single CNN network or body of the twins/triplet
    networks is extracted, without the Lambda layer, when running template inference.
  prefs: []
  type: TYPE_NORMAL
- en: 1.4 Euclidean Distance versus Cosine Distance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we move to coding, let us first differentiate between 2 common vector
    distance metric — the Euclidean distance and the Cosine Distance. So far in the
    above illustration, we have shown the Euclidean distance, because it is more intuitive
    to understand, but not necessarily more superior to the Cosine distance in building
    a better model. Let’s illustrate below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9d78ba9342a646db79e9681c87655878.png)'
  prefs: []
  type: TYPE_IMG
- en: The illustration of the Euclidean Distance and Cosine Distance between two vectors
    in a 2-D space. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the above, it is clear that the Euclidean distance is simply the ‘coordinate
    distance’ between 2 feature vectors, while the Cosine distance is one measure
    of the ‘angular distance’ between them. Hence, when 2 feature vectors are oriented
    far apart, we can see both Euclidean distance and Cosine distance are similarly
    huge. But there is a subtle difference and let’s see below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1fe1655927f5b4b0bc6fff6bde06f9f6.png)'
  prefs: []
  type: TYPE_IMG
- en: A comparison between Euclidean Distance and Cosine distance at small angles
    but with difference in vector length. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: While the Cosine distance measures only the angular difference between feature
    vectors, the Euclidean distance measures a second dimension — length difference.
    As such, while more intuitive, the Euclidean distance is inherently a more complex
    metric than the Cosine distance.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, both the Euclidean and Cosine distance are widely used,
    and the choice largely depends on empirical exploration. Nonetheless, for a smaller
    data set and dedicated number of classes, adopting the Cosine distance in the
    loss function could be a better choice, and that is what we would be doing for
    our CIFAR-10 data set.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Siamese Networks Code-Along
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let’s get our hands dirty with coding. We will adopt engineering the Triplet
    Loss Siamese Networks on the TensorFlow CIFAR-10 data set. We will base our Triplet
    Loss on the Cosine Distance, and then during the evaluation of test set, compare
    test images using Angular Similarity.
  prefs: []
  type: TYPE_NORMAL
- en: '***Note****: Angular Similarity is used, as it is based on Cosine Distance,
    except that the values are scaled between 0% to 100%.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9e537dbfa4d172e7258b836ed56ba068.png)'
  prefs: []
  type: TYPE_IMG
- en: The formula for Angular Similarity. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Also note that in the model initialization process, we would be adopting the
    TensorFlow Functional API (contrast with the Sequential API we used in the Transfer
    Learning and CNN article introduced earlier), together custom Lambda layer and
    a custom loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Without further hesitation, let’s dive into coding!
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Exploring the CIFAR-10 Data Set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/16cfa2b5ba4012be50c9d9f780b74180.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/61f9aced5df9e6b84789b1650cb2fb91.png)![](../Images/f22b68b08fe4799a91f041d0a31d8e70.png)![](../Images/6fea6756284b4263f056c09e83ed2cf4.png)![](../Images/e51b0c6f3c4b4efa4de8607be1874f2a.png)![](../Images/7157ca6350aeea8a0754b141e91e8237.png)![](../Images/2b39b23b9cd20ebaadcb917ce4d71c46.png)![](../Images/9b7925eed02a4a44dd085d1e0974cefe.png)![](../Images/a23fa14d32c333e2d635cbcf3b39bce4.png)![](../Images/62b8c3a47e98cedffdc78457504ad164.png)![](../Images/cb05639963bc4428bf686a7b120ee594.png)'
  prefs: []
  type: TYPE_IMG
- en: 2.2 Generating Triplets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ecf346bb3cdf61eabc733d4ca1a25593.png)'
  prefs: []
  type: TYPE_IMG
- en: 2.3 Preparing for Model Training/Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 2.4 Model Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f8b519f71d1c4b015ad3f10971c9dcc6.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1ba077aa358af2dca12e061686fede13.png)'
  prefs: []
  type: TYPE_IMG
- en: 2.5 Model Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/086464d89072204c0ac1bed23d6e7143.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/20d182345f5be7ff10a3d3df96a5f514.png)![](../Images/f760b286cc30a620c19bfa8e28d8c02f.png)'
  prefs: []
  type: TYPE_IMG
- en: 3\. Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations on completing the theory and code-along! I hope this tutorial
    has provided an all-around useful introduction to Siamese Networks and their application
    to object similarity.
  prefs: []
  type: TYPE_NORMAL
- en: Before we end, I should also add that how the object similarity scores are processed
    depends on the problem statement.
  prefs: []
  type: TYPE_NORMAL
- en: If we are doing a 1:1 object comparison during production (whether 2 objects
    are similar or different), then usually a similarity threshold must be set based
    on the level of False Match Rate (FMR) at test time. On the other hand, if we
    are doing 1:N object matching, then usually the objects with the highest similarity
    scores are returned and ranked.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: For the complete codes, check out my* [*GitHub*](https://github.com/tanpengshi/Siamese_Networks_Triplet_Loss_Cosine_Distance)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, I thank you for your time and hope you enjoyed this tutorial. I
    would also like to end off by introducing you to an extremely important topic
    of [data-centric machine learning](https://landing.ai/data-centric-ai/) that is
    elaborated on in this article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pub.towardsai.net/data-collection-and-augmentation-strategy-for-artificial-intelligence-37eacc49129f?source=post_page-----6aef1002c4e--------------------------------)
    [## Data-Centric AI — Data Collection and Augmentation Strategy'
  prefs: []
  type: TYPE_NORMAL
- en: A comprehensive guide to data generation strategy for data-centric Machine Learning
    projects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pub.towardsai.net](https://pub.towardsai.net/data-collection-and-augmentation-strategy-for-artificial-intelligence-37eacc49129f?source=post_page-----6aef1002c4e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading! If you have enjoyed the content, pop by my other articles
    on [Medium](https://tanpengshi.medium.com/) and follow me on [LinkedIn](https://www.linkedin.com/in/tanpengshi/).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***Support me!*** — If you are *not* subscribed to Medium, and like my content,
    do consider supporting me by joining Medium via my [referral link](https://tanpengshi.medium.com/membership).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://tanpengshi.medium.com/membership?source=post_page-----6aef1002c4e--------------------------------)
    [## Join Medium with my referral link - Tan Pengshi Alvin'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Tan Pengshi Alvin (and thousands of other writers on Medium).
    Your membership fee directly…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: tanpengshi.medium.com](https://tanpengshi.medium.com/membership?source=post_page-----6aef1002c4e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
