- en: 'Machine Learning, Illustrated: Opening Black Box Models with SHAP'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的可视化：用SHAP揭开黑箱模型的面纱
- en: 原文：[https://towardsdatascience.com/machine-learning-illustrated-opening-black-box-models-with-shap-9e92d0400680](https://towardsdatascience.com/machine-learning-illustrated-opening-black-box-models-with-shap-9e92d0400680)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/machine-learning-illustrated-opening-black-box-models-with-shap-9e92d0400680](https://towardsdatascience.com/machine-learning-illustrated-opening-black-box-models-with-shap-9e92d0400680)
- en: How to interpret and explain any machine learning model using SHAP
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 SHAP 解释和解读任何机器学习模型
- en: '[](https://medium.com/@shreya.rao?source=post_page-----9e92d0400680--------------------------------)[![Shreya
    Rao](../Images/03f13be6f5f67783d32f0798f09a4f86.png)](https://medium.com/@shreya.rao?source=post_page-----9e92d0400680--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e92d0400680--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e92d0400680--------------------------------)
    [Shreya Rao](https://medium.com/@shreya.rao?source=post_page-----9e92d0400680--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@shreya.rao?source=post_page-----9e92d0400680--------------------------------)[![Shreya
    Rao](../Images/03f13be6f5f67783d32f0798f09a4f86.png)](https://medium.com/@shreya.rao?source=post_page-----9e92d0400680--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e92d0400680--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e92d0400680--------------------------------)
    [Shreya Rao](https://medium.com/@shreya.rao?source=post_page-----9e92d0400680--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e92d0400680--------------------------------)
    ·10 min read·May 8, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e92d0400680--------------------------------)
    ·10分钟阅读·2023年5月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Shapley Values is a concept derived from cooperative game theory in Economics
    that assigns a value to each player in a cooperative game based on their contributions
    to the game. In the field of machine learning, this concept has been adapted into
    the SHAP (SHapley Additive exPlanations) framework, which is an effective technique
    for interpreting the workings of a model.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley Values 是经济学中合作博弈论的一个概念，它根据每个参与者对博弈的贡献为每个玩家分配一个价值。在机器学习领域，这一概念被适配成了 SHAP（SHapley
    Additive exPlanations）框架，这是一种有效的模型解释技术。
- en: If you’re interested in learning more about Shapley Values, I highly recommend
    checking out my [previous article](https://medium.com/@shreya.rao/economics-illustrated-shapley-values-7d33df43ada8)
    on the math and intuition behind Shapley Values. Even though it’s been modified
    for machine learning purposes, understanding its underlying principles can be
    helpful.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣深入了解 Shapley Values，我强烈推荐阅读我之前的[文章](https://medium.com/@shreya.rao/economics-illustrated-shapley-values-7d33df43ada8)以了解
    Shapley Values 背后的数学和直觉。尽管它已被修改以适应机器学习的需求，但理解其基本原理仍然是有帮助的。
- en: '[](https://medium.com/@shreya.rao/economics-illustrated-shapley-values-7d33df43ada8?source=post_page-----9e92d0400680--------------------------------)
    [## Economics, Illustrated: Shapley Values'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@shreya.rao/economics-illustrated-shapley-values-7d33df43ada8?source=post_page-----9e92d0400680--------------------------------)
    [## 经济学插图：Shapley Values'
- en: Shapley Values is a widely-used concept in game theory that provides a fair
    way to distribute the total payoff of a…
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Shapley Values 是博弈论中广泛使用的概念，它提供了一种公平的方式来分配总收益。
- en: medium.com](https://medium.com/@shreya.rao/economics-illustrated-shapley-values-7d33df43ada8?source=post_page-----9e92d0400680--------------------------------)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@shreya.rao/economics-illustrated-shapley-values-7d33df43ada8?source=post_page-----9e92d0400680--------------------------------)'
- en: The SHAP framework is similar to Shapley Values in that it calculates the individual
    impact of features in a game (aka a machine learning model). However, machine
    learning models are non-cooperative games, which means that features don’t necessarily
    interact with each other as they do in cooperative games. Instead, each feature
    contributes independently to the model’s output. While the Shapley Values formula
    can be used, it can be computationally expensive and inaccurate due to the large
    number of players and coalitions involved. To solve this problem, researchers
    have developed alternative methods such as the Monte Carlo method and kernel-based
    methods. In this article, we will delve deeper into the Monte Carlo method.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP框架类似于Shapley值，因为它计算了特征在一个游戏（即机器学习模型）中的单独影响。然而，机器学习模型是非合作性的游戏，这意味着特征之间不一定像在合作游戏中那样相互作用。相反，每个特征独立地贡献于模型的输出。虽然Shapley值公式可以使用，但由于参与者和联盟的数量众多，它可能在计算上非常昂贵且不准确。为了解决这个问题，研究人员开发了替代方法，如蒙特卡洛方法和基于核的方法。在本文中，我们将深入探讨蒙特卡洛方法。
- en: Let’s set this up with an example. Say we have a [dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)
    of the prices of 20,640 houses in California.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来设置。假设我们有一个[数据集](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)，包含20,640栋加州房屋的价格。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will use the features *MedInc, HouseAge, AveRooms, Latitude,* and *Longitude*
    (**X**)…
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用特征*MedInc, HouseAge, AveRooms, Latitude,* 和 *Longitude*（**X**）……
- en: '![](../Images/d9e9aa728c9b1f047e2360235dfee519.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9e9aa728c9b1f047e2360235dfee519.png)'
- en: '…to predict the price of a house (**y**). *Note: The house prices are expressed
    in $100,000.*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: …预测房价（**y**）。*注意：房价以$100,000为单位表示。*
- en: Let’s build a model. This can be any model but we’ll use XGBoost (read my [previous
    article](/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb) to learn
    the math behind XGBoost). Following the standard steps — divide the data into
    train and test sets and train the model with the train set.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将建立一个模型。这可以是任何模型，但我们将使用XGBoost（阅读我的[上一篇文章](/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb)以了解XGBoost背后的数学）。按照标准步骤——将数据分为训练集和测试集，并用训练集训练模型。
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then use this model to make predictions on the test set.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用这个模型对测试集进行预测。
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s break this down further. We want the predicted house price of the first
    sample (or house) in our test set. So for the first sample with these feature
    values…
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步分解。我们想要测试集中第一个样本（或房子）的预测房价。所以对于第一个样本，这些特征值是……
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '…the predicted house price is:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: …预测的房价是：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/8d031456937a9971920a73371b7570b4.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d031456937a9971920a73371b7570b4.png)'
- en: 'The prediction made by XGBoost seems mysterious as it is a black-box model
    so we don''t see what’s happening inside the **box**. To gain more insight into
    how the value was predicted, there are two things we need to understand:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost做出的预测显得神秘，因为它是一个黑箱模型，所以我们看不到**箱子**内部发生了什么。为了更深入地了解预测值是如何得出的，我们需要理解两点：
- en: Do the features affect the predicted house price positively or negatively? (For
    instance, does a higher *MedInc* value lead to an increase in the predicted house
    price?)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征对预测房价的影响是正面还是负面？（例如，更高的*MedInc*值是否导致预测房价的增加？）
- en: What is the extent of these influences? (For instance, does *MedInc* have a
    more significant impact on the predicted house price than *AveRooms*?)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些影响的程度是多少？（例如，*MedInc*对预测房价的影响是否比*AveRooms*更大？）
- en: To answer these questions and determine the contribution of each feature to
    the house price prediction of 1.596, we can rely on the SHAP values of the features.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题并确定每个特征对1.596这一房价预测的贡献，我们可以依赖特征的SHAP值。
- en: 'Let’s start by calculating the ***SHAP value of MedInc to this prediction of
    1.596*** by following these steps:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下步骤来计算对1.596这一预测的***MedInc的SHAP值***：
- en: 'Step 0: Calculate the expected predicted house price'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第0步：计算预期的预测房价
- en: 'The **expected predicted house price** is nothing but the a*verage of all the
    predictions* made. Which is:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**预期的预测房价**不过是所有预测值的*平均值*。即：'
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So, 2.07 serves as the expected predicted house price. We are now trying to
    figure out why the predicted value of 1.596 deviates from the expected prediction
    of 2.07\. Where is the discrepancy of 0.476 (2.07–1.596) coming from?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，2.07作为预期的预测房价。我们现在尝试弄清楚为什么预测值1.596与预期的2.07有偏差。0.476（2.07–1.596）的差异来自哪里？
- en: The SHAP value of a feature measures how much that feature contributed to moving
    the model’s prediction away/towards the expected predicted value.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 特征的SHAP值衡量了该特征对模型预测值偏离/接近期望预测值的贡献程度。
- en: 'Step 1: Get a random permutation of the features'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤1：获取特征的随机排列
- en: We started with this permutation of features…
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从这个特征的排列开始…
- en: '![](../Images/bdb2f16b821b15a994544bb27c8dba63.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bdb2f16b821b15a994544bb27c8dba63.png)'
- en: '…and after a random reshuffle, we get this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: …在随机重排后，我们得到这个：
- en: '![](../Images/619fe10cf225d257a337e8fa2d0f76d6.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/619fe10cf225d257a337e8fa2d0f76d6.png)'
- en: We care about *MedInc* here, so let’s highlight *MedInc* and any feature to
    the right of it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里关注*MedInc*，所以让我们突出显示*MedInc*以及其右边的任何特征。
- en: '![](../Images/1f4a973514fd5ca9d4a70c16575b98f6.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f4a973514fd5ca9d4a70c16575b98f6.png)'
- en: 'Step 2: Pick a random sample from the dataset'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤2：从数据集中选择一个随机样本
- en: 'We go back to our test dataset and choose a random sample from it:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到我们的测试数据集，从中选择一个随机样本：
- en: '![](../Images/0997fab0f5286f15e5dfdf642226a42f.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0997fab0f5286f15e5dfdf642226a42f.png)'
- en: 'Step 3: Form two new samples'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤3：形成两个新样本
- en: These samples are going to be formed partially from the original sample…
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些样本将部分来源于原始样本…
- en: '![](../Images/1eddbf91915ef607150e0be25b47cc11.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1eddbf91915ef607150e0be25b47cc11.png)'
- en: '…and the new sample that we just pulled in Step 2:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: …以及我们在步骤2中刚刚提取的新样本：
- en: '![](../Images/0997fab0f5286f15e5dfdf642226a42f.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0997fab0f5286f15e5dfdf642226a42f.png)'
- en: The first sample that we create, called x1, is going to have all the same values
    from our original sample except for the features to the right of *MedInc*. For
    the features to the right of *MedInc*, we get from the new sample.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的第一个样本，称为x1，将拥有原始样本中的所有相同值，除了*MedInc*右边的特征。对于*MedInc*右边的特征，我们从新样本中获取。
- en: '![](../Images/8723a7d0e91ad4f884ae6578c5642251.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8723a7d0e91ad4f884ae6578c5642251.png)'
- en: The second sample that we create, called x2, is going to have all the values
    from the original sample except for the features to the right of *MedInc* ***and
    MedInc***.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的第二个样本，称为x2，将拥有原始样本中的所有值，除了*MedInc*右边的特征***和MedInc***。
- en: '![](../Images/57a53edd16f43e6ad55865902d89a298.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/57a53edd16f43e6ad55865902d89a298.png)'
- en: From this, we can see that these are the exact sample samples except for one
    key thing — they vary in their *MedInc* value, the feature we care about.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从中我们可以看到，这些样本完全一样，除了一个关键的地方——它们在*MedInc*值上有所不同，这是我们关注的特征。
- en: 'Step 4: Use the new samples to make predictions and find the difference in
    predictions'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤4：使用新样本进行预测，并找出预测值的差异
- en: Now we run these samples through our model and get predictions for them.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将这些样本输入到模型中，并获取它们的预测值。
- en: '![](../Images/404b7d4e6ef4ab25dba1a1d6d431d147.png)![](../Images/988b7fbfbe21e81ecb2a0dbd8e86a64b.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/404b7d4e6ef4ab25dba1a1d6d431d147.png)![](../Images/988b7fbfbe21e81ecb2a0dbd8e86a64b.png)'
- en: 'And we find the difference between these values:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到这些值之间的差异：
- en: '![](../Images/1f0d0cbdea088dd0c9912c1c49f754d3.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f0d0cbdea088dd0c9912c1c49f754d3.png)'
- en: Since the only difference between x1 and x2 is the value of *MedInc,* this difference
    represents the change in prediction when the value of *MedInc* is altered.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于x1和x2之间的唯一区别是*MedInc*的值，这个区别表示当*MedInc*的值发生变化时预测的变化。
- en: 'Step 5: Repeat Steps 1–4 a couple of times and then calculate the average of
    the differences'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤5：重复步骤1–4几次，然后计算差异的平均值
- en: All we do now is repeat the above process and calculate the average of all the
    difference values found in Step 4.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在要做的就是重复上述过程，并计算步骤4中找到的所有差异值的平均值。
- en: Let’s assume that we repeat this process 1000 times (this number may vary based
    on the complexity of the model and dataset). After averaging the results, we obtained
    a value of **0.22**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们将这个过程重复1000次（这个数字可能会根据模型和数据集的复杂性而有所不同）。在对结果取平均后，我们得到了一个值为**0.22**。
- en: This 0.22 represents the SHAP value of *MedInc* in the first sample which implies
    that *MedInc* contributes +0.22 towards adjusting the expected prediction of 2.07
    to our prediction of 1.596.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这个0.22表示*MedInc*在第一个样本中的SHAP值，这意味着*MedInc*对将期望预测值2.07调整到我们预测值1.596的贡献为+0.22。
- en: We can apply the same process to the other features — *HouseAge, AveRooms, Latitude,*
    and *Longitude* to find their SHAP values.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对其他特征——*HouseAge, AveRooms, Latitude,* 和 *Longitude* 应用相同的过程，以找到它们的SHAP值。
- en: Now that we understand the underlying calculations of SHAP, we can apply it
    to our predictions by visualizing them. To visualize them, we will use ***Explainer***
    from Python’s ***shap*** library and input our model.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了SHAP的基本计算，我们可以通过可视化来应用它。为了可视化它们，我们将使用Python的***shap***库中的***Explainer***并输入我们的模型。
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This will give us the SHAP values for all the features (*MedInc,* *HouseAge,
    AveRooms, Latitude,* and *Longitude*) for each sample in the test set. Using these
    SHAP values, let’s get plotting.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为测试集中每个样本的所有特征（*MedInc*、*房龄*、*平均房间数*、*纬度*和*经度*）提供SHAP值。利用这些SHAP值，我们开始绘图。
- en: 1\. Waterfall Plot
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 瀑布图
- en: This plot helps us visualize the SHAP values of each sample in our data individually.
    Let’s visualize the SHAP values of the first sample.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图帮助我们逐个可视化数据中每个样本的SHAP值。让我们可视化第一个样本的SHAP值。
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/c495a96aeb6c1dcd086e1ea7f37fa0c7.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c495a96aeb6c1dcd086e1ea7f37fa0c7.png)'
- en: Notice that the expected predicted value, E[f(X)] = 2.07, which is the value
    calculated in Step 0, and the predicted house price of the first house, f(X) =
    1.596 is our prediction of the first sample.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，预期的预测值E[f(X)] = 2.07，这是第0步计算的值，而第一个房子的预测房价f(X) = 1.596是我们对第一个样本的预测。
- en: Observe that the SHAP value of *MedInc* is +0.22 (which we see in Step 5), the
    SHAP value of *Longitude* is -2.35, etc. If we add and subtract all the above
    SHAP values to and from 2.07, respectively, we arrive at the predicted value of
    1.596 for the first house.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到*MedInc*的SHAP值为+0.22（我们在第5步中看到），*经度*的SHAP值为-2.35，等等。如果我们将所有上述SHAP值加到2.07中，并从中减去，我们得到第一个房子的预测值1.596。
- en: '![](../Images/5d56ac53edea49f36e9b272963d0c1d9.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d56ac53edea49f36e9b272963d0c1d9.png)'
- en: Ignoring the signs, the magnitude of the SHAP value for *Longitude*, 2.35, is
    greater than that of the other features. This implied that *Longitude* has the
    most significant impact on this particular prediction.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略符号，*经度*的SHAP值的大小为2.35，大于其他特征的值。这意味着*经度*对这一特定预测的影响最大。
- en: Just like we visualized the SHAP values of the first sample, we can visualize
    SHAP values for the second sample too.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们可视化第一个样本的SHAP值一样，我们也可以可视化第二个样本的SHAP值。
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/01b917c3c00b0c91f0df282f81694742.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01b917c3c00b0c91f0df282f81694742.png)'
- en: Comparing the SHAP values for the first and second houses in our test data,
    we observe significant differences. In the first house, *Longitude* had the most
    significant impact on the predicted price, while in the second house, *MedInc*
    has the most prominent influence.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 比较我们测试数据中第一个和第二个房子的SHAP值，我们观察到显著差异。在第一个房子中，*经度*对预测价格的影响最大，而在第二个房子中，*MedInc*的影响最为显著。
- en: 'NOTE: These differences in the SHAP values highlight the unique contributions
    of each feature to the model’s output for each sample. It’s essential to understand
    these contributions to build trust in the model’s decision-making process and
    ensure that it’s not biased or discriminatory.'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：这些SHAP值的差异突出了每个特征对模型输出的独特贡献。理解这些贡献对于建立对模型决策过程的信任至关重要，并确保模型不会存在偏见或歧视。
- en: 2\. Force Plot
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 力图
- en: Another way to visualize the above is a force plot.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可视化上述内容的方法是力图。
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/55044cac57d3c64cac41ef4327c95dbd.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55044cac57d3c64cac41ef4327c95dbd.png)'
- en: 3\. Mean SHAP Plot
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 平均SHAP图
- en: To determine which features are generally most important for our model’s predictions,
    we can use a bar plot of the mean SHAP values across all observations. Taking
    the mean of the absolute values ensures that positive and negative values do not
    cancel each other out.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定哪些特征通常对我们模型的预测最重要，我们可以使用所有观测值的平均SHAP值的条形图。取绝对值的平均值可以确保正负值不会相互抵消。
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/65409913e4de84a4ddf04af405b50f4d.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65409913e4de84a4ddf04af405b50f4d.png)'
- en: Each feature has a corresponding bar, with the height representing the mean
    SHAP value. For instance, in our plot, the feature with the largest mean SHAP
    value is *Latitude*, indicating that it has the most substantial impact on our
    model’s predictions. This information can help us understand which features are
    critical to the model’s decision-making process.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征都有一个对应的条形，高度表示平均SHAP值。例如，在我们的图中，平均SHAP值最大的特征是*纬度*，这表明它对我们模型的预测影响最大。这些信息可以帮助我们了解哪些特征对模型的决策过程至关重要。
- en: 4\. Beeswarm Plot
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 蜂群图
- en: The beeswarm plot is a useful visualization to examine all of the SHAP values
    for each feature. The y-axis groups the SHAP values by feature, with the color
    of the points indicating the corresponding feature value. Typically, redder points
    represent higher feature values.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 蜜蜂图是一种有用的可视化工具，用于检查每个特征的所有SHAP值。y轴按特征将SHAP值分组，点的颜色表示相应的特征值。通常，较红的点代表较高的特征值。
- en: The beeswarm plot can help identify important relationships between features
    and the model’s predictions. In this plot, the features are ordered by their mean
    SHAP values.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 蜜蜂图可以帮助识别特征与模型预测之间的重要关系。在这个图中，特征按其平均SHAP值排序。
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/8aa359bf65e22090bf49cb223be05753.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8aa359bf65e22090bf49cb223be05753.png)'
- en: By examining the SHAP values in the beeswarm plot, we can start to understand
    the nature of the relationships between the features and the predicted house price.
    For instance, for *MedInc*, we observe that SHAP values increase as the feature
    value increases. This suggests that higher values of *MedInc* contribute to higher
    predicted house prices.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查蜜蜂图中的SHAP值，我们可以开始理解特征与预测房价之间关系的性质。例如，对于*MedInc*，我们观察到SHAP值随着特征值的增加而增加。这表明较高的*MedInc*值有助于提高预测的房价。
- en: In contrast, for the *Latitude* and *Longitude*, we notice the opposite trend,
    where higher feature values lead to lower SHAP values. This observation implies
    that higher *Latitude* and *Longitude* values are associated with lower predicted
    house prices.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，对于*Latitude*和*Longitude*，我们注意到相反的趋势，即更高的特征值会导致较低的SHAP值。这一观察表明较高的*Latitude*和*Longitude*值与较低的预测房价相关联。
- en: 5\. Dependence Plots
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 依赖图
- en: To gain a deeper understanding of the relationships between individual features
    and their corresponding SHAP values, we can create dependence plots. A dependence
    plot is a scatter plot that shows the relationship between the SHAP value and
    the feature value for a single feature.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地理解各个特征与其相应的SHAP值之间的关系，我们可以创建依赖图。依赖图是一个散点图，展示了单个特征的SHAP值与特征值之间的关系。
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/8428b1c963f86abd056ae4e55141a60d.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8428b1c963f86abd056ae4e55141a60d.png)'
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/675f2522c40fbd98d264bc70c56b6ee2.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/675f2522c40fbd98d264bc70c56b6ee2.png)'
- en: By analyzing dependence plots, we can confirm the observations made in the beeswarm
    plot. For instance, when we create a dependence plot for *MedInc*, we observe
    a positive relationship between *MedInc* values and SHAP values. In other words,
    higher *MedInc* values result in higher predicted house prices.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析依赖图，我们可以确认在蜜蜂图中所做的观察。例如，当我们为*MedInc*创建一个依赖图时，我们观察到*MedInc*值与SHAP值之间存在正相关关系。换句话说，更高的*MedInc*值会导致预测的房价更高。
- en: Overall, the dependence plots provide a more detailed understanding of the complex
    relationships between individual features and predicted house prices.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，依赖图提供了对单个特征与预测房价之间复杂关系的更详细理解。
- en: In conclusion, SHAP values give us a peek and insights into how each feature
    contributes to the model’s output. These insights can be further enhanced through
    the use of visualizations. We can leverage SHAP to make more informed decisions
    about feature selection, model improvement, and ultimately, achieve better performance
    in our machine learning applications.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，SHAP值让我们窥探了每个特征如何贡献于模型输出。这些见解可以通过可视化进一步增强。我们可以利用SHAP做出更明智的特征选择、模型改进决策，并最终在机器学习应用中实现更好的性能。
- en: '![](../Images/a5968fd00bf83cbd6acdff51388eb153.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5968fd00bf83cbd6acdff51388eb153.png)'
- en: As always, thank you for including me in your machine learning journey. Shoot
    me an email at *shreya.statistics@gmail.com* or connect with me on [LinkedIn](https://www.linkedin.com/in/shreyarao24/)
    for comments, questions, and suggestions!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，感谢你让我参与到你的机器学习旅程中。你可以通过邮件联系我，邮箱是*shreya.statistics@gmail.com*，或者在[LinkedIn](https://www.linkedin.com/in/shreyarao24/)上与我联系，提出你的意见、问题和建议！
