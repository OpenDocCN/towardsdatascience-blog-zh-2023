- en: 'Unraveling the Design Pattern of Physics-Informed Neural Networks: Part 03'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 揭示物理信息神经网络的设计模式：第三部分
- en: 原文：[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)
- en: Supercharging PINN’s performance with gradient boost training
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过梯度提升训练超充PINN的性能
- en: '[](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)
    ·7 min read·May 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)
    ·阅读时间7分钟·2023年5月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6135269a240dcb1660a418ff2ece06d3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6135269a240dcb1660a418ff2ece06d3.png)'
- en: Photo by [Haithem Ferdi](https://unsplash.com/@haithemfrd_off?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Haithem Ferdi](https://unsplash.com/@haithemfrd_off?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Welcome to the 3rd blog of this series, where we continue our exciting journey
    of exploring design patterns of physics-informed neural networks (PINN).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本系列的第三篇博客，在这里我们继续探索物理信息神经网络（PINN）的设计模式，进行令人兴奋的旅程。
- en: In this blog, we will look into training PINNs with gradient boosting, an exciting
    fusion of neural networks and gradient boosting algorithms 🚀.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将探讨使用梯度提升训练 PINNs，这是一种神经网络与梯度提升算法的激动人心的融合 🚀。
- en: 'As usual, I will structure this blog in the following way:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我将按照以下方式结构化这篇博客：
- en: the **problem**, the specific problem the proposed strategy is trying to address;
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题**，提出的策略试图解决的具体问题；'
- en: the **solution**, the key components of the proposed strategy, how it is implemented,
    and why it might work;
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解决方案**，提出的策略的关键组件，它是如何实施的，以及它可能有效的原因；'
- en: the **benchmark**, what physical problems are evaluated, and what’s the associated
    performance;
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基准**，评估了哪些物理问题，以及相关的性能；'
- en: the **strengths & weaknesses**, under which conditions the proposed strategy
    can be effective, while also highlighting its potential limitations;
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优点与缺点**，提出的策略在什么条件下可能有效，同时也突出其潜在的局限性；'
- en: the **alternatives**, other approaches proposed to address a similar problem,
    thus providing a broader perspective on potential solutions.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**替代方案**，为解决类似问题提出的其他方法，从而提供更广泛的潜在解决方案视角。'
- en: 'As this series continues to expand, the collection of PINN design patterns
    grows even richer*🙌* Here’s a sneak peek at what awaits you:'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 随着本系列的不断扩展，PINN 设计模式的集合变得更加丰富*🙌* 这里是对你即将迎接内容的预览：
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 01: 优化残差点分布](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 02: 动态解决方案区间扩展](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: ''
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 04：梯度增强的 PINN 学习](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: ''
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 05: automated hyperparameter tuning](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 05：自动化超参数调整](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
- en: ''
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 06：因果 PINN 训练](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: ''
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 07：与 PINN 的主动学习](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Let’s dive in!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解一下！
- en: '1\. Paper at a glance:'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 快速了解论文：
- en: '**Title**: Ensemble learning for physics informed neural networks: a Gradient
    Boosting approach'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标题**：用于物理信息神经网络的集成学习：一种梯度提升方法'
- en: '**Authors**: Z. Fang, S. Wang, P. Perdikaris'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作者**：Z. Fang, S. Wang, P. Perdikaris'
- en: '**Institutes**: University of Pennsylvania'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机构**：宾夕法尼亚大学'
- en: 'Link: [arXiv](https://arxiv.org/abs/2302.13143)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接：[arXiv](https://arxiv.org/abs/2302.13143)
- en: 2\. Design pattern
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 设计模式
- en: 2.1 Problem
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 问题
- en: Naive PINNs are known to have difficulties in simulating physical processes
    that are **sensitive to small changes** in the input and require a high degree
    of accuracy to accurately capture their dynamics. Examples of those physical systems
    include multi-scale problems and singular perturbation problems, which are highly
    relevant to domains like fluid dynamics and climate modeling.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 原始 PINNs 已知在模拟对输入的**小变化**非常敏感并需要高度准确性以准确捕捉其动态的物理过程时存在困难。这些物理系统的例子包括多尺度问题和奇异摄动问题，这些问题与流体动力学和气候建模等领域密切相关。
- en: '![](../Images/c0c53c2bc5db304471361d09715678ea.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0c53c2bc5db304471361d09715678ea.png)'
- en: PINN workflow. Naive PINNs often encounter challenges in solving complicated
    PDEs. One promising way to address this issue is by training PINNs with **boosting**
    algorithms. (Image by this blog author)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PINN 工作流程。原始 PINNs 在解决复杂 PDE 时通常面临挑战。解决此问题的一种有前景的方法是通过**提升**算法训练 PINNs。（图像由本博客作者提供）
- en: 2.2 Solution
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 解决方案
- en: 'It turns out, the same issue is also experienced by other machine learning
    algorithms, and a promising way to resolve this issue is by adopting the “Gradient
    Boosting” method. Therefore, a natural question arises: can we mimic the gradient
    boosting algorithm to train PINNs? The paper has given a positive answer.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，其他机器学习算法也会遇到相同的问题，解决此问题的一种有前景的方法是采用“梯度提升”方法。因此，自然产生了一个问题：我们能否模拟梯度提升算法来训练
    PINNs？论文对此给出了肯定的答案。
- en: 'Boosting is a general machine learning algorithm that can be succinctly expressed
    in the following iterative form:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 提升是一种通用的机器学习算法，可以简洁地表达为以下迭代形式：
- en: '![](../Images/419bb6b8157f439a5f8987d14ddea480.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/419bb6b8157f439a5f8987d14ddea480.png)'
- en: At each boosting round, an incremental model *hₘ*(•) is derived and added (discounted
    by a learning rate *ρₘ*) on top of the predictor from the last iteration f*ₘ_*₁(•),
    such that the accuracy of f*ₘ*(•) could be “boosted”.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一次提升轮次中，都会导出一个增量模型 *hₘ*(•) 并在上一次迭代的预测器 f*ₘ_*₁(•) 上添加（以学习率 *ρₘ* 进行折扣），以便提高
    f*ₘ*(•) 的准确性。
- en: 'Now, if we replace f*ₘ_*₁(•), f*ₘ*(•), and *hₘ*(•) as physics-informed neural
    networks, we can realize training PINNs with boosting algorithm. A diagram to
    showcase the training process is given below:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们将 f*ₘ_*₁(•)、f*ₘ*(•) 和 *hₘ*(•) 替换为物理信息神经网络，我们可以实现通过提升算法训练 PINNs。下面是展示训练过程的示意图：
- en: '![](../Images/b64b778fb6547d151cce05fbce42ac17.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b64b778fb6547d151cce05fbce42ac17.png)'
- en: PINN models are trained in sequence to iteratively minimize the loss. Only the
    blocks marked green are trainable. The loss is the usual PINN loss, i.e., PDE
    loss, boundary condition loss, etc. (Image by this blog author)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: PINN 模型按顺序训练以迭代地最小化损失。只有标记为绿色的块是可训练的。损失是通常的 PINN 损失，即 PDE 损失、边界条件损失等。（图像由本博客作者提供）
- en: In the paper’s implementation, the architecture and the hyperparameters of the
    additive PINN model *hₘ*(•) are **pre-determined**. This is different from the
    original gradient-boosting algorithm, as the original algorithm would utilize
    gradient descent to find the optimal *hₘ*(•) form. However, the authors claimed
    that using pre-selected *hₘ*(•)s can still mimic the behavior of boosting algorithm,
    but with significantly reduced computational complexity.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文的实现中，加性PINN模型*hₘ*(•)的结构和超参数是**预先确定的**。这与原始的梯度提升算法不同，后者会利用梯度下降找到最佳的*hₘ*(•)形式。然而，作者声称使用预选的*hₘ*(•)仍然可以模拟提升算法的行为，但计算复杂性显著降低。
- en: According to the numerical experiments conducted in the paper, usually, 3~5
    PINNs are good enough to deliver satisfactory results. For setting the learning
    rate *ρₘ*, the suggested way would be to set the initial *ρ* as 1, and exponentially
    decay the *ρ* valueas *m* increases.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 根据论文中进行的数值实验，通常3~5个PINNs足以提供令人满意的结果。对于设置学习率*ρₘ*，建议的做法是将初始*ρ*设置为1，并且随着*m*的增加，*ρ*值按指数衰减。
- en: 2.3 Why the solution might work
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 解决方案为何可能有效
- en: 'As the proposed solution mimics the mechanism of the traditional “Gradient
    Boosting”, it automatically inherits all the nice things offered by the approach:
    by sequentially adding weak models, each new model is able to correct the mistakes
    made by the previous models, thus iteratively improving the overall performance.
    This makes the approach especially effective for challenging problems such as
    multi-scale or singular perturbation problems.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所提解决方案模拟了传统的“梯度提升”机制，因此自动继承了该方法提供的所有优点：通过顺序添加弱模型，每个新模型能够纠正前一模型所犯的错误，从而迭代地提高整体性能。这使得该方法在处理多尺度或奇异摄动问题等具有挑战性的问题时尤其有效。
- en: Meanwhile, for boosting algorithm, a “strong” model can still be achieved even
    if the component model at each boosting stage is relatively “weak”. This property
    has the benefit of making the overall PINN model less sensitive to hyperparameter
    settings.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，对于提升算法，即使每个提升阶段的组件模型相对“弱”，也仍然可以实现“强”的模型。这一特性使得整体PINN模型对超参数设置的敏感性降低。
- en: 2.4 Benchmark
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 基准测试
- en: 'The paper benchmarked the performance of the proposed strategy on four diverse
    problems, each representing a distinct mathematical challenge:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 论文在四个不同的数学问题上对所提策略的性能进行了基准测试，每个问题都代表一个独特的数学挑战：
- en: '1D singular perturbation problem: singular perturbation problems are special
    cases where certain terms in the equations become disproportionately small or
    large, leading to different behaviors that are challenging to model. These problems
    often occur in many areas of science and engineering, such as fluid dynamics,
    electrical circuits, and control systems.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1D 奇异摄动问题：奇异摄动问题是一类特殊情况，其中方程中的某些项变得极小或极大，导致不同的行为模式，难以建模。这些问题通常出现在科学和工程的许多领域，如流体动力学、电路和控制系统。
- en: '![](../Images/a0b40711ff07f2c2b15330f851ed0257.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0b40711ff07f2c2b15330f851ed0257.png)'
- en: ε = 1e-4.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ε = 1e-4。
- en: '2D convection-dominated diffusion equation: this equation models physical phenomena
    where the convection effect (transport due to bulk motion) is much stronger than
    the diffusion effect (transport due to concentration gradients). These types of
    problems occur in various areas like meteorology (where wind disperses pollutants)
    and oceanography (where ocean currents transport heat).'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2D 对流主导的扩散方程：这个方程模拟了对流效应（由于整体运动而产生的传输）远强于扩散效应（由于浓度梯度产生的传输）的物理现象。这些类型的问题出现在气象学（如风传播污染物）和海洋学（如洋流输送热量）等各种领域。
- en: '![](../Images/157a22f3dd284e136c5c623f11f2c3ba.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/157a22f3dd284e136c5c623f11f2c3ba.png)'
- en: ε = 1e-3, Ω = (0, 1)².
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ε = 1e-3, Ω = (0, 1)²。
- en: '2D convection-dominated diffusion problem (featuring curved streamlines and
    an interior boundary layer): this is a more complex variant of the previous problem
    where the flow pattern is curved, and there is a significant boundary layer within
    the problem domain. These complications require a more sophisticated numerical
    approach and make the problem more representative of real-world challenges.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2D 对流主导的扩散问题（特征为弯曲流线和内部边界层）：这是前述问题的一个更复杂的变体，其中流动模式弯曲，并且在问题领域内存在显著的边界层。这些复杂性需要更复杂的数值方法，使得问题更具现实世界挑战的代表性。
- en: '![](../Images/57593bb173e4a291c3dd1b3df5d3b0fc.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/57593bb173e4a291c3dd1b3df5d3b0fc.png)'
- en: ε = 1e-4, Ω = (0, 1)², β = eˣ(sin(y), cos(y)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ε = 1e-4, Ω = (0, 1)², β = eˣ(sin(y), cos(y))。
- en: '2D nonlinear reaction-diffusion equation (time-dependent): this equation models
    reactions combined with the diffusion of substances, but it’s also nonlinear and
    changes over time. These types of problems are common in fields like biology and
    chemistry, where substances interact and spread in a medium, and the reaction
    rates can change over time.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2D 非线性反应-扩散方程（时间依赖）：这个方程模拟了物质扩散与反应的结合，但它也具有非线性，并且随时间变化。这类问题在生物学和化学等领域很常见，在这些领域中，物质在介质中相互作用并扩散，且反应速率可能随时间变化。
- en: '![](../Images/d08d9a7aca98a97d0d1eff4fecb243c5.png)![](../Images/d229e29e4ce533bab423d60fced24704.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d08d9a7aca98a97d0d1eff4fecb243c5.png)![](../Images/d229e29e4ce533bab423d60fced24704.png)'
- en: Ω = (0, 2π), periodic boundary conditions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Ω = (0, 2π)，周期边界条件。
- en: 'The benchmark studies yielded that:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 基准研究结果显示：
- en: the proposed algorithm showed substantial accuracy improvements across all test
    cases compared with naive PINNs;
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与传统的 PINNs 相比，所提出的算法在所有测试案例中显示了显著的准确性提升；
- en: the proposed algorithm showed robustness, with little sensitivity to the hyperparameter
    choices.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所提出的算法显示出鲁棒性，对超参数选择不太敏感。
- en: 2.5 Strengths and Weaknesses
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 优缺点
- en: 👍**Strengths**
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 👍**优点**
- en: Significantly improved accuracy compared to a single PINN.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比于单一的 PINN，准确性显著提升。
- en: Robust against the choice of network structure and arrangement.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对网络结构和排列的选择具有较强的鲁棒性。
- en: Fewer efforts are required for fine-tuning hyperparameters.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整超参数所需的努力较少。
- en: Flexible and can be easily integrated with other PINNs techniques.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵活且可以轻松与其他 PINNs 技术集成。
- en: 👎**Weaknesses**
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 👎**缺点**
- en: Not suitable for solving conservation laws with derivative blow-ups (e.g., inviscid
    Burgers’ equation, Sod shock tube problem, etc.), which is due to the lack of
    sensitivity of these equations’ solutions to PDE loss.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不适用于解决具有导数爆炸的守恒定律（例如，无粘性 Burgers 方程、Sod 冲击管问题等），这是由于这些方程解对 PDE 损失的敏感性不足。
- en: Limitations in terms of scalability, as it may require more computational resources
    and time to train multiple neural networks in sequence.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可扩展性方面存在限制，因为它可能需要更多的计算资源和时间来顺序训练多个神经网络。
- en: 2.6 Alternatives
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 替代方案
- en: Since this is the first paper that introduces the boosting algorithm to the
    PINN domain, there is currently no similar work as the current paper.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是第一篇将提升算法引入 PINN 领域的论文，目前尚无类似的工作。
- en: Nevertheless, in terms of enhancing the PINN’s capability of modeling challenging
    physical processes, the paper specifically mentioned the work of [Krishnapriyan
    et al.](https://arxiv.org/abs/2109.01050) There, the strategy is to divide the
    time domain into sub-intervals, and PINNs are built progressively to model each
    of the sub-intervals (similar to the idea covered in the [previous blog](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，在增强 PINN 建模具有挑战性的物理过程的能力方面，论文特别提到了 [Krishnapriyan et al.](https://arxiv.org/abs/2109.01050)
    的工作。该策略是将时间域划分为子区间，PINNs 被逐步构建以模拟每个子区间（类似于 [之前博客](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)
    中涵盖的想法）。
- en: The current paper compared Krishnapriyan’s approach with the newly proposed
    one in the last benchmark case study (section 2.4 above). The results showed that
    the proposed boosting approach is able to achieve 4 times lower error.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的论文在最后的基准案例研究（上述 2.4 节）中将 Krishnapriyan 的方法与新提出的方法进行了比较。结果表明，所提出的提升方法能够将误差降低
    4 倍。
- en: 3 Potential Future Improvements
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 未来潜在改进
- en: Further improvements of the proposed strategy include investigating the optimal
    sequential combination of the neural networks, mixing and matching with other
    types of neural network architectures in the gradient boosting training iterations,
    as well as integrating other best practices of PINN training (e.g., residual points
    generation) into the gradient boosting training framework.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对所提出的策略的进一步改进包括研究神经网络的最佳顺序组合，与其他类型的神经网络架构混合并匹配梯度提升训练迭代，以及将 PINN 训练的其他最佳实践（例如，残差点生成）集成到梯度提升训练框架中。
- en: 4 Takeaways
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 主要收获
- en: In this blog, we looked at a new PINN training paradigm via boosting-based ensemble
    learning. This topic is highly relevant as it enhances PINNs’ capability to tackle
    challenging problems like multi-scale and singular perturbation problems.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们探讨了一种基于提升的集成学习的新型 PINN 训练范式。这个话题非常相关，因为它增强了 PINNs 处理像多尺度和奇异摄动问题这样具有挑战性问题的能力。
- en: 'As usual, here are the takeaways from the design pattern proposed in this paper:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，这里是本论文提出的设计模式的要点：
- en: '[Problem]: How to enhance PINNs’ capability to solve challenging problems?'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问题]：如何提升 PINN 解决复杂问题的能力？'
- en: '[Solution]: **Gradient boosting**, where multiple “weak” PINNs are trained
    in sequence to iteratively improve the overall performance.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解决方案]：**梯度提升**，其中多个“弱”PINN 按顺序训练，以迭代地提高整体性能。'
- en: '[Potential benefits]: 1\. Able to solve challenging problems for naive PINN.
    2\. Fewer efforts for hyperparameter tuning'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[潜在的好处]：1\. 能够解决简单 PINN 的复杂问题。2\. 超参数调整的工作量减少'
- en: 'Here is another PINN design card:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个 PINN 设计卡片：
- en: '![](../Images/2e721a39dd529d97d43c9e855957a3e6.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e721a39dd529d97d43c9e855957a3e6.png)'
- en: PINN design pattern proposed in the paper. (Image by this blog author)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中提出的 PINN 设计模式。（图像由本博客作者提供）
- en: 'I hope you found this blog useful😃If you want to learn more about PINN design
    patterns, feel free to check out other posts in this series:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您觉得这篇博客有用😃如果您想了解更多关于 PINN 设计模式的内容，请随时查看本系列的其他帖子：
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 01：优化残差点分布](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: '[PINN design pattern 02: Dynamic solution interval expansion](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 02：动态解决方案区间扩展](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 04：梯度增强的 PINN 学习](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: '[PINN design pattern 05: Hyperparameter tuning for PINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 05：PINN 的超参数调整](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 06：因果 PINN 训练](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 07：利用 PINN 进行主动学习](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Looking forward to sharing more insights with you in the upcoming blogs!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 期待在即将到来的博客中与您分享更多见解！
- en: Reference
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Fang et al., Ensemble learning for physics informed neural networks: a
    Gradient Boosting approach, [arXiv](https://arxiv.org/abs/2302.13143), 2023.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Fang 等，物理信息神经网络的集成学习：一种梯度提升方法，[arXiv](https://arxiv.org/abs/2302.13143)，2023。'
- en: '[2] Krishnapriyan et al., Characterizing possible failure modes in physics-informed
    neural networks, [arXiv](https://arxiv.org/abs/2109.01050), 2021.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Krishnapriyan 等，物理信息神经网络中可能的失效模式的特征，[arXiv](https://arxiv.org/abs/2109.01050)，2021。'
