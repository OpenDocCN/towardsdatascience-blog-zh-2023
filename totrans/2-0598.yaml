- en: Creating a Gradient Descent Animation in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Python中创建梯度下降动画
- en: 原文：[https://towardsdatascience.com/creating-a-gradient-descent-animation-in-python-3c4dcd20ca51](https://towardsdatascience.com/creating-a-gradient-descent-animation-in-python-3c4dcd20ca51)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/creating-a-gradient-descent-animation-in-python-3c4dcd20ca51](https://towardsdatascience.com/creating-a-gradient-descent-animation-in-python-3c4dcd20ca51)
- en: How to plot the trajectory of a point over a complex surface
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何绘制点在复杂曲面上的轨迹
- en: '[](https://medium.com/@luisdamed?source=post_page-----3c4dcd20ca51--------------------------------)[![Luis
    Medina](../Images/d83d326290ae3272f0618d0bd28bd875.png)](https://medium.com/@luisdamed?source=post_page-----3c4dcd20ca51--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3c4dcd20ca51--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3c4dcd20ca51--------------------------------)
    [Luis Medina](https://medium.com/@luisdamed?source=post_page-----3c4dcd20ca51--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisdamed?source=post_page-----3c4dcd20ca51--------------------------------)[![Luis
    Medina](../Images/d83d326290ae3272f0618d0bd28bd875.png)](https://medium.com/@luisdamed?source=post_page-----3c4dcd20ca51--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3c4dcd20ca51--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3c4dcd20ca51--------------------------------)
    [Luis Medina](https://medium.com/@luisdamed?source=post_page-----3c4dcd20ca51--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3c4dcd20ca51--------------------------------)
    ·10 min read·Nov 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3c4dcd20ca51--------------------------------)
    ·阅读时间 10 分钟·2023年11月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7d7b4b9e511a33f93c362a2a92aaedc2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d7b4b9e511a33f93c362a2a92aaedc2.png)'
- en: Photo by [Todd Diemer](https://unsplash.com/@todd_diemer?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Todd Diemer](https://unsplash.com/@todd_diemer?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Let me tell you how I created an animation of gradient descent just to illustrate
    a point in a blog post. It was worth it since I learned more Python by doing it
    and unlocked a new skill: making animated plots.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我告诉你我是如何创建梯度下降动画的，只是为了在博客文章中说明一个观点。这是值得的，因为通过这样做我学到了更多的Python，并掌握了一项新技能：制作动画图。
- en: '![](../Images/99b27b5838acc1c636dfd987cb31ace8.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99b27b5838acc1c636dfd987cb31ace8.png)'
- en: Gradient descent animation created in Python. Image by the author.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中创建的梯度下降动画。图片由作者提供。
- en: I’ll walk you through the steps of the process I followed.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我将带你一步一步走过我所遵循的过程。
- en: A bit of background
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背景介绍
- en: A few days ago, I published a [blog post about gradient descent](https://medium.com/@luisdamed/gradient-descent-f09f19eb35fb)
    as an optimization algorithm used for training Artificial Neural Networks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 几天前，我发表了一篇[关于梯度下降的博客文章](https://medium.com/@luisdamed/gradient-descent-f09f19eb35fb)，介绍了作为训练人工神经网络的优化算法的梯度下降。
- en: I wanted to include an animated figure to show how choosing different initialization
    points for a gradient descent optimization can produce different results.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我想包含一个动画图形，以展示选择不同的初始化点对于梯度下降优化可能产生不同的结果。
- en: That’s when I stumbled upon these[**amazing animations**](https://imgur.com/a/Hqolp)created
    by [Alec Radford](https://twitter.com/alecrad) years ago, and shared on a [Reddit
    comment](https://www.reddit.com/r/MachineLearning/comments/2gopfa/comment/cklhott/?utm_source=share&utm_medium=web2x&context=3),
    illustrating the difference between some advanced gradient descent algorithms,
    like [Adagrad](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf), [Adadelta](http://arxiv.org/abs/1212.5701)
    and [RMSprop](https://class.coursera.org/neuralnets-2012-001/lecture/67).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 就在那时，我偶然发现了这些[**惊人的动画**](https://imgur.com/a/Hqolp)，这些动画由[Alec Radford](https://twitter.com/alecrad)多年前创建，并在[Reddit评论](https://www.reddit.com/r/MachineLearning/comments/2gopfa/comment/cklhott/?utm_source=share&utm_medium=web2x&context=3)中分享，展示了一些先进的梯度下降算法之间的差异，如[Adagrad](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)、[Adadelta](http://arxiv.org/abs/1212.5701)和[RMSprop](https://class.coursera.org/neuralnets-2012-001/lecture/67)。
- en: Since I’ve been pushing myself to [replace Matlab with Python](https://medium.com/@luisdamed/replacing-matlab-with-python-part-1-322271314e4d),
    I decided to give it a go and try to code a similar animation myself, using a
    “vanilla” gradient descent algorithm to start with.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我一直在努力[用Python取代Matlab](https://medium.com/@luisdamed/replacing-matlab-with-python-part-1-322271314e4d)，我决定试试自己编写类似的动画，首先使用“基本版”梯度下降算法。
- en: Let’s go, step by step.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一步一步来吧。
- en: Plot the surface used for optimization
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘制用于优化的表面
- en: The first thing we do is import the libraries we’ll need and define the mathematical
    function we’ll want to represent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们导入所需的库，并定义我们想要表示的数学函数。
- en: 'I wanted to use a saddle point surface, so I defined the following equation:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我想使用一个鞍点表面，所以我定义了以下方程：
- en: '![](../Images/511edcc9f085acb7f1fb35b1a9b29e92.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/511edcc9f085acb7f1fb35b1a9b29e92.png)'
- en: Saddle surface equation. Image by the author.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 鞍形表面方程。图像由作者提供。
- en: We also create a grid of points for plotting our surface. `[np.mgrid](https://numpy.org/doc/stable/reference/generated/numpy.mgrid.html)`
    is perfect for this. The complex number `81j` passed as step length indicates
    how many points to create between the start and stop values (81 points).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还创建了一个点网格来绘制我们的表面。`[np.mgrid](https://numpy.org/doc/stable/reference/generated/numpy.mgrid.html)`非常适合这个目的。传递的复数`81j`作为步长，表示在起始值和结束值之间创建多少个点（81
    个点）。
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The next thing to do is create a figure and axes, plot the surface, and format
    it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来要做的是创建图形和坐标轴，绘制表面并格式化。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/db2cf917efd55177930978a8d073064a.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db2cf917efd55177930978a8d073064a.png)'
- en: Saddle surface. Image by the author.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 鞍形表面。图像由作者提供。
- en: Compute the Gradient Descent trajectories
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算梯度下降轨迹
- en: We’ll need to implement the gradient descent algorithm and apply it to our surface.
    That way, we will compute the evolution of the x and y coordinates throughout
    the iterations of the optimization.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要实现梯度下降算法并将其应用到我们的表面。这样，我们将计算 x 和 y 坐标在优化过程中迭代的演变。
- en: As I mentioned in [my post about gradient descent](https://medium.com/@luisdamed/gradient-descent-f09f19eb35fb),
    the simplest implementation is an iterative update of the x and y values in proportion
    to the gradient, until we arrive at a local minimum.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在[关于梯度下降的帖子](https://medium.com/@luisdamed/gradient-descent-f09f19eb35fb)中提到的，最简单的实现是根据梯度迭代更新
    x 和 y 值，直到达到局部最小值。
- en: 'Once you initialize x and y at any arbitrary point to start the optimization,
    the algorithm is based on the following steps:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在任何任意点初始化 x 和 y 来开始优化，算法基于以下步骤：
- en: Compute the gradient of the surface (partial derivatives) at the current point
    (x, y).
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算当前点（x, y）处的表面梯度（偏导数）。
- en: Update the coordinates in proportion to the gradient.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按梯度更新坐标。
- en: Evaluate the surface function at the new coordinates.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新坐标处评估表面函数。
- en: This is done for a predefined number of iterations or until the difference between
    one iteration and the previous one is smaller than some threshold.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在预定义的迭代次数内完成的，或者直到一次迭代与前一次迭代之间的差异小于某个阈值。
- en: To achieve this, I created a function taking as arguments the initialization
    values, step size parameter, and the desired number of iterations.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我创建了一个函数，参数为初始化值、步长参数和所需的迭代次数。
- en: It returns an array with the x, y, z coordinates for each iteration.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回一个包含每次迭代的 x、y、z 坐标的数组。
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I tested it with two different initialization points, one over a symmetry line
    on y = 0, and the other one at an offset y value.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我用两个不同的初始化点进行了测试，一个在 y = 0 的对称线上的，另一个在偏移的 y 值上。
- en: I used the same step size and number of iterations for both in order to compare
    them. It also makes it easier to animate later on since the two results will have
    the same number of frames.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我对两者使用了相同的步长和迭代次数，以便进行比较。这也使得后续动画制作更为简单，因为两个结果将具有相同的帧数。
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To verify the results, I plotted the trajectory for each coordinate separately
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证结果，我分别绘制了每个坐标的轨迹
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/a04e31c090a7d6f5821a30b08c2d397e.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a04e31c090a7d6f5821a30b08c2d397e.png)'
- en: Evolution of x, y, and z coordinates during optimization. Image by the author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 优化过程中 x、y 和 z 坐标的演变。图像由作者提供。
- en: For the symmetry case, y and z converge to 0, while the optimization initialized
    at an offset moves down the z-axis quickly. All as expected.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对称情况中，y 和 z 收敛到 0，而在偏移位置初始化的优化则迅速沿 z 轴移动。一切如预期。
- en: Now we can visualize the trajectories on top of the surface.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在表面上可视化轨迹了。
- en: Plot the trajectories of gradient descent on top of the optimization surface
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在优化表面上绘制梯度下降的轨迹
- en: Initially, I thought this part was just a matter of plotting the results on
    the same coordinate axes we used for the surface, `ax1`. Unfortunately, that won’t
    work. [With Matplotlib we’ll have to do a bit more](https://stackoverflow.com/questions/49586376/draw-line-over-surface-plot/49601924#49601924).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，我认为这部分只是将结果绘制在我们为表面使用的相同坐标轴 `ax1` 上。不幸的是，这样做不起作用。[在 Matplotlib 中，我们需要做更多的工作](https://stackoverflow.com/questions/49586376/draw-line-over-surface-plot/49601924#49601924)。
- en: I added new axes to the figure and set them to have the same view angles and
    position of `ax1` . Then I plot the trajectory lines.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我在图形中添加了新的坐标轴，并将它们设置为与 `ax1` 具有相同的视角和位置。然后我绘制了轨迹线。
- en: The most important part here is using `set_zorder` to manually place the lines
    on top of the surface. Second, we need to use `set_axis_off` to make the new axes
    invisible.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的部分是使用 `set_zorder` 手动将线条放置在表面之上。其次，我们需要使用 `set_axis_off` 使新的坐标轴不可见。
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/24af05ca68f7f58498ad331b0ebb109f.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24af05ca68f7f58498ad331b0ebb109f.png)'
- en: Static representation of gradient descent trajectory. Image by the author.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降轨迹的静态表示。图片由作者提供。
- en: Great! Our plot makes sense, so we can start creating the animated version.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！我们的图表有意义了，所以我们可以开始创建动画版本。
- en: Create the animated figure
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建动画图形
- en: Remember how movies were done in the old days with sequences of static images?
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得过去电影是如何通过静态图像序列制作的吗？
- en: '![](../Images/8553a7eb8794914d4d14be18fde4d2e5.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8553a7eb8794914d4d14be18fde4d2e5.png)'
- en: Eadweard Muybridge, [Waugsberg](https://commons.wikimedia.org/wiki/User:Waugsberg)
    — Unknown source, [available on Wikipedia](https://commons.wikimedia.org/wiki/Eadweard_Muybridge#/media/File:Muybridge_horse_gallop_animated_2.gif).
    [Public Domain](https://commons.wikimedia.org/wiki/File:Muybridge_horse_gallop_animated_2.gif?uselang=en#Licensing)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Eadweard Muybridge，[Waugsberg](https://commons.wikimedia.org/wiki/User:Waugsberg)
    — 来源不明，[见于维基百科](https://commons.wikimedia.org/wiki/Eadweard_Muybridge#/media/File:Muybridge_horse_gallop_animated_2.gif)。
    [公共领域](https://commons.wikimedia.org/wiki/File:Muybridge_horse_gallop_animated_2.gif?uselang=en#Licensing)
- en: Well, they are still done the same way.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，它们的处理方式依然相同。
- en: That’s why I stored the updated x, y, and z coordinates at each iteration on
    an array.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我在每次迭代时将更新后的 x、y 和 z 坐标存储在数组中的原因。
- en: We need to find a way to plot sequentially those multiple “pictures” or frames
    of the optimization process.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要找到一种方法来依次绘制优化过程中的多个“图像”或帧。
- en: I had no clue about how to do this, so I started to look for code that did similar
    things to what I wanted to accomplish.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我对如何实现这一点毫无头绪，所以开始寻找做类似事情的代码。
- en: I found a brilliant article by [Zack Fizell](https://medium.com/u/595b588fe9e6?source=post_page-----3c4dcd20ca51--------------------------------)
    here on Medium where he showed [how to animate plots in Python](/how-to-animate-plots-in-python-2512327c8263).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我在 Medium 上找到了一篇由 [Zack Fizell](https://medium.com/u/595b588fe9e6?source=post_page-----3c4dcd20ca51--------------------------------)
    撰写的精彩文章，他展示了 [如何在 Python 中创建动画图](/how-to-animate-plots-in-python-2512327c8263)。
- en: Luckily, there is a dedicated class to do this in Matplotlib, `animation`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Matplotlib 中有一个专门的类 `animation` 来实现这一点。
- en: Zack explained all the details of the code, and you can go check them out in
    his article. For me, the most important part was using
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Zack 解释了代码的所有细节，你可以在他的文章中查看。对我而言，最重要的部分是使用
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To plot all the steps of the trajectory sequentially.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 依次绘制轨迹的所有步骤。
- en: Easy enough, right?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单，对吧？
- en: What `animation.FuncAnimation` does is updating the figure we pass as an input,
    using whatever function we define, in Zack’s case, `animate_func`. The function
    takes as an argument the number of `frames` we specify and is called `frames`
    times.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`animation.FuncAnimation` 的作用是更新我们传入的图形，使用我们定义的任何函数，在 Zack 的案例中是 `animate_func`。该函数将
    `frames` 参数作为输入，并被调用 `frames` 次。'
- en: The sequence of images is stored as an `[TimedAnimation](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.TimedAnimation.html#matplotlib.animation.TimedAnimation)`
    object, with a time `interval` (in milliseconds) between them.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图像序列被存储为 `[TimedAnimation](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.TimedAnimation.html#matplotlib.animation.TimedAnimation)`
    对象，图像之间有一个时间 `interval`（以毫秒为单位）。
- en: All of this is well explained in the [official matplotlib documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.FuncAnimation.html).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些在 [官方 matplotlib 文档](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.FuncAnimation.html)
    中有很好的解释。
- en: In our case, we need to include in the function all the workaround to avoid
    the new axes overlapping with the surface every time we update the trajectory
    lines.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们需要在函数中包含所有的解决方法，以避免每次更新轨迹线时新轴与表面重叠。
- en: 'Here’s how I defined the update function:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我定义更新函数的方式：
- en: '[PRE7]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Finally, to create the animation, I created a new figure and repeated the process
    of adding the second pair of axes. This time I only plotted the surface, since
    the trajectories will be handled by the `descent_animation` function.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了创建动画，我创建了一个新的图像，并重复添加第二对坐标轴的过程。这次我只绘制了表面，因为轨迹将由 `descent_animation` 函数处理。
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/c226b36a8f2fd30642b025673726beb1.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c226b36a8f2fd30642b025673726beb1.png)'
- en: 'Final result: gradient descent animation created on Python. Image by the author.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果：使用 Python 创建的梯度下降动画。图像由作者提供。
- en: Saving and displaying the animation
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存和显示动画
- en: We can save the animation using a few lines of code.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过几行代码保存动画。
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `PillowWriter` method works well for storing Gif files.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`PillowWriter` 方法适用于存储 Gif 文件。'
- en: The problem with *Gif* files is that you can end up with an unnecessarily large
    file if you have many frames, and want to preserve good image quality.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*Gif* 文件的问题在于，如果你有许多帧并且希望保持良好的图像质量，你可能会得到一个不必要地大的文件。'
- en: To optimize the file size, we could play around with the `interval` passed to
    `FUncAnimation` and specify the FPS and DPI we want to use when creating and saving
    the figure. Otherwise, we could use [EZGif’s Optimization](https://ezgif.com/optimize)
    to reduce the file size.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化文件大小，我们可以调整传递给 `FUncAnimation` 的 `interval` 参数，并指定创建和保存图像时希望使用的 FPS 和 DPI。否则，我们可以使用
    [EZGif 的优化](https://ezgif.com/optimize) 来减少文件大小。
- en: Another option would be storing it as an *MP4* or , even better, *WebM* file,
    using `[FFMpegWriter](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.FFMpegWriter.html#matplotlib.animation.FFMpegWriter)`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是将其存储为 *MP4* 文件，或者更好的是，使用 `[FFMpegWriter](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.FFMpegWriter.html#matplotlib.animation.FFMpegWriter)`
    存储为 *WebM* 文件。
- en: As I have discussed before, [using WebM instead of Gif files can produce a great
    improvement in speed if we want to use the figures for web display](https://medium.com/@luisdamed/using-webm-instead-of-gifs-to-improve-your-blogs-speed-e37f71a45d57),
    or just reduce the file size. Unfortunately, WebM is still not supported on Medium.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前讨论过的，[如果我们想在网页上显示图像，使用 WebM 替代 Gif 文件可以显著提高速度](https://medium.com/@luisdamed/using-webm-instead-of-gifs-to-improve-your-blogs-speed-e37f71a45d57)，或者仅仅是减少文件大小。不幸的是，Medium
    仍然不支持 WebM。
- en: 'Finally, if you are using Jupyter Notebooks or working on [Google Colab](https://colab.research.google.com/),
    you can display the animated figure using:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你正在使用 Jupyter Notebooks 或在 [Google Colab](https://colab.research.google.com/)
    上工作，你可以使用以下方法显示动画图像：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Additional
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附加说明
- en: This type of animated figure is great for comparing the trajectory of different
    types of optimization algorithms.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的动画图像非常适合比较不同类型优化算法的轨迹。
- en: Below, you can see a comparison of the performance of Stochastic Gradient Descent
    (SGD) — the one I’ve shown in this post- and a more advanced method called[*Adam*](https://arxiv.org/abs/1412.6980)
    (derived from Adaptive Moment Estimation), which is currently one of the industry
    standards for training Artificial Neural Networks, because of its robustness and
    speed.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，你可以看到随机梯度下降 (SGD)—我在这篇文章中展示的—与一种更高级的方法 [*Adam*](https://arxiv.org/abs/1412.6980)（源于自适应矩估计）
    的性能比较，Adam 目前是训练人工神经网络的行业标准之一，因为它的鲁棒性和速度。
- en: Both were initialized on the point x = 0.2, y = 1e-8, to provide a challenging
    situation. There is very little offset from the exact symmetry line (y = 0) and
    the small x coordinate provides little room for building momentum when “descending”.
    You can see how Adam manages to break the symmetry after very few iterations when
    compared to SGD.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 两者都在点 x = 0.2, y = 1e-8 初始化，以提供具有挑战性的情况。与精确对称线 (y = 0) 的偏差非常小，且小的 x 坐标在“下降”时提供了很少的动量积累空间。你可以看到，相较于
    SGD，Adam 在经过很少的迭代后就能够打破对称性。
- en: If you are interested in learning more about the differences between these two
    algorithms, check out my article about [advanced methods for gradient descent
    optimization](https://medium.com/towards-data-science/dl-notes-advanced-gradient-descent-4407d84c2515).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣了解这两种算法之间的差异，请查看我关于 [梯度下降优化的高级方法](https://medium.com/towards-data-science/dl-notes-advanced-gradient-descent-4407d84c2515)
    的文章。
- en: '![](../Images/3d771ddaf55ac0c03dd90fb487668e12.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d771ddaf55ac0c03dd90fb487668e12.png)'
- en: Comparison of SGD vs Adam. Image by the author.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: So that’s all for this one.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading! I hope you could find any useful information from what
    I shared, and perhaps use it for your own projects.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in learning more about gradient descent and neural networks,
    I recommend you read my other articles on those topics.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@luisdamed/gradient-descent-f09f19eb35fb?source=post_page-----3c4dcd20ca51--------------------------------)
    [## DL Notes: Gradient descent'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: How Neural Networks “Learn”
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'medium.com](https://medium.com/@luisdamed/gradient-descent-f09f19eb35fb?source=post_page-----3c4dcd20ca51--------------------------------)
    [](https://medium.com/@luisdamed/feedforward-artificial-neural-networks-52bcf96d6ac3?source=post_page-----3c4dcd20ca51--------------------------------)
    [## DL Notes: Feedforward Artificial Neural Networks'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The basic concept, explained
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@luisdamed/feedforward-artificial-neural-networks-52bcf96d6ac3?source=post_page-----3c4dcd20ca51--------------------------------)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: I’m writing a series of articles about Deep Learning and Machine Learning, but
    I’ll be also publishing *meta* content about other things I learn while writing
    those articles — this post is an example. So not only the theory and applications
    of DL but also Python programming tips like this one.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Be sure to follow me and subscribe to my emails to get notified whenever I publish
    new posts!
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
