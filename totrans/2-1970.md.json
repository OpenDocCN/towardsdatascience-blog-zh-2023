["```py\nmkdir js-lambda-unit-tests\ncd js-lambda-unit-tests\nmkdir stack\ncd stack\nmkdir js-lambda-unit-tests\ncd js-lambda-unit-tests\n```", "```py\n.\n├── app.js\n├── node_modules\n├── package-lock.json\n├── package.json\n└── test\n    ├── event.json\n    └── unit\n        ├── lambdaResponseTest.js\n        └── runTimeTest.js\n```", "```py\nexports.handler = async(event) => {\n\n    try {\n        const jobs = event.jobs;\n        const successfullJobs = await processEvent(jobs);\n\n        return {\n            'statusCode': 200,\n            'data': successfullJobs },\n            'context': context ? context.succeed() : null,\n        ;\n\n    } catch (e) {\n        console.log(e);\n        return {\n            'statusCode': 400,\n            'data': e \n            'context': context ? context.done() : null,\n        };\n    }\n};\n```", "```py\n...\n\"author\": \"Mike Shakhomirov mike.shakhomirov@gmail.com\",\n  \"license\": \"ISC\",\n\"devDependencies\": {\n    \"aws-sdk\": \"2.804.0\",\n    \"run-local-lambda\": \"1.1.1\",\n    \"eslint\": \"^7.20.0\",\n    \"eslint-plugin-classes\": \"^0.1.1\",\n    \"eslint-plugin-promise\": \"^4.3.1\",\n    \"mocha\": \"^7.1.1\",\n    \"chai\": \"^4.2.0\"\n  },\n  \"dependencies\": {\n    \"moment\": \"^2.24.0\"\n  }\n...\n```", "```py\n{   \"configOverride\": false,\n    \"jobs\": [\n\n        {\n            \"name\": \"gcp_to_s3\",\n            \"output\": \"s3\",\n            \"dryRun\": true,\n            \"disabled\": false,\n            \"s3Key\": \"gcs/\",\n            \"s3Bucket\": \"data-staging.avro.aws\",\n            \"sourceBucket\": \"data-staging-gcs-avro\"\n        }\n]\n}\n```", "```py\nconst processEvent = async(jobs) => {\n    const now = moment.utc();\n    const jobList = [];\n    for (const job of jobs) {\n        const jobTime = now.format('YYYY-MM-DD HH:mm');\n        jobList.push({\n            name: job.name,\n            runTime: jobTime,\n        })\n    }\n    return jobList;\n};\n```", "```py\nconst moment = require('moment');\n\nexports.handler = async(event, context) => {\n\n    console.log('Now: ', moment());\n    try {\n        const jobs = event.jobs;\n        const successfullJobs = await processEvent(jobs);\n\n        return {\n            'statusCode': 200,\n            'data': successfullJobs,\n            'result': context.succeed() \n        };\n\n    } catch (e) {\n        console.log(e);\n        return {\n            'statusCode': 400,\n            'data': e,\n            'result': context.done() \n        };\n    }\n};\n\nconst processEvent = async(jobs) => {\n    const now = moment.utc();\n    console.log(jobs);\n    const jobList = [];\n    for (const job of jobs) {\n        const jobTime = now.format('YYYY-MM-DD HH:mm');\n        jobList.push({\n            name: job.name,\n            runTime: jobTime,\n        })\n        console.log(jobList);\n    }\n    return jobList;\n};\n```", "```py\n...\n  \"scripts\": {\n    \"local\": \"export DEBUG=true; export NODE_ENV=staging; run-local-lambda --file app.js --event test/event.json --timeout 1000000\",\n    \"test\": \"test\"\n  },\n...\n```", "```py\nconst chai = require('chai');\nconst expect = chai.expect;\n\nconst app = require('../../app');\n\ndescribe('When transferring data from one cloud to another: return a list of jobs', () => {\n    before(async() => {\n\n    });\n\n    beforeEach(async() => {\n\n    });\n\n    after(async() => {\n\n    });\n\n    afterEach(async() => {\n\n    });\n\n    it('should return a 200 statusCode and array [] of jobs each having a runTime key', async() => {\n        const event = { 'configOverride': true,\n            'jobs': [\n                {\n                    'name': 'gcp_to_s3',\n                    'output': 's3',\n                    'dryRun': true,\n                    'disabled': false,\n                    's3Key': 'gcs/',\n                    's3Bucket': 'data-staging.avro.aws',\n                    'sourceBucket': 'data-staging-gcs-avro',\n                },\n            ],\n        };\n        const response = await app.handler(event);\n        console.log(response);\n        expect(response).to.have.property('statusCode');\n        expect(response.statusCode).to.be.deep.equal(200);\n        expect((response.data).length).to.equal(1);\n        expect((response.data)[0]).to.have.all.keys('name', 'runTime');\n\n    });\n\n});\n```", "```py\n...\n\"scripts\": {\n    \"local\": \"export DEBUG=true; export NODE_ENV=staging; run-local-lambda --file app.js --event test/event.json --timeout 1\",\n    \"test-lambda-runtime\": \"NODE_ENV=test mocha --timeout 10000 ./test/unit/runTimeTest.js\",\n...\n```", "```py\nconst chai = require('chai');\nconst expect = chai.expect;\n\nconst app = require('../../app');\n\ndescribe('When transferring data from one cloud to another: return a response code', () => {\n    before(async() => {\n\n    });\n\n    beforeEach(async() => {\n\n    });\n\n    after(async() => {\n\n    });\n\n    afterEach(async() => {\n\n    });\n\n    it('should return a 400 statusCode when Error', async() => {\n        const event = { 'configOverride': true,\n            'jobs': [\n                {\n                    'name_missing': 'gcp_to_s3',\n                    'output': 's3',\n                    'dryRun': true,\n                    'disabled': false,\n                    's3Key': 'gcs/',\n                    's3Bucket': 'data-staging.avro.aws',\n                    'sourceBucket': 'data-staging-gcs-avro',\n                },\n            ],\n        };\n        const response = await app.handler(event);\n        console.log(response);\n        expect(response).to.have.property('statusCode');\n        expect(response.statusCode).to.be.deep.equal(400);\n\n    });\n\n    it('should return a 200 statusCode when Succeed', async() => {\n        const event = { 'configOverride': true,\n            'jobs': [\n                {\n                    'name': 'gcp_to_s3',\n                    'output': 's3',\n                    'dryRun': true,\n                    'disabled': false,\n                    's3Key': 'gcs/',\n                    's3Bucket': 'data-staging.avro.aws',\n                    'sourceBucket': 'data-staging-gcs-avro',\n                },\n            ],\n        };\n        const response = await app.handler(event);\n        console.log(response);\n        expect(response).to.have.property('statusCode');\n        expect(response.statusCode).to.be.deep.equal(200);\n\n    });\n\n});\n```", "```py\n// in lambda.handler add this:\n\n...\n        if (successfullJobs.errorCode) {\n            throw successfullJobs;\n        }\n...\n// in processEvent() add this:\n...\n            if (typeof job.name === 'undefined') {\n                throw { errorCode: 1, message: 'job.name is missing' };\n            }\n\n...\n```", "```py\n/* eslint-disable no-throw-literal */\nconst moment = require('moment');\n\nexports.handler = async(event, context) => {\n\n    console.log('Now: ', moment());\n    try {\n        const jobs = event.jobs;\n        const successfullJobs = await processEvent(jobs);\n\n        if (successfullJobs.errorCode) {\n            throw successfullJobs;\n        }\n        console.log(successfullJobs);\n\n        return {\n            'statusCode': 200,\n            'data': successfullJobs,\n            'context': context ? context.succeed() : null,\n        };\n\n    } catch (e) {\n        return {\n            'statusCode': 400,\n            'data': e,\n            'context': context ? context.done() : null,\n\n        };\n\n    }\n};\n\nconst processEvent = async(jobs) => {\n    const now = moment.utc();\n    console.log(jobs);\n    const jobList = [];\n    for (const job of jobs) {\n\n        try {\n            if (typeof job.name === 'undefined') {\n                throw { errorCode: 1, message: 'job.name is missing' };\n            }\n            const jobTime = now.format('YYYY-MM-DD HH:mm');\n            jobList.push({\n                name: job.name,\n                runTime: jobTime,\n            });\n\n        } catch (error) {\n            return error;\n        }\n\n    }\n    return jobList;\n};\n```", "```py\n...\n\"scripts\": {\n    \"local\": \"export DEBUG=true; export NODE_ENV=staging; run-local-lambda --file app.js --event test/event.json --timeout 1\",\n    \"test-lambda-runtime\": \"NODE_ENV=test mocha --timeout 10000 ./test/unit/runTimeTest.js\",\n    \"test-lambda-response\": \"NODE_ENV=test mocha --timeout 10000 ./test/unit/lambdaResponseTest.js\",\n    \"test-unit\": \"NODE_ENV=test mocha NODE_ENV=test --exit --recursive ./test/unit\",\n    \"test-integration\": \"NODE_ENV=test mocha --delay --exit --require ./test/fixtures/bigquery-integration-bootstrap.js --timeout 100000 ./test/integration/multiCategoryArchiveTest.js\"\n  },\n```"]