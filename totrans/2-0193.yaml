- en: A Framework for Building a Production-Ready Feature Engineering Pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„å»ºç”Ÿäº§å°±ç»ªç‰¹å¾å·¥ç¨‹ç®¡é“çš„æ¡†æ¶
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f](https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f](https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)
- en: '[The Full Stack 7-Steps MLOps Framework](https://towardsdatascience.com/tagged/full-stack-mlops)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[å…¨æ ˆ 7 æ­¥ MLOps æ¡†æ¶](https://towardsdatascience.com/tagged/full-stack-mlops)'
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'è¯¾ç¨‹ 1: æ‰¹é‡æœåŠ¡ã€‚ç‰¹å¾å­˜å‚¨ã€‚ç‰¹å¾å·¥ç¨‹ç®¡é“ã€‚'
- en: '[](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    Â·13 min readÂ·Apr 28, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    Â·13åˆ†é’Ÿé˜…è¯»Â·2023å¹´4æœˆ28æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2ae381d9f40ec629b5dacf7b06536a4e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ae381d9f40ec629b5dacf7b06536a4e.png)'
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡'
- en: This tutorial represents **lesson 1 out of a 7-lesson course** that will walk
    you step-by-step through how to **design, implement, and deploy an ML system**
    using **MLOps good practices**. During the course, you will build a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ•™ç¨‹ä»£è¡¨**ä¸€ä¸ªåŒ…å« 7 è¯¾æ—¶çš„è¯¾ç¨‹ä¸­çš„ç¬¬ 1 è¯¾**ï¼Œå°†é€æ­¥æŒ‡å¯¼ä½ å¦‚ä½•**è®¾è®¡ã€å®æ–½å’Œéƒ¨ç½² ML ç³»ç»Ÿ**ï¼Œä½¿ç”¨**MLOps ä¼˜è‰¯å®è·µ**ã€‚åœ¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†æ„å»ºä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹ä¸¹éº¦æœªæ¥
    24 å°æ—¶å†…çš„èƒ½æºæ¶ˆè€—æ°´å¹³ï¼Œæ¶µç›–å¤šä¸ªæ¶ˆè´¹ç±»å‹ã€‚
- en: '*By the end of this course, you will understand all the fundamentals of designing,
    coding and deploying an ML system using a batch-serving architecture.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*å®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†äº†è§£ä½¿ç”¨æ‰¹é‡æœåŠ¡æ¶æ„è®¾è®¡ã€ç¼–ç å’Œéƒ¨ç½² ML ç³»ç»Ÿçš„æ‰€æœ‰åŸºæœ¬çŸ¥è¯†ã€‚*'
- en: This course *targets mid/advanced machine learning engineers* who want to level
    up their skills by building their own end-to-end projects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è¯¾ç¨‹*é’ˆå¯¹ä¸­çº§/é«˜çº§æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ*ï¼Œæ—¨åœ¨é€šè¿‡æ„å»ºè‡ªå·±çš„ç«¯åˆ°ç«¯é¡¹ç›®æ¥æå‡æŠ€èƒ½ã€‚
- en: Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚ä»Šï¼Œè¯ä¹¦éšå¤„å¯è§ã€‚æ„å»ºå…ˆè¿›çš„ç«¯åˆ°ç«¯é¡¹ç›®å¹¶å±•ç¤ºæ˜¯è·å¾—ä¸“ä¸šå·¥ç¨‹å¸ˆè®¤å¯çš„æœ€ä½³é€”å¾„ã€‚
- en: 'Table of Contents:'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç›®å½•ï¼š
- en: Course Introduction
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹ä»‹ç»
- en: Course Lessons
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹å†…å®¹
- en: Data Source
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®æº
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'è¯¾ç¨‹ 1: æ‰¹é‡æœåŠ¡ã€‚ç‰¹å¾å­˜å‚¨ã€‚ç‰¹å¾å·¥ç¨‹ç®¡é“ã€‚'
- en: 'Lesson 1: Code'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'è¯¾ç¨‹ 1: ä»£ç '
- en: Conclusion
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: References
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: Introduction
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: '***At the end of this 7 lessons course, you will know how to:***'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '***åœ¨è¿™ 7 è¯¾æ—¶çš„è¯¾ç¨‹ç»“æŸæ—¶ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•:***'
- en: design a batch-serving architecture
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¾è®¡æ‰¹é‡æœåŠ¡æ¶æ„
- en: use Hopsworks as a feature store
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Hopsworks ä½œä¸ºç‰¹å¾å­˜å‚¨
- en: design a feature engineering pipeline that reads data from an API
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¾è®¡ä¸€ä¸ªä»APIè¯»å–æ•°æ®çš„ç‰¹å¾å·¥ç¨‹ç®¡é“
- en: build a training pipeline with hyper-parameter tunning
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºå¸¦æœ‰è¶…å‚æ•°è°ƒä¼˜çš„è®­ç»ƒç®¡é“
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ W&B ä½œä¸º ML å¹³å°æ¥è·Ÿè¸ªä½ çš„å®éªŒã€æ¨¡å‹å’Œå…ƒæ•°æ®
- en: implement a batch prediction pipeline
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°æ‰¹é‡é¢„æµ‹ç®¡é“
- en: use Poetry to build your own Python packages
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Poetry æ„å»ºè‡ªå·±çš„ Python åŒ…
- en: deploy your own private PyPi server
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éƒ¨ç½²è‡ªå·±çš„ç§äºº PyPi æœåŠ¡å™¨
- en: orchestrate everything with Airflow
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Airflow åè°ƒä¸€åˆ‡
- en: use the predictions to code a web app using FastAPI and Streamlit
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é¢„æµ‹ç»“æœç¼–ç ä¸€ä¸ªä½¿ç”¨ FastAPI å’Œ Streamlit çš„ Web åº”ç”¨
- en: use Docker to containerize your code
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Docker å®¹å™¨åŒ–ä½ çš„ä»£ç 
- en: use Great Expectations to ensure data validation and integrity
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Great Expectations ç¡®ä¿æ•°æ®éªŒè¯å’Œå®Œæ•´æ€§
- en: monitor the performance of the predictions over time
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›‘æ§é¢„æµ‹æ€§èƒ½çš„å˜åŒ–
- en: deploy everything to GCP
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰å†…å®¹éƒ¨ç½²åˆ° GCP
- en: build a CI/CD pipeline using GitHub Actions
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GitHub Actions æ„å»º CI/CD æµæ°´çº¿
- en: If that sounds like a lot, don't worry, after you will cover this course you
    will understand everything I said before. Most importantly, you will know WHY
    I used all these tools and how they work together as a system.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™äº›å¬èµ·æ¥å¾ˆå¤šï¼Œä¸ç”¨æ‹…å¿ƒï¼Œå®Œæˆæœ¬è¯¾ç¨‹åä½ å°†ç†è§£æˆ‘ä¹‹å‰è¯´çš„ä¸€åˆ‡ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œä½ å°†äº†è§£æˆ‘ä¸ºä½•ä½¿ç”¨è¿™äº›å·¥å…·ä»¥åŠå®ƒä»¬å¦‚ä½•ä½œä¸ºä¸€ä¸ªç³»ç»ŸååŒå·¥ä½œã€‚
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. I designed the articles so you can read and run the code
    while reading the course.**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¦‚æœä½ æƒ³æœ€å¤§åŒ–æœ¬è¯¾ç¨‹çš„æ”¶ç›Šï¼Œ** [**æˆ‘å»ºè®®ä½ è®¿é—®åŒ…å«æ‰€æœ‰è¯¾ç¨‹ä»£ç çš„ GitHub ä»“åº“**](https://github.com/iusztinpaul/energy-forecasting)
    **ã€‚æˆ‘è®¾è®¡äº†è¿™äº›æ–‡ç« ï¼Œä½¿ä½ åœ¨é˜…è¯»è¯¾ç¨‹çš„åŒæ—¶å¯ä»¥é˜…è¯»å¹¶è¿è¡Œä»£ç ã€‚**'
- en: By the end of the course, you will know how to implement the diagram below.
    Don't worry if something doesn't make sense to you. I will explain everything
    in detail.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°è¯¾ç¨‹ç»“æŸæ—¶ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•å®ç°ä¸‹é¢çš„å›¾ç¤ºã€‚å¦‚æœæœ‰äº›å†…å®¹å¯¹ä½ æ¥è¯´ä¸å¤ªæ˜ç™½ï¼Œä¸ç”¨æ‹…å¿ƒã€‚æˆ‘ä¼šè¯¦ç»†è§£é‡Šä¸€åˆ‡ã€‚
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
- en: Diagram of the architecture you will build during the course [Image by the Author].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹ä¸­ä½ å°†æ„å»ºçš„æ¶æ„å›¾ [å›¾ç¤ºæ¥æºäºä½œè€…]ã€‚
- en: '***Why batch serving?***'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '***ä¸ºä»€ä¹ˆæ‰¹é‡æœåŠ¡ï¼Ÿ***'
- en: 'There are 4 main types of deploying a model:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„éƒ¨ç½²ä¸»è¦æœ‰ 4 ç§ç±»å‹ï¼š
- en: batch serving
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¹é‡æœåŠ¡
- en: request-response
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: request-response
- en: streaming
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµå¼å¤„ç†
- en: embedded
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åµŒå…¥å¼
- en: Batch serving is the perfect starting point for getting hands-on experience
    with building a real-world ML system because most AI applications start using
    batch architecture and move towards request-response or streaming.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¹é‡æœåŠ¡æ˜¯è·å–å®é™…æ“ä½œç»éªŒçš„ç»ä½³èµ·ç‚¹ï¼Œå› ä¸ºå¤§å¤šæ•° AI åº”ç”¨ç¨‹åºä»ä½¿ç”¨æ‰¹é‡æ¶æ„å¼€å§‹ï¼Œç„¶åè½¬å‘è¯·æ±‚å“åº”æˆ–æµå¼å¤„ç†ã€‚
- en: 'Lessons:'
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹å†…å®¹ï¼š
- en: '**Batch Serving. Feature Stores. Feature Engineering Pipelines.**'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ‰¹é‡æœåŠ¡ã€‚ç‰¹å¾å­˜å‚¨ã€‚ç‰¹å¾å·¥ç¨‹æµæ°´çº¿ã€‚**'
- en: '[Training Pipelines. ML Platforms. Hyperparameter Tuning.](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[è®­ç»ƒæµæ°´çº¿ã€‚ML å¹³å°ã€‚è¶…å‚æ•°è°ƒæ•´ã€‚](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[æ‰¹é‡é¢„æµ‹æµæ°´çº¿ã€‚ä½¿ç”¨ Poetry æ‰“åŒ… Python æ¨¡å—ã€‚](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ç§äºº PyPi æœåŠ¡å™¨ã€‚ä½¿ç”¨ Airflow åè°ƒä¸€åˆ‡ã€‚](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
- en: '[Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ä½¿ç”¨ GE è¿›è¡Œæ•°æ®éªŒè¯ä»¥ç¡®ä¿è´¨é‡å’Œå®Œæ•´æ€§ã€‚æ¨¡å‹æ€§èƒ½æŒç»­ç›‘æ§ã€‚](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
- en: '[Consume and Visualize your Modelâ€™s Predictions using FastAPI and Streamlit.
    Dockerize Everything.](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ä½¿ç”¨ FastAPI å’Œ Streamlit æ¶ˆè´¹å’Œå¯è§†åŒ–ä½ çš„æ¨¡å‹é¢„æµ‹ã€‚å°†ä¸€åˆ‡å®¹å™¨åŒ–ã€‚](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
- en: '[Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github Actions.](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[å°†æ‰€æœ‰ ML ç»„ä»¶éƒ¨ç½²åˆ° GCPã€‚ä½¿ç”¨ Github Actions æ„å»º CI/CD æµæ°´çº¿ã€‚](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
- en: '[[Bonus] Behind the Scenes of an â€˜Imperfectâ€™ ML Project â€” Lessons and Insights](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[[é™„åŠ ] â€˜ä¸å®Œç¾â€™ ML é¡¹ç›®çš„å¹•åâ€”â€”æ•™è®­ä¸è§è§£](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
- en: 'Data Source:'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æºï¼š
- en: We used an open API that provides hourly energy consumption values for all the
    energy consumer types within Denmark.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªå¼€æ”¾ APIï¼Œæä¾›ä¸¹éº¦æ‰€æœ‰èƒ½æºæ¶ˆè´¹è€…ç±»å‹çš„æ¯å°æ—¶èƒ½æºæ¶ˆè€—å€¼ã€‚
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬æä¾›äº†ä¸€ä¸ªç›´è§‚çš„ç•Œé¢ï¼Œä½ å¯ä»¥è½»æ¾æŸ¥è¯¢å’Œå¯è§†åŒ–æ•°æ®ã€‚[ä½ å¯ä»¥åœ¨è¿™é‡Œè®¿é—®æ•°æ®](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1]ã€‚
- en: 'The data has 4 main attributes:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æœ‰4ä¸ªä¸»è¦å±æ€§ï¼š
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å°æ—¶ UTCï¼š** è§‚å¯Ÿåˆ°æ•°æ®ç‚¹æ—¶çš„ UTC æ—¥æœŸæ—¶é—´ã€‚'
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 â€” divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»·æ ¼åŒºåŸŸï¼š** ä¸¹éº¦è¢«åˆ’åˆ†ä¸ºä¸¤ä¸ªä»·æ ¼åŒºåŸŸï¼šDK1 å’Œ DK2â€”â€”ç”±å¤§è´å°”ç‰¹æµ·å³¡åˆ†éš”ã€‚DK1 ä½äºå¤§è´å°”ç‰¹çš„è¥¿ä¾§ï¼ŒDK2 ä½äºä¸œä¾§ã€‚'
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¶ˆè´¹è€…ç±»å‹ï¼š** æ¶ˆè´¹è€…ç±»å‹ä¸ºå·¥ä¸šä»£ç  DE35ï¼Œç”±ä¸¹éº¦èƒ½æºå…¬å¸æ‹¥æœ‰å’Œç»´æŠ¤ã€‚'
- en: '**Total Consumption:** Total electricity consumption in kWh'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ€»æ¶ˆè€—ï¼š** æ€»ç”µåŠ›æ¶ˆè€—ï¼ˆkWhï¼‰'
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would be in real-time.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** è§‚å¯Ÿå€¼æœ‰15å¤©çš„æ»åï¼ä½†å¯¹äºæˆ‘ä»¬çš„æ¼”ç¤ºç”¨ä¾‹ï¼Œè¿™ä¸æ˜¯é—®é¢˜ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥æ¨¡æ‹Ÿä¸å®æ—¶ç›¸åŒçš„æ­¥éª¤ã€‚'
- en: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
- en: A screenshot from the app shows how we forecasted the energy consumption for
    area = 1 and consumer type = 212 [Image by the Author].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨ç¨‹åºä¸­çš„æˆªå›¾å±•ç¤ºäº†æˆ‘ä»¬å¦‚ä½•é¢„æµ‹åŒºåŸŸ = 1 å’Œæ¶ˆè´¹è€…ç±»å‹ = 212 çš„èƒ½æºæ¶ˆè€— [ä½œè€…æä¾›çš„å›¾ç‰‡]ã€‚
- en: 'The data points have an hourly resolution. For example: "2023â€“04â€“15 21:00Z",
    "2023â€“04â€“15 20:00Z", "2023â€“04â€“15 19:00Z", etc.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç‚¹å…·æœ‰æ¯å°æ—¶çš„åˆ†è¾¨ç‡ã€‚ä¾‹å¦‚ï¼šâ€œ2023â€“04â€“15 21:00Zâ€ï¼Œâ€œ2023â€“04â€“15 20:00Zâ€ï¼Œâ€œ2023â€“04â€“15 19:00Zâ€ç­‰ç­‰ã€‚
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æŠŠæ•°æ®å»ºæ¨¡ä¸ºå¤šä¸ªæ—¶é—´åºåˆ—ã€‚æ¯ä¸ªç‹¬ç‰¹çš„**ä»·æ ¼åŒºåŸŸ**å’Œ**æ¶ˆè´¹è€…ç±»å‹**å…ƒç»„è¡¨ç¤ºå…¶ç‹¬ç‰¹çš„æ—¶é—´åºåˆ—ã€‚
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œç‹¬ç«‹é¢„æµ‹æ¯ä¸ªæ—¶é—´åºåˆ—æ¥ä¸‹æ¥ 24 å°æ—¶çš„èƒ½æºæ¶ˆè€—ã€‚
- en: '*Check out the video below to better understand what the data looks like* ğŸ‘‡'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*æŸ¥çœ‹ä¸‹é¢çš„è§†é¢‘ï¼Œæ›´å¥½åœ°ç†è§£æ•°æ®çš„æ ·å­* ğŸ‘‡'
- en: Course & data source overview [Video by the Author].
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹ä¸æ•°æ®æºæ¦‚è§ˆ [ä½œè€…æä¾›çš„è§†é¢‘]ã€‚
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬1è¯¾ï¼šæ‰¹é‡æœåŠ¡ã€‚ç‰¹å¾å­˜å‚¨ã€‚ç‰¹å¾å·¥ç¨‹ç®¡é“ã€‚
- en: The Goal of Lesson 1
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬1è¯¾çš„ç›®æ ‡
- en: 'In lesson 1, we will focus on the components highlighted in blue: "API," "Feature
    Engineering," and the "Feature Store," as we can see in the diagram below.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬1è¯¾ä¸­ï¼Œæˆ‘ä»¬å°†å…³æ³¨å›¾ä¸­è“è‰²çªå‡ºæ˜¾ç¤ºçš„ç»„ä»¶ï¼šâ€œAPIâ€ï¼Œâ€œç‰¹å¾å·¥ç¨‹â€å’Œâ€œç‰¹å¾å­˜å‚¨â€ã€‚
- en: '![](../Images/f8a16b0c5164f20ee8c313126196f321.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8a16b0c5164f20ee8c313126196f321.png)'
- en: Diagram of the final architecture with the Lesson 1 components highlighted in
    blue [Image by the Author].
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆæ¶æ„çš„ç¤ºæ„å›¾ï¼Œå…¶ä¸­ç¬¬1è¯¾çš„ç»„ä»¶ç”¨è“è‰²çªå‡ºæ˜¾ç¤º [ä½œè€…æä¾›çš„å›¾ç‰‡]ã€‚
- en: Concretely, we will build an ETL pipeline that extracts data from the energy
    consumption API, pass them through the feature engineering pipeline, which cleans
    and transforms the features, and loads the features in the feature store for further
    usage across the system.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª ETL ç®¡é“ï¼Œä»èƒ½æºæ¶ˆè€— API ä¸­æå–æ•°æ®ï¼Œç»è¿‡ç‰¹å¾å·¥ç¨‹ç®¡é“ï¼Œè¯¥ç®¡é“æ¸…æ´—å’Œè½¬æ¢ç‰¹å¾ï¼Œå¹¶å°†ç‰¹å¾åŠ è½½åˆ°ç‰¹å¾å­˜å‚¨ä¸­ï¼Œä»¥ä¾¿åœ¨ç³»ç»Ÿä¸­è¿›ä¸€æ­¥ä½¿ç”¨ã€‚
- en: As you can see, the feature store stands at the heart of the system.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œç‰¹å¾å­˜å‚¨ç«™åœ¨ç³»ç»Ÿçš„æ ¸å¿ƒä½ç½®ã€‚
- en: Theoretical Concepts & Tools
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç†è®ºæ¦‚å¿µä¸å·¥å…·
- en: '**Batch Serving:** in the batch serving paradigm, you can prepare your data,
    train your model, and make predictions in an offline fashion. Afterward, you store
    the predictions in a database from where a client/application will use the predictions
    down the line. The word **batch** comes from the idea that you can process multiple
    samples simultaneously, which in this paradigm is usually valid. We computed all
    the predictions in our use case and stored them in a blob storage/bucket.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ‰¹é‡æœåŠ¡ï¼š** åœ¨æ‰¹é‡æœåŠ¡æ¨¡å¼ä¸­ï¼Œä½ å¯ä»¥ç¦»çº¿å‡†å¤‡æ•°æ®ã€è®­ç»ƒæ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹ã€‚ä¹‹åï¼Œä½ å°†é¢„æµ‹ç»“æœå­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œå®¢æˆ·ç«¯/åº”ç”¨ç¨‹åºå°†åœ¨åç»­ä½¿ç”¨è¿™äº›é¢„æµ‹ç»“æœã€‚**æ‰¹é‡**è¿™ä¸ªè¯æ¥æºäºä½ å¯ä»¥åŒæ—¶å¤„ç†å¤šä¸ªæ ·æœ¬ï¼Œè¿™åœ¨è¿™ç§æ¨¡å¼ä¸‹é€šå¸¸æ˜¯æœ‰æ•ˆçš„ã€‚æˆ‘ä»¬è®¡ç®—äº†æ‰€æœ‰é¢„æµ‹ç»“æœå¹¶å°†å…¶å­˜å‚¨åœ¨
    blob å­˜å‚¨/æ¡¶ä¸­ã€‚'
- en: If we would oversimplify our architecture to reflect only the main steps of
    a batch architecture, this is how it would look like ğŸ‘‡
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°†æ¶æ„è¿‡äºç®€åŒ–ï¼Œä»…åæ˜ æ‰¹é‡æ¶æ„çš„ä¸»è¦æ­¥éª¤ï¼Œå®ƒå°†å¦‚ä¸‹æ‰€ç¤º ğŸ‘‡
- en: '![](../Images/8a22ababb6bd63765cd79be166f81414.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a22ababb6bd63765cd79be166f81414.png)'
- en: Batch architecture [Image by the Author].
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¹å¤„ç†æ¶æ„ [ä½œè€…æä¾›çš„å›¾ç‰‡]ã€‚
- en: The biggest downside of the batch-serving paradigm is that your predictions
    will almost always lag. For example, in our case, we predict the energy consumption
    for the next 24 hours, and because of this lag, our predictions might be 1 hour
    late.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¹å¤„ç†æœåŠ¡èŒƒå¼çš„æœ€å¤§ç¼ºç‚¹æ˜¯ä½ çš„é¢„æµ‹å‡ ä¹æ€»æ˜¯ä¼šæ»åã€‚ä¾‹å¦‚ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬é¢„æµ‹æœªæ¥24å°æ—¶çš„èƒ½è€—ï¼Œç”±äºè¿™ç§æ»åï¼Œæˆ‘ä»¬çš„é¢„æµ‹å¯èƒ½ä¼šè¿Ÿåˆ°1å°æ—¶ã€‚
- en: '[Check out this article](https://medium.com/mlearning-ai/this-is-what-you-need-to-know-to-build-an-mlops-end-to-end-architecture-c0be1deaa3ce)
    to learn more about a *standardized architecture* *suggested by* *Google Cloud*
    that can be leveraged in almost any ML system.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹è¿™ç¯‡æ–‡ç« ](https://medium.com/mlearning-ai/this-is-what-you-need-to-know-to-build-an-mlops-end-to-end-architecture-c0be1deaa3ce)ä»¥äº†è§£æ›´å¤šå…³äº*Google
    Cloud* *å»ºè®®çš„* *æ ‡å‡†åŒ–æ¶æ„*ï¼Œè¿™åœ¨å‡ ä¹ä»»ä½•æœºå™¨å­¦ä¹ ç³»ç»Ÿä¸­éƒ½å¯ä»¥åˆ©ç”¨ã€‚'
- en: '**Feature Store:** the feature store stays at the heart of any ML system. Using
    a feature store, you can easily store and share features across the system. You
    can intuitively see a feature store as a fancy database that adds the following
    features:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å­˜å‚¨ï¼š**ç‰¹å¾å­˜å‚¨ä½äºä»»ä½•æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„æ ¸å¿ƒã€‚ä½¿ç”¨ç‰¹å¾å­˜å‚¨ï¼Œä½ å¯ä»¥è½»æ¾åœ°å­˜å‚¨å’Œå…±äº«ç³»ç»Ÿä¸­çš„ç‰¹å¾ã€‚ä½ å¯ä»¥ç›´è§‚åœ°å°†ç‰¹å¾å­˜å‚¨è§†ä¸ºä¸€ä¸ªé«˜çº§æ•°æ®åº“ï¼Œå¢åŠ ä»¥ä¸‹åŠŸèƒ½ï¼š'
- en: data versioning and lineage
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®ç‰ˆæœ¬æ§åˆ¶å’Œè¡€ç¼˜
- en: data validation
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®éªŒè¯
- en: the ability to create datasets
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºæ•°æ®é›†çš„èƒ½åŠ›
- en: the ability to hold train/validation/test splits
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ‹†åˆ†çš„èƒ½åŠ›
- en: 'two types of storage: offline (cheap, but high latency) and online (more expensive,
    but low latency).'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸¤ç§å­˜å‚¨ç±»å‹ï¼šç¦»çº¿ï¼ˆä¾¿å®œï¼Œä½†å»¶è¿Ÿé«˜ï¼‰å’Œåœ¨çº¿ï¼ˆæ›´è´µï¼Œä½†å»¶è¿Ÿä½ï¼‰ã€‚
- en: 'time-travel: easily access data given a time window'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ—¶é—´æ—…è¡Œï¼šåœ¨ç»™å®šæ—¶é—´çª—å£å†…è½»æ¾è®¿é—®æ•°æ®
- en: hold feature transformation in addition to the feature themselves
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†ç‰¹å¾æœ¬èº«å¤–ï¼Œè¿˜ä¿å­˜ç‰¹å¾è½¬æ¢
- en: data monitoring, etc...â€¦
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®ç›‘æ§ç­‰â€¦â€¦
- en: If you want to read about feature stores, [check out this article](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)
    [3].
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³é˜…è¯»å…³äºç‰¹å¾å­˜å‚¨çš„å†…å®¹ï¼Œ[è¯·æŸ¥çœ‹è¿™ç¯‡æ–‡ç« ](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)
    [3]ã€‚
- en: We chose [Hopsworks](https://www.hopsworks.ai/) as our feature store because
    it is serverless and offers a generous free plan that is more than enough to create
    this course.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€‰æ‹©äº†[Hopsworks](https://www.hopsworks.ai/)ä½œä¸ºæˆ‘ä»¬çš„ç‰¹å¾å­˜å‚¨ï¼Œå› ä¸ºå®ƒæ˜¯æ— æœåŠ¡å™¨çš„ï¼Œå¹¶æä¾›äº†æ…·æ…¨çš„å…è´¹è®¡åˆ’ï¼Œè¿™è¶³ä»¥åˆ›å»ºæœ¬è¯¾ç¨‹ã€‚
- en: Also, Hopsworks is very well designed and provides all the features mentioned
    above. If you are looking for a serverless feature store, I recommend them.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼ŒHopsworksè®¾è®¡éå¸¸ä¼˜ç§€ï¼Œå¹¶æä¾›äº†ä¸Šè¿°æ‰€æœ‰åŠŸèƒ½ã€‚å¦‚æœä½ åœ¨å¯»æ‰¾æ— æœåŠ¡å™¨çš„ç‰¹å¾å­˜å‚¨ï¼Œæˆ‘æ¨èä»–ä»¬ã€‚
- en: If you want also to run the code while reading this lesson, you have to go to
    [Hopswork](https://www.hopsworks.ai/), create an account, and a project. All the
    other steps will be explained in the rest of the class.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿˜æƒ³åœ¨é˜…è¯»æœ¬è¯¾ç¨‹æ—¶è¿è¡Œä»£ç ï¼Œä½ éœ€è¦å»[Hopswork](https://www.hopsworks.ai/)ï¼Œåˆ›å»ºä¸€ä¸ªè´¦æˆ·å’Œé¡¹ç›®ã€‚æ‰€æœ‰å…¶ä»–æ­¥éª¤å°†åœ¨è¯¾ç¨‹çš„å…¶ä½™éƒ¨åˆ†ä¸­è§£é‡Šã€‚
- en: I ensured that all the steps from this course would remain in their free plan.
    Thus it won't cost you any $$$.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç¡®ä¿äº†æœ¬è¯¾ç¨‹ä¸­çš„æ‰€æœ‰æ­¥éª¤éƒ½èƒ½ä¿ç•™åœ¨ä»–ä»¬çš„å…è´¹è®¡åˆ’ä¸­ã€‚å› æ­¤ï¼Œå®ƒä¸ä¼šèŠ±è´¹ä½ ä»»ä½•$$$ã€‚
- en: '**Feature Engineering Pipeline:** the piece of code that reads data from one
    or more data sources, cleans, transforms, validates the data and loads it to a
    feature store (basically an ETL pipeline).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å·¥ç¨‹ç®¡é“ï¼š**è¯»å–æ¥è‡ªä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®æºçš„æ•°æ®ï¼Œæ¸…æ´—ã€è½¬æ¢ã€éªŒè¯æ•°æ®å¹¶å°†å…¶åŠ è½½åˆ°ç‰¹å¾å­˜å‚¨ä¸­çš„ä»£ç ç‰‡æ®µï¼ˆåŸºæœ¬ä¸Šæ˜¯ETLç®¡é“ï¼‰ã€‚'
- en: '**Pandas vs. Spark:** we chose to use Pandas in this course as our data processing
    library because the data is small. Thus, it easily fits in the computer''s memory
    and using a distributed computing framework such as Spark would have made everything
    too complicated. But in many real-world case scenarios, when the data is too big
    to fit on a single computer (aka big data), you will use Spark (or another distributed
    computing tool) to do the exact same steps as in this lesson. [Check out this
    article](https://pub.towardsai.net/this-is-how-you-can-build-a-churn-prediction-model-using-spark-e187b7eca339)
    to see how Spark can predict churn with big data.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pandas vs. Sparkï¼š**æˆ‘ä»¬åœ¨æœ¬è¯¾ç¨‹ä¸­é€‰æ‹©ä½¿ç”¨Pandasä½œä¸ºæ•°æ®å¤„ç†åº“ï¼Œå› ä¸ºæ•°æ®è¾ƒå°ã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥è½»æ¾åœ°é€‚åº”è®¡ç®—æœºçš„å†…å­˜ï¼Œä½¿ç”¨å¦‚Sparkè¿™æ ·çš„åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ä¼šä½¿ä¸€åˆ‡å˜å¾—è¿‡äºå¤æ‚ã€‚ä½†åœ¨è®¸å¤šç°å®ä¸–ç•Œçš„åœºæ™¯ä¸­ï¼Œå½“æ•°æ®å¤ªå¤§æ— æ³•é€‚åº”å•å°è®¡ç®—æœºï¼ˆå³å¤§æ•°æ®ï¼‰æ—¶ï¼Œä½ å°†ä½¿ç”¨Sparkï¼ˆæˆ–å…¶ä»–åˆ†å¸ƒå¼è®¡ç®—å·¥å…·ï¼‰æ¥å®Œæˆä¸æœ¬è¯¾ç¨‹ç›¸åŒçš„æ­¥éª¤ã€‚[æŸ¥çœ‹è¿™ç¯‡æ–‡ç« ](https://pub.towardsai.net/this-is-how-you-can-build-a-churn-prediction-model-using-spark-e187b7eca339)ä»¥äº†è§£Sparkå¦‚ä½•å¤„ç†å¤§æ•°æ®é¢„æµ‹æµå¤±ã€‚'
- en: 'Lesson 1: Code'
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'è¯¾ç¨‹ 1: ä»£ç '
- en: '[You can access the GitHub repository here.](https://github.com/iusztinpaul/energy-forecasting)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä½ å¯ä»¥åœ¨è¿™é‡Œè®¿é—®GitHubä»“åº“ã€‚](https://github.com/iusztinpaul/energy-forecasting)'
- en: '**Note:** All the installation instructions are in the READMEs of the repository.
    Here we will jump straight to the code.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** æ‰€æœ‰å®‰è£…è¯´æ˜éƒ½åœ¨ä»“åº“çš„READMEæ–‡ä»¶ä¸­ã€‚è¿™é‡Œæˆ‘ä»¬å°†ç›´æ¥è¿›å…¥ä»£ç éƒ¨åˆ†ã€‚'
- en: '*All the code within Lesson 1 is located under the* [***feature-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)*folder.*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*Lesson 1ä¸­çš„æ‰€æœ‰ä»£ç éƒ½ä½äº* [***feature-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)*æ–‡ä»¶å¤¹ä¸‹ã€‚*'
- en: 'The files under the [**feature-pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)folderare
    structured as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[**feature-pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š'
- en: '![](../Images/a00200e79a2ce7bf64f173db2f6975fc.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a00200e79a2ce7bf64f173db2f6975fc.png)'
- en: A screenshot that shows the structure of the feature-pipeline folder [Image
    by the Author].
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç¤ºfeature-pipelineæ–‡ä»¶å¤¹ç»“æ„çš„æˆªå›¾[ä½œè€…æä¾›]ã€‚
- en: All the code is located under the [**feature_pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline/feature_pipeline)directory
    (note the "_" instead of "-")**.**
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰ä»£ç éƒ½ä½äº[**feature_pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline/feature_pipeline)ç›®å½•ä¸‹ï¼ˆæ³¨æ„æ˜¯"_"è€Œä¸æ˜¯"-"ï¼‰**ã€‚**
- en: '***Prepare Credentials***'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***å‡†å¤‡å‡­è¯***'
- en: 'In this lesson, you will use a single service, which you will use as your feature
    store: [Hopsworks](https://www.hopsworks.ai/) (for our use case, it will be *free
    of charge).*'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œä½ å°†ä½¿ç”¨ä¸€ä¸ªå•ä¸€æœåŠ¡ä½œä¸ºä½ çš„ç‰¹å¾å­˜å‚¨ï¼š[Hopsworks](https://www.hopsworks.ai/)ï¼ˆåœ¨æˆ‘ä»¬çš„ç”¨ä¾‹ä¸­ï¼Œå®ƒå°†æ˜¯*å…è´¹çš„*ï¼‰ã€‚
- en: Create an account on [Hopsworks](https://www.hopsworks.ai/) and a new project
    (or use the default project). Be careful to name your project differently than
    â€œ**energy_consumption,â€** as Hopsworks requires unique names across its serverless
    deployment.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[Hopsworks](https://www.hopsworks.ai/)ä¸Šåˆ›å»ºä¸€ä¸ªè´¦æˆ·å’Œä¸€ä¸ªæ–°é¡¹ç›®ï¼ˆæˆ–ä½¿ç”¨é»˜è®¤é¡¹ç›®ï¼‰ã€‚æ³¨æ„ä¸è¦å°†ä½ çš„é¡¹ç›®å‘½åä¸ºâ€œ**energy_consumption**â€ï¼Œå› ä¸ºHopsworksè¦æ±‚åœ¨å…¶æ— æœåŠ¡å™¨éƒ¨ç½²ä¸­é¡¹ç›®åç§°å”¯ä¸€ã€‚
- en: Now, you need an **API_KEY** from [Hopsworks](https://www.hopsworks.ai/) to
    log in and access the cloud resources using their Python module for this step.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä½ éœ€è¦ä¸€ä¸ªæ¥è‡ª[Hopsworks](https://www.hopsworks.ai/)çš„**API_KEY**æ¥ç™»å½•å¹¶ä½¿ç”¨ä»–ä»¬çš„Pythonæ¨¡å—è®¿é—®äº‘èµ„æºã€‚
- en: Directly storing credentials in your git repository is a huge security risk.
    That is why you will inject sensitive information using a **.env** file. The **.env.default**
    is an example of all the variables you must configure.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´æ¥åœ¨ä½ çš„gitä»“åº“ä¸­å­˜å‚¨å‡­è¯æ˜¯ä¸€ä¸ªå·¨å¤§çš„å®‰å…¨éšæ‚£ã€‚å› æ­¤ï¼Œä½ å°†ä½¿ç”¨**.env**æ–‡ä»¶æ³¨å…¥æ•æ„Ÿä¿¡æ¯ã€‚**.env.default**æ˜¯ä½ å¿…é¡»é…ç½®çš„æ‰€æœ‰å˜é‡çš„ç¤ºä¾‹ã€‚
- en: '![](../Images/a925923b5eecad13761347d1f873293c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a925923b5eecad13761347d1f873293c.png)'
- en: Screenshot of the **.env.default** file [Image by the Author].
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**.env.default**æ–‡ä»¶çš„æˆªå›¾[ä½œè€…æä¾›]ã€‚'
- en: 'From your **feature-pipeline** directory, run in your terminal:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä½ çš„**feature-pipeline**ç›®å½•ä¸­ï¼Œåœ¨ç»ˆç«¯ä¸­è¿è¡Œï¼š
- en: '[PRE0]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: â€¦and fill your newly generated Hopsworks API KEY under the **FS_API_KEY** variable
    and your Hopsworks project name under the **FS_PROJECT_NAME** variable (in our
    case, it was *â€œenergy_consumptionâ€*).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: â€¦å¹¶åœ¨**FS_API_KEY**å˜é‡ä¸‹å¡«å†™ä½ æ–°ç”Ÿæˆçš„Hopsworks API KEYï¼Œåœ¨**FS_PROJECT_NAME**å˜é‡ä¸‹å¡«å†™ä½ çš„Hopsworksé¡¹ç›®åç§°ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå®ƒæ˜¯*â€œenergy_consumptionâ€*ï¼‰ã€‚
- en: '***See the image below to see how to get your own Hopsworks API KEY ğŸ‘‡***'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '***æŸ¥çœ‹ä¸‹å›¾ï¼Œäº†è§£å¦‚ä½•è·å–ä½ è‡ªå·±çš„Hopsworks API KEY ğŸ‘‡***'
- en: '![](../Images/3eeba288d913985db231e149fe5148ff.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3eeba288d913985db231e149fe5148ff.png)'
- en: Go to your [Hopsworks](https://www.hopsworks.ai/) project. After, in the top-right
    corner, click on your username and after on "Account Settings." Finally, click
    "New API KEY," set a name, select all scopes, hit "Create API KEY," copy the API
    KEY, and you are done. You have your Hopswork API KEY [Image by the Author].
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›å…¥ä½ çš„[Hopsworks](https://www.hopsworks.ai/)é¡¹ç›®ã€‚ç„¶åï¼Œåœ¨å³ä¸Šè§’ç‚¹å‡»ä½ çš„ç”¨æˆ·åï¼Œå†ç‚¹å‡»â€œè´¦æˆ·è®¾ç½®â€ã€‚æœ€åï¼Œç‚¹å‡»â€œæ–°å»ºAPI
    KEYâ€ï¼Œè®¾ç½®ä¸€ä¸ªåç§°ï¼Œé€‰æ‹©æ‰€æœ‰ä½œç”¨åŸŸï¼Œç‚¹å‡»â€œåˆ›å»ºAPI KEYâ€ï¼Œå¤åˆ¶API KEYï¼Œä½ å°±å®Œæˆäº†ã€‚ä½ å·²ç»æ‹¥æœ‰äº†Hopsworks API KEY[ä½œè€…æä¾›]ã€‚
- en: Afterward, in the [**feature_pipeline/settings.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/settings.py)file,
    we will load all the variables from the **.env** file using the good old **dotenv**
    Python package.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œåœ¨[**feature_pipeline/settings.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/settings.py)æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è€ç‰Œçš„**dotenv**
    PythonåŒ…ä»**.env**æ–‡ä»¶ä¸­åŠ è½½æ‰€æœ‰å˜é‡ã€‚
- en: If you want to load the **.env** file from a different place than the current
    directory, you canexport the **ML_PIPELINE_ROOT_DIR** environment variable whenrunning
    the script. This is a "HOME" environment variable that points to the rest of the
    configuration files.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³ä»å½“å‰ç›®å½•ä»¥å¤–çš„åœ°æ–¹åŠ è½½**.env**æ–‡ä»¶ï¼Œä½ å¯ä»¥åœ¨è¿è¡Œè„šæœ¬æ—¶å¯¼å‡º**ML_PIPELINE_ROOT_DIR**ç¯å¢ƒå˜é‡ã€‚è¿™æ˜¯ä¸€ä¸ªæŒ‡å‘å…¶ä½™é…ç½®æ–‡ä»¶çš„"HOME"ç¯å¢ƒå˜é‡ã€‚
- en: We will also use the **ML_PIPELINE_ROOT_DIR** env var to point to a single directory
    from where to load the **.env** file and read/write data across all the processes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å°†ä½¿ç”¨**ML_PIPELINE_ROOT_DIR**ç¯å¢ƒå˜é‡æ¥æŒ‡å‘ä¸€ä¸ªå•ä¸€ç›®å½•ï¼Œä»ä¸­åŠ è½½**.env**æ–‡ä»¶ï¼Œå¹¶åœ¨æ‰€æœ‰è¿›ç¨‹ä¸­è¯»å†™æ•°æ®ã€‚
- en: 'Here is an example of how to use the **ML_PIPELINE_ROOT_DIR** variable:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå¦‚ä½•ä½¿ç”¨**ML_PIPELINE_ROOT_DIR**å˜é‡çš„ç¤ºä¾‹ï¼š
- en: '[PRE1]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using the following code, we will have access to all the credentials/sensitive
    information across our code using the SETTINGS dictionary.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼Œæˆ‘ä»¬å°†é€šè¿‡ SETTINGS å­—å…¸è®¿é—®ä»£ç ä¸­çš„æ‰€æœ‰å‡­æ®/æ•æ„Ÿä¿¡æ¯ã€‚
- en: '***ETL Code***'
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***ETL ä»£ç ***'
- en: In the [**feature_pipeline/pipeline.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/pipeline.py)file,
    we have the main entry point of the pipeline under the **run()** method.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ [**feature_pipeline/pipeline.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/pipeline.py)
    æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬åœ¨**run()**æ–¹æ³•ä¸‹æœ‰ç®¡é“çš„ä¸»è¦å…¥å£ç‚¹ã€‚
- en: 'As you can see below, the run method follows on a high level the exact steps
    of an ETL pipeline:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸‹æ‰€ç¤ºï¼Œrun æ–¹æ³•åœ¨é«˜å±‚æ¬¡ä¸Šéµå¾ªäº† ETL ç®¡é“çš„ç¡®åˆ‡æ­¥éª¤ï¼š
- en: '**extract.from_api()** â€” Extract the data from the energy consumption API.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**extract.from_api()** â€” ä»èƒ½æºæ¶ˆè€— API æå–æ•°æ®ã€‚'
- en: '**transform()** â€” Transform the extracted data.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**transform()** â€” è½¬æ¢æå–çš„æ•°æ®ã€‚'
- en: '**validation.build_expectation_suite()** â€” Build the data validation and integrity
    suite. Ignore this step, as we will insist on it in Lesson 6.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**validation.build_expectation_suite()** â€” æ„å»ºæ•°æ®éªŒè¯å’Œå®Œæ•´æ€§å¥—ä»¶ã€‚å¿½ç•¥è¿™ä¸€æ­¥ï¼Œå› ä¸ºæˆ‘ä»¬å°†åœ¨ç¬¬ 6 è¯¾ä¸­é‡ç‚¹è®²è§£ã€‚'
- en: '**load.to_feature_store()** â€” Load the data in the feature store.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**load.to_feature_store()** â€” å°†æ•°æ®åŠ è½½åˆ°ç‰¹å¾å­˜å‚¨ä¸­ã€‚'
- en: Please note how I used the logger to reflect the system's current state. When
    your program is deployed and running 24/7, having verbose logging is crucial to
    debugging the system. Also, always use the Python logger instead of the print
    method, as you can choose different logging levels and output streams.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„æˆ‘å¦‚ä½•ä½¿ç”¨æ—¥å¿—è®°å½•å™¨æ¥åæ˜ ç³»ç»Ÿçš„å½“å‰çŠ¶æ€ã€‚å½“ä½ çš„ç¨‹åºéƒ¨ç½²å¹¶å…¨å¤©å€™è¿è¡Œæ—¶ï¼Œè¯¦ç»†çš„æ—¥å¿—è®°å½•å¯¹äºè°ƒè¯•ç³»ç»Ÿè‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼Œæ€»æ˜¯ä½¿ç”¨ Python çš„æ—¥å¿—è®°å½•å™¨è€Œä¸æ˜¯
    print æ–¹æ³•ï¼Œå› ä¸ºä½ å¯ä»¥é€‰æ‹©ä¸åŒçš„æ—¥å¿—çº§åˆ«å’Œè¾“å‡ºæµã€‚
- en: On a higher level, it seems easy to understand. Let's dive into each component
    separately.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼Œè¿™ä¼¼ä¹å¾ˆå®¹æ˜“ç†è§£ã€‚è®©æˆ‘ä»¬åˆ†åˆ«æ·±å…¥äº†è§£æ¯ä¸ªç»„ä»¶ã€‚
- en: '**#1\. Extract**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**#1\. æå–**'
- en: In the extracting step, we request data for a given window length. The window
    will have a length equal to **days_export**. The first data point of the window
    is **export_end_reference_datetime - days_delay - days_export,** and the last
    data point of the window is equal to **export_end_reference_datetime - days_delay.**
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æå–æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬è¯·æ±‚ç»™å®šçª—å£é•¿åº¦çš„æ•°æ®ã€‚çª—å£çš„é•¿åº¦å°†ç­‰äº**days_export**ã€‚çª—å£çš„ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹æ˜¯**export_end_reference_datetime
    - days_delay - days_export**ï¼Œè€Œçª—å£çš„æœ€åä¸€ä¸ªæ•°æ®ç‚¹ç­‰äº**export_end_reference_datetime - days_delay**ã€‚
- en: We used the parameter **days_delay** to move the window based on the delay of
    the data. In our use case, the API has a delay of 15 days.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨äº†å‚æ•°**days_delay**æ¥æ ¹æ®æ•°æ®çš„å»¶è¿Ÿç§»åŠ¨çª—å£ã€‚åœ¨æˆ‘ä»¬çš„ä½¿ç”¨æ¡ˆä¾‹ä¸­ï¼ŒAPI å»¶è¿Ÿä¸º 15 å¤©ã€‚
- en: As explained above, the function makes an HTTP GET request to the API requesting
    data. Afterward, the response is decoded and loaded into a Pandas DataFrame.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šæ‰€è¿°ï¼Œè¯¥å‡½æ•°å‘ API å‘å‡º HTTP GET è¯·æ±‚ä»¥è¯·æ±‚æ•°æ®ã€‚éšåï¼Œå“åº”è¢«è§£ç å¹¶åŠ è½½åˆ° Pandas DataFrame ä¸­ã€‚
- en: The function returns the DataFrame plus additional metadata containing information
    about the data's extraction.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å‡½æ•°è¿”å› DataFrame ä»¥åŠåŒ…å«æœ‰å…³æ•°æ®æå–ä¿¡æ¯çš„é™„åŠ å…ƒæ•°æ®ã€‚
- en: '**#2\. Transform**'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**#2\. è½¬æ¢**'
- en: 'The transform steps take the raw DataFrame and apply the following transformations:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬æ¢æ­¥éª¤å°†åŸå§‹ DataFrame è¿›è¡Œå¦‚ä¸‹è½¬æ¢ï¼š
- en: rename the columns to a Python-standardized format
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†åˆ—é‡å‘½åä¸º Python æ ‡å‡†åŒ–æ ¼å¼
- en: cast the columns to their suited type
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†åˆ—è½¬æ¢ä¸ºå…¶é€‚åˆçš„ç±»å‹
- en: encode the strings columns to ints
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å­—ç¬¦ä¸²åˆ—ç¼–ç ä¸ºæ•´æ•°
- en: Note that we haven't included our EDA step (e.g., looking for null values),
    as our primary focus is on designing the system, not on the standard data science
    process.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æˆ‘ä»¬æ²¡æœ‰åŒ…æ‹¬ EDA æ­¥éª¤ï¼ˆä¾‹å¦‚ï¼ŒæŸ¥æ‰¾ç©ºå€¼ï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬çš„ä¸»è¦å…³æ³¨ç‚¹æ˜¯è®¾è®¡ç³»ç»Ÿï¼Œè€Œä¸æ˜¯æ ‡å‡†çš„æ•°æ®ç§‘å­¦è¿‡ç¨‹ã€‚
- en: '**#3\. Data Validation**'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**#3\. æ•°æ®éªŒè¯**'
- en: 'This is where we ensure that the data is as expected. In our case, based on
    our EDA and transformations, we are looking that:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬ç¡®ä¿æ•°æ®ç¬¦åˆé¢„æœŸçš„åœ°æ–¹ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼ŒåŸºäºæˆ‘ä»¬çš„ EDA å’Œè½¬æ¢ï¼Œæˆ‘ä»¬æœŸæœ›ï¼š
- en: the data doesn't have any nulls
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®ä¸­æ²¡æœ‰ä»»ä½•ç©ºå€¼
- en: the types of columns are as expected
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ—çš„ç±»å‹å¦‚é¢„æœŸ
- en: the range of values is as expected
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å€¼çš„èŒƒå›´å¦‚é¢„æœŸ
- en: '*More on this subject in Lesson 6.*'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ‰å…³æ­¤ä¸»é¢˜çš„æ›´å¤šå†…å®¹ï¼Œè¯·å‚è§ç¬¬ 6 è¯¾ã€‚*'
- en: '**#4\. Load**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**#4\. åŠ è½½**'
- en: This is where we load our processed DataFrame into the feature store.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬å°†å¤„ç†åçš„ DataFrame åŠ è½½åˆ°ç‰¹å¾å­˜å‚¨ä¸­çš„åœ°æ–¹ã€‚
- en: 'Hopsworks has a set of great tutorials which you can check [here](https://docs.hopsworks.ai/3.1/tutorials/).
    But let me explain what is going on:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Hopsworksæœ‰ä¸€ç³»åˆ—å¾ˆæ£’çš„æ•™ç¨‹ï¼Œä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://docs.hopsworks.ai/3.1/tutorials/)æŸ¥çœ‹ã€‚ä½†è®©æˆ‘è§£é‡Šä¸€ä¸‹å‘ç”Ÿäº†ä»€ä¹ˆï¼š
- en: We login into our Hopsworks project using our API_KEY.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨API_KEYç™»å½•åˆ°æˆ‘ä»¬çš„Hopsworksé¡¹ç›®ä¸­ã€‚
- en: We get a reference to the feature store.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è·å–ç‰¹å¾å­˜å‚¨çš„å¼•ç”¨ã€‚
- en: We get or create a feature group which is basically a database table with all
    the goodies of a feature store on top of it (read more [here](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/)
    [5]).
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è·å–æˆ–åˆ›å»ºä¸€ä¸ªç‰¹å¾ç»„ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªæ•°æ®åº“è¡¨ï¼Œä¸Šé¢é™„åŠ äº†ç‰¹å¾å­˜å‚¨çš„æ‰€æœ‰ä¼˜ç‚¹ï¼ˆæ›´å¤šä¿¡æ¯è¯·è§[è¿™é‡Œ](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/)
    [5]ï¼‰ã€‚
- en: We insert our new processed data samples.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ’å…¥æ–°çš„å¤„ç†æ•°æ®æ ·æœ¬ã€‚
- en: We add a set of feature descriptions for every feature of our data.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ºæ•°æ®ä¸­çš„æ¯ä¸ªç‰¹å¾æ·»åŠ ä¸€ç»„ç‰¹å¾æè¿°ã€‚
- en: We command Hopsworks to compute statistics for every feature.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æŒ‡ç¤ºHopsworksä¸ºæ¯ä¸ªç‰¹å¾è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ã€‚
- en: Check out the video below to see what I explained above looks into Hopsworks
    ğŸ‘‡
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ä¸‹é¢çš„è§†é¢‘ï¼Œçœ‹çœ‹æˆ‘åˆšæ‰è§£é‡Šçš„å†…å®¹åœ¨Hopsworksä¸­æ˜¯ä»€ä¹ˆæ ·çš„ ğŸ‘‡
- en: Hopsworks overview [Video by the Author].
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Hopsworksæ¦‚è¿°[ä½œè€…çš„è§†é¢‘]ã€‚
- en: Awesome! Now we have a Python ETL script that extracts the data from the energy
    consumption API for a given time window and loads it into the feature store.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ï¼ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªPython ETLè„šæœ¬ï¼Œå®ƒä»èƒ½è€—APIä¸­æå–æ•°æ®ï¼Œå¹¶å°†å…¶åŠ è½½åˆ°ç‰¹å¾å­˜å‚¨ä¸­ã€‚
- en: Create a Feature View & Training Dataset
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºç‰¹å¾è§†å›¾ä¸è®­ç»ƒæ•°æ®é›†
- en: One final step is to create a feature view and training dataset that will later
    be ingested into the training pipeline.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€æ­¥æ˜¯åˆ›å»ºä¸€ä¸ªç‰¹å¾è§†å›¾å’Œè®­ç»ƒæ•°æ®é›†ï¼Œç¨åå°†è¢«å¼•å…¥è®­ç»ƒç®¡é“ä¸­ã€‚
- en: '**Note:** The feature pipeline is the only process that does WRITES to the
    feature store. Other components will only query the feature store for various
    datasets. By doing so, we can safely use the feature store as our only source
    of truth and share the feature across the system.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** ç‰¹å¾ç®¡é“æ˜¯å”¯ä¸€ä¸€ä¸ªå¯¹ç‰¹å¾å­˜å‚¨è¿›è¡Œå†™æ“ä½œçš„è¿‡ç¨‹ã€‚å…¶ä»–ç»„ä»¶ä»…ä¼šæŸ¥è¯¢ç‰¹å¾å­˜å‚¨ä¸­çš„å„ç§æ•°æ®é›†ã€‚é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°å°†ç‰¹å¾å­˜å‚¨ä½œä¸ºå”¯ä¸€çš„çœŸå®æ¥æºï¼Œå¹¶åœ¨ç³»ç»Ÿä¸­å…±äº«ç‰¹å¾ã€‚'
- en: 'In the[**feature_pipeline/feature_view.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/feature_view.py)file,
    we have the **create()** method that runs the following logic:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[**feature_pipeline/feature_view.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/feature_view.py)æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ª**create()**æ–¹æ³•ï¼Œå®ƒè¿è¡Œä»¥ä¸‹é€»è¾‘ï¼š
- en: We load the metadata from the feature pipeline. Remember that the FE metadata
    contains the start and end of the extraction window, the version of the feature
    group, etc.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»ç‰¹å¾ç®¡é“ä¸­åŠ è½½å…ƒæ•°æ®ã€‚è¯·è®°ä½ï¼ŒFEå…ƒæ•°æ®åŒ…å«æå–çª—å£çš„å¼€å§‹å’Œç»“æŸæ—¶é—´ã€ç‰¹å¾ç»„çš„ç‰ˆæœ¬ç­‰ã€‚
- en: We login into the Hopswork project & create a reference to the feature store.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç™»å½•Hopsworké¡¹ç›®å¹¶åˆ›å»ºå¯¹ç‰¹å¾å­˜å‚¨çš„å¼•ç”¨ã€‚
- en: We delete all the old feature views (usually, you don't have to do this step.
    Quite the opposite, you want to keep your old datasets. But Hopwork's free version
    limits you to 100 feature views. Thus, we wanted to keep our free version).
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ é™¤æ‰€æœ‰æ—§çš„ç‰¹å¾è§†å›¾ï¼ˆé€šå¸¸ï¼Œä½ ä¸éœ€è¦æ‰§è¡Œè¿™ä¸€æ­¥ã€‚æ­£å¥½ç›¸åï¼Œä½ ä¼šå¸Œæœ›ä¿ç•™æ—§çš„æ•°æ®é›†ã€‚ä½†æ˜¯ï¼ŒHopworkçš„å…è´¹ç‰ˆæœ¬é™åˆ¶ä½ åªèƒ½ä½¿ç”¨100ä¸ªç‰¹å¾è§†å›¾ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æƒ³è¦ä¿ç•™æˆ‘ä»¬çš„å…è´¹ç‰ˆæœ¬ï¼‰ã€‚
- en: We get the feature group based on the given version.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ ¹æ®ç»™å®šç‰ˆæœ¬è·å–ç‰¹å¾ç»„ã€‚
- en: We create a feature view with all the data from the loaded feature group.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ä»åŠ è½½çš„ç‰¹å¾ç»„ä¸­å¾—åˆ°çš„æ‰€æœ‰æ•°æ®åˆ›å»ºä¸€ä¸ªç‰¹å¾è§†å›¾ã€‚
- en: We create a training dataset using only the given time window.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»…ä½¿ç”¨ç»™å®šçš„æ—¶é—´çª—å£åˆ›å»ºè®­ç»ƒæ•°æ®é›†ã€‚
- en: We create a snapshot of the metadata and save it to disk.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ›å»ºå…ƒæ•°æ®çš„å¿«ç…§å¹¶ä¿å­˜åˆ°ç£ç›˜ã€‚
- en: '**Note:** A feature view is a smart way of combining multiple feature groups
    into a single "dataset." It is similar to a VIEW in a SQL database. You can read
    more about feature views [here](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/)
    [4].'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** ç‰¹å¾è§†å›¾æ˜¯ä¸€ç§å°†å¤šä¸ªç‰¹å¾ç»„ç»„åˆæˆä¸€ä¸ªâ€œæ•°æ®é›†â€çš„æ™ºèƒ½æ–¹æ³•ã€‚å®ƒç±»ä¼¼äºSQLæ•°æ®åº“ä¸­çš„VIEWã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/)
    [4]äº†è§£æ›´å¤šå…³äºç‰¹å¾è§†å›¾çš„ä¿¡æ¯ã€‚'
- en: That was it. You built a feature pipeline that extracts, transforms, and loads
    the data to a feature store. Based on the data from the feature store, you created
    a feature view and training dataset that will later be used within the system
    as the single source of truth.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ã€‚ä½ å»ºç«‹äº†ä¸€ä¸ªç‰¹å¾ç®¡é“ï¼Œå®ƒæå–ã€è½¬æ¢å¹¶åŠ è½½æ•°æ®åˆ°ç‰¹å¾å­˜å‚¨ä¸­ã€‚åŸºäºç‰¹å¾å­˜å‚¨ä¸­çš„æ•°æ®ï¼Œä½ åˆ›å»ºäº†ä¸€ä¸ªç‰¹å¾è§†å›¾å’Œè®­ç»ƒæ•°æ®é›†ï¼Œè¿™äº›å°†ä½œä¸ºç³»ç»Ÿä¸­çš„å”¯ä¸€çœŸå®æ¥æºã€‚
- en: '**Note:** You need good software engineering principles and patterns knowledge
    to build robust feature engineering pipelines. [You can read some hands-on examples
    here](https://pub.towardsai.net/10-underrated-software-patterns-every-ml-engineer-should-know-92e702b96407).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ³¨æ„ï¼š** ä½ éœ€è¦è‰¯å¥½çš„è½¯ä»¶å·¥ç¨‹åŸåˆ™å’Œæ¨¡å¼çŸ¥è¯†æ¥æ„å»ºå¥å£®çš„ç‰¹å¾å·¥ç¨‹ç®¡é“ã€‚[ä½ å¯ä»¥åœ¨è¿™é‡Œé˜…è¯»ä¸€äº›å®è·µç¤ºä¾‹](https://pub.towardsai.net/10-underrated-software-patterns-every-ml-engineer-should-know-92e702b96407)ã€‚'
- en: Important Design Decision
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é‡è¦çš„è®¾è®¡å†³ç­–
- en: As you saw, we haven't actually computed any features in this lesson. We just
    cleaned, validated and ensured that the data was ready to be used later in the
    system.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬åœ¨è¿™èŠ‚è¯¾ä¸­å®é™…ä¸Šæ²¡æœ‰è®¡ç®—ä»»ä½•ç‰¹å¾ã€‚æˆ‘ä»¬åªæ˜¯æ¸…ç†ã€éªŒè¯å¹¶ç¡®ä¿æ•°æ®å·²ç»å‡†å¤‡å¥½ç”¨äºç³»ç»Ÿä¸­ã€‚
- en: '*But this is called "the feature pipeline," why we haven''t computed any features?*'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä½†è¿™è¢«ç§°ä¸ºâ€œç‰¹å¾ç®¡é“â€ï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬æ²¡æœ‰è®¡ç®—ä»»ä½•ç‰¹å¾å‘¢ï¼Ÿ*'
- en: Let me explain.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘è§£é‡Šä¸€ä¸‹ã€‚
- en: '**a feature = raw data + a transformation function**'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾ = åŸå§‹æ•°æ® + è½¬æ¢å‡½æ•°**'
- en: What if, instead of computing and storing the features, we store the raw data
    and the transformation functions within the feature store?
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°†åŸå§‹æ•°æ®å’Œè½¬æ¢å‡½æ•°å­˜å‚¨åœ¨ç‰¹å¾åº“ä¸­ï¼Œè€Œä¸æ˜¯è®¡ç®—å’Œå­˜å‚¨ç‰¹å¾ï¼Œä¼šæ€æ ·å‘¢ï¼Ÿ
- en: 'Doingso we have the following benefits:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·åšæˆ‘ä»¬å¯ä»¥è·å¾—ä»¥ä¸‹å¥½å¤„ï¼š
- en: Faster experimentation, as the data scientist doesn't require to ask the data
    engineer to compute a new feature. He needs to add a new transformation to the
    feature store.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ›´å¿«çš„å®éªŒï¼Œå› ä¸ºæ•°æ®ç§‘å­¦å®¶ä¸éœ€è¦è¯·æ±‚æ•°æ®å·¥ç¨‹å¸ˆè®¡ç®—æ–°ç‰¹å¾ã€‚ä»–åªéœ€å°†æ–°è½¬æ¢æ·»åŠ åˆ°ç‰¹å¾åº“ä¸­ã€‚
- en: You save a lot of storage. For example, instead of saving 5 features computed
    from the same raw data column, you save only the raw data column + the 5 transformations,
    which will use only 1/5 of the space.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥èŠ‚çœå¤§é‡å­˜å‚¨ç©ºé—´ã€‚ä¾‹å¦‚ï¼Œä¸å…¶ä¿å­˜5ä¸ªä»åŒä¸€åŸå§‹æ•°æ®åˆ—è®¡ç®—å‡ºçš„ç‰¹å¾ï¼Œä¸å¦‚åªä¿å­˜åŸå§‹æ•°æ®åˆ—å’Œ5ä¸ªè½¬æ¢ï¼Œè¿™æ ·åªä½¿ç”¨åŸæ¥çš„1/5çš„ç©ºé—´ã€‚
- en: 'Downsides of using this approach:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹ï¼š
- en: Your features will be computed on the cloud or the inference pipeline at runtime.
    Thus, you will add extra latency at runtime.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ çš„ç‰¹å¾å°†åœ¨è¿è¡Œæ—¶é€šè¿‡äº‘ç«¯æˆ–æ¨ç†ç®¡é“è¿›è¡Œè®¡ç®—ã€‚å› æ­¤ï¼Œä½ å°†åœ¨è¿è¡Œæ—¶å¢åŠ é¢å¤–çš„å»¶è¿Ÿã€‚
- en: But, when using the batch-serving paradigm, latency is not a significant constraint.
    Thus, we did just that!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨ä½¿ç”¨æ‰¹é‡æœåŠ¡èŒƒå¼æ—¶ï¼Œå»¶è¿Ÿä¸æ˜¯ä¸€ä¸ªæ˜¾è‘—çš„é™åˆ¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç¡®å®è¿™æ ·åšäº†ï¼
- en: '[Check out Lesson 2](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    to see how we modeled our time series to forecast the energy consumption for the
    next 24 hours. In [Lesson 2](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee),
    we will show you how we stored the transformations directly in the feature store.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹ç¬¬2è¯¾](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    ä»¥äº†è§£æˆ‘ä»¬å¦‚ä½•å»ºæ¨¡æ—¶é—´åºåˆ—ä»¥é¢„æµ‹æ¥ä¸‹æ¥24å°æ—¶çš„èƒ½æºæ¶ˆè€—ã€‚åœ¨ [ç¬¬2è¯¾](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•å°†è½¬æ¢ç›´æ¥å­˜å‚¨åœ¨ç‰¹å¾åº“ä¸­ã€‚'
- en: Conclusion
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Congratulations! You finished the **first lesson** from the **Full Stack 7-Steps
    MLOps Framework** course.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œï¼ä½ å®Œæˆäº†**ç¬¬ä¸€è¯¾**æ¥è‡ª**å…¨æ ˆ7æ­¥MLOpsæ¡†æ¶**è¯¾ç¨‹ã€‚
- en: 'You learned about how to design a batch-serving architecture and about developing
    your own ETL pipeline that:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ äº†è§£äº†å¦‚ä½•è®¾è®¡æ‰¹é‡æœåŠ¡æ¶æ„ä»¥åŠå¼€å‘è‡ªå·±çš„ ETL ç®¡é“ï¼Œè¿™äº›ç®¡é“ï¼š
- en: extracts data from an HTTP API
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä» HTTP API ä¸­æå–æ•°æ®
- en: cleans it
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸…ç†æ•°æ®
- en: transforms it
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è½¬æ¢æ•°æ®
- en: loads it into a feature store
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ•°æ®åŠ è½½åˆ°ç‰¹å¾åº“ä¸­
- en: creates a new training dataset version
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ–°çš„è®­ç»ƒæ•°æ®é›†ç‰ˆæœ¬
- en: Now that you understand the power of using a feature store and its importance
    to any ML system, you can deploy your model in weeks instead of months.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å·²ç»ç†è§£äº†ä½¿ç”¨ç‰¹å¾åº“çš„å¼ºå¤§åŠŸèƒ½åŠå…¶å¯¹ä»»ä½• ML ç³»ç»Ÿçš„é‡è¦æ€§ï¼Œä½ å¯ä»¥åœ¨å‡ å‘¨å†…è€Œä¸æ˜¯å‡ ä¸ªæœˆå†…éƒ¨ç½²ä½ çš„æ¨¡å‹ã€‚
- en: '[Check out Lesson 2](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    to learn about training pipelines, ML platforms, and hyperparameter tuning.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹ç¬¬2è¯¾](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    ä»¥äº†è§£æœ‰å…³è®­ç»ƒç®¡é“ã€æœºå™¨å­¦ä¹ å¹³å°å’Œè¶…å‚æ•°è°ƒæ•´çš„ä¿¡æ¯ã€‚'
- en: '**Also**, [**you can access the GitHub repository here.**](https://github.com/iusztinpaul/energy-forecasting)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¤å¤–**ï¼Œ[**ä½ å¯ä»¥åœ¨è¿™é‡Œè®¿é—® GitHub ä»“åº“ã€‚**](https://github.com/iusztinpaul/energy-forecasting)'
- en: ğŸ’¡ My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡ æˆ‘çš„ç›®æ ‡æ˜¯å¸®åŠ©æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆåœ¨è®¾è®¡å’Œç”Ÿäº§åŒ– ML ç³»ç»Ÿæ–¹é¢æå‡æ°´å¹³ã€‚å…³æ³¨æˆ‘ [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    æˆ–è®¢é˜…æˆ‘çš„ [æ¯å‘¨é€šè®¯](https://pauliusztin.substack.com/) ä»¥è·å–æ›´å¤šè§è§£ï¼
- en: ğŸ”¥ If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). By using
    [my referral link](https://pauliusztin.medium.com/membership), you can support
    me without any extra cost while enjoying limitless access to Mediumâ€™s rich collection
    of stories.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”¥ å¦‚æœä½ å–œæ¬¢é˜…è¯»ç±»ä¼¼çš„æ–‡ç« å¹¶å¸Œæœ›æ”¯æŒæˆ‘çš„å†™ä½œï¼Œè€ƒè™‘ [æˆä¸º Medium ä¼šå‘˜](https://pauliusztin.medium.com/membership)ã€‚é€šè¿‡ä½¿ç”¨
    [æˆ‘çš„æ¨èé“¾æ¥](https://pauliusztin.medium.com/membership)ï¼Œä½ å¯ä»¥åœ¨æ²¡æœ‰é¢å¤–è´¹ç”¨çš„æƒ…å†µä¸‹æ”¯æŒæˆ‘ï¼ŒåŒæ—¶äº«å— Medium
    ä¸°å¯Œæ•…äº‹çš„æ— é™è®¿é—®ã€‚
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)
    [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium - ä¿ç½—Â·ä¼Šæ–¯æ´¥]'
- en: ğŸ¤– Join to get exclusive content about designing and building production-ready
    ML systems ğŸš€ Unlock full access toâ€¦
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ğŸ¤– åŠ å…¥ä»¥è·å–å…³äºè®¾è®¡å’Œæ„å»ºç”Ÿäº§çº§æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„ç‹¬å®¶å†…å®¹ ğŸš€ è§£é”å®Œæ•´è®¿é—®æƒé™â€¦
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)'
- en: References
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [ä¸¹éº¦ API ä¸­çš„ DE35 è¡Œä¸šä»£ç èƒ½æºæ¶ˆè€—](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)ï¼Œ[ä¸¹éº¦èƒ½æºæ•°æ®æœåŠ¡](https://www.energidataservice.dk/about/)'
- en: '[2] [Hopsworks Tutorials](https://docs.hopsworks.ai/3.1/tutorials/), Hopsworks
    Documentation'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [Hopsworks æ•™ç¨‹](https://docs.hopsworks.ai/3.1/tutorials/)ï¼ŒHopsworks æ–‡æ¡£'
- en: '[3] Jim Dowling, [Feature Store vs Data Warehouse](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)
    (2020), KDnuggets'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] å‰å§†Â·é“æ—ï¼Œ[ç‰¹å¾å­˜å‚¨ä¸æ•°æ®ä»“åº“](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)ï¼ˆ2020å¹´ï¼‰ï¼ŒKDnuggets'
- en: '[4] [Hopsworks Feature Views](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/),
    Hopsworks Documentation'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [Hopsworks ç‰¹å¾è§†å›¾](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/)ï¼ŒHopsworks
    æ–‡æ¡£'
- en: '[5] [Hopsworks Feature Groups](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/),
    Hopsworks Documentation'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [Hopsworks ç‰¹å¾ç»„](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/)ï¼ŒHopsworks
    æ–‡æ¡£'
