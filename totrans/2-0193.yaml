- en: A Framework for Building a Production-Ready Feature Engineering Pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建生产就绪特征工程管道的框架
- en: 原文：[https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f](https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f](https://towardsdatascience.com/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)
- en: '[The Full Stack 7-Steps MLOps Framework](https://towardsdatascience.com/tagged/full-stack-mlops)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[全栈 7 步 MLOps 框架](https://towardsdatascience.com/tagged/full-stack-mlops)'
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '课程 1: 批量服务。特征存储。特征工程管道。'
- en: '[](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----f0b29609b20f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    ·13 min read·Apr 28, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0b29609b20f--------------------------------)
    ·13分钟阅读·2023年4月28日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2ae381d9f40ec629b5dacf7b06536a4e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ae381d9f40ec629b5dacf7b06536a4e.png)'
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上的照片'
- en: This tutorial represents **lesson 1 out of a 7-lesson course** that will walk
    you step-by-step through how to **design, implement, and deploy an ML system**
    using **MLOps good practices**. During the course, you will build a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程代表**一个包含 7 课时的课程中的第 1 课**，将逐步指导你如何**设计、实施和部署 ML 系统**，使用**MLOps 优良实践**。在课程中，你将构建一个生产就绪的模型，用于预测丹麦未来
    24 小时内的能源消耗水平，涵盖多个消费类型。
- en: '*By the end of this course, you will understand all the fundamentals of designing,
    coding and deploying an ML system using a batch-serving architecture.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*完成本课程后，你将了解使用批量服务架构设计、编码和部署 ML 系统的所有基本知识。*'
- en: This course *targets mid/advanced machine learning engineers* who want to level
    up their skills by building their own end-to-end projects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本课程*针对中级/高级机器学习工程师*，旨在通过构建自己的端到端项目来提升技能。
- en: Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如今，证书随处可见。构建先进的端到端项目并展示是获得专业工程师认可的最佳途径。
- en: 'Table of Contents:'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录：
- en: Course Introduction
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程介绍
- en: Course Lessons
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程内容
- en: Data Source
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据源
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '课程 1: 批量服务。特征存储。特征工程管道。'
- en: 'Lesson 1: Code'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '课程 1: 代码'
- en: Conclusion
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结论
- en: References
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考文献
- en: Introduction
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '***At the end of this 7 lessons course, you will know how to:***'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '***在这 7 课时的课程结束时，你将学会如何:***'
- en: design a batch-serving architecture
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计批量服务架构
- en: use Hopsworks as a feature store
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Hopsworks 作为特征存储
- en: design a feature engineering pipeline that reads data from an API
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个从API读取数据的特征工程管道
- en: build a training pipeline with hyper-parameter tunning
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建带有超参数调优的训练管道
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 W&B 作为 ML 平台来跟踪你的实验、模型和元数据
- en: implement a batch prediction pipeline
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现批量预测管道
- en: use Poetry to build your own Python packages
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Poetry 构建自己的 Python 包
- en: deploy your own private PyPi server
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署自己的私人 PyPi 服务器
- en: orchestrate everything with Airflow
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Airflow 协调一切
- en: use the predictions to code a web app using FastAPI and Streamlit
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预测结果编码一个使用 FastAPI 和 Streamlit 的 Web 应用
- en: use Docker to containerize your code
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Docker 容器化你的代码
- en: use Great Expectations to ensure data validation and integrity
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Great Expectations 确保数据验证和完整性
- en: monitor the performance of the predictions over time
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控预测性能的变化
- en: deploy everything to GCP
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有内容部署到 GCP
- en: build a CI/CD pipeline using GitHub Actions
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GitHub Actions 构建 CI/CD 流水线
- en: If that sounds like a lot, don't worry, after you will cover this course you
    will understand everything I said before. Most importantly, you will know WHY
    I used all these tools and how they work together as a system.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些听起来很多，不用担心，完成本课程后你将理解我之前说的一切。最重要的是，你将了解我为何使用这些工具以及它们如何作为一个系统协同工作。
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. I designed the articles so you can read and run the code
    while reading the course.**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你想最大化本课程的收益，** [**我建议你访问包含所有课程代码的 GitHub 仓库**](https://github.com/iusztinpaul/energy-forecasting)
    **。我设计了这些文章，使你在阅读课程的同时可以阅读并运行代码。**'
- en: By the end of the course, you will know how to implement the diagram below.
    Don't worry if something doesn't make sense to you. I will explain everything
    in detail.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 到课程结束时，你将学会如何实现下面的图示。如果有些内容对你来说不太明白，不用担心。我会详细解释一切。
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
- en: Diagram of the architecture you will build during the course [Image by the Author].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 课程中你将构建的架构图 [图示来源于作者]。
- en: '***Why batch serving?***'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '***为什么批量服务？***'
- en: 'There are 4 main types of deploying a model:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的部署主要有 4 种类型：
- en: batch serving
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量服务
- en: request-response
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: request-response
- en: streaming
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式处理
- en: embedded
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入式
- en: Batch serving is the perfect starting point for getting hands-on experience
    with building a real-world ML system because most AI applications start using
    batch architecture and move towards request-response or streaming.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 批量服务是获取实际操作经验的绝佳起点，因为大多数 AI 应用程序从使用批量架构开始，然后转向请求响应或流式处理。
- en: 'Lessons:'
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 课程内容：
- en: '**Batch Serving. Feature Stores. Feature Engineering Pipelines.**'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**批量服务。特征存储。特征工程流水线。**'
- en: '[Training Pipelines. ML Platforms. Hyperparameter Tuning.](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[训练流水线。ML 平台。超参数调整。](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[批量预测流水线。使用 Poetry 打包 Python 模块。](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[私人 PyPi 服务器。使用 Airflow 协调一切。](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
- en: '[Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[使用 GE 进行数据验证以确保质量和完整性。模型性能持续监控。](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
- en: '[Consume and Visualize your Model’s Predictions using FastAPI and Streamlit.
    Dockerize Everything.](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[使用 FastAPI 和 Streamlit 消费和可视化你的模型预测。将一切容器化。](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
- en: '[Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github Actions.](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[将所有 ML 组件部署到 GCP。使用 Github Actions 构建 CI/CD 流水线。](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
- en: '[[Bonus] Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and Insights](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[[附加] ‘不完美’ ML 项目的幕后——教训与见解](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
- en: 'Data Source:'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据源：
- en: We used an open API that provides hourly energy consumption values for all the
    energy consumer types within Denmark.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个开放 API，提供丹麦所有能源消费者类型的每小时能源消耗值。
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 他们提供了一个直观的界面，你可以轻松查询和可视化数据。[你可以在这里访问数据](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1]。
- en: 'The data has 4 main attributes:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有4个主要属性：
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小时 UTC：** 观察到数据点时的 UTC 日期时间。'
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 — divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价格区域：** 丹麦被划分为两个价格区域：DK1 和 DK2——由大贝尔特海峡分隔。DK1 位于大贝尔特的西侧，DK2 位于东侧。'
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费者类型：** 消费者类型为工业代码 DE35，由丹麦能源公司拥有和维护。'
- en: '**Total Consumption:** Total electricity consumption in kWh'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总消耗：** 总电力消耗（kWh）'
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would be in real-time.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 观察值有15天的滞后！但对于我们的演示用例，这不是问题，因为我们可以模拟与实时相同的步骤。'
- en: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
- en: A screenshot from the app shows how we forecasted the energy consumption for
    area = 1 and consumer type = 212 [Image by the Author].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序中的截图展示了我们如何预测区域 = 1 和消费者类型 = 212 的能源消耗 [作者提供的图片]。
- en: 'The data points have an hourly resolution. For example: "2023–04–15 21:00Z",
    "2023–04–15 20:00Z", "2023–04–15 19:00Z", etc.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点具有每小时的分辨率。例如：“2023–04–15 21:00Z”，“2023–04–15 20:00Z”，“2023–04–15 19:00Z”等等。
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把数据建模为多个时间序列。每个独特的**价格区域**和**消费者类型**元组表示其独特的时间序列。
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将构建一个模型，独立预测每个时间序列接下来 24 小时的能源消耗。
- en: '*Check out the video below to better understand what the data looks like* 👇'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看下面的视频，更好地理解数据的样子* 👇'
- en: Course & data source overview [Video by the Author].
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 课程与数据源概览 [作者提供的视频]。
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1课：批量服务。特征存储。特征工程管道。
- en: The Goal of Lesson 1
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1课的目标
- en: 'In lesson 1, we will focus on the components highlighted in blue: "API," "Feature
    Engineering," and the "Feature Store," as we can see in the diagram below.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1课中，我们将关注图中蓝色突出显示的组件：“API”，“特征工程”和“特征存储”。
- en: '![](../Images/f8a16b0c5164f20ee8c313126196f321.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8a16b0c5164f20ee8c313126196f321.png)'
- en: Diagram of the final architecture with the Lesson 1 components highlighted in
    blue [Image by the Author].
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最终架构的示意图，其中第1课的组件用蓝色突出显示 [作者提供的图片]。
- en: Concretely, we will build an ETL pipeline that extracts data from the energy
    consumption API, pass them through the feature engineering pipeline, which cleans
    and transforms the features, and loads the features in the feature store for further
    usage across the system.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将构建一个 ETL 管道，从能源消耗 API 中提取数据，经过特征工程管道，该管道清洗和转换特征，并将特征加载到特征存储中，以便在系统中进一步使用。
- en: As you can see, the feature store stands at the heart of the system.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，特征存储站在系统的核心位置。
- en: Theoretical Concepts & Tools
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论概念与工具
- en: '**Batch Serving:** in the batch serving paradigm, you can prepare your data,
    train your model, and make predictions in an offline fashion. Afterward, you store
    the predictions in a database from where a client/application will use the predictions
    down the line. The word **batch** comes from the idea that you can process multiple
    samples simultaneously, which in this paradigm is usually valid. We computed all
    the predictions in our use case and stored them in a blob storage/bucket.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**批量服务：** 在批量服务模式中，你可以离线准备数据、训练模型并进行预测。之后，你将预测结果存储在数据库中，客户端/应用程序将在后续使用这些预测结果。**批量**这个词来源于你可以同时处理多个样本，这在这种模式下通常是有效的。我们计算了所有预测结果并将其存储在
    blob 存储/桶中。'
- en: If we would oversimplify our architecture to reflect only the main steps of
    a batch architecture, this is how it would look like 👇
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将架构过于简化，仅反映批量架构的主要步骤，它将如下所示 👇
- en: '![](../Images/8a22ababb6bd63765cd79be166f81414.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a22ababb6bd63765cd79be166f81414.png)'
- en: Batch architecture [Image by the Author].
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理架构 [作者提供的图片]。
- en: The biggest downside of the batch-serving paradigm is that your predictions
    will almost always lag. For example, in our case, we predict the energy consumption
    for the next 24 hours, and because of this lag, our predictions might be 1 hour
    late.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理服务范式的最大缺点是你的预测几乎总是会滞后。例如，在我们的案例中，我们预测未来24小时的能耗，由于这种滞后，我们的预测可能会迟到1小时。
- en: '[Check out this article](https://medium.com/mlearning-ai/this-is-what-you-need-to-know-to-build-an-mlops-end-to-end-architecture-c0be1deaa3ce)
    to learn more about a *standardized architecture* *suggested by* *Google Cloud*
    that can be leveraged in almost any ML system.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看这篇文章](https://medium.com/mlearning-ai/this-is-what-you-need-to-know-to-build-an-mlops-end-to-end-architecture-c0be1deaa3ce)以了解更多关于*Google
    Cloud* *建议的* *标准化架构*，这在几乎任何机器学习系统中都可以利用。'
- en: '**Feature Store:** the feature store stays at the heart of any ML system. Using
    a feature store, you can easily store and share features across the system. You
    can intuitively see a feature store as a fancy database that adds the following
    features:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征存储：**特征存储位于任何机器学习系统的核心。使用特征存储，你可以轻松地存储和共享系统中的特征。你可以直观地将特征存储视为一个高级数据库，增加以下功能：'
- en: data versioning and lineage
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据版本控制和血缘
- en: data validation
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据验证
- en: the ability to create datasets
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建数据集的能力
- en: the ability to hold train/validation/test splits
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存训练/验证/测试拆分的能力
- en: 'two types of storage: offline (cheap, but high latency) and online (more expensive,
    but low latency).'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两种存储类型：离线（便宜，但延迟高）和在线（更贵，但延迟低）。
- en: 'time-travel: easily access data given a time window'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间旅行：在给定时间窗口内轻松访问数据
- en: hold feature transformation in addition to the feature themselves
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了特征本身外，还保存特征转换
- en: data monitoring, etc...…
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据监控等……
- en: If you want to read about feature stores, [check out this article](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)
    [3].
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想阅读关于特征存储的内容，[请查看这篇文章](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)
    [3]。
- en: We chose [Hopsworks](https://www.hopsworks.ai/) as our feature store because
    it is serverless and offers a generous free plan that is more than enough to create
    this course.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了[Hopsworks](https://www.hopsworks.ai/)作为我们的特征存储，因为它是无服务器的，并提供了慷慨的免费计划，这足以创建本课程。
- en: Also, Hopsworks is very well designed and provides all the features mentioned
    above. If you are looking for a serverless feature store, I recommend them.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Hopsworks设计非常优秀，并提供了上述所有功能。如果你在寻找无服务器的特征存储，我推荐他们。
- en: If you want also to run the code while reading this lesson, you have to go to
    [Hopswork](https://www.hopsworks.ai/), create an account, and a project. All the
    other steps will be explained in the rest of the class.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还想在阅读本课程时运行代码，你需要去[Hopswork](https://www.hopsworks.ai/)，创建一个账户和项目。所有其他步骤将在课程的其余部分中解释。
- en: I ensured that all the steps from this course would remain in their free plan.
    Thus it won't cost you any $$$.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我确保了本课程中的所有步骤都能保留在他们的免费计划中。因此，它不会花费你任何$$$。
- en: '**Feature Engineering Pipeline:** the piece of code that reads data from one
    or more data sources, cleans, transforms, validates the data and loads it to a
    feature store (basically an ETL pipeline).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程管道：**读取来自一个或多个数据源的数据，清洗、转换、验证数据并将其加载到特征存储中的代码片段（基本上是ETL管道）。'
- en: '**Pandas vs. Spark:** we chose to use Pandas in this course as our data processing
    library because the data is small. Thus, it easily fits in the computer''s memory
    and using a distributed computing framework such as Spark would have made everything
    too complicated. But in many real-world case scenarios, when the data is too big
    to fit on a single computer (aka big data), you will use Spark (or another distributed
    computing tool) to do the exact same steps as in this lesson. [Check out this
    article](https://pub.towardsai.net/this-is-how-you-can-build-a-churn-prediction-model-using-spark-e187b7eca339)
    to see how Spark can predict churn with big data.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pandas vs. Spark：**我们在本课程中选择使用Pandas作为数据处理库，因为数据较小。因此，它可以轻松地适应计算机的内存，使用如Spark这样的分布式计算框架会使一切变得过于复杂。但在许多现实世界的场景中，当数据太大无法适应单台计算机（即大数据）时，你将使用Spark（或其他分布式计算工具）来完成与本课程相同的步骤。[查看这篇文章](https://pub.towardsai.net/this-is-how-you-can-build-a-churn-prediction-model-using-spark-e187b7eca339)以了解Spark如何处理大数据预测流失。'
- en: 'Lesson 1: Code'
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '课程 1: 代码'
- en: '[You can access the GitHub repository here.](https://github.com/iusztinpaul/energy-forecasting)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[你可以在这里访问GitHub仓库。](https://github.com/iusztinpaul/energy-forecasting)'
- en: '**Note:** All the installation instructions are in the READMEs of the repository.
    Here we will jump straight to the code.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 所有安装说明都在仓库的README文件中。这里我们将直接进入代码部分。'
- en: '*All the code within Lesson 1 is located under the* [***feature-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)*folder.*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*Lesson 1中的所有代码都位于* [***feature-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)*文件夹下。*'
- en: 'The files under the [**feature-pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)folderare
    structured as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[**feature-pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline)文件夹下的文件结构如下：'
- en: '![](../Images/a00200e79a2ce7bf64f173db2f6975fc.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a00200e79a2ce7bf64f173db2f6975fc.png)'
- en: A screenshot that shows the structure of the feature-pipeline folder [Image
    by the Author].
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 显示feature-pipeline文件夹结构的截图[作者提供]。
- en: All the code is located under the [**feature_pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline/feature_pipeline)directory
    (note the "_" instead of "-")**.**
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码都位于[**feature_pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/feature-pipeline/feature_pipeline)目录下（注意是"_"而不是"-"）**。**
- en: '***Prepare Credentials***'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***准备凭证***'
- en: 'In this lesson, you will use a single service, which you will use as your feature
    store: [Hopsworks](https://www.hopsworks.ai/) (for our use case, it will be *free
    of charge).*'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本课程中，你将使用一个单一服务作为你的特征存储：[Hopsworks](https://www.hopsworks.ai/)（在我们的用例中，它将是*免费的*）。
- en: Create an account on [Hopsworks](https://www.hopsworks.ai/) and a new project
    (or use the default project). Be careful to name your project differently than
    “**energy_consumption,”** as Hopsworks requires unique names across its serverless
    deployment.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Hopsworks](https://www.hopsworks.ai/)上创建一个账户和一个新项目（或使用默认项目）。注意不要将你的项目命名为“**energy_consumption**”，因为Hopsworks要求在其无服务器部署中项目名称唯一。
- en: Now, you need an **API_KEY** from [Hopsworks](https://www.hopsworks.ai/) to
    log in and access the cloud resources using their Python module for this step.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你需要一个来自[Hopsworks](https://www.hopsworks.ai/)的**API_KEY**来登录并使用他们的Python模块访问云资源。
- en: Directly storing credentials in your git repository is a huge security risk.
    That is why you will inject sensitive information using a **.env** file. The **.env.default**
    is an example of all the variables you must configure.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 直接在你的git仓库中存储凭证是一个巨大的安全隐患。因此，你将使用**.env**文件注入敏感信息。**.env.default**是你必须配置的所有变量的示例。
- en: '![](../Images/a925923b5eecad13761347d1f873293c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a925923b5eecad13761347d1f873293c.png)'
- en: Screenshot of the **.env.default** file [Image by the Author].
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**.env.default**文件的截图[作者提供]。'
- en: 'From your **feature-pipeline** directory, run in your terminal:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从你的**feature-pipeline**目录中，在终端中运行：
- en: '[PRE0]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: …and fill your newly generated Hopsworks API KEY under the **FS_API_KEY** variable
    and your Hopsworks project name under the **FS_PROJECT_NAME** variable (in our
    case, it was *“energy_consumption”*).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: …并在**FS_API_KEY**变量下填写你新生成的Hopsworks API KEY，在**FS_PROJECT_NAME**变量下填写你的Hopsworks项目名称（在我们的例子中，它是*“energy_consumption”*）。
- en: '***See the image below to see how to get your own Hopsworks API KEY 👇***'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '***查看下图，了解如何获取你自己的Hopsworks API KEY 👇***'
- en: '![](../Images/3eeba288d913985db231e149fe5148ff.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3eeba288d913985db231e149fe5148ff.png)'
- en: Go to your [Hopsworks](https://www.hopsworks.ai/) project. After, in the top-right
    corner, click on your username and after on "Account Settings." Finally, click
    "New API KEY," set a name, select all scopes, hit "Create API KEY," copy the API
    KEY, and you are done. You have your Hopswork API KEY [Image by the Author].
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 进入你的[Hopsworks](https://www.hopsworks.ai/)项目。然后，在右上角点击你的用户名，再点击“账户设置”。最后，点击“新建API
    KEY”，设置一个名称，选择所有作用域，点击“创建API KEY”，复制API KEY，你就完成了。你已经拥有了Hopsworks API KEY[作者提供]。
- en: Afterward, in the [**feature_pipeline/settings.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/settings.py)file,
    we will load all the variables from the **.env** file using the good old **dotenv**
    Python package.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在[**feature_pipeline/settings.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/settings.py)文件中，我们将使用老牌的**dotenv**
    Python包从**.env**文件中加载所有变量。
- en: If you want to load the **.env** file from a different place than the current
    directory, you canexport the **ML_PIPELINE_ROOT_DIR** environment variable whenrunning
    the script. This is a "HOME" environment variable that points to the rest of the
    configuration files.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想从当前目录以外的地方加载**.env**文件，你可以在运行脚本时导出**ML_PIPELINE_ROOT_DIR**环境变量。这是一个指向其余配置文件的"HOME"环境变量。
- en: We will also use the **ML_PIPELINE_ROOT_DIR** env var to point to a single directory
    from where to load the **.env** file and read/write data across all the processes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用**ML_PIPELINE_ROOT_DIR**环境变量来指向一个单一目录，从中加载**.env**文件，并在所有进程中读写数据。
- en: 'Here is an example of how to use the **ML_PIPELINE_ROOT_DIR** variable:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个如何使用**ML_PIPELINE_ROOT_DIR**变量的示例：
- en: '[PRE1]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using the following code, we will have access to all the credentials/sensitive
    information across our code using the SETTINGS dictionary.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码，我们将通过 SETTINGS 字典访问代码中的所有凭据/敏感信息。
- en: '***ETL Code***'
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***ETL 代码***'
- en: In the [**feature_pipeline/pipeline.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/pipeline.py)file,
    we have the main entry point of the pipeline under the **run()** method.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [**feature_pipeline/pipeline.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/pipeline.py)
    文件中，我们在**run()**方法下有管道的主要入口点。
- en: 'As you can see below, the run method follows on a high level the exact steps
    of an ETL pipeline:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，run 方法在高层次上遵循了 ETL 管道的确切步骤：
- en: '**extract.from_api()** — Extract the data from the energy consumption API.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**extract.from_api()** — 从能源消耗 API 提取数据。'
- en: '**transform()** — Transform the extracted data.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**transform()** — 转换提取的数据。'
- en: '**validation.build_expectation_suite()** — Build the data validation and integrity
    suite. Ignore this step, as we will insist on it in Lesson 6.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**validation.build_expectation_suite()** — 构建数据验证和完整性套件。忽略这一步，因为我们将在第 6 课中重点讲解。'
- en: '**load.to_feature_store()** — Load the data in the feature store.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**load.to_feature_store()** — 将数据加载到特征存储中。'
- en: Please note how I used the logger to reflect the system's current state. When
    your program is deployed and running 24/7, having verbose logging is crucial to
    debugging the system. Also, always use the Python logger instead of the print
    method, as you can choose different logging levels and output streams.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我如何使用日志记录器来反映系统的当前状态。当你的程序部署并全天候运行时，详细的日志记录对于调试系统至关重要。此外，总是使用 Python 的日志记录器而不是
    print 方法，因为你可以选择不同的日志级别和输出流。
- en: On a higher level, it seems easy to understand. Let's dive into each component
    separately.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，这似乎很容易理解。让我们分别深入了解每个组件。
- en: '**#1\. Extract**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**#1\. 提取**'
- en: In the extracting step, we request data for a given window length. The window
    will have a length equal to **days_export**. The first data point of the window
    is **export_end_reference_datetime - days_delay - days_export,** and the last
    data point of the window is equal to **export_end_reference_datetime - days_delay.**
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在提取步骤中，我们请求给定窗口长度的数据。窗口的长度将等于**days_export**。窗口的第一个数据点是**export_end_reference_datetime
    - days_delay - days_export**，而窗口的最后一个数据点等于**export_end_reference_datetime - days_delay**。
- en: We used the parameter **days_delay** to move the window based on the delay of
    the data. In our use case, the API has a delay of 15 days.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了参数**days_delay**来根据数据的延迟移动窗口。在我们的使用案例中，API 延迟为 15 天。
- en: As explained above, the function makes an HTTP GET request to the API requesting
    data. Afterward, the response is decoded and loaded into a Pandas DataFrame.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，该函数向 API 发出 HTTP GET 请求以请求数据。随后，响应被解码并加载到 Pandas DataFrame 中。
- en: The function returns the DataFrame plus additional metadata containing information
    about the data's extraction.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数返回 DataFrame 以及包含有关数据提取信息的附加元数据。
- en: '**#2\. Transform**'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**#2\. 转换**'
- en: 'The transform steps take the raw DataFrame and apply the following transformations:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 转换步骤将原始 DataFrame 进行如下转换：
- en: rename the columns to a Python-standardized format
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将列重命名为 Python 标准化格式
- en: cast the columns to their suited type
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将列转换为其适合的类型
- en: encode the strings columns to ints
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将字符串列编码为整数
- en: Note that we haven't included our EDA step (e.g., looking for null values),
    as our primary focus is on designing the system, not on the standard data science
    process.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们没有包括 EDA 步骤（例如，查找空值），因为我们的主要关注点是设计系统，而不是标准的数据科学过程。
- en: '**#3\. Data Validation**'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**#3\. 数据验证**'
- en: 'This is where we ensure that the data is as expected. In our case, based on
    our EDA and transformations, we are looking that:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们确保数据符合预期的地方。在我们的案例中，基于我们的 EDA 和转换，我们期望：
- en: the data doesn't have any nulls
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中没有任何空值
- en: the types of columns are as expected
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列的类型如预期
- en: the range of values is as expected
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值的范围如预期
- en: '*More on this subject in Lesson 6.*'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*有关此主题的更多内容，请参见第 6 课。*'
- en: '**#4\. Load**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**#4\. 加载**'
- en: This is where we load our processed DataFrame into the feature store.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将处理后的 DataFrame 加载到特征存储中的地方。
- en: 'Hopsworks has a set of great tutorials which you can check [here](https://docs.hopsworks.ai/3.1/tutorials/).
    But let me explain what is going on:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Hopsworks有一系列很棒的教程，你可以在[这里](https://docs.hopsworks.ai/3.1/tutorials/)查看。但让我解释一下发生了什么：
- en: We login into our Hopsworks project using our API_KEY.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用API_KEY登录到我们的Hopsworks项目中。
- en: We get a reference to the feature store.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们获取特征存储的引用。
- en: We get or create a feature group which is basically a database table with all
    the goodies of a feature store on top of it (read more [here](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/)
    [5]).
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们获取或创建一个特征组，这基本上是一个数据库表，上面附加了特征存储的所有优点（更多信息请见[这里](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/)
    [5]）。
- en: We insert our new processed data samples.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们插入新的处理数据样本。
- en: We add a set of feature descriptions for every feature of our data.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们为数据中的每个特征添加一组特征描述。
- en: We command Hopsworks to compute statistics for every feature.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们指示Hopsworks为每个特征计算统计信息。
- en: Check out the video below to see what I explained above looks into Hopsworks
    👇
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 查看下面的视频，看看我刚才解释的内容在Hopsworks中是什么样的 👇
- en: Hopsworks overview [Video by the Author].
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Hopsworks概述[作者的视频]。
- en: Awesome! Now we have a Python ETL script that extracts the data from the energy
    consumption API for a given time window and loads it into the feature store.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！现在我们有了一个Python ETL脚本，它从能耗API中提取数据，并将其加载到特征存储中。
- en: Create a Feature View & Training Dataset
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建特征视图与训练数据集
- en: One final step is to create a feature view and training dataset that will later
    be ingested into the training pipeline.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是创建一个特征视图和训练数据集，稍后将被引入训练管道中。
- en: '**Note:** The feature pipeline is the only process that does WRITES to the
    feature store. Other components will only query the feature store for various
    datasets. By doing so, we can safely use the feature store as our only source
    of truth and share the feature across the system.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 特征管道是唯一一个对特征存储进行写操作的过程。其他组件仅会查询特征存储中的各种数据集。通过这样做，我们可以安全地将特征存储作为唯一的真实来源，并在系统中共享特征。'
- en: 'In the[**feature_pipeline/feature_view.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/feature_view.py)file,
    we have the **create()** method that runs the following logic:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在[**feature_pipeline/feature_view.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/feature-pipeline/feature_pipeline/feature_view.py)文件中，我们有一个**create()**方法，它运行以下逻辑：
- en: We load the metadata from the feature pipeline. Remember that the FE metadata
    contains the start and end of the extraction window, the version of the feature
    group, etc.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从特征管道中加载元数据。请记住，FE元数据包含提取窗口的开始和结束时间、特征组的版本等。
- en: We login into the Hopswork project & create a reference to the feature store.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们登录Hopswork项目并创建对特征存储的引用。
- en: We delete all the old feature views (usually, you don't have to do this step.
    Quite the opposite, you want to keep your old datasets. But Hopwork's free version
    limits you to 100 feature views. Thus, we wanted to keep our free version).
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们删除所有旧的特征视图（通常，你不需要执行这一步。正好相反，你会希望保留旧的数据集。但是，Hopwork的免费版本限制你只能使用100个特征视图。因此，我们想要保留我们的免费版本）。
- en: We get the feature group based on the given version.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们根据给定版本获取特征组。
- en: We create a feature view with all the data from the loaded feature group.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用从加载的特征组中得到的所有数据创建一个特征视图。
- en: We create a training dataset using only the given time window.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们仅使用给定的时间窗口创建训练数据集。
- en: We create a snapshot of the metadata and save it to disk.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建元数据的快照并保存到磁盘。
- en: '**Note:** A feature view is a smart way of combining multiple feature groups
    into a single "dataset." It is similar to a VIEW in a SQL database. You can read
    more about feature views [here](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/)
    [4].'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 特征视图是一种将多个特征组组合成一个“数据集”的智能方法。它类似于SQL数据库中的VIEW。你可以在[这里](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/)
    [4]了解更多关于特征视图的信息。'
- en: That was it. You built a feature pipeline that extracts, transforms, and loads
    the data to a feature store. Based on the data from the feature store, you created
    a feature view and training dataset that will later be used within the system
    as the single source of truth.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。你建立了一个特征管道，它提取、转换并加载数据到特征存储中。基于特征存储中的数据，你创建了一个特征视图和训练数据集，这些将作为系统中的唯一真实来源。
- en: '**Note:** You need good software engineering principles and patterns knowledge
    to build robust feature engineering pipelines. [You can read some hands-on examples
    here](https://pub.towardsai.net/10-underrated-software-patterns-every-ml-engineer-should-know-92e702b96407).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 你需要良好的软件工程原则和模式知识来构建健壮的特征工程管道。[你可以在这里阅读一些实践示例](https://pub.towardsai.net/10-underrated-software-patterns-every-ml-engineer-should-know-92e702b96407)。'
- en: Important Design Decision
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重要的设计决策
- en: As you saw, we haven't actually computed any features in this lesson. We just
    cleaned, validated and ensured that the data was ready to be used later in the
    system.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们在这节课中实际上没有计算任何特征。我们只是清理、验证并确保数据已经准备好用于系统中。
- en: '*But this is called "the feature pipeline," why we haven''t computed any features?*'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*但这被称为“特征管道”，为什么我们没有计算任何特征呢？*'
- en: Let me explain.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我解释一下。
- en: '**a feature = raw data + a transformation function**'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征 = 原始数据 + 转换函数**'
- en: What if, instead of computing and storing the features, we store the raw data
    and the transformation functions within the feature store?
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将原始数据和转换函数存储在特征库中，而不是计算和存储特征，会怎样呢？
- en: 'Doingso we have the following benefits:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做我们可以获得以下好处：
- en: Faster experimentation, as the data scientist doesn't require to ask the data
    engineer to compute a new feature. He needs to add a new transformation to the
    feature store.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更快的实验，因为数据科学家不需要请求数据工程师计算新特征。他只需将新转换添加到特征库中。
- en: You save a lot of storage. For example, instead of saving 5 features computed
    from the same raw data column, you save only the raw data column + the 5 transformations,
    which will use only 1/5 of the space.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以节省大量存储空间。例如，与其保存5个从同一原始数据列计算出的特征，不如只保存原始数据列和5个转换，这样只使用原来的1/5的空间。
- en: 'Downsides of using this approach:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法的缺点：
- en: Your features will be computed on the cloud or the inference pipeline at runtime.
    Thus, you will add extra latency at runtime.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的特征将在运行时通过云端或推理管道进行计算。因此，你将在运行时增加额外的延迟。
- en: But, when using the batch-serving paradigm, latency is not a significant constraint.
    Thus, we did just that!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 但在使用批量服务范式时，延迟不是一个显著的限制。因此，我们确实这样做了！
- en: '[Check out Lesson 2](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    to see how we modeled our time series to forecast the energy consumption for the
    next 24 hours. In [Lesson 2](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee),
    we will show you how we stored the transformations directly in the feature store.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看第2课](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    以了解我们如何建模时间序列以预测接下来24小时的能源消耗。在 [第2课](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    中，我们将展示如何将转换直接存储在特征库中。'
- en: Conclusion
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Congratulations! You finished the **first lesson** from the **Full Stack 7-Steps
    MLOps Framework** course.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你完成了**第一课**来自**全栈7步MLOps框架**课程。
- en: 'You learned about how to design a batch-serving architecture and about developing
    your own ETL pipeline that:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 你了解了如何设计批量服务架构以及开发自己的 ETL 管道，这些管道：
- en: extracts data from an HTTP API
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 HTTP API 中提取数据
- en: cleans it
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理数据
- en: transforms it
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换数据
- en: loads it into a feature store
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据加载到特征库中
- en: creates a new training dataset version
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的训练数据集版本
- en: Now that you understand the power of using a feature store and its importance
    to any ML system, you can deploy your model in weeks instead of months.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经理解了使用特征库的强大功能及其对任何 ML 系统的重要性，你可以在几周内而不是几个月内部署你的模型。
- en: '[Check out Lesson 2](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    to learn about training pipelines, ML platforms, and hyperparameter tuning.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看第2课](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
    以了解有关训练管道、机器学习平台和超参数调整的信息。'
- en: '**Also**, [**you can access the GitHub repository here.**](https://github.com/iusztinpaul/energy-forecasting)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**此外**，[**你可以在这里访问 GitHub 仓库。**](https://github.com/iusztinpaul/energy-forecasting)'
- en: 💡 My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 💡 我的目标是帮助机器学习工程师在设计和生产化 ML 系统方面提升水平。关注我 [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    或订阅我的 [每周通讯](https://pauliusztin.substack.com/) 以获取更多见解！
- en: 🔥 If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). By using
    [my referral link](https://pauliusztin.medium.com/membership), you can support
    me without any extra cost while enjoying limitless access to Medium’s rich collection
    of stories.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 🔥 如果你喜欢阅读类似的文章并希望支持我的写作，考虑 [成为 Medium 会员](https://pauliusztin.medium.com/membership)。通过使用
    [我的推荐链接](https://pauliusztin.medium.com/membership)，你可以在没有额外费用的情况下支持我，同时享受 Medium
    丰富故事的无限访问。
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)
    [## 通过我的推荐链接加入 Medium - 保罗·伊斯津]'
- en: 🤖 Join to get exclusive content about designing and building production-ready
    ML systems 🚀 Unlock full access to…
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 🤖 加入以获取关于设计和构建生产级机器学习系统的独家内容 🚀 解锁完整访问权限…
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----f0b29609b20f--------------------------------)'
- en: References
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [丹麦 API 中的 DE35 行业代码能源消耗](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)，[丹麦能源数据服务](https://www.energidataservice.dk/about/)'
- en: '[2] [Hopsworks Tutorials](https://docs.hopsworks.ai/3.1/tutorials/), Hopsworks
    Documentation'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [Hopsworks 教程](https://docs.hopsworks.ai/3.1/tutorials/)，Hopsworks 文档'
- en: '[3] Jim Dowling, [Feature Store vs Data Warehouse](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)
    (2020), KDnuggets'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] 吉姆·道林，[特征存储与数据仓库](https://www.kdnuggets.com/2020/12/feature-store-vs-data-warehouse.html)（2020年），KDnuggets'
- en: '[4] [Hopsworks Feature Views](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/),
    Hopsworks Documentation'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [Hopsworks 特征视图](https://docs.hopsworks.ai/3.1/concepts/fs/feature_view/fv_overview/)，Hopsworks
    文档'
- en: '[5] [Hopsworks Feature Groups](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/),
    Hopsworks Documentation'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [Hopsworks 特征组](https://docs.hopsworks.ai/3.1/concepts/fs/feature_group/fg_overview/)，Hopsworks
    文档'
