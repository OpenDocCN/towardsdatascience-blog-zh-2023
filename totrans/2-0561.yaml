- en: Convergence in Probability or Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/convergence-in-probability-or-distribution-1766e08125cd](https://towardsdatascience.com/convergence-in-probability-or-distribution-1766e08125cd)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What is the difference between the two?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)[![Shuo
    Wang](../Images/17a7299c0a36d9a4c0d07ebfc9d5c282.png)](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)
    [Shuo Wang](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)
    ¬∑6 min read¬∑Sep 4, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38ca6ca8cbc2275769040cd2e887056b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: During your study of statistics, have you encountered the concepts of convergence
    in probability and convergence in distribution? Have you ever pondered why these
    concepts were introduced in the first place? If you have, then this story aims
    to help you answer some of those questions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Convergence in Probability**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let‚Äôs begin by delving into the concept of convergence in probability, as it
    is the more straightforward concept to grasp. Imagine we have a sequence of random
    variables: *X1*, *X2*, ‚Ä¶, *Xn*, and as we let n approach infinity, if the probability
    that *Xn* is very close to x approaches 1, we can conclude that *Xn* converges
    to x in probability.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/25a2ce3fc83c323a08fb4a0a483aa329.png)'
  prefs: []
  type: TYPE_IMG
- en: Why is it defined in this manner? The rationale behind this definition stems
    from the fact that, regardless of how large n becomes, Xn will never precisely
    equal *x* (the constant). The most we can ascertain is to specify how close *Xn*
    must be to *x* in terms of the probability that *Xn* falls within a certain interval
    around *x*.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, our definition asserts that as n approaches infinity, the likelihood
    of *Xn* differing from *x* by an amount greater than Œµ diminishes to an infinitesimal
    level, ultimately approaching zero. Moreover, Œµ can be arbitrarily small.
  prefs: []
  type: TYPE_NORMAL
- en: An illustrative example of convergence in probability would be the concept of
    the sample mean. Consider the scenario where we repeatedly draw n samples from
    a normal distribution with a mean of 0 and a standard deviation of 0.1\. If we
    calculate the sample mean of these n samples, this resulting sample mean becomes
    a random variable denoted as Xn and possesses its own distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The question then arises: What is the nature of this distribution? When n=1,
    the sample mean is simply equivalent to the individual sample itself, and its
    distribution mirrors the population distribution, specifically the normal distribution
    with a mean of 0 and a standard deviation of 0.1.'
  prefs: []
  type: TYPE_NORMAL
- en: But what if *n=1000*? Intuitively, in such cases, we would expect the sample
    mean calculated to be very close to the population mean, which is 0\. It is reasonable
    to assume that when we repeatedly draw 1000 samples and calculate the sample mean,
    the values might cluster around numbers like 0.001, 0.002, -0.001, and so on,
    without significant fluctuations.
  prefs: []
  type: TYPE_NORMAL
- en: What if n=1,000,000? In this scenario, it‚Äôs highly probable that the sample
    means would be extremely close to 0, with any deviation from this value being
    minuscule.
  prefs: []
  type: TYPE_NORMAL
- en: This is precisely the essence of convergence in probability. As n increases,
    the distribution of the random variable *Xn* becomes progressively narrower, ultimately
    converging towards a single value.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c98a39e7d9b0895e295064f66edcbf4f.png)'
  prefs: []
  type: TYPE_IMG
- en: The sampling distribution of the sample mean is visualized in a sequence of
    histograms, showcasing samples drawn from a normal distribution for different
    sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: 'This phenomenon occurs not only with samples drawn from a normal distribution
    but also with the binomial distribution. When we draw n samples from a binomial
    distribution with 1 trial and a probability of success of 0.5, we observe a convergence
    pattern very similar to the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fe260b5d0ec160f3075f62b4e23200fd.png)'
  prefs: []
  type: TYPE_IMG
- en: The sampling distribution of the sample mean is visualized in a sequence of
    histograms, showcasing samples drawn from a binomial distribution for different
    sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of how tightly we attempt to constrain the sample mean within a specific
    interval, we can always identify a sufficiently large n where the probability
    of the sample mean falling within that interval approaches 100%.
  prefs: []
  type: TYPE_NORMAL
- en: Convergence in Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conversely, it‚Äôs important to note that not every sequence of random variables
    converges to a single number in probability. In many cases, a sequence of random
    variables does not converge to a specific number but instead converges to a random
    variable with its own distinct distribution. In such instances, we refer to this
    behavior as convergence in distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5c675de23c01ecad4885ea5694a0169.png)'
  prefs: []
  type: TYPE_IMG
- en: CDFn(t) represents the cumulative distribution function of the random variable
    Xn within the given sequence, while CDF(t) signifies the cumulative distribution
    function of a random variable X.
  prefs: []
  type: TYPE_NORMAL
- en: The definition states that when considering a sequence of random variables *Xn*,
    the cumulative distribution function (CDF) of the random variables in this sequence
    converges to the CDF of a random variable *X* as *n* approaches infinity.
  prefs: []
  type: TYPE_NORMAL
- en: 'An illustrative example of this concept is the standardized sample mean. Below,
    you will find the definition of the standardized sample mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/783c3a10e68ad323288653e2b3fd0ac3.png)'
  prefs: []
  type: TYPE_IMG
- en: Z represents the standardized sample mean, where n is the number of samples
    drawn, X_bar is the sample mean, ùúá is the population mean, and ùúé is the population
    standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have drawn n samples from the population, you can obtain the standardized
    sample mean by following these steps: calculate the sample mean from the n samples,
    subtract the population mean from it, multiply the result by the square root of
    the sample size, and then divide by the population standard deviation.'
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, while the sample mean itself converges in probability to the
    population mean, the standardized sample mean converges in distribution to a random
    variable with normal distribution with a mean of zero and a standard deviation
    of one.
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, we can conceptualize the standardized sample mean as a rescaled
    version of the sample mean. Referring back to the previous illustrations of the
    sample mean convergence, we observe that its distribution gradually resembles
    that of a normal distribution as the sample size increases, only becoming progressively
    narrower. By rescaling the sample mean through multiplication by the square root
    of the sample size, we effectively broaden the distribution, allowing it to maintain
    the shape of a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The visualization below illustrates the convergence of the standardized sample
    mean for samples drawn from both a normal distribution and a binomial distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7d2bb75aef9c7328ab9db039869502e5.png)'
  prefs: []
  type: TYPE_IMG
- en: The sampling distribution of the standardized sample mean is visualized in a
    sequence of histograms, showcasing samples drawn from a normal distribution for
    different sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/43c73f6a84450ebbdb75202679d98652.png)'
  prefs: []
  type: TYPE_IMG
- en: The sampling distribution of the standardized sample mean is visualized in a
    sequence of histograms, showcasing samples drawn from a binomial distribution
    for different sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  prefs: []
  type: TYPE_NORMAL
- en: Why do We Care?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a sense, there exists only one overarching form of convergence: convergence
    by distribution. We can regard convergence by probability as a particular instance
    of convergence by distribution, wherein the final distribution becomes degenerate
    and converges to a single value. But why is this distinction significant?'
  prefs: []
  type: TYPE_NORMAL
- en: First and foremost, the observation that the sample mean converges to the true
    population mean is what enables us to estimate that population mean. This estimation
    process is a common practice in a wide array of real-life situations. For instance,
    whenever we make generalizations like ‚Äúneighbors are nosy,‚Äù we are implicitly
    relying on the idea that our limited sampling, derived from our own experiences,
    converges to the actual population mean. This principle is known as the Weak Law
    of Large Numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Even more crucial is the observation that the standardized sample mean converges
    to a normal distribution. It is this fact that empowers us to conduct hypothesis
    tests and make informed assessments regarding the likelihood that a particular
    set of observations arises from mere chance or an underlying causal process. This
    phenomenon is more formally recognized as the Central Limit Theorem.
  prefs: []
  type: TYPE_NORMAL
- en: '**Links**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Notebook for convergence illustration](https://github.com/swang225/meinyenura/blob/main/python/research/notebook/sample_mean_std_sample_mean_convergence.ipynb)'
  prefs: []
  type: TYPE_NORMAL
