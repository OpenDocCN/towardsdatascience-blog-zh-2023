# 创建并部署一个提取图像主要颜色的REST API

> 原文：[https://towardsdatascience.com/create-and-deploy-a-rest-api-extracting-predominant-colors-from-images-a44b94cc3d46](https://towardsdatascience.com/create-and-deploy-a-rest-api-extracting-predominant-colors-from-images-a44b94cc3d46)

## 使用无监督机器学习、FastAPI和Docker

[](https://nicolo-albanese.medium.com/?source=post_page-----a44b94cc3d46--------------------------------)[![Nicolo Cosimo Albanese](../Images/9a2c26207146741b58c3742927d09450.png)](https://nicolo-albanese.medium.com/?source=post_page-----a44b94cc3d46--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a44b94cc3d46--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a44b94cc3d46--------------------------------) [Nicolo Cosimo Albanese](https://nicolo-albanese.medium.com/?source=post_page-----a44b94cc3d46--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a44b94cc3d46--------------------------------) ·阅读时间15分钟·2023年9月26日

--

![](../Images/2c1fc392c4d210706b63a714d397b644.png)

图片由作者提供。

# 目录

1.  [问题陈述](#c5a9)

1.  [从图像中提取颜色](#dfe8)

1.  [项目结构](#dfe8)

1.  [代码](#50f4)

1.  [部署Docker容器](#d547)

1.  [让我们尝试一下！](#aeea)

1.  [API文档](#1e07)

1.  [结论](#17f9)

1.  [许可证声明](#01e6)

# 1\. 问题陈述

让我们设想一个**制造设施**的控制室，其中生产的产品需要自动分类。例如，根据颜色，货物可能会被重新导向滚筒输送机的不同分支，以进行进一步处理或包装。

否则，我们也可以设想一个**在线零售商**试图通过添加*按颜色搜索*功能来增强用户体验。客户可以更容易地找到特定颜色的衣物，从而简化他们对感兴趣产品的访问。

或者，就像作者一样，你可以将自己想象成一位**IT顾问**，实现一个简单、快速且可重用的工具，用于从输入图像中生成适用于演示文稿、图表和应用程序的色彩调色板。

这些只是从图片中提取主要颜色如何提升操作效率或增强客户体验的几个示例。

在这篇博客文章中，我们使用Python实现从给定图片中提取主要颜色。然后，我们使用FastAPI和Docker将解决方案打包并部署为服务。

本帖的目的是分享一个关于部署轻量且自洽服务的端到端示例，该服务利用机器学习技术实现商业目的。这样的服务可以轻松集成到[microservice architecture](https://microservices.io/index.html)中。

# 2\. 从图像中提取颜色

数字图像本质上是一个二维的像素网格。[像素](https://en.wikipedia.org/wiki/Pixel)是图像中最小的显示单元，携带关于颜色的信息。常用的颜色表示方法是[RGB颜色模型](https://en.wikipedia.org/wiki/RGB_color_model)。这一加法模型使用三种原色——红色、绿色和蓝色（因此称为RGB）组合，创造出丰富的颜色。每种原色的强度由一个8位值表示。因此，每个像素有三个强度值，分别对应三种原色，范围从0到255：

![](../Images/d2c8f47bfe42b47c0b34d156753956d1.png)

加法 RGB 颜色模型。来源于 [维基百科](https://it.wikipedia.org/wiki/RGB#/media/File:AdditiveColor.svg)。

我们可以通过聚类从图像中提取主要颜色。简而言之，聚类技术尝试将相似的对象分组。在聚类方法中，我们将使用[K-Means](https://en.wikipedia.org/wiki/K-means_clustering)算法。它旨在通过最小化数据点与各自组中心（质心）之间的平方距离之和来创建“紧凑”的组。我们可以选择要创建的组/簇数量 `k`。在我们的案例中，数据点是每个像素的 RGB 值。模型训练后，我们可以将质心视为图像中主要颜色的代表。

让我们进入实践，创建一个 `ColorAnalyzer` 类，接受输入图像并提取其主要颜色。该类将具有以下方法：

+   `load_image` 从本地路径或 URL 加载图像到二维数组。

+   `is_url` 检查输入路径是否为 URL。

+   `preprocess_image` 调整图像大小以提高处理速度。

+   `find_clusters` 应用 K-Means 聚类以提取重要颜色作为质心。

+   `sort_clusters_by_size` 按簇大小降序排序颜色。

+   `plot_image` 显示原始输入图像（已调整大小）。

+   `plot_3d_clusters` 显示簇的三维图。观察结果显示其质心（主要）颜色。

+   `plot_predominant_colors` 绘制一张按图像中颜色出现频率排序的条形图。

+   `get_predominant_colors` 返回主要颜色的 JSON 对象列表。

[PRE0]

我们可以使用 Python notebook 测试我们的类：

+   使用指向在线图像的输入 URL 实例化类：

[PRE1]

+   绘制原始图像（已调整大小）：

[PRE2]

![](../Images/f8293b34b0fc5aebbf5e674107db75a8.png)

图片由作者提供。

+   绘制最主要颜色的条形图：

[PRE3]

![](../Images/1f5ef6576add27124dbd825e02ffa182.png)

图片由作者提供。

+   显示获得的簇：

[PRE4]

![](../Images/feeceaf27f30e61a9b885552456a345f.png)

图片由作者提供。

+   返回提取颜色的 JSON 对象列表：

[PRE5]

[PRE6]

我们可以对任何输入图像（URL或本地路径）重复这一过程，并检查结果。例如：

[PRE7]

![](../Images/8ab7b9205cce01bc4730af5e13adf475.png)

图片由作者提供。

如何创建一个在请求时提供图像分析功能的Web服务？我们需要将我们的笔记本转换为一个暴露REST API的Python项目。

# 3\. 项目结构

让我们介绍一下项目的主要组成部分：

1.  [REST API](https://www.redhat.com/en/topics/api/what-is-a-rest-api)：[REST](https://en.wikipedia.org/wiki/REST)（表述性状态转移）API是一种设计应用程序的架构风格。它使用标准的HTTP方法（GET、POST等）来允许不同系统之间的通信。在我们的案例中，我们希望通过HTTP请求使客户端能够请求从输入图像中提取主要颜色。我们将使用[FastAPI](https://fastapi.tiangolo.com/)来构建API服务。

1.  [Docker](https://docs.docker.com/)：一个允许在隔离容器中构建、部署和运行应用程序的平台。使用Docker将帮助我们将所有用于颜色提取任务所需的依赖项打包在一起，确保一致性、可移植性并消除操作上的麻烦（*我使用的是哪个Python版本？我安装了所有包吗？我需要什么版本的OpenCV？*）。

![](../Images/1d593e563f4b288d979a6371fdc9caaf.png)

REST API。图像由作者提供。

我们可以将项目结构如下：

[PRE8]

+   `README.md`：项目文档，以Markdown格式编写。

+   `requirements.txt`：运行项目所需的Python依赖项列表。

+   `Dockerfile`：包含所有组装Docker镜像命令的文本文件，即用于项目的隔离环境。

+   `main.py`：我们应用程序的入口点。

+   `api/`：包含REST API端点定义的子文件夹。在我们的简单示例中，我们只有一个端点用于请求颜色提取。

+   `dto/`：包含在API服务请求和响应中使用的数据类的子文件夹。名称`dto`源自[数据传输对象](https://en.wikipedia.org/wiki/Data_transfer_object)，因为这些类代表客户端和服务之间的接口。

+   `service/`：包含应用程序逻辑的子文件夹。在我们的示例中，`ColorAnalyzer`类提供图像处理能力。

+   `notebooks/`：包含笔记本实验的子文件夹。

在不同模块（`dto/`、`api/`、`service/`）中分离数据（或*模型*）、端点定义（或*控制器*）和应用程序逻辑（或*服务*）是一种保证清晰性、可维护性和可重用性的方法。这也促进了更清洁的架构，并简化了后续开发。读者可以参考[MVC设计模式](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller)以获取更多信息。

# 4\. 代码

让我们开始查看`main.py`。在我们的入口点中，我们：

+   创建FastAPI应用程序：`app = FastAPI()`。

+   启用CORS以通过`add_middleware`方法允许客户端调用Web服务。

+   为根端点（`"/"`）定义一个`GET`请求处理程序，返回一个简单的消息。

+   在我们的api模块中包含一个路由器，并使用`"api/"`前缀。该前缀将成为最终端点的一部分，如下所示：`"http://<host>:<port>/api/<endpoint>"`。

[PRE9]

端点的定义在`api`模块中。在`"api/endpoints.py"`文件内，我们：

+   为FastAPI应用程序创建路由器：`router = APIRouter()`，该路由器在`main.py`中被导入。

+   为`/colors`端点定义一个`POST`请求。应用程序期望一个`ColorExtractionRequest`类的请求，并返回一个`ColorExtractionResponse`类的响应。这两个对象在`dto`模块中定义。

+   在接收到请求后，会实例化一个`ColorAnalyzer`对象，并将颜色提取结果作为响应返回给用户。

[PRE10]

让我们探索请求和响应的数据模型。其类定义在`dto`模块中，位于`dto/image_data.py`文件内：

[PRE11]

这个数据模型很简单。简而言之，该服务：

+   接受一个输入的URL或路径，以及一个期望的集群数量/主要颜色。

+   返回一个由RGB值和图像中属于该集群的像素百分比组成的JSON对象列表。

有趣的是，定义`pydantic`类不仅提高了可读性和维护性，还简化了利用FastAPI框架生成API文档的过程（更多内容见后续段落）。

现在，我们只需要定义一个Docker镜像并部署Docker容器。

# 5\. 部署Docker容器

让我们观察项目根目录中的`Dockerfile`。此文本文件包含了为我们的项目创建Docker镜像的所有命令。具体如下：

+   `FROM python:3.8-slim`将基础镜像设置为起始点。

+   `WORKDIR /colors-extractor`将容器内的工作目录设置为`/colors-extractor`。

+   `COPY requirements.txt requirements.txt`将依赖项从本地机器复制到容器内的`WORKDIR`。

+   `RUN pip install -r requirements.txt`在Docker容器中安装requirements.txt中列出的Python依赖项。

+   `COPY . .`将项目文件从本地机器复制到容器中。我们在安装依赖项后再执行此操作，因为Docker通过分层后续命令创建镜像。如果我们只是更新代码库，根据当前命令的顺序，Docker引擎不会重新安装所有依赖项。

+   `EXPOSE 8000`暴露了8000端口，我们的FastAPI应用程序就在这个端口上运行。

+   `CMD [“uvicorn”, `main:app`, “--host”, “0.0.0.0”, “--port”, “8000”]`是容器启动时运行的命令。在这种情况下，我们指示容器使用Uvicorn运行FastAPI应用程序。映射`main:app`设置了我们应用程序的正确入口点，即`main.py`。

[PRE12]

要在本地部署Docker容器，从命令行：

[PRE13]

我们可以通过以下方式展示运行中的容器：

[PRE14]

使用此命令，我们可以获取与我们的应用程序相关联的容器ID，并使用它来检查日志：

[PRE15]

日志确认应用程序正在运行：

![](../Images/18ae641e0cb5b912b04ddec4644f313a.png)

图片由作者提供。

# 6\. 让我们试试吧！

让我们记住端点结构：

+   `main.py`声明了一个带有`/api`前缀的路由器指向`api`模块。

+   `api`模块在`endpoints.py`文件中定义了一个用于`/colors`端点的`POST`请求处理程序。

+   运行端口是`8000`。

因此，我们应该执行一个`POST`请求到：

+   `[http://localhost:8000/api/colors](http://localhost:8000/api/colors.)`

要测试服务，我们可以使用[curl](https://curl.se/)或[Postman](https://www.postman.com/)等工具：

[PRE16]

结果：

[PRE17]

同样地，使用Postman：

![](../Images/0f7022adc2c32f7e6b995f2e6ab7d6bc.png)

使用Postman测试服务。图片由作者提供。

我们可以再次检查容器以验证日志中是否存在我们的测试调用：

![](../Images/43df7a68a2f05c6e99085f0656f1cc4c.png)

日志。图片由作者提供。

# 7\. API文档

FastAPI会自动提供已实现API的文档。默认情况下，它可以在以下地址访问：

+   `[http://<host>:<port>/docs](http://localhost:8000/api/colors.)`

访问该URL，我们可以找到一个完全记录我们端点的网页用户界面（[Swagger UI](https://github.com/swagger-api/swagger-ui)）：

![](../Images/72e3c56bb3ab7f165cf89e93209a09ba.png)

API文档。图片由作者提供。

请求和响应的数据模型在网页界面的`Schemas`部分下，并且它填充了在`dto`模块中定义的`pydantic`模型，并与路由器的处理程序相关联：

![](../Images/d8b9917ee6c7b99af2aeef87b3a85950.png)

数据模型。图片由作者提供。

# 8\. 结论

在这篇博客文章中，我们分享了利用以下内容逐步实现服务的过程：

+   无监督机器学习技术用于实现业务目标，即从图像中提取主要颜色。

+   FastAPI用来将解决方案作为REST API提供服务。

+   使用Docker进行隔离和一致的部署。

我们的目标是展示一个全面的示例，可以轻松地重用和扩展以将机器学习模型部署为REST API。

本博客的完整代码可以在[GitHub](https://github.com/NicoloAlbanese/colors-extractor/tree/main)上找到。

# **9\. 许可声明**

为撰写此文章，我们使用了两张图片：

+   “[*棕色草地背景的山景*](https://unsplash.com/photos/xjXz8GKXcTI)”由[Linh Nguyen](https://unsplash.com/@bylinhnguyen)拍摄。

+   “[*白色陶瓷杯装满咖啡*](https://unsplash.com/photos/ZJsseAxEcqM)”由[Justin Leibow](https://unsplash.com/@justinleibow)拍摄。

两个来源均可在[Unsplash许可证](https://unsplash.com/license)下免费用于个人和商业用途。我们使用[Picsum](https://picsum.photos/)（[GitHub repo](https://github.com/DMarby/picsum-photos)）生成了图像URL，且其使用[MIT许可证](https://github.com/DMarby/picsum-photos/blob/main/LICENSE.md)。
