- en: Getting started with JAX
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/getting-started-with-jax-a6f8d8d0e20](https://towardsdatascience.com/getting-started-with-jax-a6f8d8d0e20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Powering the future of high-performance numerical computing and ML research
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)[![Pier
    Paolo Ippolito](../Images/981abb84149adab275473b76bdbde66f.png)](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)
    [Pier Paolo Ippolito](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)
    ·5 min read·Jul 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17e806ec59ab7110eb1eb8acbdca9117.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Lance Asper](https://unsplash.com/@lance_asper?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: JAX is a Python library developed by Google to perform high-performance numerical
    computing on any type of device (CPU, GPU, TPU, etc…). One of the main applications
    of JAX is Machine Learning and Deep Learning research development, although the
    library is mainly designed to provide all the necessary capabilities to perform
    general-purpose scientific computing tasks (highly dimensional matrices operations,
    etc…).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Considering the focus specifically on high-performance computing, JAX has been
    designed to be extremely fast being built on top of XLA (Accelerated Linear Algebra).
    XLA is in fact a compiler designed to speed up linear algebra operations and can
    be used to work behind also other frameworks such as TensorFlow and Pytorch. Additionally,
    JAX arrays have been designed to follow the same principles as Numpy, making it
    really easy to migrate old Numpy code to JAX and take advantage of performance
    speed-ups through GPUs and TPUs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the main characteristics of JAX are:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**Just in Time (JIT) compilation**: JIT and accelerated hardware are what can
    enable JAX to be much faster than plain Numpy. Using the *jit()* function can
    be possible to compile and cache custom functions with the XLA kernel. Using caching
    we will increase the overall execution time we first run the function, to then
    drastically reduce the time for the successive runs. When using caching it is
    important to make sure to clear the caches when needed in order to avoid stale
    results (e.g. global variables changing).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automatic Parallelization:** Asynchronous Dispatch enables JAX vectors to
    be lazily evaluated, materializing content just when accessed (control is returned
    to the program before computation completion). Additionally, in order to make
    possible graph optimization, JAX arrays are immutable (similar concepts with lazy
    evaluation and graph optimization applies to [Apache Spark](/getting-started-with-apache-spark-cb703e1b3ee9)).
    The *pmap()* function can be used to parallelize computations on multiple GPUs/TPUs.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动并行化**：异步调度使得 JAX 向量可以延迟计算，仅在访问时才生成内容（在计算完成之前控制权返回程序）。此外，为了实现图优化，JAX 数组是不可变的（类似的概念包括延迟计算和图优化，适用于
    [Apache Spark](/getting-started-with-apache-spark-cb703e1b3ee9)）。*pmap()* 函数可以用于在多个
    GPU/TPU 上并行计算。'
- en: '**Automatic Vectorization**: Automatic vectorization to parallelize operations
    can be performed using the *vmap()* function. During vectorization, an algorithm
    is transformed from operating with a single value to a set of values.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动矢量化**：可以使用 *vmap()* 函数进行自动矢量化以并行化操作。在矢量化过程中，算法从对单个值的操作转变为对一组值的操作。'
- en: '**Automatic Differentiation**: The *grad()* function can be used to automatically
    calculate the gradient (derivative) of functions. In particular, JAX Automatic
    Differentiation enables the development of general-purpose differential programs
    outside the spectrum of Deep Learning. Making it possible to differentiate through
    recursion, branches, loops, perform higher-order differentiation (e.g. Jacobians
    and Hessians), and using both forward and reverse mode differentiation.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动微分**：*grad()* 函数可以用于自动计算函数的梯度（导数）。特别是，JAX 自动微分使得在深度学习领域之外开发通用的微分程序成为可能。可以通过递归、分支、循环进行微分，执行高阶微分（例如，雅可比矩阵和海森矩阵），并使用前向和反向模式微分。'
- en: Therefore JAX is able to provide us with all the necessary foundations to build
    advanced Deep Learning models but not out-of-the-box high-level utils for some
    of the most common Deep Learning operations (e.g. loss/activation functions, layers,
    etc…). For example, model parameters learned during ML training can be stored
    in a Pytree structure in JAX. Considering all the advantages provided by JAX different
    DL-oriented frameworks have been built on top of it such as Haiku (used by DeepMind)
    and Flax (used by Google Brain).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，JAX 能为我们提供构建先进深度学习模型所需的所有基础，但没有提供一些最常见深度学习操作（例如，损失/激活函数、层等）的开箱即用的高级工具。例如，在
    ML 训练过程中学到的模型参数可以存储在 JAX 的 Pytree 结构中。考虑到 JAX 提供的所有优势，不同的深度学习框架已经在其基础上构建，例如 Haiku（由
    DeepMind 使用）和 Flax（由 Google Brain 使用）。
- en: Demonstration
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 演示
- en: As part of this article, we are now going to see how to solve a simple classification
    problem using JAX and the [Kaggle Mobile Price Classification dataset](https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification)
    [1] to predict in which price range a phone will be. All the code used throughout
    this article (and more!) is available on [my GitHub](https://github.com/pierpaolo28)
    and [Kaggle accounts](https://www.kaggle.com/pierpaolo28).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本文的一部分，我们将看到如何使用 JAX 和 [Kaggle 移动价格分类数据集](https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification)
    [1] 来解决一个简单的分类问题，以预测手机的价格范围。本文中使用的所有代码（以及更多！）都可以在 [我的 GitHub](https://github.com/pierpaolo28)
    和 [Kaggle 账户](https://www.kaggle.com/pierpaolo28) 上找到。
- en: First of all, we need to make sure to have JAX installed in our environment.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确保在环境中安装了 JAX。
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: At this point, we are ready to import the necessary libraries and datasets (Figure
    1). In order to simplify our analysis, instead of using all the classes in our
    label we filter the data to use just 2 classes and subset the number of features.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们已经准备好导入必要的库和数据集（图 1）。为了简化分析，我们不使用所有标签中的类别，而是过滤数据以仅使用 2 个类别，并减少特征的数量。
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/650db3e4167067f50af65e416b5a9563.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/650db3e4167067f50af65e416b5a9563.png)'
- en: 'Figure 1: Mobile Price Classification Dataset (Image by Author).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：移动价格分类数据集（图片由作者提供）。
- en: Once cleaned the dataset, we can now divide it into training and test subsets
    and standardize the input features so that to make sure they all lie within the
    same ranges. At this point, the input data is also converted in JAX arrays.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集清理完成后，我们可以将其划分为训练集和测试集，并标准化输入特征，以确保它们都位于相同范围内。此时，输入数据也被转换为 JAX 数组。
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In order to predict the price range of the phones, we are going to create a
    Logistic Regression model from scratch. To do so, we first need to create a couple
    of helper functions (one to create the Sigmoid activation function, and another
    for the binary loss function).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We are now ready to create our training loop and plot the results (Figure 2).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/6204d9b6d257691a91df3ceb667ba819.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Logistic Regression Training History (Image by Author).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Once happy with the results, we can then test the model against our test set
    (Figure 3).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/effce9fd630a04de06c437405e3f83b1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Classification Report on Test Data (Image by Author).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As demonstrated in this brief example, JAX has a very intuitive API that closely
    follows Numpy conventions while making it possible to use the same code for CPU/GPU/TPU
    usage. Making use of these building blocks it can then be possible to create highly
    customizable Deep Learning models optimized by design for performance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Contacts
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you want to keep updated with my latest articles and projects [follow me
    on Medium](https://pierpaoloippolito28.medium.com/subscribe) and subscribe to
    my [mailing list](http://eepurl.com/gwO-Dr). These are some of my contacts details:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[Linkedin](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Personal Website](https://pierpaolo28.github.io/)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Medium Profile](https://towardsdatascience.com/@pierpaoloippolito28)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GitHub](https://github.com/pierpaolo28)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kaggle](https://www.kaggle.com/pierpaolo28)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bibliography
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] “Mobile Price Classification” (ABHISHEK SHARMA). Accessed at: [https://thecleverprogrammer.com/2021/03/05/mobile-price-classification-with-machine-learning/](https://thecleverprogrammer.com/2021/03/05/mobile-price-classification-with-machine-learning/)
    (MIT License: [https://github.com/alifrmf/Mobile-Price-Prediction-Classification-Analysis/tree/main](https://github.com/alifrmf/Mobile-Price-Prediction-Classification-Analysis/tree/main))'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
