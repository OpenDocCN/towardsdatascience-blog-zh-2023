- en: OpenAI API — Intro & Implementation of the Models Behind ChatGPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI API — ChatGPT 背后的模型介绍与实现
- en: 原文：[https://towardsdatascience.com/openai-api-intro-11-practical-implementation-examples-of-the-models-behind-chatgpt-18601f68b51b](https://towardsdatascience.com/openai-api-intro-11-practical-implementation-examples-of-the-models-behind-chatgpt-18601f68b51b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/openai-api-intro-11-practical-implementation-examples-of-the-models-behind-chatgpt-18601f68b51b](https://towardsdatascience.com/openai-api-intro-11-practical-implementation-examples-of-the-models-behind-chatgpt-18601f68b51b)
- en: A programmatic approach to use models behind ChatGPT.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 ChatGPT 背后的模型的编程方法。
- en: '[](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)[![Farzad
    Mahmoodinobar](../Images/2d75209693b712300e6f0796bd2487d0.png)](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)
    [Farzad Mahmoodinobar](https://medium.com/@fmnobar?source=post_page-----18601f68b51b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)
    ·19 min read·Nov 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----18601f68b51b--------------------------------)
    ·19 分钟阅读·2023 年 11 月 7 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/33ae9ba7ca530fc3af3daf6fde9e8927.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33ae9ba7ca530fc3af3daf6fde9e8927.png)'
- en: Photo by [Freddy Castro](https://unsplash.com/@readysetfreddy?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/black-twist-pen-near-white-teacup-u3ajSXhZM_U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Freddy Castro](https://unsplash.com/@readysetfreddy?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    提供，来源于 [Unsplash](https://unsplash.com/photos/black-twist-pen-near-white-teacup-u3ajSXhZM_U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: ChatGPT needs no further introduction these days and in this post we would like
    to look deeper into how we can programmatically interact with the models and engines
    that power ChatGPT (e.g. GPT-4, GPT-3.5, DALL·E, etc.) through the official [OpenAI
    API](https://openai.com/blog/openai-api) (OpenAI is the company behind ChatGPT).
    Machine learning scientists and engineers generally demonstrate a preference for
    using APIs rather than graphical user interfaces, such as ChatGPT, since APIs
    provide a much higher level of flexibility and customization, as we will see in
    the implementation examples, which are required in business settings.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现如今 ChatGPT 不需要进一步介绍，在这篇文章中，我们将更深入地探讨如何通过官方的 [OpenAI API](https://openai.com/blog/openai-api)（OpenAI
    是 ChatGPT 背后的公司）以编程方式与 ChatGPT（如 GPT-4、GPT-3.5、DALL·E 等）背后的模型和引擎互动。机器学习科学家和工程师通常更喜欢使用
    API 而不是图形用户界面，例如 ChatGPT，因为 API 提供了更高的灵活性和定制性，正如我们将在实现示例中看到的，这在商业环境中是必需的。
- en: 'In order to use OpenAI’s API, we will set up and activate a Python virtual
    environment (this a recommended but optional step), install OpenAI Python library
    and start implementing 11 practical examples. These examples are my personal favorite
    ones among many that I have explored and will cover the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 OpenAI 的 API，我们将设置并激活一个 Python 虚拟环境（这是一项推荐但可选的步骤），安装 OpenAI Python 库，并开始实现
    11 个实际示例。这些示例是我在众多探索过的示例中最喜欢的，将包括以下内容：
- en: Explain Code
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释代码
- en: Image Generation
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像生成
- en: Emoji Translation (i.e. we provide a text description and the model returns
    emojis that describe the provided text!)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 表情符号翻译（即我们提供文本描述，模型返回描述该文本的表情符号！）
- en: Grammatical Error Correction
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 语法错误纠正
- en: Airport Code Extractor
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机场代码提取器
- en: Named-Entity Extractor
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 命名实体提取器
- en: Machine Translation
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器翻译
- en: Sentiment Analysis
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 情感分析
- en: Text Summarization
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本摘要
- en: Parse Unstructured Data
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析非结构化数据
- en: Write SQL Queries
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写 SQL 查询
- en: I will provide more details about each task as we go through them but now that
    we know the outline of what we will cover, let’s get started!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我会在逐步讲解每项任务时提供更多细节，但现在既然我们知道了大纲，让我们开始吧！
- en: 1\. Setup Python
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 设置 Python
- en: This step is just to create a virtual environment so that you can isolate what
    is created and used in this post from your other Python bodies of work. As I mentioned
    earlier in the post, use of a virtual environment is optional but is generally
    among the recommended best practices for machine learning practitioners and programmers.
    There are more than one methods to create this and below is one approach that
    I have used. We will create the virtual environment, then activate it and then
    install OpenAI’s Python library (OpenAI’s Python library installation is a required
    step, even if you decide to skip the virtual environment step).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步只是为了创建一个虚拟环境，以便你可以将本文中创建和使用的内容与其他 Python 工作隔离开来。正如我在文章中提到的，使用虚拟环境是可选的，但通常是机器学习从业者和程序员推荐的最佳实践之一。有多种方法可以创建虚拟环境，下面是我使用的一种方法。我们将创建虚拟环境，然后激活它，再安装
    OpenAI 的 Python 库（即使你决定跳过虚拟环境步骤，安装 OpenAI 的 Python 库仍然是必需的步骤）。
- en: Mac users open your Terminal and Windows users open the Command Prompt (instructions
    are below, in case you are not familiar with this step) and follow along!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Mac 用户打开你的终端，Windows 用户打开命令提示符（说明见下方，以防你对这一步不熟悉），并跟随操作！
- en: '**Tip:** How to open the “Terminal” (on Mac) or “Command Prompt” (on Windows)
    are as follows:'
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示：** 如何打开“终端”（在 Mac 上）或“命令提示符”（在 Windows 上）如下：'
- en: ''
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**- Mac Users:** Go to “Applications” folder or search for “Terminal” using
    “Spotlight” (Command + Space opens “Spotlight”)'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**- Mac 用户：** 前往“应用程序”文件夹或使用“Spotlight”搜索“终端”（Command + Space 打开“Spotlight”）'
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**- Windows Users:** Search for “cmd” in the start menu to open the “Command
    Prompt”'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**- Windows 用户：** 在开始菜单中搜索“cmd”以打开“命令提示符”'
- en: 1.1\. Virtual Environment
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1\. 虚拟环境
- en: 'With the Terminal or Command Prompt open, we can create the virtual environment
    named `openai-env` with the following command:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 打开终端或命令提示符，我们可以使用以下命令创建名为`openai-env`的虚拟环境：
- en: '`python -m venv openai-env`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`python -m venv openai-env`'
- en: 'Once the virtual environment is created, we can then activate it with the command
    below:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦虚拟环境创建完成，我们可以使用下面的命令激活它：
- en: '`source openai-env/bin/activate`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`source openai-env/bin/activate`'
- en: Now we are in the newly-created and activated virtual environment. Next, we
    will install OpenAI’s Python library.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在新创建并激活的虚拟环境中。接下来，我们将安装 OpenAI 的 Python 库。
- en: 1.2\. Install OpenAI Python Library
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2\. 安装 OpenAI Python 库
- en: 'Note that while use of a virtual environment was optional, installation of
    OpenAI Python library is a required step for implementation. The following command
    installs the latest OpenAI Python library:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然虚拟环境的使用是可选的，但安装 OpenAI Python 库是实现的必需步骤。以下命令安装最新的 OpenAI Python 库：
- en: '`pip install — upgrade openai`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip install — upgrade openai`'
- en: 2\. Setup API Key
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 设置 API 密钥
- en: Using OpenAI API requires setting up an OpenAI account and acquiring an OpenAI
    API Key — I will walk you through both steps.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenAI API 需要设置一个 OpenAI 账户并获取 OpenAI API 密钥——我将带你完成这两个步骤。
- en: Setting up an OpenAI account can be accomplished through [OpenAI Sign-Up Website](https://platform.openai.com/signup).
    Once the OpenAI account is created, you can navigate to the [API Key Page](https://platform.openai.com/account/api-keys)
    and click on “Create new secret key”. You would want to save this somewhere safe
    and generally would not want to share your API Keys with others.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 OpenAI 账户可以通过 [OpenAI 注册网站](https://platform.openai.com/signup) 完成。创建 OpenAI
    账户后，你可以访问 [API 密钥页面](https://platform.openai.com/account/api-keys) 并点击“创建新的密钥”。你需要将其保存在安全的地方，并且通常不想与他人分享你的
    API 密钥。
- en: 'Once the API Key is set up, we will import it as follows, replacing the `YOUR_API_KEY`
    with your own recently-created OpenAI API Key:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置好 API 密钥，我们将按如下方式导入它，将 `YOUR_API_KEY` 替换为你最近创建的 OpenAI API 密钥：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With the prep work out of the way, we can finally focus on creating a function
    to call OpenAI’s API and start the fun part of implementing the examples!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备工作完成后，我们终于可以专注于创建一个函数来调用 OpenAI 的 API，并开始实现示例的有趣部分！
- en: 3\. Call Function
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 调用函数
- en: In this section, we will create a function to make a call to OpenAI’s API, which
    I named as the `magicWand`! Invoking OpenAI’s API requires passing a set of variables
    (covered below). Creation of this function will simplify the process so that we
    do not repeat the same steps for each example.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个函数来调用 OpenAI 的 API，我将其命名为`magicWand`！调用 OpenAI 的 API 需要传递一组变量（如下所述）。创建此函数将简化过程，以便我们不需要为每个示例重复相同的步骤。
- en: For all the examples, except for image generation, we will be using OpenAI’s
    [Chat Completion](https://platform.openai.com/docs/api-reference/chat/create)
    and will be using the following variables in the request. Understanding these
    variables at the moment is not required. We will learn how they work as we go
    through the examples but I have provided an overview for reference.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有示例，除了图像生成外，我们将使用OpenAI的[聊天完成](https://platform.openai.com/docs/api-reference/chat/create)，并在请求中使用以下变量。目前无需了解这些变量的详细信息。我们将在逐步示例中学习它们的工作原理，但我已经提供了一个概述以供参考。
- en: '`engine`: Identifies the model to be used, such as `gpt-4` or `gpt-3.5-turbo`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`engine`：识别将要使用的模型，例如`gpt-4`或`gpt-3.5-turbo`'
- en: '`system_prompt`: System-level prompt used to provide a high-level guidance
    about the task'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`system_prompt`：用于提供任务高层次指导的系统级提示'
- en: '`user_prompt`: User-level prompt used to provide a more detailed instruction
    for the task'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_prompt`：用于提供任务更详细说明的用户级提示'
- en: '`temperature`: This is a sampling temperature between 0 and 2\. Higher numbers
    (e.g. 0.8) will ensure the output is more randomly generated, while lower numbers
    (e.g. 0.2) will make it more deterministic'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature`：这是介于0和2之间的采样温度。较高的数字（例如0.8）将确保输出更随机生成，而较低的数字（例如0.2）将使其更具确定性'
- en: '`max_tokens`: Maximum number of tokens that the model will generate (this helps
    limit the length of the response)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_tokens`：模型将生成的最大令牌数量（这有助于限制响应长度）'
- en: 'We will pass these variables as the values of a configuration dictionary with
    the following format in our examples:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在示例中将这些变量作为配置字典的值，格式如下：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let’s create our function! At this point, do not worry about completely understanding
    the function. We will ask GPT-4 to explain the code to us, as the very first example!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建我们的函数！此时，不必完全理解函数的内容。我们将请求GPT-4解释代码，这是第一个示例！
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 4\. Task Implementation
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 任务实施
- en: Now that we have the function, let’s try it for our first task, which is code
    explanation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了函数，让我们尝试第一个任务，即代码解释。
- en: 4.1\. Explain Code
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1\. 解释代码
- en: As promised earlier, let’s ask GPT-4 to explain our own code to us to better
    understand the function!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前承诺的那样，让我们请GPT-4解释我们的代码，以便更好地理解该函数！
- en: 'In order to do this, we will use the `magicWand` function that we just created
    and pass the values as demonstrated below. Note that the main instruction is the
    `system_prompt`, where we explain the task to GPT-4 as: `You will be provided
    with a piece of code, and your task is to explain it in a concise way`.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将使用刚刚创建的`magicWand`函数，并按如下方式传递值。请注意，主要指令是`system_prompt`，我们向GPT-4解释任务为：`您将获得一段代码，您的任务是以简洁的方式解释它`。
- en: Let’s implement this task and look at the results.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实施这个任务并查看结果。
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Results:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/d7cf2f4c2f9408817b5de4f36ccbbf5b.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7cf2f4c2f9408817b5de4f36ccbbf5b.png)'
- en: GPT-4’s explanation of the `magicWand` function
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4对`magicWand`函数的解释
- en: I find the results quite impressive and fascinating at the same time. It provides
    a step-by-step explanation of what our `magciWand` function variables are and
    what they are intended to accomplish. Once you are done reading through the results,
    let’s move on to generating an image next!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现这些结果既令人印象深刻又迷人。它逐步解释了我们的`magciWand`函数变量是什么以及它们的目的是什么。阅读完结果后，我们接下来就生成一个图像吧！
- en: 4.2\. Image Generation
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2\. 图像生成
- en: As the name suggests, we are going to generate an image this time. This is the
    only example where we do not use OpenAI’s Chat Completion and use OpenAI’s DALL·E
    model instead. Use case is pretty straight forward — we just provide the description
    of the image in `prompt`, the number of images as `n` and the size of the image
    as `size`. Let’s ask for `A black Scottish fold cat with light golden eyes laying
    down on white sheets` and look at the resulting image!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如名字所示，这次我们将生成一张图像。这是唯一一个我们不使用OpenAI的聊天完成，而是使用OpenAI的DALL·E模型的示例。使用案例非常直接——我们只需在`prompt`中提供图像描述，`n`为图像数量，`size`为图像大小。让我们请求`一只黑色的苏格兰折耳猫，带有浅金色眼睛，躺在白色床单上`，并查看生成的图像！
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Results:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/a95726232c85b10dc058de4e14dbd48b.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a95726232c85b10dc058de4e14dbd48b.png)'
- en: Image of a cat generated through OpenAI’s API
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过OpenAI的API生成的猫咪图像
- en: That’s a pretty good image and consistent with our prompt. Next, we will work
    on a fun request — we will ask GPT-4 to translate a natural language input (i.e.
    text) into emojis!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当不错的图像，并且与我们的提示一致。接下来，我们将处理一个有趣的请求——我们将要求GPT-4将自然语言输入（即文本）翻译成表情符号！
- en: 4.3\. Emoji Translation
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3\. 表情符号翻译
- en: This one is probably my favorite example! We will ask GPT-4 to translate our
    text to emojis, using our very own `magicWand` function. We will provide GPT4
    the overall instruction as the `system_prompt` of `You will be provided with text,
    and your task is to translate it into emojis. Do not use any regular text. Do
    your best with emojis only` and then provide the `user_prompt` that needs to be
    translated from text to emoji as `Data science articles are fun`. Let’s look at
    the results!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是我最喜欢的例子！我们将要求GPT-4使用我们自己的`magicWand`函数将文本翻译成表情符号。我们将提供给GPT4的总体指示作为`system_prompt`，即`你将会收到文本，你的任务是将其翻译成表情符号。不要使用任何常规文本。仅使用表情符号尽力而为`，然后提供需要从文本翻译成表情符号的`user_prompt`为`数据科学文章很有趣`。让我们看看结果！
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Results:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/cacce625834fc22556d3bdee818b7b93.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cacce625834fc22556d3bdee818b7b93.png)'
- en: GPT-4’s translation of text to emojis
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的文本到表情符号的翻译
- en: That is quite interesting! I can see how the first half of the emojis relate
    to data and science and the second half of the emojis relate to being fun.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常有趣！我能看到前半部分的表情符号与数据和科学相关，后半部分的表情符号则与乐趣相关。
- en: Next, we will ask GPT models to correct grammatical errors in a given sentence.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将要求GPT模型纠正给定句子中的语法错误。
- en: 4.4\. Grammatical Error Correction
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4\. 语法错误纠正
- en: One of the use cases of machine learning models is the ability to correct grammatical
    errors present in a sentence. These can have many benefits in business settings.
    For example, businesses dealing with customer communications need to have human
    representatives read, review and respond to such customer communications. Human
    representatives are quite costly and if incoming messages are difficult to understand,
    such communications will require extra work for the humans to understand and then
    respond to. Alternatively, businesses can rely on grammatical error correction
    models to first clean up the incoming communications and then send the corrected
    version of the communications to the human representatives for review and action.
    I wrote a separate post on a different grammatical error correction model in the
    past (linked below) so I decided to use the same sentence with GPT models to see
    how GPT models perform!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的一个应用场景是纠正句子中的语法错误。这在商业环境中可以带来许多好处。例如，处理客户沟通的企业需要人类代表阅读、审查并回复这些客户沟通。人类代表的成本相当高，如果收到的消息难以理解，这样的沟通将需要额外的工作来让人类理解和回复。作为替代方案，企业可以依赖语法错误纠正模型来首先清理传入的沟通，然后将修正后的沟通版本发送给人类代表进行审查和处理。我以前写过关于另一种语法错误纠正模型的独立帖子（见下文链接），所以我决定使用相同的句子来看看GPT模型的表现！
- en: '[](/grammatical-error-correction-with-machine-learning-overview-and-implementation-ccd0b50a1700?source=post_page-----18601f68b51b--------------------------------)
    [## Grammatical Error Correction with Machine Learning — Overview and Implementation'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/grammatical-error-correction-with-machine-learning-overview-and-implementation-ccd0b50a1700?source=post_page-----18601f68b51b--------------------------------)
    [## 机器学习中的语法错误纠正 — 概述与实现'
- en: 'Using Grammatical Error Correction: Tag, Not Rewrite (GECTor)'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用语法错误纠正：标记，而不是重写（GECTor）
- en: towardsdatascience.com](/grammatical-error-correction-with-machine-learning-overview-and-implementation-ccd0b50a1700?source=post_page-----18601f68b51b--------------------------------)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/grammatical-error-correction-with-machine-learning-overview-and-implementation-ccd0b50a1700?source=post_page-----18601f68b51b--------------------------------)
- en: We will instruct both `gpt-4` or `gpt-3.5-turbo` to correct the grammatical
    errors in the sentence of `she looks at sky yesterday whil brushed her hair` and
    then will compare how they perform. Note there are intentional typos and grammatical
    errors in the sentence for the models to correct. In order to do so, we will use
    a `system_prompt` of `You will be provided with statements, and your task is to
    convert them to standard English` to both models and then provide the sentence
    as the `user_prompt`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将指示`gpt-4`或`gpt-3.5-turbo`纠正句子中的语法错误`她昨天看天空时梳头`，然后比较它们的表现。请注意，句子中有故意的拼写和语法错误供模型纠正。为此，我们将使用`system_prompt`为`你将会收到陈述，你的任务是将其转换为标准英语`来给这两个模型，然后将句子提供为`user_prompt`。
- en: 'Let’s implement with GPT-3.5 and look at the results first:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用GPT-3.5实现并查看结果：
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Results:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/3f8ac713ae43e7b59e9f5280ccf4d638.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f8ac713ae43e7b59e9f5280ccf4d638.png)'
- en: GPT-3.5’s corrected sentence
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5修正后的句子
- en: 'And now let’s implement with GPT-4:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们用GPT-4来实现：
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Results:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/9afe59f4907fc787b532020bb9042628.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9afe59f4907fc787b532020bb9042628.png)'
- en: GPT-4’s corrected sentence
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4修正后的句子
- en: First observation is that both models performed very well in correcting the
    grammatical errors and improving readability of the original sentence. The second
    observation is that `gpt-3.5-turbo` performed almost as well as `gpt-4` and given
    the higher cost of `gpt-4`, maybe we can just use the `gpt-3.5-turbo` going forward
    for grammatical error correction.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先的观察是，两种模型在修正语法错误和提高原句可读性方面表现都非常好。第二个观察是，`gpt-3.5-turbo`的表现几乎与`gpt-4`一样，考虑到`gpt-4`的更高成本，也许我们可以在未来的语法错误修正中仅使用`gpt-3.5-turbo`。
- en: In the next example, we will ask GPT to identify airport codes inside a sentence!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个例子中，我们将要求GPT识别句子中的机场代码！
- en: 4.5\. Airport Code Extractor
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5\. 机场代码提取器
- en: I have to confess this task is a bit odd in nature and is something that I personally
    would not be able to do off the top of my head but we are going to ask GPT to
    return the airport codes from a text, with a `system_prompt` of `You will be provided
    with a text, and your task is to extract the airport codes from it` and a `user_prompt`
    of `I flew from Seattle to Boston in August`. Let’s use both `gpt-4` or `gpt-3.5-turbo`
    and compare the results, starting with GPT-3.5.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须承认这个任务有点奇怪，是我个人无法立即完成的，但我们将要求GPT从文本中返回机场代码，`system_prompt`为`你将获得一段文本，你的任务是从中提取机场代码`，`user_prompt`为`我在八月从西雅图飞往波士顿`。让我们使用`gpt-4`或`gpt-3.5-turbo`并比较结果，从GPT-3.5开始。
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Results:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/1754ca3b3280ed8af140277f81ea0e7d.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1754ca3b3280ed8af140277f81ea0e7d.png)'
- en: GPT-3.5’s extracted airport names
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5提取的机场名称
- en: 'And then let’s implement with GPT-4:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们用GPT-4来实现：
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Results:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/b533564d91530d33fb05acee0b1efeb1.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b533564d91530d33fb05acee0b1efeb1.png)'
- en: GPT-4’s attempt at extracting airport names
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4尝试提取的机场名称
- en: As you can see, the results are both “technically” correct but also very different.
    `gpt-3.5-turbo` correctly returns the actual airport codes for the two city names
    of Seattle and Boston that are in the sentence, although the airport codes are
    not explicitly included in the prompt, as `gpt-4` states. My assumption here is
    that `gpt-3.5-turbo` is fine-tuned to be able return the airport codes, while
    `gpt-4` treats the task more literally and does not retrieve the airport codes
    — both are quite interesting to see.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，结果在“技术上”都是正确的，但也非常不同。`gpt-3.5-turbo`准确地返回了句子中西雅图和波士顿这两个城市名称的实际机场代码，尽管机场代码在提示中并未明确包含，正如`gpt-4`所说。我的假设是`gpt-3.5-turbo`经过微调，能够返回机场代码，而`gpt-4`则更字面地对待任务，没有检索出机场代码——这两者都很有趣。
- en: Next, let’s move on to identifying named-entities in a provided text.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们继续识别提供文本中的命名实体。
- en: 4.6\. Named-Entity Extractor
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6\. 命名实体提取器
- en: Named-entity recognition is a common natural language processing (NLP) task
    where named-entities such as names, locations, addresses, organizations, etc.
    are identified. This will become much easier to understand through an example.
    We will prompt both `gpt-4` and `gpt-3.5-turbo` with the `system_prompt` of `You
    will be provided with a text, and your task is to extract the named-entities from
    it` and the `user_prompt` of `I flew from Seattle to Boston in August. I remember
    I was wearing my brand new Nike shoes because I was so excited about them that
    I ended up leaving my iPhone in the yellow Camry cab`. We expect the models to
    identify named-entities such as Seattle, Boston, August, Nike, iPhone and Camry
    but let’s see how the models do, starting with GPT-3.5.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 命名实体识别是一个常见的自然语言处理（NLP）任务，其中识别命名实体，如名称、地点、地址、组织等。通过一个例子，这将变得更容易理解。我们将给`gpt-4`和`gpt-3.5-turbo`提供`system_prompt`为`你将获得一段文本，你的任务是从中提取命名实体`和`user_prompt`为`我在八月从西雅图飞往波士顿。我记得我穿着崭新的耐克鞋，因为我对它们非常兴奋，以至于把我的iPhone忘在了黄色的凯美瑞出租车里`。我们期望模型能识别出如西雅图、波士顿、八月、耐克、iPhone和凯美瑞等命名实体，但让我们先看看模型的表现，从GPT-3.5开始。
- en: '[PRE10]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Results:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/48778af230d356b08a34eac443f2b945.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48778af230d356b08a34eac443f2b945.png)'
- en: GPT-3.5’s extracted named-entities
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5提取的命名实体
- en: 'and let’s implement and look at the GPT-4 results:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们实现并查看GPT-4的结果：
- en: '[PRE11]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Results:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/ed070a7f006c45d90c2256f4b3f1c6a3.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed070a7f006c45d90c2256f4b3f1c6a3.png)'
- en: GPT-4’s extracted named-entities
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4提取的命名实体
- en: Very good results! Both models were able to recognize all the named-entities
    and unlike `gpt-4`, `gpt-3.5-turbo` was also able to return the type of the named-entity
    (e.g. Seattle and Boston are locations, etc.). So if I have a named-entity recognition
    task, I will be more likely to use `gpt-3.5-turbo`, which has the advantage of
    returning the type of the recognized named-entities and also is less expensive
    than `gpt-4`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常好！两个模型都能够识别所有命名实体，而与`gpt-4`不同，`gpt-3.5-turbo`还能够返回命名实体的类型（例如，Seattle和Boston是地点等）。因此，如果我有命名实体识别的任务，我更可能使用`gpt-3.5-turbo`，因为它能够返回识别出的命名实体的类型，并且比`gpt-4`便宜。
- en: Let’s move to the next task and ask the models to translate for us!
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入下一个任务，请模型为我们进行翻译！
- en: 4.7\. Machine Translation
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7\. 机器翻译
- en: This task is self-explanatory. We will include a `system_prompt` of `You will
    be provided with a text, and your task is to translate it to French` and then
    provide a `user_prompt` of `Can you help me with this task?` to be translated
    to French. I tested both GPT models and the results were identical so I’ll only
    include one of them below for reference.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务不言而喻。我们将包含一个`system_prompt`为`You will be provided with a text, and your
    task is to translate it to French`，然后提供一个`user_prompt`为`Can you help me with this
    task?`，需要翻译成法语。我测试了两个GPT模型，结果相同，所以下面仅包含其中一个作为参考。
- en: '[PRE12]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Results:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/52fa96857b5324259c4cd61e63f493ab.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52fa96857b5324259c4cd61e63f493ab.png)'
- en: GPT-4’s English to French translation results
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的英法翻译结果
- en: That’s a good translation as expected! Feel free to play around with the `system_prompt`
    and have the models translate the `user_prompt` to other languages!
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个预期中的好翻译！随意调整`system_prompt`，让模型将`user_prompt`翻译成其他语言吧！
- en: Next, we will look at sentiment analysis.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看情感分析。
- en: 4.8\. Sentiment Analysis
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.8\. 情感分析
- en: Sentiment analysis is another common NLP task. At its most basic form, it tells
    whether a sentence carries a positive, negative or neutral sentiment. This can
    be quite useful for businesses in understanding their customers’ feedback. For
    example, a model can consume all customer reviews of a restaurant, product or
    service and return the percentage of the comments that are positive, neutral or
    negative and use that as an overall rating for that restaurant, product, or service!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析是另一项常见的NLP任务。在最基本的形式中，它告诉我们一个句子是带有积极、消极还是中立的情感。这对企业理解客户反馈非常有用。例如，一个模型可以处理所有的餐馆、产品或服务的客户评论，并返回正面、中性或负面的评论百分比，并用作该餐馆、产品或服务的总体评分！
- en: Let’s instruct `gpt-4` with a `system_prompt` of `You will be provided with
    a text, and your task is to provide a nuanced sentiment analysis` and the `user_prompt`
    of `That was such an exciting movie`. Note that the sentence sounds quite positive
    so we want to see whether the sentiment analysis results are aligned with that
    expectation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们给`gpt-4`一个`system_prompt`为`You will be provided with a text, and your task
    is to provide a nuanced sentiment analysis`和`user_prompt`为`That was such an exciting
    movie`。请注意，这句话听起来非常积极，因此我们想看看情感分析结果是否与预期一致。
- en: Let’s look at the results!
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看结果吧！
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Results:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/237409237e9a44114f8abda019aaf88b.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/237409237e9a44114f8abda019aaf88b.png)'
- en: GPT-4’s sentiment analysis results
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的情感分析结果
- en: As expected, `gpt-4` also agrees that the sentence is a positive one and adds
    a second sentence that sounds like the reasoning behind the model’s decision.
    It is important to note that the “reasoning” provided may or may not be true,
    since LLMs, such as GPT-4 are not exactly deterministic — it only indicates that
    the model associates “exciting” with enjoyment, engagement and a positive sentiment
    — there is a lot we do not know about how these models generate what they generate
    but that is a topic for another day.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，`gpt-4`也认为这个句子是积极的，并添加了一个听起来像是模型决策背后理由的第二句。需要注意的是，“推理”可能真实也可能不真实，因为像GPT-4这样的LLM并不是完全确定性的——它仅仅表明模型将“激动人心”与享受、参与和积极情感关联起来——我们对于这些模型生成内容的方式知之甚少，但这是另一个话题。
- en: As the next task, let’s ask the model to summarize a text!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的任务，让我们请模型总结一个文本！
- en: 4.9\. Text Summarization
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.9\. 文本摘要
- en: Text summarization is another self-explanatory task. Imagine when we call a
    customer support line and the representative wants to read the previous communications
    on this topic between customer support and the customer. Instead of reading the
    entire correspondence, a model would summarize the most important parts of the
    past communications and then the customer support representative would only read
    the summary provided by the model. This saves valuable time both for the customer
    and the service provider.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 文本摘要是另一项不言自明的任务。想象一下，当我们拨打客户支持热线时，代表希望阅读之前关于这个话题的客户支持与客户之间的通信。与其阅读整个通信记录，不如使用模型总结过去通信中的最重要部分，然后客户支持代表只需阅读模型提供的摘要。这为客户和服务提供商节省了宝贵的时间。
- en: In order to do so, let’s provide GPT-4 with the `system_prompt` of `You will
    be provided with a text, and your task is to provide a summary of it, without
    using the original words` and provide a lengthy text to be summarized as the `user_prompt`
    of `Text summarization is the task of automatically summarizing textual input,
    while still conveying the main points and gist of the incoming text. One example
    of the business intuition behind the need for such summarization models is the
    situations where humans read incoming text communications (e.g. customer emails)
    and using a summarization model can save human time`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，让我们向 GPT-4 提供 `system_prompt` 为 `你将会收到一段文本，你的任务是对其进行总结，不使用原文中的词语`，并提供一段较长的文本作为
    `user_prompt`，其内容为 `文本摘要是自动总结文本输入的任务，同时仍传达主要观点和要点。需要这种总结模型的商业直觉之一是人们阅读收到的文本通信（例如客户电子邮件），并且使用总结模型可以节省人工时间`。
- en: Let’s see the results!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看结果吧！
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Results:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/0430abc250092e1842774eca2399b5de.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0430abc250092e1842774eca2399b5de.png)'
- en: GPT-4’s text summarization results
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 的文本摘要结果
- en: That seems to be a good summary of the provided text! I don’t think I could
    have done a much better job myself.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎是对提供文本的一个很好的总结！我认为我自己也未必能做得更好。
- en: Next task is for those dealing with data analytics, which is parsing through
    unstructured data.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的任务是处理数据分析的那些人，即解析非结构化数据。
- en: 4.10\. Parse Unstructured Data
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.10\. 解析非结构化数据
- en: This one is quite useful for those users who have to deal with a lot of unstructured
    data. We can have the model go through the text and then organize the data into
    groups. Let’s look at an example to better understand this.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些需要处理大量非结构化数据的用户，这个结果非常有用。我们可以让模型处理文本，然后将数据组织成不同的组。让我们看一个例子来更好地理解这一点。
- en: We will provide GPT-4 with the `system_prompt` of `You will be provided with
    unstructured data, and your task is to parse it into a Pandas dataframe` and then
    provide the unstructured data as the `user_prompt` of `As I was walking around
    Mars a few days ago, I came across a group of Amazon employees. The first one,
    Jack, was originally from Boston and wore black pants with a white shirt and black
    running shoes. Another one, Jill, had a long indigo-colored dress on with light
    blue sandals and was originally from Seattle. The third one was named John. I
    cannot remember what he was wearing but I particularly recall that John was from
    Newark, New Jersey. The last individual was Jenna and she was from San Francisco.
    Jenna had a white t-shirt and blue pants on but I cannot recall her shoes`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向 GPT-4 提供 `system_prompt` 为 `你将会收到非结构化数据，你的任务是将其解析成一个 Pandas 数据框`，然后提供非结构化数据作为
    `user_prompt`，内容为 `几天前我在火星上散步时，遇到了一群亚马逊员工。第一个人，杰克，来自波士顿，穿着黑色裤子、白色衬衫和黑色跑鞋。另一个人，吉尔，穿着长款靛蓝色连衣裙，脚踩浅蓝色凉鞋，来自西雅图。第三个人名叫约翰。我不记得他穿了什么，但我特别记得约翰来自新泽西州的纽瓦克。最后一个人是珍娜，她来自旧金山。珍娜穿着白色T恤和蓝色裤子，但我不记得她穿了什么鞋子`。
- en: You can see that the `user_prompt` includes names of the individuals and what
    they wear. Let’s see how the model can organize this information.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到 `user_prompt` 包括了个人的名字和他们穿的衣物。让我们看看模型如何组织这些信息。
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Results:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/83d9ada2103499ef038f451c29a2a206.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83d9ada2103499ef038f451c29a2a206.png)'
- en: GPT-3.5’s structured output of the unstructured input
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5 对非结构化输入的结构化输出
- en: That is quite impressive and well done! As you can see, GPT-3.5 was able to
    go through the provided text and organize (i.e. parse) it into relevant columns
    for each of the individuals. This parsing used to be done mostly manually in the
    past and can be very helpful when one wishes to analyze the data in a tabular
    format.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常令人印象深刻，做得很好！正如你所看到的，GPT-3.5 能够处理提供的文本，并将其组织（即解析）成每个人的相关列。这种解析在过去大多是手动完成的，当人们希望以表格格式分析数据时，这会非常有帮助。
- en: As the last task, we will ask the model to write a SQL query for us!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的任务，我们将要求模型为我们编写一个 SQL 查询！
- en: 4.11\. Write SQL Queries
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.11\. 编写 SQL 查询
- en: I was personally curious about the SQL writing abilities of GPT models, since
    I use SQL quite frequently for work and had posted the below SQL tutorial on Medium
    in the past.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人对 GPT 模型的 SQL 编写能力非常好奇，因为我在工作中频繁使用 SQL，并且在 Medium 上发布过以下 SQL 教程。
- en: '[](https://medium.com/@fmnobar/sql-requirements-for-a-data-scientist-in-amazon-cheat-sheet-b1e24004ede7?source=post_page-----18601f68b51b--------------------------------)
    [## SQL Tutorial + Cheat Sheet'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[## SQL 教程 + 备忘单](https://medium.com/@fmnobar/sql-requirements-for-a-data-scientist-in-amazon-cheat-sheet-b1e24004ede7?source=post_page-----18601f68b51b--------------------------------)'
- en: Introduction
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: medium.com](https://medium.com/@fmnobar/sql-requirements-for-a-data-scientist-in-amazon-cheat-sheet-b1e24004ede7?source=post_page-----18601f68b51b--------------------------------)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@fmnobar/sql-requirements-for-a-data-scientist-in-amazon-cheat-sheet-b1e24004ede7?source=post_page-----18601f68b51b--------------------------------)'
- en: In order to evaluate the abilities of GPT models, I selected one of the examples
    that I had used in my SQL post above and asked `gpt-3.5-turbo` to write the query
    that I had prepared myself. In order to do so, we want to define the table to
    be queried as part of the `system_prompt` and then define the task in the `user_prompt`
    as usual. Let’s look at the implementation of this example, followed by the results
    and comparison to the query I had written myself.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 GPT 模型的能力，我选择了我在 SQL 帖子中使用的一个示例，并要求 `gpt-3.5-turbo` 编写我自己准备的查询。为此，我们希望将要查询的表定义为
    `system_prompt` 的一部分，然后像往常一样在 `user_prompt` 中定义任务。让我们看看这个示例的实现，然后是结果和与我自己编写的查询的比较。
- en: '[PRE16]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Results:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '![](../Images/20ecac63eff1c1aad69637eba3960aea.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20ecac63eff1c1aad69637eba3960aea.png)'
- en: GPT-3.5’s query
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5 的查询
- en: This is quite impressive! This query involves using window functions, which
    are among the more challenging concepts in SQL but the model is handling them
    quite well. Below is my own solution from the post above for reference and as
    you can see the overall structure of the response from the model is quite similar
    to how I had written the query!
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常令人印象深刻！这个查询涉及使用窗口函数，这些函数是 SQL 中较具挑战性的概念之一，但模型处理得相当好。以下是我在上面帖子中提供的解决方案作为参考，你可以看到模型的响应整体结构与我编写的查询非常相似！
- en: '![](../Images/e8e69df00c7fa3a83ac678736296c64f.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8e69df00c7fa3a83ac678736296c64f.png)'
- en: My own query
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我自己的查询
- en: 5\. Conclusion
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 结论
- en: In this post, we walked through OpenAI’s API, which provides access to the behind-the-scene
    models enabling ChatGPT perform various tasks. Then we implemented 11 examples
    of chat completion and image generation using OpenAI’s API and compared the performance
    of `gpt-4` and `gpt-3.5-turbo` for some of these tasks. Overall, I found both
    GPT models quite powerful and consider them useful tools for my personal use and
    DALL·E is an impressive image generator.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了 OpenAI 的 API，它提供了对后台模型的访问，使 ChatGPT 能够执行各种任务。然后，我们使用 OpenAI 的 API
    实现了 11 个聊天完成和图像生成的示例，并比较了 `gpt-4` 和 `gpt-3.5-turbo` 在这些任务中的表现。总体而言，我发现这两个 GPT
    模型都非常强大，并认为它们是我个人使用的有用工具，而 DALL·E 是一个令人印象深刻的图像生成器。
- en: Thanks For Reading!
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you found this post helpful, please [follow me on Medium](https://medium.com/@fmnobar)
    and [subscribe](https://medium.com/@fmnobar/subscribe) to receive my latest posts!
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这篇文章对你有帮助，请 [关注我在 Medium 上](https://medium.com/@fmnobar) 和 [订阅](https://medium.com/@fmnobar/subscribe)
    以接收我的最新帖子！
- en: (All images, unless otherwise noted, are by the author.)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: （所有图片，除非另有说明，均由作者提供。）
