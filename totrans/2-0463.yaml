- en: How to Build a Local Chatbot with Llama2 and LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/can-a-llama-2-powered-chatbot-be-trained-on-a-cpu-ce9ec6ebe3c2](https://towardsdatascience.com/can-a-llama-2-powered-chatbot-be-trained-on-a-cpu-ce9ec6ebe3c2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overview and Implementation with Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@aashishnair?source=post_page-----ce9ec6ebe3c2--------------------------------)[![Aashish
    Nair](../Images/23f4b3839e464419332b690a4098d824.png)](https://medium.com/@aashishnair?source=post_page-----ce9ec6ebe3c2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce9ec6ebe3c2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce9ec6ebe3c2--------------------------------)
    [Aashish Nair](https://medium.com/@aashishnair?source=post_page-----ce9ec6ebe3c2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce9ec6ebe3c2--------------------------------)
    ·6 min read·Oct 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ded2ef377ff10804f982df906fed5cbe.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Adi Goldstein](https://unsplash.com/@adigold1?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ∘ [Introduction](#6563)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Case Study](#dcc3)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Step 1 — Creating a Vector Store](#9999)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Step 2—Creating the QA Chain](#b94f)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Step 3 — Creating the User Interface](#a748)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Evaluating the chatbot](#347d)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [The Results](#3580)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [The Final Verdict](#b61a)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [References](#ec13)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The advent of local models has been welcomed by businesses looking to build
    their own custom LLM applications. They enable developers to build solutions that
    can run offline and adhere to their privacy and security requirements.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Such LLMs were originally huge and mostly catered to enterprises that have the
    funds and resources to provision GPUs and train models on large volumes of data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'However, local LLMs are now available in much smaller sizes, which begs the
    question: is it possible for individuals with basic CPUs to harness these same
    tools and technologies?'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: It’s a question worth considering as users stand to gain a lot from building
    their own personal, local chatbots that can perform tasks offline.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Here, we explore this possibility by building a close-sourced chatbot using
    Meta’s Llama2 on a CPU and evaluate its performance as a reliable tool for individuals.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '**Case Study**'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To test the feasibility of a building local chatbot that can run offline on
    a personal computer, let’s carry out a case study.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The objective is to build a chatbot using a quantized version of Meta’s Llama2
    (7B parameters). The model will be used to build a LangChain application that
    facilitates response generation, which can be accessed with a user interface that
    enables people to interact with the application.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4e0460af3009b86e062b0bbd6677d1ee.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e0460af3009b86e062b0bbd6677d1ee.png)'
- en: Chatbot Diagram (Created by Author)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人图示（由作者创建）
- en: 'The chatbot will be trained with two PDF documents (both accessible with the
    arXiv API):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 该聊天机器人将使用两个PDF文档进行训练（两个文档均可通过arXiv API访问）：
- en: '[A Comprehensive Review of Computer Vision in Sports: Open Issues, Future Trends
    and Research Directions](https://browse.arxiv.org/pdf/2203.02281.pdf)'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[计算机视觉在体育中的全面综述：开放问题、未来趋势和研究方向](https://browse.arxiv.org/pdf/2203.02281.pdf)'
- en: '[A Survey of Deep Learning in Sports Applications: Perception, Comprehension,
    and Decision](https://browse.arxiv.org/pdf/2307.03353.pdf)'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[深度学习在体育应用中的调研：感知、理解和决策](https://browse.arxiv.org/pdf/2307.03353.pdf)'
- en: 'For context, this bot will be trained on a computer with the following specifications:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供背景，这个机器人将在具有以下规格的计算机上进行训练：
- en: 'Operating System: Windows 10'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统：Windows 10
- en: 'Processor: Intel i7'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理器：Intel i7
- en: 'RAM: 8GB'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'RAM: 8GB'
- en: 'Note: Following along case study will require prior knowledge of the LangChain
    framework and the Streamlit library'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注：跟随本案例研究需要具备LangChain框架和Streamlit库的基础知识
- en: Step 1 — Creating a Vector Store
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步 — 创建向量存储
- en: First, we create the vector store, which will store the embedded data from the
    documents and facilitate the retrieval of documents relevant to the users’ queries.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建向量存储，它将存储来自文档的嵌入数据，并促进与用户查询相关文档的检索。
- en: '![](../Images/2f5d8138129b691dd2d8d3963a7a7789.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f5d8138129b691dd2d8d3963a7a7789.png)'
- en: Creating a Vector Store (Created by Author)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 创建向量存储（由作者创建）
- en: For that, the data has to be converted into chunks. This is done by loading
    the PDF documents with the PyPDFLoader and splitting the text into chunks of 500
    characters.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，数据必须转换为文本块。这通过使用PyPDFLoader加载PDF文档，并将文本分割成500个字符的块来完成。
- en: Next, the chunks are converted into embeddings with the use of a sentence transformer
    from HuggingFace. It’s important to specify the device as “cpu” in the parameters.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用来自HuggingFace的句子变换器将文本块转换为嵌入。参数中指定设备为“cpu”是很重要的。
- en: With the text chunks created and the embedding model loaded, we can create the
    vector store. For this case study, we use the Facebook AI Similarity Search (FAISS).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建了文本块并加载了嵌入模型后，我们可以创建向量存储。对于这个案例研究，我们使用Facebook AI相似性搜索（FAISS）。
- en: This vector store will be saved locally for future use.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个向量存储将被保存在本地，以备将来使用。
- en: Step 2—**Creating the QA Chain**
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步—**创建QA链**
- en: Next, we need to load the retrieval QA chain, which retrieves the relevant documents
    from the vector store and uses them to answer the users’ queries.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要加载检索QA链，它从向量存储中检索相关文档，并使用它们来回答用户的查询。
- en: '![](../Images/fb286d6019a13a7ece66c82aaf70f62b.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb286d6019a13a7ece66c82aaf70f62b.png)'
- en: QA Chain (Created by Author)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: QA链（由作者创建）
- en: 'The QA chain requires three components: the quantized Llama 2 model, the FAISS
    vector store, and a prompt template.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: QA链需要三个组件：量化的Llama 2模型、FAISS向量存储和一个提示模板。
- en: First, we download the quantized Llama2 model, which is available in the [HuggingFace
    repository](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main). For
    this case study, the model is downloaded through a file named “[llama-2-7b-chat.ggmlv3.q2_K.bin](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/blob/main/llama-2-7b-chat.ggmlv3.q2_K.bin)”,
    which uses 2.87 GB in memory.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们下载量化的Llama2模型，该模型可在[HuggingFace仓库](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main)中找到。对于这个案例研究，模型通过名为“[llama-2-7b-chat.ggmlv3.q2_K.bin](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/blob/main/llama-2-7b-chat.ggmlv3.q2_K.bin)”的文件进行下载，占用内存2.87
    GB。
- en: The model is then loaded using CTransformers, the Python library for binding
    transformer models implemented in C. Since we want an objective chatbot that generates
    responses with less creativity, so we set `temperature` to 0.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用CTransformers加载模型，这是一个用于绑定在C中实现的变换器模型的Python库。由于我们想要一个生成响应的目标型聊天机器人，因此将`temperature`设置为0。
- en: Next, we load the vector store previously created.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载先前创建的向量存储。
- en: After that, we define the prompt template. This step is optional, but since
    we are looking to interact with research papers, we need to prioritize accuracy,
    which we can enforce through the instructions in the prompt. Hallucinations are
    highly undesired, so the main instruction is to respond with “I don’t know” to
    questions that can not be answered with the provided PDF documents.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们定义提示模板。此步骤是可选的，但由于我们希望与研究论文进行互动，我们需要优先考虑准确性，这可以通过提示中的指令来实现。幻想回答是非常不受欢迎的，因此主要指令是对无法通过提供的PDF文档回答的问题回应“我不知道”。
- en: With these elements, we can create the QA chain, which will generate responses
    to users’ queries using the loaded quantized Llama2 model, the vector store, and
    the prompt template.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些元素，我们可以创建QA链，该链将使用加载的量化Llama2模型、向量存储和提示模板生成对用户查询的响应。
- en: Finally, we create the function that executes the response generation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建执行响应生成的函数。
- en: Step 3 — Creating the User Interface
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步——创建用户界面
- en: The core elements needed for the LangChain application have been built, so we
    can pivot to building a user interface for the chatbot.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain应用所需的核心元素已经构建完成，因此我们可以转向为聊天机器人构建用户界面。
- en: The Streamlit library is suited for this task as it contains features tailored
    for chatbot applications.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit库适合这个任务，因为它包含了针对聊天机器人应用的特性。
- en: The following code incorporates the previously built functions into the user
    interface (to review the entire source code, please visit the GitHub [repository](https://github.com/anair123/Llama2-Powered-QA-Chatbot-For-Research-Papers)).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将先前构建的函数整合到用户界面中（要查看完整的源代码，请访问GitHub [仓库](https://github.com/anair123/Llama2-Powered-QA-Chatbot-For-Research-Papers)）。
- en: 'The Streamlit app is run with the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit应用使用如下：
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And voila! We have our personal closed-sourced chatbot up and running!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了！我们的个人闭源聊天机器人已成功运行！
- en: '![](../Images/5eb1eda91c8dff86597b8a988f2c9a8a.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5eb1eda91c8dff86597b8a988f2c9a8a.png)'
- en: Chatbot User Interface (Created by Author)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人用户界面（由作者创建）
- en: Evaluating the chatbot
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估聊天机器人
- en: 'We have our chatbot, so let’s evaluate its performance with 3 different questions:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有了聊天机器人，让我们用3个不同的问题来评估其表现：
- en: '**What is the benefit of computer vision in sports analysis?**'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算机视觉在运动分析中的好处是什么？**'
- en: '![](../Images/c796ce889e5faa6928d3ed29082b0146.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c796ce889e5faa6928d3ed29082b0146.png)'
- en: Chatbot Response (Created by Author)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人响应（由作者创建）
- en: '**2\. Give me a list of sports that incorporate computer vision.**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 给我一个包含计算机视觉的运动项目列表。**'
- en: '![](../Images/085b38ed3cfe22a1f9edce81dfdad268.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/085b38ed3cfe22a1f9edce81dfdad268.png)'
- en: Chatbot Response (Created by Author)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人响应（由作者创建）
- en: '**3\. What algorithms are used to track players?**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 用什么算法来追踪运动员？**'
- en: '![](../Images/a33fd4016343cfd0a9ac8a7b81cf95e2.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a33fd4016343cfd0a9ac8a7b81cf95e2.png)'
- en: Chatbot Response (Created by Author)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人响应（由作者创建）
- en: The Results
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: Overall, the bot seems to return satisfactory responses without including unsolicited
    information.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，机器人似乎能够返回令人满意的响应，而不包含未经请求的信息。
- en: 'However, one limitation is evident from the response to the question: “What
    algorithms are used to track players?”, where the answer cuts off mid-sentence.
    This can be attributed to the limited context window (i.e. number of tokens) of
    the quantized version of the Llama2 model. The chatbot is unable to properly answer
    questions that require many tokens.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从对“用什么算法来追踪运动员？”这个问题的回答中，可以明显看出一个限制，即答案在句子中途被截断。这可以归因于量化版Llama2模型的有限上下文窗口（即令牌数量）。聊天机器人无法正确回答需要大量令牌的问题。
- en: Moreover, a limitation that isn’t conveyed in the responses itself is time.
    While the bot responded appropriately to questions, it took over a minute on average
    to generate responses on this CPU. With such a long run time, there isn’t a strong
    argument for using this tool as an alternative to manually searching for content
    in a collection of documents.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一个在响应中未传达的限制是时间。虽然机器人对问题的回答适当，但在这台CPU上生成响应平均需要超过一分钟。由于运行时间如此长，使用此工具作为替代手动搜索文档集合中的内容的理由并不充分。
- en: Finally, this entire exercise exhausted a lot of memory from my computer, which
    rendered other applications unusable.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这整个过程消耗了我计算机大量内存，使其他应用程序无法使用。
- en: The Final Verdict
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终裁决
- en: '![](../Images/34038f008137bb643850a7239b2b6497.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34038f008137bb643850a7239b2b6497.png)'
- en: Image by [Arek Socha](https://pixabay.com/users/qimono-1962238/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2492011)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2492011)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Arek Socha](https://pixabay.com/users/qimono-1962238/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2492011)提供，来自[Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2492011)
- en: 'Now that the case study has concluded, let’s revisit the initial question:
    Can we build LLM-powered applications on a CPU?'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 既然案例研究已经结束，让我们重新审视最初的问题：我们能否在CPU上构建LLM驱动的应用程序？
- en: 'The answer is: Yes… but we probably shouldn’t.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是：是的……但我们可能不应该。
- en: The positives from this case study are that the quantized Llama2 model is easy
    to download and incorporate into the application and that the chatbot is able
    to generate responses of high quality.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例研究的积极之处在于量化后的Llama2模型容易下载并融入应用中，并且聊天机器人能够生成高质量的回应。
- en: However, the combination of limited tokens, long run time, and high memory usage
    makes the prospect of training closed-sourced chatbots on CPUs unfeasible.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有限的令牌、较长的运行时间和高内存使用的组合使得在CPU上训练闭源聊天机器人的前景变得不可行。
- en: Of course, this conclusion is predicated on the constraints of the device used
    to conduct the case study, so a computer with greater processing power and storage
    may yield more promising results. In addition, in time, smaller LLMs with larger
    context windows will be made available to the public, making closed-sourced chatbots
    easier to build and utilize on CPUs.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这一结论是基于进行案例研究所用设备的限制，因此，具有更高处理能力和存储空间的计算机可能会产生更有希望的结果。此外，未来会有更小的LLM与更大的上下文窗口公开，使得闭源聊天机器人在CPU上构建和使用变得更加容易。
- en: 'If you’re interested in finding out how this application would perform on your
    device, feel free to check out the code in the following repository:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣了解这个应用在你的设备上表现如何，随时可以查看以下代码库中的代码：
- en: '[anair123/Llama2-Powered-QA-Chatbot-For-Research-Papers (github.com)](https://github.com/anair123/Llama2-Powered-QA-Chatbot-For-Research-Papers)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[anair123/Llama2-Powered-QA-Chatbot-For-Research-Papers (github.com)](https://github.com/anair123/Llama2-Powered-QA-Chatbot-For-Research-Papers)'
- en: Thank you for reading!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: References
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Naika, B. T., Hashmi, M. F., & Bokde, N. D. (n.d.). *A Comprehensive Review
    of Computer Vision in Sports: Open Issues, Future Trends and Research Directions*.
    Arxiv. [https://arxiv.org/pdf/2203.02281](https://arxiv.org/pdf/2203.02281)'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Naika, B. T., Hashmi, M. F., & Bokde, N. D. (n.d.). *《计算机视觉在体育中的综合评述：开放问题、未来趋势和研究方向》*。Arxiv.
    [https://arxiv.org/pdf/2203.02281](https://arxiv.org/pdf/2203.02281)
- en: 'Zhao, Z., Chai, W., Hao, S., Hu, W., Wang, G., Cao, S., Song, M., Hwang, J.-N.,
    & Wang, G. (n.d.). *A Survey of Deep Learning in Sports Applications: Perception,
    Comprehension, and Decision*. Arxiv. [https://arxiv.org/pdf/2307.03353.pdf](https://arxiv.org/pdf/2307.03353.pdf)'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zhao, Z., Chai, W., Hao, S., Hu, W., Wang, G., Cao, S., Song, M., Hwang, J.-N.,
    & Wang, G. (n.d.). *《深度学习在体育应用中的调查：感知、理解与决策》*。Arxiv. [https://arxiv.org/pdf/2307.03353.pdf](https://arxiv.org/pdf/2307.03353.pdf)
