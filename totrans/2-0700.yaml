- en: Defining Artificial General Intelligence
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义通用人工智能
- en: 原文：[https://towardsdatascience.com/defining-artificial-general-intelligence-a4b167aa84ba](https://towardsdatascience.com/defining-artificial-general-intelligence-a4b167aa84ba)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/defining-artificial-general-intelligence-a4b167aa84ba](https://towardsdatascience.com/defining-artificial-general-intelligence-a4b167aa84ba)
- en: How do you know when a system has reached AGI?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你如何判断一个系统是否达到了AGI（通用人工智能）？
- en: '[](https://medium.com/@raicik.zach?source=post_page-----a4b167aa84ba--------------------------------)[![Zachary
    Raicik](../Images/860760b53fcc75013007067190e8ca65.png)](https://medium.com/@raicik.zach?source=post_page-----a4b167aa84ba--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a4b167aa84ba--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a4b167aa84ba--------------------------------)
    [Zachary Raicik](https://medium.com/@raicik.zach?source=post_page-----a4b167aa84ba--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@raicik.zach?source=post_page-----a4b167aa84ba--------------------------------)[![Zachary
    Raicik](../Images/860760b53fcc75013007067190e8ca65.png)](https://medium.com/@raicik.zach?source=post_page-----a4b167aa84ba--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a4b167aa84ba--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a4b167aa84ba--------------------------------)
    [Zachary Raicik](https://medium.com/@raicik.zach?source=post_page-----a4b167aa84ba--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a4b167aa84ba--------------------------------)
    ·7 min read·Nov 23, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a4b167aa84ba--------------------------------)
    ·阅读时间7分钟·2023年11月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/0cb8bbd3f1b2149af9b043d909d88722.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cb8bbd3f1b2149af9b043d909d88722.png)'
- en: Photo by [Possessed Photography](https://unsplash.com/@possessedphotography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Possessed Photography](https://unsplash.com/@possessedphotography?utm_source=medium&utm_medium=referral)
    提供，[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Last week Sam Altman was fired as CEO of OpenAI. The true reason for his departure
    remains unknown. According to the board, he was fired because they “concluded
    that he was not consistently candid in his communications with the board, hindering
    its ability to exercise its responsibilities.” This vague explanation led to tons
    of speculation about why Altman was fired. Some of the best theories include:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 上周，萨姆·奥特曼被解除OpenAI的首席执行官职务。他离开的真正原因仍然未知。根据董事会的说法，他被解雇是因为董事会“得出结论认为他在与董事会的沟通中并不始终坦诚，这妨碍了董事会履行其职责。”这一模糊的解释引发了大量关于奥特曼被解雇原因的猜测。一些最有说服力的理论包括：
- en: Altman prioritized market penetration over security & privacy testing
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奥特曼将市场渗透优先于安全与隐私测试
- en: Altman circumvented the board in a major deal
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奥特曼在一项重大交易中绕过了董事会
- en: Altman’s ego became too big and started to conflict with the company’s mission
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奥特曼的自我膨胀过大，开始与公司的使命发生冲突
- en: Interestingly, one of the most compelling rumors points towards a divergence
    in views on AI ethics, particularly around the development of Artificial General
    Intelligence (“AGI”). While Altman has been a vocal proponent of AGI’s potential,
    rumors suggest that chief scientist Ilya Sutskever harbored growing concerns over
    the rapid advancement of OpenAI’s internal technologies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，一些最有说服力的传言指向了对AI伦理的观点分歧，特别是在通用人工智能（“AGI”）的发展方面。虽然奥特曼一直是AGI潜力的 vocal 支持者，但传言称首席科学家伊利亚·苏茨克弗对OpenAI内部技术的快速进展产生了日益增长的担忧。
- en: 'In this post, we will summarize some concepts from Google DeepMind’s new paper
    [Levels of AGI: Operationalizing Progress on the Path to AGI](https://arxiv.org/pdf/2311.02462.pdf).
    This paper helps to define AGI, sets up a framework for evaluating AGI systems,
    and summarizes some of the potential risks of AGI.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '在这篇文章中，我们将总结谷歌DeepMind的新论文 [Levels of AGI: Operationalizing Progress on the
    Path to AGI](https://arxiv.org/pdf/2311.02462.pdf) 中的一些概念。这篇论文有助于定义AGI，建立评估AGI系统的框架，并总结一些AGI可能带来的风险。'
- en: Defining AGI
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义AGI（通用人工智能）
- en: In the artificial intelligence (“AI”) field, AGI is a subset of systems that
    can perform most human level tasks. Hypothetically, these systems are capable
    of understanding, learning, and applying their intelligence broadly like a human
    can. A complete AGI system would not be limited to the data it was trained on.
    Instead, as the system exists it can gather information and learn as time passes.
    For many AI companies, AGI is either explicitly or implicitly the long term goal.
    Currently, AGI hasn’t been achieved. However, given the rapid advancements in
    LLMs and artificial intelligence more broadly, AGI feels closer than ever.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能（“AI”）领域，AGI是能够执行大多数人类水平任务的系统的一个子集。假设这些系统能够像人类一样广泛理解、学习和应用其智能。一个完整的AGI系统不应局限于其所训练的数据。相反，系统在存在的过程中可以收集信息并随时间学习。对于许多AI公司来说，AGI是明确或隐含的长期目标。目前，AGI尚未实现。然而，鉴于LLM和人工智能领域的快速进展，AGI感觉比以往任何时候都更接近。
- en: In the paper, researchers at DeepMind outline defining characteristics of AGI.
    “<DeepMind Researchers> argue that any definition of AGI should meet the following
    six criteria:”
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文中，DeepMind的研究人员概述了AGI的定义特征。 “<DeepMind研究人员>认为，AGI的任何定义应满足以下六个标准：”
- en: '**“Focus on Capabilities, not Process”:** It doesn’t matter how the AGI system
    does the thing, it matters what thing(s) the system can do. AGI systems are not
    required to think or understand in a humanlike way, or develop humanlike consciousness.
    This not to say these systems will not demonstrate these things — but they are
    not required to meet the definition of AGI.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**“专注于能力，而非过程”**：AGI系统的关键不在于其如何完成任务，而在于系统能够做什么任务。AGI系统不要求以类似人类的方式思考或理解，也不需要具有人类意识。这并不是说这些系统不会表现出这些特性——但它们不必符合AGI的定义。'
- en: '**“Focus on Generality and Performance”:** Some systems choose to emphasize
    generality — or the ability to handle a wide range of tasks and adapt to various
    environments. However, generality should not come at the cost of competence. These
    systems need to be able to perform a wide range of tasks at a high level of performance.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**“专注于通用性和性能”**：一些系统选择强调通用性——即处理各种任务和适应不同环境的能力。然而，通用性不应以能力为代价。这些系统需要能够以高水平的性能执行广泛的任务。'
- en: '**“Focus on Cognitive and MetaCognitive Tasks”:** The researchers argue that
    systems do not need to be able to perform physical tasks to be considered AGI.
    Instead, these systems should focus on the ability to complete cognitive and metacognitive
    tasks. In this context, cognitive tasks are things like perception, memory, language
    and problem solving. Metacognitive tasks include the ability to learn new tasks
    or gather more information when required.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**“专注于认知和元认知任务”**：研究人员认为，系统是否能够执行物理任务并不是判断其是否为AGI的标准。相反，这些系统应专注于完成认知和元认知任务。在这种情况下，认知任务包括感知、记忆、语言和问题解决。元认知任务包括在需要时学习新任务或获取更多信息的能力。'
- en: '**“Focus on Potential, not Deployment”:** Any system developed that meets the
    criteria of AGI does not have to be deployed into the real world to be considered
    AGI. Instead, the system needs to demonstrate that it is capable of meeting the
    criteria of AGI. According to the authors, “Requiring deployment as a condition
    of measuring AGI introduces non-technical hurdles such as legal and social considerations,
    as well as potential ethical and safety concerns.”'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**“专注于潜力，而非部署”**：任何符合AGI标准的系统并不需要在现实世界中部署才能被认为是AGI。相反，系统需要证明其能够满足AGI的标准。根据作者的说法，“要求部署作为衡量AGI的条件会引入非技术性障碍，例如法律和社会考虑，以及潜在的伦理和安全问题。”'
- en: '**“Focus on Ecological Validity”:** Any system that is developed in an effort
    to meet the definition of AGI should focus on tasks that people will value in
    the real world. In other words, AGI should not focus on highly specialized or
    abstract tasks like solving extremely complex theoretical problems. Something
    like this would not be valuable to most people in every day life.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**“专注于生态有效性”**：任何致力于实现AGI定义的系统应关注人们在现实世界中重视的任务。换句话说，AGI不应专注于高度专业化或抽象的任务，比如解决极其复杂的理论问题。这类任务对大多数人日常生活中并不有价值。'
- en: '**“Focus on the path to AGI, not a single endpoint”:** Outlining varying levels
    of AGI and attaching clear metrics, benchmarks, and risks enable easier discussions
    of policy and progress. Different levels can make it easier to compare systems
    against each other and quantify progress.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**“关注通向AGI的路径，而不是单一的终点”**：概述不同等级的AGI并附上明确的指标、基准和风险，使政策和进展的讨论变得更加容易。不同的等级可以使系统之间的比较更为简单，并量化进展。'
- en: These 6 criteria for AGI ensure that researchers and other interested parties
    are talking about AGI in the same way. The criteria seek to eliminate confusion
    related to different terms, capabilities, or outcomes and focus discussion on
    the things that matter. I’m not saying these are the right 6 criteria, but they
    do make it easier to think through systems as they relate to AGI.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这六个AGI标准确保研究人员和其他相关方对AGI有一致的理解。这些标准旨在消除与不同术语、能力或结果相关的混淆，并将讨论集中在重要的方面上。我并不是说这六个标准是正确的，但它们确实使得在考虑与AGI相关的系统时更容易思考。
- en: Levels of AGI
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AGI的等级
- en: 'In the section above, the sixth criteria mentioned a system to outline varying
    levels of AGI. The table below summarizes the various levels of AGI, as defined
    by DeepMind. Note that for each level, the table exanines both narrow and general
    AI tasks where:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的部分中，第六个标准提到一个系统来概述不同等级的AGI。下表总结了DeepMind定义的各种AGI等级。请注意，对于每个等级，表格审视了狭义和广义AI任务，其中：
- en: Narrow tasks are clearly scoped or defined
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 狭义任务是明确界定或定义的。
- en: General tasks are a wide variety of tasks including the ability to learn new
    skills
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一般任务是包括学习新技能的各种任务。
- en: '![](../Images/d9a803ad735876b3bead25a3940a6a1c.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9a803ad735876b3bead25a3940a6a1c.png)'
- en: Levels of AGI, Google DeepMind [https://arxiv.org/pdf/2311.02462.pdf](https://arxiv.org/pdf/2311.02462.pdf)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: AGI的等级，Google DeepMind [https://arxiv.org/pdf/2311.02462.pdf](https://arxiv.org/pdf/2311.02462.pdf)
- en: When we’re talking about narrowly focused AI, we see numerous examples of products
    at specific levels (like the humble calculator at level 0). Building fully autonomous
    solutions is easier when the use case is tightly scoped and specific. However,
    these systems, due to their specialized nature, fall short of fulfilling DeepMind’s
    criteria for AGI. For example, AlphaFold is a system designed to predict 3D protein
    structures. While its specialized capabilities are impressive, its narrow focus
    means it lacks the ecological validity that is central to AGI.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论狭义的AI时，我们会看到许多特定等级的产品实例（例如，等级0的简单计算器）。当使用案例范围明确且具体时，构建完全自主的解决方案更为容易。然而，这些系统由于其专业化的性质，未能满足DeepMind对AGI的标准。例如，AlphaFold是一个旨在预测3D蛋白质结构的系统。尽管其专业化能力令人印象深刻，但其狭窄的关注点意味着它缺乏对AGI至关重要的生态有效性。
- en: When we talk about more generalized system like ChatGPT, we encounter a different
    set of challenges. Initially, ChatGPT’s ability to handle a wide variety of questions
    was impressive. Yet, the more I used the tool, the more I realized that while
    ChatGPT might seem superhuman on the surface, it often falls short in areas requiring
    deep expertise. We can connect this idea to the AGI levels outlined above — it
    only answers at the level of an unskilled human (level 1). Many of its responses
    seem factually true, but are actually plagued by inaccuracies. This realization
    highlights that today’s AI systems, despite their “first of their kind” capabilities,
    often lack the depth in performance. They prioritize a wide range of functions
    but don’t excel at all of them, conflicting with DeepMind’s second criterion for
    AGI.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论像ChatGPT这样更为通用的系统时，我们会遇到一系列不同的挑战。最初，ChatGPT处理各种问题的能力令人印象深刻。然而，随着使用工具的时间增加，我逐渐意识到，尽管ChatGPT在表面上看似超人，但在需要深入专业知识的领域，它常常有所欠缺。我们可以将这个观点与上面提到的AGI等级联系起来——它仅能在无技能人类（等级1）的水平上回答问题。它的许多回答看起来似乎是事实正确的，但实际上却充满了不准确性。这一认识突显了今天的AI系统，尽管具备“首创”的能力，但在性能的深度上往往有所欠缺。它们优先考虑广泛的功能，但并不擅长所有这些功能，这与DeepMind对AGI的第二个标准相冲突。
- en: Risks of AGI
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AGI的风险
- en: In the 2004 movie *I, Robot*, robots exist to serve their human owners. These
    robots are not allowed to injure humans, they must obey their humans at all times,
    and they must protect their owners at all costs. As the movie progresses, the
    robots start to disobey these rules. They develop a sense of free will and emotions.
    As a result, the robots become an existential threat to humanity.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在2004年电影*机器人总动员*中，机器人存在是为了服务于人类主人。这些机器人不被允许伤害人类，必须随时服从人类，并且必须不惜一切代价保护主人。随着电影情节的发展，这些机器人开始不再遵守这些规则。它们发展出了自由意志和情感。结果，这些机器人成为了对人类的存在性威胁。
- en: Although this doomsday scenario could become a risk in the AGI world, there
    are more practical risks as well. The table below summarizes various risks associated
    with narrow and general AI associated with varying levels of AI autonomy.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种世界末日场景可能在 AGI 世界中成为风险，但还有更多实际的风险。下表总结了与窄域和通用 AI 相关的各种风险，涉及不同级别的 AI 自主性。
- en: '![](../Images/37564f823f94adbc7d6a30693f260b64.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37564f823f94adbc7d6a30693f260b64.png)'
- en: Risks of AGI, Google DeepMind [https://arxiv.org/pdf/2311.02462.pdf](https://arxiv.org/pdf/2311.02462.pdf)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: AGI 的风险，Google DeepMind [https://arxiv.org/pdf/2311.02462.pdf](https://arxiv.org/pdf/2311.02462.pdf)
- en: Admittedly, when I first started using advanced AI tools and researching AGI
    as a concept, I had blinders on to the potential risks of the tools. I subconsciously
    refused to acknowledge that the development and advancement of these tools could
    come with any negative side effects. I mean, who doesn’t love having 24/7 access
    to 30 second code reviews?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 诚然，当我首次开始使用高级 AI 工具并研究 AGI 这一概念时，我对工具的潜在风险视而不见。我下意识地拒绝承认这些工具的发展和进步可能会带来任何负面副作用。我是说，谁不喜欢全天候访问
    30 秒代码审查的服务呢？
- en: However, when I stumbled across this table it changed my perspective. It opened
    my eyes to some of the associated risks of these systems, including the tools
    we use today. Using AI as a consultant (“Autonomy Level 2) is similar to how many
    use ChatGPT today or rely on recommender systems for product or movie recommendations.
    Using the tools in this way can lead to chronic overtrust or targeted manipulation.
    In fact, recently I couldn’t find anyone to review my code so I used ChatGPT review
    my code. The ChatGPT review came back clean, so I pushed the code to production.
    As it turns out, the code was riddled with bugs and had to be rolled back almost
    instantly. I put too much trust in ChatGPT and paid the price!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我偶然看到这张表格时，它改变了我的观点。它让我看到了这些系统的相关风险，包括我们今天使用的工具。将 AI 作为顾问（“自主级别 2”）类似于许多人今天使用
    ChatGPT 或依赖推荐系统来获取产品或电影推荐的方式。以这种方式使用工具可能导致长期的过度信任或有针对性的操控。事实上，最近我找不到人来审查我的代码，于是我让
    ChatGPT 审查了我的代码。ChatGPT 的审查结果显示代码无误，于是我将代码推向了生产环境。结果，代码中充满了 bug，几乎立即被回滚。我对 ChatGPT
    过度信任，付出了代价！
- en: As we continue to advance both narrow and general AI systems, the risk grows
    substantially. The current systems can lead to over-trust and targeted manipulation
    whereas more powerful systems can lead to large job loss and a concentration of
    power. The technology-oriented side of me is wildly impressed with how far we’ve
    come and just as excited to see where were going. However, the practical side
    of me recognizes the need to build advanced AI systems with careful thought about
    the risks and consequences.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续推动窄域和通用 AI 系统的发展，风险也显著增加。目前的系统可能导致过度信任和针对性操控，而更强大的系统则可能导致大量失业和权力集中。作为技术导向的一方，我对我们取得的进展感到非常惊讶，并对未来的发展充满了*激动*。然而，作为实践的一方，我认识到需要在构建先进
    AI 系统时仔细考虑风险和后果。
