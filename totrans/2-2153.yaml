- en: Turn Linear Regression into Logistic Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/turn-linear-regression-into-logistic-regression-e088e2408ec9](https://towardsdatascience.com/turn-linear-regression-into-logistic-regression-e088e2408ec9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Comprehensive Guideline on How to Implement Logistic Regression from Scratch
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)[![Md.
    Zubair](../Images/1b983a23226ce7561796fa5b28c00d65.png)](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)
    [Md. Zubair](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)
    ¬∑10 min read¬∑Mar 27, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/764eaf14aa790304658c9ca236dfedb0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Rutger Leistra](https://unsplash.com/ko/@rutgerleistra?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you read my previous articles on [*simple linear regression*](https://medium.com/towards-data-science/deep-understanding-of-simple-linear-regression-3776afe34473)
    and [*multiple linear regression*](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236),
    you will get to know that linear regression predicts continuous value. But not
    all of our real-life prediction problems are associated with continuous values.
    Sometimes we need to classify an object or data based on its features. Linear
    regression algorithms can‚Äôt solve these problems. In this scenario, logistic regression‚Äôs
    necessity comes in. The title of the algorithm, ‚Äò**Logistic Regression‚Äô** holds
    the word **‚ÄòRegression‚Äô.** It is the modified version of linear regression so
    that it can predict the discrete class value rather than continuous values.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '`So, this article will explain how logistic regression generates the prediction
    value of a class derived from linear regression.`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`[**What does Make Linear Regression a Logistic Regression?**](#b874)`'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`[**Which Function Plays a Key Role?**](#a923)`'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`[**How Does Linear Regression Fall into Logistic Regression?**](#8b86)`'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`[**Generate a Loss Function**](#7623)`'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`[**Why can‚Äôt We use MSE as a cost function?**](#7222)`'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`[**Gradient Descent for Parameter Optimization**](#daa3)`'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`[**Putting All the Concept Together for Python Implementation from Scratch**](#1a72)`'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What Does Make Linear Regression a Logistic Regression?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I will bring two equations mentioned in my previous articles on [*simple*](https://medium.com/towards-data-science/deep-understanding-of-simple-linear-regression-3776afe34473)
    and [*multiple linear regression*](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The first one is the equation for simple linear regression.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/920f82c0f7922826fbf6113a6fcd5063.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: We will get the predicted regression value `(y)` only by plugging the value
    of the independent variable `(x)`. But we need to fit the value of the coefficients
    slope`(m)` and the y-intercept value `c`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: The second equation is similar to the first one, but there is more than one
    independent variable `*(x1‚Ä¶‚Ä¶..xn)*`*, coefficients m* `*(m1‚Ä¶‚Ä¶.m0)*`, and y-intercept
    `m0`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/282ecd71530478bad24425e4ceefaa2e.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Both for the ***1st and 2nd*** equations, if we have the best-fit values of
    the coefficients, we can easily get the regression value like 34, 687.93 etc.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: But it doesn‚Äôt give us any sense of transforming the continuous value into a
    distinct classification value. So, we need a function or way by which we can convert
    all the regression values into a range of values between `**[0,1]**`. In logistic
    regression, we exactly do the same. I am going to discuss the function in the
    next section.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Which Function Plays a Key Role?
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of directly mentioning the function, I will explain it gradually. *Let‚Äôs
    try to have some visual impacts of linear regression and logistic regression.*
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83a42f810ece4934a0e2ed0b27530a3d.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Regression Model Graph (Image By Author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Look at the above regression model graph. The diagonal blue line is the regression
    line. We can predict any value of `***y***`only by plugging the`***x***`value.
    Try to formulate a logistic regression problem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8828848f104c2f56fe8d8a28eb85890c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: Image By Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: The above dataset has one feature, **‚ÄòAge‚Äô,** based on the feature the target
    class is defined. The value **1** indicates the person is a student, and **0**
    represents the person is not a student. And it is impossible to predict such categorical
    values with linear regression. ***How does it look like if we plot it? Let‚Äôs see.***
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2f120d89c87e3d29036fb8d601003d0.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Image By Author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: The stars represent the level of the class (Student or not). Simply, a regression
    line won‚Äôt be an appropriate way to predict the classification values.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Here, the **‚ÄòS-shaped** function named ‚Äò‚Äò**sigmoid** ‚Äô‚Äô comes to play the role.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b777a2e970131850f52585d18304177b.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: This function can convert any number between `*[0,1]*`. I will show you a coding
    example of the sigmoid function.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '***Creating a function for sigmoid function***'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '***Plotting the sigmoid graph***'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: This **S-shaped** sigmoid graph would be the best fit for the classification
    problem rather than a straight line. With the increasing value of **x,** the **y**
    value goes from ***0 to 1*** and for ***x=0, y=0.5***. It‚Äôs a good function to
    be used. We can easily set a threshold value like 0.5\. All values greater than
    the threshold (0.5) will be 1; otherwise, 0.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '*Yes! finally, we have found the appropriate function.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: How Does Linear Regression Fall into Logistic Regression?
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we have all the staff to translate a linear regression into a logistic
    regression. Let‚Äôs put it all together.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: In the [**first section**](#b874), I have shown the linear regression equations
    for simple and multiple linear regression. The value of the linear regression
    is continuous. It can be any continuous numerical value.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: But the sigmoid function helps us produce a categorical value like ***0* and
    *1***, as shown in the [**last section**](#a923).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: So, the equation for the logistics regression will be as follows.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5df00f2eb8c759ad124fac20919765cc.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: The symbol **œÉ** represents the sigmoid function. If we pass the output of the
    equation into the sigmoid function, we will get results ranging from ***0 to 1.***
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can calculate the linear equation‚Äôs value by manually multiplying and
    adding the values.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b0152745c586c8f2e5aef39d2285af9.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: But the manual process is time-consuming. Vectorized implementation is much
    faster and easy. Let‚Äôs formulate the linear equation to make it compatible with
    vectorized implementation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/98a2acce6d48d63851f8a1cc4ae2041e.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: We have added an extra constant variable `***xi0=1***`***.***
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3ef0d02a2078307aedd85548cff7852a.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: Matrix Implementation for Calculating the Linear Equation (Image By Author)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: The **X** holds all the values of the independent variables, and the transpose
    of **M** represents the transpose matrix of all the coefficients.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '**Vectorized Logistic Regression Equation**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Vectorized implementation of the logistic regression will be something like
    this.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/98867d6ce9809b40eebe991c7324044f.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: It will transform the linear equation values between 0 to 1\. A function with
    python is given below.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Testing the function with a demo value.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Yeah! We have successfully created the function.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Generate a Loss Function
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we look back to our previous [**multiple linear regression**](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236)
    article, we will find the **Mean Square Error (MSE)** as a cost function.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac1432e6410acf46306052db39d43187.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
- en: But we know logistics regression is not a regression algorithm. Rather, it is
    a binary classification (two classes) algorithm. In logistic regression, there
    are two classes, **1** and **0**. So, **MSE** is not an appropriate cost function
    to be used in case of logistic regression. `*(But why? I will explain the exact
    reason a bit later)*`
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Now, I will introduce a new cost function for this classification algorithm.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88464bbf8811c6148e81e80b913ba542.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: The above cost function is suitable for logistic regression.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs try to have some intuition about the cost function. For `**yi = 1**`,
    the cost function is ‚Äî
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eb64152ec90b186342590592b4c2a425.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: How does the function look like? Let‚Äôs plot the function.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: The above plot is the graphical representation of the loss function when `yi=1`.
    The graph says the more the prediction value closer to **1**, the less the error.
    And when the prediction value is 0.0, the error is infinity.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '*Let‚Äôs plot the cost function for* `***y0=1***`*.*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: For `yi=0`, when the prediction value is close to `**1**`**,** the error is
    infinity and reduces the errors by decreasing the value. Now, we will plot the
    two graphs combined.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Now, the graphical representation is more intuitive. If we combine the loss
    functions for `**yi=0 and yi=1**`, we will get an appropriate function to apply
    gradient descent which has global minima.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b9bf8f7e5cb2ebf8fec25254e1f469b.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
- en: If we plugin the target value`***yi=1*** *or* ***yi=0***`in the above equation,
    one part will be cancelled and turn out to be the same equation I mentioned. This
    is what we need.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '***Convert the cost function into code.***'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '**Why can‚Äôt We Use MSE as a cost function?**'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In logistic regression, the target or output value is discrete or categorical.
    It is not a continuous value like regression problems. If we plug in the value
    in the **MSE** cost function *(the cost function which we have used for linear
    and multiple linear regression),* we will get the following graph rather than
    a convex curve.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b0d02be4a76ad791e5986ce4fd52591.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: Cost Function with Many Local Minima (Image by Author)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: As this type of curve contains many local minima, we will be in trouble to apply
    gradient descent in the cost function. That‚Äôs why we won‚Äôt use MSE as a cost function
    in logistic regression.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Descent for Parameter Optimization
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gradient descent is a way of minimizing the loss/cost function by optimizing
    the coefficients of a machine learning algorithm how the cost function looks like.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/28ca4da8d625104cf9c1ab593f94ec5e.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
- en: Gradient Descent (Image By Author)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: The cost function is a **convex** curve, as shown in the **Loss Function** section.
    Now, we have to calculate the derivative of the cost function. Derivative indicates
    how the cost is changed in which direction.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we will randomly initialize the weights of the coefficients and update
    the weights gradually. The main target is finding the minimum cost shown in the
    above image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b9bf8f7e5cb2ebf8fec25254e1f469b.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
- en: '*The derivative of the cost function will be ‚Äî*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/34e0a5589e0fbd3ae80df4f2517a1ee0.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
- en: '*[N.B. If I show the details calculation of the derivative, the article will
    be unnecessarily long. Read out the* [***article***](https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d)
    *for a details explanation.]*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '*Vectorized implementation will be as follows.*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9aef7d6eaa9ef8b78d26ff839b06d03a.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: '`***X***` is the matrix form of all the features value, `**M**` represents
    the vectorized form of the coefficients, and `**Y**` stands for the vectorized
    representation of the target value.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '*Code for vectorized gradient descent implementation.*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '*We are one step ahead of our final implementation. We have all the functions
    ready to implement the logistic regression. In the next step, we will combine
    all tools and implement the complete algorithms.*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Putting All the Concepts Together for Python Implementation from Scratch
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let‚Äôs load the dataset of titanic (first thing first). The [**dataset is publicly**
    **available**](https://www.kaggle.com/datasets/brendan45774/test-file) and licenced
    under the public domain.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '**Importing the necessary libraries**'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`*[Our main target is to show the basic mechanism of the algorithm. So, we
    have kept the pre-processing simple and easy. Rather than concentrate on the data
    analysis, we will keep our eyes on the core implementation.]*`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '*For our convenience, we have selected some features ‚Äî*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '**Let‚Äôs have some insights into the selected features.**'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The features ‚Äò`Age‚Äô` and `‚ÄòFare‚Äô` have some missing values. We will fill the
    values with the average value. And map the `‚ÄòSex‚Äô` **male** with **1** *and* **female**
    with **0**.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Now, all the features are numerical, and no missing value exists.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '**Let‚Äôs extract the independent variables (x) and dependent variable (y)**'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Normalizing the data so that it will increase the performance of gradient
    descent**'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Splitting the train and test set**'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kept 25% data for testing and rest of the data for training. Now, we will feed
    the data to our scratch model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '**Putting all the functions together for performing logistic regression**'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fit the model with training data**'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**See how the coefficients of the model are optimized**'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Create a prediction function**'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, I have used a threshold value of *0.5* to classify the data. All the results
    below *0.5* are considered as class *0*, and above or equal to *0.5* is *1*.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '**Let‚Äôs compare our model with the benchmark scikit-learn library**'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Creating a logistic regression model with scikit-learn*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '*Prediction on the test data*'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '**Results of scikit-learn model vs our scratch model**'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**üëâResult of our scratch model**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '*Confusion matrix*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '*Precision, recall and f1-score*'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '**üëâ Result of scikit-learn model**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '*Confusion matrix*'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '*Precision, recall and f1-score*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: It turns out that both our scratch model and scikit-learn model possess the
    same results. So, we claim that our scratch model is identical to the scikit-learn
    model.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nowadays, machine learning models are very easy to implement for some built-in
    libraries. So, learning the core mechanisms may be unnecessary for you. As a researcher
    and academician, I always consider it from a different point of view. If you know
    the core concepts of the algorithms, it will be very helpful for you to work at
    the core level, like research, development and optimization of the algorithm,
    etc. You can implement the concept in those programming languages where machine
    learning libraries don‚Äôt exist.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '`[***Full Notebook and dataset is available in the repository***](https://github.com/Zubair063/ML_articles/tree/main/Logistic%20Regression%20from%20Scratch)***.***`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Logistic Regression from scratch ‚Äî Philipp Muens](https://philippmuens.com/logistic-regression-from-scratch)'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Machine Learning Course By Andrew Ng
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`My previous **Algorithm from Scratch** series articles.`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[](/multiple-linear-regression-a-deep-dive-f104c8ede236?source=post_page-----e088e2408ec9--------------------------------)
    [## Multiple Linear Regression: A Deep Dive'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple Linear Regression from Scratch: Deep Understanding'
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/multiple-linear-regression-a-deep-dive-f104c8ede236?source=post_page-----e088e2408ec9--------------------------------)
    [](/deep-understanding-of-simple-linear-regression-3776afe34473?source=post_page-----e088e2408ec9--------------------------------)
    [## Deep Understanding of Simple Linear Regression
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear Regression from Scratch: Detailed Explanation'
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/deep-understanding-of-simple-linear-regression-3776afe34473?source=post_page-----e088e2408ec9--------------------------------)
    [](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----e088e2408ec9--------------------------------)
    [## KNN Algorithm from Scratch
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Implementation and Details Explanation of the KNN Algorithm
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----e088e2408ec9--------------------------------)
    [](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----e088e2408ec9--------------------------------)
    [## K-means Clustering from Scratch
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'K-means: The Best ML Algorithm to Cluster Data'
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----e088e2408ec9--------------------------------)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '`**Statistics and data visualization** for data science series.`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[](/ultimate-guide-to-statistics-for-data-science-a3d8f1fd69a7?source=post_page-----e088e2408ec9--------------------------------)
    [## Ultimate Guide to Statistics for Data Science'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'Statistics at a glance for data science: standard guidelines'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/ultimate-guide-to-statistics-for-data-science-a3d8f1fd69a7?source=post_page-----e088e2408ec9--------------------------------)
    [](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)
    [## Ultimate Guide to Data Visualization for Data Science
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[Êï∞ÊçÆÁßëÂ≠¶ÁªàÊûÅÁªüËÆ°ÊåáÂçó](https://towardsdatascience.com/ultimate-guide-to-statistics-for-data-science-a3d8f1fd69a7?source=post_page-----e088e2408ec9--------------------------------)
    [](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)
    [## Êï∞ÊçÆÁßëÂ≠¶Êï∞ÊçÆÂèØËßÜÂåñÁªàÊûÅÊåáÂçó'
- en: 'Data Visualization at a glance for data science: standard guidelines'
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Êï∞ÊçÆÁßëÂ≠¶‰∏≠ÁöÑÊï∞ÊçÆÂèØËßÜÂåñÊ¶ÇËø∞ÔºöÊ†áÂáÜÊåáÂçó
- en: medium.datadriveninvestor.com](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[Êï∞ÊçÆÈ©±Âä®ÊäïËµÑËÄÖ](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)'
