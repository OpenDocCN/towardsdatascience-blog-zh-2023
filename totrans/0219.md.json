["```py\nimport gymnasium as gym\nfrom PIL import Image\n\nenv = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\", is_slippery=False)\nenv.reset()\n\nImage.fromarray(env.render())\n```", "```py\nfrom itertools import product\nimport random\n\nfrom gymnasium.spaces.tuple import Tuple\n\ndef space_to_tuples(space):\n    if isinstance(space, Tuple):\n        for encoding in product(*[range(factor.n) for factor in space]):\n            yield encoding\n    else:\n        for encoding in range(space.n):\n            yield encoding\n\ndef get_best_action(q_table, state): # for a given state, find the best action from the Q table\n    return max(((action, value) for action, value in q_table[state].items()), key=lambda x: x[1])[0]\n```", "```py\nalpha = 0.1\ngamma = 0.9\nn_episodes = 100_000\nmax_steps = 100\nepsilon = 0.2\n\nq_table = {i: {j: 0 for j in space_to_tuples(env.action_space)} for i in space_to_tuples(env.observation_space)}\n```", "```py\n{0: {0: 0, 1: 0, 2: 0, 3: 0},\n 1: {0: 0, 1: 0, 2: 0, 3: 0},\n 2: {0: 0, 1: 0, 2: 0, 3: 0},\n 3: {0: 0, 1: 0, 2: 0, 3: 0},\n 4: {0: 0, 1: 0, 2: 0, 3: 0},\n 5: {0: 0, 1: 0, 2: 0, 3: 0},\n 6: {0: 0, 1: 0, 2: 0, 3: 0},\n 7: {0: 0, 1: 0, 2: 0, 3: 0},\n 8: {0: 0, 1: 0, 2: 0, 3: 0},\n 9: {0: 0, 1: 0, 2: 0, 3: 0},\n 10: {0: 0, 1: 0, 2: 0, 3: 0},\n 11: {0: 0, 1: 0, 2: 0, 3: 0},\n 12: {0: 0, 1: 0, 2: 0, 3: 0},\n 13: {0: 0, 1: 0, 2: 0, 3: 0},\n 14: {0: 0, 1: 0, 2: 0, 3: 0},\n 15: {0: 0, 1: 0, 2: 0, 3: 0}}\n```", "```py\nfor _ in range(n_episodes):\n    # new episode (game), so we need a reset\n    state, _ = env.reset()\n\n    # play the game for max_steps\n    for step in range(max_steps):\n        # pick an action\n        if random.random() < epsilon:\n            # sometimes it is random to encourage exploration, otherwise we cannot find good policies ...\n            action = env.action_space.sample()\n        else:\n            # ... and sometimes we use the best action according to our Q-table\n            action = get_best_action(q_table, state)\n\n        # we take that action and then get some data from the game\n        next_state, reward, terminated, _, _ = env.step(action)\n\n        # update the Q-table according to the magic formula\n        q_table[state][action] = (1-alpha)*q_table[state][action] + alpha*(reward + gamma*max(q_table[next_state].values()))\n\n        # check if the game is finished, can be if you win or lose\n        if terminated:\n            # a new episode starts after this\n            break\n        else:\n            # if the episode continues, update the current state (we took an action!)\n            state = next_state\n```", "```py\n{0: {0: 0.53, 1: 0.59, 2: 0.59, 3: 0.53},\n 1: {0: 0.53, 1: 0.0, 2: 0.66, 3: 0.55},\n 2: {0: 0.56, 1: 0.73, 2: 0.43, 3: 0.63},\n 3: {0: 0.6, 1: 0.0, 2: 0.17, 3: 0.0},\n 4: {0: 0.59, 1: 0.66, 2: 0.0, 3: 0.53},\n 5: {0: 0, 1: 0, 2: 0, 3: 0},\n 6: {0: 0.0, 1: 0.81, 2: 0.0, 3: 0.64},\n 7: {0: 0, 1: 0, 2: 0, 3: 0},\n 8: {0: 0.66, 1: 0.0, 2: 0.73, 3: 0.59},\n 9: {0: 0.66, 1: 0.81, 2: 0.81, 3: 0.0},\n 10: {0: 0.73, 1: 0.9, 2: 0.0, 3: 0.73},\n 11: {0: 0, 1: 0, 2: 0, 3: 0},\n 12: {0: 0, 1: 0, 2: 0, 3: 0},\n 13: {0: 0.0, 1: 0.81, 2: 0.9, 3: 0.73},\n 14: {0: 0.81, 1: 0.9, 2: 1.0, 3: 0.81},\n 15: {0: 0, 1: 0, 2: 0, 3: 0}}\n```", "```py\n{0: 'Down',\n 1: 'Right',\n 2: 'Down',\n 3: 'Left',\n 4: 'Down',\n 5: 'Left',\n 6: 'Down',\n 7: 'Left',\n 8: 'Right',\n 9: 'Down',\n 10: 'Down',\n 11: 'Left',\n 12: 'Left',\n 13: 'Right',\n 14: 'Right',\n 15: 'Left'}\n```", "```py\ndef render_func(env):\n    img = Image.fromarray(env.render())\n    display(img)\n\nstate, _ = env.reset()\n\nwhile True:\n    render_func(env) # draw a picture\n    action = get_best_action(q_table, state) # best action according to our table\n    next_state, _, terminated, _, _ = env.step(action)\n\n    if terminated:\n        break\n    else:\n        state = next_state\n\nrender_func(env)\n```", "```py\ndef play_episode(env, q_table):\n    state, _ = env.reset()\n\n    while True:\n        action = get_best_action(q_table, state)\n        next_state, reward, terminated, _, _ = env.step(action)\n\n        if terminated:\n            break\n        else:\n            state = next_state\n\n    return reward\n\nrewards = []\nfor episode in range(10000):\n    rewards.append(play_episode(env, q_table))\n```", "```py\nfrom collections import Counter\n\nprint(Counter(rewards))\n\n# Output:\n# Counter({1.0: 10000})\n```", "```py\nenv = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n```", "```py\nenv = gym.make('Blackjack-v1', natural=True, sab=False, render_mode=\"rgb_array\")\n```", "```py\nenv = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\", is_slippery=True)\n```", "```py\ngit clone https://github.com/magni84/gym_bandits.git\ncd gym_bandits\npip install -e .\n```", "```py\nimport gym_bandits\n\nenv = gym.make('MultiarmedBandits-v0')\n```"]