- en: Fine-Tuning Large Language Models (LLMs)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调大型语言模型（LLMs）
- en: 原文：[https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91](https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91](https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91)
- en: A conceptual overview with example Python code
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个带有示例Python代码的概念概述
- en: '[](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23473d763b91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23473d763b91--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)[](https://towardsdatascience.com/?source=post_page-----23473d763b91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----23473d763b91--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----23473d763b91--------------------------------)
    ·14 min read·Sep 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----23473d763b91--------------------------------)
    ·14分钟阅读·2023年9月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This is the 5th article in a [series on using Large Language Models](https://medium.com/towards-data-science/a-practical-introduction-to-llms-65194dda1148)
    (LLMs) in practice. In this post, we will discuss how to fine-tune (FT) a pre-trained
    LLM. We start by introducing key FT concepts and techniques, then finish with
    a concrete example of how to fine-tune a model (locally) using Python and Hugging
    Face’s software ecosystem.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于[使用大型语言模型](https://medium.com/towards-data-science/a-practical-introduction-to-llms-65194dda1148)（LLMs）实践的第5篇文章。在这篇文章中，我们将讨论如何对预训练的LLM进行微调（FT）。我们将首先介绍关键的FT概念和技术，然后通过一个具体的示例，演示如何使用Python和Hugging
    Face的软件生态系统在本地微调模型。
- en: '![](../Images/d74b7565b127d69e37ddf51e16125896.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d74b7565b127d69e37ddf51e16125896.png)'
- en: Tuning a language model. Image by author.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 调整语言模型。图像由作者提供。
- en: In the [previous article](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    of this series, we saw how we could build practical LLM-powered applications by
    integrating prompt engineering into our Python code. For the vast majority of
    LLM use cases, this is the initial approach I recommend because it requires significantly
    less resources and technical expertise than other methods while still providing
    much of the upside.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在[本系列的上一篇文章](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)中，我们看到如何通过将提示工程整合到Python代码中来构建实用的LLM驱动应用程序。对于绝大多数LLM使用案例，这是我推荐的初步方法，因为它比其他方法需要的资源和技术专长少得多，同时仍然能提供许多好处。
- en: However, there are situations where prompting an existing LLM out-of-the-box
    doesn’t cut it, and a more sophisticated solution is required. This is where model
    fine-tuning can help.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，存在一些情况，其中直接提示现有的LLM并不够有效，需要更复杂的解决方案。这就是模型微调可以发挥作用的地方。
- en: Supplemental Video.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 附加视频。
- en: '**What is Fine-tuning?**'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**什么是微调？**'
- en: '**Fine-tuning** is taking a pre-trained model and **training at least one internal
    model parameter** (i.e. weights). In the context of LLMs, what this typically
    accomplishes is transforming a general-purpose base model (e.g. GPT-3) into a
    specialized model for a particular use case (e.g. ChatGPT) [1].'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**微调**是对一个预训练的模型进行**至少一个内部模型参数的训练**（即权重）。在LLMs的上下文中，这通常是将一个通用的基础模型（例如GPT-3）转变为一个针对特定用例的专业模型（例如ChatGPT）[1]。'
- en: The **key upside** of this approach is that models can achieve better performance
    while requiring (far) fewer manually labeled examples compared to models that
    solely rely on supervised training.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的**主要优势**在于，与仅依赖监督训练的模型相比，模型可以在需要（远）少得多的人工标记示例的情况下实现更好的性能。
- en: While strictly self-supervised base models can exhibit impressive performance
    on a wide variety of tasks with the help of prompt engineering [2], they are still
    word predictors and may generate completions that are not entirely helpful or
    accurate. For example, let’s compare the completions of davinci (base GPT-3 model)
    and text-davinci-003 (a fine-tuned model).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然严格的自监督基础模型在借助提示工程[2]的帮助下可以在各种任务上展现出令人印象深刻的表现，但它们仍然是词预测器，可能生成的完成结果并不完全有用或准确。例如，让我们比较davinci（基础GPT-3模型）和text-davinci-003（一个经过微调的模型）的完成结果。
- en: '![](../Images/b3618c95fe5ccf99162d28d4b1bb1344.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3618c95fe5ccf99162d28d4b1bb1344.png)'
- en: Completion comparison of davinci (base GPT-3 model) and text-davinci-003 (a
    fine-tuned model). Image by author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: davinci（基础GPT-3模型）和text-davinci-003（一个经过微调的模型）的完成结果比较。图片由作者提供。
- en: Notice the base model is simply trying to complete the text by listing a set
    of questions like a Google search or homework assignment, while the **fine-tuned
    model gives a more helpful response**. The flavor of fine-tuning used for text-davinci-003
    is **alignment tuning,** which aims to make the LLM’s responses more helpful,
    honest, and harmless, but more on that later [3,4].
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，基础模型仅仅是通过列出一系列问题来完成文本，就像谷歌搜索或作业任务一样，而**微调模型提供了更有帮助的响应**。text-davinci-003所使用的微调方法是**对齐微调**，其目的是使大型语言模型的响应更有帮助、更诚实和无害，但稍后会详细介绍[3,4]。
- en: '**Why Fine-tune**'
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**为什么要微调**'
- en: Fine-tuning not only improves the performance of a base model, but **a smaller
    (fine-tuned) model can often outperform larger (more expensive) models** on the
    set of tasks on which it was trained [4]. This was demonstrated by OpenAI with
    their first generation “InstructGPT” models, where the 1.3B parameter InstructGPT
    model completions were preferred over the 175B parameter GPT-3 base model despite
    being 100x smaller [4].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 微调不仅能提高基础模型的性能，而且**较小的（微调的）模型在训练的任务集上往往能超越更大的（更昂贵的）模型**[4]。OpenAI通过其第一代“InstructGPT”模型证明了这一点，其中1.3B参数的InstructGPT模型在完成结果上优于175B参数的GPT-3基础模型，尽管它小了100倍[4]。
- en: Although most of the LLMs we may interact with these days are not strictly self-supervised
    models like GPT-3, there are still drawbacks to prompting an existing fine-tuned
    model for a specific use case.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们今天可能与之互动的大多数大型语言模型并非像GPT-3那样严格的自监督模型，但对现有的微调模型进行特定用例的提示仍然存在缺陷。
- en: A big one is LLMs have a finite context window. Thus, the model may perform
    sub-optimally on tasks that require a large knowledge base or domain-specific
    information [1]. Fine-tuned models can avoid this issue by “learning” this information
    during the fine-tuning process. This also precludes the need to jam-pack prompts
    with additional context and thus can result in lower inference costs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的问题是，大型语言模型有一个有限的上下文窗口。因此，模型可能在需要大量知识基础或特定领域信息的任务上表现不佳[1]。微调模型可以通过在微调过程中“学习”这些信息来避免这个问题。这也避免了在提示中塞入额外的上下文，从而可以降低推理成本。
- en: '**3 Ways to Fine-tune**'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**微调的三种方法**'
- en: 'There are **3 generic ways one can fine-tune** a model: self-supervised, supervised,
    and reinforcement learning. These are not mutually exclusive in that any combination
    of these three approaches can be used in succession to fine-tune a single model.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 有**三种通用的模型微调方法**：自监督、监督和强化学习。这些方法并非相互排斥，可以按顺序组合使用这三种方法来微调一个模型。
- en: '**Self-supervised Learning**'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**自监督学习**'
- en: '**Self-supervised learning** consists of **training a model based on the inherent
    structure of the training data**. In the context of LLMs, what this typically
    looks like is given a sequence of words (or tokens, to be more precise), predict
    the next word (token).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**自监督学习**包括**基于训练数据的固有结构来训练模型**。在大型语言模型的背景下，这通常表现为给定一个词（或更准确地说是令牌）的序列，预测下一个词（令牌）。'
- en: While this is how many pre-trained language models are developed these days,
    it can also be used for model fine-tuning. A potential use case of this is developing
    a model that can mimic a person’s writing style given a set of example texts.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是许多现今预训练语言模型的开发方式，但它也可以用于模型微调。一个潜在的应用场景是开发一个能够模拟某人写作风格的模型，给定一组示例文本。
- en: '**Supervised Learning**'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**监督学习**'
- en: The next, and perhaps most popular, way to fine-tune a model is via **supervised
    learning**. This involves **training a model on input-output pairs** for a particular
    task. An example is **instruction tuning,** which aims to improve model performance
    in answering questions or responding to user prompts [1,3].
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下一种，也许是最流行的，微调模型的方法是通过**监督学习**。这涉及到**对特定任务的输入-输出对进行模型训练**。一个例子是**指令调整**，其目的是提升模型在回答问题或回应用户提示时的表现[1,3]。
- en: 'The **key step** in supervised learning is **curating a training dataset**.
    A simple way to do this is to create question-answer pairs and integrate them
    into a prompt template [1,3]. For example, the question-answer pair: *Who was
    the 35th President of the United States? — John F. Kennedy* could be pasted into
    the below prompt template. More example prompt templates are available in section
    A.2.1 of ref [4].'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习中的**关键步骤**是**策划训练数据集**。一种简单的方法是创建问答对并将其整合到提示模板中[1,3]。例如，问答对：*谁是美国第35任总统？——
    约翰·F·肯尼迪* 可以粘贴到下面的提示模板中。更多示例提示模板可以在参考文献[4]的A.2.1节中找到。
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Using a prompt template is important because base models like GPT-3 are essentially
    “document completers”. Meaning, given some text, the model generates more text
    that (statistically) makes sense in that context. This goes back to the [previous
    blog](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    of this series and the idea of “tricking” a language model into solving your problem
    via prompt engineering.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提示模板很重要，因为像GPT-3这样的基础模型本质上是“文档补全器”。这意味着，给定一些文本，模型会生成在该上下文中（统计上）有意义的更多文本。这回到本系列的[上一篇博客](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)和通过提示工程“欺骗”语言模型来解决问题的想法。
- en: '[](/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f?source=post_page-----23473d763b91--------------------------------)
    [## Prompt Engineering — How to trick AI into solving your problems'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f?source=post_page-----23473d763b91--------------------------------)
    [## 提示工程 — 如何“欺骗”AI来解决你的问题'
- en: 7 prompting tricks, Langchain, and Python example code
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7个提示技巧、Langchain和Python示例代码
- en: towardsdatascience.com](/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f?source=post_page-----23473d763b91--------------------------------)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f?source=post_page-----23473d763b91--------------------------------)
- en: '**Reinforcement Learning**'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**强化学习**'
- en: Finally, one can use **reinforcement learning (RL)** to fine-tune models. RL
    **uses a reward model to guide the training of the base model**. This can take
    many different forms, but the basic idea is to train the reward model to score
    language model completions such that they reflect the preferences of human labelers
    [3,4]. The reward model can then be combined with a reinforcement learning algorithm
    (e.g. Proximal Policy Optimization (PPO)) to fine-tune the pre-trained model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可以使用**强化学习（RL）**来微调模型。RL**使用奖励模型来指导基础模型的训练**。这可以采取多种形式，但基本思想是训练奖励模型以对语言模型的完成情况进行评分，使其反映人类标注者的偏好[3,4]。然后，奖励模型可以与强化学习算法（例如，近端策略优化（PPO））结合使用，以微调预训练模型。
- en: An example of how RL can be used for model fine-tuning is demonstrated by OpenAI’s
    InstructGPT models, which were developed through **3 key steps** [4].
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的InstructGPT模型展示了如何使用强化学习进行模型微调，这些模型是通过**3个关键步骤**开发的[4]。
- en: 'Generate high-quality prompt-response pairs and fine-tune a pre-trained model
    using supervised learning. (~13k training prompts) *Note: One can (alternatively)
    skip to step 2 with the pre-trained model [3].*'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成高质量的提示-响应对，并使用监督学习微调预训练模型。（~13k训练提示） *注意：可以（可选地）跳到步骤2，使用预训练模型[3]。*
- en: Use the fine-tuned model to generate completions and have human-labelers rank
    responses based on their preferences. Use these preferences to train the reward
    model. (~33k training prompts)
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用微调后的模型生成完成，并让人工标注者根据其偏好对响应进行排名。使用这些偏好来训练奖励模型。（~33k训练提示）
- en: Use the reward model and an RL algorithm (e.g. PPO) to fine-tune the model further.
    (~31k training prompts)
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用奖励模型和强化学习算法（例如PPO）进一步微调模型。（~31k训练提示）
- en: While the strategy above does generally result in LLM completions that are significantly
    more preferable to the base model, it can also come at a cost of lower performance
    in a subset of tasks. This drop in performance is also known as an **alignment
    tax** [3,4].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述策略通常会导致LLM完成度显著优于基础模型，但这也可能导致在某些任务上的性能下降。这种性能下降也被称为**对齐成本**[3,4]。
- en: '**Supervised Fine-tuning Steps (High-level)**'
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**监督微调步骤（高级）**'
- en: As we saw above, there are many ways in which one can fine-tune an existing
    language model. However, for the remainder of this article, we will focus on fine-tuning
    via supervised learning. Below is a high-level procedure for supervised model
    fine-tuning [1].
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，可以通过许多方法微调现有语言模型。然而，本文剩余部分将专注于通过监督学习进行微调。以下是监督模型微调的高级程序[1]。
- en: '**Choose fine-tuning task** (e.g. summarization, question answering, text classification)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择微调任务**（例如总结、问答、文本分类）'
- en: '**Prepare training dataset** i.e. create (100–10k) input-output pairs and preprocess
    data (i.e. tokenize, truncate, and pad text).'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备训练数据集**即创建（100–10k）输入输出对并预处理数据（即标记化、截断和填充文本）。'
- en: '**Choose a base model** (experiment with different models and choose one that
    performs best on the desired task).'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择基础模型**（尝试不同模型并选择在所需任务上表现最佳的一个）。'
- en: '**Fine-tune model via supervised learning**'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**通过监督学习微调模型**'
- en: '**Evaluate model performance**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估模型性能**'
- en: While each of these steps could be an article of their own, I want to focus
    on **step 4** and discuss how we can go about training the fine-tuned model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些步骤中的每一个都可以成为一篇文章，但我想专注于**第 4 步**并讨论如何训练微调后的模型。
- en: '**3 Options for Parameter Training**'
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**参数训练的 3 种选项**'
- en: When it comes to fine-tuning a model with ~100M-100B parameters, one needs to
    be thoughtful of computational costs. Toward this end, an important question is
    — *which parameters do we (re)train?*
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调拥有~100M-100B参数的模型时，需要考虑计算成本。在这方面，一个重要的问题是——*我们（重新）训练哪些参数？*
- en: With the mountain of parameters at play, we have countless choices for which
    ones we train. Here, I will focus on **three generic options** of which to choose.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理大量参数时，我们有无数的选择来决定训练哪些参数。在这里，我将专注于**三种通用选项**。
- en: '**Option 1: Retrain all parameters**'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**选项 1：重新训练所有参数**'
- en: The first option is to **train all internal model parameters** (called **full
    parameter tuning**) [3]. While this option is simple (conceptually), it is the
    most computationally expensive. Additionally, a known issue with full parameter
    tuning is the phenomenon of catastrophic forgetting. This is where the model “forgets”
    useful information it “learned” in its initial training [3].
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个选项是**训练所有内部模型参数**（称为**完全参数调优**）[3]。虽然这个选项在概念上很简单，但它是最耗费计算资源的。此外，完全参数调优的一个已知问题是灾难性遗忘现象。这是模型“遗忘”了在初始训练中“学到”的有用信息[3]。
- en: One way we can mitigate the downsides of Option 1 is to freeze a large portion
    of the model parameters, which brings us to Option 2.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过冻结模型参数的大部分来缓解选项 1 的缺点，这就引出了选项 2。
- en: '**Option 2: Transfer Learning**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**选项 2：迁移学习**'
- en: 'The big idea with **transfer learning (TL)** is to preserve the useful representations/features
    the model has learned from past training when applying the model to a new task.
    This generally consists of **dropping “the head” of a neural network (NN) and
    replacing it with a new one** (e.g. adding new layers with randomized weights).
    *Note: The head of an NN includes its final layers, which translate the model’s
    internal representations to output values.*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**迁移学习（TL）**的核心思想是保留模型从过去训练中学到的有用表示/特征，并将模型应用于新任务时使用。这通常包括**“去掉神经网络（NN）的头部并用新的头部替换它”**（例如，添加具有随机权重的新层）。*注意：神经网络的头部包括其最终层，这些层将模型的内部表示转换为输出值。*'
- en: While leaving the majority of parameters untouched mitigates the huge computational
    cost of training an LLM, TL may not necessarily resolve the problem of catastrophic
    forgetting. To better handle both of these issues, we can turn to a different
    set of approaches.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然保持大部分参数不变可以减轻训练LLM的巨大计算成本，但TL可能无法解决灾难性遗忘问题。为了更好地处理这两个问题，我们可以转向一组不同的方法。
- en: '**Option 3: Parameter Efficient Fine-tuning (PEFT)**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**选项 3：参数高效微调（PEFT）**'
- en: '**PEFT** involves **augmenting a base model with a relatively small number
    of trainable parameters**. The key result of this is a fine-tuning methodology
    that demonstrates comparable performance to full parameter tuning at a tiny fraction
    of the computational and storage cost [5].'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**PEFT** 涉及 **用相对少量的可训练参数增强基础模型**。其关键结果是一种微调方法，能够在极低的计算和存储成本下展示出与完全参数调整相当的性能
    [5]。'
- en: PEFT encapsulates a family of techniques, one of which is the popular **LoRA
    (Low-Rank Adaptation)** method [6]. The basic idea behind LoRA is to pick a subset
    of layers in an existing model and modify their weights according to the following
    equation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: PEFT 封装了一系列技术，其中之一是流行的 **LoRA (低秩适配)** 方法 [6]。LoRA 的基本思想是选择现有模型中的一部分层，并根据以下方程式修改它们的权重。
- en: '![](../Images/446dc4369edc5bc4655f4986a426a513.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/446dc4369edc5bc4655f4986a426a513.png)'
- en: Equation showing how weight matrices are modified for fine-tuning using LoRA
    [6]. Image by author.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式显示了如何使用 LoRA 修改权重矩阵以进行微调 [6]。图片由作者提供。
- en: Where *h()* = a hidden layer that will be tuned, *x* = the input to *h()*, *W₀*
    = the original weight matrix for the *h*, and *ΔW* = a matrix of trainable parameters
    injected into *h*. *ΔW* is decomposed according to *ΔW*=*BA*, where *ΔW* is a
    d by k matrix, *B* is d by r, and *A* is r by k*.* r is the assumed “intrinsic
    rank” of *ΔW* (which can be as small as 1 or 2) [6].
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *h()* = 一个将被调整的隐藏层，*x* = 输入到 *h()* 的数据，*W₀* = *h* 的原始权重矩阵，而 *ΔW* = 注入到 *h*
    的可训练参数矩阵。*ΔW* 根据 *ΔW*=*BA* 被分解，其中 *ΔW* 是一个 d 乘 k 的矩阵，*B* 是 d 乘 r 的矩阵，而 *A* 是 r
    乘 k 的矩阵。r 是 *ΔW* 的假定“内在秩”（可以小到 1 或 2）[6]。
- en: Sorry for all the math, but the **key point is the (d * k) weights in *W₀* are
    frozen and, thus, not included in optimization**. Instead, the ((d * r) + (r *
    k)) weights making up matrices *B* and *A* are the only ones that are trained.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对不起有这么多数学公式，但**关键点是 *W₀* 中的 (d * k) 权重是冻结的，因此不包括在优化中**。相反，构成矩阵 *B* 和 *A* 的 ((d
    * r) + (r * k)) 权重是唯一经过训练的。
- en: Plugging in some made-up numbers for d=100, k=100, and r=2 to get a sense of
    the efficiency gains, the **number of trainable parameters drops from 10,000 to
    400** in that layer. In practice, the authors of the LoRA paper cited a **10,000x
    reduction in parameter checkpoint size** using LoRA fine-tune GPT-3 compared to
    full parameter tuning [6].
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将一些虚构的数字代入 d=100, k=100 和 r=2 来感受效率提升，**可训练参数的数量从 10,000 降到 400**。实际上，LoRA
    论文的作者提到，使用 LoRA 微调 GPT-3 相比完全参数调整，**参数检查点大小减少了 10,000 倍** [6]。
- en: To make this more concrete, let’s see how we can use LoRA to fine-tune a language
    model efficiently enough to run on a personal computer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这更加具体，让我们看看如何使用 LoRA 高效地微调语言模型，以便在个人计算机上运行。
- en: '**Example Code: Fine-tuning an LLM using LoRA**'
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**示例代码：使用 LoRA 微调 LLM**'
- en: In this example, we will use the Hugging Face ecosystem to fine-tune a language
    model to classify text as ‘positive’ or ‘negative’. Here, we fine-tune [*distilbert-base-uncased*](https://huggingface.co/distilbert-base-uncased),
    a ~70M parameter model based on [BERT](https://arxiv.org/pdf/1810.04805.pdf).
    Since this base model was trained to do language modeling and not classification,
    we employ **transfer learning** to replace the base model head with a classification
    head. Additionally, we use **LoRA** to fine-tune the model efficiently enough
    that it can run on my Mac Mini (M1 chip with 16GB memory) in a reasonable amount
    of time (~20 min).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用 Hugging Face 生态系统来微调语言模型，以将文本分类为“正面”或“负面”。在这里，我们微调 [*distilbert-base-uncased*](https://huggingface.co/distilbert-base-uncased)，一个基于
    [BERT](https://arxiv.org/pdf/1810.04805.pdf) 的约 70M 参数模型。由于这个基础模型是为了语言建模而不是分类训练的，我们采用
    **迁移学习** 将基础模型头部替换为分类头。此外，我们使用 **LoRA** 高效地微调模型，使其可以在我的 Mac Mini（M1 芯片，16GB 内存）上在合理时间内（约
    20 分钟）运行。
- en: The code, along with the conda environment files, are available on the [GitHub
    repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning).
    The [final model](https://huggingface.co/shawhin/distilbert-base-uncased-lora-text-classification)
    and [dataset](https://huggingface.co/datasets/shawhin/imdb-truncated) [7] are
    available on Hugging Face.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 代码以及 conda 环境文件可以在 [GitHub 仓库](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning)
    中找到。最终模型和 [数据集](https://huggingface.co/datasets/shawhin/imdb-truncated) [7] 可在
    Hugging Face 上获得。
- en: '[](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning?source=post_page-----23473d763b91--------------------------------)
    [## YouTube-Blog/LLMs/fine-tuning at main · ShawhinT/YouTube-Blog'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning?source=post_page-----23473d763b91--------------------------------)
    [## YouTube-Blog/LLMs/fine-tuning at main · ShawhinT/YouTube-Blog'
- en: Codes to complement YouTube videos and blog posts on Medium. - YouTube-Blog/LLMs/fine-tuning
    at main ·…
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码以补充 YouTube 视频和 Medium 上的博客文章。 - YouTube-Blog/LLMs/fine-tuning at main ·…
- en: github.com](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning?source=post_page-----23473d763b91--------------------------------)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning?source=post_page-----23473d763b91--------------------------------)
- en: Imports
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入
- en: We start by importing helpful libraries and modules. [Datasets](https://huggingface.co/docs/datasets/index),
    [transformers](https://huggingface.co/docs/transformers/index), [peft](https://huggingface.co/docs/peft/index),
    and [evaluate](https://huggingface.co/docs/evaluate/index) are all libraries from
    [Hugging Face](https://huggingface.co/) (HF).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从导入有用的库和模块开始。[Datasets](https://huggingface.co/docs/datasets/index)、[transformers](https://huggingface.co/docs/transformers/index)、[peft](https://huggingface.co/docs/peft/index)
    和 [evaluate](https://huggingface.co/docs/evaluate/index) 都是来自[Hugging Face](https://huggingface.co/)
    (HF) 的库。
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Base model
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础模型
- en: Next, we load in our base model. The base model here is a relatively small one,
    but there are several other (larger) ones that we could have used (e.g. roberta-base,
    llama2, gpt2). A full list is available [here](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载基础模型。这里的基础模型相对较小，但我们还可以使用其他几个（更大的）模型（例如 roberta-base、llama2、gpt2）。完整列表请参见[这里](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification)。
- en: '[PRE2]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Load data
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: We can then load our [training and validation data](https://huggingface.co/datasets/shawhin/imdb-truncated)
    from HF’s datasets library. This is a dataset of 2000 movie reviews (1000 for
    training and 1000 for validation) with binary labels indicating whether the review
    is positive (or not).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以从 HF 的数据集库中加载我们的[训练和验证数据](https://huggingface.co/datasets/shawhin/imdb-truncated)。这是一个包含2000条电影评论（1000条用于训练，1000条用于验证）的数据集，其中的二元标签表示评论是积极的（还是消极的）。
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Preprocess data
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理数据
- en: Next, we need to preprocess our data so that it can be used for training. This
    consists of using a tokenizer to convert the text into an integer representation
    understood by the base model.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要预处理数据，以便用于训练。这包括使用分词器将文本转换为基础模型可以理解的整数表示。
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To apply the tokenizer to the dataset, we use the .*map()* method. This takes
    in a custom function that specifies how the text should be preprocessed. In this
    case, that function is called *tokenize_function()*. In addition to translating
    text to integers, this function truncates integer sequences such that they are
    no longer than 512 numbers to conform to the base model’s max input length.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要将分词器应用于数据集，我们使用.*map()*方法。这需要一个自定义函数来指定文本应如何预处理。在这种情况下，该函数称为*tokenize_function()*。除了将文本转换为整数之外，此函数还会截断整数序列，使其不超过512个数字，以符合基础模型的最大输入长度。
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: At this point, we can also create a data collator, which will dynamically pad
    examples in each batch during training such that they all have the same length.
    This is computationally more efficient than padding all examples to be equal in
    length across the entire dataset.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们还可以创建一个数据整理器，它将在训练期间动态填充每个批次中的示例，以使它们都具有相同的长度。这比将所有示例填充到整个数据集中的相同长度更具计算效率。
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Evaluation metrics
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估指标
- en: We can define how we want to evaluate our fine-tuned model via a custom function.
    Here, we define the *compute_metrics()* function to compute the model’s accuracy.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过自定义函数定义如何评估我们微调后的模型。在这里，我们定义了*compute_metrics()*函数来计算模型的准确率。
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Untrained model performance
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未训练模型的性能
- en: Before training our model, we can evaluate how the base model with a randomly
    initialized classification head performs on some example inputs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型之前，我们可以评估基础模型在随机初始化分类头上的一些示例输入的表现。
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As expected, the model performance is equivalent to random guessing. Let’s see
    how we can improve this with fine-tuning.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，模型的性能等同于随机猜测。让我们看看如何通过微调来改善这一点。
- en: Fine-tuning with LoRA
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 LoRA 微调
- en: To use LoRA for fine-tuning, we first need a config file. This sets all the
    parameters for the LoRA algorithm. See comments in the code block for more details.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 LoRA 进行微调，我们首先需要一个配置文件。这设置了 LoRA 算法的所有参数。有关更多详细信息，请参见代码块中的注释。
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can then create a new version of our model that can be trained via PEFT.
    Notice that the scale of trainable parameters was reduced by about 100x.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以创建一个新的模型版本，该模型可以通过PEFT进行训练。注意到可训练参数的规模减少了大约100倍。
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Next, we define hyperparameters for model training.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义模型训练的超参数。
- en: '[PRE11]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Finally, we create a trainer() object and fine-tune the model!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建一个trainer()对象并微调模型！
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The above code will generate the following table of metrics during training.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将在训练期间生成以下指标表。
- en: '![](../Images/75c8df11198f7db7e4d932cd45924488.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75c8df11198f7db7e4d932cd45924488.png)'
- en: Model training metrics. Image by author.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练指标。图片由作者提供。
- en: Trained model performance
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练模型性能
- en: To see how the model performance has improved, let’s apply it to the same 5
    examples from before.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看模型性能的提升，我们来将其应用于之前的相同5个示例。
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The fine-tuned model improved significantly from its prior random guessing,
    correctly classifying all but one of the examples in the above code. This aligns
    with the ~90% accuracy metric we saw during training.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 微调后的模型相较于之前的随机猜测有了显著改善，正确分类了上述代码中的所有示例，除了一个。这与我们在训练过程中看到的约90%准确率指标相符。
- en: 'Links: [Code Repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning)
    | [Model](https://huggingface.co/shawhin/distilbert-base-uncased-lora-text-classification)
    | [Dataset](https://huggingface.co/datasets/shawhin/imdb-truncated)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '链接: [代码库](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning)
    | [模型](https://huggingface.co/shawhin/distilbert-base-uncased-lora-text-classification)
    | [数据集](https://huggingface.co/datasets/shawhin/imdb-truncated)'
- en: Conclusions
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: While fine-tuning an existing model requires more computational resources and
    technical expertise than using one out-of-the-box, (smaller) fine-tuned models
    can outperform (larger) pre-trained base models for a particular use case, even
    when employing clever prompt engineering strategies. Furthermore, with all the
    open-source LLM resources available, it’s never been easier to fine-tune a model
    for a custom application.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然微调现有模型比使用开箱即用的模型需要更多的计算资源和技术专长，（较小的）微调模型可以在特定用例中超过（较大的）预训练基础模型，即使在使用巧妙的提示工程策略时也是如此。此外，借助所有可用的开源LLM资源，微调模型以满足自定义应用从未如此简单。
- en: The next article of this series will go one step beyond model fine-tuning and
    discuss how to train a language model from scratch.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本系列的下一篇文章将超越模型微调，讨论如何从头开始训练一个语言模型。
- en: '👉 **More on LLMs**: [Introduction](/a-practical-introduction-to-llms-65194dda1148)
    | [OpenAI API](https://medium.com/towards-data-science/cracking-open-the-openai-python-api-230e4cae7971)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [Build an LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [Text Embeddings](/text-embeddings-classification-and-semantic-search-8291746220be)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '👉 **更多关于LLMs**: [介绍](/a-practical-introduction-to-llms-65194dda1148) | [OpenAI
    API](https://medium.com/towards-data-science/cracking-open-the-openai-python-api-230e4cae7971)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [提示工程](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [构建LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [文本嵌入](/text-embeddings-classification-and-semantic-search-8291746220be)'
- en: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
- en: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----23473d763b91--------------------------------)'
- en: Large Language Models (LLMs)
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）
- en: '[View list](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----23473d763b91--------------------------------)13
    stories![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----23473d763b91--------------------------------)13
    个故事![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
- en: Resources
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**联系**: [我的网站](https://shawhintalebi.com/) | [预约通话](https://calendly.com/shawhintalebi)
    | [问我任何问题](https://shawhintalebi.com/contact/)'
- en: '**Socials**: [YouTube 🎥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**社交媒体**: [YouTube 🎥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) ☕️'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持**: [请我喝咖啡](https://www.buymeacoffee.com/shawhint) ☕️'
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----23473d763b91--------------------------------)
    [## Get FREE access to every new story I write'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/subscribe?source=post_page-----23473d763b91--------------------------------)
    [## 免费获取我写的每个新故事'
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create a…
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 免费获取我写的每个新故事 P.S. 我不会将您的邮件分享给任何人 注册即创建一个…
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----23473d763b91--------------------------------)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----23473d763b91--------------------------------)
- en: '[1] Deeplearning.ai Finetuning Large Langauge Models Short Course: [https://www.deeplearning.ai/short-courses/finetuning-large-language-models/](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Deeplearning.ai 大型语言模型微调短课程: [https://www.deeplearning.ai/short-courses/finetuning-large-language-models/](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)'
- en: '[2] [arXiv:2005.14165](https://arxiv.org/abs/2005.14165) **[cs.CL] (**GPT-3
    Paper)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [arXiv:2005.14165](https://arxiv.org/abs/2005.14165) **[cs.CL] (**GPT-3论文)'
- en: '[3] [arXiv:2303.18223](https://arxiv.org/abs/2303.18223) **[cs.CL] (**Survey
    of LLMs)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [arXiv:2303.18223](https://arxiv.org/abs/2303.18223) **[cs.CL] (**LLMs综述)'
- en: '[4] [arXiv:2203.02155](https://arxiv.org/abs/2203.02155) **[cs.CL] (**InstructGPT
    paper)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [arXiv:2203.02155](https://arxiv.org/abs/2203.02155) **[cs.CL] (**InstructGPT论文)'
- en: '[5] 🤗 PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource
    Hardware: [https://huggingface.co/blog/peft](https://huggingface.co/blog/peft)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] 🤗 PEFT: 在低资源硬件上对亿级规模模型进行参数高效微调: [https://huggingface.co/blog/peft](https://huggingface.co/blog/peft)'
- en: '[6] [arXiv:2106.09685](https://arxiv.org/abs/2106.09685) **[cs.CL]** (LoRA
    paper)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [arXiv:2106.09685](https://arxiv.org/abs/2106.09685) **[cs.CL]** (LoRA论文)'
- en: '[7] Original dataset source — Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
    Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011\. [Learning Word Vectors
    for Sentiment Analysis](https://aclanthology.org/P11-1015). In *Proceedings of
    the 49th Annual Meeting of the Association for Computational Linguistics: Human
    Language Technologies*, pages 142–150, Portland, Oregon, USA. Association for
    Computational Linguistics.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] 原始数据集来源 — Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew
    Y. Ng, 和 Christopher Potts. 2011\. [学习词向量进行情感分析](https://aclanthology.org/P11-1015)。在*第49届计算语言学协会年会：人类语言技术会议论文集*，第142–150页，美国俄勒冈州波特兰市。计算语言学协会。'
