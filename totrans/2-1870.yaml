- en: Singular Value Decomposition (SVD), Demystified
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奇异值分解（SVD）揭秘
- en: 原文：[https://towardsdatascience.com/singular-value-decomposition-svd-demystified-57fc44b802a0](https://towardsdatascience.com/singular-value-decomposition-svd-demystified-57fc44b802a0)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/singular-value-decomposition-svd-demystified-57fc44b802a0](https://towardsdatascience.com/singular-value-decomposition-svd-demystified-57fc44b802a0)
- en: A comprehensive guide to SVD with Python examples
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一份包含 Python 示例的 SVD 综合指南
- en: '[](https://medium.com/@roiyeho?source=post_page-----57fc44b802a0--------------------------------)[![Dr.
    Roi Yehoshua](../Images/905a512ffc8879069403a87dbcbeb4db.png)](https://medium.com/@roiyeho?source=post_page-----57fc44b802a0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----57fc44b802a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----57fc44b802a0--------------------------------)
    [Dr. Roi Yehoshua](https://medium.com/@roiyeho?source=post_page-----57fc44b802a0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@roiyeho?source=post_page-----57fc44b802a0--------------------------------)[![Dr.
    Roi Yehoshua](../Images/905a512ffc8879069403a87dbcbeb4db.png)](https://medium.com/@roiyeho?source=post_page-----57fc44b802a0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----57fc44b802a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----57fc44b802a0--------------------------------)
    [Dr. Roi Yehoshua](https://medium.com/@roiyeho?source=post_page-----57fc44b802a0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----57fc44b802a0--------------------------------)
    ·19 min read·Nov 8, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----57fc44b802a0--------------------------------)
    ·阅读时间19分钟·2023年11月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Singular value decomposition (SVD) is a powerful matrix factorization technique
    that decomposes a matrix into three other matrices, revealing important structural
    aspects of the original matrix. It is used in a wide range of applications, including
    signal processing, image compression, and dimensionality reduction in machine
    learning.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 奇异值分解（SVD）是一种强大的矩阵因式分解技术，将矩阵分解成三个其他矩阵，从而揭示了原始矩阵的重要结构特征。它在信号处理、图像压缩以及机器学习中的降维等广泛应用中都发挥了作用。
- en: This article provides a step-by-step guide on how to compute the SVD of a matrix,
    including a detailed numerical example. It then demonstrates how to use SVD for
    dimensionality reduction using examples in Python. Finally, the article discusses
    various applications of SVD and some of its limitations.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章提供了计算矩阵奇异值分解的逐步指南，包括详细的数值示例。随后，文章演示了如何使用奇异值分解进行降维，并使用 Python 示例说明了这一过程。最后，文章讨论了奇异值分解的各种应用及其一些局限性。
- en: The article assumes the reader has basic knowledge of linear algebra. More specifically,
    the reader should be familiar with concepts such as vector and matrix norms, rank
    of a matrix, eigen-decomposition (eigenvectors and eigenvalues), orthonormal vectors,
    and linear projections.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 文章假设读者具有基础的线性代数知识。具体来说，读者应该熟悉诸如向量和矩阵范数、矩阵的秩、特征分解（特征向量和特征值）、正交归一向量和线性投影等概念。
- en: '![](../Images/502e38be1631c3d04de689deedbe2734.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/502e38be1631c3d04de689deedbe2734.png)'
- en: Image by [Peggy und Marco Lachmann-Anke](https://pixabay.com/users/peggy_marco-1553824/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1027571)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1027571)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Peggy und Marco Lachmann-Anke](https://pixabay.com/users/peggy_marco-1553824/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1027571)
    提供，来源于 [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1027571)
- en: Mathematical Definition
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数学定义
- en: 'The singular value decomposition of an *m* × *n* real matrix *A* is a factorization
    of the form *A* = *U*Σ*Vᵗ*, where:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *m* × *n* 实数矩阵 *A* 的奇异值分解是形式为 *A* = *U*Σ*Vᵗ* 的因式分解，其中：
- en: '*U* is an *m* × *m* **orthogonal matrix** (i.e., its columns and rows are orthonormal
    vectors). The columns of *U* are called the **left-singular** **vectors** of *A*.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*U* 是一个 *m* × *m* **正交矩阵**（即，其列和行是正交归一的向量）。*U* 的列被称为 *A* 的 **左奇异** **向量**。'
- en: Σ is an *m* × *n* rectangular diagonal matrix with non-negative real numbers
    on the diagonal. The diagonal entries *σᵢ* = Σ*ᵢᵢ* are known as the **singular
    values** of *A* and are typically arranged in descending order, i.e., *σ*₁ *≥
    σ*₂ *≥ … ≥ σₙ ≥* 0\. The number of the non-zero singular values is equal to the
    rank of *A*.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Σ 是一个 *m* × *n* 的矩形对角矩阵，对角线上有非负实数。对角线条目 *σᵢ* = Σ*ᵢᵢ* 被称为 *A* 的**奇异值**，通常按降序排列，即
    *σ*₁ *≥ σ*₂ *≥ … ≥ σₙ ≥* 0。非零奇异值的数量等于 *A* 的秩。
- en: '*V* is an *n* × *n* orthogonal matrix. The columns of *V* are called the **right-singular
    vectors** of *A*.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*V* 是一个 *n* × *n* 的正交矩阵。*V* 的列称为 *A* 的**右奇异向量**。'
- en: '![](../Images/4f242c74c521d6be82324f67851bcccc.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f242c74c521d6be82324f67851bcccc.png)'
- en: SVD of a matrix
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵的 SVD
- en: Every matrix has a singular value decomposition(a proof of this statement can
    be found [here](https://en.wikipedia.org/wiki/Singular_value_decomposition#Proof_of_existence)).
    This is unlike eigenvalue decomposition, for example, which can be applied only
    to squared diagonalizable matrices.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 每个矩阵都有一个奇异值分解（此声明的证明可以在[这里](https://en.wikipedia.org/wiki/Singular_value_decomposition#Proof_of_existence)找到）。这与特征值分解不同，例如，特征值分解仅适用于平方对角化矩阵。
- en: Computing the SVD
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算 SVD
- en: 'The singular value decomposition of a matrix *A* can be computed using the
    following observations:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 *A* 的奇异值分解可以通过以下观察来计算：
- en: The left-singular vectors of *A* are a set of orthonormal eigenvectors of *AAᵗ*.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*A* 的左奇异向量是一组 *AAᵗ* 的正交特征向量。'
- en: The right-singular vectors of *A* are a set of orthonormal eigenvectors of *AᵗA*.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*A* 的右奇异向量是一组 *AᵗA* 的正交特征向量。'
- en: The non-zero singular values of *A* are the square roots of the non-zero eigenvalues
    of both *AᵗA* and *AAᵗ*.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*A* 的非零奇异值是 *AᵗA* 和 *AAᵗ* 的非零特征值的平方根。'
- en: If *U*Σ*Vᵗ* is the SVD of *A*, thenfor each singular value *σᵢ,*
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 *U*Σ*Vᵗ* 是 *A* 的 SVD，那么对于每个奇异值 *σᵢ*，
- en: '![](../Images/c21f44352bebcf44ded85f4b62127668.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c21f44352bebcf44ded85f4b62127668.png)'
- en: where **u***ᵢ* is the *i*-th column of *U* and **v***ᵢ* is the *i*-th column
    of *V*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 **u***ᵢ* 是 *U* 的第 *i* 列，**v***ᵢ* 是 *V* 的第 *i* 列。
- en: '**Proof**:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**证明**：'
- en: We will first show that the left-singular vectors of *A* are a set of orthonormal
    eigenvectors of *AAᵗ*.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先证明 *A* 的左奇异向量是一组 *AAᵗ* 的正交特征向量。
- en: 'Let *A* = *U*Σ*Vᵗ* be the SVD of *A*, and let’s examinethe product *AAᵗ*:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 设 *A* = *U*Σ*Vᵗ* 为 *A* 的 SVD，接下来检查 *AAᵗ* 的乘积：
- en: '![](../Images/13bab9f9fe073214d3fde47c3655c08b.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13bab9f9fe073214d3fde47c3655c08b.png)'
- en: 'Since Σ is a diagonal matrix with singular values *σᵢ* on its diagonal, ΣΣ*ᵗ*
    is also a diagonal matrix where each diagonal element is *σᵢ*². Let’s denote this
    matrix by Σ². This gives us:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Σ 是一个对角矩阵，对角线上有奇异值 *σᵢ*，ΣΣ*ᵗ* 也是一个对角矩阵，其中每个对角元素是 *σᵢ*²。我们用 Σ² 来表示这个矩阵。这给我们带来了：
- en: '![](../Images/79a6fc8fe5780e4abe9da1471306492f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79a6fc8fe5780e4abe9da1471306492f.png)'
- en: 'Since *U* is orthonormal, *UᵗU* = *I*, and by right multiplying both sides
    of the equation by *U* we get:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *U* 是正交的，*UᵗU* = *I*，通过将方程的两边右乘 *U*，我们得到：
- en: '![](../Images/676c6c9399ba59fd0de48bf82c1f47b9.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/676c6c9399ba59fd0de48bf82c1f47b9.png)'
- en: 'Let’s now consider a single column of *U*, denoted by **u***ᵢ*. Since *ABᵢ*
    = [*AB*]*ᵢ* (i.e., matrix *A* multiplied by column *i* of matrix *B* is equal
    to column *i* of their product *AB*), we can write:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑 *U* 的一列，记作 **u***ᵢ*。由于 *ABᵢ* = [*AB*]*ᵢ*（即矩阵 *A* 乘以矩阵 *B* 的第 *i* 列等于它们的积
    *AB* 的第 *i* 列），我们可以写出：
- en: '![](../Images/5dd5007f733784ba871a30e6ea3e7e96.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5dd5007f733784ba871a30e6ea3e7e96.png)'
- en: Therefore, **u***ᵢ* is an eigenvector of *AAᵗ* corresponding to the eigenvalue
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，**u***ᵢ* 是 *AAᵗ* 的一个特征向量，对应于特征值
- en: '*λᵢ* = *σᵢ*². In other words, the columns of *U* are eigenvectors of *AAᵗ.*
    Because the columns of *U* are orthonormal, the left-singular vectors of *A* (the
    columns of *U*) are a set of orthonormal vectors of *AAᵗ.*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*λᵢ* = *σᵢ*²。换句话说，*U* 的列是 *AAᵗ* 的特征向量。由于 *U* 的列是正交的，*A* 的左奇异向量（*U* 的列）是 *AAᵗ*
    的一组正交向量。'
- en: 2\. In a similar fashion, we can show that the right-singular vectors of *A*
    are a set of orthonormal eigenvectors of *AᵗA*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 以类似的方式，我们可以证明 *A* 的右奇异向量是一组 *AᵗA* 的正交特征向量。
- en: '3\. We first notice that *AAᵗ* is symmetric and positive semi-definite. Therefore
    all its eigenvalues are real and non-negative, and it has a full set of orthonormal
    eigenvectors. Let {**u**₁, …, **u***ₙ*} be the orthonormal eigenvectors of *AAᵗ*
    corresponding to eigenvalues *λ*₁ *≥ λ*₂ *≥ … ≥ λₙ ≥* 0\. For any eigenvector
    **u***ᵢ* of *AAᵗ* corresponding to an eigenvalue *λᵢ* we have:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 我们首先注意到*AAᵗ*是对称且半正定的。因此，它的所有特征值都是实数且非负的，并且有一组完整的正交特征向量。设{**u**₁, …, **u***ₙ*}为对应特征值*λ*₁
    *≥ λ*₂ *≥ … ≥ λₙ ≥* 0的*AAᵗ*的正交特征向量。对于任何特征值为*λᵢ*的*AAᵗ*的特征向量**u***ᵢ*，我们有：
- en: '![](../Images/e3544ed7c7e7528d220657cb5e0e4d1d.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3544ed7c7e7528d220657cb5e0e4d1d.png)'
- en: Thus, the singular values of *A* are the square roots of the eigenvalues of
    *AAᵗ*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*A*的奇异值是*AAᵗ*特征值的平方根。
- en: Similarly, we can show that the singular values of *A* are also the square roots
    of the eigenvalues of *AᵗA*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以证明*A*的奇异值也是*AᵗA*特征值的平方根。
- en: 4\. Left as an exercise to the reader.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 留给读者作为练习。
- en: 'Based on the above observations, we can compute the SVD of an *m* × *n* matrix
    *A* using the following steps:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述观察，我们可以使用以下步骤计算一个*m* × *n*矩阵*A*的SVD。
- en: Construct the matrix *AᵗA*.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构造矩阵*AᵗA*。
- en: Compute the eigenvalues and eigenvectors of *AᵗA*. The eigenvalues will be the
    squares of the singular values of *A*, and the eigenvectors will form the columns
    of the matrix *V* in the SVD.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算*AᵗA*的特征值和特征向量。特征值将是*A*的奇异值的平方，特征向量将形成矩阵*V*在SVD中的列。
- en: Arrange the singular values of *A* in descending order. Create an *m* × *n*
    diagonal matrix Σ with the singular values on the diagonal, padding with zeros
    if necessary so that the matrix has the same dimensions as *A*.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将矩阵*A*的奇异值按降序排列。创建一个*m* × *n* 的对角矩阵Σ，奇异值放在对角线上，如有必要可填充零，以使矩阵与*A*具有相同的维度。
- en: Normalize the eigenvectors of *AᵗA* to have unit length, and place them as columns
    of matrix *V*.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将*AᵗA*的特征向量归一化为单位长度，并将它们作为矩阵*V*的列。
- en: For each singular value *σᵢ*, calculate the corresponding left-singular vector
    **u***ᵢ* as
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个奇异值*σᵢ*，计算相应的左奇异向量**u***ᵢ*为：
- en: '![](../Images/c21f44352bebcf44ded85f4b62127668.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c21f44352bebcf44ded85f4b62127668.png)'
- en: where **v***ᵢ* is the *i*-th column of *V*. Place these vectors as columns in
    the matrix *U*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 其中**v***ᵢ*是*V*的第*i*列。将这些向量作为列放入矩阵*U*中。
- en: If *n* < *m* or *A* is rank-deficient (i.e., rank(*A*) < min(*m*, *n*)), then
    there would not be enough non-zero singular values to determine the columns of
    *U*. In this case, we need to complete *U* to an orthogonal matrix by finding
    additional orthonormal vectors that span the null space (kernel) of *Aᵗ*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*n* < *m* 或*A*是秩亏的（即，rank(*A*) < min(*m*, *n*）），那么没有足够的非零奇异值来确定*U*的列。在这种情况下，我们需要通过找到额外的正交向量来完成*U*，这些向量生成*Aᵗ*的零空间（核）。
- en: The **null space** of *Aᵗ*, denoted *N*(*Aᵗ*), is theset of vectors **x** such
    that *Aᵗ***x** = **0**, which are also theeigenvectors of *AAᵗ* corresponding
    to eigenvalue 0 (since *AAᵗ***x** = 0⋅**x)**. To find an orthonormal basis for
    *N*(*Aᵗ*), we first solve the homogenous linear system *Aᵗ***x** = **0** to find
    a basis for *N*(*Aᵗ*), then use the [Gram-Schmidt process](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process)
    on this set of basis vectors to make them orthogonal, and finally we normalize
    them into unit vectors.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*Aᵗ*的**零空间**，记作*N*(*Aᵗ*），是满足*Aᵗ***x** = **0**的向量**x**的集合，这些向量也是*AAᵗ*的特征值为0的特征向量（因为*Aᵗ**x**
    = 0⋅**x**）。要找到*N*(*Aᵗ*)的正交基，我们首先解齐次线性系统*Aᵗ***x** = **0**以找到*N*(*Aᵗ*)的基，然后对这组基向量应用[Gram-Schmidt
    过程](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process)使它们正交，最后将它们归一化为单位向量。'
- en: Another way to find the left-singular vectors of *A* (the columns of *U*) is
    to compute the eigenvectors of *AAᵗ*, but this process is usually more time consuming
    than using the relationship between the left and right singular vectors (observation
    4) and computing the null space of *Aᵗ* (if necessary).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 找到*A*的左奇异向量（*U*的列）的另一种方法是计算*AAᵗ*的特征向量，但这种方法通常比使用左奇异向量和右奇异向量之间的关系（观察4）以及计算*Aᵗ*的零空间（如有必要）更耗时。
- en: 'Note that it is also possible to start the SVD computation by finding the left-singular
    vectors (i.e., the eigenvectors of *AAᵗ*), and then use the following relationship
    to find the right singular vectors:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，也可以通过找到左奇异向量（即*AAᵗ*的特征向量）来开始SVD计算，然后使用以下关系找到右奇异向量：
- en: '![](../Images/110ed3cc815bf70840c1c8596582dc58.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/110ed3cc815bf70840c1c8596582dc58.png)'
- en: The choice of using either *AAᵗ* or *AᵗA* depends on which matrix is smaller.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 选择使用 *AAᵗ* 或 *AᵗA* 取决于哪个矩阵较小。
- en: Numerical Example
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数值示例
- en: 'For example, let’s compute the SVD of the following matrix:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们计算以下矩阵的 SVD：
- en: '![](../Images/7863fab4be0889643756280c8720f074.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7863fab4be0889643756280c8720f074.png)'
- en: Let *U*Σ*Vᵗ* be the SVD of *A*. The dimensions of *A* are 3 × 2\. Therefore,
    the size of *U* is 3 × 3, the size of Σ is 3 × 2, and the size of *V* is 2 × 2.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 设 *U*Σ*Vᵗ* 为 *A* 的奇异值分解（SVD）。*A* 的维度是 3 × 2\. 因此，*U* 的大小是 3 × 3，Σ 的大小是 3 × 2，而
    *V* 的大小是 2 × 2。
- en: Since the size of *AᵗA* (2 × 2) is smaller than the size of *AAᵗ* (3 × 3), it
    makes sense to start with the right-singular vectors of *A*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *AᵗA* (2 × 2) 的大小小于 *AAᵗ* (3 × 3) 的大小，因此从 *A* 的右奇异向量开始是有意义的。
- en: 'We first compute *AᵗA*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先计算 *AᵗA*：
- en: '![](../Images/fc515d2380b0e69037162789a3e5604f.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc515d2380b0e69037162789a3e5604f.png)'
- en: 'We now find the eigenvalues and eigenvectors of *AᵗA*. The characteristic polynomial
    of the matrix is:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在找到 *AᵗA* 的特征值和特征向量。矩阵的特征多项式为：
- en: '![](../Images/5e37c8b5642652f5f68643e9c39aa19c.png)![](../Images/834eef5899cb68f07136bb858a00414e.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e37c8b5642652f5f68643e9c39aa19c.png)![](../Images/834eef5899cb68f07136bb858a00414e.png)'
- en: 'The roots of this polynomial are:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这个多项式的根是：
- en: '![](../Images/3ab34c0275d4936e09527d087060f4ec.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ab34c0275d4936e09527d087060f4ec.png)'
- en: 'The eigenvalues of *AᵗA* in descending order are *λ*₁ *=* 9 and *λ*₂ = 1\.
    Therefore, the singular values of *A* are *σ*₁ = 3 and *σ*₂ = 1, and the matrix
    Σ is:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*AᵗA* 的特征值按降序排列为 *λ*₁ *=* 9 和 *λ*₂ = 1\. 因此，*A* 的奇异值为 *σ*₁ = 3 和 *σ*₂ = 1，矩阵
    Σ 为：'
- en: '![](../Images/c3776d71f19bdc5b4fda4fdd6e39cf3d.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3776d71f19bdc5b4fda4fdd6e39cf3d.png)'
- en: We now find the right singular vectors (the columns of *V*) by finding an orthonormal
    set of eigenvectors of *AᵗA.*
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在通过找到 *AᵗA* 的一组正交标准特征向量来找到右奇异向量（*V* 的列）。
- en: 'The eigenvectors corresponding to *λ*₁ *=* 9 are:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对应于 *λ*₁ *=* 9 的特征向量是：
- en: '![](../Images/50e703ab654f3dbddbe3d5143c556689.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50e703ab654f3dbddbe3d5143c556689.png)'
- en: 'Therefore, the eigenvectors are of the form **v**₁ = (*t*, *t*). For a unit-length
    eigenvector we need:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，特征向量的形式为 **v**₁ = (*t*, *t*)。为了得到单位长度的特征向量，我们需要：
- en: '![](../Images/8d93b0c39847d3e4f6c57f4bcba1048b.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d93b0c39847d3e4f6c57f4bcba1048b.png)'
- en: 'Thus, the unit eigenvector corresponding to *λ*₁ =9 is:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对应于 *λ*₁ =9 的单位特征向量是：
- en: '![](../Images/bc3ffc48e7cca566f3f1c7df5dbd05a3.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc3ffc48e7cca566f3f1c7df5dbd05a3.png)'
- en: 'Similarly, the eigenvectors corresponding to *λ*₂ = 1 are:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对应于 *λ*₂ = 1 的特征向量是：
- en: '![](../Images/f7185037c3919b7ee925753a226065c9.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7185037c3919b7ee925753a226065c9.png)'
- en: Therefore, the eigenvectors are of the form **v**₂ = (*t*, *t*). For a unit-length
    eigenvector we need
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，特征向量的形式为 **v**₂ = (*t*, *t*)。为了得到单位长度的特征向量，我们需要
- en: '![](../Images/c32ff60f94a25186ab5863ef19258d5e.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c32ff60f94a25186ab5863ef19258d5e.png)'
- en: 'Thus, the unit eigenvector corresponding to *λ*₂=1 is:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*λ*₂=1 对应的单位特征向量是：
- en: '![](../Images/616619eddbf0b6fb58ba11aa00b67061.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/616619eddbf0b6fb58ba11aa00b67061.png)'
- en: 'We can now write the matrix *V*, whose columns are the vectors **v**₁ and **v**₂:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以写出矩阵 *V*，其列为向量 **v**₁ 和 **v**₂：
- en: '![](../Images/6351f3a52d7178db921d5d4f88b5d18a.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6351f3a52d7178db921d5d4f88b5d18a.png)'
- en: 'Lastly, we find the left-singular vectors of *A*. From observation 4, it follows
    that:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们找到 *A* 的左奇异向量。从观察 4 中可以得出：
- en: '![](../Images/9beead040a784812facb1db49f382a47.png)![](../Images/486b62402fedddcdd13ede9f3eb24022.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9beead040a784812facb1db49f382a47.png)![](../Images/486b62402fedddcdd13ede9f3eb24022.png)'
- en: Since there is only one remaining column vector of *U*, instead of computing
    the kernel of *Aᵗ*, we can simplyfind a unit vector that is perpendicular to both
    **u**₁ and **u**₂.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 由于只剩下一个 *U* 的列向量，我们可以直接找到一个垂直于 **u**₁ 和 **u**₂ 的单位向量，而不是计算 *Aᵗ* 的核。
- en: Let **u**₃ = (*a*, *b*, *c*). To be perpendicular to **u**₂ we need *a* = *b*.
    Then the condition **u**₃*ᵗ***u**₁ = 0 becomes
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 设 **u**₃ = (*a*, *b*, *c*)。为了垂直于 **u**₂，我们需要 *a* = *b*。然后条件 **u**₃*ᵗ***u**₁
    = 0 变为
- en: '![](../Images/9c8519c4529d48cad0a8c973579212e7.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c8519c4529d48cad0a8c973579212e7.png)'
- en: Therefore,
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，
- en: '![](../Images/6b966381dacc639dbdc3ccdbb8bdd37a.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b966381dacc639dbdc3ccdbb8bdd37a.png)'
- en: For the vector to be unit-length, we need
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使向量长度为单位，我们需要
- en: '![](../Images/1a0d95b6f7fe2a1bf236bf24a375f126.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a0d95b6f7fe2a1bf236bf24a375f126.png)'
- en: Thus,
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，
- en: '![](../Images/b1ede1a29a0a754de74452845f6968ca.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1ede1a29a0a754de74452845f6968ca.png)'
- en: 'And the matrix *U* is:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 而矩阵 *U* 为：
- en: '![](../Images/13dc3c108f7528dd53d58bf1a21c02d5.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13dc3c108f7528dd53d58bf1a21c02d5.png)'
- en: 'The final SVD of *A* in its full glory is:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*A* 的最终完整 SVD 为：'
- en: '![](../Images/37569562af67c034776853c773235120.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37569562af67c034776853c773235120.png)'
- en: Computing SVD with NumPy
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 NumPy 计算 SVD
- en: To compute the SVD of a matrix using numpy, you can call the function `[np.linalg.svd](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html)`.
    Given a matrix *A* with shape (*m*, *n*), the function returns a tuple (*U*, *S*,
    *Vᵗ*), where *U* is a matrix with shape (*m*, *m*) containing the left- singular
    vectors in its columns, *S* is a vector of size *k* =min(*m*, *n*) containing
    the singular values in descending order, and *Vᵗ* is a matrix with shape (*n*,
    *n*) containing the right singular vectors in its rows.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 numpy 计算矩阵的 SVD，可以调用函数 `[np.linalg.svd](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html)`。给定一个形状为
    (*m*，*n*) 的矩阵 *A*，该函数返回一个元组 (*U*，*S*，*Vᵗ*)，其中 *U* 是一个形状为 (*m*，*m*) 的矩阵，包含左奇异向量在其列中，*S*
    是一个大小为 *k* = min(*m*，*n*) 的向量，包含按降序排列的奇异值，而 *Vᵗ* 是一个形状为 (*n*，*n*) 的矩阵，包含右奇异向量在其行中。
- en: 'For example, let’s use this function to compute the SVD of the matrix from
    the previous example:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用这个函数来计算之前示例中矩阵的 SVD：
- en: '[PRE0]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output we get is:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出是：
- en: '[PRE1]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This is the same SVD decomposition we have obtained with our manual computation,
    up to a sign difference (e.g., the first column of *U* has flipped direction).
    This shows that an SVD decomposition of a matrix is not entirely unique. While
    the singular values themselves are unique, the associated singular vectors (i.e.,
    the columns of *U* and *V*) are not strictly unique due to the following reasons:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们通过手动计算得到的相同 SVD 分解，只是符号有所不同（例如，*U* 的第一列方向已翻转）。这表明，矩阵的 SVD 分解不是完全唯一的。虽然奇异值本身是唯一的，但相关的奇异向量（即
    *U* 和 *V* 的列）由于以下原因不是严格唯一的：
- en: If a singular value is repeated, the corresponding singular vectors can be chosen
    to be any orthonormal set that spans the associated eigenspace.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果奇异值重复，则可以选择任何正交归一集来填满相关的特征空间。
- en: Even if the singular values are distinct, the corresponding singular vectors
    can be multiplied by -1 (i.e., their direction can be flipped) and still form
    a valid SVD.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 即使奇异值不同，对应的奇异向量也可以乘以 -1（即，它们的方向可以被翻转），仍然可以形成有效的 SVD。
- en: Compact SVD
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 紧凑 SVD
- en: The compact singular value decomposition is a reduced form of the full SVD,
    which retains only the non-zero singular values and their corresponding singular
    vectors.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 紧凑奇异值分解是完整 SVD 的简化形式，仅保留非零奇异值及其对应的奇异向量。
- en: 'Formally, the compact SVD of an *m* × *n* matrix *A* with rank *r* (*r* ≤ min{*m*,
    *n*}) is a factorization of the form *A* = *Uᵣ*Σ*ᵣVᵣᵗ*, where:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 正式来说，一个 *m* × *n* 矩阵 *A* 的紧凑 SVD（秩为 *r*（*r* ≤ min{*m*，*n*}））的分解形式是 *A* = *Uᵣ*Σ*ᵣVᵣᵗ*，其中：
- en: '*Uᵣ* is an *m* × *r* matrix whose columns are the first *r* left-singular vectors
    of *A*.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Uᵣ* 是一个 *m* × *r* 的矩阵，其列是 *A* 的前 *r* 个左奇异向量。'
- en: Σ*ᵣ* is an *r* × *r* diagonal matrix with the *r* non-zero singular values on
    the diagonal.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Σ*ᵣ* 是一个 *r* × *r* 的对角矩阵，对角线上是 *r* 个非零奇异值。
- en: '*Vᵣ* is an *n* × *r* matrix whose columns are the first *r* right-singular
    vectors of *A*.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Vᵣ* 是一个 *n* × *r* 的矩阵，其列是 *A* 的前 *r* 个右奇异向量。'
- en: 'For example, the rank of the matrix from our previous example is 2, since it
    has two non-zero singular values. Therefore, its compact SVD decomposition is:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们之前示例中的矩阵的秩为 2，因为它有两个非零奇异值。因此，它的紧凑 SVD 分解为：
- en: '![](../Images/d2c05c5c19fd1d7568c9164624fe7fdd.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2c05c5c19fd1d7568c9164624fe7fdd.png)'
- en: The matrices *Uᵣ*, Σ*ᵣ* and *Vᵣ* contain only the essential information needed
    to reconstruct the matrix *A*. The compact SVD can yield significant savings in
    storage and computation, especially for matrices with many zero singular values
    (i.e., when *r* << min{*m*, *n*}).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 *Uᵣ*、Σ*ᵣ* 和 *Vᵣ* 仅包含重构矩阵 *A* 所需的基本信息。紧凑 SVD 可以显著节省存储和计算，尤其是对于具有许多零奇异值的矩阵（即，当
    *r* << min{*m*，*n*}）。
- en: Truncated SVD
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 截断 SVD
- en: Truncated (reduced) SVD is a variation of SVD used for approximating the original
    matrix *A* with a matrix of a lower rank.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 截断（简化）SVD 是 SVD 的一种变体，用于用较低秩的矩阵来近似原始矩阵 *A*。
- en: 'To create a truncated SVD of a matrix *A* with rank *r*, we take only the *k*
    < *r* largest singular values and their corresponding singular vectors (*k* is
    a parameter). This gives us an approximation of the original matrix *Aₖ* = *Uₖ*Σ*ₖVₖᵗ*,
    where:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个具有秩 *r* 的矩阵 *A* 的截断 SVD，我们仅取前 *k* < *r* 个最大奇异值及其对应的奇异向量（*k* 是一个参数）。这给出了原矩阵
    *Aₖ* 的近似，即 *Aₖ* = *Uₖ*Σ*ₖVₖᵗ*，其中：
- en: '*Uₖ* is an *m* × *k* matrix whose columns are the first *k* left-singular vectors
    of *A*, corresponding to the *k* largest singular values.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Uₖ* 是一个 *m* × *k* 的矩阵，其列是 *A* 的前 *k* 个左奇异向量，对应于 *k* 个最大的奇异值。'
- en: Σ*ₖ* is an *k* × *k* diagonal matrix with the *k* largestsingular values on
    the diagonal.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Σ*ₖ* 是一个 *k* × *k* 的对角矩阵，对角线上是 *k* 个最大的奇异值。
- en: '*Vₖ* is an *n* × *k* matrix whose columns are the first *k* right-singular
    vectors of *A*,corresponding to the *k* largest singular values.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Vₖ* 是一个 *n* × *k* 的矩阵，其列是 *A* 的前 *k* 个右奇异向量，对应于 *k* 个最大的奇异值。'
- en: '![](../Images/b1a390420d641eabcdfa226bb2fc661b.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1a390420d641eabcdfa226bb2fc661b.png)'
- en: Truncated SVD
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 截断 SVD
- en: 'For example, we can truncate the matrix from the previous example to have a
    rank of *k* = 1 by taking only the largest single value and its corresponding
    vectors:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以通过仅取最大单一值及其对应向量，将前面例子的矩阵截断到秩 *k* = 1：
- en: '![](../Images/1cd29a6bf53e41bd6ccfdb35c218bcc2.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cd29a6bf53e41bd6ccfdb35c218bcc2.png)'
- en: 'In NumPy, the truncated SVD can be easily computed using the following code
    snippet:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在 NumPy 中，可以使用以下代码片段轻松计算截断 SVD：
- en: '[PRE2]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Truncated SVD is particularly effective, since the truncated matrix *Aₖ* is
    the best rank-*k* approximation of the matrix *A* in terms of both the Frobenius
    norm (the least squares difference) and the 2-norm, i.e.,
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 截断 SVD 特别有效，因为截断矩阵 *Aₖ* 在 Frobenius 范数（最小二乘差异）和 2-范数方面都是矩阵 *A* 的最佳秩-*k* 近似，即：
- en: '![](../Images/e0e1bb4d47b09953c2f4f85d5300f3d0.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0e1bb4d47b09953c2f4f85d5300f3d0.png)'
- en: This result is known as the **Eckart-Young-Mirsky theorem** or the matrix approximation
    lemma, and its proof can be found in this [Wikipedia page](https://en.wikipedia.org/wiki/Low-rank_approximation).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果被称为**Eckart-Young-Mirsky 定理**或矩阵近似引理，其证明可以在这个[维基百科页面](https://en.wikipedia.org/wiki/Low-rank_approximation)中找到。
- en: The choice of *k* controls the tradeoff between approximation accuracy and the
    compactness of the representation. A smaller *k* results in a more compact matrix
    but a rougher approximation. In real-world data matrices, only a very small subset
    of the singular values are large. In such cases, *Aₖ* can be a very good approximation
    of *A* by retaining the few singular values that are large.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '*k* 的选择控制了近似精度与表示紧凑性之间的权衡。较小的 *k* 会导致矩阵更紧凑，但近似更粗糙。在实际数据矩阵中，只有非常小的奇异值较大。在这种情况下，*Aₖ*
    通过保留少量较大的奇异值，可以很好地近似 *A*。'
- en: Dimensionality Reduction with Truncated SVD
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 截断 SVD 降维
- en: 'Using the truncated SVD, it is also possible to reduce the number of dimensions
    (features) in the data matrix *A*. To reduce the dimensionality of *A* from *n*
    to *k*, we project the matrix rows onto the space spanned by the first *k* right-singular
    vectors. This is done by multiplying the original data matrix *A* by the matrix
    *Vₖ*:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用截断 SVD，也可以减少数据矩阵 *A* 的维度（特征）。为了将 *A* 的维度从 *n* 降到 *k*，我们将矩阵行投影到由前 *k* 个右奇异向量张成的空间。这是通过将原始数据矩阵
    *A* 乘以矩阵 *Vₖ* 来完成的：
- en: '![](../Images/7004da42b377d58a89dc4bb0ee1527ba.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7004da42b377d58a89dc4bb0ee1527ba.png)'
- en: The reduced matrix now has dimensions *n* × *k* and contains the projection
    of the original data onto the *k*-dimensional subspace. Its columns are the new
    features in the reduced dimensional space. These features are linear combinations
    of the original features and are orthogonal to each other.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 降维矩阵现在具有 *n* × *k* 的维度，并包含原始数据在 *k* 维子空间上的投影。它的列是降维空间中的新特征。这些特征是原始特征的线性组合，并且彼此正交。
- en: 'Using our previous example, we can reduce the number of dimensions of our data
    matrix *A* from 2 to 1 as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们之前的例子，我们可以将数据矩阵 *A* 的维度从 2 降到 1，如下所示：
- en: '![](../Images/98c43b99316ef3dca3c3acfcb5da6b6b.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98c43b99316ef3dca3c3acfcb5da6b6b.png)'
- en: 'Another way to compute the reduced matrix is based on the following observation:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种计算降维矩阵的方法基于以下观察：
- en: '![](../Images/6ee1e4598c87a05d490eb22a10379ac9.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ee1e4598c87a05d490eb22a10379ac9.png)'
- en: '*Proof*: The full SVD of *A* is *A* = *U*Σ*Vᵗ*, therefore *AV* = *U*Σ. By comparing
    the *j*-th columns of each side of the equation we get:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*：*A* 的完整 SVD 是 *A* = *U*Σ*Vᵗ*，因此 *AV* = *U*Σ。通过比较方程两边的 *j* 列，我们得到：'
- en: '![](../Images/2245c489796bac445c0173ec2094c1de.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2245c489796bac445c0173ec2094c1de.png)'
- en: Therefore, all the columns of *AVₖ* are equal to all the columns of *Uₖ*Σ*ₖ*,
    so the two matrices must be equal.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*AVₖ* 的所有列都等于 *Uₖ*Σ*ₖ* 的所有列，因此这两个矩阵必须相等。
- en: Using *Uₖ*Σ*ₖ* is a more efficient way to compute the reduced matrix, because
    it requires to multiply matrices of size *m* × *k* and *k* × *k*, instead of matrices
    of size *m* × *n* and *n* × *k* (*k* is typically much smaller than *n*).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 *Uₖ*Σ*ₖ* 是计算降维矩阵的更高效的方法，因为它只需乘以 *m* × *k* 和 *k* × *k* 的矩阵，而不是 *m* × *n* 和
    *n* × *k* 的矩阵（*k* 通常比 *n* 小得多）。
- en: 'In our previous example:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中：
- en: '![](../Images/11ca2dc913d0b4796eef207009154bdf.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11ca2dc913d0b4796eef207009154bdf.png)'
- en: Dimensionality reduction using truncated SVD is often used as a data preprocessing
    step before machine learning tasks such as classification or clustering, where
    it helps dealing with the [curse of dimensionality](https://medium.com/ai-made-simple/what-is-the-curse-of-dimensionality-b9b4b81a25c5),
    reduce computational costs and potentially improve the performance of the machine
    learning algorithm.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 使用截断 SVD 进行降维通常作为机器学习任务（如分类或聚类）之前的数据预处理步骤，这有助于处理[维度灾难](https://medium.com/ai-made-simple/what-is-the-curse-of-dimensionality-b9b4b81a25c5)，减少计算成本，并可能提高机器学习算法的性能。
- en: 'To reduce the dimensionality of new data points that arrive after the machine
    learning model has been trained (e.g., samples in the test set), we simply project
    them onto the same subspace spanned by the first *k* right-singular vectors of
    *A*:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要对训练完成后的新数据点（例如测试集中的样本）进行降维，我们只需将它们投影到 *A* 的前 *k* 个右奇异向量张成的相同子空间上：
- en: '![](../Images/778903ab270b9e709c230fecd5fc8f55.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/778903ab270b9e709c230fecd5fc8f55.png)'
- en: Recall that our convention is to express each vector **x** as a column vector,
    while data points are stored as rows of *A*, which is why we left-multiply **x**
    by *Vₖᵗ* instead of right multiplying it by *Vₖ*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们的惯例是将每个向量 **x** 表示为列向量，而数据点以 *A* 的行形式存储，这就是为什么我们用 *Vₖᵗ* 左乘 **x** 而不是右乘
    *Vₖ*。
- en: Reconstruction Error
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重建误差
- en: A key metric in assessing the effectiveness of dimensionality reduction techniques
    is called the **reconstruction error**. It provides a quantitative measure of
    the loss of information resulting from the reduction process.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 评估降维技术效果的一个关键指标叫做**重建误差**。它提供了一个定量衡量降维过程导致信息丢失的指标。
- en: 'To measure the reconstruction error of a specific vector, we first project
    it back onto the original space spanned by the *m* right-singular vectors. This
    is done by multiplying *Vₖ* by the reduced vector:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量特定向量的重建误差，我们首先将其投影回由 *m* 个右奇异向量张成的原始空间。这是通过将 *Vₖ* 乘以降维后的向量来完成的：
- en: '![](../Images/08f100f85c777f0b6352415cccd8c4af.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08f100f85c777f0b6352415cccd8c4af.png)'
- en: 'We then measure the reconstruction error as the mean squared error (MSE) between
    the reconstructed components of the vector and the original components:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将重建误差测量为向量重建组件与原始组件之间的均方误差（MSE）：
- en: '![](../Images/e4b8fb15bc8ea0a768763b9cf3ef1843.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4b8fb15bc8ea0a768763b9cf3ef1843.png)'
- en: 'We can also measure the reconstruction error of the entire matrix *A* by projecting
    the reduced matrix rows back onto the original space spanned by the *m* right-singular
    vectors. This is done by multiplying the reduced *A* by the transpose of *Vₖ*:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过将降维后的矩阵行投影回由 *m* 个右奇异向量张成的原始空间来测量整个矩阵 *A* 的重建误差。这是通过将降维后的 *A* 乘以 *Vₖ*
    的转置来完成的：
- en: '![](../Images/f4db376362f03e7ae341dc5011d6781c.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4db376362f03e7ae341dc5011d6781c.png)'
- en: 'We can then use either the MSE between the elements of the reconstructed matrix
    and the original elements, or the Frobenius norm of the difference between the
    two matrices:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用重建矩阵与原始元素之间的均方误差（MSE）或两个矩阵之间差异的弗罗贝纽斯范数：
- en: '![](../Images/bf18b90e913c87acecaee380bc703b4d.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf18b90e913c87acecaee380bc703b4d.png)'
- en: 'For example, the reconstructed matrix of the reduced matrix from our previous
    example is:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们之前示例中降维矩阵的重建矩阵是：
- en: '![](../Images/e2739756ecfa713d0dc68120496a2568.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2739756ecfa713d0dc68120496a2568.png)'
- en: 'And the reconstruction error is:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 重建误差为：
- en: '![](../Images/f4141ea0e68f78cacf9658d132b0e8b8.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4141ea0e68f78cacf9658d132b0e8b8.png)'
- en: Truncated SVD in Scikit-Learn
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit-Learn 中的截断 SVD
- en: 'Scikit-Learn provides an efficient implementation of truncated SVD in the class
    `[sklearn.decomposition.TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)`.
    Its important parameters are:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Learn 提供了 `sklearn.decomposition.TruncatedSVD` 类的高效实现。其重要参数包括：
- en: '`n_components`: Desired number of dimensions for the output data (defaults
    to 2).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_components`：输出数据的期望维度数量（默认为2）。'
- en: '`algorithm`: The SVD solver to use. Can be one of the following options:'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`algorithm`：要使用的SVD求解器。可以是以下选项之一：'
- en: 1\. `‘arppack’` uses the [ARPACK wrapper](https://docs.scipy.org/doc/scipy/tutorial/arpack.html)
    in SciPy to compute the eigen-decomposition of *AAᵗ* or *AᵗA* (whichever is more
    efficient). ARPACK is an iterative algorithm that efficiently computes a few eigenvalues
    and eigenvectors of large sparse matrices.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1\. `‘arppack’` 使用[ARPACK包装器](https://docs.scipy.org/doc/scipy/tutorial/arpack.html)在SciPy中计算*AAᵗ*或*AᵗA*的特征分解（以更高效的方式）。ARPACK是一个迭代算法，能高效地计算大稀疏矩阵的几个特征值和特征向量。
- en: 2\. `‘randomized’` (the default) uses a fast randomized SVD solver based on
    an algorithm by Halko et al. [1].
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2\. `‘randomized’`（默认）使用基于Halko等人算法的快速随机SVD求解器[1]。
- en: '`n_iter`: The number of iterations for the randomized SVD solver (defaults
    to 5).'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_iter`：随机SVD求解器的迭代次数（默认为5）。'
- en: 'For example, let’s demonstrate the usage of this class on our matrix from the
    previous example:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们演示如何在之前示例中的矩阵上使用此类：
- en: '[PRE4]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output we get is the reduced matrix:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出是减少后的矩阵：
- en: '[PRE5]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Example: Image Compression'
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：图像压缩
- en: Singular value decomposition can be used for image compression. Although an
    image matrix is often of full rank, its lower ranks usually have very small singular
    values. Thus, truncated SVD can lead to a significant reduction in the image size
    without losing too much information.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 奇异值分解可用于图像压缩。尽管图像矩阵通常是满秩的，但其较低的秩通常具有非常小的奇异值。因此，截断SVD可以显著减少图像大小，而不会丢失太多信息。
- en: 'For example, we will demonstrate how to use truncated SVD to compress the following
    image:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们将演示如何使用截断SVD压缩以下图像：
- en: '![](../Images/94b9e82024270d9e2cc85e5ee2df2eba.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94b9e82024270d9e2cc85e5ee2df2eba.png)'
- en: Photo taken by the author
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 作者拍摄的照片
- en: 'We first load the image into a NumPy array using the function `[matplotlib.pyplot.imread](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imread.html)`:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用函数`[matplotlib.pyplot.imread](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imread.html)`将图像加载到NumPy数组中：
- en: '[PRE6]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The shape of the image is:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的形状为：
- en: '[PRE7]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The height of the image is 1600 pixels, its width is 1200 pixels, and it has
    3 color channels (RGB).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的高度为1600像素，宽度为1200像素，具有3个颜色通道（RGB）。
- en: Since SVD can only be applied to 2D data, we can either execute it on each color
    channel separately, or we can reshape the image from a 3D matrix to a 2D matrix
    by flattening each color channel and stacking them horizontally (or vertically).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于SVD仅适用于二维数据，我们可以分别对每个颜色通道执行它，或者通过将每个颜色通道展平并水平（或垂直）堆叠，将图像从3D矩阵重塑为2D矩阵。
- en: 'For example, the following code snippet reshapes the image into a 2D matrix
    by stacking the color channels horizontally:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码片段通过水平堆叠颜色通道将图像重塑为2D矩阵：
- en: '[PRE9]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The shape of the flattened image is:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 展平图像的形状为：
- en: '[PRE10]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The rank of the image’s matrix is:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图像矩阵的秩为：
- en: '[PRE12]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The matrix is of full rank (since min(1600, 3600) = 1600).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵是满秩的（因为min(1600, 3600) = 1600）。
- en: 'Let’s plot the first 100 singular values of the matrix:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制矩阵的前100个奇异值：
- en: '[PRE14]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/abbf501b06d1601d8bbc75dac28a29e0.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/abbf501b06d1601d8bbc75dac28a29e0.png)'
- en: The first 100 singular values in the image
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图像中的前100个奇异值
- en: We can clearly see a rapid decay in the singular values. This decay means that
    we can effectively truncate the image without a significant loss of accuracy.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以清楚地看到奇异值的快速衰减。这种衰减意味着我们可以有效地截断图像，而不会显著损失精度。
- en: 'For example, let’s truncate the image to have a rank of 100 using Truncated
    SVD:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们使用Truncated SVD将图像截断到秩为100：
- en: '[PRE15]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The shape of the truncated image is:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 截断图像的形状为：
- en: '[PRE16]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The size of the truncated image is only 100/3600 = 2.78% of the original image!
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 截断图像的大小仅为原始图像的100/3600 = 2.78%！
- en: To see how much information was lost in the compression we can measure the image’s
    **reconstruction error**. We will measure the reconstruction error as the mean
    of squared errors (MSE) between the the pixel values of the original image and
    the reconstructed image.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看压缩中丢失了多少信息，我们可以测量图像的**重建误差**。我们将重建误差测量为原始图像与重建图像之间像素值的均方误差（MSE）。
- en: 'In Scikit-Learn, the reconstructed image can be obtained by calling the method
    `inverse_transform` of the `TruncatedSVD` transformer:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在Scikit-Learn中，可以通过调用`TruncatedSVD`转换器的`inverse_transform`方法来获得重建图像：
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Therefore, the reconstruction error is:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重建误差为：
- en: '[PRE19]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Thus, the root mean squared error (RMSE) between the pixel intensities in the
    original image and the reconstructed image is only about 5.41 (which is small
    relative to the range of the pixels [0, 255]).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，原始图像和重建图像之间的像素强度的均方根误差（RMSE）只有大约5.41（相对于像素范围[0, 255]来说很小）。
- en: 'To display the reconstructed image, we first need to reshape it into the original
    3D shape and then clip the pixel values to integers in the range [0, 255]:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 要显示重建图像，我们首先需要将其重新塑造成原始的3D形状，然后将像素值剪裁到[0, 255]范围内的整数：
- en: '[PRE21]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can now display the image using the `plt.imshow` function:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用`plt.imshow`函数显示图像：
- en: '[PRE22]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/02b156d5e18310d9a41d4f7f3758e108.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02b156d5e18310d9a41d4f7f3758e108.png)'
- en: The reconstructed image
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 重建图像
- en: We can see that the reconstruction at rank 100 loses only a small amount of
    detail.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，排名为100的重建仅丢失了少量细节。
- en: 'Let’s place all the above steps into a function that compresses a given 3D
    image to a specified number of dimensions and then reconstructs it:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将上述所有步骤放入一个函数中，该函数将给定的3D图像压缩到指定数量的维度，然后重建它：
- en: '[PRE23]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can now call this function with different number of components and examine
    the reconstructions:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以用不同数量的组件调用这个函数，并检查重建结果：
- en: '[PRE24]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/58308a6031323a4b706cbe2c7ec1fa98.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58308a6031323a4b706cbe2c7ec1fa98.png)'
- en: SVD reconstructions at different ranks
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 不同排名的SVD重建
- en: As we can see, using a rank that is too low, such as *k* = 10, can lead to a
    substantial loss of information, while an SVD of rank 200 is almost indistinguishable
    from the full-rank image.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，使用过低的排名，如*k* = 10，可能会导致信息的显著丢失，而排名为200的SVD几乎与全秩图像不可区分。
- en: In addition to compressing images, SVD can also be used to remove noise from
    images. This is because discarding the lower-order components of the image tends
    to remove the granular, noisy elements, while preserving the more significant
    parts of the image.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 除了压缩图像，SVD还可以用来去除图像中的噪声。这是因为丢弃图像的低阶成分倾向于去除细小的噪声元素，同时保留图像中更重要的部分。
- en: Applications of SVD
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVD的应用
- en: 'SVD is employed in many types of applications where it helps to uncover the
    latent features of the observed data. Examples include:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: SVD被应用于许多类型的应用程序中，它有助于揭示观察数据的潜在特征。示例包括：
- en: '[Latent semantic analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis)
    (LSA) is a technique in natural language processing that uncovers the latent relationships
    between words and text documents by reducing the dimensionality of text data using
    SVD.'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[潜在语义分析](https://en.wikipedia.org/wiki/Latent_semantic_analysis)（LSA）是自然语言处理中的一种技术，它通过使用SVD减少文本数据的维度，从而揭示词语和文本文档之间的潜在关系。'
- en: In recommendation systems, SVD is used to factorize the user-item interaction
    matrix, revealing latent features about user preferences and item properties,
    thus helping the predictive algorithms make more accurate recommendations.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在推荐系统中，SVD用于分解用户-项目交互矩阵，揭示有关用户偏好和项目属性的潜在特征，从而帮助预测算法做出更准确的推荐。
- en: SVD can be used to efficiently compute the [Moore-Penrose pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse),
    which is used in situations where a matrix is not invertible, such as computing
    the least squares solution to a linear system of equations that lacks a solution.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SVD可以用来高效计算[摩尔-彭若斯伪逆](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse)，这在矩阵不可逆的情况下使用，例如计算线性方程组的最小二乘解而该方程组没有解。
- en: Limitations of SVD
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVD的局限性
- en: 'SVD has several limitations, including:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: SVD有几个局限性，包括：
- en: Can be computationally intensive, especially for large matrices. The standard
    (non-randomized) implementation of SVD has a runtime complexity of *O*(*mn*²)
    if *m* ≥ *n*, or *O*(*m*²*n*) if *m* < *n*.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算可能会非常密集，特别是对于大矩阵。SVD的标准（非随机化）实现的运行时间复杂度为*O*(*mn*²)，如果*m* ≥ *n*，或者为*O*(*m*²*n*)，如果*m*
    < *n*。
- en: Requires to store the entire data matrix in memory, which makes it impractical
    for very large datasets or real-time applications.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要将整个数据矩阵存储在内存中，这使得它在非常大的数据集或实时应用中不切实际。
- en: Assumes that the relationships within the data are linear, which means that
    SVD may not be able to capture more complex, nonlinear interactions between the
    variables (features).
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设数据内部的关系是线性的，这意味着SVD可能无法捕捉变量（特征）之间更复杂的非线性交互。
- en: The latent features obtained from SVD are often not easy to interpret.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从SVD获得的潜在特征通常不容易解释。
- en: Standard SVD cannot handle missing data, which means that some form of imputation
    is needed, potentially introducing biases in the data.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标准 SVD 无法处理缺失数据，这意味着需要某种形式的填补，这可能会引入数据偏差。
- en: There is no simple way to update the SVD incrementally when new data arrives,
    which is needed in dynamic systems where the data changes frequently (such as
    real-time recommendation systems).
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当新数据到达时，没有简单的方法可以逐步更新 SVD，这在数据频繁变化的动态系统中（如实时推荐系统）是必需的。
- en: Final Notes
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的说明
- en: All the images are by the author unless stated otherwise.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者提供。
- en: 'You can find the code examples of this article on my github: [https://github.com/roiyeho/medium/tree/main/svd](https://github.com/roiyeho/medium/tree/main/svd)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在我的 GitHub 上找到本文的代码示例：[https://github.com/roiyeho/medium/tree/main/svd](https://github.com/roiyeho/medium/tree/main/svd)。
- en: Thanks for reading!
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: References
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Halko, N., Martinsson, P. G., & Tropp, J. A. (2011). Finding structure
    with randomness: Probabilistic algorithms for constructing approximate matrix
    decompositions. *SIAM review*, 53(2), 217–288.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Halko, N., Martinsson, P. G., & Tropp, J. A. (2011). Finding structure
    with randomness: Probabilistic algorithms for constructing approximate matrix
    decompositions. *SIAM review*, 53(2), 217–288。'
- en: '[2] Singular value decomposition, *Wikipedia, The Free Encyclopedia,* [https://en.wikipedia.org/wiki/Singular_value_decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] 奇异值分解，*维基百科，自由百科全书，* [https://en.wikipedia.org/wiki/Singular_value_decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)。'
