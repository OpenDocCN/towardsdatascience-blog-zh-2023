- en: 'Training Problem-Solving Skills in Data Science with Real-Life Simulations:
    A Role-Playing Dual-Chatbot Approach'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c](https://towardsdatascience.com/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A complete LLM project walk-through with code implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shuaiguo.medium.com/?source=post_page-----c80dec3dd08c--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----c80dec3dd08c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c80dec3dd08c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c80dec3dd08c--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----c80dec3dd08c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c80dec3dd08c--------------------------------)
    ·22 min read·Sep 4, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e415cad17323447a7606ec41a90f893.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Headway](https://unsplash.com/@headwayio?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: When I was learning data science and machine learning at university, the curriculum
    was geared heavily towards algorithms and machine learning techniques. I still
    remember those days cracking the math, not exactly fun, but nonetheless a rewarding
    process that had given me a solid foundation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once I graduated and started working as a data scientist, I soon realized the
    challenge: In real life, problems rarely present themselves as nicely formulated
    and readily addressable by machine learning techniques. It is the data scientist’s
    job to first define, scope, and convert the real-life problem into a machine-learning
    problem, before even talking about the algorithms. This is a crucial step as completely
    different approaches may be adopted depending on how the problem is formulated,
    what is the desired outcome, what data is available, the timeline, the budget,
    the computing infrastructure, and many other factors. In a word, it is not a simple
    math problem anymore.'
  prefs: []
  type: TYPE_NORMAL
- en: This gap in my data science training made me feel disoriented and pressured
    in the beginning. Luckily, I had my mentor and project colleagues, who helped
    me a lot in picking up the essentials and learning to ask the right questions.
    Step by step, I became more confident in managing data science projects.
  prefs: []
  type: TYPE_NORMAL
- en: Reflecting on my own experience, I really wish I could have the chance to learn
    those soft skills in data science to better prepare for my professional life.
    Now I have gone through the struggles, but is there anything I could do for the
    newly graduated data scientists?
  prefs: []
  type: TYPE_NORMAL
- en: A famous book for preparing interviews in management consulting is “Case in
    Point”. This book provides numerous practice case studies that cover a wide range
    of topics and industries. By observing and understanding how those case studies
    are solved, the candidates can learn quite a lot in practical problem-solving
    processes and be ready for real-life challenges.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspired by this case-study format, a thought occurred to me: Can we leverage
    the recent large language models (LLM) to generate relevant, diverse data science
    case studies on-demand and simulate the problem-solving process of a data scientist?
    This way, we could create a “Case in Point (*Data Science Edition*)” and help
    prepare the aspiring data scientist for real-life challenges.'
  prefs: []
  type: TYPE_NORMAL
- en: So, in this blog post, we will try to bring this idea to life. Specifically,
    we will walk through the process of developing a **role-playing dual-chatbot system**
    that can simulate problem-solving for data science problems.
  prefs: []
  type: TYPE_NORMAL
- en: Does this idea resonate with you? let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: '[NOTE]: All the prompts shown in this blog are generated and optimized by ChatGPT
    (GPT-4). This is necessary as it ensures the quality of the prompts and beneficial
    as it saves one from tedious manual prompt engineering.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is the 3rd blog on my series of LLM projects. The 1st one is [Building
    an AI-Powered Language Learning App](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd),
    and the 2nd one is [Developing an Autonomous Dual-Chatbot System for Research
    Paper Digesting](/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343).
    Feel free to check them out!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Table of Content
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**·** [**1\. Solution Strategy**](#a2f4)'
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [1.1 System overview](#831f)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [1.2 Abstract LLM class](#fe2f)
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**2\. Scenario Generation**](#7783)'
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [2.1 User options](#2cdc)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [2.2 Generation strategy](#b07c)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [2.3 Code implementation](#c1bf)
  prefs: []
  type: TYPE_NORMAL
- en: '∘ [2.4 Testing: Scenario generation](#2ef1)'
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**3\. Client-Data Scientist Simulation**](#9a4f)'
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [3.1 Client bot design](#5fb9)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [3.2 Data scientist bot design](#243f)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [3.3 Simulating conversation](#643d)
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**4\. Conversation Assessment**](#5d12)'
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4.1 Strategy overview](#f7fe)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4.2 Summarizer bot design](#e927)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4.3 Assessor bot design](#6409)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4.4 Testing the workflow](#ec52)
  prefs: []
  type: TYPE_NORMAL
- en: '**·** [**5\. Retrospective**](#98c2)'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Solution Strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1.1 System overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The foundation of our solution evolves around the concept of a **role-playing
    dual-chatbot system**. In essence, this system involves two chatbots (powered
    by large language models) taking on different **roles** and engaging in an **autonomous
    conversation**.
  prefs: []
  type: TYPE_NORMAL
- en: Given that our ultimate purpose is to simulate the real-life problem-solving
    process of a data scientist, a natural option for setting the roles of the chatbots
    can be **“client”** and **“data scientist”**, i.e., one bot plays the role of
    a client, who is seeking the solution for a problem its company is currently facing,
    and the other bot plays the role of a data scientist. Through their conversation,
    the data scientist bot will try to understand the problem in-depth and the client
    bot will clarify and confirm various aspects of the problem. Together, two bots
    collaborate to properly define and scope the problem, and agree on suitable machine
    learning solutions. In section 3, we will dive into the design of this dual-chatbot
    system.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/014320fcf6500e84632a9d956c99eaed.png)'
  prefs: []
  type: TYPE_IMG
- en: An illustration of the workflow of the client-data scientist dual-chatbot system.
    (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: To facilitate the client-data scientist conversation, we first need to generate
    a high-quality scenario description, and the produced description should be tailored
    to the user’s interests. More specifically, in my current design, the user can
    choose, e.g., their interested problem type, target industry, and business size.
    Then, a relevant, concrete data science project scenario will be generated accordingly,
    which will be subsequently fed to both bots to serve as the foundation for their
    dialogue. In section 2, we will discuss the design details of the scenario generation
    procedure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9bea0d3f2f59e0a8e7fcd81a5f309d2b.png)'
  prefs: []
  type: TYPE_IMG
- en: An illustration of the workflow of scenario generation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: To further enhance the user’s learning experience, it is beneficial to reflect
    on the conversation and extract the key learning points for the user to review.
    Those key learning points could include the specific strategyadopted by the data
    scientist bot in terms of scoping the problem, the various aspects covered/not
    covered in the conversation, as well as potential follow-up questions or topics
    for discussion. In section 4, we will take a close look at the design details
    of this assessment procedure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e66c122be6d7f88afd854fb23ead5bc9.png)'
  prefs: []
  type: TYPE_IMG
- en: An illustration of the workflow of analyzing conversation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, our entire system consists of scenario generation, conversation simulation,
    as well as conversation assessment modules, which can be depicted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ee25518f0681bde371cd9682a12ab9b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The entire system consists of three parts: scenario generation, conversation
    simulation, as well as conversation assessment. (Image by author)'
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Abstract LLM class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this blog, we will create different LLM bots for different purposes.
    To streamline the code, we can define an abstract base class `LLMBot` to serve
    as the template. We will use the versatile LangChain library to manage our interaction
    with the language model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For the LLM bot, we distinguish between a *chat* endpoint and a *completion*
    endpoint. The chat endpoint is designed for multi-round conversations (i.e., a
    chatbot), whereas the completion endpoint is designed for single-turn tasks. Different
    LLMs will be invoked based on which endpoint is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, we defined two common methods: `instruct()` is used to determine
    the LLM bot’s behavior, and `step()` is used to send input to the LLM bot and
    receive the bot’s response.'
  prefs: []
  type: TYPE_NORMAL
- en: With the template in place, we are prepared to create specific instances of
    LLM bots later. In the next sections, we will discuss the design of each sub-module
    of the system and its code implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Scenario Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s start with the scenario generation. The main objective of this module
    is to generate a concrete and detailed data science case study that is tailored
    to the user’s interests. In this section, we discuss two design considerations
    relevant to the scenario generation: the user options for defining the case study,
    and the strategy for generating the case study with LLM.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8a018736bfc62c4e5f693a2941943289.png)'
  prefs: []
  type: TYPE_IMG
- en: We focus on scenario generation in this section. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 User options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To define a case study that aligns with the user’s interests, we need to first
    get input from the user. Here, the strategy I adopted is to give the user a set
    of categories of options that are limited in number so that they are not overwhelmed,
    but also comprehensive enough to allow LLM to generate meaningful data science
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'After some experiments, I found the following three categories of options could
    serve as the seed for shaping the generated case study:'
  prefs: []
  type: TYPE_NORMAL
- en: 1️⃣ **Problem type**, defines the specific type of machine learning problems
    that the user is interested in learning. This category includes options such as
    *classification, regression, clustering, anomaly detection, recommendation, time
    series analysis, natural language processing,* and *computer vision*.
  prefs: []
  type: TYPE_NORMAL
- en: 2️⃣ **Target industry**, indicates which industry the user would like to see
    the application of the machine learning techniques. This category includes options
    such as *healthcare, finance, retail, technology, manufacturing, transportation,
    energy, real estate, education, government,* and *non-profit.*
  prefs: []
  type: TYPE_NORMAL
- en: 3️⃣ **Business size**,may suggest the complexity and constraints of the data
    science problem. This category includes options such as *small* (less than 100
    employees), *medium* (100–500 employees), and *large* (more than 500 employees).
  prefs: []
  type: TYPE_NORMAL
- en: After the user selects the option for each category, we need to generate a corresponding
    data science case study. How exactly can we do that?
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Generation strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have mentioned in the “strategy overview” section, we can employ an LLM
    (e.g., GPT-3.5) to achieve our goal.
  prefs: []
  type: TYPE_NORMAL
- en: Technically, I adopted a *staged* strategy with two passes of the LLM to create
    the desired description of the problem scenario. More specifically, in the first
    stage, the LLM was prompted to generate a *broad* description of the scenario;
    in the second stage, the LLM was prompted to *fill in the details* for the previously
    generated scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to getting everything from a single pass of the LLM, this staged approach
    mimics the process of ***draft-and-refine*** and therefore has a clear goal at
    each stage. As a result, it is easier for the LLM to follow our instructions and
    produce a final problem description that is more specific and detailed, which
    could better serve as the foundation for the subsequent client-data scientist
    conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Code implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given that the two stages are tightly connected, a chat endpoint (instead of
    a completion endpoint) would be a natural fit as it automatically keeps the context
    in memory. This way, we can simply ask the chat LLM two questions in turn (each
    question represents one stage) and use the chat model’s second answer as the final
    result.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the definition of the “scenario generator” bot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note that we set a high default temperature value for the backbone LLM as we
    want diversity in the generated case study scenarios. In the `self.instruct()`
    method, we introduced a new attribute `self.details`. This attribute specifies
    the extra details added to the problem description and will be useful for the
    2nd stage generation. Additionally, we have instantiated a `ConversationChain`
    to set up the scenario generator bot. Finally, in the `self.step()` method, we
    implemented the two-stage approach, and the bot’s response in the second stage
    is used as the final produced scenario description. Note that there is no need
    to re-input the LLM’s response in the 1st stage to the LLM in the 2nd stage. Since
    the scenario generator is a chatbot, its memory automatically carries the previous
    response to the next round of conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s take a closer look at the prompt used in the two stages. The purpose
    of the first stage is to draft a description of a typical data science scenario
    given the user input (i.e., industry, business size, and problem type). The prompt
    used there is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the prompt above, the scenario generator bot is explicitly asked to output
    the *problem description*, *desired outcome*, and *available data* for describing
    the data science scenario. Those three pieces of information constitute the foundation
    for the subsequent client-data scientist conversation.
  prefs: []
  type: TYPE_NORMAL
- en: For the second stage, the purpose is to enrich the scenario description obtained
    from the 1st stage with more tangible details. This is where the `self.details`
    come into play. The `ScenarioGenerator` class contains a class variable called
    `industry_specifics`, which is a dictionary with the keys being the industry names
    and values being the tangible details associated with a specific industry. A snippet
    of the dictionary is shown below as an example. The complete dictionary can be
    found in the companion [notebook](https://github.com/ShuaiGuo16/data_science_soft_skills_simulation)
    💻.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the prompt used in the 2nd stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '2.4 Testing: Scenario generation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To assess if the adopted two-stage approach can generate a concrete data science
    case study given the user input, we put the defined `ScenarioGenerator` class
    to a test. As an example, I selected the “manufacturing” industry, the “medium”
    business size, and the “anomaly detection” problem type, and passed them to the
    scenario generator bot to create a possible scenario.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The produced `scenario` is shown in the figure below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38c76e6cc114033323112c32c2fb6ce9.png)'
  prefs: []
  type: TYPE_IMG
- en: Scenario generator bot produced case study description. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the generated scenario contained very specific details and proposed
    a typical data science problem faced by the manufacturing industry. This shows
    that the scenario generator bot has followed our instructions closely and fulfilled
    our goal in a satisfactory manner. Later, the client-data scientist bot interaction
    will be based on this produced scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Client-Data Scientist Simulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key component of our entire system is the dual-chatbot interaction module.
    For our current problem, the two chatbots take the role of client and data scientist,
    respectively. The client bot is in charge of clarifying the situation and giving
    feedback on possible solutions, while the data scientist bot is in charge of understanding
    the problem in depth and proposing possible solutions. Collaboratively, they define
    and scope the data science project.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discuss the technical details of the dual-chatbot interaction.
    We will start by outlining the design of the two chatbots, followed by simulating
    their conversation based on the scenario generated from the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9a772731e394580fb0458922753e202e.png)'
  prefs: []
  type: TYPE_IMG
- en: We focus on the conversation simulation in this section. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Client bot design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start with the client bot design:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The definition of the `ClientBot` is quite similar to the `ScenarioGenerator`.
    Noticeable differences include:'
  prefs: []
  type: TYPE_NORMAL
- en: The `self.instruct()` method now takes the “scenario” generated by the `ScenarioGenerator`
    earlier as the input. This information will be used to guide the client bot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The instruction of the client bot is not fed as a direct prompt (like we did
    with the `ScenarioGenerator`) but rather a so-called `SystemMessage`. This is
    a common way to instruct the chatbot on how to behave during the entire conversation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `self.step()` method is simplified as the client will only need to respond
    to what the data scientist bot says (contained in the `prompt` variable).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, let’s examine the prompt design for the client bot. The overall goal
    of the prompt design should be to emphasize collaboration, clear communication,
    and problem definition. Meanwhile, it should also keep the chatbot’s responses
    aligned with its role (i.e., a client). To achieve this goal, we can structure
    it in a way that first sets the stage for the client bot, then informs it about
    the proposed problem, followed by setting the goals and guidelines to constrain
    its behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: One thing worth mentioning is that in the prompt, we gave the permission to
    let the bot *improvise* if the data scientist asks questions beyond what’s described
    in the `self.scenario`. The motivation for that is to further promote diversity.
  prefs: []
  type: TYPE_NORMAL
- en: That’s it for the client bot part. Let’s now switch gears to the data scientist
    bot.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Data scientist bot design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data scientist bot has almost the same class design as the client bot, except
    the the information input to the `self.instruct()` method, and the prompt design.
  prefs: []
  type: TYPE_NORMAL
- en: For the data scientist bot, we do not input the detailed problem description.
    It is the data scientist bot’s job to figure that out via discussing with the
    client bot. Instead, we simply inform it what type of machine learning problem
    the client is interested in.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As for the prompt design, it basically follows the same design philosophy as
    the client bot, with different focuses on understanding the problem and suggesting
    solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 3.3 Simulating conversation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we have set up both bots, let’s see what kind of conversation they will
    have!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The generated conversation script is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d4cf252294c4473097406ee510e8742.png)'
  prefs: []
  type: TYPE_IMG
- en: 1st round conversation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a24800ba5e51e6a1a5ddadacff71cfc.png)'
  prefs: []
  type: TYPE_IMG
- en: 2nd round conversation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/acd69edbbc581740f1893e5c37ee1485.png)'
  prefs: []
  type: TYPE_IMG
- en: 3rd round conversation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f32e7c51fb036632ecf4c1095f9c1c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 4th round conversation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6656d0feb86f799adbbf5976606ff7e.png)![](../Images/188402b0ecdc2d84a5843334e3474ada.png)'
  prefs: []
  type: TYPE_IMG
- en: 5th round conversation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/206b9e7ff0490a6688b3787fa40a978f.png)'
  prefs: []
  type: TYPE_IMG
- en: 6th round conversation. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the two bots have a very interesting and productive conversation😃.
    The data scientist bot asked probing questions to better understand the problem
    at hand, the client bot responded with necessary clarifications, and then the
    data scientist bot proposed solutions and explained how the solutions might work
    for the client’s case. Overall the conversation went as we would expect, and could
    potentially serve as valuable material for aspiring data scientists to learn practical
    problem-solving.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Conversation Assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To further enhance the learning experience, it could be useful to re-examine
    the generated conversation script and extract the key learning points. In this
    section, we discuss the final module of our system, the conversation assesser.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dd81eb5caf55a6f477b4074f671253c5.png)'
  prefs: []
  type: TYPE_IMG
- en: We focus on conversation assessment in this section. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Strategy overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create an assessment of the conversation, we could instantiate another LLM
    bot to achieve the goal. Here, we need to answer two questions: first, what information
    should be made available to the assessor bot? Second, how should we design the
    instruction/prompt for the assessor bot? Let’s investigate them one by one.'
  prefs: []
  type: TYPE_NORMAL
- en: For the first question, it is important that the assessor bot has knowledge
    of the basic problem settings. Meanwhile, it should also have access to the generated
    conversation script. The basic problem settings are already encapsulated in the
    user-selected “problem type”, “industry”, and “problem size”, thus providing them
    to the assessor bot is straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: However, for the generated conversation script, we need to be a bit careful.
    Usually, the conversation script can be quite lengthy. As a consequence, directly
    feeding in the entire conversation script may easily exceed the context window
    limit of the underlying LLM. On the other hand, for the assessor bot to make an
    assessment, it is actually not necessary for it to know all the details of the
    script. What really matters is the *logical flow* of the conversation. Therefore,
    we could have a “summarizer” bot to first summarize the conversation script, and
    later send the *condensed* script to the assessor bot to make the assessment.
    This staged strategy is illustrated in the figure below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a75baa7172ea175f1390882cb3ea036f.png)'
  prefs: []
  type: TYPE_IMG
- en: A staged strategy to first summarize the conversation script and then input
    it to the assessor bot to analyze the conversation between the client and data
    scientist bot. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: In the next two subsections, we discuss how to create the summarizer bot and
    how to design the prompt for the assessor bot.
  prefs: []
  type: TYPE_NORMAL
- en: '**4.2 Summarizer bot design**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start by constructing a class to define the summarizer bot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note that we are now using the *completion* endpoint, as the summarization is
    intended to be a one-time task and there is no need for the summarizer bot to
    keep the memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we set up the instructions for the summarizer bot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, our strategy is to loop over individual rounds of the conversation and
    extract their associated key points. Therefore, our `self.step()` method looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 4.3 Assessor bot design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the conversation summary ready, we can now focus on developing the assessor
    bot. Same as the summarizer bot, we invoke the *completion* endpoint for the assessor
    bot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we define the instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note that in the above prompt, we ask the assessor bot to act as a senior data
    scientist to provide feedback on the strategies adopted by the data scientist
    bot, as well as to indicate room for improvement. Both aspects are valuable for
    understanding the data science problem-solving process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, to invoke the assessor bot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 4.4 Testing the workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To test the workflow of the summarizer-assessor bot, we can feed in the previously
    generated conversation script and analyze how it goes. The produced assessment
    is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fcad37eaddbc4580dcc2c42f8db1b8d8.png)'
  prefs: []
  type: TYPE_IMG
- en: The assessment of how the data scientist bot did in the collaborative conversation
    with the client bot. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the assessor bot produced a useful analysis of how the data
    scientist bot performed in understanding the problem and proposing corresponding
    solutions. It also hinted at which aspects that were not covered. All those summaries
    can serve as valuable learning points.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Retrospective
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog, we investigated the problem of simulating real-world data science
    problem-solving processes, which could provide valuable insights for aspiring
    data scientists to prepare for practical challenges. Toward that end, we developed
    a system that constitutes a scenario generator bot, which generates a realistic,
    detailed description of data science scenarios, a client-data scientist dual-chatbot,
    which collaborative defines and scopes the problem, and an assessor bot, that
    analyzes the conversation and extracted the key learning points. Together, the
    system allows for generating interesting data science case studies on demand and
    possesses the potential as a learning tool that complements traditional, algorithm-focused
    machine learning education.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reflecting on what we have built, there are certainly many things to be improved:'
  prefs: []
  type: TYPE_NORMAL
- en: Although the initial results seemed promising, more tests are needed to assess
    if the same quality can be obtained for other industries, problem types, and business
    sizes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is important to investigate the sensitivity of different design decisions
    on the quality of the generated conversation. For example, one important design
    decision we made is that only the problem description, desired outcome, and data
    availability are presented in the generated scenario, and the client bot will
    improvise if any other information is requested by the data scientist bot. Is
    this a good choice? Would the conversation quality be higher if the generated
    scenario contained more information? It would be interesting to find out.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Currently, there are no explicit criteria to naturally stop the conversation,
    except a hard-coded number of exchanges we specified. I had a similar problem
    in my [previous project](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd),
    and I proposed two different strategies to handle this issue. Further investigation
    is necessary to see if those two strategies (or other strategies) could work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the current design, the only place where the user can influence the conversation
    is when specifying the inputs (e.g., problem type, etc.) for scenario generation.
    However, we can further enhance the user experience by allowing the user to participate
    in the conversation, either acting as the data scientist to ask clarifying questions/propose
    novel solutions, or acting as the client to provide missing details. A similar
    idea was also pursued in my [previous blog](https://medium.com/towards-data-science/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343).
    Feel free to check it out if you are interested in its implementation details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our developed system can also be extended to other learning settings. In the
    current blog, we only focused on the problem-solving aspect. However, we could
    also use the same system (with the right prompts of course) to simulate scenarios
    for project management, conflict management, communication, and many other important
    soft skills required by the data scientist role.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you find my content useful, you could buy me a coffee [here](https://www.buymeacoffee.com/Shuaiguo09f)
    🤗 Thank you very much for your support! As always, you can find the companion
    notebook with full code [here](https://github.com/ShuaiGuo16/data_science_soft_skills_simulation)
    💻 Looking forward to sharing with you more exciting LLM projects. Stay tuned!
  prefs: []
  type: TYPE_NORMAL
