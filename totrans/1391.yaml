- en: 'ü¶úüîóLangChain: Allow LLMs to interact with your code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/langchain-allow-llms-to-interact-with-your-code-55d5751aa8a2](https://towardsdatascience.com/langchain-allow-llms-to-interact-with-your-code-55d5751aa8a2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/ff27b1999a99a1cc7a7add035a1901f0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [David Clode](https://unsplash.com/@davidclode?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to implement custom functions for your LLM, using tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----55d5751aa8a2--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----55d5751aa8a2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----55d5751aa8a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----55d5751aa8a2--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----55d5751aa8a2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----55d5751aa8a2--------------------------------)
    ¬∑5 min read¬∑Jul 5, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative models are under everyone‚Äôs attention. Many AI applications now no
    longer require Machine Learning experts in the field but simply know how to Implement
    API calls.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, for example, I participated in a hackathon, and I had to implement
    a custom-named entity recognition, but I directly used an LLM and exploited its
    few-shot learner capability to get the result I wanted, which to win the hackathon
    was quite enough! (You can check the project [here](https://www.brianknows.org/)
    if you want).
  prefs: []
  type: TYPE_NORMAL
- en: So for many real-world applications, the focus is shifting more toward how to
    interact and use these LLMs rather than creating models. **LangChain** is a library
    that allows you to do just that, and I‚Äôve written several articles about it lately.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Tools are utilities that an LLM can use to augment its capabilities**. Tools
    can be instantiated within chains or agents.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, an LLM might conduct a Wikipedia search before responding to ensure
    an up-to-date response.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, an agent can use multiple tools, and so often what is done is to
    define a list of tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us now look at the anatomy of a tool. **A tool is nothing more than a class
    consisting of several fields**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**name** (str): defines a unique name of the tool'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**description** (str): a description of the tool‚Äôs utility in natural language.
    The LLM will be able to read this description and figure out whether or not it
    will need the tool to answer the query.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**return_direct** (bool): A tool might return the output of a custom function
    for example. Do we want that output to be presented directly to the user (True)
    or to be preprocessed by the LLM (False)?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**args_schema** (Pydantic BaseModel): For example, the tool might use a custom
    function whose input parameters must be retrieved from the user‚Äôs query. We can
    provide more information about each parameter so that the LLM can do this step
    more easily.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to define a tool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are **multiple approaches to defining a tool** that we will look at in
    this article. First, we import the necessary libraries and instantiate an OpenAI
    model.
  prefs: []
  type: TYPE_NORMAL
- en: To do this you will need a token, you can see in my previous article how to
    get it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**The first way to instantiate a tool is to use the Tool class.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Suppose we want to give the tool the ability to search the web for information,
    to do this we will use some Google API called SerpAPI**, you can register and
    get the API here: [https://serpapi.com/](https://serpapi.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs instantiate a SerpAPIWrapper class, and define the tool with the from_function
    method.
  prefs: []
  type: TYPE_NORMAL
- en: In the func field, we need to put a pointer to the method we want to launch
    using this tool, which is the run method of SerpAPI. And as we have seen we give
    a name and description to the tool. It is easier to do than explain it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now we can provide our agent with the list of tools created, in this case only
    one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Custom Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The clearest method in my opinion for creating a custom tool is to inherit the
    BaseTool class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You see this is the implementation of a custom tool, which will be used whenever
    the user asks a question regarding Medium. However, the returned string will not
    be exactly what I set up because it will be processed further by the Large Language
    Model.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to return something directly just add a ‚Äúreturn_direct‚Äù field in
    the following way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Even if we don‚Äôt use the _arun method (which is useful for asynchronous calling)
    we still have to implement it because BaseTool is an abstract class, and if we
    don‚Äôt implement all the abstract methods we‚Äôll get an error.
  prefs: []
  type: TYPE_NORMAL
- en: Real Life Example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One day a friend of mine said, ‚ÄúHey Marcello, since you do AI and that kind
    of stuff, why don‚Äôt you make me a **chatbot, which when required returns the doctors‚Äô
    working hours, and books appointments?**‚Äù
  prefs: []
  type: TYPE_NORMAL
- en: The first thing I thought of to solve this problem is to use LangChain and let
    the LLM interact with the user, and then as soon as the model understands that
    the user has requested to see the working hours it will just return a CSV file
    (or dataframe if you like).
  prefs: []
  type: TYPE_NORMAL
- en: So the same thing can be used for this use case as well. Suppose we have a CSV
    file called, work_time.csv
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: And just like that, a prototype of the app my friend wanted is ready in just
    a few lines of code! Obviously, work with a good front-end developer to make it
    look better!
  prefs: []
  type: TYPE_NORMAL
- en: Final Thought
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LangChain is a recent library that allows us to use the power of LLMs in different
    contexts.
  prefs: []
  type: TYPE_NORMAL
- en: I find it very useful to be able to use an LLM to understand the context, to
    **understand what the user is requesting, and then to run my own custom function
    to actually solve the task**.
  prefs: []
  type: TYPE_NORMAL
- en: This will allow you to write code that is versatile. To add a feature to your
    app all you need to do is **write a function and tell the model to use this function
    when it thinks it is needed**, and you are done!
  prefs: []
  type: TYPE_NORMAL
- en: If you were interested in this article follow me on Medium!
  prefs: []
  type: TYPE_NORMAL
- en: üíº [Linkedin](https://www.linkedin.com/in/marcello-politi/) Ô∏è| üê¶ [Twitter](https://twitter.com/_March08_)
    | [üíª](https://emojiterra.com/laptop-computer/) [Website](https://marcello-politi.super.site/)
  prefs: []
  type: TYPE_NORMAL
