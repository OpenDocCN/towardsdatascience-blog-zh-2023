- en: Extracting Data from (Azure) SQL Server Huge Tables in RFC 4180-Compliant CSV
    Files
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从（Azure）SQL Server 大型表中提取数据到 RFC 4180 兼容 CSV 文件
- en: 原文：[https://towardsdatascience.com/extracting-data-from-azure-sql-server-huge-tables-in-rfc-4180-compliant-csv-files-1cb09a7a0883](https://towardsdatascience.com/extracting-data-from-azure-sql-server-huge-tables-in-rfc-4180-compliant-csv-files-1cb09a7a0883)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/extracting-data-from-azure-sql-server-huge-tables-in-rfc-4180-compliant-csv-files-1cb09a7a0883](https://towardsdatascience.com/extracting-data-from-azure-sql-server-huge-tables-in-rfc-4180-compliant-csv-files-1cb09a7a0883)
- en: The nightmare of extracting data containing strings with special characters
    from (Azure) SQL Server huge tables into CSV files
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从（Azure）SQL Server 大型表中提取包含特殊字符的字符串到 CSV 文件中的噩梦
- en: '[](https://lucazavarella.medium.com/?source=post_page-----1cb09a7a0883--------------------------------)[![Luca
    Zavarella](../Images/6af72e50d79498ac378e2f1e469a0e65.png)](https://lucazavarella.medium.com/?source=post_page-----1cb09a7a0883--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1cb09a7a0883--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1cb09a7a0883--------------------------------)
    [Luca Zavarella](https://lucazavarella.medium.com/?source=post_page-----1cb09a7a0883--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lucazavarella.medium.com/?source=post_page-----1cb09a7a0883--------------------------------)[![Luca
    Zavarella](../Images/6af72e50d79498ac378e2f1e469a0e65.png)](https://lucazavarella.medium.com/?source=post_page-----1cb09a7a0883--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1cb09a7a0883--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1cb09a7a0883--------------------------------)
    [Luca Zavarella](https://lucazavarella.medium.com/?source=post_page-----1cb09a7a0883--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1cb09a7a0883--------------------------------)
    ·21 min read·Jan 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----1cb09a7a0883--------------------------------)
    ·阅读时间21分钟·2023年1月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/623f3bda214162d325d7158441329fe3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/623f3bda214162d325d7158441329fe3.png)'
- en: (Image from Unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （图片来自 Unsplash）
- en: When a team of Data Scientists from outside your company is hired to implement
    Machine Learning models, you somehow have to share with them the data to be used
    for model training. If the aforementioned team cannot directly access the data
    persisted in a database, the first option is to extract it from the database into
    files in CSV format. Considering that most of the time these data are in large
    quantities (5+ GB) and that some fields may contain special characters (comma,
    which coincides with the field separator; carriage return and/or new line characters),
    the usual tools used for export by non-developer users may not be adequate, even
    causing memory problems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当一组来自公司外部的数据科学家被聘用来实现机器学习模型时，你必须以某种方式与他们分享用于模型训练的数据。如果上述团队无法直接访问数据库中持久化的数据，第一种选择是将数据从数据库中提取到
    CSV 格式的文件中。考虑到这些数据通常是大量的（超过 5 GB），而且某些字段可能包含特殊字符（逗号，与字段分隔符重合；回车和/或换行符），非开发用户使用的通常导出工具可能不够合适，甚至可能导致内存问题。
- en: In this article you will see how to solve the problem of extracting a large
    amount of data containing special characters from an (Azure) SQL Server database
    in RFC 4180-Compliant CSV Files using PowerShell functions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，你将看到如何使用 PowerShell 函数解决从（Azure）SQL Server 数据库中提取包含特殊字符的大量数据到 RFC 4180
    兼容 CSV 文件中的问题。
- en: When you need to extract data from an (Azure) SQL Server database, the first
    tools that come to mind for the user are [*SQL Server Management Studio*](https://learn.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?WT.mc_id=AI-MVP-5003688)
    (SSMS) and *Azure Data Studio* (ADS). This is because both contain simple features
    that allow you to extract data from a database with a few clicks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要从（Azure）SQL Server 数据库中提取数据时，用户首先想到的工具是[*SQL Server Management Studio*](https://learn.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?WT.mc_id=AI-MVP-5003688)（SSMS）和*Azure
    Data Studio*（ADS）。这是因为这两者都包含简单的功能，允许你通过几次点击从数据库中提取数据。
- en: The interfacing tool with (Azure) SQL Server par excellence is SSMS. Recently
    Microsoft has been investing heavily in adding features in ADS to make it the
    tool of choice for the Microsoft data platform on Azure and beyond. Therefore,
    when you install the latest versions of SSMS today, the setup also installs ADS
    behind the scenes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与（Azure）SQL Server完美配合的工具是SSMS。最近，微软在向ADS中添加功能方面进行了大量投资，使其成为Azure及其他平台上微软数据平台的首选工具。因此，当你安装最新版本的SSMS时，安装程序也会在后台安装ADS。
- en: Any third-party system that involves importing a CSV file to load a dataset
    must be based on a standard that defines the CSV format. Therefore, before moving
    on to practical tests, let’s see if there is a standard definition of the CSV
    format.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 任何涉及导入CSV文件以加载数据集的第三方系统必须基于一个定义CSV格式的标准。因此，在进行实际测试之前，让我们看看是否有CSV格式的标准定义。
- en: What’s the RFC 4180
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是RFC 4180
- en: 'RFC 4180 is a standard that formalizes the format used for *Comma-Separated
    Values* (CSV) files and the specific *Multipurpose Internet Mail Extensions* (MIME)
    type associated with the CSV format (“text/csv”). The contents of this standard
    can be found here:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: RFC 4180是一个标准，它规范了用于*逗号分隔值*（CSV）文件的格式和与CSV格式相关的特定*多用途互联网邮件扩展*（MIME）类型（“text/csv”）。该标准的内容可以在这里找到：
- en: '[## RFC 4180: Common Format and MIME Type for Comma-Separated Values (CSV)
    Files'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[## RFC 4180：逗号分隔值（CSV）文件的通用格式和MIME类型'
- en: 'INFORMATIONAL 7111 Errata Exist Network Working Group Y. Shafranovich Request
    for Comments: 4180 SolidMatrix…'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: INFORMATIONAL 7111 Errata Exist 网络工作组 Y. Shafranovich 请求评论：4180 SolidMatrix…
- en: www.rfc-editor.org](https://www.rfc-editor.org/rfc/rfc4180?source=post_page-----1cb09a7a0883--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: www.rfc-editor.org](https://www.rfc-editor.org/rfc/rfc4180?source=post_page-----1cb09a7a0883--------------------------------)
- en: 'As you can see from the definition of the format in the previous link, while
    the first four points are fairly obvious, the remaining three need to be read
    carefully:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面链接中格式的定义所示，虽然前四点比较明显，但其余三点需要仔细阅读：
- en: Each field *may or may not be enclosed in double quotes* (however
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个字段*可能被括在双引号内，也可能不被括在双引号内*（但
- en: some programs, such as Microsoft Excel, do not use double quotes
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一些程序，如Microsoft Excel，不使用双引号
- en: at all). If fields are not enclosed with double quotes, then
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果字段没有被双引号括起，那么
- en: double quotes may not appear inside the fields.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 双引号可能不会出现在字段内。
- en: Fields containing line breaks (CR/LF), double quotes, and commas
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含换行符（CR/LF）、双引号和逗号的字段
- en: '*should be enclosed in double-quotes*.'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*应被括在双引号内*。'
- en: If double-quotes are used to enclose fields, then a double-quote
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用双引号来括起字段，那么一个双引号
- en: appearing inside a field *must be escaped by preceding it with
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 出现在字段内的*必须通过在其前面加上转义字符*来进行转义
- en: another double quote*.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一个双引号*。
- en: Keeping in mind also the examples given in the link, it is evident that the
    value of a field will be enclosed with double quotes only when needed. It doesn’t
    make sense to use double quotes for all the values of a field when only some of
    the values need them.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 同时考虑链接中给出的示例，可以看出字段的值只有在必要时才会用双引号括起。对于那些只需部分值使用双引号的字段，将所有值都用双引号括起来是没有意义的。
- en: 'When you need to share information with third-party systems using CSV format
    files, the following applies:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要使用CSV格式文件与第三方系统共享信息时，适用以下内容：
- en: It’s important that the CSV files you generate from your exports are RFC 4180
    compliant to be sure that the files can be read by any external system that provides
    CSV file import capability.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 重要的是，你从导出中生成的CSV文件必须符合RFC 4180，以确保文件可以被任何提供CSV文件导入功能的外部系统读取。
- en: In order to test how the upon mentioned tools extracts data in CSV format, let’s
    create a simple table containing special characters mentioned in the RFC 4180
    standard, and Unicode characters to ensure the generality of the contents in text
    fields.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试上述工具如何以CSV格式提取数据，让我们创建一个包含RFC 4180标准中提到的特殊字符和Unicode字符的简单表，以确保文本字段内容的通用性。
- en: Creating a dummy table containing special characters
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个包含特殊字符的虚拟表
- en: 'First, you have to create the `extract_test` table in your SQL Server instance
    using the following script:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要使用以下脚本在SQL Server实例中创建`extract_test`表：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then you can add data to this table using the following script:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用以下脚本向该表中添加数据：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see from the contents of the INSERT statements, we have provided
    all the special characters mentioned in the standard. We have also used Japanese
    characters, so that we can verify that the CSV file is written correctly using
    the Unicode character table.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从INSERT语句的内容中可以看出，我们提供了标准中提到的所有特殊字符。我们还使用了日文字符，以便验证CSV文件是否正确使用Unicode字符表进行编写。
- en: 'Evidently the table created in this case will not be a 5 GB table, but will
    contain special characters to test CSV format exports. Here the output of a SELECT
    in ADS:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，此情况下创建的表不会是5 GB的表，而是包含特殊字符以测试CSV格式导出的。这里是ADS中的SELECT输出：
- en: '![](../Images/eaf2a39c72049f69be92efdf94cd812c.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eaf2a39c72049f69be92efdf94cd812c.png)'
- en: Figure 1 — Output of the content of your dummy table on ADS (by the author)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图1 — 在ADS中输出的虚拟表内容（作者提供）
- en: Do not worry from the fact that the carriage return does not show up in the
    output grid of ADS or SSMS. The way the INSERT of that row was done, the carriage
    return is there.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 不必担心ADS或SSMS的输出网格中未显示回车符。由于INSERT该行的方式，回车符确实存在。
- en: So, let’s try to extract data from this table using SSMS and ADS.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们尝试使用SSMS和ADS从这个表中提取数据。
- en: Using Microsoft user-friendly tools to extract data
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用微软用户友好的工具来提取数据
- en: Let’s first try to use the traditional tool with which we interface with SQL
    Server, namely the SQL Server Management Studio.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先尝试使用传统工具，即SQL Server Management Studio来进行操作。
- en: Extracting data with SSMS
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SSMS提取数据
- en: 'Once you have opened SSMS and connected to your database instance, right-click
    on the name of the database hosting the table you’ve just created, go to *Tasks*
    and then *Export Data*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 打开SSMS并连接到数据库实例后，右键点击刚创建表所在的数据库名称，选择*任务*，然后选择*导出数据*：
- en: '![](../Images/0e5a5cd2336ac931a44980e7caa97902.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e5a5cd2336ac931a44980e7caa97902.png)'
- en: Figure 2 — Exporting data from a database using SSMS (by the author)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图2 — 使用SSMS从数据库导出数据（作者提供）
- en: 'You will be shown an initial screen describing the Extract Data activity. If
    you go forward, you will be shown this window:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到一个描述提取数据活动的初始屏幕。如果继续操作，将会看到这个窗口：
- en: '![](../Images/6771f58266f92bbcff0a8ae2331beae9.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6771f58266f92bbcff0a8ae2331beae9.png)'
- en: Figure 3 — Selecting a data source from the Export Wizard (by the author)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图3 — 从导出向导中选择数据源（作者提供）
- en: Select the SQL Server Client data source, enter your server instance name, then
    choose the authentication to use to login to database. In my case, having persisted
    the test table on an Azure SQL database, I used a SQL Server authentication to
    access my *test-sql-bug* database, as you can see in *Figure 3*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 选择SQL Server客户端数据源，输入您的服务器实例名称，然后选择登录数据库所使用的身份验证方式。在我的例子中，因为测试表存储在Azure SQL数据库上，我使用了SQL
    Server身份验证来访问我的*test-sql-bug*数据库，如*图3*所示。
- en: 'On the next screen of the Wizard you have the option of selecting the export
    destination. In our case, select *Flat File Destination*, create a CSV destination
    file via the *Browse* button in your preferred folder (remember to select the
    CSV extension in the Open window that opens after pressing Browse). Remember to
    check the *Unicode* flag to make sure you also handle the Japanese characters
    in our example. After that, select *Delimited* as the format, leaving the *Text
    qualifier* at “*<none>*”. Also make sure that the “*Column names in the first
    data row*” flag is checked. Then press *Next*:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在向导的下一个屏幕上，您可以选择导出目标。在我们的例子中，选择*平面文件目标*，通过*浏览*按钮在您首选的文件夹中创建一个CSV目标文件（记得在点击浏览后打开的窗口中选择CSV扩展名）。记得勾选*Unicode*标志，以确保还处理了我们示例中的日文字符。之后，选择*分隔符*作为格式，将*文本限定符*保持为“*<none>*”。还要确保勾选了“*首行数据中的列名*”标志。然后点击*下一步*：
- en: '![](../Images/c0449416dd54667408166e7b20be2d06.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0449416dd54667408166e7b20be2d06.png)'
- en: Figure 4 — Selecting a destination for the data output (by the author)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图4 — 选择数据输出的目标（作者提供）
- en: In the next window select *Copy data from one or more tables or views* and press
    *Next* again.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个窗口中选择*从一个或多个表或视图中复制数据*，然后再次点击*下一步*。
- en: 'In the configuration window that appears you can then select the table ` `[dbo].[extract_text]`
    as *Source table or view*. For the other options, you can leave everything as
    is, since the row delimiter (*CR\LF*) and the column delimiter (*comma*) are as
    defined by the RFC 4180 standard. Then press *Next*:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在出现的配置窗口中，您可以选择表` `[dbo].[extract_text]` 作为*源表或视图*。对于其他选项，您可以保持默认设置，因为行分隔符（*CR\LF*）和列分隔符（*逗号*）均按照RFC
    4180标准定义。然后点击*下一步*：
- en: '![](../Images/cd514fc41e93dd51c7ee8655eb5a34d3.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd514fc41e93dd51c7ee8655eb5a34d3.png)'
- en: Figure 5 — Configuring the flat file destination options (by the author)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5 — 配置平面文件目标选项（作者提供）
- en: In the next window keep *Run immediately* selected and press *Finish*. A summary
    window of the selected options will appear. Press *Finish* again and the extraction
    will start. When finished, press *Close*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个窗口中保持 *立即运行* 选项被选中，然后点击 *完成*。将出现选项摘要窗口。再次点击 *完成* 开始提取。完成后，点击 *关闭*。
- en: 'If you now try to open the output CSV file with a text editor (not Excel),
    you will notice the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在尝试用文本编辑器（而不是 Excel）打开输出的 CSV 文件，你会注意到以下内容：
- en: '![](../Images/8ef38686fd3879fea02e5673ccb17c5a.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ef38686fd3879fea02e5673ccb17c5a.png)'
- en: Figure 6 — The output of the SSMS Export Wizard without text qualifier (by the
    author)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6 — SSMS 导出向导输出（没有文本限定符）（作者提供）
- en: Basically, in this case the Export Wizard extracts the contents of each text
    field regardless of whether it may contain special characters (comma and carriage
    return). This means that any carriage return contained in a text field is interpreted
    as a row delimiter by the system that has to read the file, just as any comma
    contained in a text field is interpreted as a field delimiter. Unicode characters,
    on the other hand, have been treated correctly. Therefore, the generated CSV file
    will not be recognized as correct by any third-party system that needs to import
    that information.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，在这种情况下，导出向导会提取每个文本字段的内容，而不管它是否可能包含特殊字符（逗号和回车）。这意味着文本字段中包含的任何回车都会被系统解释为行分隔符，就像文本字段中包含的任何逗号会被解释为字段分隔符一样。另一方面，Unicode
    字符已被正确处理。因此，生成的 CSV 文件将无法被任何需要导入这些信息的第三方系统识别为正确。
- en: 'If you try to repeat the export, this time entering the double quotes as a
    text qualifier, you will get the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试重复导出，这次将双引号作为文本限定符输入，你将得到以下结果：
- en: '![](../Images/0a30ade9cdc7cbcb38a845d1c32daf9d.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a30ade9cdc7cbcb38a845d1c32daf9d.png)'
- en: Figure 7 — The output of the SSMS Export Wizard using double quotes as text
    qualifier (by the author)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 — 使用双引号作为文本限定符的 SSMS 导出向导输出（作者提供）
- en: In this case, all extracted values are surrounded by double quotes, including
    the header. However, this forces an external system that must read the data to
    consider all numeric values as strings. Moreover, if a value in a text field contains
    a double quote character, it is not escaped, generating parsing problems for external
    systems. Therefore, again, the generated CSV file will not be recognized as correct
    by any third-party system that needs to import this information.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，所有提取的值都被双引号包围，包括标题。然而，这会强迫必须读取数据的外部系统将所有数字值视为字符串。此外，如果文本字段中的值包含双引号字符，则不会转义，从而给外部系统带来解析问题。因此，再次生成的
    CSV 文件将无法被任何需要导入这些信息的第三方系统识别为正确。
- en: Regarding the scalability of the extraction operation on very large masses of
    data, there are no problems, because the Export Wizard uses *SQL Server Integration
    Services* (SSIS) as its engine, which is developed to handle huge bulk volumes
    of data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在非常大数据量上进行提取操作的可扩展性，毫无问题，因为导出向导使用 *SQL Server 集成服务*（SSIS）作为其引擎，SSIS 开发用于处理巨大的数据量。
- en: 'Moreover, it may sometimes happen that you need to take action on the data
    source data types to avoid some errors during export with the Export Wizard, as
    highlighted in this blog post:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，有时你可能需要对数据源的数据类型采取措施，以避免在使用导出向导时出现一些错误，如本博客文章所强调：
- en: '[](https://www.sqlshack.com/export-data-sql-server-flat-file/?source=post_page-----1cb09a7a0883--------------------------------)
    [## How to export data from SQL Server to a Flat file'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 如何将数据从 SQL Server 导出到平面文件](https://www.sqlshack.com/export-data-sql-server-flat-file/?source=post_page-----1cb09a7a0883--------------------------------)'
- en: December 7, 2017 by In this article, we will illustrate how to export SQL Server
    data into a Flat file, by using the…
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2017年12月7日 在这篇文章中，我们将展示如何使用…将 SQL Server 数据导出到平面文件中。
- en: www.sqlshack.com](https://www.sqlshack.com/export-data-sql-server-flat-file/?source=post_page-----1cb09a7a0883--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.sqlshack.com](https://www.sqlshack.com/export-data-sql-server-flat-file/?source=post_page-----1cb09a7a0883--------------------------------)'
- en: 'We can conclude this section by stating the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下陈述来总结这一部分：
- en: Using the SSMS Export Wizard as a tool for extracting data in CSV format from
    an (Azure) SQL Server database doesn’t guarantee having a format that complies
    with the standard defined by RFC 4180, with the consequence that the extracted
    information may not be properly read by an external system.
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用 SSMS 导出向导作为从（Azure）SQL Server 数据库提取 CSV 格式数据的工具，并不能保证具有符合 RFC 4180 定义的标准格式，因此提取的信息可能无法被外部系统正确读取。
- en: Instead, let’s see what happens when we use Azure Data Studio to extract the
    information in CSV format.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，让我们看看使用 Azure Data Studio 提取 CSV 格式信息时会发生什么。
- en: Extracting data with ADS
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 ADS 提取数据
- en: Once Azure Data Studio is open, the first thing to do is to [add a new connection
    to your server instance](https://learn.microsoft.com/en-us/sql/azure-data-studio/quickstart-sql-server?WT.mc_id=AI-MVP-5003688).
    Watch out that starting with newer versions, the *Encrypted* option is set to
    *True* by default. This will not result in connection errors if you connect to
    an Azure SQL database, but it might generate one if your data source is an on-prem
    SQL Server. In that case, you can set the option to *False*.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦打开 Azure Data Studio，首先要做的是[添加一个新的服务器实例连接](https://learn.microsoft.com/en-us/sql/azure-data-studio/quickstart-sql-server?WT.mc_id=AI-MVP-5003688)。注意，从较新的版本开始，*加密*选项默认设置为*True*。如果你连接到
    Azure SQL 数据库，这不会导致连接错误，但如果你的数据源是本地 SQL Server，则可能会产生错误。在这种情况下，你可以将选项设置为*False*。
- en: 'That said, in order to extract the contents of a table (or view, or query)
    in ADS, you must first perform a SELECT query and display its contents in the
    output grid running it. After that, simply press the “Save As CSV” button at the
    top right of the grid:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，为了在 ADS 中提取表（或视图、查询）的内容，你必须首先执行一个 SELECT 查询，并在运行时将其内容显示在输出网格中。之后，只需按下网格右上角的“保存为
    CSV”按钮：
- en: '![](../Images/761cd9020cf9946afb9c7c68b290f0c0.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/761cd9020cf9946afb9c7c68b290f0c0.png)'
- en: Figure 8 — Saving the output of a query in ADS in CSV format (by the author)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8 — 在 ADS 中以 CSV 格式保存查询输出（作者提供）
- en: 'An output file selection window will open, allowing you to name the file that
    will be extracted (in our case *ExtractTestADS.csv*). As soon as you press the
    *Save* button, the contents of the CSV file will be shown directly within ADS:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一个输出文件选择窗口将打开，允许你命名要提取的文件（在我们的例子中是*ExtractTestADS.csv*）。一旦按下*保存*按钮，CSV 文件的内容将直接显示在
    ADS 中：
- en: '![](../Images/0f3abdf699119f41e38bb107d72ac01c.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f3abdf699119f41e38bb107d72ac01c.png)'
- en: Figure 9 — The output of ADS in CSV format (by the author)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9 — ADS 以 CSV 格式输出的结果（作者提供）
- en: Wow! The output generated by ADS complies with the RFC 4180 standard to all
    intents and purposes! Thus, it would seem that ADS is the perfect tool for extracting
    information in CSV format from an (Azure) SQL database.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！ADS 生成的输出在所有方面都符合 RFC 4180 标准！因此，ADS 似乎是从（Azure）SQL 数据库中提取 CSV 格式信息的完美工具。
- en: However, there is a scalability problem. Since ADS requires that the query output
    be first exposed in the output grid, this limits the functionality when dealing
    with many GB of data. In these cases, containing all that data in a grid involves
    taking up so much RAM on the system, causing the application to crash.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这里存在一个扩展性问题。由于 ADS 要求查询输出首先在输出网格中暴露，这限制了处理大量数据时的功能。在这些情况下，将所有数据包含在一个网格中会占用系统大量内存，导致应用程序崩溃。
- en: 'We can therefore conclude this section as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以得出以下结论：
- en: ADS’s CSV format data export procedure guarantees output that conforms to the
    RFC 4180 standard. However, the use of ADS for extraction tasks is indicated when
    the size of the dataset to be exported is rather limited. When more than 2–3 GB
    of data needs to be extracted, ADS may occupy the entire system memory and crash.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ADS 的 CSV 格式数据导出过程保证了符合 RFC 4180 标准的输出。然而，当待导出的数据集大小相对有限时，使用 ADS 进行提取任务是合适的。当需要提取超过
    2–3 GB 的数据时，ADS 可能会占用整个系统内存并导致崩溃。
- en: 'In general, we can therefore conclude that:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们可以得出以下结论：
- en: Unfortunately, the *user-friendly features* provided by Microsoft’s data platform
    tools don’t allow to extract huge amount of data in CSV format following the RFC
    4180 standard.
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不幸的是，微软的数据平台工具提供的*用户友好功能*无法按照 RFC 4180 标准提取大量数据为 CSV 格式。
- en: Let’s try to see if we can achieve our goal through more specific tools known
    by expert users.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过专家用户知道的更具体的工具来实现我们的目标。
- en: Using the BCP tool to extract data
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 BCP 工具提取数据
- en: The *Bulk Copy Program* (BCP) command line utility is used to import large numbers
    of new rows into SQL Server tables or to export data from tables to data files
    in a user-specified format. This is the solution that imports or exports data
    *as fast as possible* in even very large quantities. Therefore, it has no problem
    with scalability.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to being installed by default with a standard on-prem SQL Server
    installation, and in addition to being able to be [installed stand-alone](https://learn.microsoft.com/en-us/sql/tools/bcp-utility?WT.mc_id=AI-MVP-5003688)
    on a Windows operating system, the BCP utility can also be used from the Azure
    cloud shell to interact with an Azure SQL database, as shown in this blog post:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://kontext.tech/article/763/export-csv-file-from-azure-sql-databases?source=post_page-----1cb09a7a0883--------------------------------)
    [## Export CSV File from Azure SQL Databases'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many ways to export CSV file from Azure SQL Databases. This article
    shows two approaches: bcp and sqlcmd…'
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: kontext.tech](https://kontext.tech/article/763/export-csv-file-from-azure-sql-databases?source=post_page-----1cb09a7a0883--------------------------------)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'Without going into too much detail, the main problem with BCP is that it doesn’t
    extract table headers and doesn’t handle double quotes in a simple way out of
    the box. This is evidenced by the fact that [*Erland Sommarskog*](https://sessionize.com/ErlandSommarskog/)’s
    reference guide for its use reports a number of workarounds for getting both headers
    and double quotes, as you can see here:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[## Using the Bulk-Load Tools in SQL Server'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: An SQL text by Erland Sommarskog, SQL Server MVP. Most recent update 2021-01-26\.
    Copyright applies to this text. See…
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.sommarskog.se](https://www.sommarskog.se/bulkload.html?source=post_page-----1cb09a7a0883--------------------------------#exportexamples)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the drawbacks of this is approach is that you have to know in advance
    which fields need double quotes (unless you provide them for all text fields).
    Generally, I do not have the ability to know in advance which fields might have
    the need for double quotes. I just want to extract the data worry-free. Should
    you be able to get the headers and double quotes via Erland’s advice, however,
    the quotes would be applied to all values in the selected fields. As Erland himself
    points out:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '… the assumption is that the data should always be quoted. If you only want
    to quote when needed, you will need to handle this in your query, which is outside
    the scope of this article. All I can say is: good luck. Or more directly: avoid
    it if you can.'
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Also, should a field with double quotes have a string containing both a comma
    and a double quote, the BCP does not handle the feature of escaping the double
    quote by doubling it.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'We can therefore state that:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Using BCP to export data in a CSV format that includes both headers and double
    quotes is very arcane for the non-expert user. One downside is that you have to
    know in advance for which fields to provide double quotes. In addition, it would
    still not result in a format consistent with the RFC 4180 standard.
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I will not go into the details of using Microsoft’s other command-line tool
    called [SQLCMD](https://learn.microsoft.com/en-us/sql/tools/sqlcmd-utility?WT.mc_id=AI-MVP-5003688),
    because the issues are similar to those highlighted in this section.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: So what? How to proceed? Since I couldn’t find an application on the Internet
    that was able to extract data in an RFC 4180-compliant CSV format and at the same
    time handle very large data masses, the only possible solution was to develop
    a *custom solution* that can be easily used even by the non-expert user. Let’s
    see how this solution works.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Developing a custom solution in PowerShell
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first thing I asked myself when I decided to develop a specific solution
    for this problem was what programming language to use. The first language that
    came to mind was definitely Python. I then thought, however, that a standard user
    approaching the world of automation on a Windows machine may not know Python,
    and he would not find it preinstalled on the operating system. That is why the
    choice fell on *PowerShell*, which provides, among other things, a specific module
    for SQL Server.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Issues with the SQL Server PowerShell module
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first attempt I made was to use the [SQL Server PowerShell module](https://learn.microsoft.com/en-us/sql/powershell/download-sql-server-ps-module?WT.mc_id=AI-MVP-5003688),
    which allows SQL Server developers, administrators, and business intelligence
    professionals to automate database development and server administration.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, the command I tried to use to send the query needed to retrieve
    the data to the Azure SQL database was [Invoke-Sqlcmd](https://learn.microsoft.com/en-us/powershell/module/sqlserver/invoke-sqlcmd?WT.mc_id=AI-MVP-5003688).
    This command does nothing more than invoke the [sqlcmd.exe command-line utility](https://learn.microsoft.com/en-us/sql/tools/sqlcmd-utility?WT.mc_id=AI-MVP-5003688),
    often used by automation processes to retrieve information from a SQL Server database.
    So far, so good. The problem is that Invoke-Sqlcmd persists all query output directly
    into PowerShell data structures. As you can guess, when the query output takes
    up more than 3–4 GB, you have the same problem encountered with extraction done
    in ADS, which is that your system becomes unstable due to excessive RAM consumption.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, I found it appropriate to directly use [ADO.NET objects](https://learn.microsoft.com/en-us/dotnet/framework/data/adonet/retrieving-and-modifying-data?WT.mc_id=AI-MVP-5003688)
    in PowerShell to try to work around the problem. Let’s see how I used them in
    this solution.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Batch exporting data to output file
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main idea of my solution is to always use an intermediate data structure
    (a [*DataTable*](https://learn.microsoft.com/en-us/dotnet/api/system.data.datatable?WT.mc_id=AI-MVP-5003688))
    that would collect the query data, but a number of rows at a time. Once the maximum
    capacity of the intermediate data structure is reached, its contents are written
    to the target file, it is emptied and is immediately loaded with the next rows
    of data from the data source:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我的解决方案的主要思想是始终使用一个中间数据结构（一个 [*DataTable*](https://learn.microsoft.com/en-us/dotnet/api/system.data.datatable?WT.mc_id=AI-MVP-5003688)），该结构会收集查询数据，但一次只收集一定数量的行。一旦达到中间数据结构的最大容量，它的内容会被写入目标文件，结构会被清空，并立即加载数据源中的下一批数据：
- en: '![](../Images/c3198964bb710faa2e714c6b1f447642.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3198964bb710faa2e714c6b1f447642.png)'
- en: Figure 10 — Main process of the solution (image by the author)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10 — 解决方案的主要过程（图片由作者提供）
- en: This process goes on until there are new lines to read in the data source.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程持续进行，直到数据源中没有新行可读。
- en: You might wonder why I used an intermediate DataTable and didn’t implement a
    direct write stream to the output file through the [*StreamWriter*](https://learn.microsoft.com/en-us/dotnet/api/system.io.streamwriter?WT.mc_id=AI-MVP-5003688).
    The answer lies in the ability to use PowerShell’s *Export-Csv* [cmdlet](https://learn.microsoft.com/en-us/powershell/scripting/developer/cmdlet/cmdlet-overview?WT.mc_id=AI-MVP-5003688)
    directly.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么我使用了一个中间的 DataTable，而没有通过 [*StreamWriter*](https://learn.microsoft.com/en-us/dotnet/api/system.io.streamwriter?WT.mc_id=AI-MVP-5003688)
    实现直接写入输出文件。答案在于直接使用 PowerShell 的 *Export-Csv* [cmdlet](https://learn.microsoft.com/en-us/powershell/scripting/developer/cmdlet/cmdlet-overview?WT.mc_id=AI-MVP-5003688)
    的能力。
- en: Writing data using Export-Csv
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Export-Csv 写入数据
- en: One of the goals I set for myself when I have to solve a problem is always not
    to reinvent the wheel if there are already convenient solutions that help you
    solve it completely or partially. In this case, I thought I would dispense with
    rewriting all the logic that handles the special characters mentioned by the RFC
    4180 standard using the [*Export-Csv* cmdlet](https://learn.microsoft.com/en-us/previous-versions/powershell/module/microsoft.powershell.utility/export-csv?WT.mc_id=AI-MVP-5003688).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我在解决问题时设定的目标之一是，尽量避免重新发明轮子，如果已经有方便的解决方案可以完全或部分解决问题。在这种情况下，我认为可以省略重新编写处理 RFC
    4180 标准所提及特殊字符的所有逻辑，直接使用 [*Export-Csv* cmdlet](https://learn.microsoft.com/en-us/previous-versions/powershell/module/microsoft.powershell.utility/export-csv?WT.mc_id=AI-MVP-5003688)。
- en: 'Checking the PowerShell cmdlet guide, I realized that *Export-Csv* provides
    the parameters that control the use of double quotes only as of version 7:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 查阅 PowerShell cmdlet 指南时，我意识到 *Export-Csv* 仅在版本 7 中提供控制双引号使用的参数：
- en: '![](../Images/17eccee714413ecca5c7cd538b60c771.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17eccee714413ecca5c7cd538b60c771.png)'
- en: Figure 11 — Differences between Export-Csv versions 6 and 7 (image by the author)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11 — Export-Csv 版本 6 和 7 的区别（图片由作者提供）
- en: 'Specifically, the [*UseQuotes parameter*](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/export-csv?view=powershell-7.3&WT.mc_id=AI-MVP-5003688#-usequotes)
    provides the value *AsNeeded* and defines its functionality as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，[*UseQuotes 参数*](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/export-csv?view=powershell-7.3&WT.mc_id=AI-MVP-5003688#-usequotes)
    提供了值 *AsNeeded*，其功能定义如下：
- en: only quote fields that contain a delimiter character, double-quote, or newline
    character
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 仅为包含分隔符字符、双引号或换行符的字段加引号
- en: Basically, it’s what we want in order to meet the requirements of the RFC 4180
    standard.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，这正是我们为了满足 RFC 4180 标准要求所需要的。
- en: Should you wish to provide double quotes only for certain fields, you can specify
    them explicitly via the *QuoteFields* parameter.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望仅为某些字段提供双引号，你可以通过 *QuoteFields* 参数明确指定它们。
- en: Now there is just a small problem with PowerShell versioning. Keep in mind that
    Windows 10, Windows 11, and Windows Server 2022 preinstall version 5.1 of Windows
    PowerShell (also known as Desktop edition). In order to use the newer versions
    of the *Export-Csv* cmdlet, you must install the [newer version of PowerShell](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-windows?WT.mc_id=AI-MVP-5003688)
    (at least PowerShell 7.0), which is for all intents and purposes a separate piece
    of software from Windows PowerShell based on .NET Core (if you are interested
    in learning about its evolution over time, you can learn more at [this link](https://www.itechtics.com/windows-powershell-vs-powershell-core/)).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，PowerShell 版本存在一个小问题。请注意，Windows 10、Windows 11 和 Windows Server 2022 预装了版本
    5.1 的 Windows PowerShell（也称为桌面版）。为了使用较新的 *Export-Csv* cmdlet，你必须安装[较新版本的 PowerShell](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-windows?WT.mc_id=AI-MVP-5003688)（至少
    PowerShell 7.0），这实际上是基于 .NET Core 的 Windows PowerShell 的独立软件（如果你有兴趣了解它的演变，你可以在[此链接](https://www.itechtics.com/windows-powershell-vs-powershell-core/)中了解更多）。
- en: 'It’s important to emphasize the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 强调以下几点很重要：
- en: Since this module was developed for Core versions of PowerShell, it can also
    be used on Linux and macOS systems.
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于该模块是为 PowerShell Core 版本开发的，因此也可以在 Linux 和 macOS 系统上使用。
- en: That said, let’s see how to use this new module.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们来看看如何使用这个新模块。
- en: How to use the SqlBulkExport module
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用 SqlBulkExport 模块
- en: 'The new *SqlBulkExport* module is available on GitHub here:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 *SqlBulkExport* 模块可以在 GitHub 上找到，链接如下：
- en: '[](https://github.com/lucazav/sql-bulk-export?source=post_page-----1cb09a7a0883--------------------------------)
    [## GitHub - lucazav/sql-bulk-export: This PowerShell module contains two functions
    that are useful for…'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[## GitHub - lucazav/sql-bulk-export: 这个 PowerShell 模块包含两个对导出大量数据很有用的函数…](https://github.com/lucazav/sql-bulk-export?source=post_page-----1cb09a7a0883--------------------------------)'
- en: This PowerShell module contains two functions that are useful for exporting
    large amounts of data from tables, views…
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这个 PowerShell 模块包含两个对导出大量数据非常有用的函数。
- en: github.com](https://github.com/lucazav/sql-bulk-export?source=post_page-----1cb09a7a0883--------------------------------)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/lucazav/sql-bulk-export?source=post_page-----1cb09a7a0883--------------------------------)'
- en: 'It provides two functions:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了两个功能：
- en: '**Export-SqlBulkCsv**: Exports the content of a SQL Server database table,
    view or query in an RFC 4180-Compliant CSV file. This function supports the export
    of huge result sets, writing the CSV file content in multiple batches.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Export-SqlBulkCsv**：将 SQL Server 数据库表、视图或查询的内容导出到一个符合 RFC 4180 的 CSV 文件中。此功能支持导出大量结果集，将
    CSV 文件内容分多次写入。'
- en: '**Export-SqlBulkCsvByPeriod**: Exports the content of a SQL Server database
    table, view or query in multiple RFC 4180-Compliant CSV files, broken down by
    time period (yearly, monthly or daily), based on the contents of a selected date
    field. This function supports the export of huge result sets, writing each CSV
    file content in multiple batches.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Export-SqlBulkCsvByPeriod**：将 SQL Server 数据库表、视图或查询的内容导出到多个符合 RFC 4180 的
    CSV 文件中，按时间段（按年、按月或按日）进行拆分，基于所选日期字段的内容。此功能支持导出大量结果集，将每个 CSV 文件的内容分多次写入。'
- en: 'Both functions require the following parameters:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 两个函数都需要以下参数：
- en: '*ServerName*: The SQL Server instance name to connect to.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ServerName*：要连接的 SQL Server 实例名称。'
- en: '*Port*: The SQL Server instance port number. By default, it is 1433.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Port*：SQL Server 实例端口号。默认值为 1433。'
- en: '*DatabaseName*: The SQL Server database name to connect to.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DatabaseName*：要连接的 SQL Server 数据库名称。'
- en: '*SchemaName*: The database schema of a table of view from which extract data.
    By default, it is “*dbo*”.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SchemaName*：提取数据的表或视图的数据库架构。默认值为“*dbo*”。'
- en: '*TableViewName*: The database table or view name from which extract data.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TableViewName*：提取数据的数据库表或视图的名称。'
- en: '*Query*: The T-SQL query with which extract data.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Query*：提取数据的 T-SQL 查询。'
- en: '*User*: The username to use to connect to database.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*User*：用于连接数据库的用户名。'
- en: '*Password*: The password of the username to connect to database.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Password*：用于连接数据库的用户名的密码。'
- en: '*ConnectionTimeout*: The connection timeout in seconds. By default it is 30
    seconds.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ConnectionTimeout*：连接超时时间（以秒为单位）。默认值为 30 秒。'
- en: '*DatabaseCulture*: The database culture code (es. it-IT). It’s used to extract
    the decimal separator properly. By default, it is “*en-US*”.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DatabaseCulture*：数据库文化代码（例如 it-IT）。它用于正确提取小数分隔符。默认情况下为“*en-US*”。'
- en: '*BatchSize*: The size (number of rows) of batches that are written to the output
    file until data to extract is over.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*BatchSize*：写入到输出文件中的批次大小（行数），直到提取的数据结束。'
- en: '*OutputFileFullPath*: Full path (including filename and csv extension) of the
    output file.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OutputFileFullPath*：输出文件的完整路径（包括文件名和 csv 扩展名）。'
- en: '*SeparatorChar*: Character used to build string separators shown in console.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SeparatorChar*：用于构建在控制台中显示的字符串分隔符的字符。'
- en: 'The *Export-SqlBulkCsvByPeriod* function provides three more mandatory parameters
    to be able to partition the result set according to a time period:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*Export-SqlBulkCsvByPeriod* 函数提供了三个更多的必填参数，以便根据时间段对结果集进行分区：'
- en: '*DateColumnName*: Date/time type column by which data will be broken down by
    the time period.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DateColumnName*：按时间段拆分数据的日期/时间类型列。'
- en: '*StartPeriod*: Time period string (allowed formats: “*yyyy*”, “*yyyy-MM*”,
    “*yyyy-MM-dd*”) representing the period from which to start extracting data (period
    in question included).'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*StartPeriod*：时间段字符串（允许的格式：“*yyyy*”、“*yyyy-MM*”、“*yyyy-MM-dd*”），表示从哪个时间段开始提取数据（包括该时间段）。'
- en: '*EndPeriod*: Time period string (allowed formats: “*yyyy*”, “*yyyy-MM*”, “*yyyy-MM-dd*”)
    representing the period up to which to extract data (period in question included).'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*EndPeriod*：时间段字符串（允许的格式：“*yyyy*”、“*yyyy-MM*”、“*yyyy-MM-dd*”），表示提取数据的结束时间段（包括该时间段）。'
- en: It’s evident that the formats used for the two input periods must be consistent
    with each other.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，两个输入时间段所使用的格式必须一致。
- en: It’s important to note that extracting multiple CSV files broken down by a time
    period using the *Export-SqlBulkCsvByPeriod* function is only possible using a
    table/view, and not a query. If there are, for example, special needs for selecting
    fields and filters to be applied to a table, one must then first expose a view
    with these logics to then be able to extract multiple CSV files by time period.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，使用 *Export-SqlBulkCsvByPeriod* 函数提取按时间段划分的多个 CSV 文件只能通过表/视图实现，而不能通过查询实现。如果需要选择字段和应用过滤器，必须首先暴露一个具有这些逻辑的视图，然后才能按时间段提取多个
    CSV 文件。
- en: Moreover, the *Export-SqlBulkCsvByPeriod* function involves the use of the string
    token `{}` (curly brackets open and closed) within the name of the output CSV
    file, which token will be replaced by the string associated with the time period
    of the transactions contained in the CSV file in question.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*Export-SqlBulkCsvByPeriod* 函数在输出 CSV 文件名中涉及使用字符串标记 `{}`（大括号），该标记将被与 CSV
    文件中交易时间段相关的字符串替换。
- en: Both functions automatically recognize when to connect using Windows authentication
    or SQL Server authentication based on whether or not the User and Password parameters
    are passed.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 两个函数会根据是否传递了 User 和 Password 参数自动识别是使用 Windows 身份验证还是 SQL Server 身份验证。
- en: Before proceeding with the examples, make sure you have installed the latest
    version of PowerShell.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续示例之前，请确保您已安装最新版本的 PowerShell。
- en: Installing the latest PowerShell and SqlBulkExport versions
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装最新的 PowerShell 和 SqlBulkExport 版本
- en: In order to install the latest version of PowerShell on Windows machines, download
    and run the 64-bit installer (in our case, version 7.3.0) from [this link](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-windows?WT.mc_id=AI-MVP-5003688#installing-the-msi-package).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 Windows 机器上安装最新版本的 PowerShell，请从 [此链接](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-windows?WT.mc_id=AI-MVP-5003688#installing-the-msi-package)
    下载并运行 64 位安装程序（在我们的例子中为 7.3.0 版本）。
- en: 'Click *Next* to all the Setup Wizard windows. Then click *Finish*. You’ll see
    the PowerShell 7 (x64) prompt installed into your applications:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 *Next* 继续所有的设置向导窗口。然后点击 *Finish*。你会看到 PowerShell 7 (x64) 提示符已安装到你的应用程序中：
- en: '![](../Images/5360576ace50843f971a799953bfa3d0.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5360576ace50843f971a799953bfa3d0.png)'
- en: Figure 12 — PowerShell 7 just installed (image by the author)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12 — PowerShell 7 刚刚安装完成（图像由作者提供）
- en: 'Run it and you’ll see the PowerShell prompt ready for your commands:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 运行它，你会看到 PowerShell 提示符准备好接收你的命令：
- en: '![](../Images/dbc29ca3bc3b72081470f642617b7c9b.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbc29ca3bc3b72081470f642617b7c9b.png)'
- en: Figure 13 — PowerShell 7 prompt ready (image by the author)
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13 — PowerShell 7 提示符准备就绪（图像由作者提供）
- en: 'You can enter the `$PSVersionTable` command and press Enter to check if all
    is working fine:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以输入 `$PSVersionTable` 命令并按 Enter 键检查是否一切正常：
- en: '![](../Images/c4ecfb1c7ad431c5bbc2917190935fb7.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4ecfb1c7ad431c5bbc2917190935fb7.png)'
- en: Figure 14 — PSVersionTable output (image by the author)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14 — PSVersionTable 输出（图像由作者提供）
- en: Great! If necessary, you can also install PowerShell on [Linux](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-linux?WT.mc_id=AI-MVP-5003688)
    or [macOS](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-macos?WT.mc_id=AI-MVP-5003688).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！如有必要，您还可以在 [Linux](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-linux?WT.mc_id=AI-MVP-5003688)
    或 [macOS](https://learn.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-macos?WT.mc_id=AI-MVP-5003688)
    上安装 PowerShell。
- en: 'Now you have to download the SqlBulkExport module files:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要下载 SqlBulkExport 模块文件：
- en: Go to the [releases page](https://github.com/lucazav/sql-bulk-export/releases)
    of the SqlBulkExport GitHub repository and download the *Source code.zip* file
    of the latest release.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 SqlBulkExport GitHub 仓库的 [发布页面](https://github.com/lucazav/sql-bulk-export/releases)
    下载最新版本的 *Source code.zip* 文件。
- en: Once your file is saved on your machine, unzip it and copy its content into
    the `C:\Temp` folder (or you can choose your preferred folder). So, your module
    files will be persisted into the `C:\Temp\sql-bulk-export-<version>` folder.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦文件保存在您的机器上，解压缩它并将其内容复制到 `C:\Temp` 文件夹中（或您可以选择您喜欢的文件夹）。这样，您的模块文件将被保存在 `C:\Temp\sql-bulk-export-<version>`
    文件夹中。
- en: Ok! Now you are ready to try few examples.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 好的！现在您可以尝试一些示例了。
- en: Export the content of our dummy table in one CSV file
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将我们的虚拟表内容导出到一个 CSV 文件中
- en: 'Let us try extracting the contents of the *extract_test* table created at the
    beginning of this article to check its consistency with the RFC 4180 standard.
    In our case, the table in question is persisted in an Azure SQL database:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试提取本文开始时创建的 *extract_test* 表的内容，以检查其是否符合 RFC 4180 标准。在我们的案例中，相关表被保存在 Azure
    SQL 数据库中：
- en: Open the PowerShell 7 prompt, enter the `cd C:\Temp\sql-bulk-export-<version>`
    command and press *Enter* to change your working directory to the module’s one.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 PowerShell 7 提示符，输入 `cd C:\Temp\sql-bulk-export-<version>` 命令并按 *Enter* 键，将工作目录更改为模块目录。
- en: Enter the `Import-Module -Name ".\SqlBulkExport.psd1"` command to import the
    *SqlBulkExport* module.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `Import-Module -Name ".\SqlBulkExport.psd1"` 命令来导入 *SqlBulkExport* 模块。
- en: 'Enter the `Export-SqlBulkCsv -ServerName "<your-server-name>" -DatabaseName
    "<your-database-name>" -User "<username>" -Password "<password>" -TableViewName
    "export_test" -BatchSize 30000 -OutputFileFullPath "C:\Temp\ExtractedTestPS.csv"`
    to export the content of a database table (or view) into the *ExtractedTestPS.csv*
    file in batches of 30K rows. Here the output:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `Export-SqlBulkCsv -ServerName "<your-server-name>" -DatabaseName "<your-database-name>"
    -User "<username>" -Password "<password>" -TableViewName "export_test" -BatchSize
    30000 -OutputFileFullPath "C:\Temp\ExtractedTestPS.csv"` 命令，将数据库表（或视图）的内容以每批 30K
    行的方式导出到 *ExtractedTestPS.csv* 文件中。以下是输出：
- en: '![](../Images/f9c971ff04c77ac0b4730993bbf3e986.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9c971ff04c77ac0b4730993bbf3e986.png)'
- en: Figure 15 — Console output of the command that extracts the contents of the
    dummy table into a CSV file (image by the author)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15 — 提取虚拟表内容到 CSV 文件的命令控制台输出（图片来源于作者）
- en: 'Here the content of the output CSV file:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出 CSV 文件的内容：
- en: '![](../Images/eeb8565fad9adc7fd92f210ae911f75b.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eeb8565fad9adc7fd92f210ae911f75b.png)'
- en: Figure 16 — Dummy table extracted in a CSV file using the SqlBulkExport module
    (image by the author)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16 — 使用 SqlBulkExport 模块提取的 CSV 文件中的虚拟表（图片来源于作者）
- en: As you can see, the output CSV file content meets the RFC 4180 standard. Because
    the dummy table used had few rows, only one batch was used for extraction. Let’s
    now try to extract the contents of a table having a few tens of thousands of rows.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，输出的 CSV 文件内容符合 RFC 4180 标准。由于使用的虚拟表行数较少，因此只使用了一个批次进行提取。现在我们来尝试提取一个拥有几万行的表的内容。
- en: Exporting the content of a table/view in one CSV file
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将表/视图的内容导出到一个 CSV 文件中
- en: 'As before, also the table we’re going to use to extract data from, is persisted
    in an Azure SQL database:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，我们要用于提取数据的表也保存在 Azure SQL 数据库中：
- en: Open the PowerShell 7 prompt, enter the `cd C:\Temp\sql-bulk-export-<version>`
    command and press *Enter* to change your working directory to the module’s one.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 PowerShell 7 提示符，输入 `cd C:\Temp\sql-bulk-export-<version>` 命令并按 *Enter* 键，将工作目录更改为模块目录。
- en: Enter the `Import-Module -Name ".\SqlBulkExport.psd1"` command to import the
    *SqlBulkExport* module.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `Import-Module -Name ".\SqlBulkExport.psd1"` 命令来导入 *SqlBulkExport* 模块。
- en: 'Enter the `Export-SqlBulkCsv -ServerName "<your-server-name>" -DatabaseName
    "<your-database-name>" -User "<username>" -Password "<password>" -TableViewName
    "<your-table-or-view-name>" -BatchSize 30000 -OutputFileFullPath "C:\Temp\output.csv"`
    command to export the content of a database table (or view) into the *output.csv*
    file in batches of 30K rows. Here the output:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`Export-SqlBulkCsv -ServerName "<your-server-name>" -DatabaseName "<your-database-name>"
    -User "<username>" -Password "<password>" -TableViewName "<your-table-or-view-name>"
    -BatchSize 30000 -OutputFileFullPath "C:\Temp\output.csv"`命令将数据库表（或视图）的内容按30K行的批次导出到*output.csv*文件中。以下是输出：
- en: '![](../Images/a5cec7c861005446c9f0d03d8c9c04ad.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5cec7c861005446c9f0d03d8c9c04ad.png)'
- en: Figure 17 — Console output of the command that extracts the contents of a tab/view
    into a CSV file (image by the author)
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图17 — 提取表/视图内容到CSV文件的命令的控制台输出（图片由作者提供）
- en: As you can see, it took 3 batches of 30K rows to extract the contents of a table
    of about 74K rows, taking a total of 1 second and 88 milliseconds. Not bad!
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，提取一个约74K行的表内容需要3批次的30K行，总共花费了1秒钟和88毫秒。不错！
- en: Let’s try using a query to export the data.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用查询来导出数据。
- en: Exporting the output of a query in one CSV file
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将查询输出导出到一个CSV文件中
- en: In this case we will extract data from the same table as in the previous case,
    but using a query like `SELECT * FROM <table> WHERE <condition>`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将从与前一个案例相同的表中提取数据，但使用类似`SELECT * FROM <table> WHERE <condition>`的查询。
- en: Open the PowerShell 7 prompt, enter the `cd C:\Temp\sql-bulk-export-<version>`
    command and press *Enter* to change your working directory to the module’s one.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开PowerShell 7提示符，输入`cd C:\Temp\sql-bulk-export-<version>`命令并按*Enter*键，将工作目录更改为模块目录。
- en: Enter the `Import-Module -Name ".\SqlBulkExport.psd1"` command to import the
    *SqlBulkExport* module.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`Import-Module -Name ".\SqlBulkExport.psd1"`命令以导入*SqlBulkExport*模块。
- en: 'Enter the `Export-SqlBulkCsv -ServerName "<your-server-name>" -DatabaseName
    "<your-database-name>" -User "<username>" -Password "<password>" -Query "SELECT
    * FROM <your-table-or-view-name> WHERE <condition>" -BatchSize 30000 -OutputFileFullPath
    "C:\Temp\output.csv"` command to export the content of a query result set into
    the *output.csv* file in batches of 30K rows. Here the output:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`Export-SqlBulkCsv -ServerName "<your-server-name>" -DatabaseName "<your-database-name>"
    -User "<username>" -Password "<password>" -Query "SELECT * FROM <your-table-or-view-name>
    WHERE <condition>" -BatchSize 30000 -OutputFileFullPath "C:\Temp\output.csv"`命令，将查询结果集的内容按30K行的批次导出到*output.csv*文件中。以下是输出：
- en: '![](../Images/d49bc259f0d72c2e9eb8eef2e6d11347.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d49bc259f0d72c2e9eb8eef2e6d11347.png)'
- en: Figure 18 — Console output of the command that extracts the output of a query
    into a CSV file (image by the author)
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图18 — 提取查询输出到CSV文件的命令的控制台输出（图片由作者提供）
- en: Everything works like a charm! Let us now try exporting the contents of one
    view to multiple monthly CSV files.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 一切运行得非常顺利！现在让我们尝试将一个视图的内容导出到多个每月的CSV文件中。
- en: Exporting the content of a table/view in multiple monthly CSV files
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将表/视图的内容导出到多个每月的CSV文件中
- en: Imagine you have a transaction table containing hundreds of thousands of rows
    per month. There is a group of Data Scientists from outside the company who are
    assigned to do advanced analysis on the transaction history. For convenience,
    they ask you to extract a dataset consisting of subsets of the fields available
    in the table for a couple of months of transactions. Instead of generating a single
    CSV file, they ask you to provide them with multiple CSV files broken down by
    month.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你有一个每月包含数十万行的交易表。有一组来自公司外部的数据科学家被分配来对交易历史进行高级分析。为了方便，他们要求你提取一个数据集，其中包含表中字段的子集，涵盖几个月的交易记录。他们要求你提供多个按月份划分的CSV文件，而不是生成一个单一的CSV文件。
- en: 'Let’s see how to do this thanks to the *Export-SqlBulkCsvByPeriod* function:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何通过*Export-SqlBulkCsvByPeriod*函数做到这一点：
- en: Open the PowerShell 7 prompt, enter the `cd C:\Temp\sql-bulk-export-<version>`
    command and press *Enter* to change your working directory to the module’s one.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开PowerShell 7提示符，输入`cd C:\Temp\sql-bulk-export-<version>`命令并按*Enter*键，将工作目录更改为模块目录。
- en: Enter the `Import-Module -Name ".\SqlBulkExport.psd1"` command to import the
    *SqlBulkExport* module.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`Import-Module -Name ".\SqlBulkExport.psd1"`命令以导入*SqlBulkExport*模块。
- en: 'Enter the `Export-SqlBulkCsvByPeriod -ServerName "<your-server-name>" -DatabaseName
    "<your-database-name>" -User "<username>" -Password "<password>" -TableViewName
    "<your-table-name>" -DateColumnName "<your-date-column-name>" -StartPeriod "2022-01"
    -EndPeriod "2022-03" -BatchSize 100000 -OutputFileFullPath "C:\Temp\output_{}.csv"`
    command to export the content of a database table (or view) into multiple monthly
    CSV files in batches of 100K rows, starting from January 2022 to March 2022\.
    Here the output:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/3a3b9613b382db4191d13ffd0b515f40.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
- en: Figure 19 — Console output of the command that extracts multiple monthly CSV
    file (image by the author)
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Amazing! You just extracted about 1.5mln rows broken down into three monthly
    CSV files in just 1 minute and 19 seconds!
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The need that prompted me to write this article is to extract a large amount
    of data (3–4+ GB) into one or more files in CSV format compliant with the RFC
    4180 standard.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: You have seen how the tools provided by Microsoft (whether they are IDEs, such
    as SSMS and ADS; whether they are command-line tools, such as BCP) are unable
    to meet the above need. The only tool that seemed a bit more suitable is ADS,
    but it cannot extract large amounts of data without crashing. Without mincing
    words, it is quite embarrassing that to date Microsoft has not yet made a tool
    available to users that would meet the requirements set forth above.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Not having found software on the Internet that met the above needs, I wrote
    the *SqlBulkExport* PowerShell module that solves the problem and made it available
    opensource [on GitHub](https://github.com/lucazav/sql-bulk-export) under an MIT
    license. I emphasize that I am not a PowerShell developer, so any input from you
    that would improve the solution is really welcome!
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
