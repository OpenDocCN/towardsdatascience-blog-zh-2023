- en: Bayesian AB Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/bayesian-ab-testing-ed45cc8c964d](https://towardsdatascience.com/bayesian-ab-testing-ed45cc8c964d)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[CAUSAL DATA SCIENCE](https://towardsdatascience.com/tagged/causal-data-science)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Using and choosing priors in randomized experiments.*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@matteo.courthoud?source=post_page-----ed45cc8c964d--------------------------------)[![Matteo
    Courthoud](../Images/d873eab35a0cf9fc696658c0bee16b33.png)](https://medium.com/@matteo.courthoud?source=post_page-----ed45cc8c964d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ed45cc8c964d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ed45cc8c964d--------------------------------)
    [Matteo Courthoud](https://medium.com/@matteo.courthoud?source=post_page-----ed45cc8c964d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ed45cc8c964d--------------------------------)
    ¬∑11 min read¬∑Jan 10, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df5da2cdfb6605d49b3a8df1019335f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Cover, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Randomized experiments, a.k.a. **AB tests**, are the established standard in
    the industry to estimate causal effects. Randomly assigning the treatment (new
    product, feature, UI, ‚Ä¶) to a subset of the population (users, patients, customers,
    ‚Ä¶) we ensure that, on average, the difference in outcomes (revenue, visits, clicks,
    ‚Ä¶) can be attributed to the treatment. Established companies like [Booking.com](https://partner.booking.com/en-gb/click-magazine/industry-perspectives/role-experimentation-bookingcom)
    report constantly running thousands of AB tests at the same time. And newer growing
    companies like [Duolingo](https://blog.duolingo.com/improving-duolingo-one-experiment-at-a-time/)
    attribute a large chunk of their success to their culture of experimentation at
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'With so many experiments, one question comes natural: in one specific experiment,
    can you leverage information from previous tests? How? In this post, I will try
    to answer these questions by introducing the **Bayesian approach to AB testing**.
    The Bayesian framework is well suited for this type of task because it naturally
    allows for the updating of existing knowledge (the prior) using new data. However,
    the method is particularly sensitive to functional form assumptions, and apparently
    innocuous model choices, like the skewness of the prior distribution, can translate
    into very different estimates.'
  prefs: []
  type: TYPE_NORMAL
- en: Search and Infinite Scrolling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the rest of the article, we are going to use a toy example, loosely inspired
    by [Azavedo et al. (2019)](https://www.aeaweb.org/articles?id=10.1257%2Fpandp.20191003):
    a **search engine** that wants to increase its **ad revenue**, without sacrificing
    search quality. We are a company with an established experimentation culture and
    we continuously test new ideas on how to improve our landing page. Suppose that
    we came up with a new brilliant idea: [infinite scrolling](https://blog.google/products/search/continuous-scrolling-mobile/)!
    Instead of having a discrete sequence of pages, we allow users to keep scrolling
    down if they want to see more results.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/06a5e4ee8ea9d5d056790f604188b8c6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image, generated by Author using [NightCaf√©](https://creator.nightcafe.studio/)
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand whether infinite scrolling works, we ran an **AB test**: we randomize
    users into a treatment and a control group and we implement infinite scrolling
    only for users in the treatment group. I import the data-generating process `dgp_infinite_scroll()`
    from `[src.dgp](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py)`.
    With respect to previous articles, I generated a new DGP parent class that handles
    randomization and data generation, while its children classes contain specific
    use cases. I also import some plotting functions and libraries from `[src.utils](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)`.
    To include not only code but also data and tables, I use [Deepnote](https://deepnote.com),
    a Jupyter-like web-based collaborative notebook environment.'
  prefs: []
  type: TYPE_NORMAL
- en: We have information on 10.000 website visitors for which we observe the monthly
    `ad_revenue` they generated, whether they were assigned to the treatment group
    and were using the `infinite_scroll`, and also the average monthly `past_revenue`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The random treatment assignment makes the **difference-in-means** estimator
    [**unbiased**](https://en.wikipedia.org/wiki/Bias_of_an_estimator): we expect
    the treatment and control group to be comparable on average, so we can causal
    attribute the average observed difference in outcomes to the treatment effect.
    We estimate the treatment effect by linear regression. We can interpret the coefficient
    of `infinite_scroll` as the estimated treatment effect.'
  prefs: []
  type: TYPE_NORMAL
- en: It seems that the `infinite_scroll` was indeed a good idea and it increased
    the average monthly revenue by 0.1524$. Moreover, the effect is significantly
    different from zero at the 1% confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: We could further improve the precision of the estimator by controlling for `past_revenue`
    in the regression. We do not expect a sensible change in the estimated coefficient,
    but the precision should improve (if you want to know more on control variables,
    check my other articles on [CUPED](/understanding-cuped-a822523641af) and [DAGs](/controls-b63dc69e3d8c)).
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, `past_revenue` is highly predictive of current `ad_revenue` and the
    precision of the estimated coefficient for `infinite_scroll` decreases by one-third.
  prefs: []
  type: TYPE_NORMAL
- en: So far, everything has been very standard. However, as we said at the beginning,
    suppose this is not the only experiment we ran trying to improve our browser (and
    ultimately ad revenue). The infinite scroll is just one idea among thousands of
    others that we have tested in the past. Is there a way to efficiently use this
    additional **information**?
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the main advantages of Bayesian statistics over the frequentist approach
    is that it easily allows to incorporate additional information into a model. The
    idea directly follows from the main theorem behind all Bayesian statistics: [**Bayes
    Theorem**](https://en.wikipedia.org/wiki/Bayes''_theorem). Bayes theorem, allows
    you to do inference on a model by **inverting the inference problem**: from the
    probability of the model given the data, to the probability of the data given
    the model, a much easier object to deal with.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c1b156c8d9cc62e6c9e75c9ef9302fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Bayes Theorem, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'We can split the right-hand side of Bayes Theorem into two components: the
    **prior** and the **likelihood**. The likelihood is the information about the
    model that comes from the data, the prior instead is any additional information
    about the model.'
  prefs: []
  type: TYPE_NORMAL
- en: First of all, let‚Äôs map Bayes theorem into our context. What is the data, what
    is the model, and what is our object of interest?
  prefs: []
  type: TYPE_NORMAL
- en: the **data** which consists of our outcome variable `ad_revenue`, *y*, the treatment
    `infinite_scroll`, *D* and the other variables, `past_revenue` and a constant,
    which we jointly denote as *X*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the **model** is the distribution of `ad_revenue`, given `past_revenue` and
    the `infinite_scroll` feature, *y|D,X*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: our **object of interest** is the posterior *Pr(model | data)*, in particular
    the relationship between `ad_revenue` and `infinite_scroll`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we use prior information in the context of AB testing, potentially including
    additional covariates?
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let‚Äôs use a linear model to make it directly comparable with the frequentist
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c6956e93d00d1110027196e4e62c76d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Conditional distribution of y|x, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a parametric model with **two sets of parameters**: the linear coefficients
    *Œ≤* and *œÑ*, and the variance of the residuals *œÉ*. An equivalent, but more Bayesian,
    way to write the model is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e1bcfc54584f23f114c4bd3393d19cff.png)'
  prefs: []
  type: TYPE_IMG
- en: Conditional distribution of y|x, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: where the semi-column separates the data from the model parameters. Differently
    from the frequentist approach, in Bayesian regressions, we do not rely on the
    [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) to
    approximate the conditional distribution of *y*, but we directly **assume** it
    is normal.
  prefs: []
  type: TYPE_NORMAL
- en: We are interested in doing inference on the model parameters, *Œ≤*, *œÑ*, and
    *œÉ*. Another **core difference** between the frequentist and the Bayesian approach
    is that the first assumes that the model parameters are fixed and unknown, while
    the latter allows them to be random variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'This assumption has a very practical **implication**: you can easily incorporate
    previous information about the model parameters in the form of **prior** distributions.
    As the name says, priors contain information that was available *before* looking
    at the data. This leads to one of the most relevant questions in Bayesian statistics:
    **how do you choose a prior**?'
  prefs: []
  type: TYPE_NORMAL
- en: Priors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When choosing a prior, one analytically appealing restriction is to have a prior
    distribution such that the posterior belongs to the same family. These priors
    are called **conjugate priors**. For example, before seeing the data, I assume
    my treatment effect is normally distributed and I would like it to be normally
    distributed also after incorporating the information contained in the data.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of Bayesian linear regression, the conjugate priors for *Œ≤*, *œÑ*,
    and *œÉ* are normally and inverse-gamma distributed. Let‚Äôs start by blindly using
    a standard normal and inverse gamma distribution as prior.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/af9184dc16201d5d1baf247a8a6d1e24.png)'
  prefs: []
  type: TYPE_IMG
- en: Prior distributions, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the probabilistic programming package [PyMC](https://www.pymc.io/projects/docs/en/stable/learn.html)
    to do inference. First, we need to specify the model: the prior distributions
    of the different parameters and the likelihood of the data.'
  prefs: []
  type: TYPE_NORMAL
- en: PyMC has an extremely nice function that allows us to visualize the model as
    a graph, `model_to_graphviz`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ea20c0b269460a1e85dede7516f44713.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the model, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: From the graphical representation, we can see the various model components,
    their distributions, and how they interact with each other.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to **compute** the model posterior. How does it work? In short,
    we sample realizations of model parameters, we compute the likelihood of the data
    given those values and derive the corresponding posterior.
  prefs: []
  type: TYPE_NORMAL
- en: The fact that Bayesian inference requires **sampling**, has been historically
    one of the main bottlenecks of Bayesian statistics since it makes it sensibly
    slower than the frequentist approach. However, this is less and less of a problem
    with the increased computational power of model computers.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to inspect the results. First, with the `summary()` method,
    we can print a model summary very similar to those produced by the `[statsmodels](https://www.statsmodels.org/dev/index.html)`
    package we used for linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: The estimated parameters are extremely close to the ones we got with the frequentist
    approach, with an estimated effect of the `infinite_scroll` equal to 0.157.
  prefs: []
  type: TYPE_NORMAL
- en: If sampling had the disadvantage of being slow, it has the advantage of being
    very **transparent**. We can directly plot the distribution of the posterior.
    Let‚Äôs do it for the treatment effect *œÑ*. The PyMC function `plot_posterior` plots
    the distribution of the posterior, with a black bar for the Bayesian equivalent
    of a 95% confidence interval.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b630dbc9300b7f6e652fde85b82098a.png)'
  prefs: []
  type: TYPE_IMG
- en: Posterior distribution of *œÑÃÇ, image by Author*
  prefs: []
  type: TYPE_NORMAL
- en: As expected, since we chose conjugate priors, the posterior distribution looks
    gaussian.
  prefs: []
  type: TYPE_NORMAL
- en: So far we have chosen the prior without much guidance. However, suppose we had
    access to **past experiments**. How do we incorporate this specific information?
  prefs: []
  type: TYPE_NORMAL
- en: Past Experiments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose that the idea of the infinite scroll was just one among a ton of **other
    ideas** that we tried and tested in the past. For each idea, we have the data
    on the corresponding experiment, with the corresponding estimated coefficient.
  prefs: []
  type: TYPE_NORMAL
- en: We have generated 1000 estimates from past experiments. How do we use this additional
    information?
  prefs: []
  type: TYPE_NORMAL
- en: Normal Prior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first idea could be to **calibrate** our prior to reflect the data distribution
    in the past. Keeping the normality assumption, we use the estimated average and
    standard deviations of the estimates from past experiments.
  prefs: []
  type: TYPE_NORMAL
- en: On average, had practically no effect on `ad_revenue`, with an average effect
    of 0.0009.
  prefs: []
  type: TYPE_NORMAL
- en: However, there was sensible variation across experiments, with a standard deviation
    of 0.029.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs rewrite the model, using the mean and standard deviation of past estimates
    for the prior distribution of *œÑ*.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs sample from the model
  prefs: []
  type: TYPE_NORMAL
- en: and plot the sample posterior distribution of the treatment effect parameter
    *œÑ*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a19a581ccf2c4c38a1b345acc141854d.png)'
  prefs: []
  type: TYPE_IMG
- en: Posterior distribution of *œÑÃÇ, image by Author*
  prefs: []
  type: TYPE_NORMAL
- en: 'The estimated coefficient is sensibly smaller: 0.11 instead of the previous
    estimate of 0.16\. Why is it the case?'
  prefs: []
  type: TYPE_NORMAL
- en: The fact is that the previous coefficient of 0.16 is extremely unlikely, given
    our prior. We can compute the probability of getting the same or a more extreme
    value, given the prior.
  prefs: []
  type: TYPE_NORMAL
- en: The probability of this value is virtually zero. Therefore, the estimated coefficient
    has moved towards the prior mean of 0.0009.
  prefs: []
  type: TYPE_NORMAL
- en: Student-t Prior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have assumed a normal distribution for all linear coefficients. Is
    it appropriate? Let‚Äôs check it visually (check [here](https://medium.com/towards-data-science/how-to-compare-two-or-more-distributions-9b06ee4d30bf)
    for other methods on how to compare distributions), starting from the intercept
    coefficient *Œ≤‚ÇÄ*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d72e820093e5d420a6ba1a951d44565a.png)'
  prefs: []
  type: TYPE_IMG
- en: The distribution seems pretty normal. What about the treatment effect parameter
    *œÑ*?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ce7182d1e58d384fac78d4e6f732bef9.png)'
  prefs: []
  type: TYPE_IMG
- en: The distribution is very **heavy-tailed**! While at the center it looks like
    a normal distribution, the tails are much ‚Äúfatter‚Äù and we have a couple of very
    extreme values. Excluding measurement error, this is a setting that happens often
    in the industry, where most ideas have extremely small or null effects, and very
    few ideas are breakthroughs.
  prefs: []
  type: TYPE_NORMAL
- en: One way to model this distribution is a [student-t](https://en.wikipedia.org/wiki/Student%27s_t-distribution)
    distribution. In particular, we use a t-student with mean 0.0009, variance 0.003,
    and 1.3 degrees of freedom to match the moments of the empirical distributions
    of past estimates.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs sample from the model.
  prefs: []
  type: TYPE_NORMAL
- en: And plot the sample posterior distribution of the treatment effect parameter
    *œÑ*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5ae956118438a68bff16dae1c021816.png)'
  prefs: []
  type: TYPE_IMG
- en: Posterior distribution of *œÑÃÇ, image by Author*
  prefs: []
  type: TYPE_NORMAL
- en: The estimated coefficient is now again similar to the one we got with the standard
    normal prior, 0.11\. However, the estimate is more precise since the confidence
    interval has shrunk from [0.077, 0.016] to [0.065, 0.015].
  prefs: []
  type: TYPE_NORMAL
- en: What has happened?
  prefs: []
  type: TYPE_NORMAL
- en: Shrinking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The answer lies in the shape of the different **prior distributions** that
    we have used:'
  prefs: []
  type: TYPE_NORMAL
- en: standard normal, N(0,1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: normal with matched moments, N(0, 0.03)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: t-student with matched moments, t‚ÇÅ.‚ÇÉ(0, 0.003)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let‚Äôs plot all of them together.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/abdf3ad8eaa441bf847053395335a2ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Different prior distributions, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, all distributions are centered on zero, but they have very different
    shapes. The standard normal distribution is essentially flat over the [-0.15,
    0.15] interval. Every value has basically the same probability. The last two instead,
    even though they have the same mean and variance, have very different shapes.
  prefs: []
  type: TYPE_NORMAL
- en: How does it translate into our estimation? We can plot the implied posterior
    for different estimates, for each prior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f07ed12b6145dde8c65e18e4049c650e.png)'
  prefs: []
  type: TYPE_IMG
- en: Effect of priors on experiment estimates, image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, the different priors transform the experimental estimates in
    very different ways. The standard normal prior essentially has no effect on estimates
    in the [-0.15, 0.15] interval. The normal prior with matched moments instead shrinks
    each estimate by approximately 2/3\. The effect of the t-student prior is instead
    **non-linear**: it shrinks small estimates towards zero, while it keeps large
    estimates as they are. The dotted grey line marks the effects of the different
    priors, for our experimental estimate *œÑÃÇ.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cd6c0ce346759de9409047ff7f0d924.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by Author using [NightCaf√©](https://creator.nightcafe.studio/)
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we have seen how to extend the analysis of AB tests to incorporate
    **information from past experiments**. In particular, we have introduced the Bayesian
    approach to AB testing and we have seen the importance of choosing a prior distribution.
    Given the same mean and variance, assuming a prior distribution with ‚Äúfat tails‚Äù
    (very skewed) implies a stronger shrinkage of small effects and a lower shrinkage
    of large effects.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **intuition** is the following: a prior distribution with ‚Äúfat tails‚Äù is
    equivalent to assuming that breakthrough ideas are rare but not impossible. This
    has practical **implications** after the experiment, as we have seen in this post,
    but also before it. In fact, as reported by [Azevedo et al. (2020)](https://www.journals.uchicago.edu/doi/full/10.1086/710607),
    if you think the distribution of the effects of your ideas is more ‚Äúnormal‚Äù, it
    is optimal to run *few but large* experiments to be able to discover smaller effects.
    If instead, you think that your ideas are ‚Äúbreakthrough or nothing‚Äù, i.e. their
    effects are fat-tailed, it makes more sense to run *small but many* experiments
    since you don‚Äôt need a large size to detect large effects.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'E. Azevedo, A. Deng, J. Olea, G. Weyl, [Empirical Bayes Estimation of Treatment
    Effects with Many A/B Tests: An Overview](https://www.aeaweb.org/articles?id=10.1257%2Fpandp.20191003)
    (2019). *AEA Papers and Proceedings*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: E. Azevedo, A. Deng, J. Olea, J. Rao, G. Weyl, [AB Testing with Fat Tails](https://www.journals.uchicago.edu/doi/full/10.1086/710607)
    (2020). *Journal of Political Economy*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A. Deng, [Objective Bayesian Two Sample Hypothesis Testing for Online Controlled
    Experiments](https://dl.acm.org/doi/abs/10.1145/2740908.2742563) (2016). *WWW
    ‚Äô15 Companion.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Related Articles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[The Bayesian Bootstrap](https://medium.com/towards-data-science/the-bayesian-bootstrap-6ca4a1d45148)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding CUPED](/understanding-cuped-a822523641af)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DAGs and Control Variables](/controls-b63dc69e3d8c)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can find the original Jupyter Notebook here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[## Blog-Posts/bayes_ab.ipynb at main ¬∑ matteocourthoud/Blog-Posts'
  prefs: []
  type: TYPE_NORMAL
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab or‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/bayes_ab.ipynb?source=post_page-----ed45cc8c964d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for reading!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*I really appreciate it!* ü§ó *If you liked the post and would like to see more,
    consider* [***following me***](https://medium.com/@matteo.courthoud)*. I post
    once a week on topics related to causal inference and data analysis. I try to
    keep my posts simple but precise, always providing code, examples, and simulations.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Also, a small* ***disclaimer****: I write to learn so mistakes are the norm,
    even though I try my best. Please, when you spot them, let me know. I also appreciate
    suggestions on new topics!*'
  prefs: []
  type: TYPE_NORMAL
