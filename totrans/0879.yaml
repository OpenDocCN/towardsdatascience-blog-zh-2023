- en: 'FastAPI and Streamlit: The Python Duo You Must Know About'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243](https://towardsdatascience.com/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[THE FULL STACK 7-STEPS MLOPS FRAMEWORK](https://towardsdatascience.com/tagged/full-stack-mlops)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Lesson 6: Consume and Visualize your Model''s Predictions using FastAPI and
    Streamlit. Dockerize Everything'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/?source=post_page-----72825def1243--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----72825def1243--------------------------------)[](https://towardsdatascience.com/?source=post_page-----72825def1243--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----72825def1243--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----72825def1243--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----72825def1243--------------------------------)
    ·14 min read·Jun 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7beb5df667e2b1bf00cd37002c98447f.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial represents **lesson 6 out of a 7-lesson course** that will walk
    you step-by-step through how to **design, implement, and deploy an ML system**
    using **MLOps good practices**. During the course, you will build a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  prefs: []
  type: TYPE_NORMAL
- en: '*By the end of this course, you will understand all the fundamentals of designing,
    coding and deploying an ML system using a batch-serving architecture.*'
  prefs: []
  type: TYPE_NORMAL
- en: This course *targets mid/advanced machine learning engineers* who want to level
    up their skills by building their own end-to-end projects.
  prefs: []
  type: TYPE_NORMAL
- en: '*Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Table of Contents:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Lessons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lesson 6: Consume and Visualize your Model’s Predictions using FastAPI and
    Streamlit. Dockerize Everything.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lesson 6: Code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Course Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***At the end of this 7 lessons course, you will know how to:***'
  prefs: []
  type: TYPE_NORMAL
- en: design a batch-serving architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Hopsworks as a feature store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: design a feature engineering pipeline that reads data from an API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a training pipeline with hyper-parameter tunning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: implement a batch prediction pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Poetry to build your own Python packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy your own private PyPi server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: orchestrate everything with Airflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the predictions to code a web app using FastAPI and Streamlit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Docker to containerize your code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use Great Expectations to ensure data validation and integrity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: monitor the performance of the predictions over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deploy everything to GCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a CI/CD pipeline using GitHub Actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If that sounds like a lot, don't worry. After you cover this course, you will
    understand everything I said before. Most importantly, you will know WHY I used
    all these tools and how they work together as a system.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. This course is designed to quickly read and replicate
    the code along the articles.**'
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the course, you will know how to implement the diagram below.
    Don't worry if something doesn't make sense to you. I will explain everything
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the architecture you will build during the course [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: By the **end of Lesson 6**, you will know how to consume the predictions and
    the monitoring metrics from the GCP bucket within a web app using FastAPI and
    Streamlit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Course Lessons:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Batch Serving. Feature Stores. Feature Engineering Pipelines.](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Training Pipelines. ML Platforms. Hyperparameter Tuning.](https://medium.com/towards-data-science/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Consume and Visualize your Model''s Predictions using FastAPI and Streamlit.
    Dockerize Everything.**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github Actions.](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[[Bonus] Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and Insights](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check out [Lesson 3](/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)
    to learn how we computed and stored the predictions in a GCP bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Also, in [Lesson 5](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360),
    you can see how we calculated the monitoring metrics, which are also stored in
    a GCP bucket.
  prefs: []
  type: TYPE_NORMAL
- en: You will consume the predictions and the monitoring metrics from the GCP bucket
    and display them in a friendly dashboard using FastAPI and Streamlit.
  prefs: []
  type: TYPE_NORMAL
- en: Data Source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We used a free & open API that provides hourly energy consumption values for
    all the energy consumer types within Denmark [1].
  prefs: []
  type: TYPE_NORMAL
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data has 4 main attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 — divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total Consumption:** Total electricity consumption in kWh'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would in real-time.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4eab6debdb7ba94406b8d0a8e28e3438.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot from our web app showing how we forecasted the energy consumption
    for area = 1 and consumer_type = 212 [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'The data points have an hourly resolution. For example: "2023–04–15 21:00Z",
    "2023–04–15 20:00Z", "2023–04–15 19:00Z", etc.'
  prefs: []
  type: TYPE_NORMAL
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  prefs: []
  type: TYPE_NORMAL
- en: '*Check out the video below to better understand what the data looks like* 👇'
  prefs: []
  type: TYPE_NORMAL
- en: Course & data source overview [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'Lesson 6: Consume and Visualize your Model''s Predictions using FastAPI and
    Streamlit. Dockerize Everything.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of Lesson 6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Lesson 6, you will build a FastAPI backend that will consume the predictions
    and monitoring metrics from GCS and expose them through a RESTful API. More concretely,
    through a set of endpoints that will expose the data through HTTP(S).
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, you will implement 2 different frontend applications using solely Streamlit:'
  prefs: []
  type: TYPE_NORMAL
- en: a dashboard showing the forecasts (aka your application),
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a dashboard showing the monitoring metrics (aka your monitoring dashboard).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both frontend applications will request data from the FastAPI RESTful API through
    HTTP(s) and use Streamlit to render the data into some beautiful plots.
  prefs: []
  type: TYPE_NORMAL
- en: I want to highlight that you can use both frameworks (FastAPI & Streamlit) in
    Python. This is extremely useful for a DS or MLE, as Python is their holy grail.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a7712f71ecc251c99dd732bb42dc92c.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the final architecture with the Lesson 6 components highlighted in
    blue [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that consuming the predictions from the bucket is completely decoupled
    from the 3 pipeline design. For example, running the 3 pipelines: feature engineer,
    training, and inference takes ~10 minutes. But to read the predictions or the
    monitor metrics from the bucket is almost instant.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, by caching the predictions into GCP, you served the ML model online from
    the client''s point of view: the predictions are served in real time.'
  prefs: []
  type: TYPE_NORMAL
- en: '*This is the magic of the batch architecture.*'
  prefs: []
  type: TYPE_NORMAL
- en: The next natural steps are to move your architecture from a batch architecture
    to a request-response or streaming one.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that the FE and training pipelines would be almost the same,
    and you would have to move only the batch prediction pipeline (aka the inference
    step) into your web infrastructure. [Read this article to learn the basics of
    deploying your model in a request-response fashion using Docker.](https://medium.com/faun/key-concepts-for-model-serving-38ccbb2de372)
  prefs: []
  type: TYPE_NORMAL
- en: '***Why?***'
  prefs: []
  type: TYPE_NORMAL
- en: Because the training pipeline uploads the weights of the trained model into
    the model registry. From there, you can use the weights as it fits best for your
    use case.
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical Concepts & Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**FastAPI:** One of the latest and most famous Python API web frameworks. I
    have tried all of the top Python API web frameworks: Django, Flask, and FastAPI,
    and my heart goes to FastAPI.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Why?***'
  prefs: []
  type: TYPE_NORMAL
- en: First, it is natively async, which can boost performance with fewer computing
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, it is easy and intuitive to use, which makes it suitable for applications
    of all sizes. Even though, for behemoth monoliths, I would still choose Django.
    But this is a topic for another time.
  prefs: []
  type: TYPE_NORMAL
- en: '**Streamlit:** Streamlit makes coding simple UI components, mostly dashboards,
    extremely accessible using solely Python.'
  prefs: []
  type: TYPE_NORMAL
- en: The scope of Streamlit is to let Data Scientists and ML engineers use what they
    know best, aka Python, to build a beautiful frontend for their models quickly.
  prefs: []
  type: TYPE_NORMAL
- en: '*Which is precisely what we did*✌️'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, you will use FastAPI as your backend and Streamlit as your frontend to
    build a web app solely in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lesson 6: Code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[You can access the GitHub repository here.](https://github.com/iusztinpaul/energy-forecasting)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** All the installation instructions are in the READMEs of the repository.
    Here you will jump straight to the code.'
  prefs: []
  type: TYPE_NORMAL
- en: '*The code within Lesson 6 is located under the following:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[***app-api***](https://github.com/iusztinpaul/energy-forecasting/tree/main/app-api)folder
    — FastAPI backend'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***app-frontend***](https://github.com/iusztinpaul/energy-forecasting/tree/main/app-frontend)
    folder — Predictions Dashboard'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[***app-monitoring***](https://github.com/iusztinpaul/energy-forecasting/tree/main/app-monitoring)
    folder — Monitoring Dashboard'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using Docker, you can quickly spin up all 3 components at once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Directly storing credentials in your git repository is a huge security risk.
    That is why you will inject sensitive information using a **.env** file.
  prefs: []
  type: TYPE_NORMAL
- en: The **.env.default** is an example of all the variables you must configure.
    It is also helpful to store default values for attributes that are not sensitive
    (e.g., project name).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/87b81fc121cea9485a6b41dd4d656eb8.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot of the .env.default file [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: Prepare Credentials
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this lesson, the only service you need access to is GCS. In the **Prepare
    Credentials** section of[Lesson 3](/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489),
    we already explained in detail how to do this. Also, you have more information
    in the [GitHub README](https://github.com/iusztinpaul/energy-forecasting/blob/main/README.md#gcp).
  prefs: []
  type: TYPE_NORMAL
- en: To keep things concise, in this lesson, I want to highlight that the web app
    GCP service account should have read access only for security reasons.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why?**'
  prefs: []
  type: TYPE_NORMAL
- en: Becausethe FastAPI API will only read data from the GCP buckets & keeping the
    permissions to the bare minimum is good practice.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, if your web app is hacked, the attacker can only read the data using the
    stolen service account credentials. He can't delete or overwrite the data, which
    is much more dangerous in this case.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, repeat the same steps as in the **Prepare Credentials** section of [Lesson
    3](/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489),
    but instead of choosing the *Store Object Admin* role, choose the *Storage Object
    Viewer role*.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that now you have to download a different JSON file containing your
    GCP service account key with read-only access.
  prefs: []
  type: TYPE_NORMAL
- en: Check out the [README](https://github.com/iusztinpaul/energy-forecasting/blob/main/README.md#the-web-app)
    to learn how to complete the **.env** file. I want to highlight that only the
    FastAPI backend will have to load the **.env** file. Thus, you must place the
    **.env** file only in the [***app-api***](https://github.com/iusztinpaul/energy-forecasting/tree/main/app-api)
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: FastAPI Backend
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FastAPI backend overview [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: As a reminder, the FastAPI code can be found under [***app-api/api***](https://github.com/iusztinpaul/energy-forecasting/tree/main/app-api/api).
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1:** Create the FastAPI application, where we configured the docs, the
    CORS middleware and the endpoints root API router.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2:** Define the Settings class. The scope of this class is to hold all
    the constants and configurations you need across your API code, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*generic configurations:* the port, log level or version,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*GCP credentials:* bucket name or path to the JSON service account keys.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will use the Settings object across the project using the **get_settings()**
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Also, inside the **Config** class, we programmed FastAPI to look for a **.env**
    file in the current directory and load all the variables prefixed with **APP_API_.**
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the **.env.default** file, all the variables start with **APP_API_**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/87b81fc121cea9485a6b41dd4d656eb8.png)'
  prefs: []
  type: TYPE_IMG
- en: A screenshot of the .env.default file [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3:** Define the schemas of the API data using Pydantic. These schemas
    encode or decode data from JSON to a Python object or vice versa. Also, they validate
    the type and structure of your JSON object based on your defined data model.'
  prefs: []
  type: TYPE_NORMAL
- en: When defining a Pydantic BaseModel, it is essential to add a type to every variable,
    which will be used at the validation step.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4:** Define your endpoints, in web lingo, known as views. Usually, a
    view has access to some data storage and based on a query, it returns a subset
    of the data source to the requester.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Thus, a standard flow for retrieving (aka GET request) data looks like this:***'
  prefs: []
  type: TYPE_NORMAL
- en: “client → request data → endpoint → access data storage → encode to a Pydantic
    schema → decode to JSON → respond with requested data”
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how we defined an endpoint to GET all the consumer types:'
  prefs: []
  type: TYPE_NORMAL
- en: We used "**gcsfs.GCSFileSystem"** to access the GCS bucket as a standard filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: We attached the endpoint to the **api_router**.
  prefs: []
  type: TYPE_NORMAL
- en: Using the **api_router.get()** Python decorator, we attached a basic function
    to the **/consumer_type_values** endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: In the example above, when calling "**https://<some_ip>:8001/api/v1/consumer_type_values"**
    the **consumer_type_values()** function will be triggered, and the response of
    the endpoint will be strictly based on what the function return.
  prefs: []
  type: TYPE_NORMAL
- en: Another important thing is to highlight that by defining the **response_model
    (aka the schema) in the Python decorator,** you don't have to create the Pydantic
    schema explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: If you return a dictionary that is 1:1, respecting the schema structure, FastAPI
    will automatically create the Pydantic object for you.
  prefs: []
  type: TYPE_NORMAL
- en: '*That''s it. Now we will repeat the same logic to define the rest of the endpoints.
    FastAPI makes everything so easy and intuitive for you.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at the whole [***views.py***](https://github.com/iusztinpaul/energy-forecasting/blob/main/app-api/api/views.py)file,
    where we defined endpoints for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**/health** → health check'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**/consumer_type_values** → GET all possible consumer types'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**/area_values** → GET all possible area types'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**/predictions/{area}/{consumer_type}** → GET the predictions for a given area
    and consumer type. Note that using the {<some_variable>} syntax, you can add parameters
    to your endpoint — [FastAPI docs](https://fastapi.tiangolo.com/tutorial/path-params/)
    [2].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**/monitoring/metrics** → GET the aggregated monitoring metrics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**/monitoring/values/{area}/{consumer_type}** → GET the monitoring values for
    a given area and consumer type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I want to highlight again that the FastAPI backend only reads the GCS bucket's
    predictions. The inference step is done solely in the batch prediction pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also go to "[**http://<your-ip>:8001/api/v1/docs**](http://35.207.134.188:8001/api/v1/docs)**"**
    to access the Swagger docs of the API, where you can easily see and test all your
    endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f22922d4e71d0df403068efcff1c0d3c.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the Swapper API docs [Image by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: Thats it! Now you know how to build a FastAPI backend. Things might get more
    complicated when adding a database layer and user sessions, but you learned all
    the main concepts that will get you started!
  prefs: []
  type: TYPE_NORMAL
- en: Streamlit Predictions Dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Streamlit predictions dashboard overview [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: Access the code under [***app-frontend/frontend***](https://github.com/iusztinpaul/energy-forecasting/tree/main/app-frontend/frontend).
  prefs: []
  type: TYPE_NORMAL
- en: Using Streamlit is quite simple. The whole UI is defined using the code below
    that does the following
  prefs: []
  type: TYPE_NORMAL
- en: it defines the title,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: it makes a request to the backend for all possible area types & creates a dropdown
    based on it,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: it makes a request to the backend for all possible consumer types & creates
    a dropdown based on it,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: based on the current chosen area and consumer types, it builds and renders a
    plotly chart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Straight forward, right?
  prefs: []
  type: TYPE_NORMAL
- en: Note that we could have made additional checks for the status code of the HTTP
    requests. For example, if the request status code differs from 200, display a
    text with "The server is down." But we wanted to keep things simple and emphasize
    only the Streamlit code ✌️
  prefs: []
  type: TYPE_NORMAL
- en: We moved all the constants to a different file to be easily accessible all over
    the code. As a next step, you could make them configurable through a **.env**
    file, similar to the FastAPI setup.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how we built the chart 🔥
  prefs: []
  type: TYPE_NORMAL
- en: This part contains no Streamlit code, only some Pandas and Plotly code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **build_data_plot()** function performs 3 main steps:'
  prefs: []
  type: TYPE_NORMAL
- en: It requests the prediction data for an area and consumer type from the FastAPI
    backend.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the response is valid (status_code == 200), it extracts the data from the
    response and builds a DataFrame from it. Otherwise, it creates an empty DataFrame
    to pass the same structure further.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It builds a line plot — plotly graph using the DataFrame computed above.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The role of the **build_dataframe()** function is to take 2 lists:'
  prefs: []
  type: TYPE_NORMAL
- en: a list of datetimes which will be used as the X axis of the line plot;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a list of values that be used as the Y-axis of the line plot;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: …and to convert them into a DataFrame. If some data points are missing, we resample
    the datetimes to a frequency of 1H to have the data continuous and highlight the
    missing data points.
  prefs: []
  type: TYPE_NORMAL
- en: Quite simple, right? That is why people love Streamlit.
  prefs: []
  type: TYPE_NORMAL
- en: Streamlit Monitoring Dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Streamlit monitoring dashboard overview [Video by the Author].
  prefs: []
  type: TYPE_NORMAL
- en: The monitoring code can be accessed under [***app-monitoring/monitoring***](https://github.com/iusztinpaul/energy-forecasting/tree/main/app-monitoring)***.***
  prefs: []
  type: TYPE_NORMAL
- en: You will see that the code is almost identical to the predictions dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: When defining the Streamlit UI structure, we additionally implemented a plot
    containing the aggregated metrics and a divider.
  prefs: []
  type: TYPE_NORMAL
- en: The nice thing about decoupling the definition of the UI components with the
    data access is that you can inject any data in the UI without modifying it as
    long as you respect the interface of the expected data.
  prefs: []
  type: TYPE_NORMAL
- en: The **build_metrics_plot()** function is almost identical to the **build_data_plot()**
    function from the predictions dashboard, except for the data we request from the
    API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same story goes for the **build_data_plot()** function from the monitoring
    dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, all the data access and manipulation are handled on the FastAPI
    backend. The Streamlit UI's job is to request and display the data.
  prefs: []
  type: TYPE_NORMAL
- en: It is nice that we just reused 90% of the predictions dashboard code to build
    a friendly monitoring dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap Everything with Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final step is to Dockerize the 3 web applications and wrap them up in a
    docker-compose file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we can start the whole web application with a single command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '***Here is the*** [***FastAPI Dockerfile***](https://github.com/iusztinpaul/energy-forecasting/blob/main/app-api/Dockerfile)***:***'
  prefs: []
  type: TYPE_NORMAL
- en: One interesting thing to highlight is that we initially copied & installed only
    the Poetry dependencies. Thus, when you modify the code, the Docker image will
    be rebuilt only starting from line 19, aka copying your code.
  prefs: []
  type: TYPE_NORMAL
- en: This is a common strategy to leverage the Docker caching features when building
    an image to speed up your development process, as you rarely add new dependencies
    and installing them is the most time-consuming step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, inside **run.sh** we call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: But wait, there is no Python file in the command 😟
  prefs: []
  type: TYPE_NORMAL
- en: Well, you can actually define a **__main__.py** file inside a module, making
    your module executable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, when calling the **api** module, you call the [**__main__.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/app-api/api/__main__.py)
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: In our case, in the[**__main__.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/app-api/api/__main__.py)
    file, we use the uvicorn web server to start the FastAPI backend and configure
    it with the right IP, port, log_level, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '**Here is the** [**Streamlit predictions dashboard Dockerfile**](https://github.com/iusztinpaul/energy-forecasting/blob/main/app-frontend/Dockerfile)**:**'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this Dockerfile is almost identical to the one used for the
    FastAPI backend, except for the last **CMD** command, which is a standard CLI
    command for starting your Streamlit application.
  prefs: []
  type: TYPE_NORMAL
- en: The [Streamlit monitoring dashboard Dockerfile](https://github.com/iusztinpaul/energy-forecasting/blob/main/app-monitoring/Dockerfile)
    is identical to the predictions dashboard Dockerfile. So it is redundant to copy-paste
    it here.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that you can leverage the Dockerfile template I showed you
    above to Dockerize most of your Python applications ✌️
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s see how to wrap up everything with docker-compose. You can
    access the file under [***deploy/app-docker-compose.yml***](https://github.com/iusztinpaul/energy-forecasting/blob/main/deploy/app-docker-compose.yml):'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the frontend and monitoring services must wait for the API to
    turn on before starting.
  prefs: []
  type: TYPE_NORMAL
- en: Also, only the API needs to load the credentials from a **.env** file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you can run the entire web application using only the following command,
    and Docker will take care of building the images and running the containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You finished the **sixth lesson** from the **Full Stack 7-Steps
    MLOps Framework** course. It means that now you understand how to consume the
    predictions of your ML system to build your awesome application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this lesson, you learned how to:'
  prefs: []
  type: TYPE_NORMAL
- en: consume the predictions & monitoring metrics from GCS,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: build a FastAPI backend to load and serve the data from GCS,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: implement a dashboard in Streamlit to show the predictions,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: create a monitoring dashboard in Streamlit to visualize the performance of the
    model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you understand the flexibility of building an application on top of
    an ML system that uses a batch prediction architecture, you can easily design
    full-stack machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: '[Check out Lesson 7](/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)
    for the final step of the **Full Stack 7-Steps MLOps Framework**, which is to
    deploy everything to GCP and build a CI/CD pipeline using GitHub Actions.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Also,** [**you can access the GitHub repository here**](https://github.com/iusztinpaul/energy-forecasting)**.**'
  prefs: []
  type: TYPE_NORMAL
- en: 💡 My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  prefs: []
  type: TYPE_NORMAL
- en: 🔥 If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). Using [my
    referral link](https://pauliusztin.medium.com/membership), you can support me
    without extra cost while enjoying limitless access to Medium's rich collection
    of stories.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----72825def1243--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  prefs: []
  type: TYPE_NORMAL
- en: 🤖 Join to get exclusive content about designing and building production-ready
    ML systems 🚀 Unlock full access to…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----72825def1243--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Thank you ✌🏼 !
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Path Parameters](https://fastapi.tiangolo.com/tutorial/path-params/),
    FastAPI Documentation'
  prefs: []
  type: TYPE_NORMAL
