- en: 'Mastering the Art of Regression Analysis: 5 Key Metrics Every Data Scientist
    Should Know'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mastering-the-art-of-regression-analysis-5-key-metrics-every-data-scientist-should-know-1e2a8a2936f5](https://towardsdatascience.com/mastering-the-art-of-regression-analysis-5-key-metrics-every-data-scientist-should-know-1e2a8a2936f5)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The definitive guide on all the knowledge you should have on the metrics used
    in regression analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://federicotrotta.medium.com/?source=post_page-----1e2a8a2936f5--------------------------------)[![Federico
    Trotta](../Images/e997e3a96940c16ab5071629016d82fd.png)](https://federicotrotta.medium.com/?source=post_page-----1e2a8a2936f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1e2a8a2936f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1e2a8a2936f5--------------------------------)
    [Federico Trotta](https://federicotrotta.medium.com/?source=post_page-----1e2a8a2936f5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1e2a8a2936f5--------------------------------)
    ·14 min read·Feb 20, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/32e89ae41525384c0ef802641c329339.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by Author on Dall-E by the prompt “A futuristic robot teaching
    math at a blackboard”.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of Supervised Learning, we can subdivide the ML problems into two
    subgroups: regression and classification problems.'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll discuss the five metrics we use in the case of regression
    analysis to understand if a model is good or bad to solve a particular ML problem.
  prefs: []
  type: TYPE_NORMAL
- en: But, first of all, let’s refresh what is a regression analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '**Regression analysis** is a mathematical technique useful to find a functional
    relationship between a dependent variable and one or more independent variable(s).'
  prefs: []
  type: TYPE_NORMAL
- en: In ML we define “feature” as the independent variable and “label” (or “target”)
    as the dependent variable, so the aim of regression analysis is to find an estimate
    (a good one!) between the features and the label.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The residuals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before talking about the metrics, we need to talk about the **residuals**.
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of simplicity, let’s consider the linear regression model (but
    the results can be generalized for any other ML model).
  prefs: []
  type: TYPE_NORMAL
- en: 'So, suppose we have a dataset where the data are distributed somehow linearly.
    We typically find a situation like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d3bc6d25e582b685c1b0f6f5daf2d8f.png)'
  prefs: []
  type: TYPE_IMG
- en: A regression line. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The red line is called the **regression line** and it is the line through which
    we will make our predictions. As we can see, the data points do not lie perfectly
    on the regression line; so we can define the **residuals** as the error between
    the regression line (the predictions) and the actual data points, in the vertical
    direction.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, with respect to the above image, we mathematically define a residual as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c40efda98c5130aae9a2e012c6613dc.png)'
  prefs: []
  type: TYPE_IMG
- en: The definition of a residual. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: What we would like to have is `e_i=0` because this means that all the data points
    lie exactly on the regression line but, unfortunately, this is not possible and
    this is why we use the following metrics to validate our ML models, in the case
    of a regression problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define *“hat” y* as the **fitted** or **predicted value** (fitted/predicted
    by the model: in this case, the linear regression model), while *y* is the **true
    value**. So, the predicted values can be calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46f1ea9f17fc341b35e796cddca90015.png)'
  prefs: []
  type: TYPE_IMG
- en: How to calculate the predicted values. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: where in the above formula the coefficients *w* (called the *weight)* and *b*
    (called the *bias* or *constant)* are estimated values, which means that are learned
    during the learning process by the ML model.
  prefs: []
  type: TYPE_NORMAL
- en: 'This knowledge is important because now we can define the **Residual Sum of
    Squares (RSS)** as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6f2d41eac75a3e1245e64949dbbcc57c.png)'
  prefs: []
  type: TYPE_IMG
- en: The formula for the Residuals Sum of Squares. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if we substitute inside the parenthesis the formula for the predicted
    values we’ve seen before we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ff6b3fee22d6a6f64894cefaa79f027.png)'
  prefs: []
  type: TYPE_IMG
- en: The extended formula for the Residuals Sum of Squares. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Where the estimated coefficients *w* and *b* are the ones that minimize the
    RSS.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, we have to remember that the process of learning requires that the
    chosen **metrics** (also called **cost functions** or **loss functions**) must
    be minimized.
  prefs: []
  type: TYPE_NORMAL
- en: 'In mathematics, minimizing a function means calculating its derivative and
    equaling it to 0\. So, we should perform something like that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f3fa2f68d8f80c848606aef419a80336.png)'
  prefs: []
  type: TYPE_IMG
- en: The derivative of the RSS function with respect to w. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e12032aeb11fa08cf27f71b91c34078.png)'
  prefs: []
  type: TYPE_IMG
- en: The derivative of the RSS function with respect to b. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'We won’t do the calculations here; so, consider that the results of these calculations
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d048f1cc39719bce0b3acade97dd85f2.png)'
  prefs: []
  type: TYPE_IMG
- en: The values that minimize the RSS function Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Where, in the above formula, x and y with a “bar” above are the mean values.
    So they can be calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/822f81f1df95aafb57d762392e2a4fd2.png)'
  prefs: []
  type: TYPE_IMG
- en: The mean value of x (it also applies to y). Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Now, with all this in mind, we’ll define and calculate the 5 cost functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use 5 numbers in a table to show the differences between the various
    metrics. The table has the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The true values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The predicted values (the values predicted by the linear regression model).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/55c8bde03ef2a7ad0aa4e12f83689240.png)'
  prefs: []
  type: TYPE_IMG
- en: The table we’ll refer to for the following calculations. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 1\. The mean squared error (MSE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We define the **mean squared error** (**MSE**) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f83fee927f25fbcd4f9fbbafb577c8fa.png)'
  prefs: []
  type: TYPE_IMG
- en: The definition of the MSE. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Where *n* is the number of observations. In other words, it represents how many
    values in total we have. In our case, since we have a table with just 5 numbers,
    then n=5.
  prefs: []
  type: TYPE_NORMAL
- en: The MSE measures the average squared difference between the predicted and the
    actual values. In other words, it tells us how far our predictions are from the
    actual values, on average.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s calculate it, with respect to the tabled values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bdfd3e90676eab4ec256ae3c9631cd96.png)'
  prefs: []
  type: TYPE_IMG
- en: The calculation of MSE with the given numbers. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'And we get: MSE = 51.2'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. The root mean square error (RMSE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **root mean square error** (**RMSE)** is simply the root square of the
    MSE; so its formula is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ff8464e6b11c6e886a50e3fcf4ec399.png)'
  prefs: []
  type: TYPE_IMG
- en: The definition of the RMSE. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s consider the values in the above table, and calculate the RMSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/277d8a4b1694b8226ae09a932384747b.png)'
  prefs: []
  type: TYPE_IMG
- en: The calculation of RMSE with the given numbers. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: There is not a big difference between MSE and RMSE. They refer to the same quantities,
    and the only mathematical difference is that RMSE has a square root. However,
    RMSE is easier to interpret, as it is in the same units as the input values (the
    predicted and the true values), so is more directly comparable to them.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s make an example to understand that.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that we have trained a linear regression model to predict the price
    of a house based on its size and number of bedrooms. We calculate the values of
    the MSE and RMSE and compare them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose the model predicts that a house with 1000 square feet and 2 bedrooms
    will have a price of 200,000 USD. However, the actual price of the house is 250,000
    USD. We’ll have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7df77eae6e70c084bc86aebfa2e9aa03.png)'
  prefs: []
  type: TYPE_IMG
- en: MSE for the price of the house (n=1 in this case because we calculated just
    one value). Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c924e89da00961a441cd1b0f988d8abb.png)'
  prefs: []
  type: TYPE_IMG
- en: RMSE for the price of the house (n=1 in this case because we calculated just
    one value). Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, here’s the point: RMSE is easily comparable with the input data because,
    in such cases, how would we explain USD² as a unit of measure? Is not explainable,
    but it is the correct one!'
  prefs: []
  type: TYPE_NORMAL
- en: So, this is the difference between these two metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. The mean absolute error (MAE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **mean absolute error** (**MAE**) is another way to calculate the distance
    between the actual data point and the predicted one. Its formula is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/abecac058a86c04d1377bf39428d9b29.png)'
  prefs: []
  type: TYPE_IMG
- en: The definition of the MAE. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Here the distance between the actual and the estimated values is calculated
    with the norm (sometimes called “Manhattan distance”).
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the formula, even MAE is in the same units as the input values,
    so is easy to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s consider the values in the table, and calculate MAE:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/faa0b71bb9a3f1fbac22da7d12789861.png)'
  prefs: []
  type: TYPE_IMG
- en: The calculation of MAE with the given numbers. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'And we get: MAE = 5.6.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, before explaining the other two metrics, we have to say something about
    the three above.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen that MAE and RMSE are more easily explainable than MSE because
    the results we get have the same unit as the input data, but this is not the only
    thing we can say.
  prefs: []
  type: TYPE_NORMAL
- en: One other thing to say is that a value near 0 **for any** of these metrics indicates
    that the model’s predictions are closer to the actual values; in other words,
    the model predicts pretty well the data.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, values that are far from 0 indicate that the model’s predictions are
    far from the actual values; in other words, the model badly predicts the data.
  prefs: []
  type: TYPE_NORMAL
- en: Another thing we can say is that MSE and RMSE are sensitive to outliers, because
    they are based on the squared differences between the predicted and true values.
    In cases where there are a few large errors between the actual and the predicted
    values, the squared errors will be very large, and this affects significantly
    MSE and RMSE. In these cases, it may be more appropriate to use a different MAE,
    which is less sensitive to outliers.
  prefs: []
  type: TYPE_NORMAL
- en: If we analyze the above table, we can see that the prediction for the fifth
    data point is very far off (the true value is 50 while the predicted value is
    64), and this has a significant impact on the MSE but a smaller impact on MAE,
    as we can see from the results we have obtained.
  prefs: []
  type: TYPE_NORMAL
- en: So, one of the first things we should always do is to correctly treat the outliers
    (and [here’s an article](/how-to-detect-outliers-in-a-data-science-project-17f39653fb17)
    explaining how you can do so).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another thing to take into account is that we won’t use a single model to solve
    our ML problems: typically, we start with 4–5, refine their hyperparameters and,
    in the end, we’ll choose the best model.'
  prefs: []
  type: TYPE_NORMAL
- en: But as a starting point, as we may understand, we can’t calculate MAE, MSE,
    and RMSE for 4–5 models because it will be time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s see a situation we typically face: we have decided to use a pool
    of 5 ML models and, for example, we have calculated MAE and get the following
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'MAE for ML_1: 115'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MAE for ML_2: 351'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MAE for ML_3: 78'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MAE for ML_4: 1103'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MAE for ML_5: 3427'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We know that the value of MAE (but this applies even for MSE and RMSE) has
    to be as near as possible to 0; so we understand immediately that ML_1 and ML_3
    are the best among the 5 we have chosen, but the question is: how good are they?'
  prefs: []
  type: TYPE_NORMAL
- en: Each of these metrics can reach any value, even 1 million or more. We only know
    that we have to be as near as possible to 0 to say that our model is good to solve
    this ML problem; but how near must the result be to 0? Is an MAE of 78 enough
    to say that ML_3 is very good to solve this ML problem?
  prefs: []
  type: TYPE_NORMAL
- en: So, because of the fact that each of these metrics can reach any value, statisticians
    have defined other two metrics that have values bounded between 0 and 1\. This
    may be more helpful for some Data Scientists when comparing the result of the
    metrics between different models.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. The Coefficient of Determination (R²)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We define the **coefficient of determination** (or **R²**)as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b280ddbaa3d9539f9d829fc3ae61c75c.png)'
  prefs: []
  type: TYPE_IMG
- en: The definition of the coefficient of determination. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'where we’ve defined RSS as the residual sum of squares before. Then we have
    the Total Sum of Squares which is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/196d96f994559f287e14d3ce00a1098e.png)'
  prefs: []
  type: TYPE_IMG
- en: The definition of the Total Sum of Squares. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'The TSS is simply the variance of the predicted variable *y*; in fact, let’s
    stick altogether and multiply and divide for *1/n*​both the numerator and the
    denominator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/96b3c1a952826da9cb73c427495fd6e0.png)'
  prefs: []
  type: TYPE_IMG
- en: The modified definition of the coefficient of determination. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the numerator is exactly the *MSE* and the denominator is the variance
    of *y*; so we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6ff6d07f0fd18b7e12c502cdad372812.png)'
  prefs: []
  type: TYPE_IMG
- en: Another form to define the coefficient of determination. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: If R²=1 it means that MSE=0, so the model perfectly fits the data. Instead,
    R²=0 indicates that our model does not fit the data at all.
  prefs: []
  type: TYPE_NORMAL
- en: R² is bounded between 0 and 1, as we wanted, but only for the train set. This
    means that TSS>RSS or var(y)> MSE. Instead, in the test set, R² can become negative,
    which means that our model is badly fitting the test set (but we won’t discuss
    it any further here).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s recall what we have done before. Using the table provided above
    we had:'
  prefs: []
  type: TYPE_NORMAL
- en: MSE = 51.2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RMSE = 7.15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MAE = 5.6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, judging from RMSE and MAE the (only) model we are using for these calculations
    seems good, because we are near 0.
  prefs: []
  type: TYPE_NORMAL
- en: But, if you are familiar with Mathematical Analysis you can agree that 5.6 can
    be considered far from 0\. This is because we have no reference to judge.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see what happens if we calculate R².
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s calculate the mean value of *y*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17831287738ba4f8063d4c4e74f4219b.png)'
  prefs: []
  type: TYPE_IMG
- en: The mean value of y with the provided values in the table. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can calculate the variance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/61d803fa73eb3552ed684430b4da7fbf.png)'
  prefs: []
  type: TYPE_IMG
- en: The variance of y with the provided values in the table. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'We calculated MSE before (MSE = 51.2) so, finally, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/acae133cc268f592061671460d4849a2.png)'
  prefs: []
  type: TYPE_IMG
- en: The calculation of the coefficient of determination with the provided values.
    Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Remembering that, on the train set, R² is bounded between 0 and 1 and that the
    more we are near to 1 the better the model, an R² of 0.7 or higher is generally
    considered to be a good fit.
  prefs: []
  type: TYPE_NORMAL
- en: So, immediately and without any doubt, we can say that our model fits the data
    pretty well because we know that the best value we can get is 1, and since we
    found 0.739 as a result we can say, for comparison, that this result is pretty
    good.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem with R² is that it tends to increase when we add extra-explanatory
    variables to our model. This happens for a simple reason: additional variables
    can potentially improve the fit of the model. So, as we add more explanatory variables
    to a model, it has more information about the predicted variable, and this can
    allow it to make more accurate predictions. Then, this can lead to a decrease
    in the variance of the predicted variable, which can lead to an increase in the
    R².'
  prefs: []
  type: TYPE_NORMAL
- en: To determine if a variable is explanatory for our model, we have to consider
    if it is likely to have an effect on the dependent variable. For example, if we
    are studying the relationship between income and happiness, the money spent on
    holidays may be considered an explanatory variable because it is likely to have
    an effect on happiness. On the other hand, the color of the car of the people
    interviewed may not be considered an explanatory variable in this context, because
    it is unlikely to have an effect on happiness.
  prefs: []
  type: TYPE_NORMAL
- en: To deal with this behavior of R² statisticians have defined the adjusted R².
  prefs: []
  type: TYPE_NORMAL
- en: 5\. The adjusted R²
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **adjusted R²** is a special form of R² we use to correct the overestimation
    in R² that can be due to new explanatory variables in the model. We can define
    it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc2cdb47fb6c867ff99463d8a30e5209.png)'
  prefs: []
  type: TYPE_IMG
- en: The definition of the adjusted R-squared. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*n* is the number of samples in our data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*p* is the number of features (sometimes called predictors in the case of a
    regression problem: this is why we use the letter *p*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s say we have a model with 2 independent variables and a sample size of
    10, and R² for this model is 0.8\. We have:'
  prefs: []
  type: TYPE_NORMAL
- en: The calculation of the adjusted R-squared. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: In general, it is recommended to use the adjusted R² when we have a large number
    of independent variables in the model, because it gives a more accurate measure
    than the “standard” R².
  prefs: []
  type: TYPE_NORMAL
- en: Calculating all the Metrics in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Luckily to use, in Python we don’t have to calculate these metrics: the library
    `sklearn` does it for use, except for the adjusted R²: in this case, we have to
    calculate the parameters of the formula by coding them.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see an example. We generate some random data, fit the train set with a
    linear regression model, and print the results of all the metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, in this case, there is no difference between R² and the adjusted R² because
    the data were created on purpose and, also, we have just 5 features.
  prefs: []
  type: TYPE_NORMAL
- en: This code was just a way to show how we can use the knowledge we got in this
    article in a practical case, in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Also, here we can clearly see what it means for MAE, MSE, and RMSE to be near
    0\. As R² is 0.98, in fact, these metrics are “0.xx” which is pretty much near
    0 than 5.6, as we found in the tabled example.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we’ve seen a complete overview of all the metrics related to regression
    analysis in Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Even if we came out with a very long article, we hope that this can help the
    reader better understand what’s under the hood on these metrics, to better understand
    how to use them, and the differences between them.
  prefs: []
  type: TYPE_NORMAL
- en: '*You may also like:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/classification-metrics-the-complete-guide-for-aspiring-data-scientists-9f02eab796ae?source=post_page-----1e2a8a2936f5--------------------------------)
    [## Classification Metrics: The Complete Guide For Aspiring Data Scientists'
  prefs: []
  type: TYPE_NORMAL
- en: The only guide you’ll need to master classification metrics in Machine Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/classification-metrics-the-complete-guide-for-aspiring-data-scientists-9f02eab796ae?source=post_page-----1e2a8a2936f5--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**FREE PYTHON EBOOK:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Started learning Python Data Science but struggling with it? [***Subscribe
    to my newsletter and get my free ebook: this will give you the right learning
    path to follow to learn Python for Data Science with hands-on experience.***](https://federico-trotta.ck.page/a3970f33f4)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enjoyed the story? Become a Medium member for 5$/month [through my referral
    link](https://medium.com/@federicotrotta/membership): I’ll earn a small commission
    to no additional fee to you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@federicotrotta/membership?source=post_page-----1e2a8a2936f5--------------------------------)
    [## Join Medium with my referral link — Federico Trotta'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Federico Trotta (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@federicotrotta/membership?source=post_page-----1e2a8a2936f5--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Python:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Loops and statements in Python: A deep understanding (with examples)](/loops-and-statements-in-python-a-deep-understanding-with-examples-2099fc6e37d7)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Loops: A Complete Guide On How To Iterate in Python](/python-loops-a-complete-guide-on-how-to-iterate-in-python-b29e0d12211d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Python Libraries to Learn to Start Your Data Science Career](/5-python-libraries-to-learn-to-start-your-data-science-career-2cd24a223431)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Study Python for Data Science](/how-to-study-python-for-data-science-888a1ad649ae)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Science:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[How To Deal With Missing Values in Data Science](/how-to-deal-with-missing-values-in-data-science-9e5a56fbe928)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Perform Feature Selection in a Data Science Project](/how-to-perform-feature-selection-in-a-data-science-project-591ba96f86eb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How To Detect Outliers in a Data Science Project](/how-to-detect-outliers-in-a-data-science-project-17f39653fb17)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What is the Difference between a Barplot and a Histogram?](/what-is-the-difference-between-a-barplot-and-a-histogram-e62d0e532e7d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Difference Between Correlation and Regression](/the-difference-between-correlation-and-regression-134a5b367f7c)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding l1 and l2 Regularization](/understanding-l1-and-l2-regularization-93918a5ac8d0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
