- en: Natural Language Processing For Absolute Beginners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/natural-language-processing-for-absolute-beginners-a195549a3164](https://towardsdatascience.com/natural-language-processing-for-absolute-beginners-a195549a3164)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Solving complex NLP tasks in 10 lines of Python code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dmitryelj.medium.com/?source=post_page-----a195549a3164--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----a195549a3164--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a195549a3164--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a195549a3164--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----a195549a3164--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a195549a3164--------------------------------)
    ·9 min read·Sep 2, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc90b1586db7d9db3689cfb34615b58a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author (Generated using Craiyon)
  prefs: []
  type: TYPE_NORMAL
- en: It is mostly true that NLP (Natural Language Processing) is a complex area of
    computer science. Frameworks like SpaCy or NLTK are large and often require some
    learning. But with the help of open-source large language models (LLMs) and modern
    Python libraries, many tasks can be solved much more easily. And even more, results,
    which only several years ago were available only in science papers, can now be
    achieved with only 10 lines of Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Without further ado, let’s get into it.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Language Translation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Have you ever wondered how Google Translate works? Google [is using](https://blog.research.google/2020/06/recent-advances-in-google-translate.html)
    a deep learning model trained on a vast amount of text. Now, with the help of
    the [Transformers library](https://huggingface.co/docs/transformers/index), it
    can be done not only in Google Labs but on an ordinary PC. In this example, I
    will be using a pre-trained [T5-base](https://huggingface.co/t5-base) (Text-to-Text
    Transfer Transformer) model. This model was first trained on raw text data, then
    fine-tuned on source-target pairs like (“translate English to German: the house
    is wonderful”, “Das Haus ist Wunderbar”). Here “translate English to German” is
    a prefix that “tells” the model what to do, and the phrases are the actual context
    that the model should learn.'
  prefs: []
  type: TYPE_NORMAL
- en: I**mportant warning**. Large language models are literally pretty large. The
    *T5ForConditionalGeneration* class, used in this example, will automatically download
    the “t5-base” model, which is about 900 MB in size. Before running the code, be
    sure that there is enough disk space and that your traffic is not limited.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A pre-trained T5 model can be used in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, a *T5Tokenizer* class converts a source string to a digital form; this
    process is called *tokenization*. In our example, a “*translate English to German:
    the weather is good*” text will be converted to the *[13959, 1566, 12, 2968, 10,
    8, 1969, 19, 207, 1]* array. A “*generate”* method is doing the actual job, and
    finally, the tokenizer is making a backward conversion. As an output, we will
    get the result “Das Wetter ist gut”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Can we make this code even shorter? Actually, we can. With the help of the
    [Transformer’s *pipeline*](https://huggingface.co/docs/transformers/main_classes/pipelines)
    class, we can create an abstract pipeline that allows us to do this task in only
    2 lines of Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: For self-education purposes, I generally prefer the first approach because it
    is easier to understand what is going on “under the hood”. But for “production”
    purposes, the second way is much more flexible, and it also allows the use of
    different models without changing the code.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Summarization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The goal of text summarization is to transform the document into a shortened
    version, which obviously will take time if done manually. And surprisingly, a
    T5 model can do it as well; the only change we need is to change the prefix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the result is pretty accurate.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way, as with the first example, using a pipeline can produce shorter
    code for the same task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Readers can be curious about other tasks that are possible with a “t5-base”
    model. We can easily print them all:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Question Answering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another interesting functionality that large language models can provide is
    answering questions in a given context. I will be using the same piece of text
    as in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this case, I was using a [distilbert-base-cased-distilled-squad](https://huggingface.co/distilbert-base-cased-distilled-squad)
    model, which is 261 MB in size. As we can see, the model is not only providing
    an answer but also retrieving the position from the original text, which is good
    for verification of the results.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Language Generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another fun process is language generation. For this example, I will be using
    a [GPT-2 model](https://huggingface.co/gpt2). This is obviously not the latest
    GPT model we have today, but GPT-2 is freely available, and it is small enough
    (the file size is 548 MB) to run on an ordinary PC.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the same way, a much shorter code can be used with a pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Practically speaking, I cannot see a lot of sense in these texts, but from
    a grammar perspective, they are good enough, and for some sort of automation or
    unit testing, they can be useful. Interestingly, the GPT-2 model was released
    in 2019\. Just for fun, I asked the same question, “Please continue the phrase
    I am going to say,” to GPT-3.5 (released in 2022), and got this answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This result is much better; great progress was achieved in these three years.
    But obviously, it would not be possible to run a GPT-3.5 model on a regular PC
    today, even if it were released in the public domain.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Sentiment Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A previous example was mostly made for fun, but sentiment analysis is much more
    important for business. Sentiment analysis is the process of analyzing the sentiment
    in a given text and finding a subjective opinion. It may be particularly important
    for web shops, streaming platforms, and any other services where many users can
    publish reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this test, I will be using a [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: I deliberately tried to use phrases that were not so easy to analyze, but the
    model gave correct answers. Obviously, natural language is very flexible, and
    it is still possible to make a text that will give a false result. For example,
    this model gave the incorrect answer to the phrase “I expected it to be terrible,
    but I was mistaken”. At the same time, the (many times larger) GPT-3.5 model was
    able to parse it correctly. On the other side, considering that the DistilBERT
    model size is only 268 MB and it can be used for free (a model has an Apache 2.0
    license), the result is pretty good. Readers can also try [other open-source models](https://huggingface.co/models?pipeline_tag=text-classification)
    and choose the best one for their needs.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Named Entity Recognition (NER)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another interesting part of natural language processing is “named entity recognition”.
    It is the process of extracting the entities, like names, locations, dates, etc.,
    from the unstructured text. For this test, I will be using a [bert-base-NER model](https://huggingface.co/dslim/bert-base-NER)
    (file size is 433 MB).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the model was able to correctly determine the main entities mentioned
    in the text, such as name, location, and company.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Keyword Extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the last example, we tested NER, but not all parameters were extracted from
    a text. A separate keyword extraction algorithm can also be useful for the same
    task. For this example, I will be using [KeyBERT](https://maartengr.github.io/KeyBERT/index.html):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, keyword extraction can also be useful as an addition to NER,
    and it can find some extra data from the same phrase.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this article, I tested different algorithms for Natural Language Processing
    (NLP). As I promised at the beginning of the article, with the help of modern
    libraries, pretty complex tasks can be solved in 10 lines of Python code. It is
    also important to mention that all this code can run locally without any API subscriptions
    or keys. And last but not least, I hope readers can see that NLP can also be fun.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading. If you enjoyed this story, feel free [to subscribe](https://medium.com/@dmitryelj/membership)
    to Medium, and you will get notifications when my new articles will be published,
    as well as full access to thousands of stories from other authors.
  prefs: []
  type: TYPE_NORMAL
