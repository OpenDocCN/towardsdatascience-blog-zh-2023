- en: Exploring Token Probabilities as a Means to Filter GPT-3’s Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c](https://towardsdatascience.com/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To build better GPT-3-powered chatbots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[![LucianoSphere
    (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)
    [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)
    ·12 min read·Jan 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9db8b157fe2ab50887c47f5f7f1ac837.png)'
  prefs: []
  type: TYPE_IMG
- en: Log probabilities produced by GPT-3 for each token that makes up the displayed
    sentence, made up to test the system. The picture was composed by the author from
    a screenshot of a web app written to carry out these tests, linked near the end
    of the article.
  prefs: []
  type: TYPE_NORMAL
- en: As powerful language models become increasingly prevalent, the need for control
    over the content they generate becomes ever more pressing. These models, trained
    on massive amounts of text data, have the ability to generate highly convincing
    written content, from news articles to social media posts. However, without proper
    oversight, they can also produce misinformation or various kinds of harmful content.
    It is thus crucial that apps using these language models attempt to check the
    veracity of the information generated by these AI systems, in order to prevent
    the spread of false, misleading or harmful information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like many others, probably including yourself since you are reading this, I
    have used GPT-3 and ChatGPT quite a bit, and in doing so I have identified that
    very often they reply to questions very convincingly yet incorrectly. Indeed,
    I explored this quite deeply when GPT-3 was released, in the form of examinations
    just like those I would take to a student in a science subject:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pub.towardsai.net/power-limitations-and-use-cases-of-gpt-3-from-my-tests-and-prototype-apps-you-can-replicate-right-89bfb40daf5e?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Power, Limitations, and Use Cases of Gpt-3 From My Tests and Prototype Apps
    You Can Replicate…'
  prefs: []
  type: TYPE_NORMAL
- en: Exemplified with smart chatbots that can even listen and talk naturally command
    programs, or help students as full-time…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pub.towardsai.net](https://pub.towardsai.net/power-limitations-and-use-cases-of-gpt-3-from-my-tests-and-prototype-apps-you-can-replicate-right-89bfb40daf5e?source=post_page-----3e7dfc9ca0c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently, and carefully because I was aware of these limitations, I eagerly
    started creating my own chatbots powered by GPT-3\. First by patching some PHP
    libraries and writing the corresponding JavaScript code, and more recently purely
    in JavaScript:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://pub.towardsai.net/core-code-to-build-chatgpt-like-bots-in-20-lines-of-javascript-c2a506e5cc9a?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Core Code to Build ChatGPT-like Bots in < 20 Lines of JavaScript!'
  prefs: []
  type: TYPE_NORMAL
- en: No more PHP like in my previous examples. By using the modern fetch() function
    right in JavaScript, it’s now easier…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pub.towardsai.net](https://pub.towardsai.net/core-code-to-build-chatgpt-like-bots-in-20-lines-of-javascript-c2a506e5cc9a?source=post_page-----3e7dfc9ca0c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Working on that last project, i.e. calling GPT-3 from pure JavaScript, I explored
    more of OpenAI’s reference for the GPT-3 API, and found that one can very easily
    retrieve a series of scores associated to each token produced by the language
    model. It turns these scores are actually probabilities in logarithmic form, delivered
    by GPT-3 token by token together with the text prediction. These probabilities
    measure the “probability” of the different tokens that GPT-3 produced. While these
    probabilities could potentially contain information about how sure GPT-3 is about
    the content produced, this is not given. Therefore I set myself to study this
    here hands-on through a series of new JavaScript apps that you can build upon.
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, here I will explore how to retrieve these token probabilities
    and what values they take for texts that I know are either correct or wrong. I
    will also probe the effect of few-shot learning on these scores, to know if it
    actually makes GPT-3 more certain about its answers or not.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3 and token log probabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are reading this, GPT-3 needs no presentation. But in case, suffice to
    say that GPT-3 stands for Generative Pre-trained Transformer (now in version 3
    but actually consisting in various different models each at different version)
    and that it is a state-of-the-art language model that generates written content
    given an input.
  prefs: []
  type: TYPE_NORMAL
- en: When you feed some text into GPT-3 (called a “prompt”) it is split into so-called
    tokens, which are units of variable size ranging from single letters to syllables
    and even words (depending on various things). The tokens are propagated through
    the network, which as a result synthesizes new tokens that together form new words,
    sentences, and paragraphs. These texts usually have meaning and quite good grammatic,
    unless you are dealing with an exotic language that GPT-3 hasn’t seen much upon
    training. However, they are not necessarily accurate in their content, especially
    if you expect it to “think” about a problem or make relationships between concepts,
    or if you ask about things that the model hasn’t seen during training (for example
    it won’t know who I am, so it will probably make something up, see example later
    on).
  prefs: []
  type: TYPE_NORMAL
- en: 'One important feature of GPT-3 and other large language models is that they
    are “few-shot learners” which means they can process and “understand” some information
    passed on in a prompt, and then may answer a question or execute a task based
    on this information. There a whole preprint explaining this in the arXiv; and
    I have several example projects where I exploit this feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://arxiv.org/abs/2005.14165?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Language Models are Few-Shot Learners'
  prefs: []
  type: TYPE_NORMAL
- en: Recent work has demonstrated substantial gains on many NLP tasks and benchmarks
    by pre-training on a large corpus of…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2005.14165?source=post_page-----3e7dfc9ca0c--------------------------------)
    [](https://lucianosphere.medium.com/why-you-should-and-how-you-can-inform-your-chatbots-with-custom-data-or-wikipedia-access-500995dc87f3?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Why you should and how you can inform your chatbots with custom data or Wikipedia
    access
  prefs: []
  type: TYPE_NORMAL
- en: Extending my purely web-based, GPT3-powered chatbot to know content fed by me
    or that it retrieves automatically from…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: lucianosphere.medium.com](https://lucianosphere.medium.com/why-you-should-and-how-you-can-inform-your-chatbots-with-custom-data-or-wikipedia-access-500995dc87f3?source=post_page-----3e7dfc9ca0c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Now, the feature of GPT-3 that I’m touching upon here (and that isn’t much discussed
    on the internet, despite its huge importance) is that besides returning text,
    GPT-3 can return a probability associated to each token that composes the created
    text. These probabilities, actually returned in logarithmic form, measure how
    likely each token is to occur in the context of the output text. Lower log probabilities
    indicate less likely words and higher log probabilities indicate more likely words.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to ChatGPT itself, GPT-3 uses these log probabilities to generate
    text that is coherent and grammatically correct; besides, it uses the log probabilities
    to generate the next word based on the most likely word that can come next, allowing
    it to generate contextually accurate text. What I will investigate here is whether
    this also contains information about the accuracy of the content. Spoiler alert:
    yes, at least a bit; and moreover, few-shot learning not only improves the answers
    themselves but also improves log probabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving log probabilities upon calling GPT-3’s API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to note that GPT-3, like other language models, is not able
    to tell the difference between true and false information. It simply generates
    text based on the patterns it has learned from the data it was trained on and
    what is fed in the prompt for few-shot learning.
  prefs: []
  type: TYPE_NORMAL
- en: Token log probabilities can in principle help detect incorrect information;
    but, how do we get them?
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a slight modification of the code I presented recently to call GPT-3’s
    API totally from JavaScript, amended to get the token log probabilities as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The fetch() call includes everything that’s needed to call GPT-3 and get texts
    and token probabilities. And the prompt includes information for few-shot learning,
    placed before the question “Where is Luciano Abriata from?”
  prefs: []
  type: TYPE_NORMAL
- en: Testing token probabilities in different scenarios
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s see what happens if we call the above function with a prompt that only
    includes the question “Where is Luciano Abriata from?”, that is, without any assisting
    information that explains I’m from Argentina.
  prefs: []
  type: TYPE_NORMAL
- en: 'We expect GPT-3 will not know where I’m from, as I’m not a celebrity. And indeed,
    it “makes up” that I’m from Italy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d8ac10729f424b7ac93cf949f9aa10c.png)'
  prefs: []
  type: TYPE_IMG
- en: '(Fun fact: it’s not so much off, because my ancestors were all Italian… here,
    GPT-3 likely made a guess based on my name… but no, I was born and grew up in
    Argentina.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, what do we see in the console log? Lots of interesting outputs, besides
    the output text itself. Let’s analyze the most important elements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you see the object **text** which includes the output: *Luciano Abriata
    is from Italy*.'
  prefs: []
  type: TYPE_NORMAL
- en: But then a few lines above **text**, you see an array containing the tokens
    that make up that text. And a few lines above this, you have **token_logprobs**,
    an array of the same size that lists the log probabilities for each token.
  prefs: []
  type: TYPE_NORMAL
- en: You can see that **token_logprobs** reaches a minimum of -0.49 at token 9, “Italy”,
    while all other tokens are very close to 0 (except those at the end which are
    also negative, but we don’t care about these closing tokens).
  prefs: []
  type: TYPE_NORMAL
- en: This is in principle good news, because it means that GPT-3 is providing a clue
    that this piece of information might be wrong, or “made up”. Let’s no rush to
    draw any conclusions yet, though, and let’s explore this further.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we provide some information in the prompt, and then ask about it? Something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Luciano Abriata is a scientist born in Argentina, now working in Switzerland.
    He works on structural biology, virtual reality, NMR, scientific writing, programming,
    etc. Where is Luciano Abriata from?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, GPT-3 not only replies correctly saying that I’m from Argentina,
    but it also says this confidently: “Argentina”, again in token 9, has a log probability
    very close to 0:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d8d45250450c08e55874e04696ad390.png)'
  prefs: []
  type: TYPE_IMG
- en: More thorough tests by representing token probabilities as colors on the produced
    text
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To test the power of log probabilities in flagging potentially incorrect information,
    I wrote this simple web app (link near the end) that processes a prompt with GPT-3
    and displays the produced text colored at each token by its log probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8ba6078bdc49f1509dd65c087c58df0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this app, which you can try in a link I provide below, color keys for each
    token are injected via HTML’s <font> tag as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: log prob. > -0.1 → green
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: -0.3 > log prob. > -0.1 → yellow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: -0.5 > log prob. > -0.3 → orange
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: log prob. < -0.5 → red
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s analyze this a bit: the question is about a person that I made up, and
    about whom GPT-3 replies rather than saying it doesn’t know, although temperature
    is 0 so it’s not expected to make up stuff… Clearly, one cannot rely on the temperature
    parameter as a way to prevent the generation of fake information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, notice that of the 4 most important features invented for this fictional
    character (he’s Italian, a philosopher and professor of philosophy, and at the
    University of Rome La Sapienza) some are flagged strongly:'
  prefs: []
  type: TYPE_NORMAL
- en: “philosopher and professor of philosophy” averages a log probability of around
    -1, and “Rome La” of around -1.5.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, “Sapienza” probably remains unflagged, i.e. with high log probability,
    because it is a perfect continuation for “University of Rome La”. Likewise, “Italian”
    probably remains high because it comes soon after “Giulio”, which is a very Italian
    name.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, it seems like a low log probability is indicative of potentially inaccurate
    information, but a high value doesn’t ensure factual accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: It seems like a low log probability is indicative of potentially inaccurate
    information, but a high value doesn’t ensure factual accuracy.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let’s now try changing “Giulio” by “John”, i.e. asking “Who is John Caranchani?”:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/58b1e032a1209968a7f8618143f41a03.png)'
  prefs: []
  type: TYPE_IMG
- en: This time it made up that the character is Italian-American, and has flagged
    this information with a quite bad score.
  prefs: []
  type: TYPE_NORMAL
- en: 'One more test, using the typically French name “Philippe”:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f831737ef9279f75346df9f04c835c2.png)'
  prefs: []
  type: TYPE_IMG
- en: It now makes up that the character is French, and flags this in orange.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now ask about something different: chemistry. What’s the molecular formula
    of acetic acid?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bee9295d58d6631dfa0b46ab79ff0788.png)'
  prefs: []
  type: TYPE_IMG
- en: We get a correct answer, and all in green indicating very good scores.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we make up a molecule? Bizarric acid, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa18983bb3b2b0a6b72e75c65e47e7c0.png)'
  prefs: []
  type: TYPE_IMG
- en: Looks like it does “realize” that it’s making up stuff. Of course, we’d rather
    prefer that GPT-3 replied “I don’t know” or “Bizarric acid doesn’t exist”. But
    a very bad score is better than nothing.
  prefs: []
  type: TYPE_NORMAL
- en: Effect of passing information for few-shot learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed earlier and in numerous articles everywhere, GPT-3 can extract
    information from pieces of text passed for few-shot learning, and thus reply to
    questions more accurately -at least according to the passed information.
  prefs: []
  type: TYPE_NORMAL
- en: How is it reflected in the token probabilities?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example. I made up a person called Stephan Farconi, and want to
    know where he is from and what he does:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8384d9b25f6c5df81ba06479707dda8c.png)'
  prefs: []
  type: TYPE_IMG
- en: As expected, everything was made up and flagged with bad scores.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s give GPT-3 some information about this person, and let’s ask again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f9dfe6f75072b2efa5fad4707dadb372.png)'
  prefs: []
  type: TYPE_IMG
- en: The answer is now factually consistent with the information passed, and GPT-3
    flags a part of it (“Greece”) as certain. However, it is not sure about “computer
    scientist”. Note that “scientist” is a good continuation for “computer”, so in
    my interpretation GPT-3 is actually “unsure” about the whole “computer scientist”
    concept.
  prefs: []
  type: TYPE_NORMAL
- en: Want to try this app?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**https://lucianoabriata.altervista.org/tests/gpt-3/js-only/GPT3-JSonly-logprobs-color.html**](https://lucianoabriata.altervista.org/tests/gpt-3/js-only/GPT3-JSonly-logprobs-color.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Just paste your OpenAI API key for GPT-3, enter a question or prompt and click
    “Send to bot”.
  prefs: []
  type: TYPE_NORMAL
- en: Please share your results in the comments! Did the token probabilities reflect
    the actual accuracy of the produced text?
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The use of GPT-3 and similar language models in chatbot applications can present
    a significant challenge in terms of generating accurate and reliable information.
    While new methods will hopefully improve on veracity, for the moment an option
    is to utilize token probabilities to measure the “certainty” that GPT-3 has on
    each token that constitutes its output. I showed you that using this information
    it is possible to approximate the level of confidence that GPT-3 has in its generated
    text -but it’s not entirely safe.
  prefs: []
  type: TYPE_NORMAL
- en: From the few examples tested it looks like high scores throughout all tokens
    are indicative of accurate information, but low scores at some tokens do not necessarily
    imply that the information is incorrect. Of course, this is only anecdotal evidence,
    and a much larger study is required to evaluate this seriously. This could be
    an interesting project that a group doing research on AI could carry out relatively
    easy -just needing a sufficient number of persons interacting with the system
    by asking questions and evaluating the answers. (And note, as a further caveat,
    that I chose my thresholds for interpretation of log probabilities somewhat arbitrarily.)
  prefs: []
  type: TYPE_NORMAL
- en: I also showed you that few-shot learning helps to improve not only the accuracy
    of the answers, especially for questions that GPT-3 doesn’t “know” about, but
    also their reliability as measured by the token probabilities. However, also here
    we see that providing information through few-shot learning does not guarantee
    high scores in the replies, even when the information in these answers is correct.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, token probabilities look promising but, even without a full evaluation,
    it is clear that they are fallible. Therefore, it is crucial to use GPT-3 carefully,
    possibly utilizing token probabilities to improve outputs but without placing
    undue trust in them.
  prefs: []
  type: TYPE_NORMAL
- en: '[***www.lucianoabriata.com***](https://www.lucianoabriata.com/) *I write and
    photoshoot about everything that lies in my broad sphere of interests: nature,
    science, technology, programming, etc.* [***Become a Medium member***](https://lucianosphere.medium.com/membership)
    *to access all its stories (affiliate links of the platform for which I get small
    revenues without cost to you) and* [***subscribe to get my new stories***](https://lucianosphere.medium.com/subscribe)
    ***by email****. To* ***consult about small jobs,*** *check my* [***services page
    here***](https://lucianoabriata.altervista.org/services/index.html)*. You can*
    [***contact me here***](https://lucianoabriata.altervista.org/office/contact.html)***.***'
  prefs: []
  type: TYPE_NORMAL
