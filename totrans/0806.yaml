- en: Enhance Your ML Experimentation Workflow with Real-Time Plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/enhance-your-ml-experimentation-workflow-with-real-time-plots-434106b1a1c2](https://towardsdatascience.com/enhance-your-ml-experimentation-workflow-with-real-time-plots-434106b1a1c2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/14872005fa4fb7dbad42661022c573bb.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated with Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: Part 2 of the tutorial on how to run and evaluate experiments without leaving
    your IDE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)[![Eryk
    Lewinson](../Images/56e09e19c0bbfecc582da58761d15078.png)](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)
    [Eryk Lewinson](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)
    ·13 min read·Mar 13, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: In [the previous article of this series](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27),
    I demonstrated how to use DVC’s VS Code extension to transform our IDE into an
    experimentation platform, allowing us to directly run and evaluate ML experiments.
    I also mentioned that the extension offers useful plotting functionalities, which
    enable us to visualize and evaluate the performance of our experiments using interactive
    plots. To make it even better, the extension also offers live plotting of certain
    metrics during the training phase. You can get a sneak peek of this feature in
    the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/523d72401f29f69adb75ac1bec395dce.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Source](https://dvc.org/doc/dvclive/get-started?tab=DVC-Extension-for-VS-Code),
    GIF used with permission by iterative'
  prefs: []
  type: TYPE_NORMAL
- en: This article will demonstrate how to enhance the previously-introduced experimentation
    workflow by monitoring model performance and evaluating experiments with interactive
    plots, all within VS Code. To achieve this, we’ll tackle a binary image classification
    problem. First, we will provide an overview of transfer learning in computer vision
    and share some details about the selected dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Problem definition and methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image classification is one of the most popular tasks in the field of computer
    vision. For our example, we will use the cat vs dog classification problem, which
    has been widely used in the research community to benchmark different deep learning
    models. As you might have guessed, the goal of the project is to classify an input
    image as either a cat or a dog.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve high accuracy even with limited training data, we will leverage transfer
    learning to speed up the training process. Transfer learning is a powerful deep
    learning technique that has recently gained significant popularity, especially
    in various domains of computer vision. With the vast amount of data available
    on the internet, transfer learning allows us to leverage existing knowledge from
    one domain/problem and apply it to a different one.
  prefs: []
  type: TYPE_NORMAL
- en: One of the approaches to using transfer learning for computer vision is based
    on the idea of feature extraction. First, a model is trained on a large and general
    dataset (for example, the [ImageNet dataset](https://en.wikipedia.org/wiki/ImageNet)).
    This model serves as a generic model of “vision”. Then, we can use the learned
    feature maps of such a model without having to start the training of a custom
    network from scratch
  prefs: []
  type: TYPE_NORMAL
- en: 'For our use case, we will utilize a pre-trained model (ResNet50) to extract
    relevant features for our binary classification problem. The approach consists
    of a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtain a pre-trained model, i.e., a saved network that was previously trained
    on a large dataset. You can find some examples [here](https://www.tensorflow.org/api_docs/python/tf/keras/applications).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the feature maps learned by the selected network to extract meaningful features
    from images that the network was not trained on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new classifier on top of the pre-trained network. The classifier will
    be trained from scratch since the classification component of the pre-trained
    model is specific to its original task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will show how to do all of this in the following sections. However, please
    bear in mind that this is not a tutorial on transfer learning. If you would like
    to learn more about the theory and implementation, please refer to [this article](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)
    or [this tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning).
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By using the following snippet, we can download the cats vs. dogs dataset. The
    [original dataset](https://www.microsoft.com/en-us/download/details.aspx?id=54765)
    contained 12500 images of each class. However, for our project, we will be using
    a smaller, filtered dataset that contains 1000 training images and 500 validation
    images per class. The additional benefit of downloading the filtered dataset via
    TensorFlow is that it does not contain some corrupted images that were present
    in the original dataset (please see [here](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs)
    for more information).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following tree presents the structure of the directories containing the
    downloaded images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In case you would like to use the complete dataset for your experiments, you
    can load it using `[tensorflow_datasets](https://www.tensorflow.org/guide/keras/transfer_learning#getting_the_data)`.
  prefs: []
  type: TYPE_NORMAL
- en: Experimenting with Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will show the code used for training and experimenting
    with our neural network classifier. Specifically, we will need the following three
    files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`train.py` — contains the code used for training the neural network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`params.yaml` — contains the parameters used for training the neural network,
    such as the size of the input images, batch size, learning rate, number of epochs,
    etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dvc.yaml` — contains the DVC pipeline, which stores information about all
    the steps that are executed within our project, including their respective dependencies
    and outputs. For a more thorough description of this file and its structure, please
    refer to [my previous article](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a matter of fact, our current setup is more advanced than the bare minimum.
    While we could have started with just the training script, we chose to implement
    a more sophisticated setup right from the start. This will allow us to conveniently
    run experiments in a queue and easily parameterize them, among other benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with the `dvc.yaml` file as it contains this project’s pipeline.
    As this is a relatively simple project, it only has one stage called `train`.
    In the file, we can see which script contains the stage’s code, what its dependencies
    are, where the parameters are located, and what the outputs are. The `outs` step
    contains a directory that does not exist yet (`dvclive`), which will be automatically
    created while running our experiments.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s proceed to the `params.yaml` file. We have already mentioned what it
    contains, so its contents should not come as a surprise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Naturally, the file can contain many more parameters for multiple stages of
    the project, which are defined in the DVC pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we proceed to the file used for training the neural network. To make
    it more readable, we will break it down into three code snippets. In the first
    one, we execute the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the necessary libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the data directories separately for the training and validation datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load the parameters from the `params.yaml` file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the training and validation datasets using the `image_dataset_from_directory`
    functionality of `keras`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The second part of the training script contains the definition of the neural
    network architecture that we want to use for this project.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We will not dive deeply into the code used for transfer learning, as it is
    slightly outside the scope of this article. However, it is worth mentioning that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We used some very simple image augmentation techniques: random horizontal flip
    and random rotation. These augmentations are only applied to the training set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While training the model, we want to track its accuracy. We chose this metric
    because we are dealing with a balanced dataset, but we could easily track additional
    metrics such as precision and recall.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The third and last snippet contains the main body of our script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In this snippet, we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We create the `models` directory if it does not exist.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We get the model using the `get_model` function defined in the previous snippet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We define the callbacks we want to use. The first two are standard callbacks
    used while training neural networks. The first one is used for creating checkpoints
    while training. The second one stores the selected metrics (in our case, accuracy
    and loss) after each epoch into a CSV file. We will cover the third callback in
    a moment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We fit the model to the training data and evaluate using the validation set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third callback we used, `DVCLiveCallback`, comes from a companion library
    called DVCLive. In general, it is a library that provides utilities for logging
    ML parameters, metrics, and other metadata in simple file formats. You can think
    of it as an ML logger similar to, for example, MLFlow. The biggest difference
    is that by using DVCLive, we do not have to use any additional services or servers.
    All of the logged metrics and metadata are stored as plain text files, which can
    be versioned with Git.
  prefs: []
  type: TYPE_NORMAL
- en: In this particular case, we used a Keras-compatible callback provided by DVCLive.
    DVCLive provides similar utilities for the most popular machine and deep learning
    libraries, such as TensorFlow, PyTorch, LightGBM, XGBoost, and more. You can find
    the complete list of supported libraries [here](https://dvc.org/doc/dvclive/api-reference/ml-frameworks).
    It is also worth mentioning that even though DVCLive provides many useful callbacks
    that we can use out-of-the-box, it does not mean this is the only way to log the
    metrics. We can [manually log](https://dvc.org/doc/dvclive/how-it-works) whichever
    metrics/plots we want at any point we want.
  prefs: []
  type: TYPE_NORMAL
- en: When we specified the `DVCLiveCallback`, we set the `save_dvc_exp` argument
    to `True`. By doing so, we indicated that we would like to automatically track
    the results using Git.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we are ready to run our first experiment. For that, we will
    use the parameters we have initially specified in the `params.yaml` file. To run
    the experiment, we can either press the *Run Experiment* button in the *Experiments*
    tab of the DVC panel or use the following command in the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: For more information on running the experiments and navigating the *Experiments*
    tab, please refer to [my previous article](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27).
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the experiment, we notice that a new directory was created —`dvclive`.
    The DVCLive callback we used in our code automatically logged data and stored
    it in plain text files in that directory. In our case, the directory looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We provide a brief description of the generated files:'
  prefs: []
  type: TYPE_NORMAL
- en: The TSV files contain the accuracy and loss over epochs, separately for the
    training and validation datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metrics.json` contains the requested metrics for the final epoch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`report.html` contains plots of the tracked metrics in a form of an HTML report.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this point, we can inspect the tracked metrics in the HTML report. However,
    we can also do that directly from VS Code by navigating to the *Plots* tab in
    the DVC extension.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8a53a352f01a619b84332cffce8f043.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the left-hand sidebar, we can select the experiments we want to visualize.
    I have chosen the `main` one, but you can see that I have already run a few experiments
    before. In the *Plots* menu, we can select which metrics we want to plot. This
    functionality is very handy when we track a lot of metrics, but we only want to
    inspect a few of them at a time.
  prefs: []
  type: TYPE_NORMAL
- en: In the main view, we can see the visualized metrics. The upper plots present
    the metrics calculated using the validation set, while the lower ones are based
    on the training set. What you cannot see in the static image is that those plots
    are live plots. It means that the metrics are updated after each epoch of training
    is completed. We can use this tab to monitor the progress of our training jobs
    in real-time.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the second experiment, we increase the learning rate from 0.01 to 0.1\.
    We can run such an experiment using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: To monitor the model during training, we also selected the `workspace` experiment
    in the *Experiments* menu. In the image below, you can see what the plots look
    like while the neural network is still in the training stage (you can see that
    the process is running in the terminal window).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b662fcb293a00d4a09afd2b2cedc1b9f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So far, all of our plots were generated in the *Data Series* section of the
    *Plots* tab. In total, there are three sections, each with different kinds of
    plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data Series* — contains visualizations of metrics stored in text files (JSON,
    YAML, CSV, or TSV).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Images* — contains side-by-side visualizations of stored images, such as JPG
    files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Trends* — contains automatically generated and updated scalar metrics per
    epoch if [DVC checkpoints](https://dvc.org/doc/user-guide/experiment-management/checkpoints)
    are enabled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have already explored how to track and visualize metrics using DVCLive’s
    callbacks. Using DVC also allows us to track plots stored as images. For instance,
    we could create a bar chart representing the feature importance obtained from
    a certain model. Or, to simplify, we could track a confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general approach to track and visualize custom plots using DVC is to create
    the plot manually, save it as an image, and then track it. This allows us to track
    any custom plot we create. Alternatively, for certain `scikit-learn` plots, we
    can use DVCLive’s `log_sklearn_plot` method and generate the plot using data (predictions
    vs. ground truth) stored in JSON files. This approach currently works for the
    following kinds of plots: probability calibration, confusion matrix, ROC curve,
    and precision-recall curve.'
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we will demonstrate how to start tracking a confusion matrix.
    In the code snippet below, you can see the modified `train.py` script. We have
    removed many things that did not change, making it easier to follow the modifications.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this time we created an instance of a `Live` object, which we
    use both for the callback and the `log_sklearn_plot` method. To track all the
    metrics, we used a context manager (the `with` statement) to instantiate the `Live`
    instance. Without doing so, DVCLive would create an experiment when `keras` calls
    `on_train_end`. As a result, any data logged after that (in our case, the confusion
    matrix plot) would not be tracked within the experiment.
  prefs: []
  type: TYPE_NORMAL
- en: After modifying the training script, we ran again the two experiments with different
    learning rates (0.1 vs. 0.01). As a result, we can now see the confusion matrices
    in the *Plots* tab, right under the previously explored plots.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/117aa0f0844b327b85954c7c0670e101.png)'
  prefs: []
  type: TYPE_IMG
- en: The last thing to mention is that running the modified training script also
    modifies the `dvc.yaml` pipeline within the `dvclive` directory. As you can see
    below, it now contains information about the tracked confusion matrix, such as
    how to build it, which template to use, and what labels to use.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Wrapping up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous article of the series, we showed how to start using DVC and
    the dedicated VS Code extension to turn your IDE into an ML experimentation platform.
    In this part, we continued where we left off and we explored various (live-) plotting
    capabilities of the extension. Using those, we can easily evaluate and compare
    experiments to choose the best one.
  prefs: []
  type: TYPE_NORMAL
- en: In my opinion, there are two significant advantages of using a DVC-enhanced
    workflow. First, we do not need any external services or setups to start our experiments.
    The only requirement is a Git repo. Furthermore, DVC works with Git in a clean
    way. Although every experiment is saved in a Git commit, those commits are hidden
    and do not clutter our repository. In fact, we do not even need to create separate
    branches.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, everything happens within our IDE, enabling us to focus on our project
    without constantly switching between the IDE, browser, and other tools. This way,
    we can avoid distractions and the ever-threatening context-switching.
  prefs: []
  type: TYPE_NORMAL
- en: As always, any constructive feedback is more than welcome. You can reach out
    to me on [Twitter](https://twitter.com/erykml1) or in the comments. You can find
    all the code used for this article in [](https://github.com/erykml/vscode_exp_tracking_with_dvc)
    [this repository](https://github.com/erykml/cats_vs_dogs_classification).
  prefs: []
  type: TYPE_NORMAL
- en: '*Liked the article? Become a Medium member to continue learning by reading
    without limits. If you use* [*this link*](https://eryk-lewinson.medium.com/membership)
    *to become a member, you will support me at no extra cost to you. Thanks in advance
    and see you around!*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might also be interested in one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------)
    [## Turn VS Code into a One-Stop Shop for ML Experiments'
  prefs: []
  type: TYPE_NORMAL
- en: How to run and evaluate experiments without leaving your IDE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------)
    [](/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------)
    [## 3 Simple Ways to Create a Waterfall Plot in Python
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to quickly create a presentation-ready plot to aid your data storytelling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------)
    [](https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------)
    [## Introducing the second edition of Python for Finance Cookbook
  prefs: []
  type: TYPE_NORMAL
- en: What led me to write a second edition and what you can expect from reading it
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: eryk-lewinson.medium.com](https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------)
    [](/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------)
    [## R Shiny is coming to Python
  prefs: []
  type: TYPE_NORMAL
- en: Shiny is joining the ranks of web app tools such as Streamlit and Dash
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://www.microsoft.com/en-us/download/details.aspx?id=54765](https://www.microsoft.com/en-us/download/details.aspx?id=54765)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/competitions/dogs-vs-cats/overview](https://www.kaggle.com/competitions/dogs-vs-cats/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/iterative/dvclive](https://github.com/iterative/dvclive)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://iterative.ai/blog/exp-tracking-dvc-python/](https://iterative.ai/blog/exp-tracking-dvc-python/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://keras.io/examples/vision/image_classification_from_scratch/](https://keras.io/examples/vision/image_classification_from_scratch/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All images, unless noted otherwise, are by the author.
  prefs: []
  type: TYPE_NORMAL
