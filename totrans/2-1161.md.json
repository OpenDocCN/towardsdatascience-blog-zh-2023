["```py\n!cp kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n!kaggle datasets download jessicali9530/celeba-dataset\n!unzip celeba-dataset.zip\n```", "```py\nimport pandas as pd \n\ndata = pd.read_csv(\"list_attr_celeba.csv\")\ndata = data.replace(-1, 0)\ndata = data.sample(25000)\n\ndata.head(5)\n```", "```py\n# src/train/datasets.py\n\nimport os\nfrom PIL import Image\nimport pandas as pd\nimport torch\nfrom torchvision.transforms.transforms import Compose\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\nfrom src.train.utils import train_transform, valid_transform\n\nclass CelebaDataset(Dataset):\n    def __init__(\n        self,\n        data: pd.DataFrame,\n        image_folder: str,\n        augmentation: Compose,\n    ):\n        self.data = data\n        self.column_labels = self.data.columns.tolist()[1:]\n        self.column_image_id = self.data.columns.tolist()[0]\n        self.image_folder = image_folder\n        self.augmentation = augmentation\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index: int):\n        row = self.data.iloc[index]\n        labels = torch.FloatTensor(row[self.column_labels])\n        image_id = row[self.column_image_id]\n        image = Image.open(os.path.join(self.image_folder, image_id))\n        tensors = self.augmentation(image)\n        return dict(\n            tensors=tensors,\n            labels=labels,\n        )\n```", "```py\nclass CelebaDataModule(pl.LightningDataModule):\n    def __init__(self, train_df, test_df, batch_size, image_folder, num_workers):\n        super().__init__()\n        self.train_df = train_df\n        self.test_df = test_df\n        self.batch_size = batch_size\n        self.image_folder = image_folder\n        self.num_workers = num_workers\n\n    def setup(self, stage=None):\n        self.train_dataset = CelebaDataset(\n            self.train_df,\n            self.image_folder,\n            train_transform,\n        )\n        self.test_dataset = CelebaDataset(\n            self.test_df,\n            self.image_folder,\n            valid_transform,\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=self.num_workers,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n        )\n```", "```py\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nimport pytorch_lightning as pl\nfrom torchmetrics import AUROC\nfrom torchvision.models import resnet34\nfrom src.train.config import NUM_LABELS\n\nclass AttributeClassifier(pl.LightningModule):\n    def __init__(self, lr: float):\n        super().__init__()\n        self.backbone = resnet34(pretrained=True)\n        self.model = nn.Sequential(*list(self.backbone.children())[:-1])\n        self.classifier = nn.Linear(512, NUM_LABELS)\n        self.auroc = AUROC(task=\"multilabel\", num_labels=NUM_LABELS)\n        self.lr = lr\n        self.criterion = nn.BCELoss()\n\n    def forward(self, tensors):\n        output = self.model(tensors)\n        output = output.view(output.shape[0], -1)\n        output = self.classifier(output)\n        output = torch.sigmoid(output)\n        return output\n\n    def training_step(self, batch, batch_idx):\n        tensors = batch[\"tensors\"]\n        labels = batch[\"labels\"]\n        outputs = self(tensors)\n        loss = self.criterion(outputs, labels)\n        self.log(\n            \"train_loss\",\n            loss,\n            prog_bar=True,\n            logger=True,\n            on_epoch=True,\n            on_step=True,\n        )\n        score = self.auroc(outputs, labels.long())\n        self.log(\n            \"train_auc\",\n            score,\n            prog_bar=True,\n            logger=True,\n            on_epoch=True,\n            on_step=True,\n        )\n        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n\n    def validation_step(self, batch, batch_idx):\n        tensors = batch[\"tensors\"]\n        labels = batch[\"labels\"]\n        outputs = self(tensors)\n        loss = self.criterion(outputs, labels)\n        self.log(\n            \"val_loss\",\n            loss,\n            prog_bar=True,\n            logger=True,\n            on_epoch=True,\n            on_step=True,\n        )\n        score = self.auroc(outputs, labels.long())\n        self.log(\n            \"val_auc\",\n            score,\n            prog_bar=True,\n            logger=True,\n            on_epoch=True,\n            on_step=True,\n        )\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = Adam(self.parameters(), lr=self.lr)\n        return dict(optimizer=optimizer)\n```", "```py\ncheckpoint_callback = ModelCheckpoint(\n    dirpath=\"checkpoints\",\n    filename=\"best-checkpoint\",\n    save_top_k=1,\n    verbose=True,\n    monitor=\"val_auc\",\n    mode=\"max\",\n)\n\nearly_stopping_callback = EarlyStopping(\n    monitor=\"val_auc\", \n    patience=2, \n    mode=\"max\"\n)\n```", "```py\nearly_stopping_callback = EarlyStopping(\n    monitor=\"val_auc\",\n    patience=2,\n    mode=\"max\",\n)\nmodel = AttributeClassifier(lr=config.lr)\n\ntrainer = pl.Trainer(\n    callbacks=[early_stopping_callback, checkpoint_callback],\n    max_epochs=config.n_epochs,\n)\ntrainer.fit(model, data_module)\n```", "```py\nscript = model.to_torchscript()\ntorch.jit.save(script, \"torchscript_model.pt\")\n```", "```py\ngit clone https://github.com/ahmedbesbes/face-attributes-bentoml\ncd face-attributes-bentoml/\npoetry install\n```", "```py\ncd face-attributes-bentoml/models/\ncurl -O https://bentoml-ts.s3.eu-west-3.amazonaws.com/ts_model.pt\n```", "```py\n# src/serve/save_model.py\n\nimport bentoml\nimport torch\n\npath = \"models/ts_model.pt\"\nscript = torch.jit.load(path)\nbentoml.torchscript.save_model(\n    \"torchscript-attribute-classifier\",\n    script,\n    signatures={\"__call__\": {\"batchable\": True}},\n)\n```", "```py\nimport torch\nimport bentoml\nfrom bentoml.io import Image, JSON\nfrom torchvision import transforms\nfrom config import LABELS\n\ntorchscript_runner = bentoml.torchscript.get(\n    \"torchscript-attribute-classifier\"\n).to_runner()\n\nsvc = bentoml.Service(\n    \"face-attribute-classifier\",\n    runners=[torchscript_runner],\n)\n```", "```py\n@svc.api(input=Image(), output=JSON())\ndef classify(input_image):\n    tensor = process_image(input_image)\n    tensor = torch.unsqueeze(tensor, 0)\n    predictions = torchscript_runner.run(tensor)\n    _, indices = torch.where(predictions > 0.3)\n    indices = indices.numpy()\n    output = {}\n    labels = []\n    for index in indices:\n        probability = round(float(predictions[0][index]), 3)\n        labels.append(\n            {\n                \"label_id\": index,\n                \"label\": LABELS[index],\n                \"probability\": probability,\n            }\n        )\n    output[\"labels\"] = labels\n\n    print(output)\n\n    return output\n```", "```py\npoetry shell\npoetry src/serve/\nbentoml serve service:svc --reload\n```", "```py\nservice: \"service.py:svc\"\ninclude:\n  - \"__init__.py\"\n  - \"service.py\"\n  - \"config.py\"\n  - \"configuration.yaml\"\npython:\n  packages:\n    - torch==1.13.1\n    - torchvision==0.14.1\n    - pandas==1.5.3\n    - scikit-learn==1.2.2\n    - bentoml==1.0.16\n    - bentoctl==0.3.4\n```", "```py\ncd src/serve/\nbentoml build\n```", "```py\nbentoml yatai login --api-token <API_TOKEN> \\ \n                    --endpoint https://default.cloud.bentoml.com\n```", "```py\nbentoml push face-attribute-classifier:qwwyr5gl7cw6ehqa\n```"]