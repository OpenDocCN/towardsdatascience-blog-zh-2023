- en: Traditional Versus Neural Metrics for Machine Translation Evaluation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统指标与神经指标在机器翻译评估中的比较
- en: 原文：[https://towardsdatascience.com/traditional-versus-neural-metrics-for-machine-translation-evaluation-2931bd22fe61](https://towardsdatascience.com/traditional-versus-neural-metrics-for-machine-translation-evaluation-2931bd22fe61)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/traditional-versus-neural-metrics-for-machine-translation-evaluation-2931bd22fe61](https://towardsdatascience.com/traditional-versus-neural-metrics-for-machine-translation-evaluation-2931bd22fe61)
- en: 100+ new metrics since 2010
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自2010年以来新增的100多种指标
- en: '[](https://medium.com/@bnjmn_marie?source=post_page-----2931bd22fe61--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----2931bd22fe61--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2931bd22fe61--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2931bd22fe61--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----2931bd22fe61--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bnjmn_marie?source=post_page-----2931bd22fe61--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----2931bd22fe61--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2931bd22fe61--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2931bd22fe61--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----2931bd22fe61--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2931bd22fe61--------------------------------)
    ·15 min read·Mar 9, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----2931bd22fe61--------------------------------)
    ·15分钟阅读·2023年3月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6177bf23f91d84b81a888a899af3c75e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6177bf23f91d84b81a888a899af3c75e.png)'
- en: Image from [Pixabay](https://pixabay.com/photos/tunnel-light-grim-dark-art-6786462/)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于[Pixabay](https://pixabay.com/photos/tunnel-light-grim-dark-art-6786462/)
- en: An evaluation with automatic metrics has the advantages to be **faster, more
    reproducible, and cheaper** than an evaluation conducted by humans.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自动指标进行评估的优势在于其**速度更快、可重复性更强且成本更低**，相比于由人工进行的评估。
- en: This is especially true for the evaluation of machine translation. For a human
    evaluation, we would ideally need expert translators
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点在机器翻译的评估中尤为明显。对于人工评估，我们理想情况下需要专家翻译人员
- en: For many language pairs, such experts are **extremely rare and difficult to
    hire**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多语言对而言，这些专家**极其稀少且难以聘请**。
- en: A large-scale and fast manual evaluation, as required by the very dynamic research
    area of machine translation to evaluate new systems, is often impractical.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模且快速的人工评估，如机器翻译这一动态研究领域所需的评估新系统，通常是不切实际的。
- en: Consequently, automatic evaluation for machine translation has been a **very
    active, and productive, research area** for more than 20 years.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，机器翻译的自动评估已经成为一个**非常活跃且富有成效的研究领域**，已经有超过20年的历史。
- en: While BLEU remains by far the most used evaluation metric, there are countless
    better alternatives.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管BLEU仍然是使用最广泛的评估指标，但有无数更好的替代方案。
- en: '[](/bleu-a-misunderstood-metric-from-another-age-d434e18f1b37?source=post_page-----2931bd22fe61--------------------------------)
    [## BLEU: A Misunderstood Metric from Another Age'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/bleu-a-misunderstood-metric-from-another-age-d434e18f1b37?source=post_page-----2931bd22fe61--------------------------------)
    [## BLEU：一种被误解的古老指标'
- en: But still used today in AI research
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 但在AI研究中仍然在用
- en: towardsdatascience.com](/bleu-a-misunderstood-metric-from-another-age-d434e18f1b37?source=post_page-----2931bd22fe61--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/bleu-a-misunderstood-metric-from-another-age-d434e18f1b37?source=post_page-----2931bd22fe61--------------------------------)
- en: Since 2010, 100+ automatic metrics have been proposed to improve machine translation
    evaluation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自2010年以来，已经提出了100多种自动指标以改进机器翻译评估。
- en: 'In this article, I present the most popular metrics that are used as alternatives,
    or in addition, to BLEU. I grouped them into two categories: traditional or neural
    metrics, each category having different advantages.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我介绍了最受欢迎的指标，这些指标作为BLEU的替代方案或补充方案。我将它们分为两类：传统指标和神经指标，每类都有不同的优势。
- en: Automatic Metrics for Machine Translation
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器翻译的自动评估指标
- en: 'Most automatic metrics for machine translation only require:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器翻译的自动指标只需要：
- en: The **translation hypothesis** generated by the machine translation system to
    evaluate
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器翻译系统生成的**翻译假设**用于评估
- en: At least one **reference translation** produced by humans
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少需要一个**参考翻译**由人工生成
- en: (Rarely) the **source text** translated by the machine translation system
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （很少）**机器翻译系统翻译的源文本**
- en: 'Here is an example of a French-to-English translation:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个法语到英语翻译的例子：
- en: 'Source sentence:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来源句子：
- en: '*Le chat dort dans la cuisine donc tu devrais cuisiner ailleurs.*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*Le chat dort dans la cuisine donc tu devrais cuisiner ailleurs.*'
- en: 'Translation hypothesis (generated by machine translation):'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 翻译假设（由机器翻译生成）：
- en: '*The cat sleeps in the kitchen so cook somewhere else.*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*The cat sleeps in the kitchen so cook somewhere else.*'
- en: 'Reference translation:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考翻译：
- en: '*The cat is sleeping in the kitchen, so you should cook somewhere else.*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*The cat is sleeping in the kitchen, so you should cook somewhere else.*'
- en: The translation hypothesis and the reference translation are both translations
    of the same source text.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译假设和参考翻译都是相同源文本的翻译。
- en: The objective of the automatic metric is to yield a score that can be interpreted
    as a distance between the translation hypothesis and the reference translation.
    The smaller the distance is and the closer the system is to generate a translation
    of human quality.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 自动评价指标的目标是生成一个可以被解释为翻译假设和参考翻译之间距离的分数。距离越小，系统生成的翻译就越接近人类翻译质量。
- en: The absolute score returned by a metric is **usually not interpretable alone**.
    It is almost always used to **rank machine translation systems**. A system with
    a better score is a better system.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 指标返回的绝对分数**通常不能单独解释**。它几乎总是用来**排名机器翻译系统**。得分更高的系统就是更好的系统。
- en: 'In one of my studies ([Marie et al., 2021](https://aclanthology.org/2021.acl-long.566.pdf)),
    I showed that almost 99% of the research papers in machine translation rely on
    the automatic metric BLEU to evaluate translation quality and rank systems, while
    more than **100 other metrics have been proposed during the last 12 years**. *Note:
    I looked only at research papers published from 2010 by the ACL. Potentially many
    more metrics have been proposed to evaluate machine translation.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的一项研究中（[Marie et al., 2021](https://aclanthology.org/2021.acl-long.566.pdf)），我展示了几乎
    99% 的机器翻译研究论文依赖于自动评价指标 BLEU 来评估翻译质量和排名系统，而在过去 12 年中，**已经提出了 100 多种其他指标**。*注意：我只查看了
    2010 年以来 ACL 发布的研究论文。可能还有更多指标被提出用于评估机器翻译。*
- en: 'Here is a non-exhaustive list of 106 metrics proposed from 2010 to 2020 (click
    on the metric name to get the source):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个不完整的 106 种指标的列表，提出于 2010 年到 2020 年（点击指标名称获取来源）：
- en: '[Noun-phrase chunking](https://aclanthology.org/P10-1012.pdf), [SemPOS refinement](https://aclanthology.org/P10-2016.pdf),
    [mNCD](https://aclanthology.org/P10-2015.pdf), [RIBES](https://aclanthology.org/D10-1092.pdf),
    [extended METEOR](https://aclanthology.org/N10-1031.pdf), [Badger 2.0, ATEC 2.1,
    DCU-LFG, LRKB4, LRHB4, I-letter-BLEU, I-letter-recall, SVM-RANK,TERp, IQmt-DR,
    BEwT-E, Bkars, SEPIA](https://aclanthology.org/W10-1703.pdf), [MEANT](https://aclanthology.org/P11-1023.pdf),
    [AM-FM](https://aclanthology.org/P11-2027.pdf). [AMBER, F15, MTeRater, MP4IBM1,
    ParseConf, ROSE, TINE](https://aclanthology.org/W11-2103.pdf), [TESLA-CELAB](https://aclanthology.org/P12-1097.pdf),
    [PORT](https://aclanthology.org/P12-1098.pdf), [lexical cohesion](https://aclanthology.org/D12-1097.pdf),
    [pFSM, pPDA](https://aclanthology.org/D12-1090.pdf), [HyTER](https://aclanthology.org/N12-1017.pdf),
    [SAGAN-STS, SIMPBLEU, SPEDE, TerrorCAT, BLOCKERRCATS, XENERRCATS, PosF, TESLA](https://aclanthology.org/W12-3102.pdf),
    [LEPOR, ACTa, DEPREF, UMEANT, LogRefSS](https://aclanthology.org/W13-2202v2.pdf),
    [discourse-based](https://aclanthology.org/P14-1065.pdf), [XMEANT](https://aclanthology.org/P14-2124.pdf),
    [BEER](https://aclanthology.org/D14-1025.pdf), [SKL](https://aclanthology.org/D14-1027.pdf),
    [AL-BLEU](https://aclanthology.org/D14-1026.pdf), [LBLEU](https://aclanthology.org/D14-1140.pdf),
    [APAC, RED-*, DiscoTK-*, ELEXR, LAYERED, Parmesan, tBLEU, UPC-IPA, UPC-STOUT,
    VERTa-*](https://aclanthology.org/W14-3336.pdf), [pairwise neural](https://aclanthology.org/P15-1078.pdf),
    [neural representation-based](https://aclanthology.org/P15-2025.pdf), [ReVal](https://aclanthology.org/D15-1124.pdf),
    [BS, LeBLEU, chrF, DPMF, Dreem, Ratatouille, UoW-LSTM, UPF-Colbat, USAAR-ZWICKEL](https://aclanthology.org/W15-3031.pdf),
    [CharacTER, DepCheck, MPEDA, DTED](https://aclanthology.org/W16-2302.pdf), [meaning
    features](https://aclanthology.org/E17-1020.pdf), [BLEU2VEC_Sep, Ngram2vec, MEANT
    2.0, UHH_TSKM, AutoDA, TreeAggreg, BLEND](https://aclanthology.org/W17-4755.pdf),
    [HyTERA](https://aclanthology.org/N18-2077.pdf), [RUSE, ITER, YiSi](https://aclanthology.org/W18-6450.pdf),
    [BERTr](https://aclanthology.org/P19-1269.pdf), [EED, WMDO, PReP](https://aclanthology.org/W19-5302.pdf),
    [cross-lingual similarity+target language model](https://aclanthology.org/2020.acl-main.151.pdf),
    [XLM+TLM](https://aclanthology.org/2020.acl-main.327.pdf), [Prism](https://aclanthology.org/2020.emnlp-main.8.pdf),
    [COMET](https://aclanthology.org/2020.emnlp-main.213.pdf), [PARBLEU, PARCHRF,
    MEE, BLEURT, BAQ-*, OPEN-KIWI-*, BERT, mBERT, EQ-*](https://aclanthology.org/2020.wmt-1.77.pdf)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of these metrics have been shown to be better than BLEU, but have never
    been used. In fact, only 2 (1.8%) of these metrics, RIBES and chrF, have been
    used in more than two research publications (among the 700+ publications that
    I checked). Since 2010, **the most used metrics are metrics proposed before 2010**
    (BLEU, TER, and METEOR):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些度量中的大多数已被证明比BLEU更好，但从未被使用。事实上，只有2个（1.8%），即RIBES和chrF，被用于两篇以上的研究论文中（在我检查的700多篇论文中）。自2010年以来，**最常用的度量是2010年之前提出的度量**（BLEU、TER和METEOR）：
- en: '![](../Images/e33b3b596dc9e5171fb2919ae936d6d2.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e33b3b596dc9e5171fb2919ae936d6d2.png)'
- en: Table by [Marie et al., 2021](https://aclanthology.org/2021.acl-long.566.pdf)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 表格由[Marie et al., 2021](https://aclanthology.org/2021.acl-long.566.pdf)提供
- en: Most of the metrics created after 2016 are neural metrics. They rely on neural
    networks and the most recent ones even rely on the very popular pre-trained language
    models.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数2016年后创建的度量是神经度量。它们依赖于神经网络，最新的甚至依赖于非常流行的预训练语言模型。
- en: In contrast, traditional metrics published earlier can be more simple and cheaper
    to run. They remain extremely popular for various reasons, and this popularity
    doesn’t seem to decline, at least in research.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，早期发布的传统度量可以更简单且成本更低。由于各种原因，它们仍然极其受欢迎，并且这种受欢迎程度似乎没有下降，至少在研究中是这样。
- en: In the following sections, I introduce several metrics selected according to
    their popularity, their originality, or their correlation with human evaluation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我将介绍几个根据其受欢迎程度、原创性或与人工评估相关性选择的度量。
- en: Traditional Metrics
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统度量
- en: Traditional metrics for machine translation evaluation can be seen as metrics
    that evaluate **the distance between two strings simply based on the characters
    they contain**.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 机器翻译评估的传统度量可以被视为基于两个字符串包含的字符**之间的距离**来评估的度量。
- en: 'These two strings are the translation hypothesis and the reference translation.
    Note: *Typically, traditional metrics don’t exploit the source text translated
    by the system.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个字符串分别是翻译假设和参考翻译。注意：*通常，传统度量不会利用系统翻译的源文本。*
- en: WER (Word Error Rate) was one the most used of these metrics, and the ancestor
    of BLEU, before BLEU took over in the early 2000’s.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: WER（字错误率）曾是这些度量中使用最广泛的，并且是BLEU的前身，直到BLEU在2000年代初期取代了它。
- en: 'Advantages:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 优势：
- en: '**Low computational cost**: Most traditional metrics rely on the efficiency
    of string matching algorithms run at character and/or token levels. Some metrics
    do need to perform some shifting of tokens which can be more costly, particularly
    for long translations. Nonetheless, their computation is easily parallelizable
    and doesn’t require a GPU.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算成本低**：大多数传统度量依赖于字符和/或标记级别上运行的字符串匹配算法的效率。有些度量确实需要对标记进行一些移动，这可能更昂贵，特别是对于长翻译。然而，它们的计算易于并行化，并且不需要GPU。'
- en: '**Explainable**: Scores are usually easy to compute by hand for small segments
    and thus facilitate the analysis. *Note: “Explainable” doesn’t mean “interpretable”,
    i.e., we can exactly explain how a metric score is computed, but the score alone
    can’t be interpreted as it usually tells us nothing of the translation quality.*'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释**：小段的分数通常可以手动轻松计算，从而促进分析。*注意：“可解释”并不意味着“可解读”，即我们可以确切解释度量分数的计算方法，但分数本身无法解释，因为它通常无法告诉我们翻译质量。*'
- en: '**Language independent**: Except some particular metrics, the same metric algorithms
    can be applied independently of the language of the translation.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言无关**：除了一些特定度量外，相同的度量算法可以独立于翻译语言进行应用。'
- en: 'Disadvantages:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点：
- en: '**Poor correlation with human judgments**: This is their main disadvantage
    against neural metrics. To get the best estimation of the quality of a translation,
    traditional metrics shouldn’t be used.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与人工评估的相关性差**：这是它们相对于神经度量的主要缺点。为了获得对翻译质量的最佳估计，不应使用传统度量。'
- en: '**Require particular preprocessing**: Except for one metric (chrF), all the
    traditional metric I present in this article requires the evaluated segments,
    and their reference translations, to be tokenized. The tokenizer isn’t embedded
    in the metric, i.e., it has to be performed by the user using external tools.
    The scores obtained are then dependent on a particular tokenization that may not
    be reproducible.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**需要特定预处理**：除了一个度量（chrF）外，我在本文中介绍的所有传统度量都需要被评估的段落及其参考翻译进行分词。分词器不包含在度量中，即需要用户使用外部工具进行。获得的分数因此依赖于特定的分词，可能无法重复。'
- en: BLEU
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BLEU
- en: This is the most popular metric. It is used by almost 99% of the machine translation
    research publications.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最受欢迎的度量标准。几乎99%的机器翻译研究出版物都使用它。
- en: I already presented BLEU in one of [my previous article](/bleu-a-misunderstood-metric-from-another-age-d434e18f1b37).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经在[我的上一篇文章](/bleu-a-misunderstood-metric-from-another-age-d434e18f1b37)中介绍过BLEU。
- en: BLEU is a metric with many well-identified flaws.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU是一个存在许多明显缺陷的度量标准。
- en: '[](https://medium.com/@bnjmn_marie/12-critical-flaws-of-bleu-1d790ccbe1b1?source=post_page-----2931bd22fe61--------------------------------)
    [## 12 Critical Flaws of BLEU'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bnjmn_marie/12-critical-flaws-of-bleu-1d790ccbe1b1?source=post_page-----2931bd22fe61--------------------------------)
    [## 12 BLEU的关键缺陷'
- en: Why you shouldn’t trust BLEU according to 37 studies published over 20 years
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 根据37项研究结果，为什么你不应该相信BLEU，这些研究已发表超过20年。
- en: medium.com](https://medium.com/@bnjmn_marie/12-critical-flaws-of-bleu-1d790ccbe1b1?source=post_page-----2931bd22fe61--------------------------------)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@bnjmn_marie/12-critical-flaws-of-bleu-1d790ccbe1b1?source=post_page-----2931bd22fe61--------------------------------)
- en: What I didn’t discuss in my two articles about BLEU is the many variants of
    BLEU.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我在关于BLEU的两篇文章中没有讨论BLEU的众多变体。
- en: When reading research papers, you may find metrics denoted BLEU-1, BLEU-2, BLEU-3,
    and so on. The number after the hyphen is *usually* the maximum length of the
    n-grams of tokens used to compute the score.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读研究论文时，你可能会发现度量标准标记为BLEU-1、BLEU-2、BLEU-3等。连字符后的数字*通常*表示用于计算分数的n-grams的最大长度。
- en: For instance, BLEU-4 is a BLEU computed by taking {1,2,3,4}-grams of tokens
    into account. In other words, BLEU-4 is the typical BLEU computed in most machine
    translation papers, as originally proposed by [Papineni et al. (2002)](https://aclanthology.org/P02-1040.pdf).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，BLEU-4是通过考虑{1,2,3,4}-grams的令牌来计算的BLEU。换句话说，BLEU-4是大多数机器翻译论文中计算的典型BLEU，如[Papineni等人（2002）](https://aclanthology.org/P02-1040.pdf)最初提出的。
- en: BLEU is a metric that requires a lot of statistics to be accurate. It doesn’t
    work well on short text, and may even yield an error if computed on a translation
    that doesn’t match any 4-grams from the reference translation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU是一个需要大量统计数据才能准确的度量标准。它在短文本上表现不佳，甚至可能在计算与参考翻译中的任何4-gram不匹配的翻译时产生错误。
- en: Since evaluating translation quality at sentence level may be necessary in some
    applications or for analysis, a variant denoted sentence BLEU, sBLEU, or sometimes
    BLEU+1 can be used. It avoids computational errors. There are many variants of
    BLEU+1\. The most popular ones are described by [Chen and Cherry (2014)](https://aclanthology.org/W14-3346.pdf).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在某些应用或分析中可能需要按句子级别评估翻译质量，因此可以使用一种变体，称为句子BLEU、sBLEU，或有时称为BLEU+1。它避免了计算错误。BLEU+1有很多变体。最流行的变体由[Chen和Cherry（2014）](https://aclanthology.org/W14-3346.pdf)描述。
- en: As we will see with neural metrics, BLEU+1 has many better alternatives and
    shouldn’t be used.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将看到的神经度量标准，BLEU+1有许多更好的替代方案，不应使用。
- en: chrF(++)
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: chrF(++)
- en: chrF ([Popović, 2015](https://aclanthology.org/W15-3049.pdf)) is the second
    most popular metric for machine translation evaluation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: chrF（[Popović，2015](https://aclanthology.org/W15-3049.pdf)）是机器翻译评估中第二受欢迎的度量标准。
- en: It has been around since 2015 and has since been increasingly used in machine
    translation publications.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 自2015年以来，它逐渐在机器翻译出版物中得到越来越多的应用。
- en: It has been shown to better correlate with human judgment than BLEU.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 已经证明，它与人类判断的相关性优于BLEU。
- en: In addition, chrF is tokenization independent. This is the only metric with
    this feature that I know of. Since it doesn’t require any prior custom tokenization
    by some external tool, it is one of the best metrics to ensure the reproducibility
    of an evaluation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，chrF是与分词无关的。这是我知道的唯一具有这一特性的度量标准。由于它不需要任何外部工具进行自定义分词，因此它是确保评估可重复性最佳的度量标准之一。
- en: chrF exclusively relies on the characters. Spaces are ignored by default.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: chrF完全依赖于字符。空格默认被忽略。
- en: chrF++ ([Popović, 2017](https://aclanthology.org/W17-4770.pdf)) is a variant
    of chrF that better correlates with human evaluation but at the cost of its tokenization
    independence. Indeed, chrF++ exploits spaces to take into account word order,
    hence its better correlation with human evaluation.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: chrF++（[Popović，2017](https://aclanthology.org/W17-4770.pdf)）是chrF的一个变体，与人工评估的相关性更高，但代价是失去了分词独立性。确实，chrF++利用空格来考虑词序，因此与人工评估的相关性更好。
- en: I do strongly recommend the use of chrF when I review machine translation papers
    for conferences and journals to make an evaluation more reproducible, but not
    chrF++ due to its tokenization dependency.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我在为会议和期刊审阅机器翻译论文时强烈推荐使用chrF，以使评估更具可重复性，但不推荐chrF++，因为它依赖于分词。
- en: '*Note: Be wary when you read a research work using chrF. Authors often confuse
    chrF and chrF++. They may also cite the chrF paper when using chrF++, and vice
    versa.*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：阅读使用chrF的研究工作时要小心。作者常常将chrF和chrF++混淆。他们也可能在使用chrF++时引用chrF的论文，反之亦然。*'
- en: The [original implementation of chrF by Maja Popović](https://github.com/m-popovic/chrF)
    is available on github.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[Maja Popović的chrF原始实现](https://github.com/m-popovic/chrF)可以在github上找到。'
- en: You can also find an implementation in [SacreBLEU](https://github.com/mjpost/sacrebleu)
    (Apache 2.0 license).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在 [SacreBLEU](https://github.com/mjpost/sacrebleu)（Apache 2.0 许可证）中找到一个实现。
- en: RIBES
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RIBES
- en: RIBES ([Isozaki et al., 2010](https://aclanthology.org/D10-1092.pdf)) is regularly
    used by the research community.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: RIBES ([Isozaki et al., 2010](https://aclanthology.org/D10-1092.pdf)) 在研究社区中被定期使用。
- en: This metric was designed for “distant language pairs” with very different sentence
    structures.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标是为具有非常不同句子结构的“远程语言对”设计的。
- en: For instance, translating English into Japanese requires a significant word
    reordering since the verb in Japanese is located at the end of the sentence while
    in English it is usually placed before the complement.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，将英语翻译成日语需要显著的词序调整，因为在日语中动词位于句子的末尾，而在英语中动词通常放在补语之前。
- en: The authors of RIBES found that the metrics available at that time, in 2010,
    were not sufficiently penalizing incorrect word order and thus proposed this new
    metric instead.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: RIBES的作者发现2010年时可用的指标对错误的词序惩罚不足，因此提出了这一新指标。
- en: An implementation of [RIBES is available on Github](https://github.com/nttcslab-nlp/RIBES)
    (GNU General Public License V2.0).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[RIBES的实现可以在Github上找到](https://github.com/nttcslab-nlp/RIBES)（GNU通用公共许可证V2.0）。'
- en: METEOR
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: METEOR
- en: METEOR ([Banerjee and Lavie, 2005](https://aclanthology.org/W05-0909.pdf)) was
    first proposed in 2005 with the objective of correcting several flaws of traditional
    metrics available at that time.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: METEOR ([Banerjee and Lavie, 2005](https://aclanthology.org/W05-0909.pdf)) 最早在2005年提出，旨在纠正当时可用的传统指标中的几个缺陷。
- en: For instance, BLEU only counts exact token matches. It is too strict since words
    are not rewarded by BLEU if they are not exactly the same in the reference translation
    even if they have a similar meaning. As such, BLEU is blind to many valid translations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，BLEU只计算准确的词汇匹配。由于BLEU不会奖励与参考翻译不完全相同但具有类似意义的词，因此它过于严格。因而，BLEU对许多有效的翻译视而不见。
- en: METEOR partly corrects this flaw by introducing more flexibility in the matching.
    Synonyms, word stems, and even paraphrases are all accepted as valid translations,
    effectively improving the recall of the metric. The metric also implements a weighting
    mechanism to give more importance, for instance, to an exact matching over a stem
    matching.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: METEOR通过引入更多的匹配灵活性部分修正了这一缺陷。同义词、词干甚至释义都被接受为有效的翻译，从而有效提高了指标的召回率。该指标还实现了加权机制，例如，更注重准确匹配而不是词干匹配。
- en: The metric is computed by the harmonic mean between recall and precision, with
    the particularity that the recall has a higher weight than precision.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标通过召回率和精确率的调和平均数来计算，特别之处在于召回率的权重高于精确率。
- en: METEOR better correlates with human evaluation than BLEU, and has been improved
    multiple times until 2015\. It is still regularly used nowadays.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: METEOR与人类评估的相关性优于BLEU，并且在2015年之前已经经过多次改进。它至今仍然被定期使用。
- en: '[METEOR has an official webpage](https://www.cs.cmu.edu/~alavie/METEOR/) maintained
    by CMU which proposes the original implementation of the metric (unknown license).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[METEOR有一个由CMU维护的官方网页](https://www.cs.cmu.edu/~alavie/METEOR/)，提供了该指标的原始实现（许可证未知）。'
- en: TER
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TER
- en: TER ([Snover et al., 2006](https://aclanthology.org/2006.amta-papers.25.pdf))
    is mainly used to evaluate the effort it would take for a human translator to
    post-edit a translation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: TER ([Snover et al., 2006](https://aclanthology.org/2006.amta-papers.25.pdf))
    主要用于评估人类翻译者后编辑翻译所需的努力。
- en: '**Definition**'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**定义**'
- en: ''
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Post-editing in machine translation is the action of correcting a machine translation
    output into an acceptable translation. Machine translation followed by post-editing
    is a standard pipeline used in the translation industry to reduce translation
    cost.
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 机器翻译中的后编辑是将机器翻译输出修正为可接受的翻译的过程。机器翻译加上后编辑是翻译行业中一种标准流程，用于减少翻译成本。
- en: 'There are two well-known variants: TERp ([Snover et al., 2009](https://web.jhu.edu/HLTCOE/Publications/terplusdorr.pdf))
    and HTER ([Snover et al., 2009](https://web.jhu.edu/HLTCOE/Publications/terplusdorr.pdf),
    [Specia and Farzindar, 2010](https://aclanthology.org/2010.jec-1.5.pdf)).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个知名的变体：TERp ([Snover 等人, 2009](https://web.jhu.edu/HLTCOE/Publications/terplusdorr.pdf))
    和 HTER ([Snover 等人, 2009](https://web.jhu.edu/HLTCOE/Publications/terplusdorr.pdf),
    [Specia 和 Farzindar, 2010](https://aclanthology.org/2010.jec-1.5.pdf))。
- en: TERp is TER augmented with a paraphrase database to improve the recall of the
    metric and its correlation with human evaluation. A match between the hypothesis
    and the reference is counted if a token, or one of its paraphrases, from the translation
    hypothesis is in the reference translation.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: TERp 是在 TER 的基础上增加了一个同义句数据库，以提高度量的召回率及其与人工评估的相关性。如果翻译假设中的一个标记或其同义句出现在参考翻译中，则算作匹配。
- en: HTER, standing for “Human TER”, is a standard TER computed between machine translation
    hypothesis and its post-editing produced by a human. It can be used to evaluate
    the cost, a posteriori, of post-editing a particular translation.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: HTER，即“人工 TER”，是计算机器翻译假设与其人工后编辑之间的标准 TER。它可以用来评估后编辑特定翻译的成本。
- en: CharacTER
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CharacTER
- en: 'The name of the metric already gives some hints on how it works: This is the
    TER metric applied at character level. Shift operations are performed at word
    level.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 该度量的名称已经给出了一些关于其工作原理的提示：这是在字符级别应用的 TER 度量。移位操作在词级别进行。
- en: The edit distance obtained is also normalized by the length of the translation
    hypothesis.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的编辑距离也按翻译假设的长度进行标准化。
- en: CharacTER ([Wang et al., 2016](https://aclanthology.org/W16-2342.pdf)) has one
    of the highest correlation with human evaluation among the traditional metrics.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: CharacTER ([Wang 等人, 2016](https://aclanthology.org/W16-2342.pdf)) 在传统度量中与人工评估的相关性最高。
- en: Nonetheless, it remains less used than other metrics. I couldn’t find any papers
    that used it recently.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，它的使用仍然少于其他度量。我最近找不到使用它的论文。
- en: '[The implementation of characTER by its authors](https://github.com/rwth-i6/CharacTER)
    is available on Github (unknown license).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[其作者对 CharacTER 的实现](https://github.com/rwth-i6/CharacTER)可以在 Github 上找到（未知许可证）。'
- en: Neural Metrics
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经度量
- en: Neural metrics take a very different approach from the traditional metrics.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 神经度量采用了与传统度量截然不同的方法。
- en: They estimate a translation quality score using **neural networks**.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 他们使用**神经网络**来估计翻译质量评分。
- en: To the best of my knowledge, ReVal, proposed in 2015, was the first neural metric
    with the objective of computing a translation quality score.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 据我所知，2015年提出的 ReVal 是第一个旨在计算翻译质量评分的神经度量。
- en: Since ReVal, new neural metrics are regularly proposed for evaluating machine
    translation.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 自 ReVal 以来，新的神经度量定期被提出用于评估机器翻译。
- en: The research effort in machine translation evaluation is now almost **exclusively
    focusing on neural metrics**.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 机器翻译评估的研究工作现在几乎**完全专注于神经度量**。
- en: Yet, as we will see, despite their superiority, neural metrics are far from
    popular. While neural metrics have been around for almost 8 years, traditional
    metrics are still overwhelmingly preferred, at least by the research community
    (the situation is probably different in the machine translation industry).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，正如我们将看到的，尽管神经度量具有优势，但其普及度仍远远不如传统度量。尽管神经度量已经存在近 8 年，但传统度量仍然被研究界压倒性地偏好（在机器翻译行业的情况可能不同）。
- en: 'Advantages:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 优势：
- en: '**Good correlation with human evaluation**: Neural metrics are state-of-the-art
    for machine translation evaluation'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与人工评估的良好相关性**：神经度量是机器翻译评估的最先进技术。'
- en: '**No preprocessing required**: This is mainly true for recent neural metrics
    such as COMET and BLEURT. The preprocessing, such as tokenization, is done internally
    and transparently by the metric, i.e., the users don’t need to care about it.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无需预处理**：这主要适用于最近的神经度量，如 COMET 和 BLEURT。预处理，如标记化，由度量内部和透明地完成，即用户无需关心。'
- en: '**Better recall**: Thanks to the exploitation of embeddings, neural metrics
    can reward translation even when they don’t exactly match the reference. For instance,
    a word that has a meaning similar to a word in the reference will be likely rewarded
    by the metric, in contrast to traditional metrics that can only reward exact matches.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好的召回率**：得益于嵌入的利用，神经指标即使在翻译与参考不完全匹配时也能给出奖励。例如，与参考中某个词意义相似的词更可能被指标奖励，这与只能奖励精确匹配的传统指标形成对比。'
- en: '**Trainable**: This may be an advantage as well as a disadvantage. Most neural
    metrics must be trained. It is an advantage if you have training data for your
    specific use case. You can fine-tune the metric to best correlate with human judgments.
    However, if you don’t have the specific training data, the correlation with human
    evaluation will be far from optimal.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可训练**：这可能既是优点也是缺点。大多数神经指标必须经过训练。如果你有适用于特定用例的训练数据，这是一个优势。你可以微调指标以最好地与人类判断相关。然而，如果没有特定的训练数据，与人类评估的相关性将远非最佳。'
- en: 'Disadvantages:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点：
- en: '**High computational cost**: Neural metrics don’t require a GPU but are much
    faster if you have one. Yet, even with a GPU, they are significantly slower than
    traditional metrics. Some metrics relying on large language models such as BLEURT
    and COMET also require a significant amount of memory. Their high computational
    cost also makes statistical significance testing extremely costly.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高计算成本**：神经指标不需要GPU，但如果有GPU的话会更快。然而，即使有GPU，它们也明显比传统指标慢。一些依赖大型语言模型的指标，如BLEURT和COMET，也需要大量内存。它们的高计算成本还使得统计显著性测试极为昂贵。'
- en: '**Unexplainable**: Understanding why a neural metric yields a particular score
    is nearly impossible since the neural model behind it often leverages millions
    or billions of parameters. Improving the explainability of neural models is a
    very active research area.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无法解释**：理解神经指标为何产生特定评分几乎是不可能的，因为其背后的神经模型通常利用了数百万或数十亿个参数。提高神经模型的可解释性是一个非常活跃的研究领域。'
- en: '**Difficult to maintain**: Older implementations of neural metrics don’t work
    anymore if they were not properly maintained. This is mainly due to the changes
    in nVidia CUDA and/or frameworks such as (py)Torch and Tensorflow. Potentially,
    the current version of the neural metrics we use today won’t work in 10 years.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**难以维护**：如果没有得到适当维护，较老的神经指标实现将不再有效。这主要是由于nVidia CUDA以及（py）Torch和Tensorflow等框架的变化。当前使用的神经指标在10年后可能无法使用。'
- en: '**Not reproducible**: Neural metrics usually come with many more hyperparameters
    than traditional metrics. Those are largely underspecified in the scientific publications
    using them. Therefore, reproducing a particular score for a particular dataset
    is often impossible.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不可重复**：神经指标通常比传统指标有更多的超参数。这些在使用它们的科学出版物中大多未被详细说明。因此，重复特定数据集的特定评分通常是不可能的。'
- en: ReVal
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReVal
- en: To the best of my knowledge, ReVal ([Gupta et al., 2015](https://aclanthology.org/D15-1124.pdf))
    is the first neural metric proposed to evaluate machine translation quality.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 据我所知，ReVal ([Gupta et al., 2015](https://aclanthology.org/D15-1124.pdf)) 是第一个提出用于评估机器翻译质量的神经指标。
- en: ReVal was a significant improvement over traditional metrics with a significantly
    better correlation with human evaluation.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ReVal相比传统指标有显著改进，与人类评估的相关性显著更好。
- en: The metric is based on an LSTM and is very simple, but has never been used in
    machine translation research as far as I know.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标基于LSTM，虽然非常简单，但据我所知，尚未在机器翻译研究中使用过。
- en: It is now outperformed by more recent metrics.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已被更新的指标所超越。
- en: If you are interested to understand how it works, you can still find [ReVal’s
    original implementation on Github](https://github.com/rohitguptacs/ReVal) (GNU
    General Public License V2.0).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣了解它的工作原理，你仍然可以在[Github上找到ReVal的原始实现](https://github.com/rohitguptacs/ReVal)（GNU通用公共许可证V2.0）。
- en: YiSi
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YiSi
- en: YiSi ([Chi-kiu Lo, 2019](https://aclanthology.org/W19-5358.pdf)) is a very versatile
    metric. It mainly exploits an embedding model but can be augmented with various
    resources such as a semantic parser, a large language model (BERT), and even features
    from the source text and source language.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: YiSi ([Chi-kiu Lo, 2019](https://aclanthology.org/W19-5358.pdf)) 是一个非常多功能的指标。它主要利用了嵌入模型，但可以通过各种资源如语义解析器、大型语言模型（BERT），甚至是源文本和源语言的特征来增强。
- en: Using all these options can make it fairly complex and reduces its scope to
    a few language pairs. Moreover, the gains in terms of correlation with human judgments
    when using all these options are not obvious.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用所有这些选项可能会使其相当复杂，并将其范围缩小到少数语言对。此外，使用所有这些选项时，与人工判断的相关性提升并不明显。
- en: Nonetheless, the metric itself, using just the original embedding model, shows
    a very good correlation with human evaluation.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，使用仅原始嵌入模型的指标与人工评估表现出非常好的相关性。
- en: '![](../Images/67b29d9e097f29153a18e57206fddddb.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67b29d9e097f29153a18e57206fddddb.png)'
- en: Figure by [Chi-kiu Lo, 2019](https://aclanthology.org/W19-5358.pdf)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图来源于[Chi-kiu Lo, 2019](https://aclanthology.org/W19-5358.pdf)
- en: The author showed that for evaluating English translations YiSi significantly
    outperforms traditional metrics.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 作者展示了在评估英语翻译时，YiSi显著优于传统指标。
- en: The original implementation of YiSi is [publicly available on Github](https://github.com/chikiulo/yisi)
    (MIT license).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: YiSi的原始实现[公开在Github上](https://github.com/chikiulo/yisi)（MIT许可证）。
- en: BERTScore
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BERTScore
- en: BERTScore ([Zhang et al., 2020](https://arxiv.org/pdf/1904.09675.pdf)) exploits
    the contextual embeddings of BERT for each token in the evaluated sentence and
    compares them with the token embeddings of the reference.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore ([Zhang et al., 2020](https://arxiv.org/pdf/1904.09675.pdf)) 利用BERT对评估句子中每个标记的上下文嵌入，并将其与参考的标记嵌入进行比较。
- en: 'It works as illustrated below:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 它的工作方式如下所示：
- en: '![](../Images/38fa77a7febfd7d0a00bdce488c3aec6.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38fa77a7febfd7d0a00bdce488c3aec6.png)'
- en: Figure by [Zhang et al., 2020](https://arxiv.org/pdf/1904.09675.pdf)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图来源于[Zhang et al., 2020](https://arxiv.org/pdf/1904.09675.pdf)
- en: It is one of the first metrics to adopt a large language model for evaluation.
    It wasn’t proposed specifically for machine translation but rather for any language
    generation task.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 它是最早采用大型语言模型进行评估的指标之一。它不是专门为机器翻译提出的，而是为任何语言生成任务设计的。
- en: BERTScore is the most used neural metric in machine translation evaluation.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore是机器翻译评估中使用最广泛的神经指标。
- en: A [BERTScore implementation](https://github.com/Tiiiger/bert_score) is available
    on Github (MIT license).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[BERTScore实现](https://github.com/Tiiiger/bert_score)可在Github上获得（MIT许可证）。'
- en: BLEURT
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BLEURT
- en: BLEURT ([Sellam et al., 2020](https://aclanthology.org/2020.acl-main.704.pdf))
    is another metric relying on BERT but that can be specifically trained for machine
    translation evaluation.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: BLEURT ([Sellam et al., 2020](https://aclanthology.org/2020.acl-main.704.pdf))
    是另一个依赖于BERT的指标，但可以专门针对机器翻译评估进行训练。
- en: 'More precisely, it is a BERT model fine-tuned on synthetic data that are sentences
    from Wikipedia paired with their random perturbations of different kinds: *Note:
    This step is confusedly denoted “pre-training” by the authors (see note 3 in the
    paper) but it actually comes after the original pre-training of BERT.*'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 更确切地说，它是一个在合成数据上微调的BERT模型，这些数据是来自维基百科的句子与其不同类型的随机扰动：*注意：这一步被作者混乱地称为“预训练”（见论文中的注释3），但实际上是在BERT的原始预训练之后进行的。*
- en: Masked word (as in the original BERT)
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被遮蔽的词（如原始BERT中）
- en: Dropped word
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被丢弃的词
- en: Backtranslation (i.e., sentences generated by a machine translation system)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回译（即机器翻译系统生成的句子）
- en: 'Each sentence pair is evaluated during training with several losses. Some of
    these losses are computed with evaluation metrics:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 每对句子在训练过程中都会通过多个损失进行评估。其中一些损失是通过评估指标计算的：
- en: '![](../Images/75a0959127e110f106e5646f4a15184c.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75a0959127e110f106e5646f4a15184c.png)'
- en: Table by [Sellam et al., 2020](https://aclanthology.org/2020.acl-main.704.pdf)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表格来源于[Sellam et al., 2020](https://aclanthology.org/2020.acl-main.704.pdf)
- en: Finally, in a second phase, BLEURT is fine-tuned on translations and their rating
    provided by humans.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第二阶段，BLEURT会在翻译和由人工提供的评分上进行微调。
- en: Intuitively, thanks to the use of synthetic data that may resemble machine translation
    errors or outputs, BLEURT is much more robust to quality and domain drifts than
    BERTScore.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，由于使用了可能类似于机器翻译错误或输出的合成数据，BLEURT在质量和领域漂移方面比BERTScore更具鲁棒性。
- en: Moreover, since BLEURT exploits a combination of metric as “pre-training signals”,
    it is intuitively better than each one of these metrics, including BERTScore.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于BLEURT利用了作为“预训练信号”的指标组合，它在直观上比这些指标中的每一个都要好，包括BERTScore。
- en: 'However, BLEURT is very costly to train. I am only aware of BLEURT checkpoints
    released by Google. *Note: If you are aware of other models, please let me know
    in the comments.*'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，训练BLEURT的成本非常高。 我只知道Google发布的BLEURT检查点。 *注意：如果你知道其他模型，请在评论中告诉我。*
- en: The first version was only trained for English, but the newer version, denoted
    BLEURT-20, now includes 19 more languages. [Both BLEURT versions are available
    in the same repository](https://github.com/google-research/BLEURT).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个版本仅对英语进行训练，但较新的版本，称为BLEURT-20，现在包括19种其他语言。[这两个BLEURT版本可以在同一仓库中获取](https://github.com/google-research/BLEURT)。
- en: Prism
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prism
- en: In their work proposing Prism, [Thompson and Post (2019)](http://aclanthology.lst.uni-saarland.de/2020.emnlp-main.8.pdf)
    intuitively argue that machine translation and paraphrasing evaluation are very
    similar tasks. Their only difference is that the source language is not the same.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在提出Prism的工作中，[Thompson和Post（2019）](http://aclanthology.lst.uni-saarland.de/2020.emnlp-main.8.pdf)直观地认为机器翻译和释义评估是非常相似的任务。他们唯一的区别在于源语言不同。
- en: Indeed, with paraphrasing, the objective is to generate a new sentence A’, given
    a sentence A, with A and A’ having the same meaning. Assessing how close A and
    A’ is identical to assessing how a translation hypothesis is close to a given
    reference translation. In other words, is the translation hypothesis a good paraphrase
    of the reference translation.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，通过释义，目标是生成一个新的句子A’，给定句子A，其中A和A’具有相同的意义。评估A和A’的相似度与评估翻译假设与给定参考翻译的接近程度是相同的。换句话说，翻译假设是否是参考翻译的一个好的释义。
- en: Prism is a neural metric trained on a large multilingual parallel dataset through
    a multilingual neural machine translation framework.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Prism是通过多语言神经机器翻译框架在大型多语言平行数据集上训练的神经度量标准。
- en: Then, at inference time, the trained model is used as a zero-shot paraphraser
    to score the similarity between a source text (the translation hypothesis) and
    the target text (the reference translation) that are both in the same language.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在推理时，训练好的模型被用作零-shot释义器，以评分源文本（翻译假设）和目标文本（参考翻译）之间的相似度，这两者都在同一语言中。
- en: The main advantage of this approach is that Prism doesn’t need any human evaluation
    training data nor any paraphrasing training data. The only requirement is to have
    parallel data for the languages you plan to evaluate.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要优点是Prism不需要任何人工评估训练数据，也不需要任何释义训练数据。唯一的要求是拥有你计划评估的语言的平行数据。
- en: While Prism is original, convenient to train, and seems to outperform most other
    metrics (including BLEURT), I couldn’t find any machine translation research publication
    using it.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Prism是原创的、方便训练，并且似乎优于大多数其他度量标准（包括BLEURT），但我没有找到使用它的机器翻译研究出版物。
- en: The original implementation of [Prism is publicly available on Github](https://github.com/thompsonb/prism)
    (MIT license).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[Prism的原始实现可以在Github上公开获取](https://github.com/thompsonb/prism)（MIT许可证）。'
- en: COMET
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: COMET
- en: COMET ([Rei et al., 2020](https://aclanthology.org/2020.emnlp-main.213.pdf))
    is a more supervised approach also based on a large language model. The authors
    selected XLM-RoBERTa but mention that other models such as BERT could also work
    with their approach.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: COMET（[Rei 等, 2020](https://aclanthology.org/2020.emnlp-main.213.pdf)）是一种基于大型语言模型的监督方法。作者选择了XLM-RoBERTa，但提到像BERT这样的其他模型也可以与他们的方法一起使用。
- en: In contrast to most other metrics, COMET exploits the source sentence. The large
    language model is thus fine-tuned on a triplet {translated source sentence, translation
    hypothesis, reference translation}.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数其他度量标准不同，COMET利用了源句子。因此，大型语言模型在一个三元组{翻译源句子、翻译假设、参考翻译}上进行微调。
- en: '![](../Images/b4b14895c18748a1c6b68369be04ea0c.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4b14895c18748a1c6b68369be04ea0c.png)'
- en: Figure by [Rei et al., 2020](https://aclanthology.org/2020.emnlp-main.213.pdf)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图由[Rei等, 2020](https://aclanthology.org/2020.emnlp-main.213.pdf)提供
- en: The metric is trained using human ratings (the same ones used by BLEURT).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 该度量标准使用人工评分（与BLEURT使用的相同评分）进行训练。
- en: COMET is much more simple to train than BLEURT since it doesn’t require the
    generation and the scoring of synthetic data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: COMET比BLEURT更容易训练，因为它不需要生成和评分合成数据。
- en: COMET is available in many versions, including distilled models ([COMETHINO](https://aclanthology.org/2022.eamt-1.9.pdf))
    that have a much smaller memory footprint.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: COMET有许多版本，包括[COMETHINO](https://aclanthology.org/2022.eamt-1.9.pdf)这种记忆占用更小的蒸馏模型。
- en: The [released implementation of COMET](https://github.com/Unbabel/COMET) (Apache
    license 2.0) also includes a tool to efficiently perform statistical significance
    testing.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[COMET的发布实现](https://github.com/Unbabel/COMET)（Apache许可证2.0）还包括一个高效执行统计显著性测试的工具。'
- en: Conclusion and Recommendations
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论和建议
- en: Machine translation evaluation is a **very active research area**. Neural metrics
    are **getting better and more efficient every year**.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 机器翻译评估是一个**非常活跃的研究领域**。神经指标**每年都在变得更好、更高效**。
- en: Yet, traditional metrics such as BLEU remain the favorites of machine translation
    practitioners, mainly by habits.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，传统指标如BLEU仍然是机器翻译从业者的最爱，主要是由于习惯。
- en: 'In 2022, the [Conference on Machine Translation (WMT22) published a ranking
    of evaluation metrics](https://www.statmt.org/wmt22/pdf/2022.wmt-1.2.pdf) according
    to their correlation with human evaluation, including metrics I presented in this
    article:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年，[机器翻译会议（WMT22）发布了一份根据与人工评估相关性的评价指标排名](https://www.statmt.org/wmt22/pdf/2022.wmt-1.2.pdf)，其中包括了我在本文中介绍的指标：
- en: '![](../Images/b80680afbb0d0928893a0e512bfe22c8.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b80680afbb0d0928893a0e512bfe22c8.png)'
- en: Table by [Freitag et al. (2022)](https://www.statmt.org/wmt22/pdf/2022.wmt-1.2.pdf)
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 表格由[Freitag等（2022）](https://www.statmt.org/wmt22/pdf/2022.wmt-1.2.pdf)提供
- en: COMET and BLEURT rank at the top while BLEU appears at the bottom. Interestingly,
    you can also notice in this table that there are some metrics that I didn’t write
    about in this article. Some of them, such as MetricX XXL, are undocumented.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: COMET和BLEURT排名靠前，而BLEU排在底部。有趣的是，你还可以在这个表格中看到一些我在本文中没有提及的指标。其中一些，如MetricX XXL，是没有文档记录的。
- en: Despite having countless better alternatives, BLEU remains by far the most used
    metric, at least in machine translation research.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有无数更好的替代方案，BLEU仍然是迄今为止使用最广泛的指标，至少在机器翻译研究中如此。
- en: '**Personal recommendations:**'
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**个人推荐：**'
- en: 'When I review scientific papers for conferences and journals, I always recommend
    the following to the authors who only use BLEU for machine translation evaluation:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 当我为会议和期刊审阅科学论文时，我总是建议那些仅使用BLEU进行机器翻译评估的作者：
- en: Add the results for at least **one neural metric** such as COMET or BLEURT,
    if the language pair is covered by these metrics.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加至少**一个神经指标**的结果，例如COMET或BLEURT，前提是这些指标涵盖了语言对。
- en: Add the results for **chrF** (not chrF++). While chrF is not state-of-the-art,
    it is significantly better than BLEU, yield scores that are easily reproducible,
    and can be used for diagnostic purposes.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加**chrF**（不是chrF++）的结果。虽然chrF不是最先进的技术，但它明显优于BLEU，生成的评分易于复现，并且可以用于诊断目的。
