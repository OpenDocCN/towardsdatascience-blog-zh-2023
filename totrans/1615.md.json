["```py\n# Intallation of the pca library\npip install pca\n```", "```py\n# Load other libraries\nfrom sklearn.datasets import load_wine\nimport pandas as pd\n\n# Load dataset\ndata = load_wine()\n\n# Make dataframe\ndf = pd.DataFrame(index=data.target, data=data.data, columns=data.feature_names)\n\nprint(df)\n#     alcohol  malic_acid   ash  ...   hue  ..._wines  proline\n# 0     14.23        1.71  2.43  ...  1.04  3.92   1065.0\n# 0     13.20        1.78  2.14  ...  1.05  3.40   1050.0\n# 0     13.16        2.36  2.67  ...  1.03  3.17   1185.0\n# 0     14.37        1.95  2.50  ...  0.86  3.45   1480.0\n# 0     13.24        2.59  2.87  ...  1.04  2.93    735.0\n# ..      ...         ...   ...  ...   ...  ...\n# 2     13.71        5.65  2.45  ...  0.64  1.74    740.0\n# 2     13.40        3.91  2.48  ...  0.70  1.56    750.0\n# 2     13.27        4.28  2.26  ...  0.59  1.56    835.0\n# 2     13.17        2.59  2.37  ...  0.60  1.62    840.0\n# 2     14.13        4.10  2.74  ...  0.61  1.60    560.0\n# \n# [178 rows x 13 columns]\n```", "```py\n# Import library\nfrom pca import pca\n\n# Initialize pca to also detected outliers.\nmodel = pca(normalize=True, detect_outliers=['ht2', 'spe'], n_std=2  )\n\n# Fit and transform\nresults = model.fit_transform(df)\n```", "```py\n# Print outliers\nprint(results['outliers'])\n\n#     y_proba     p_raw    y_score  y_bool  y_bool_spe  y_score_spe\n#0   0.982875  0.376726  21.351215   False       False     3.617239\n#0   0.982875  0.624371  17.438087   False       False     2.234477\n#0   0.982875  0.589438  17.969195   False       False     2.719789\n#0   0.982875  0.134454  27.028857   False       False     4.659735\n#0   0.982875  0.883264  12.861094   False       False     1.332104\n#..       ...       ...        ...     ...         ...          ...\n#2   0.982875  0.147396  26.583414   False       False     4.033903\n#2   0.982875  0.771408  15.087004   False       False     3.139750\n#2   0.982875  0.244157  23.959708   False       False     3.846217\n#2   0.982875  0.333600  22.128104   False       False     3.312952\n#2   0.982875  0.138437  26.888278   False       False     4.238283\n\n[178 rows x 6 columns]\n```", "```py\n# Plot Hotellings T2\nmodel.biplot(SPE=False, HT2=True, density=True, title='Outliers marked using Hotellings T2 method.')\n\n# Make a plot in 3 dimensions\nmodel.biplot3d(SPE=False, HT2=True, density=True, arrowdict={'scale_factor': 2.5, 'fontsize': 20}, title='Outliers marked using Hotellings T2 method.')\n\n# Get the outliers using SPE/DmodX method.\ndf.loc[results['outliers']['y_bool'], :]\n```", "```py\n# Plot SPE/DmodX method\nmodel.biplot(SPE=True, HT2=True, title='Outliers marked using SPE/dmodX method and Hotelling T2.')\n\n# Make a plot in 3 dimensions\nmodel.biplot3d(SPE=True, HT2=True, title='Outliers marked using SPE/dmodX method and Hotelling T2.')\n\n# Get the outliers using SPE/DmodX method.\ndf.loc[results['outliers']['y_bool_spe'], :]\n```", "```py\n# Grab overlapping outliers\nI_overlap = np.logical_and(results['outliers']['y_bool'], results['outliers']['y_bool_spe'])\n\n# Print overlapping outliers\ndf.loc[I_overlap, :]\n```", "```py\n# Import library\nfrom pca import pca\n\n# Initialize\nmodel = pca()\n\n# Load Student Performance data set\ndf = model.import_example(data='student')\n\nprint(df)\n#     school sex  age address famsize Pstatus  ...  Walc  health absences\n# 0       GP   F   18       U     GT3       A  ...     1       3        4\n# 1       GP   F   17       U     GT3       T  ...     1       3        2\n# 2       GP   F   15       U     LE3       T  ...     3       3        6\n# 3       GP   F   15       U     GT3       T  ...     1       5        0  \n# 4       GP   F   16       U     GT3       T  ...     2       5        0  \n# ..     ...  ..  ...     ...     ...     ...  ...   ...     ...      ...  \n# 644     MS   F   19       R     GT3       T  ...     2       5        4  \n# 645     MS   F   18       U     LE3       T  ...     1       1        4  \n# 646     MS   F   18       U     GT3       T  ...     1       5        6  \n# 647     MS   M   17       U     LE3       T  ...     4       2        6  \n# 648     MS   M   18       R     LE3       T  ...     4       5        4  \n\n# [649 rows x 33 columns]\n```", "```py\n# Install onehot encoder\npip install df2onehot\n\n# Initialize\nfrom df2onehot import df2onehot\n\n# One hot encoding\ndf_hot = df2onehot(df)[‘onehot’]\n\nprint(df_hot)\n#      school_GP  school_MS  sex_F  sex_M  ...  \n# 0         True      False   True  False  ...  \n# 1         True      False   True  False  ...  \n# 2         True      False   True  False  ...  \n# 3         True      False   True  False  ...  \n# 4         True      False   True  False  ...  \n# ..         ...        ...    ...    ...  ...  \n# 644      False       True   True  False  ...  \n# 645      False       True   True  False  ...  \n# 646      False       True   True  False  ...  \n# 647      False       True  False   True  ...  \n# 648      False       True  False   True  ...  \n\n# [649 rows x 177 columns]\n```", "```py\n# Initialize PCA to also detected outliers.\nmodel = pca(normalize=True,\n            detect_outliers=['ht2', 'spe'],\n            alpha=0.05,\n            n_std=3,\n            multipletests='fdr_bh')\n\n# Fit and transform\nresults = model.fit_transform(df_hot)\n\n# [649 rows x 177 columns]\n# [pca] >Processing dataframe..\n# [pca] >Normalizing input data per feature (zero mean and unit variance)..\n# [pca] >The PCA reduction is performed to capture [95.0%] explained variance using the [177] columns of the input data.\n# [pca] >Fit using PCA.\n# [pca] >Compute loadings and PCs.\n# [pca] >Compute explained variance.\n# [pca] >Number of components is [116] that covers the [95.00%] explained variance.\n# [pca] >The PCA reduction is performed on the [177] columns of the input dataframe.\n# [pca] >Fit using PCA.\n# [pca] >Compute loadings and PCs.\n# [pca] >Outlier detection using Hotelling T2 test with alpha=[0.05] and n_components=[116]\n# [pca] >Multiple test correction applied for Hotelling T2 test: [fdr_bh]\n# [pca] >Outlier detection using SPE/DmodX with n_std=[3]\n# [pca] >Plot PC1 vs PC2 with loadings.\n\n# Overlapping outliers between both methods\noverlapping_outliers = np.logical_and(results['outliers']['y_bool'],\n                                      results['outliers']['y_bool_spe'])\n\n# Show overlapping outliers\ndf.loc[overlapping_outliers]\n\n#     school sex  age address famsize Pstatus  ...  Walc  health absences \n# 279     GP   M   22       U     GT3       T  ...     5       1       12  \n# 284     GP   M   18       U     GT3       T  ...     5       5        4 \n# 523     MS   M   18       U     LE3       T  ...     5       5        2 \n# 605     MS   F   19       U     GT3       T  ...     3       2        0 \n# 610     MS   F   19       R     GT3       A  ...     4       1        0 \n\n# [5 rows x 33 columns]\n```", "```py\n# Make biplot\nmodel.biplot(SPE=True,\n             HT2=True,\n             n_feat=10,\n             legend=True,\n             labels=df['sex'],\n             title='Student Performance',\n             figsize=(20, 12),\n             color_arrow='k',\n             arrowdict={'fontsize':16, 'c':'k'},\n             cmap='bwr_r',\n             gradient='#FFFFFF',\n             edgecolor='#FFFFFF',\n             density=True,\n             )\n```"]