- en: Forecasting Intermittent Time Series in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/forecasting-intermittent-time-series-in-python-9fd028a0c9ee](https://towardsdatascience.com/forecasting-intermittent-time-series-in-python-9fd028a0c9ee)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A complete guide on intermittent time series forecasting in Python with a capstone
    project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcopeixeiro?source=post_page-----9fd028a0c9ee--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----9fd028a0c9ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9fd028a0c9ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9fd028a0c9ee--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----9fd028a0c9ee--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9fd028a0c9ee--------------------------------)
    ¬∑15 min read¬∑Aug 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b059b7a1862602f8507d5feeee2ed7b8.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Wexor Tmg](https://unsplash.com/@wexor?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Intermittent time series, or sparse time series, is a special case where non-zero
    values appear sporadically in time, while the rest of the values are 0.
  prefs: []
  type: TYPE_NORMAL
- en: A common example of spare time series is rainfall over time. There can be a
    lot of consecutive days without rain, and when it rains, the volume varies.
  prefs: []
  type: TYPE_NORMAL
- en: Another real-life example of intermittent series is in the demand of slow-moving
    or high-value items, such as spare parts in aerospace or heavy machinery.
  prefs: []
  type: TYPE_NORMAL
- en: The intermittent nature of some time series pose a real challenge in forecasting,
    as traditional model do not handle intermittency well. Therefore, we must turn
    to alternate forecasting methods tailored for sparse time series.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we explore different ways of forecasting intermittent time
    series. As always, we explore each model theoretically first, and implement them
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: As always, the full source code is available on [GitHub](https://github.com/marcopeix/intermittent_time_series).
  prefs: []
  type: TYPE_NORMAL
- en: '**Learn the latest time series analysis techniques with my** [**free time series
    cheat sheet**](https://www.datasciencewithmarco.com/pl/2147608294) **in Python!
    Get the implementation of statistical and deep learning techniques, all in Python
    and TensorFlow!**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let‚Äôs get started!
  prefs: []
  type: TYPE_NORMAL
- en: Croston‚Äôs method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Croston‚Äôs method is one of the most common approaches to forecasting spare time
    series. It often acts as a baseline model to evaluate more complex methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'With Croston‚Äôs method, two series are constructed from the original series:'
  prefs: []
  type: TYPE_NORMAL
- en: A series containing the time periods with only zero values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A series containing time periods with non-zero values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let‚Äôs consider a toy example to illustrate that. Given the spare time series
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df44d08073163f068cc6e4c9d9cb5e02.png)'
  prefs: []
  type: TYPE_IMG
- en: A simulated sparse time series. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, according to Croston‚Äôs method, we create two new series: one with non-zero
    values, and the other with the period of time separating non-zero values.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6871b33517a24311247bf9ad9ac0b30.png)'
  prefs: []
  type: TYPE_IMG
- en: Constructing two new series. The first has only the non-zero values. The second
    has the period between non-zero values. Note that we assign a period of 1 between
    two consecutive values. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the table above, we can see that the we denote non-zero values as ***q·µ¢***
    and the period between two consecutive non-zero values as ***a·µ¢***.
  prefs: []
  type: TYPE_NORMAL
- en: Note also that the first value of ***a·µ¢*** is 1, because we have a non-zero
    value at *t=1*. Also, the period between two consecutive values is also considered
    to be 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'From there, we predict each series using simple exponential smoothing according
    to the equations below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a83635165e840d0becbc233ca1c45950.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting non-zero values. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d64db53e151787e3783147263c724ea.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting intervals of time between consecutive non-zero values. Image by
    the author.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the smoothing parameter *alpha* is between 0 and 1, as we are using
    simple exponential smoothing. Note also that the same smoothing parameter is used
    for both equations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the final forecast is the ratio of ***q*** and ***a***, as shown in the
    equation below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f4bb57020e0e29f43c82bd703940cafa.png)'
  prefs: []
  type: TYPE_IMG
- en: One-step ahead forecast using Croston‚Äôs method. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Now, since simple exponential smoothing is used to forecast each series, the
    prediction will be a flat horizontal line. That is why we often use it as a baseline
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Also, most implementations of the basic Croston‚Äôs method use a value of 0.1
    for the smoothing parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this is the most basic method for forecasting intermittent time series,
    but there are ways to easily improve it, as we discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the Croston‚Äôs method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have seen earlier, the classical Croston‚Äôs method uses the same smoothing
    parameter of 0.1 to forecast both constructed series, which does not seem to be
    ideal.
  prefs: []
  type: TYPE_NORMAL
- en: An optimized version of Croston‚Äôs method was suggested, where the smoothing
    parameter is varied between 0.1 and 0.3\. Also, each series is optimized separately.
  prefs: []
  type: TYPE_NORMAL
- en: Everything remains unchanged, but now, we have unique optimized smoothing parameters
    for each series that make up the final forecast.
  prefs: []
  type: TYPE_NORMAL
- en: Croston‚Äôs method in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let‚Äôs implement Croston‚Äôs method on a simulated dataset to see the kind of predictions
    we can make with this model.
  prefs: []
  type: TYPE_NORMAL
- en: First, I will import the required libraries and read the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then, we use the implementation available in *statsforecast*. For now, let‚Äôs
    work with the classical version of Croston‚Äôs method which uses a smoothing factor
    of 0.1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Then, to compare the model‚Äôs predictions to the actual data in our simulated
    dataset, we run the cross-validation function. Here, we set the horizon to 1,
    so that our prediction curve is updated at every time step, over the last 50 time
    steps of our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can plot the actual values and the predictions coming from the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4581f35d3c5bfb5b33c8b4ab98073dfe.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting the next time step with Croston‚Äôs method. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we can see how, intuitively, Croston‚Äôs method is really
    a weighted average for intermittent time series.
  prefs: []
  type: TYPE_NORMAL
- en: Looking closely, if a past value was large, then the next prediction would increase,
    and if a past value was small, then the next prediction would decrease.
  prefs: []
  type: TYPE_NORMAL
- en: Notice also the period of time where we have consecutive zero values, meaning
    that the prediction curve does not get updated, and remains flat.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, keep in mind that our prediction curve moves a lot because we forecast
    only the next time step. If we set a longer horizon, the curve resemble more of
    a staircase, since Croston‚Äôs method outputs a constant value.
  prefs: []
  type: TYPE_NORMAL
- en: Optimized Croston‚Äôs method in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let‚Äôs repeat the same exercise as above, but using the optimized version
    of Croston‚Äôs method, where the smoothing parameter is optimized separately for
    the non-zero values series, and the zero values series.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Plotting the results gives the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4fa9a8d895ede6d4a9c99d47be0f00c0.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting with the optimized Croston‚Äôs method. It is essentially the same
    thing as the previous method in this case. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the figure, we can see how optimizing smoothing parameter resulted
    in essentially the same predictions as the classical method for our simulated
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand Croston‚Äôs method, let‚Äôs move on to another forecasting
    technique.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregate-Disaggreagate Intermittent Demand Approach (ADIDA)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Aggregate-Disaggregate Intermittent Demand Approach, or ADIDA, aims to remove
    intermittence by aggregating the series at a lower frequency.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if hourly data has zero values, then summing over 24 hours to get
    daily data might get rid of the zero values. The same logic applies to intermittent
    daily data that we could aggregate to weekly data to remove periods with zero
    values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d8cc0fddd41c0584c0a19ac929a4093.png)'
  prefs: []
  type: TYPE_IMG
- en: Aggregating our simulated data with a rolling sum of five time steps. Notice
    how the bottom plot (aggregated values) effectively removes the intermittence
    in the series. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: In the figure above, we can see the effect of aggregation on our simulated data.
    Here, we aggregate over five time steps. The resulting aggregated series, shown
    in the bottom plot, is not intermittent anymore, since we got rid of all zero
    values.
  prefs: []
  type: TYPE_NORMAL
- en: Once the data is aggregated, simple exponential smoothing is again used to forecast
    the aggregated series.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we disaggregate the predictions to bring them back to the original frequency.
    For example, if hourly data was aggregated to daily data, then each prediction
    would be divided by 24 (since there are 24 hours in a day) to get the disaggregated
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: How to choose the aggregation level
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Of course, the aggregation level greatly impacts the predictions and performance
    of the model.
  prefs: []
  type: TYPE_NORMAL
- en: If the aggregation is too big, for example going from hourly to weekly data,
    then you might lose a lot of information.
  prefs: []
  type: TYPE_NORMAL
- en: If the aggregation is too small, then the resulting series might also be intermittent,
    in which case traditional forecasting methods will not work appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: While there is no clear answer on how to choose the aggregation level, one way
    that is implemented in *statsforecast* is to calculate the the length of all intervals
    between non-zero values, and take the average of the intervals as the aggregate
    level.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if your intermittent series has intervals between non-zero values
    of [3, 5, 4], then the aggregate level would be 4.
  prefs: []
  type: TYPE_NORMAL
- en: In the best case scenario, this method completely removes the intermittency.
    Otherwise, only a few zero values will remain, which should not greatly impact
    exponential smoothing.
  prefs: []
  type: TYPE_NORMAL
- en: ADIDA in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let‚Äôs implement ADIDA on our simulated data and see the predictions we
    obtain.
  prefs: []
  type: TYPE_NORMAL
- en: Using *statsforecast*, the implementation remains straightforward, as we simply
    need to change the model, but the pipeline stays the same.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We then plot the predictions and see how it behaves when compared to Croston‚Äôs
    method.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6bb3441cf12ba7ef97485d273bae1ddb.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting with ADIDA (dotted) and Croston‚Äôs method (dashed). We can see that
    ADIDA reacts more to periods with 0 values by lowering the predictions. Image
    by the author.
  prefs: []
  type: TYPE_NORMAL
- en: In the figure above, we can see that ADIDA reacts much more to periods with
    zero values. While the predictions from Croston will remain constant if zero values
    are observed, ADIDA will gradually decrease the prediction curve, and so it approaches
    more the actual data.
  prefs: []
  type: TYPE_NORMAL
- en: While ADIDA considers a single aggregation level, an iteration to the model
    was proposed to consider multiple aggregation levels. This is what we study in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Intermittent Multiple Aggregation Prediction Algorithm (IMAPA)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, ADIDA only considers one aggregation level.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is possible that information can be retrieved from a series at different
    aggregation levels.
  prefs: []
  type: TYPE_NORMAL
- en: For example, given hourly data, different patterns will arise if we aggregate
    the data daily, weekly, or monthly.
  prefs: []
  type: TYPE_NORMAL
- en: This is the general idea behind the Intermittent Multiple Aggregation Prediction
    Algorithm or IMAPA.
  prefs: []
  type: TYPE_NORMAL
- en: Again, the data is aggregated, but at multiple levels. Then, just like with
    ADIDA, simple exponential smoothing is used to generate predictions at each aggregation
    level. After, each prediction is dissagregated, just like in ADIDA.
  prefs: []
  type: TYPE_NORMAL
- en: The final prediction is then obtained by taking the average of each predictions
    at each aggregation level.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we can think of IMAPA as running ADIDA multiple times at different aggregation
    levels, and then simply averaging the predictions to get a final prediction.
  prefs: []
  type: TYPE_NORMAL
- en: With all that in mind, let‚Äôs see how IMAPA behaves on our simulated data.
  prefs: []
  type: TYPE_NORMAL
- en: IMAPA in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Still using *statsforecast*, we simply add the IMAPA algorithm to our pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can plot the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eec9ebe62e799ea01d7e0a8adee5522c.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting with IMAPA. In this case, it gives the same results as ADIDA. Image
    by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the figure above, we notice that both curves are overlapping, meaning
    that IMAPA and ADIDA give the same forecasts, in this case.
  prefs: []
  type: TYPE_NORMAL
- en: While this is underwhelming, keep in mind that we are using simulated data and
    we will work on a real-life dataset soon.
  prefs: []
  type: TYPE_NORMAL
- en: Before that, we have one last method to explore.
  prefs: []
  type: TYPE_NORMAL
- en: Teunter-Syntetos-Babai model (TSB)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Teunter-Syntetos-Babais model, or TSB, proposes an improvement over Croston‚Äôs
    method.
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen earlier, predictions from Croston‚Äôs method stay constant during
    period with zero values. This means that the predictions can become outdated with
    many periods of zero values.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, Croston‚Äôs method ignores the risk of obsolescence, which occurs
    when non-zero values are separated by longer and longer zero demand periods.
  prefs: []
  type: TYPE_NORMAL
- en: This is especially important in inventory management of low-demand products,
    as companies can hold stocks of unused inventory for many years, which comes at
    a cost. They must therefore assess the risk of obsolescence to determine if they
    can get rid of dead stock or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where the TSB model comes in. Instead of considering the demand interval,
    which are the periods of zero values, it will consider the demand probability,
    defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2423831eec24f52c868813379589f1c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Definition of demand probability. Image by R. Teunter, A. Syntetos, M. Babai,
    from [Intermittent demand: Linking forecasting to inventory obsolescence](https://www.sciencedirect.com/science/article/abs/pii/S0377221711004437)'
  prefs: []
  type: TYPE_NORMAL
- en: While this seems to be a small difference, it can actually have a big impact.
    With Croston‚Äôs method, the demand interval can only be updated once we observe
    a non-zero value.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the demand probability is updated at every time step, making
    the model more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make a prediction, the model also creates two series from the original series:'
  prefs: []
  type: TYPE_NORMAL
- en: One containing only non-zero values (also called **demand**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other is for the demand probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictions for each series is done using simple exponential smoothing. Then,
    the final prediction is obtained by multiplying the demand by the demand probability.
  prefs: []
  type: TYPE_NORMAL
- en: With all that in mind, let‚Äôs apply the TSB model to our simulated data.
  prefs: []
  type: TYPE_NORMAL
- en: TSB in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike the optimized version of Croston‚Äôs method, the implementation of TSB
    in *statsforecast* needs us to specify the smoothing parameter for each series.
  prefs: []
  type: TYPE_NORMAL
- en: This means that we have to manually optimize those parameters. For now, let‚Äôs
    just use 0.1 for both parameters, just to see how the model behaves on our simulated
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can plot the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1c1130c2954ecaab6e9f788974adeb58.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting with TSB. We can see how using the demand probability updates the
    prediction curve during zero-demand periods, unlike Croston‚Äôs method. Image by
    the author.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the figure above, we can see how using the demand probability makes
    a big difference, as the predictions are decreasing during no-demand periods,
    instead of being constant.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered many forecasting models for intermittent time series,
    let‚Äôs apply our knowledge in a little capstone project.
  prefs: []
  type: TYPE_NORMAL
- en: Capstone project ‚Äî Predict the power output of wind turbines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Wind turbines are a source of renewable energy, but are unfortunately unreliable,
    due to the unpredictable nature of wind.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the power output can be very large, and other times, it can be very
    small.
  prefs: []
  type: TYPE_NORMAL
- en: There can also be days where the wind is too strong, so the wind turbine shuts
    down and no power is generated. Also, there may be not enough wind, which also
    results in no power being produced.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, we can see how the power output of a wind turbine is an intermittent
    time series.
  prefs: []
  type: TYPE_NORMAL
- en: As a reminder, you can look at the full source code of this project on [GitHub](https://github.com/marcopeix/intermittent_time_series).
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start by reading our data and formatting it such that we can use *statsforecast*.
    We drop unecessary columns and format the time as a timestamp. Finally, we create
    a *unique_id* column and rename the columns appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/054601a00df30eba81ed7c8b36a8f7a6.png)'
  prefs: []
  type: TYPE_IMG
- en: First five rows of the formatted dataset. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Like that, we have our data formatted the way *statsforecast* expects it. Remember
    that the *unique_id* column is to identify different time series within the same
    dataset. In our case, we only have one series, so the *unique_id* is constant
    for all rows.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we can visualize our data. Here, we focus only on the first 200 time steps,
    as we have a fairly large dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5e1495a3f7abf727fa13cc5d683b825b.png)'
  prefs: []
  type: TYPE_IMG
- en: Power output of a wind turbine in Texas. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we can see the intermittent nature of our data. We definitely
    notice periods of zero values, and notice also very large swings between high
    power output and low power output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let‚Äôs try to forecast the power output of the wind turbine. We will consider
    three different forecast horizons:'
  prefs: []
  type: TYPE_NORMAL
- en: one hour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: one day
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: one week
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each horizon, we will use the mean absolute error (MAE) to evaluate the
    performance of each model and select the best one. Our baseline model will be
    simple exponential smoothing.
  prefs: []
  type: TYPE_NORMAL
- en: Forecast the next hour
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To test different models, we simply list them out in a Python list.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we immediately used the optimized implementation of Croston‚Äôs method to
    have the optimal values for the smoothing parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Once this is done, we can initialize the *Statsforecast* object to pass in our
    dataset, and specify the frequency of our data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Then, we run cross-validation to compare the predicted values against known
    values. Since we are forecasting the next hour, we set our horizon to 1\. Also,
    we evaluate our models over 50 predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This results in a DataFrame with predictions from each model and the actual
    values. This allows us to plot the predicted values against the real values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/cd1c233e34e83338cd7e8ebd858f9e14.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting the power output of a wind turbine for the next hour. Image by the
    author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we notice two things.
  prefs: []
  type: TYPE_NORMAL
- en: First, I did not plot the curve from IMAPA, as it gave the exact same forecast
    as ADIDA.
  prefs: []
  type: TYPE_NORMAL
- en: Second, simple exponential smoothing seems to be doing a really good job at
    forecasting the next time step, since its curve is much closer to the actual values
    than the other models.
  prefs: []
  type: TYPE_NORMAL
- en: To verify that, let‚Äôs calculate the MAE for each model and create a bar plot
    to identify the best model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7e44897792667c223d32f27675d08cf3.png)'
  prefs: []
  type: TYPE_IMG
- en: MAE of each model when forecasting the next hour. Here, SES is the top model.
    Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: With no surprise, simple exponential smoothing is the best model as it achieves
    the lowest MAE. In this situation, it seems that our baseline performs best for
    forecasting the next time step.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs see how the models behave for forecasting the next day.
  prefs: []
  type: TYPE_NORMAL
- en: Forecast the next day
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To forecast the next day, the *Statforecast* object stays the same.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we simply set the horizon to 24 hours and shift the cross-validation window
    by 24 time steps. Here, we do five rounds of cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can plot the predictions and the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b235208c80f5c64fb6432933f5449374.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting the next 24 hours of power output. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: In the figure above, we notice how our predictions are flat over the horizon,
    which is normal since each model outputs a constant value.
  prefs: []
  type: TYPE_NORMAL
- en: We can also see that the performance of simple exponential smoothing quickly
    degraded when forecasting on a longer horizon. Clearly, periods with zero values
    are not handled well by simple exponential smoothing.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating each model using the MAE gives the following result.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ed8c06d96122a2fa73cdec1b2208eef2.png)'
  prefs: []
  type: TYPE_IMG
- en: MAE for each model when forecasting the next day. Here, Croston is the best
    model. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we see that the optimized Croston‚Äôs method is the best
    performing model, achieving the lowest MAE. We also that simple exponential smoothing,
    when forecasting on a longer horizon, performs worse than Croston and TSB.
  prefs: []
  type: TYPE_NORMAL
- en: Also, keep in mind that since we increased our forecast horizon, the errors
    also increase, which is to be expected. The further we forecast into the future,
    the more likely we will be far from the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let‚Äôs set the horizon for a week.
  prefs: []
  type: TYPE_NORMAL
- en: Forecast the next week
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To forecast the next week, we set our horizon to 168 time steps, since there
    are 168 hours in a week, and we have hourly data
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Again, we can plot the predictions of each model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c07c92a5d70a59825551a8a7cf29455d.png)'
  prefs: []
  type: TYPE_IMG
- en: Forecasting the power output for next week. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The figure above is a bit underwhelming, as we can clearly see that are models
    are very far from the actual values. This is to be expected since our horizon
    is fairly long.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating our models gives the following result.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f60227eec9810af06cb5ec38d09580c.png)'
  prefs: []
  type: TYPE_IMG
- en: MAE for each model when forecasting the next week. Again, Croston is the best
    model. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: From the figure above, we again see that Croston‚Äôs method is the best model
    as it achieves the lowest MAE.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, we also notice that the MAE did not increase significantly compared
    to forecasting the next day, even though the horizon is the seven times longer.
  prefs: []
  type: TYPE_NORMAL
- en: Still, in practice, I doubt that forecasting a constant value over a week is
    really going to help make a decision or plan for the future.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen how intermittent time series pose an interesting forecasting challenge,
    as traditional models do not handle periods of zero values very well.
  prefs: []
  type: TYPE_NORMAL
- en: We explored different forecasting models, like Croston‚Äôs method, ADIDA, IMAPA
    and TSB, each bringing a new approach to predicting sparse time series.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations on making it to the end and thank you so much for reading! I
    hope that you enjoyed and that your learned something new!
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking to master time series forecasting? The check out [Applied
    Time Series Forecasting in Python](https://www.datasciencewithmarco.com/offers/zTAs2hi6/checkout?coupon_code=ATSFP10).
    This is the only course that uses Python to implement statistical, deep learning
    and state-of-the-art models in 15 guided hands-on projects.
  prefs: []
  type: TYPE_NORMAL
- en: Cheers üçª
  prefs: []
  type: TYPE_NORMAL
- en: Support me
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enjoying my work? Show your support with [Buy me a coffee](http://buymeacoffee.com/dswm),
    a simple way for you to encourage me, and I get to enjoy a cup of coffee! If you
    feel like it, just click the button below üëá
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/7ad9438bd50b1698fdd722fa6661b16c.png)](http://buymeacoffee.com/dswm)'
  prefs: []
  type: TYPE_NORMAL
