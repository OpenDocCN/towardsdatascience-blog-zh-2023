# 超越 NeRFs（第二部分）

> 原文：[https://towardsdatascience.com/beyond-nerfs-part-two-83af2bd17d0](https://towardsdatascience.com/beyond-nerfs-part-two-83af2bd17d0)

## 成功使用 NeRFs 的技巧和窍门

[](https://wolfecameron.medium.com/?source=post_page-----83af2bd17d0--------------------------------)[![Cameron R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----83af2bd17d0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----83af2bd17d0--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----83af2bd17d0--------------------------------) [Cameron R. Wolfe 博士](https://wolfecameron.medium.com/?source=post_page-----83af2bd17d0--------------------------------)

·发表于 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----83af2bd17d0--------------------------------) ·阅读时长 16 分钟·2023年6月13日

--

![](../Images/84d3b26f3db9121dd04bc299b88a98e0.png)

（照片由 [Ashim D’Silva](https://unsplash.com/@randomlies?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 提供，来源于 [Unsplash](https://unsplash.com/s/photos/wild-west?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）

在 3D 场景的表示和渲染领域，神经辐射场（NeRFs）在准确性上取得了巨大的突破。给定几个基础场景的图像，NeRFs 可以从任意视角重建高分辨率的 2D 渲染图像。与先前的技术如 [局部光场融合（LLFF）](https://cameronrwolfe.substack.com/p/local-light-field-fusion) [5] 和 [场景表示网络（SRNs）](https://cameronrwolfe.substack.com/p/scene-representation-networks) [6] 相比，NeRFs 更能够捕捉场景外观和几何结构的复杂组件（例如，视角依赖的反射和复杂的材料）。

NeRFs 具有颠覆虚拟现实、计算机图形学等应用的潜力。例如，可以设想使用 NeRFs 来重建正在出售的房子的 3D 渲染图像，前提是提供了该房子的在线图像，甚至可以使用基于现实场景训练的 NeRFs 设计视频游戏环境。然而，在其原始形式中，NeRFs 大多是在简单、受控的环境中进行评估的。当对现实世界场景的图像进行训练时，NeRFs 的表现往往不如预期（见下文），这使得它们在实际应用中的实用性降低。

![](../Images/c8ab7a99a383caaa1cf72a5ae255c55a.png)

（来自 [2]）

在本概述中，我们将深入研究 NeRF，以更好地理解它们在现实世界中表现不佳的原因以及如何解决这个问题。特别是，我们将探讨一些最近的提议，如 NeRF-W [1] 和 def-NeRF [2]，这些提议修改了 NeRF，以更好地处理在不受控的噪声环境中拍摄的图像。这些技术通过使 NeRF 能够应用于与大多数实际应用中遇到的数据更接近的图像，从而使 NeRF 更加有用。

![](../Images/6a47569552b85a66235aa90fde0ae29c.png)

（来自 [1, 2]）

# 背景

本概述是我们关于 3D 形状和场景的深度学习系列的一部分。如果你还没有阅读过，我建议阅读这个系列中的 [先前帖子](https://cameronrwolfe.substack.com/i/100102968/related-posts)，因为它们包含了大量关于 NeRF 和相关技术的有用背景信息。在这里，我们将简要概述 NeRF 和一些其他相关概念（例如，潜在空间、非刚性变形、位置编码等），这些概念将在我们讨论 NeRF-W [1] 和 def-NeRF [2] 时出现。

## NeRF 的简要概述

在之前的概述中，我们已经深入讨论了神经辐射场（NeRFS）[3] 的概念。鉴于本概述探讨了扩展和修改 NeRF 以用于现实世界应用，我建议阅读 NeRF 的概述 [这里](https://cameronrwolfe.substack.com/p/understanding-nerfs)。

**快速概览。** 要重述 NeRF 的基本理念，它们只是 [前馈神经网络](https://cameronrwolfe.substack.com/i/94634004/feed-forward-neural-networks)，接受 3D 坐标和视角方向作为输入，并生成体积密度和 RGB 颜色作为输出。通过在 3D 空间的不同点（和视角方向）上评估 NeRF，我们可以积累大量关于场景几何和外观的信息，这些信息可以用来渲染该场景的图像（或视图）；见下文。

![](../Images/88182a1c4ca8fc497e64aea572d9496c.png)

（来自 [3]）

要训练 NeRF，我们只需积累几个场景的图像和每张图像的相关 [相机姿态信息](https://cameronrwolfe.substack.com/i/97472888/background)。然后，我们可以使用这些图像作为目标来训练我们的 NeRF！特别是，我们反复 *i)* 使用 NeRF 在已知视点处渲染图像，*ii)* 使用光度损失函数（即测量 RGB 像素值之间的差异）将 NeRF 的输出与实际图像进行比较；见下文。

![](../Images/6c82a1fb388d13c6afc9f4c656ef5a77.png)

（来自 [3]）

**NeRFs的问题**。NeRFs在3D场景表示领域是一个重大突破，但它们也有一些局限性。在一个[前期概述](https://cameronrwolfe.substack.com/p/beyond-nerfs-part-one)中，我们讨论了训练和渲染NeRFs的计算负担，以及它们对场景的多张图片的需求。然而，像InstantNGP [7]和PixelNeRF [8]这样的技术大幅提高了NeRFs的计算和样本效率。

更进一步，NeRFs假设场景是静态的。实际上，这一假设往往不成立。图像可能包含移动的物体（例如人），这些物体会遮挡场景中的相关部分，甚至可能是在一天的不同时间拍摄的（例如在晚上或早晨）。这些是场景的瞬时成分，可能在一张图像中存在，而在另一张图像中不存在。

> “NeRF的中心限制……是它假设世界在几何、材料和光度上都是静态的。NeRF要求任何在相同位置和方向下拍摄的两张照片必须是相同的。这一假设在许多现实世界的数据集中是被违背的。” *— 引自 [1]*

这一静态假设是NeRF在不受控制的环境中表现不佳的一个重要因素。在本概述中，我们将探讨如何减轻这一假设，使NeRFs能够在我们在实际应用中遇到的不完美现实世界数据集上进行训练。

## 形状变形入门

为了成功地在嘈杂的智能手机图像上训练NeRFs，最近的技术将NeRFs与可学习的变形场结合在一起。然而，要理解这意味着什么，我们需要了解一般的变形。我们将简要介绍这一概念。

简单来说，变形描述了初始几何形状到最终几何形状的转变（例如，通过相对于某个[参考系](https://isaacphysics.org/concepts/cp_frame_reference?stage=all)的位移、平移或形态变换）。我们通常会遇到两种基本类型的变形：

1.  刚性变形

1.  非刚性变形

对于刚性变形（例如旋转和平移），变形的对象相对于外部参考系发生变化，但相对于内部参考系则保持不变。下面的图片中提供了相关示例。

![](../Images/5ad25b320d5edc3f1aa50a826c5d13ce.png)

刚性变形的示例（来自 sci.sdsu.edu）

非刚性变形略有不同。物体相对于内部和外部参考系都会发生变化。因此，非刚性变形可以捕捉到像膨胀和剪切这样的变换；见下文。

![](../Images/ba37d08698e69bd16c1a871ed046cf91.png)

非刚性变形的示例（来自 sci.sdsu.edu）

**变形场。** 变形场是一种表示变形的方法。它通过对3D空间中的点进行映射来定义一个变换（即，每个空间中的点被映射到一个新点）。通过根据该场定义的映射重新定位/变换物体，我们可以任意变换物体的形状，类似于上面显示的变形。

## 其他资源

除了上述讨论，还有一些概念可能会提供对本文内容的更深刻理解。请查看下面的链接以获取相关资源：

+   潜在空间是什么？ [[link](https://www.baeldung.com/cs/dl-latent-space)]

+   位置编码简介 [[link](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)]

+   体积渲染 [[link](https://www.heavy.ai/technical-glossary/volume-rendering)]

# 发表物

尽管NeRF在受控环境中效果良好，但它们在渲染从现实世界中捕获的图像的3D场景时遇到困难。在这里，我们将概述两种最近提出的方法，称为NeRF-W [1]和def-NeRF [2]，它们试图解决这一问题。这些方法可以从一组捕捉不完美的照片（例如，手机拍摄）中渲染出准确的3D场景，甚至包含剧烈的光照变化或遮挡物体！

## [NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections](https://arxiv.org/abs/2008.02268) [1]

![](../Images/a971ab584fb7f06926f532d3fe104ebd.png)

（来源 [1]）

现实世界中的图像往往具有许多不希望出现的特性，这使得训练NeRF变得相当困难。例如，考虑尝试训练一个NeRF，使用几年前拍摄的多个重要地标图像；见上图。这些场景的图像可能在不同的时间（夜晚或白天）拍摄，并且包含任何数量的移动人员或物体，这些人员或物体实际上并不是场景几何的一部分！

在不受控制的情况下，由于NeRF的假设是场景是静态的，这使得其在实际应用中往往失败。NeRF-W [1] —— NeRF的扩展 —— 通过放宽NeRF所做的静态假设来缓解这些问题，从而允许在常见的现实问题（例如瞬态对象和光照变化）下准确建模3D场景。

![](../Images/4191703746567fac7b8b3418b6f9532c.png)

（来源 [1]）

**分解场景。** NeRF在实际应用中遇到的主要问题可以大致分类如下：

1.  *光度变化：* 一天中的时间和大气条件影响场景的光照/辐射。

1.  *瞬态对象：* 现实世界的场景很少被孤立地捕捉。通常会有一些人或物体在拍摄过程中遮挡或移动。

上述图中说明了这些问题，这些问题都是对静态假设的违反。

**光度变化。** 为了解决光度变化问题，每张图片都会被分配一个“外观”向量，NeRF-W在预测输出RGB颜色时会将其视为（额外输入）。然而，外观嵌入对预测的体积密度没有影响，体积密度捕捉了场景的3D几何形状。这个改变仅通过将NeRF的前馈网络分离为几个接受不同输入的组件来实现；详见下文。

![](../Images/cc109e5a629cbdeb3af944f0adf5712a.png)

外观嵌入影响颜色但不影响体积密度（来自[1]）。

通过将NeRF-W的RGB输出与此外观嵌入条件化，模型可以基于特定图像改变场景的外观，同时确保场景的基本几何形状对外观是不变的，并且在图像之间共享。分配给每张训练图像的独特外观嵌入在训练过程中与模型参数一起优化。

**静态与瞬态组件。** 为了处理瞬态对象，我们应注意场景包含两种类型的实体：

+   图像依赖组件（即移动/瞬态对象）

+   共享组件（即实际场景）

NeRF-W使用独立的前馈网络组件来建模图像依赖（瞬态）和共享（静态）场景组件。网络的瞬态部分和静态部分分别输出它们自己的颜色和密度估计，这使得NeRF-W能够分离场景的静态和瞬态组件；详见下文。

![](../Images/b05768b6cdbb48d70989b5dc18e66737.png)

NeRF-W的静态和瞬态组件（来自[1]）

NeRF-W的瞬态部分发出一个不确定性场（使用贝叶斯学习框架[4]），允许在训练过程中忽略被遮挡的场景组件。为了确保瞬态效果依赖于图像，每张训练图像都与一个“瞬态”嵌入向量相关联，该向量作为输入提供给NeRF-W的瞬态组件。与外观嵌入类似，瞬态嵌入在训练过程中被学习。见下文以获得NeRF-W架构的完整描述。

![](../Images/de0532dd247f1137f1dce665d9ad52c0.png)

（来自[1]）

NeRF-W的所有组件都通过类似于NeRF [3]的程序进行联合优化，具体描述可以在[此处](https://cameronrwolfe.substack.com/p/understanding-nerfs#%C2%A7modeling-nerfs)找到。NeRF-W使用真实世界中著名地标的照片集合进行评估，这些照片从[Photo Tourism dataset](http://phototour.cs.washington.edu/datasets/)中选取。当NeRF-W被训练以表示六个地标时，我们看到NeRF-W在大多数情况下在定量上优于基线；详见下文。

![](../Images/05e119f300b13901ef597ec64a871e49.png)

（来自[1]）

我们应该回顾一下，为了进行评估，我们：

1.  在对应于单个场景的图像上训练模型。

1.  采样一个保留测试图像（及其对应的相机姿态）。

1.  使用来自保留图像的相机姿态信息渲染一个视点（使用训练好的模型）。

1.  将渲染图像与真实图像进行比较。

对于NeRF-W，我们没有测试图像的外观或瞬态嵌入。因此，NeRF-W基于测试图像的一半优化这些嵌入，并在另一半图像上进行评估；见下文。

![](../Images/a8188c9c47ad277928edd82795bbbe81.png)

（来自[1]）

当我们检查不同NeRF变体的输出时，我们发现NeRF的输出往往包含由于训练图像中的瞬态物体而产生的鬼影伪影。相比之下，NeRF-W生成的渲染图像清晰准确，表明它更能处理现实世界中场景外观的变化；见下文。

![](../Images/877a1093e345c693798e829bde25e1c4.png)

（来自[1]）

此外，NeRF-W可以根据不同光照条件的训练图像生成准确的场景渲染。考虑到NeRF-W能够根据不同的外观嵌入生成输出，我们可以调整NeRF-W的外观嵌入以修改最终渲染的外观；见下文。

![](../Images/a37f6b3eeed2bda8022f135660f8cbd9.png)

（来自[1]）

进一步推进这一理念，我们甚至可以在不同训练图像的外观嵌入之间进行插值，从而实现渲染场景外观的平滑变化；见下文。

![](../Images/5068204217d0160271cc5474393b961e.png)

（来自[1]）

## [Nerfies: 变形神经辐射场](https://arxiv.org/abs/2011.12948) [2]

![](../Images/381faf50b33a9ad8fd0d8b09484bda3c.png)

（来自[2]）

现代应用的大多数计算机视觉数据都是通过智能手机捕捉的。考虑到这一点，人们可能会想是否可以使用这些数据训练NeRF。在[2]中，作者探讨了沿这些思路的具体应用：*将随意捕捉的“自拍”图像/视频转换为能够生成真实感渲染的NeRF*。作者将这些模型称为“NeRFies”（即基于NeRF的自拍）！

最初，这个应用可能看起来相当具体且无用。*我们真的那么在意调整自拍角度吗？这能让我们的Instagram帖子更具美感吗？* 然而，[2]中提出的方法在几个方面都非常有洞察力：

1.  它让我们了解了使用智能手机图像和视频训练NeRF的可行性。

1.  它提高了NeRF处理场景中具有挑战性、细节丰富或捕捉不完美材料的能力。

1.  它不仅适用于捕捉自画像，还可以应用于更一般的场景建模应用。

使用 [2] 中提出的技术，我们可以在给定噪声和不完美的手机拍摄图像的情况下生成高质量的场景表示。举个例子，想象一下仅通过在手机上拍摄一个快速视频来生成你自己的 3D 模型。目前的相关方法需要整个专门的实验室，配备同步的灯光和相机！

**NeRFs + 变形场**。当我们考虑使用手持相机来构建一个人的 3D 模型时，会想到一些可能的困难：

+   相机将会移动（这违反了静态假设！）。

+   人类包含许多复杂的几何形状和材料，这些是难以建模的（例如，头发、眼镜、珠宝等）。

在 [2] 中，作者通过用一个共同优化的非刚性变形场来增强 NeRF，解决了这些挑战，该变形场学习在 3D 空间中变换场景的底层几何形状。

![](../Images/43b46e16aba5b3137524ed0e71a3fac4.png)

使用变形场变换坐标（来自 [2]）

这个变形场通过一个 [前馈网络](https://cameronrwolfe.substack.com/i/94634004/feed-forward-neural-networks)建模，该网络接受位置编码的 3D 坐标和每张图像的潜在变形代码作为输入，然后生成一个非刚性变形的 3D 坐标作为输出；见上文。

**def-NeRF 的工作原理**。在 [2] 中的方法论，我们称之为可变形神经辐射场（def-NeRF），包含两个组件：

1.  *变形场*：使用前馈神经网络建模 3D 坐标的非刚性变形。

1.  *NeRF*：使用原始的 NeRF 架构来创建底层场景几何形状和外观的模板。

我们将每张训练图像与可学习的变形和外观向量关联。这些潜在代码模拟了 NeRF-W [1] 中使用的每图像嵌入方法，使得变形和外观依赖于图像，从而使 def-NeRF 能够处理场景图像中的变异（例如，光照变化）。

![](../Images/e7e47a6a32e3b7bb8fa4d99697e79f07.png)

(来自 [2])

def-NeRF 接受 3D 坐标作为输入。这个坐标经过位置编码，并与潜在的变形代码（通过加法）结合，然后传递给建模 def-NeRF 变形场的前馈网络。这个网络的输出是一个变换后的 3D 坐标；见上文。

![](../Images/0b3ff1c04ef38a092a23103806589d1f.png)

(来自 [2])

这个变换后的坐标作为输入传递给 NeRF。类似于 NeRF-W [1]，我们用一个每张图像的、可学习的外观向量来增强这个 NeRF。给定变换后的坐标、观察方向和一个外观向量作为输入，NeRF 输出一个体积密度和 RGB 颜色；见上文。

![](../Images/c3d8049d21e17a25908d61ba4e5d8c0b.png)

(来自 [2])

上述的完整 def-NeRF 架构与原始 NeRF 的 [架构和训练策略](https://cameronrwolfe.substack.com/i/97915766/modeling-nerfs) 几乎相同。主要区别是：

+   变形场的建模。

+   每图像变形和外观向量的使用。

> “在渲染时，我们简单地在观察帧中投射光线并采样点，然后使用变形场将采样点映射到模板。” *— 来自 [2]*

![](../Images/70ebd9f6d2ede2b208953ad5b62e43a1.png)

（来自 [2]）

**为什么这是必要的？** def-NeRF 仅在主要的 NeRF 架构上添加了一个变形场，该变形场以非刚性方式变形输入坐标。因此，这种方法将场景表示分解为两部分：

1.  场景的几何模型。

1.  将这种几何形状变形为期望的视角。

因此，def-NeRF 解除 NeRF 的静态假设，允许在对位移、平移、视角变化等不变的情况下学习基础场景几何。

![](../Images/23cb63f6742ecee5901df78b76de65d2.png)

添加的正则化提高了重建质量（来自 [2]）

**正则化。** [2] 中的作者观察到学习到的变形场容易陷入局部最小值和过拟合。作为解决方案，我们可以在 def-NeRF 的优化过程中添加额外的正则化；详见上述。采用了几种不同的正则化方案，如 [2] 第 3.3–3.5 节所述。

**效果好吗？** def-NeRF 主要基于其生成 “Nerfies” （即从任意视角拍摄的逼真渲染图）的能力进行评估。为了创建 Nerfie，用户使用智能手机拍摄他们的脸大约 20 秒。然后，def-NeRF 方法在这些数据上进行训练，并用于从各种新颖的视角渲染自拍。

![](../Images/f3470aa24b0d545ac5f92eb492c416db.png)

（来自 [2]）

为了评估从新视角生成的这些场景重建的质量，作者构建了一个相机装置，同时从多个视角捕捉对象。这允许使用捕捉同一确切场景的两种不同视角的图像构建验证集；详见上述。

![](../Images/f19e6985a5a71db532ff9c80d6536515.png)

（来自 [2]）

当与各种基线进行定量比较时，def-NeRF 在大多数情况下能够生成更高质量的对象重建。值得注意的是，def-NeRF 似乎在处理 [PSNR metric](https://www.mathworks.com/help/vision/ref/psnr.html) 时遇到困难。然而，作者声称该指标偏向模糊图像，不适合评估场景重建。

![](../Images/2a968d151f94faf7ffdac431d3e7129d.png)

（来自 [2]）

定性地，我们看到相较于基线，def-NeRF 更能够捕捉场景中的细节（例如头发、衬衫褶皱、眼镜等）；见上文。此外，该方法适用于一般场景，超越了在 NeRFie 中重建人类主体的范围。总体而言，def-NeRF 在给定手机图像的情况下似乎能够提供高质量的场景重建！

![](../Images/f133741062ab23b6cc955ae6a5f3ded6.png)

（摘自 [2]）

# 主要收获

尽管 NeRFs（神经辐射场）展示了令人印象深刻的演示效果，但除非我们能将它们应用于现实世界中的图像，否则它们的实际用途有限。在本综述中，我们强调了在实际应用中使用 NeRFs 的主要困难（即静态假设），并概述了一些旨在解决这一问题的近期研究。以下是一些主要的收获。

**静态假设**。NeRFs 在其原始形式中假设场景是静态的，这意味着从相同位置/方向拍摄的两个场景图像必须是相同的。在实际操作中，这一假设很少成立！人或物体可能在场景中移动，而变化的光照条件可以显著改变图像的外观。在现实世界中部署 NeRFs 需要显著放宽这一假设。

**图像依赖的嵌入**。现实世界中的场景可以分为图像独立和图像依赖的组件。如果我们希望学习场景的基础几何而不对图像依赖的组件进行过拟合，我们必须根据每张图像定制 NeRF 的输出。对于 NeRF-W 和 def-NeRF，这主要通过添加每图像嵌入向量（即外观、瞬态和变形向量）来实现。然而，未见过/测试图像的每图像嵌入向量的缺乏可能使得这些模型的部署更加困难。

**局限性**。允许 NeRFs 超越受控环境的应用是重要的，但这并不是 NeRFs 唯一的局限性！这些模型仍然面临着样本效率低和计算复杂性高的问题，正如 [之前的文章](https://cameronrwolfe.substack.com/p/beyond-nerfs-part-one)中讨论的那样。使 NeRFs 适用于实时应用将需要结合解决 NeRFs 每个个别问题的技术。

## 结语

非常感谢您阅读本文。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/) 的 AI 主管。我研究深度学习的经验和理论基础。您还可以查看我在 medium 上的 [其他文章](https://medium.com/@wolfecameron)！如果您喜欢这篇文章，请在 [twitter](https://twitter.com/cwolferesearch) 上关注我或订阅我的 [Deep (Learning) Focus 新闻通讯](https://cameronrwolfe.substack.com/)，我在其中帮助读者通过对热门论文的通俗概述建立对深度学习研究主题的更深理解。

## 参考文献

[1] Martin-Brualla, Ricardo 等. “Nerf in the wild：用于无约束照片集合的神经辐射场。” *IEEE/CVF 计算机视觉与模式识别会议论文集*。2021。

[2] Park, Keunhong 等. “Nerfies：可变形神经辐射场。” *IEEE/CVF 国际计算机视觉大会论文集*。2021。

[3] Mildenhall, Ben 等. “Nerf：将场景表示为神经辐射场以进行视图合成。” *ACM 通讯* 65.1 (2021): 99–106。

[4] Kendall, Alex 和 Yarin Gal. “在计算机视觉的贝叶斯深度学习中，我们需要哪些不确定性？” *神经信息处理系统进展* 30 (2017)。

[5] Mildenhall, Ben 等. “局部光场融合：具有规范化采样指南的实用视图合成。” *ACM 图形学会论文 (TOG)* 38.4 (2019): 1–14。

[6] Sitzmann, Vincent, Michael Zollhöfer 和 Gordon Wetzstein. “场景表示网络：连续 3D 结构感知神经场景表示。” *神经信息处理系统进展* 32 (2019)。

[7] Müller, Thomas 等. “瞬时神经图形原语与多分辨率哈希编码。” *ACM 图形学会论文 (ToG)* 41.4 (2022): 1–15。

[8] Yu, Alex 等. “pixelnerf：来自一张或少量图像的神经辐射场。” *IEEE/CVF 计算机视觉与模式识别会议论文集*。2021。
