# 从基础逻辑门到深度神经网络：权威感知机教程

> 原文：[https://towardsdatascience.com/the-definitive-perceptron-guide-fd384eb93382](https://towardsdatascience.com/the-definitive-perceptron-guide-fd384eb93382)

## 朝着掌握AI的方向前进

## 数学、二分类、逻辑门等

[](https://jvision.medium.com/?source=post_page-----fd384eb93382--------------------------------)[![Joseph Robinson, Ph.D.](../Images/3117b65a4e10752724585d3457343695.png)](https://jvision.medium.com/?source=post_page-----fd384eb93382--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fd384eb93382--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fd384eb93382--------------------------------) [Joseph Robinson, Ph.D.](https://jvision.medium.com/?source=post_page-----fd384eb93382--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fd384eb93382--------------------------------) ·阅读时间21分钟·2023年4月28日

--

## TL;DR

感知机的世界令人着迷，因为这些模型是现代人工智能的基础。在这篇博客文章中，我们将简明扼要地讲述感知机的故事，从它的神经网络起源到其演变为多层感知机及更高级的模型。我们将探讨驱动这个模型的基本数学，使其能够作为二分类器、模拟计算机晶体管、乘法器和逻辑门。此外，我们还将考察感知机模型如何为更高级的分类器奠定基础，包括逻辑回归、支持向量机和深度学习。我们将提供示例代码片段和插图以增强理解。此外，我们还将使用实际案例来了解何时以及如何使用感知机模型。

本指南是任何对数据科学感兴趣的人的宝贵资源，无论其专业水平如何。我们将探讨感知机模型，这一模型自人工智能早期便存在，并且至今依然相关。我们将深入了解其历史、工作原理及与其他模型的比较。此外，我们还将构建模型和逻辑门，并提供对未来发展的见解。无论你是自学的数据科学家、AI从业者还是有经验的机器学习专业人士，你都会在这本全面的指南中找到有价值的内容。

# 目录

[1\. 介绍](#cded)

[1.1 感知机模型的简史](#3a63)

[1.2\. 感知机模型在机器学习中的重要性](#3213)

[2\. 感知机模型背后的数学](#794d)

[2.1\. 线性可分性](#84d1)

[2.2\. 感知机学习算法](#12bc)

[2.3\. 感知机收敛定理](#5e61)

[3\. 感知机模型作为二分类器](#424d)

[3.1\. 线性分类](#865e)

[3.2\. 感知器模型的局限性](#f383)

[3.3\. 感知器模型的多类分类](#d784)

[4\. 逻辑门与感知器模型](#f223)

[4.1\. 感知器如何用于生成逻辑门](#fe2d)

[4.2\. 示例：使用感知器实现NAND门](#2465)

[4.3\. 扩展到其他逻辑门：AND、OR、XOR](#1428)

[5\. 感知器用于乘法和晶体管类似功能](#fdba)

[5.1\. 感知器与晶体管的类比](#cc7c)

[5.2\. 使用感知器进行乘法](#d860)

[5.3\. 感知器的未来与硬件实现](#a2e8)

[6\. 比较感知器模型与逻辑回归](#e6c4)

[6.1\. 感知器与逻辑回归的相似性](#3b99)

[6.2\. 感知器与逻辑回归的差异](#f1c3)

[6.3\. 在感知器与逻辑回归之间的选择](#75d4)

[7\. 感知器模型的创意与独特应用](#6e58)

[7.1\. 光学字符识别（OCR）](#1fc1)

[7.2\. 音乐类型分类](#79b2)

[7.3\. 入侵检测系统](#64a0)

[7.4\. 情感分析](#518f)

[8\. 感知器模型的演变及其在深度学习中的遗产](#e342)

[8.1\. 感知器到多层感知器（MLPs）的演变](#5396)

[8.2\. 深度学习与感知器的遗产](#077c)

[8.3\. 感知器与深度学习的未来](#3762)

9\. [结论](#236b)

· [参考文献](#3a73)

· [联系方式](#2117)

# 1\. 介绍

## 1.1 感知器模型的简史

Warren McCulloch和Walter Pitts在1943年的人工神经元研究[1]启发了一位名叫Frank Rosenblatt的心理学家在1957年制造了感知器模型[2]。Rosenblatt的感知器是第一个用算法描述的神经网络（NN），为现代机器学习（ML）技术铺平了道路。发现后，感知器受到了科学家和公众的广泛关注。有些人认为这一新技术对智能机器至关重要——一个学习和改变的模型[3]。

然而，感知器的受欢迎程度并没有持续。然后，在1969年，Marvin Minsky和Seymour Papert出版了他们的书《感知器》，书中强调了感知器模型的局限性，同时揭示了它无法解决像XOR分类这样的难题[4]（第3节）。这项工作引发了对神经网络的重大兴趣丧失，转而关注其他方法。感知器的早期历程列于**图1**。

![](../Images/c2a6184cd79ca03b2ba4e583233adc83.png)

**图1\.** 感知器历史上的重要里程碑（1943–1982）。图由作者创作。

虽然花费了十多年时间，但1980年代对神经网络的兴趣得以重新点燃。部分感谢于Rumelhart、Hinton和Williams通过反向传播算法引入的多层神经网络训练[5]（第5节）。

2012年，计算能力、大数据、RELU等非线性激活以及dropout技术的重大进展促成了最全面的卷积神经网络的诞生。ImageNet提供的大型标注数据集在填充其容量方面发挥了重要作用。

![](../Images/6690b121315e96ace058902793d46ee0.png)

**图 2\.** 感知机历史上的重要里程碑（1985–1997）。图由作者绘制。

今天对深度学习的狂热由此兴起。因此，感知机模型在其基础中扮演了关键角色—**图 2**和**图 3**列出了剩余的里程碑（**图 1**的延续）。

![](../Images/864ec1ba2971d7a281ad9b4709fade39.png)

**图 3\.** 感知机历史上的重要里程碑（2006–2018）。图由作者绘制。

## 1.2\. 感知机模型在机器学习中的重要性

尽管有其局限性，感知机模型仍然是机器学习中的一个重要构建块。它是人工神经网络的基础组成部分，现在这些网络被广泛用于各种应用，从图像识别到理解人类语言。

感知机模型的简洁性使其成为新手入门机器学习的绝佳起点。它使线性分类和从数据中学习变得易于理解。此外，感知机算法可以很容易地修改以创建更复杂的模型，例如多层感知机（MLP）和支持向量机（SVM），这些模型可以在更多情况下使用，并解决许多原始感知机模型无法解决的问题。

在接下来的部分，我们将介绍感知机模型背后的数学，如何将其用作二分类器和构建逻辑门，以及如何用于执行类似计算机晶体管的乘法任务。我们还将讨论感知机模型与逻辑回归之间的区别，并展示感知机模型如何以新颖和令人兴奋的方式使用。

# 2\. 感知机模型背后的数学

## 2.1\. 线性可分性

从本质上讲，感知机模型是一个线性分类器。它旨在找到一个“超平面”（二维空间中的一条线、三维空间中的一个平面，或更高维度的类似物）来分隔两个数据类别。为了使数据集具有线性可分性，超平面必须正确地分类所有数据点[6]。

从数学上讲，感知机模型可以表示如下：

`y = f(w * x + b)`。

`x`是输入向量；`w`是权重向量；`b`是偏置项；`f`是激活函数。在感知机的情况下，激活函数是一个阶跃函数，将输出映射为1或0，表示两个类别（**图 4**）。

![](../Images/61fcc753b8ee15617e40a4b5d8b4408f.png)

**图 4\.** 单位阶跃函数的描述，包含将输出映射为0或1的分段条件。图由作者绘制。

感知机模型可以扩展到具有多个输入特征`x`，定义如下：

`y = f(w_1 * x_1 + w_1 * x_1 ... w_n * x_n + b)`。

上述方程及其输出的阶跃函数被激活（即，通过0关闭或通过1打开），如下图所示，**图5**。

![](../Images/51274211ab39f1e65f7ffa1434fe5aa8.png)

**图5.** 多变量线性分类。注意加权和通过激活函数，上述阶跃函数——来源 [link](https://pythoniseasytolearn.blogspot.com/2020/09/perceptron-mother-of-all-anns.html)。

## 2.2. 感知器学习算法

感知器学习算法是一种保持权重和偏置最新以减少分类错误的方法[2]。该算法可以总结如下：

1.  将权重和偏置初始化为小的随机值。

1.  对于每对输入输出`(x, d)`，计算预测输出`y = f(w * x + b)`。

1.  根据误差`e = d - y`更新权重和偏置：

`w = w + η * e * x`

`b = b + η * e`,

其中`η`是学习率，一个小的正数，控制更新的步长。

4. 对固定次数的迭代或直到误差收敛，重复步骤2和3。

我们可以使用Python和Sklearn快速实现上述步骤：

[PRE0]

然后，使用拟合的模型，我们可以进行如下预测：

[PRE1]

如果数据是线性可分的，[7]中的感知器学习算法保证收敛。

![](../Images/97605757fef4dfe521e0c78e13507bc8.png)

**图6.** 布尔分类，其中类别是线性可分的。图像由作者创建。

## 2.3. 感知器收敛定理

1960年，Rosenblatt证明了感知器收敛定理。该定理指出，如果数据集可以线性分隔，感知器学习算法将在有限的步骤内找到解决方案[8]。该定理表明，只要时间足够，感知器模型将找到最佳的权重和偏置，以对所有数据点进行线性分隔的分类。

但如果数据集不是线性可分的，感知器学习算法可能找不到合适的解决方案或收敛。因此，研究人员开发了更复杂的算法，如多层感知器和支持向量机，这些算法可以处理不能直线分隔的数据[9]。

# 3. 感知器模型作为二分类器

## 3.1. 线性分类

如前所述，感知器模型是一种线性分类器。它创建了一个决策边界，这是一个特征空间中的直线，用于分隔两个类别[6]。当添加新数据点时，感知器模型根据其在决策边界上的位置对其进行排序。感知器运行快速且易于使用，因为它简单，但只能解决数据可以线性分隔的问题。

## 3.2. 感知器模型的局限性

感知器模型的一个大问题是它不能处理无法用直线分隔的数据。异或问题是一些数据集无法通过单个超平面分隔的例子，这使得感知器无法找到解决方案[4]。研究人员开发了更高级的方法来绕过这个问题，例如多层感知器，它们有多个神经网络层，能够学习进行不沿直线的决策[5]。

感知器模型对学习率和初始权重的设置也很敏感。例如，如果学习率过低，收敛可能会很慢，而较大的学习率可能会导致振荡或发散。同样，初始权重的选择会影响解决方案的收敛速度以及最终效果[10]。

## 3.3\. 感知器模型的多类分类

尽管基本的感知器模型是为两类问题设计的，但通过训练多个感知器分类器（每个类别一个），它可以解决多于两类的问题[11]。最常见的方法是“一对多（OvA）”，其中训练一个单独的感知器来区分各类。然后，在分类新数据点时，选择输出值最高的感知器作为预测类别。

另一种方法是“一对一（OvO）”方法，其中对每对类别训练一个感知器。最终的分类决策是通过投票机制做出的，每个感知器对其预测的类别进行投票，票数最多的类别被选择。虽然OvO需要训练比OvA更多的分类器，但每个感知器只需要处理数据的一个较小子集，这对大型数据集或高计算复杂度的问题可能更有利。

# 4\. 逻辑门与感知器模型

## 4.1\. 感知器如何用于生成逻辑门

感知器模型可以用来表示逻辑门，这些逻辑门是数字电路的最基本组成部分。通过适当调整感知器的权重和偏置，它可以被训练执行逻辑操作，如与（AND）、或（OR）和非（NOT）[12]。感知器与逻辑门之间的联系表明，神经网络不仅可以进行计算，还具有模拟复杂系统的潜力。

![](../Images/f6c507183d7f02a8bad4b768a95b44cd.png)

**图 6\.** 线性可分逻辑门：**与（AND）** 和 **或（OR）**（分别为左侧和中间）。另一方面，**异或（XOR）** 不能通过单一线性分类器（右侧）进行分离，但可以通过两层网络进行分离（稍后会详细介绍）——该图由作者创建。

## 4.2\. 示例：使用感知器实现 NAND 门

NAND 门是一个基本的逻辑门，只有当两个输入都为 1 时，输出才为 0，在其他情况下输出为 1。NAND 门的真值表如下：

![](../Images/c92423d759617e15d8d93502f11b33ad.png)

NAND 门真值表。表格由作者创建。

要使用感知器实现 NAND 门，我们可以手动设置权重和偏置，或使用感知器学习算法来训练感知器。以下是可能的权重和偏置配置：

`w1 = -1`；

`w2 = -1`；

`b = 1.5`。

使用这些参数，感知器可以表示为：

`y = f((-1 * A) + (-1 * B) + 1.5)`。

![](../Images/64348e4b15a4774b35b293f756e5225c.png)

**图 6\.** 训练数据、图形表示以及 AND 门的线性函数。图由作者创建。

在这里，`f` 是步进函数，`A` 和 `B` 是输入。如果使用真值表中的值测试此设置，你将从 NAND 门获得正确的结果：

![](../Images/eff8348e1a6f6841628032dd6544e48a.png)

**图 7.** 逻辑 NAND 的真值表，以及上述训练的感知器的输出和作者创建的结果。

在 Python 中，NAND 可以如下实现：

[PRE2]

正如预期的那样，重现上述总结 NAND 门的表格

[PRE3]

NAND 门可以用于构建所有其他门，因为它在功能上是完整的，这意味着任何其他逻辑函数都可以仅使用 NAND 门来推导。以下是如何使用 NAND 门创建一些基本门的简要说明：

1.  NOT 门：将 NAND 门的两个输入连接到输入值。

1.  AND 门：首先创建一个 NAND 门，然后将输出通过一个 NOT 门。

1.  OR 门：在将每个输入馈送到 NAND 门之前，对每个输入应用 NOT 门。

要创建一个接受任意数量输入的 NAND 门，可以使用 Python 定义一个函数，该函数接受一个输入列表并返回 NAND 输出。以下是演示此操作的代码片段：

[PRE4]

该函数使用一个辅助函数（即`and_gate`）来创建一个具有两个或更多输入的 NAND 门。然后在给定的输入上重复 AND 操作。最终结果是 NAND 门的输出，具有任意数量的输入位，即 AND 门的取反值。

## 4.3\. 扩展到其他逻辑门：AND、OR、XOR

类似地，感知器可以建模其他逻辑门，如 AND、OR 和 NOT。例如，具有权重 `w1 = 1`、`w2 = 1` 和 `b = -1.5` 的感知器可以表示一个 AND 门。

[PRE5]

再次，输出模仿预期的 AND 门。

[PRE6]

然而，单个感知器无法建模 XOR 门，因为 XOR 门不是线性可分的。相反，必须使用多层感知器或感知器组合来解决 XOR 问题[5]。

# 5\. 用于乘法和类似晶体管功能的感知器

## 5.1\. 感知器与晶体管之间的类比

晶体管是电子设备的基本构建块。它们负责执行像加法和乘法这样的简单任务。有趣的是，感知器也可以被视为展示类似功能的计算单元。例如，感知器在机器学习和人工神经元中被使用。相比之下，晶体管是物理部件，改变电信号的流动 [13]。尽管如此，正如上一节所示，这两种系统都可以建模和执行逻辑运算。

## 5.2\. 使用感知器进行乘法运算

我们可以利用感知器的二进制运算能力来执行乘法。例如，考虑两个二进制位（即`A`和`B`）的展开，可以将其表示为一个简单的AND门。正如第4节所示，AND门可以用感知器建模。

但是，对于涉及多个二进制位的更复杂的乘法任务，我们需要添加更多的部件，如半加器和全加器，这些部件需要逻辑门的组合 [14]。使用感知器来构建这些部件使得构建可以执行二进制乘法的人工神经网络成为可能。

例如，假设我们要乘以两个2位的二进制数，`A1A0` 和 `B1B0`。那么，我们可以将乘法分解为一系列的AND运算和加法：

1.  计算部分乘积：`P00 = A0 * B0`、`P01 = A0 * B1`、`P10 = A1 * B0` 和 `P11 = A1 * B1`。

1.  使用半加器和全加器将部分乘积相加，得到一个4位的二进制乘积。

每个AND运算和加法都可以通过感知器或表示所需逻辑门的感知器组来完成。

使用上一节中设置的AND门函数，我们可以在Python中实现基于感知器的乘法：

[PRE7]

## 5.3\. 感知器及其硬件实现的未来

尽管感知器可以像晶体管一样执行基本的数学运算，但其硬件实现的效率不如传统晶体管。然而，近期在神经形态计算方面的改进表明，可能有办法制造类似于神经网络的硬件，如感知器 [15]。这些神经形态芯片可能有助于机器学习任务减少能源消耗，并开启对计算机新思维方式的探索。

# 6\. 感知器模型与逻辑回归的比较

## 6.1\. 感知器与逻辑回归的相似性

感知器模型和逻辑回归都是线性分类器，可以用来解决二分类问题。它们都依赖于找到一个决策边界（一个超平面），以在特征空间中分隔不同的类别 [6]。此外，它们还可以通过一对多和一对一等技术扩展以处理多分类问题 [11]。

让我们来看一下Python实现的区别：

[PRE8]

[PRE9]

这将输出：

[PRE10]

## 6.2\. 感知器与逻辑回归的区别

尽管感知器模型和逻辑回归有一些相似之处，但两者之间存在一些本质区别：

1.  激活函数：感知器模型使用阶跃函数作为其激活函数，而逻辑回归使用逻辑（Sigmoid）函数[10]。这种差异导致感知器具有二元输出（`0` 或 `1`）。与此同时，逻辑回归生成一个概率值（介于0和1之间），表示实例属于特定类别的可能性。

1.  损失函数：感知器学习算法最小化误分类错误，而逻辑回归最小化对数似然或交叉熵损失[16]。这种区别使逻辑回归对数据集中的噪声和异常值更具鲁棒性，因为它考虑了错误的幅度，而不仅仅是误分类实例的数量。

1.  收敛性：感知器学习算法在数据线性可分时可以收敛，但在其他情况下可能无法收敛[7]。另一方面，逻辑回归使用基于梯度的优化技术，如梯度下降或牛顿-拉夫森方法，这些方法能够保证在对数似然等凸损失函数中找到全局最优解[17]。

1.  非线性可分数据：尽管感知器模型在处理非线性可分数据时会遇到困难，但逻辑回归可以通过引入高阶多项式特征或使用核方法来扩展处理非线性决策边界[18]。

## 6.3\. 选择感知器与逻辑回归

感知器模型和逻辑回归的选择取决于问题和数据集。逻辑回归更可靠，可以处理更广泛的问题，因为它基于概率并且可以建模非线性决策边界。然而，在某些情况下，特别是处理可以线性分离的数据时，感知器模型可能更易于使用且计算资源消耗更少。

# 7\. 感知器模型的创造性和独特应用

## 7.1\. 光学字符识别（OCR）

感知器模型已被应用于光学字符识别（OCR）任务，其目标是识别并将打印或手写文本转换为机器编码文本[19]。感知器或其他机器学习算法通常用于OCR任务，以预处理将被读取的图像，从中提取特征并进行分类。感知器模型对于字符可以通过直线分离的OCR任务是一个不错的选择，因为它易于使用且与计算机配合良好。

## 7.2\. 音乐类型分类

感知机也可以用于音乐流派分类，这涉及识别给定音频轨迹的流派。可以训练感知机模型将音频分类为已设置的流派 [20]。这通过提取音频信号的相关部分，如频谱特征或时间特征，然后将其组合起来来完成。尽管深度学习和卷积神经网络等更先进的方法通常能提供更好的结果，但感知机模型仍能很好地工作，特别是在只有少数几个流派或特征可以线性分离的情况下。

## 7.3\. 入侵检测系统

入侵检测系统，或称为IDS，广泛用于网络安全中，以查找恶意行为或未经授权的访问计算机网络。IDS可以使用感知机作为分类器，通过查看数据包大小、协议类型和网络流量连接长度来确定活动是常规的还是恶意的 [21]。支持向量机和深度学习可能更擅长检测，但感知机模型可以用于简单的IDS任务或作为比较点。

## 7.4\. 情感分析

感知机可以应用于情感分析，这是一个自然语言处理任务，旨在确定文本中表达的情感（例如，正面、负面或中性）。通过将文本转换为数值特征向量，如词频-逆文档频率（TF-IDF）表示 [22]，可以训练感知机模型根据其语气分类文本。尽管更先进的技术如递归神经网络或变换器在情感分析性能上已经超越了感知机，但感知机仍然可以作为文本分类的入门方法或特定用例的简单替代方案。

# 8\. 感知机模型的演变及其在深度学习中的遗产

## 8.1\. 感知机到多层感知机（MLPs）的演变

感知机模型已经能够解决具有明确决策边界的问题，但在需要明确决策边界的任务中仍存在困难。多层感知机（MLPs）的引入，包含多个感知机样单位的层，标志着人工神经网络的显著进步 [5]。MLPs可以逼近任何连续函数，只要具有足够数量的隐藏层和神经元 [23]。通过采用反向传播算法，MLPs可以训练以解决更复杂的任务，例如XOR问题，这是单个感知机无法解决的。

## 8.2\. 深度学习与感知机的遗产

感知机模型奠定了深度学习的基础，深度学习是机器学习的一个子领域，专注于具有多层（深度神经网络）的神经网络。感知机模型是卷积神经网络（CNNs）和递归神经网络（RNNs）等深度学习技术的基础，这些技术在图像分类、自然语言处理和语音识别等任务中达到了**最先进的**性能 [24]。

在 CNNs 中，来自感知器的加权输入信号和激活函数的思想被传递到卷积层。这些层通过对输入区域应用滤波器来学习数据中的空间层次结构。同样，RNNs 通过添加递归连接来建立在感知器模型的基础上。这使得网络能够学习序列数据中的时间依赖关系 [25]。

![](../Images/acbfdb72a70289f1aa6ad8468c4c25b1.png)

深度学习与其他模型的对比：Google 趋势随时间变化。图片由作者根据 [Carrie Fowle](https://medium.com/u/3b0511e6a8d3?source=post_page-----fd384eb93382--------------------------------)’s TDS Medium 博客 ([link](/using-google-trends-at-scale-1c8b902b6bfa)) 制作。

## 8.3\. 感知器与深度学习的未来

尽管基础，更多复杂的深度学习技术已经主要取代了感知器模型。然而，它仍然对机器学习有价值，因为它是一种简单而有效的方式来教授神经网络的基础知识，并为构建更复杂的模型提供了思路。随着深度学习的不断进步，感知器模型的核心思想和原则可能仍会保持不变，并影响新架构和算法的设计。

# 9\. 结论

本博客全面探讨了感知器模型及其数学、二元分类和逻辑门生成应用。通过理解这些基础知识，我们已经解锁了在各种实际应用中利用感知器的潜力，甚至可以构建更高级的模型，如多层感知器（MLPs）和卷积神经网络（CNNs）。

我们还比较了感知器和逻辑回归，通过考察感知器作为机器学习中更高级技术的基础，突出了它们的异同。我们进一步探讨了感知器在人工智能中的作用、历史意义和持续影响。

请记住，感知器只是其中的一部分。还有无数其他模型和技术，无论是已被发现的还是待发现的，每个都有独特的优点和应用。尽管如此，借助本教程提供的坚实基础，你已准备好迎接人工智能领域中的挑战和机遇。

我希望本博客既引人入胜又富有启发性，鼓励你继续学习和尝试感知器模型及其他相关内容。拥抱你获得的新知识，让你的创造力和好奇心引导你探索人工智能和机器学习的精彩世界。请在下方分享你的想法和评论！

# 参考文献

[1] McCulloch, W.S., & Pitts, W. (1943). 神经活动中固有思想的逻辑演算。数学生物物理学公报，5，115–133。

[2] Rosenblatt, F. (1958). 感知器是脑中信息存储和组织的概率模型。心理学评论，65(6)，386–408。

[3] 纽约时报 (1958年7月8日). 一种新型海军设备通过实践学习. 纽约时报.

[4] Minsky, M. 和 Papert, S. (1969). 感知器：计算几何入门, MIT Press.

[5] Rumelhart, D. E., Hinton, G. E., 和 Williams, R. J. (1986). 通过反向传播错误学习表示. Nature, 323 (6088), 533–536.

[6] Duda, R. O., Hart, P. E., 和 Stork, D. G. (2001). 模式分类 (第2版). Wiley.

[7] Novikoff, A. B. (1962), 关于感知器收敛证明. 自动机数学理论研讨会, 12, 615–622.

[8] Rosenblatt, F. (1960). 感知器：认知系统中统计可分离性的理论 (项目 PARA 报告 60–3777). 康奈尔航空实验室.

[9] Cortes, C. 和 Vapnik, V. (1995). 支持向量网络. 机器学习, 20(3), 273–297.

[10] Bishop, C. M. (2006). 模式识别与机器学习, Springer.

[11] Rifkin, R. 和 Klautau, A. (2004). 为一对多分类辩护. 机器学习研究期刊, 5, 101–141.

[12] Minsky, M. L. (1961). 迈向人工智能的步骤. IRE 会议录, 49(1), 8–30.

[13] Horowitz, P. 和 Hill, W. (1989). 电子艺术 (第2版). 剑桥大学出版社.

[14] Mano, M. M. 和 Ciletti, M. D. (2007). 数字设计 (第4版). Prentice Hall.

[15] Merolla, P. A., Arthur, J. V., Alvarez-Icaza, R., Cassidy, A. S., Sawada, J., Akopyan, F.,... 和 Modha, D. S. (2014). 百万尖峰神经元集成电路与可扩展通信网络和接口. Science, 345 (6197), 668–673.

[16] Hastie, T., Tibshirani, R., 和 Friedman, J. (2009). 统计学习的元素：数据挖掘、推断与预测 (第2版). Springer.

[17] Nocedal, J. 和 Wright, S. (2006). 数值优化 (第2版). Springer.

[18] Schölkopf, B. 和 Smola, A. J. (2002). 使用核的学习：支持向量机、正则化、优化及其他. MIT Press.

[19] LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., 和 Jackel, L. D. (1989). 反向传播应用于手写邮政编码识别. 神经计算, 1(4), 541–551.

[20] Tzanetakis, G. 和 Cook, P. (2002). 音频信号的音乐类型分类. IEEE 语音与音频处理汇刊, 10(5), 293–302.

[21] Garcia-Teodoro, P., Diaz-Verdejo, J., Maciá-Fernández, G., 和 Vázquez, E. (2009). 基于异常的网络入侵检测：技术、系统和挑战. 计算机与安全, 28 (1–2), 18–28.

[22] Pang, B., Lee, L., 和 Vaithyanathan, S. (2002). 竖起大拇指？使用机器学习技术进行情感分类. ACL-02 自然语言处理经验方法会议论文集, 10, 79–86.

[23] Hornik, K., Stinchcombe, M., 和 White, H. (1989). 多层前馈网络是通用逼近器. 神经网络, 2(5), 359–366.

[24] LeCun, Y., Bengio, Y., 和 Hinton, G. (2015). 深度学习. Nature, 521 (7553), 436–444.

[25] Hochreiter, S., & Schmidhuber, J. (1997). 长期记忆。神经计算，9(8), 1735–1780。

# 联系方式

想要联系？请关注**罗宾逊博士**的[LinkedIn](https://www.linkedin.com/in/jrobby/)、[Twitter](https://twitter.com/jrobvision)、[Facebook](https://www.facebook.com/joe.robinson.39750)和[Instagram](https://www.instagram.com/doctor__jjj/)。访问我的主页获取论文、博客、邮箱注册等更多信息！

[](https://www.jrobs-vision.com/?source=post_page-----fd384eb93382--------------------------------) [## AI研究工程师与企业家 | 约瑟夫·P·罗宾逊

### 研究员与企业家，您好！作为一名研究员，**罗宾逊博士**提出并采用了先进的AI技术来理解…

[www.jrobs-vision.com](https://www.jrobs-vision.com/?source=post_page-----fd384eb93382--------------------------------)
