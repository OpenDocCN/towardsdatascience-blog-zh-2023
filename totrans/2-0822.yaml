- en: Environmental Impact of Ubiquitous Generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800](https://towardsdatascience.com/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What could happen to our environment if billions of people began to use generative
    AI technology on a daily basis?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://kaspergroesludvigsen.medium.com/?source=post_page-----9e061bac6800--------------------------------)[![Kasper
    Groes Albin Ludvigsen](../Images/3c31c9e54fae4fd1c8f1c441379d1f10.png)](https://kaspergroesludvigsen.medium.com/?source=post_page-----9e061bac6800--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e061bac6800--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e061bac6800--------------------------------)
    [Kasper Groes Albin Ludvigsen](https://kaspergroesludvigsen.medium.com/?source=post_page-----9e061bac6800--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e061bac6800--------------------------------)
    ·15 min read·Jul 12, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aba978b066343f9a34e7fcee5c0e854d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Johannes Plenio on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: 'This article ponders the question: What would be the environmental impact of
    large-scale adoption of generative AI like ChatGPT? That is, what might the environmental
    impact be if billions of people began to use generative AI extensively on a daily
    basis?'
  prefs: []
  type: TYPE_NORMAL
- en: The reason this question is interesting to contemplate is that we can use its
    answer to inform how worried we should or shouldn’t be about the speedy adoption
    of this new technology.
  prefs: []
  type: TYPE_NORMAL
- en: As AI models have grown larger and larger [1] and as they have been made widely
    accessible by companies like OpenAI and Google, the environmental impact of AI
    models — eg. carbon and water footprint — have become the subject of inquiry and
    debate. First in academia (e.g. [2] and [3]) and later in mainstream media (e.g.
    [4] and [5]).
  prefs: []
  type: TYPE_NORMAL
- en: With ChatGPT reportedly having hundreds of millions of users – if not billions
    [6] – and Google embedding generative AI into several products [7], generative
    AI is arguably the most widely adopted type of AI at the moment. Combined with
    the immense size of generative AI models like GPT-4 – rumored to be almost 6 times
    larger than its predecessor [8] – generative AI is likely also the type of AI
    to have the largest environmental impact for the foreseeable future.
  prefs: []
  type: TYPE_NORMAL
- en: This article is a thought experiment that contemplates what the environmental
    impact might be of large-scale adoption of generative AI. Will it lead to environmental
    catastrophe, will it be a drop in the ocean or somewhere in between? The purpose
    of this article is to provide a basis for beginning to shed light on that question.
  prefs: []
  type: TYPE_NORMAL
- en: Many assumptions went into making the estimates presented in this article, and
    if you’d like to play around with your own assumptions, you can do so [in this
    spreadsheet](https://docs.google.com/spreadsheets/d/1fXtR85LTtUiZ25rcPXzHmL4vR03x_hB9GPEWMLFhhXc/edit?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’d like to get full access to my stories on the environmental impact
    of AI, become a Medium member through the link below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9e061bac6800--------------------------------)
    [## Join Medium with my referral link - Kasper Groes Albin Ludvigsen'
  prefs: []
  type: TYPE_NORMAL
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9e061bac6800--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Stages in an AI system’s life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Even though this article does not analyze one specific model, it’s informative
    to distinguish between different stages of an AI model’s life cycle. We can think
    of an AI model’s life cycle as consisting of 6 distinct stages [9]:'
  prefs: []
  type: TYPE_NORMAL
- en: Raw material extraction
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Materials manufacturing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hardware manufacturing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model training
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model deployment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: End-of-life
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this article, I’ll focus on hardware manufacturing (stage 3), model training
    (stage 4) and model deployment (stage 5) and will therefore briefly describe these
    stages below.
  prefs: []
  type: TYPE_NORMAL
- en: Hardware manufacturing refers to the environmental impact from manufacturing
    the hardware on which the AI model runs. Model training is the stage in which
    the model is developed. Model deployment is the stage in which the model is “deployed”
    to a “production environment” where it can be used by users. This is also sometimes
    referred to as the inference stage or the production stage. The life cycle is
    often depicted as linear although many AI systems require their models to be re-trained
    or adjusted during the system’s lifetime.
  prefs: []
  type: TYPE_NORMAL
- en: To estimate the environmental impact of either of the 3 above-mentioned stages,
    we need to get an idea of how much hardware large-scale adoption of generative
    AI would require. This is what we’ll consider in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/chatgpts-electricity-consumption-7873483feac4?source=post_page-----9e061bac6800--------------------------------)
    [## ChatGPT’s Electricity Consumption'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT may have consumed as much electricity as 175,000 people in January 2023.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/chatgpts-electricity-consumption-7873483feac4?source=post_page-----9e061bac6800--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: How much hardware does large-scale generative AI adoption require?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To assess the potential environmental impact of large-scale adoption of generative
    AI, we need to know how much hardware would be required to handle billions of
    daily queries.
  prefs: []
  type: TYPE_NORMAL
- en: To figure out how much hardware is needed, we need to think about how many users
    the technology will have and how much they'll use it. The more users, the more
    hardware is needed.
  prefs: []
  type: TYPE_NORMAL
- en: So, what would large-scale generative AI adoption look like in terms of user
    numbers? Let’s assume that 3.5B people start to use ChatGPT or similar technology
    daily and they make 30 queries per day. That’s a total of 105B daily requests.
    In lieu of ChatGPT’s staggering user numbers and efforts by Google and other companies
    to integrate generative AI into various products, this shouldn’t be an unreasonable
    assumption.
  prefs: []
  type: TYPE_NORMAL
- en: Now we need to get a sense of what kind and how much hardware it takes to handle
    100B daily requests.
  prefs: []
  type: TYPE_NORMAL
- en: Patel and Ahmad have previously estimated that it takes around 3,617 Nvidia
    HGX A100 servers containing 28,936 Nvidia A100 GPUs to handle 195,000,000 daily
    ChatGPT requests [10]. The A100 GPU is a piece of processing hardware designed
    for AI workloads. Let’s assume that those numbers are in the right ballpark and
    that they will generalize to other generative AI services. Let’s further assume
    that the number of GPUs increases linearly with the number of daily requests.
    This means that if 3,617 HGX servers can handle 195,000,000 daily requests, we
    need 538.46x more compute — ie 1,947,615 Nvidia HGX A100 servers with a total
    of 15,580,923 A100 GPUs — to handle 105B daily requests.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an idea of how much hardware is needed to support large-scale
    adoption of generative AI, let’s look at the environmental impact of manufacturing
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Environmental impact of large-scale generative AI adoption in the hardware manufacturing
    stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw that large-scale adoption of generative AI technology
    may require 1,947,615 Nvidia HGX servers and 15,580,923 Nvidia A100 GPUs. Let’s
    look at the environmental impact from manufacturing this hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Nvidia have not released any information about the carbon footprint of their
    products, so we’ll have to use some proxies here, which means that the numbers
    we arrive at are highly speculative, so take them with a grain of salt and please
    challenge them.
  prefs: []
  type: TYPE_NORMAL
- en: The embodied emissions of Hewlett-Packard’s ProLiant DL345 Gen10 Plus server
    is 2,500 kgCO2e, according to the company’s own estimate [11]. This the only reasonably
    similar server for which I’ve been able to find embodied emissions data, so we’ll
    use that as proxy like Luccioni et al have previously done [9].
  prefs: []
  type: TYPE_NORMAL
- en: The ProLiant server does not contain any GPUs, so let’s add the embodied emissions
    of 8 A100 GPUs. Again, Nvidia have not disclosed this, but 150 kgCO2e per GPU
    has been used by others [9] [12].
  prefs: []
  type: TYPE_NORMAL
- en: We’re assuming that the Nvidia HGX with 8 GPU slots is used, so let’s add 8
    * 150 kgCO2e to the 2,500 kgCO2e. That’s a total of 3,700 kgCO2e per Nvidia HGX
    A100 server.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that we need 1,947,615 of these to handle 105B daily requests. The embodied
    emissions of the GPU hardware needed to accommodate large-scale adoption of generative
    AI is thus estimated to be 1,947,615 * 3,7 = 7,206,177 tons CO2e.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s spread out those emissions evenly over the life span of the hardware.
    We’ll assume that the hardware has a life span of 5 years after which it is either
    worn out or replaced by newer technology [13].
  prefs: []
  type: TYPE_NORMAL
- en: Based on this, the carbon footprint of manufacturing the hardware needed for
    large-scale adoption of generative AI is estimated to be 1,441,235.4 tons CO2e
    per year.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://kaspergroesludvigsen.medium.com/subscribe?source=post_page-----9e061bac6800--------------------------------)
    [## Get an email whenever Kasper Groes Albin Ludvigsen publishes.'
  prefs: []
  type: TYPE_NORMAL
- en: Get an email whenever Kasper Groes Albin Ludvigsen publishes. By signing up,
    you will create a Medium account if you…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/subscribe?source=post_page-----9e061bac6800--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Environmental impact of large-scale generative AI adoption in the training stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s consider the environmental impact of training the AI models that
    will underpin generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: The initial version of ChatGPT was based on the large language model (LLM) called
    GPT-3.5 which is a version of GPT-3\. The newest version of ChatGPT is likely
    based on OpenAI’s newest LLM called GPT-4, but OpenAI have not released any information
    about GPT-4 that can be used to estimate its training costs. We do however have
    reliable estimates of GPT-3's energy consumption during training. These come from
    a paper by Google and UC Berkeley researchers who estimate the energy consumption
    of training GPT-3 to be 1,287,000 KWh [14]. Let’s assume that models trained by
    other companies are in the same ballpark.
  prefs: []
  type: TYPE_NORMAL
- en: To compute the carbon footprint of consuming 1,287,000 KWh, we need to get an
    idea of how much carbon is emitted when 1 KWh of electricity is produced. This
    is called the carbon intensity of electricity and varies between regions, because
    sources of electricity (wind, coal, solar etc.) vary between regions. For this
    thought experiment, let’s use the average carbon intensity of electricity used
    by Google’s, Amazon’s, and Microsoft’s data centers. Using data from the ML CO2
    Impact Calculator [18], the mean carbon intensity of electricity used by these
    three cloud providers is 484 gCO2e/KWh.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to obtain an estimate of the annual carbon footprint of training generative
    models, we’ll need to know how many companies offer such models and how often
    they are trained. Let assume that there will be 9 major players in generative
    AI: OpenAI/Microsoft, Google, Meta, Anthropic, Inflection, Character, Tencent,
    ByteDance, Baidu. Let’s further assume that they train one model each per year.
    That’s an annual training footprint of 6,229 tons CO2e.'
  prefs: []
  type: TYPE_NORMAL
- en: The assumptions that go into this part of the article are the most speculative.
    However, as we’ll see, they won’t affect the total picture much because the environmental
    impact of the training stage pales in comparison to the environmental impact of
    the hardware manufacturing and deployment stages.
  prefs: []
  type: TYPE_NORMAL
- en: '**Environmental impact of large-scale generative AI adoption in the deployment
    stage**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s now consider the environmental impact of the deployment stage of the generative
    AI models. In other words, let’s look at how much electricity it takes to keep
    the 1,947,615 HGX servers running.
  prefs: []
  type: TYPE_NORMAL
- en: One way to calculate this is to look at the so-called Thermal Design Power (TDP)
    of the server. TDP is often used to quantify how much power a piece of processing
    hardware requires to run. The TDP of the HGX server is unknown, but the TDP of
    a similar Nvidia server, the DGX, is 6.5 kW [15] which we’ll assume also applies
    to the HGX server. So, if the server runs at full power for one hour, it has used
    6.5 kilowatt hours (kWh). However, for this thought experiment, let’s assume that
    all the servers run at 75% of their TDP on average, in which case they’ll consume
    4.875 KWh per hour. That’s 1,947,615 servers each consuming 4.875 KWh per hour.
    That’s a total of 9,494,625 KWh per hour, 227,871,000 KWh per day and 83,172,915,000
    KWh per year.
  prefs: []
  type: TYPE_NORMAL
- en: When calculating the electricity consumption from data center grade hardware,
    the electricity consumption of the hardware itself is often multiplied by the
    so-called Power Usage Effectiveness (PUE) of the data center in which the hardware
    is running. PUE is a metric used to express the energy efficiency of a data center.
    The more energy the data center uses on, say, cooling compared to the energy used
    to power the actual computer hardware, the higher the PUE. Microsoft’s global
    PUE is 1.18 [16] and Google’s is 1.10 [17], so let’s use the average of these
    two, i.e. 1.14.
  prefs: []
  type: TYPE_NORMAL
- en: If we multiply the HGX servers’ estimated annual electricity consumption of
    83,172,915,000 KWh by 1.14, we get an annual electricity consumption of 94,817,123,100
    KWh.
  prefs: []
  type: TYPE_NORMAL
- en: Next, to calculate carbon emissions, we’ll multiply by the carbon intensity
    of 484 g/KWh presented in the previous section. Based on this, we can estimate
    the annual carbon footprint of large-scale generative AI adoption to be 45,891,487
    tons in the deployment stage.
  prefs: []
  type: TYPE_NORMAL
- en: Combined environmental impact of ubiquitous adoption of generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have estimated the carbon footprint of the hardware manufacturing,
    training and deployment stages of large-scale adoption of generative AI, let’s
    combine those into the total annual carbon footprint of large-scale generative
    AI adoption.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that we estimated the annual emissions from manufacturing the hardware
    to be 1,441,235 tons. Then, we estimated the annual CO2e emissions from the training
    stage to be 6,229 tons. Finally, we estimated the carbon footprint of the deployment
    stage of large-scale adoption of generative AI to be 45,891,487 tons annually.
  prefs: []
  type: TYPE_NORMAL
- en: So the total carbon footprint of ubiquitous adoption of generative AI can be
    estimated to be 47,338,952 tons CO2e per year.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1 below depicts how much larger the carbon emissions from the model deployment
    stage are compared to the hardware manufacturing and model training stages. Consequently,
    research should address how to reduce the deployment stage emissions rather than
    the training stage emissions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/024865a779ffe8fa4734f1c77dcbe06d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Estimated annual carbon emissions from large-scale adoption of generative
    AI, by life cycle stage. Chart by Kasper Groes Albin Ludvigsen'
  prefs: []
  type: TYPE_NORMAL
- en: '**Putting the annual carbon footprint of large-scale adoption of generative
    AI into perspective**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Throughout the article, you may have wondered: “What do these numbers actually
    mean? Is it a lot or not?”'
  prefs: []
  type: TYPE_NORMAL
- en: Above, we estimated the total annual carbon footprint of large-scale adoption
    of generative AI to be 47,338,952 tons CO2e across the hardware manufacturing,
    model training and model deployment life cycle stages.
  prefs: []
  type: TYPE_NORMAL
- en: That’s equivalent to the annual emissions of 4,303,541 Danes. When put like
    that, it sounds like a lot in my opinion. On the other hand, 4.3M people is just
    a tiny fraction of the world’s population. So, let’s also compare the carbon footprint
    of ubiquitous generative AI to the entire world’s annual emissions.
  prefs: []
  type: TYPE_NORMAL
- en: Estimates of global annual CO2e emissions vary between sources, but IAE [19]
    estimate that in 2021, 40B metric tons of CO2e was emitted globally. Of 40B tons,
    47,338,952 tons is 0.12 %. Put differently, if 3.5B people made 30 daily queries
    to generative AI models like ChatGPT, this article estimates that it could increase
    global CO2e emissions by 0.12 %. I’ll let it be up to the readers to decide if
    they think that’s a lot or not.
  prefs: []
  type: TYPE_NORMAL
- en: Water footprint of ubiquitous generative AI adoption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far we have analyzed the potential carbon footprint of large-scale adoption
    of generative AI. But carbon emissions are not the only environmental impact of
    digital technology. Another important consideration is the water consumption from
    cooling the data centers which host large AI models. Water consumption refers
    to water that is lost and cannot be reused.
  prefs: []
  type: TYPE_NORMAL
- en: 'A recent paper by Pengfei Li et al [20] analyzes the water consumption from
    large language models like the one underpinning ChatGPT. In their paper, the authors
    present a methodology for estimating the water consumption from data centers and
    they estimate that ChatGPT consumes 500 ml of water for every 20–50 queries. Data
    centers consume water in two primary ways:'
  prefs: []
  type: TYPE_NORMAL
- en: direct consumption which is when water evaporates and is flushed as data center
    hardware is cooled, and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: indirect water consumption which accounts for the water being used to produce
    the electricity that data centers need to run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s assume that the water consumption of ChatGPT will generalize to other
    AI services and that 50 queries require 500 ml of water, so that’s 10 ml of water
    per query. Recall that we assumed that 105B daily requests will be made to generative
    AI models. That’s 1,050,000,000 liters of water per day, or 383,250,000,000 liters
    in a year. For comparison, the annual recommended fluid intake for adults is 3.2
    liters [21], or an annual intake of 1,168 liters. This means that the water consumption
    from large scale adoption of generative AI could sustain the annual fluid intake
    of 328,135,000 adults.
  prefs: []
  type: TYPE_NORMAL
- en: You may wonder why water consumption can be problematic. The main issue is when
    data centers that consume a lot of water are placed in regions affected by drought.
    This is an issue because we generally don’t have the infrastructure needed to
    move water across large distances. The paper by Pengfei Li et al presents this
    map which shows areas of the US affected by drought. Thousands of data centers
    are located in these areas.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f875c35208a82c1e5c63c52779fc20d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [https://arxiv.org/pdf/2304.03271.pdf](https://arxiv.org/pdf/2304.03271.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s now discuss some of the potential implications of the estimates presented
    above.
  prefs: []
  type: TYPE_NORMAL
- en: Can we power large-scale generative AI adoption with renewable energy?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So how might we mitigate the environmental impact of large-scale adoption of
    generative AI?
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9e061bac6800--------------------------------)
    [## How to estimate and reduce the carbon footprint of machine learning models'
  prefs: []
  type: TYPE_NORMAL
- en: Two ways to easily estimate the carbon footprint of machine learning models
    and 17 ideas for how you might reduce it
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9e061bac6800--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: One idea that springs to mind is to power it all with renewable energy. Let’s
    consider that idea.
  prefs: []
  type: TYPE_NORMAL
- en: In the following, I’ll assume that all queries made of generative AI will require
    additional energy. I.e. I assume the queries won’t substitute queries made to
    other existing services. You might argue that some ChatGPT queries currently replaces
    traditional search engine queries, but given that generative AI is being built
    into both Bing and Google, I’d venture that near all generative AI queries will
    be additional.
  prefs: []
  type: TYPE_NORMAL
- en: In order to make large-scale adoption of generative AI sustainable, the energy
    would therefore have to be generated by *additional* renewable energy capacity
    — i.e. we’d have to install additional renewable energy capacity. Recall that
    ubiquitous generative AI could require just shy of 95 billion KWh of electricity
    per year. The average wind turbine can generate 6 million KWh in a year [22].
  prefs: []
  type: TYPE_NORMAL
- en: So to produce enough renewable energy with wind turbines, we would need to install
    around 15,800 new wind turbines. To put that into perspective, Denmark, a leading
    nation in wind energy, currently has 6,286 active wind turbines [23]
  prefs: []
  type: TYPE_NORMAL
- en: I therefore think it’s safe to say that establishing enough additional renewable
    energy to power ubiquitous generative AI adoption would be a massive and expensive
    undertaking.
  prefs: []
  type: TYPE_NORMAL
- en: On a side note, even renewable energy is considered to have a carbon footprint
    because the emissions caused by producing and installing e.g. a wind turbine are
    spread out over the life time of the energy source. Thus, electricity from off-shore
    wind power is considered to have a median carbon intensity of 12 gCO2e/KWh [24].
    So even all generative AI was powered by wind energy, it would have an annual
    carbon footprint of 1,114,000 tons CO2e — roughly the same as 104k Danes.
  prefs: []
  type: TYPE_NORMAL
- en: Do the benefits outweigh the costs?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another interesting aspect to consider in this debate is whether the productivity
    gains we can achieve with generative AI justifies its environmental impact. In
    a yet to be peer reviewed article (i.e. take it with a grain of salt), MIT PhD
    students Shakked Noy and Whitney Zhang show that using ChatGPT improved both productivity
    and quality of work for a number of tasks in an experimental setting [25]. Noy
    and Zhang measured productivity on tasks such as writing press releases, short
    reports, analysis plans, and delicate emails. Quality is assessed by (blinded)
    experienced professionals working in the same occupations.
  prefs: []
  type: TYPE_NORMAL
- en: Whether productivity gains are worth their environmental costs is in essence
    a value judgement, but it would be a good start for the debate if we could ascertain
    whether generative AI actually does make us more productive. More research should
    therefore be conducted, and companies using generative AI should critically assess
    the effects on productivity.
  prefs: []
  type: TYPE_NORMAL
- en: Caveats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The estimates put forward in this article should be considered educated guesswork.
    This is first and foremost because we’re trying to guess what will happen in the
    future. Secondly, any effort at estimating the environmental impact of these types
    of AI models is hampered by the fact that the providers don’t disclose the necessary
    information, which means we must make assumptions. By writing this, I hope to
    inspire others to challenge my assumptions or produce their own estimates.
  prefs: []
  type: TYPE_NORMAL
- en: Although generative AI is an umbrella term for AI products than can generate
    both text and/or images, this article focuses on models that generate text. The
    estimates made here do therefore not consider the adoption of image generation
    technology per se.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT in it’s original version (based on GPT-3.5) was the point of departure
    for this article because relevant data is unavailable for OpenAI’s latest model,
    GPT-4\. As written above, GPT-4 is larger than GPT-3, which could mean that it
    consumes more energy. However, it’s not necessarily the case.
  prefs: []
  type: TYPE_NORMAL
- en: I assume that the environmental impact of one company’s generative AI product
    will be in the same ballpark as competing products offered by other companies,
    but it could be the case that some companies will offer smaller or more specialized
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this thought experiment we looked at what the environmental impact could
    be if a large part of the world’s population begins to use generative AI like
    ChatGPT on a daily basis. The purpose of this thought experiment is give the reader
    a basis for assessing the question: Should we worry about the environmental impact
    of large-scale adoption of generative AI?'
  prefs: []
  type: TYPE_NORMAL
- en: We estimated that ubiquitous generative AI might consume 95B KWh of electricity
    annually, and producing this amount of electricity could cause emission of 47,338,952
    tons CO2e. That’s 0.12 % of global CO2e emissions. In other words, this article
    estimates that if 3.5B people make 30 queries per day to generative AI services,
    it could increase global CO2e emissions by 0.12 %. Another environmental impact
    to consider is water consumption. This article estimates that ubiquitous generative
    AI might consume 383,250,000,000 liters of water in a year. This amount of water
    is the same as the recommended annual fluid intake of 328,125,000 adults.
  prefs: []
  type: TYPE_NORMAL
- en: That’s it! I hope you enjoyed the story. Let me know what you think!
  prefs: []
  type: TYPE_NORMAL
- en: Follow me for more on AI and sustainability and [subscribe](https://kaspergroesludvigsen.medium.com/subscribe)
    to get my stories via email when I publish.
  prefs: []
  type: TYPE_NORMAL
- en: I also sometimes write about [time series forecasting](/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e).
  prefs: []
  type: TYPE_NORMAL
- en: And feel free to connect on [LinkedIn](https://www.linkedin.com/in/kaspergroesludvigsen).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [https://huggingface.co/blog/large-language-model](https://huggingface.co/blog/large-language-models)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [https://arxiv.org/abs/1907.10597](https://arxiv.org/abs/1907.10597)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [https://arxiv.org/abs/1906.02243](https://arxiv.org/abs/1906.02243)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] [https://www.forbes.com/sites/bernardmarr/2023/03/22/green-intelligence-why-data-and-ai-must-become-more-sustainable/](https://www.forbes.com/sites/bernardmarr/2023/03/22/green-intelligence-why-data-and-ai-must-become-more-sustainable/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] [https://www.standard.co.uk/tech/ai-chatgpt-water-usage-environment-study-b1073866.html](https://www.standard.co.uk/tech/ai-chatgpt-water-usage-environment-study-b1073866.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] [https://www.similarweb.com/blog/insights/ai-news/chatgpt-growth-flattens/](https://www.similarweb.com/blog/insights/ai-news/chatgpt-growth-flattens/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] [https://nypost.com/2023/05/10/google-integrates-more-ai-into-products-in-battle-with-microsoft/](https://nypost.com/2023/05/10/google-integrates-more-ai-into-products-in-battle-with-microsoft/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] [https://the-decoder.com/gpt-4-has-a-trillion-parameters/](https://the-decoder.com/gpt-4-has-a-trillion-parameters/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] [https://arxiv.org/pdf/2211.02001.pdf](https://arxiv.org/pdf/2211.02001.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] [https://www.semianalysis.com/p/the-inference-cost-of-search-disruption](https://www.semianalysis.com/p/the-inference-cost-of-search-disruption)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] [https://www.hpe.com/psnow/doc/a50005151enw](https://www.hpe.com/psnow/doc/a50005151enw)'
  prefs: []
  type: TYPE_NORMAL
- en: '[12] [https://medium.com/teads-engineering/building-an-aws-ec2-carbon-emissions-dataset-3f0fd76c98ac](https://medium.com/teads-engineering/building-an-aws-ec2-carbon-emissions-dataset-3f0fd76c98ac)'
  prefs: []
  type: TYPE_NORMAL
- en: '[13] [https://cybersided.com/how-long-do-gpus-last/](https://cybersided.com/how-long-do-gpus-last/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14] [https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf](https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[15] [https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-dgx-a100-datasheet.pdf](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-dgx-a100-datasheet.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16] [https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/](https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[17] [https://www.google.com/about/datacenters/efficiency/](https://www.google.com/about/datacenters/efficiency/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[18] [https://github.com/mlco2/impact/blob/master/data/impact.csv](https://github.com/mlco2/impact/blob/master/data/impact.csv)'
  prefs: []
  type: TYPE_NORMAL
- en: '[19] [https://www.iea.org/reports/co2-emissions-in-2022](https://www.iea.org/reports/co2-emissions-in-2022)'
  prefs: []
  type: TYPE_NORMAL
- en: '[20] [https://arxiv.org/pdf/2304.03271.pdf](https://arxiv.org/pdf/2304.03271.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[21] [https://www.health.harvard.edu/staying-healthy/how-much-water-should-you-drink](https://www.health.harvard.edu/staying-healthy/how-much-water-should-you-drink)'
  prefs: []
  type: TYPE_NORMAL
- en: '[22] [https://www.ewea.org/wind-energy-basics/faq/](https://www.ewea.org/wind-energy-basics/faq/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[23] [https://turbines.dk/](https://turbines.dk/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[24] [https://en.wikipedia.org/wiki/Life-cycle_greenhouse_gas_emissions_of_energy_sources](https://en.wikipedia.org/wiki/Life-cycle_greenhouse_gas_emissions_of_energy_sources)'
  prefs: []
  type: TYPE_NORMAL
- en: '[25] [https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1.pdf](https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1.pdf)'
  prefs: []
  type: TYPE_NORMAL
