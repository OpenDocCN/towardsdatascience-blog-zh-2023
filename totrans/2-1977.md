# 文本模式提取：比较 GPT-3 和 人工在环工具

> 原文：[https://towardsdatascience.com/text-pattern-extraction-comparing-gpt-3-human-in-the-loop-tool-f2380fd13cf1](https://towardsdatascience.com/text-pattern-extraction-comparing-gpt-3-human-in-the-loop-tool-f2380fd13cf1)

## 比较 LLM 和人工在环工具在文本模式提取中的初步实验和结果

[](https://maeda-han.medium.com/?source=post_page-----f2380fd13cf1--------------------------------)[![Maeda Hanafi](../Images/c1ceef15ccbe82a5b8655593d685db74.png)](https://maeda-han.medium.com/?source=post_page-----f2380fd13cf1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f2380fd13cf1--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f2380fd13cf1--------------------------------) [Maeda Hanafi](https://maeda-han.medium.com/?source=post_page-----f2380fd13cf1--------------------------------)

·发布于 [数据科学的前沿](https://towardsdatascience.com/?source=post_page-----f2380fd13cf1--------------------------------) ·10分钟阅读·2023年1月26日

--

![](../Images/3c44a30478df4c48cb757c512b575935.png)

图片来源于 [Aaron Burden](https://unsplash.com/@aaronburden?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 在 [Unsplash](https://unsplash.com/photos/nDeo4F3Zq28?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

在过去几年中，AI 在多个工业应用中引起了广泛关注。医生、分析师和记者等最终用户希望为其特定的使用案例构建 AI 模型。

然而，构建 AI 模型的工作流程需要技术专长，而最终用户可能不一定具备：

+   准备数据，例如提取、清理和转换训练数据。

+   训练 AI 模型，包括微调参数和重新训练模型的层。

![](../Images/5862ab47b5a9c4c07d14c3f881ecef5f.png)

动机：使最终用户能够构建 AI 模型。图片来源于作者。

最终用户可能会直接使用现有工具***开箱即用***。有几种工具适用于最终用户以***开箱即用***的方式构建 AI 模型。

最近，一类称为人工在环 (HITL) 工具的工具旨在降低最终用户构建 AI 模型的门槛。“人工在环”在模型构建过程中融入了人类知识。它本质上是一个人机协作的框架。在这个框架中，模型构建和用户输入之间有一个持续的反馈过程。

另一方面，AI 领域有一些广泛研究的模型，即大型生成语言模型，如 GPT-3、OPT、BLOOM 等。语言模型在大规模数据集上进行训练，具有惊人的语言理解能力。这些模型的规模达到数亿参数，并且在多个自然语言处理任务（例如提取、分类等）中表现出了*少量样本*的优异性能（即它们只需少量输入）。

![](../Images/60f6e8dc6bae212b3e9b4343a1d141a5.png)

现有工作。图像由作者提供。

我们想了解这些广泛研究的大型语言模型在帮助终端用户构建 AI 模型的背景下，与人机协作工具的表现如何。*在我们的实验中，我们模拟了一个终端用户或业务用户（即没有太多技术培训的人）如何使用这些工具来执行文本模式提取任务。* 在这篇简短的博客文章中，我想谈谈我们在 IBM 的几项实验，我们比较了人机协作系统与大型语言模型在模式提取任务中的表现。我们在 DaSH@EMNLP 2022 上展示了这项工作，你可以在 [这里找到论文](https://aclanthology.org/2022.dash-1.7/)。

具体来说，我们研究了以下工具：

+   **模式归纳** 是 IBM Watson Discovery 上用于文本模式提取的 HITL 工具。

+   **GPT-3** 是一个流行的大型生成语言模型。GPT-3 是最大的语言模型之一，拥有 1750 亿个参数。

![](../Images/ccb50b60ff825ecbc2b2a849f987ae4a.png)

我们比较工作的目标。图像由作者提供。

## 文本模式提取

什么是文本模式提取？下面，我们有一个场景，其中包含一系列财务新闻稿，我们需要提取财政时间段。我们希望的提取结果包括“2014年第一季度”和“2013年第四季度”。注意，财政时间段的年份可以出现在提取结果的开始或结束，而季度则可以是“第一”、“第二”、“第三”或“第四”。

![](../Images/996c313fa5129d1351e11a99b28389ba.png)

文本模式提取。图像由作者提供。

# **文本模式提取与模式归纳**

模式归纳在 IBM Watson Discovery 上可用。它是一个用于文本模式提取的 HITL 工具。终端用户通过提供反馈来提取文本模式。该工具无需任何编码，用户也不需要提供大规模的训练数据集。

模式归纳支持两种用户操作：

1.  终端用户高亮他们希望提取的文本示例。

1.  终端用户还会向系统的提取结果提供反馈。用户可以接受或拒绝这些提取结果。

在我们的实验中，我们通过模拟两种用户操作来进行用户模拟：(1) 高亮示例文本，和 (2) 提供反馈。

![](../Images/10eaa83cfdf4b30015c6f5e5b37ba658.png)

通过模拟用户操作来评估 HITL 工具。图像作者提供。

在后台，模式诱导学习 *提取规则*。可以将它们视为类似于正则表达式的东西：描述一系列标记或单词模式的表达式。

![](../Images/6a337ac23048b501216414bdb11b006c.png)

模式诱导流程及其基础规则模型。图像作者提供。

# GPT-3 的文本模式提取

虽然最终用户会在模式诱导中提供文本高亮和反馈，但在 GPT-3 中完成文本提取任务需要构造输入提示，而 GPT-3 输出一个 *完成文本*，我们期望其中包含提取的文本。

![](../Images/8aacfbfe400216c1cfbed505e5a4a651.png)

基本的 GPT-3 文本模式提取提示。图像作者提供。

假设我们需要从报告数据集中提取 ISO 编号，如“ISO 18788”或“ISO 223000”。在上面的图像中，我们有一个按照以下方式制作的输入提示：

+   输入提示的第一部分是我们要提取的来自数据集的句子。我们将此句子放在方括号中。

+   提示的第二部分包含以列表形式列出的示例提取，其中每个示例提取都放在竖线字符“|”之间。

输入提示的格式用于向 GPT-3 显示和演示我们希望从句子中提取哪些类型的文本。在上面的例子中，GPT-3 从句子中完成了文本，输出了“ISO 9001”。上述输入提示是一种相当天真的方法，它模仿了最终用户可能构造提示的方式。构造提示需要一定程度的工程技术，整个研究子领域都致力于提示工程。

## 提示

![](../Images/0d8740fc0ab58ee3243de934e2a65f83.png)

尝试了几种不同的输入格式。图像作者提供。

输入提示的格式有很多种。我们尝试了几种格式：

+   **基本提示**：模仿可能没有太多技术专长的最终用户如何构造提示。

+   **结构化提示**：不是列出提取示例，而是将每个提取示例与一个句子配对。

![](../Images/998c937acea0e78f8b28dc1818128e91.png)

结构化提示。图像作者提供。

+   **带有附加和负面示例的结构化提示：** 在最后一种提示中，我们添加了附加示例和负面示例。在模式诱导中，用户可以接受和拒绝提取。在 GPT-3 中，我们将这些类型的提取作为附加示例添加。

![](../Images/edff1ed0cd87cfc9e4f8c3399a7f2c1f.png)

带有负面示例的结构化提示。图像作者提供。

要了解有关输入提示格式的更多细节，请参阅 [论文](https://aclanthology.org/2022.dash-1.7/)。

## 后处理 GPT-3 的输出

使用GPT-3进行文本模式提取的主要挑战之一是它有时会对输出进行创意性的处理。这是GPT-3常见的现象，考虑到其文本生成能力。GPT-3提取的文本并不总是文档数据集的一部分。

![](../Images/7d04884bb49171756c4367f9b03e0fcf.png)

GPT-3输出的文本有创意。图片由作者提供。

在一个用例中，我们希望从犯罪报告中提取犯罪事件的百分比，如“财产犯罪”或“人身犯罪”的百分比。但GPT-3生成了有关其他主题的百分比，如种族或性别，例如“0.6%为美洲印第安人或阿拉斯加土著”。这些文本甚至没有出现在数据集中，这对精确度评分产生了负面影响。因此，我们对GPT-3的所有输出进行了后处理。后处理步骤包括清理输出文本（去除分隔符）和删除那些不属于文档数据集的输出。

# 实验设置

这是我们用于将GPT-3与模式归纳进行比较的实验设置的详细信息：

![](../Images/29f68d7572a783f93de94c60d43c1e71.png)

用户模拟实验设置。图片由作者提供。

用户模拟在模式归纳和GPT-3上运行。每个工具都进行了7个用例任务：

![](../Images/12c948f71ff2a5257d2930ba9c07585e.png)

我们给GPT-3和模式归纳的用例任务。图片由作者提供。

用户模拟记录了每次运行的精确度和召回率。

## GPT-3实验

![](../Images/ee285086ec3134b1c8edd8918652a609.png)

图片由作者提供。

在对GPT-3的评估过程中，我们使用了用户模拟将作为高亮文本的相同种子示例，种子示例取自模式归纳用户模拟的日志，然后这些种子示例被用作GPT-3的输入提示。这是为了使其与模式归纳的运行结果可比。由于GPT-3的输入提示有令牌数量限制（约4K个令牌），我们还将文档拆分成部分。

## 结果：精确度评分

我们计算了平均精确度，这些精确度是对每个7个用例中的100次用户模拟运行的综合结果。结果显示GPT-3的精确度评分低于模式归纳的精确度评分（绿色线条带三角标记）：

![](../Images/0d9f6e0c285419e70b2c242a834dca1b.png)

GPT-3的精确度评分低于模式归纳。图片由作者提供。

图表中有几条GPT-3的线，每条线属于某种不同的输入提示格式变体。虽然不同的输入提示格式提高了精确度评分，但GPT-3的精确度评分平均值并没有超过HITL的精确度评分。总体而言，**在精确度方面，模式归纳的表现比最佳GPT-3模型（结构化提示和额外示例）平均高出38.8%**。

## 结果：召回率评分

我们还计算了平均召回率，即对每个 7 个用例任务的 100 次用户模拟运行的汇总。

![](../Images/050b41d6ef7406f67112d4c9d1d4ac17.png)

GPT-3 的召回分数相似且更高。图片来自作者。

总体而言，**在召回率方面，模式诱导的表现比最好的 GPT-3 模型平均好 4.0%。** 然而，当对每个用例任务分析召回分数时，我们注意到 GPT-3 的运行在召回分数上要么相似，要么甚至高于模式诱导的运行：

+   任务 U1、U3、U4：在这些任务中，预期的提取不遵循某些语法模式。例如，任务 U3 需要提取不同类型的犯罪，例如“财产犯罪”、“人身犯罪”。或者，任务 U4 需要提取整数和分数类型的量杯。这些任务提取的是*概念*，GPT-3 在这些任务中表现得相当好。GPT-3 理解某些词指代概念和实体，例如国家、犯罪类型或整数和分数量。**GPT-3 对文本中的概念理解得非常好。**

![](../Images/6721cbcee53eefab344b4f57758ba403.png)

GPT-3 对文本中的概念理解得非常好。图片来自作者。

+   任务 U2、U5、U6、U7：另一方面，我们看到，具有更严格语法模式的任务在模式诱导中处理得更好。例如，在任务 U2 中，我们希望提取事件的计数。字面上的“事件”通常出现在一个 6 位整数的末尾。这个模式适用于所有预期的提取。这些任务更具语法性，**模式诱导在处理具有更严格语法模式的提取任务时表现更好。** 这很合理，因为底层的模式诱导模型是基于规则的。

![](../Images/9896e83ce41c7e719b20d2830a158bc0.png)

模式诱导更好地学习严格模式。图片来自作者。

## 改进提示格式提高了召回分数

我们在 GPT-3 运行中观察到的另一个关键点是，改进输入提示格式会提高召回分数。

![](../Images/4c50c06640cee4d2c87790b5da34a070.png)

结构化提示提高了召回率。图片来自作者。

从上面的图表可以看出，从基础提示分数（橙色线）到结构化提示分数（黄色线），**召回分数平均提高了 59.8%**。这张图的关键结论是，提示工程和格式化对于提高召回分数非常重要。

# 比较分析总结

![](../Images/7a42e52aaa29e88daeed149dfac91807.png)

图片来自作者。

HITL 方法用于文本模式提取的结果具有更高的精度，适合那些没有太多技术背景的最终用户。此外，有两个方面在 GPT-3 中找不到，但在 HITL 中存在：

1.  HITL 方法能够引出有针对性的用户反馈，并

1.  这允许采用迭代方法来构建模型。

然而，HITL方法的召回率较低，并且更适合处理句法文本模式。

在大型生成模型中，给定结构化的提示和后处理步骤，GPT-3提供了更高的召回率。GPT-3能够对提示进行上下文化并学习更通用的模型。然而，GPT-3在文本模式提取中的缺点是，它本身无法像HITL方法那样执行提取任务。实际上，为了获得与HITL模型相当的结果，我们不得不

1.  设计并构建提示的结构，以利用GPT-3强大的语言能力和

1.  对GPT-3的字符串输出进行后处理。

然而，这些步骤可能不会被没有太多技术培训的终端用户采取。

# 结论与未来工作

在我们的初步工作中，我们比较了HITL和预训练的大型生成语言模型在文本模式提取任务中的表现。我们想了解终端用户如何使用广泛研究的模型进行文本模式提取。我们发现，HITL方法在精确度上平均表现更好，而GPT-3在召回率上具有相当或更高的得分。

我们的未来工作在这些结果的基础上进行。**我们如何结合HITL和预训练的大型生成语言模型的优点？** 我们如何利用用户输入来改进提示设计，并进而利用大型语言模型的上下文和语言能力？
