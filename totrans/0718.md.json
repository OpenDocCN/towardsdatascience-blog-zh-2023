["```py\nimport os\nimport boto3\nimport re\nimport time\nimport json\nfrom sagemaker import get_execution_role, session\nimport pandas as pd\n\nfrom time import gmtime, strftime\nimport sagemaker\nfrom sagemaker.model import Model\nfrom sagemaker.image_uris import retrieve\nfrom sagemaker.workflow.pipeline_context import PipelineSession\nfrom sagemaker.workflow.model_step import ModelStep\nfrom sagemaker.inputs import TrainingInput\nfrom sagemaker.workflow.steps import TrainingStep\nfrom sagemaker.workflow.parameters import ParameterString\nfrom sagemaker.estimator import Estimator\n\n# Custom Lambda Step\nfrom sagemaker.workflow.lambda_step import (\n    LambdaStep,\n    LambdaOutput,\n    LambdaOutputTypeEnum,\n)\nfrom sagemaker.lambda_helper import Lambda\nfrom sagemaker.workflow.pipeline import Pipeline\n```", "```py\npipeline_session = PipelineSession()\n```", "```py\n!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/uci_abalone/train_csv/abalone_dataset1_train.csv .\n!aws s3 cp abalone_dataset1_train.csv s3://{default_bucket}/xgboost-regression/train.csv\ntraining_path = 's3://{}/xgboost-regression/train.csv'.format(default_bucket)\n```", "```py\ntraining_input_param = ParameterString(\n    name = \"training_input\",\n    default_value=training_path,\n)\n\ntraining_instance_param = ParameterString(\n    name = \"training_instance\",\n    default_value = \"ml.c5.xlarge\")\n```", "```py\nmodel_path = f's3://{default_bucket}/{s3_prefix}/xgb_model'\n\nimage_uri = sagemaker.image_uris.retrieve(\n    framework=\"xgboost\",\n    region=region,\n    version=\"1.0-1\",\n    py_version=\"py3\",\n    instance_type=training_instance_param,\n)\n\nimage_uri\n```", "```py\nxgb_train_one = Estimator(\n    image_uri=image_uri,\n    instance_type=training_instance_param,\n    instance_count=1,\n    output_path=model_path,\n    sagemaker_session=pipeline_session,\n    role=role\n)\n\nxgb_train_one.set_hyperparameters(\n    objective=\"reg:linear\",\n    num_round=40,\n    max_depth=4,\n    eta=0.1,\n    gamma=3,\n    min_child_weight=5,\n    subsample=0.6,\n    silent=0,\n)\n```", "```py\nxgb_train_two = Estimator(\n    image_uri=image_uri,\n    instance_type=training_instance_param,\n    instance_count=1,\n    output_path=model_path,\n    sagemaker_session=pipeline_session,\n    role=role\n)\n\n#adjusting hyperparams\nxgb_train_two.set_hyperparameters(\n    objective=\"reg:linear\",\n    num_round=50,\n    max_depth=5,\n    eta=0.2,\n    gamma=4,\n    min_child_weight=6,\n    subsample=0.7,\n    silent=0,\n)\n```", "```py\ntrain_args_one = xgb_train_one.fit(\n    inputs={\n        \"train\": TrainingInput(\n            s3_data=training_input_param,\n            content_type=\"text/csv\",\n        )\n    }\n)\n\ntrain_args_two = xgb_train_two.fit(\n    inputs={\n        \"train\": TrainingInput(\n            s3_data=training_input_param,\n            content_type=\"text/csv\",\n        )\n    }\n)\n```", "```py\nstep_train_one = TrainingStep(\n    name=\"TrainOne\",\n    step_args=train_args_one,\n)\n\nstep_train_two = TrainingStep(\n    name = \"TrainTwo\",\n    step_args= train_args_two\n)\n```", "```py\nimport boto3\nimport json\n\niam = boto3.client(\"iam\")\n\ndef create_lambda_role(role_name):\n    try:\n        response = iam.create_role(\n            RoleName=role_name,\n            AssumeRolePolicyDocument=json.dumps(\n                {\n                    \"Version\": \"2012-10-17\",\n                    \"Statement\": [\n                        {\n                            \"Effect\": \"Allow\",\n                            \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n                            \"Action\": \"sts:AssumeRole\",\n                        }\n                    ],\n                }\n            ),\n            Description=\"Role for Lambda to call SageMaker functions\",\n        )\n\n        role_arn = response[\"Role\"][\"Arn\"]\n\n        response = iam.attach_role_policy(\n            RoleName=role_name,\n            PolicyArn=\"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\",\n        )\n\n        response = iam.attach_role_policy(\n            PolicyArn=\"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\", RoleName=role_name\n        )\n\n        return role_arn\n\n    except iam.exceptions.EntityAlreadyExistsException:\n        print(f\"Using ARN from existing role: {role_name}\")\n        response = iam.get_role(RoleName=role_name)\n        return response[\"Role\"][\"Arn\"]\n```", "```py\nfrom iam_helper import create_lambda_role\n\nlambda_role = create_lambda_role(\"lambda-deployment-role\")\n```", "```py\nsm_client = boto3.client(\"sagemaker\")\ns3 = boto3.resource('s3')\n\ndef extract_bucket_key(model_data):\n    \"\"\"\n    Extracts the bucket and key from the model data tarballs that we are passing in\n    \"\"\"\n    bucket = model_data.split('/', 3)[2]\n    key = model_data.split('/', 3)[-1]\n    return [bucket, key]\n\ndef create_mme_dir(model_data_dir):\n    \"\"\"\n    Takes in a list of lists with the different trained models, \n    creates a central S3 bucket/key location with all model artifacts for MME.\n    \"\"\"\n    bucket_name = model_data_dir[0][0]\n    for i, model_data in enumerate(model_data_dir):\n        copy_source = {\n              'Bucket': bucket_name,\n              'Key': model_data[1]\n            }\n        bucket = s3.Bucket(bucket_name)\n        destination_key = 'xgboost-mme-pipelines/model-{}.tar.gz'.format(i)\n        bucket.copy(copy_source, destination_key)\n    mme_s3_path = 's3://{}/xgboost-mme-pipelines/'.format(bucket_name)\n    return mme_s3_path\n```", "```py\n model_name = 'mme-source' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n    create_model_response = sm_client.create_model(\n        ModelName=model_name,\n        Containers=[\n            {\n                \"Image\": image_uri,\n                \"Mode\": \"MultiModel\",\n                \"ModelDataUrl\": model_url\n            }\n        ],\n        #to-do parameterize this\n        ExecutionRoleArn='arn:aws:iam::474422712127:role/sagemaker-role-BYOC',\n    )\n    print(\"Model Arn: \" + create_model_response[\"ModelArn\"])\n\n    #Step 2: EPC Creation\n    xgboost_epc_name = \"mme-source\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n    endpoint_config_response = sm_client.create_endpoint_config(\n        EndpointConfigName=xgboost_epc_name,\n        ProductionVariants=[\n            {\n                \"VariantName\": \"xgbvariant\",\n                \"ModelName\": model_name,\n                \"InstanceType\": \"ml.c5.large\",\n                \"InitialInstanceCount\": 1\n            },\n        ],\n    )\n    print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])\n\n    #Step 3: EP Creation\n    endpoint_name = \"mme-source\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n    create_endpoint_response = sm_client.create_endpoint(\n        EndpointName=endpoint_name,\n        EndpointConfigName=xgboost_epc_name,\n    )\n    print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n```", "```py\nreturn {\n        \"statusCode\": 200,\n        \"body\": json.dumps(\"Created Endpoint!\"),\n        \"endpoint_name\": endpoint_name\n    }\n```", "```py\n# Lambda helper class can be used to create the Lambda function\nfunc = Lambda(\n    function_name=function_name,\n    execution_role_arn=lambda_role,\n    script=\"code/lambda_helper.py\",\n    handler=\"lambda_helper.lambda_handler\",\n)\n```", "```py\noutput_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\noutput_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\noutput_param_3 = LambdaOutput(output_name=\"endpoint_name\", output_type=LambdaOutputTypeEnum.String) \n```", "```py\nstep_deploy_lambda = LambdaStep(\n    name=\"LambdaStep\",\n    lambda_func=func,\n    inputs={\n        \"model_artifacts_one\": step_train_one.properties.ModelArtifacts.S3ModelArtifacts,\n        \"model_artifacts_two\": step_train_two.properties.ModelArtifacts.S3ModelArtifacts\n    },\n    outputs=[output_param_1, output_param_2, output_param_3],\n)\n```", "```py\npipeline = Pipeline(\n    name=\"mme-pipeline\",\n    steps=[step_train_one, step_train_two, step_deploy_lambda],\n    parameters= [training_input_param, training_instance_param]\n)\n```", "```py\npipeline.upsert(role_arn=role)\nexecution = pipeline.start()\nexecution.wait()\n```", "```py\nimport boto3\nsmr = boto3.client('sagemaker-runtime') #client for inference\n\n#specify the tarball you are invoking in the TargetModel param\nresp = smr.invoke_endpoint(EndpointName=endpoint_name, Body=b'.345,0.224414,.131102,0.042329,.279923,-0.110329,-0.099358,0.0', \n                           ContentType='text/csv', TargetModel = 'model-0.tar.gz')\n\nprint(resp['Body'].read())\n```"]