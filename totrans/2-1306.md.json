["```py\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom typing import List\nimport numpy as np\nimport seaborn as sns\nimport os\nimport cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom skimage.registration import optical_flow_tvl1, optical_flow_ilk\nfrom skimage.transform import warp\nfrom skimage.color import rgb2gray\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.metrics import normalized_root_mse as nrmse\n```", "```py\ndef retrieve_images(patient_id = '156518', laterality = 'L', date = None):\n    # Set the root directory for the patient data\n    root_dir = Path(f'../data/{patient_id}')\n\n    # Get the list of image filenames for the left eye\n    image_filenames = [f for f in os.listdir(root_dir) if f'{laterality}.png' in f]\n\n    # If we are registering to same visit, only keep files from given date\n    if date != None:\n        pattern = re.compile(r\"\\w+_(\\d{4}-\\d{2}-\\d{2})_\")\n        image_filenames = [file for file in image_filenames if date in file]\n    # Read the images into a list\n    images = [cv2.imread(str(root_dir / f)) for f in image_filenames]\n    # Convert the images to grayscale\n    gray_images = [rgb2gray(img) for img in images]\n    # Register all images to the first image\n    template = gray_images[0]\n    # Remove invalid images\n    final_images = [x for x in gray_images[1:] if x.shape == template.shape]\n    return final_images, template\n```", "```py\ndef evaluate_registration(template_img: np.ndarray, \n                          registered_imgs: List[np.ndarray]) -> (List[float], List[float], List[float]):\n    \"\"\"\n    Evaluate the registration quality of multiple registered images with respect to a template image.\n    \"\"\"\n    l1_losses = []\n    ncc_values = []\n    ssim_values = []\n\n    for registered_img in registered_imgs:\n        # Compute L1 loss between the template and registered images\n        l1_loss = np.mean(np.abs(template_img - registered_img))\n        l1_losses.append(l1_loss)\n\n        # Compute normalized cross-correlation between the template and registered images\n        ncc = np.corrcoef(template_img.ravel(), registered_img.ravel())[0,1]\n        ncc_values.append(ncc)\n\n        # Compute structural similarity index between the template and registered images\n        ssim_value = ssim(template_img, registered_img, data_range=registered_img.max() - registered_img.min())\n        ssim_values.append(ssim_value)\n\n    return l1_losses, ncc_values, ssim_values\n```", "```py\ndef visualise_registration_results(registered_images, original_images, template, loss_values):\n    num_images = min(len(registered_images), 3)\n    # Get the indices of the three images with the highest L1 losses\n    top_indices = np.argsort(loss_values)[-num_images:]\n    # Get the indices of the three images with the lowest L1 losses\n    bottom_indices = np.argsort(loss_values)[:num_images]\n    # Create the grid figure\n    fig, axes = plt.subplots(num_images, 4, figsize=(20, 15))\n    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n    # Loop through the top three images\n    for i, idx in enumerate(top_indices):\n        # Plot the original image in the first column of the left section\n        ax = axes[i][0]\n        ax.imshow(original_images[idx], cmap='gray')\n        original_l1 = np.mean(np.abs(template - original_images[idx]))\n        ax.set_title(\"Original Image (L1 Loss: {:.2f})\".format(original_l1))\n        # Plot the registered image in the second column of the left section\n        ax = axes[i][1]\n        ax.imshow(registered_images[idx], cmap='gray')\n        ax.set_title(\"Registered Image (L1 Loss: {:.2f})\".format(loss_values[idx]))\n    # Loop through the bottom three images\n    for i, idx in enumerate(bottom_indices):\n        # Plot the original image in the first column of the right section\n        ax = axes[i][2]\n        ax.imshow(original_images[idx], cmap='gray')\n        original_l1 = np.mean(np.abs(template - original_images[idx]))\n        ax.set_title(\"Original Image (L1 Loss: {:.2f})\".format(original_l1))\n        # Plot the registered image in the second column of the right section\n        ax = axes[i][3]\n        ax.imshow(registered_images[idx], cmap='gray')\n        ax.set_title(\"Registered Image (L1 Loss: {:.2f})\".format(loss_values[idx]))\n    # Show the grid\n    plt.show()\n```", "```py\ndef highlight_worse(val, comparison_column, worse_val, better_val):\n    color = better_val if val == worse_val else worse_val\n    return 'background-color: {}'.format(color)\n\ndef style_df(df_dict):\n    df = pd.DataFrame(df_dict)\n    for column in df.columns:\n        comparison_column = 'original' if column == 'registered' else 'registered'\n        worse_val = 'red'\n        better_val = 'green'\n        if column in ['ncc', 'ssim']:\n            worse_val, better_val = better_val, worse_val\n        df.style.apply(highlight_worse, axis=1, subset=[column], comparison_column=comparison_column, worse_val=worse_val, better_val=better_val)\n    return df\n\ndef summarise_registration(original_images, registered_images, template):\n\n    # Calculate metrics for original images\n    l1_losses, ncc_values, ssim_values = evaluate_registration(template, original_images)\n    l1_original, ncc_original, ssim_original = np.mean(l1_losses), np.mean(ncc_values), np.mean(ssim_values)\n\n    # Calculate metrics for registered images\n    l1_losses, ncc_values, ssim_values = evaluate_registration(template, registered_images)\n    l1_registered, ncc_registered, ssim_registered = np.mean(l1_losses), np.mean(ncc_values), np.mean(ssim_values)\n\n    # Create dataframe\n    df_dict = {'original': {'l1': l1_original, 'ncc': ncc_original, 'ssim': ssim_original}, \n               'registered': {'l1': l1_registered, 'ncc': ncc_registered, 'ssim': ssim_registered}}\n\n    return style_df(df_dict)\n```", "```py\nclass RegistrationAlgorithm:\n\n    def __init__(self, registration_function):\n        self.registration_function = registration_function\n        self.final_images, self.template = retrieve_images()\n        self.registered_images = self.apply_registration()\n\n    def apply_registration(self):\n        # Do the registration process\n        registered_images = []\n        for i, img in enumerate(tqdm(self.final_images)):\n            registered = self.registration_function(self.template, img) \n            registered_images.append(registered)\n        return registered_images\n\n    def evaluate(self, template_img, registered_imgs):\n        l1_losses = []\n        ncc_values = []\n        ssim_values = []\n\n        for registered_img in registered_imgs:\n\n            # Compute L1 loss between the template and registered images\n            l1_loss = np.mean(np.abs(template_img - registered_img))\n            l1_losses.append(l1_loss)\n\n            # Compute normalized cross-correlation between the template and registered images\n            ncc = np.corrcoef(template_img.ravel(), registered_img.ravel())[0,1]\n            ncc_values.append(ncc)\n\n            # Compute structural similarity index between the template and registered images\n            ssim_value = ssim(template_img, registered_img, data_range=registered_img.max() - registered_img.min())\n            ssim_values.append(ssim_value)\n\n        return l1_losses, ncc_values, ssim_values\n```", "```py\nimages, template = retrieve_images()\n```", "```py\n# calculate various distances\nl1_losses, ncc_values, ssim_values = evaluate_registration(template, images)\n\n# plot most and least similar images\nvisualise_registration_results(images, images, template, l1_losses)\n```", "```py\nplt.imshow(template, cmap=\"gray\");\n```", "```py\ndef calculate_total_rmse(images):\n    n = len(images)\n    sum_rmse = np.zeros(n)\n    for i in range(n):\n        for j in range(i+1, n):\n            rmse = np.sqrt(np.mean((images[i] - images[j])**2))\n            sum_rmse[i] += rmse\n            sum_rmse[j] += rmse\n    return sum_rmse\n\npatient_id = '123456'\nlaterality = 'L'\n# Set the root directory for the patient data\nroot_dir = Path(f'../data/{patient_id}')\n# Get the list of image filenames for the left eye\nimage_filenames = [f for f in os.listdir(root_dir) if f'{laterality}.png' in f]\n# Read the images into a list\nimages = [cv2.imread(str(root_dir / f)) for f in image_filenames]\n# Convert the images to grayscale\ngray_images = [rgb2gray(img) for img in images]\n# Remove invalid images\nfinal_images = [x for x in gray_images[1:] if x.shape == (768, 768)]\n# Calculate the RMSEs\nrmses = calculate_total_rmse(final_images)\n```", "```py\nimages = final_images\nsorted_indices = [i[0] for i in sorted(enumerate(rmses), key=lambda x:x[1])]\nfig, ax = plt.subplots(2, 2, figsize=(10, 10))\nfor i in range(4):\n    ax[i//2][i%2].imshow(images[sorted_indices[i]], cmap='gray')\n    ax[i//2][i%2].set_title(\"RMSE: {:.2f}\".format(rmses[sorted_indices[i]]))\n    ax[i//2][i%2].axis(\"off\")\nplt.show()\n```", "```py\n# Plot the histogram\nsns.set_style(\"whitegrid\")\nsns.displot(rmses, kde=False)\nplt.show()\nplt.rcdefaults()\n```", "```py\nplt.rcdefaults()\n\ndef get_best_images(images, rmses, num_images=10):\n    sorted_indices = sorted(range(len(rmses)), key=lambda x: rmses[x])\n    best_indices = sorted_indices[:num_images]\n    return [images[i] for i in best_indices]\nbest_images = get_best_images(images, rmses)\nav_img = np.mean(best_images, axis=0)\nplt.imshow(av_img, cmap='gray')\nplt.show()\n```", "```py\nnum_images_range = np.linspace(4, 36, 9, dtype=int)\nbest_images_list = []\nfor num_images in num_images_range:\n    best_images = get_best_images(images, rmses, num_images)\n    av_img = np.mean(best_images, axis=0)\n    best_images_list.append(av_img)\n\nfig, axs = plt.subplots(3, 3, figsize=(12,12))\nfor i, av_img in enumerate(best_images_list):\n    row, col = i//3, i%3\n    axs[row, col].imshow(av_img, cmap='gray')\n    axs[row, col].axis('off')\n    axs[row, col].set_title(f\"Best {num_images_range[i]} images\")\nplt.show()\n```", "```py\nimport SimpleITK as sitk\nimport numpy as np\n\ndef rigid(fixed_image, moving_image):\n    # Convert the input images to SimpleITK images\n    fixed_image = sitk.GetImageFromArray(fixed_image)\n    moving_image = sitk.GetImageFromArray(moving_image)\n    # Create a rigid registration method and set the initial transform to the identity\n    registration_method = sitk.ImageRegistrationMethod()\n    initial_transform = sitk.Euler2DTransform()\n    initial_transform.SetMatrix(np.eye(2).ravel())\n    initial_transform.SetTranslation([0, 0])\n    registration_method.SetInitialTransform(initial_transform)\n    # Set the number of iterations and the learning rate for the optimization\n    registration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100)\n    # Use mean squared error as the similarity metric\n    registration_method.SetMetricAsMeanSquares()\n    # Execute the registration\n    final_transform = registration_method.Execute(fixed_image, moving_image)\n    # Transform the moving image using the final transform\n    registered_image = sitk.Resample(moving_image, fixed_image, final_transform, sitk.sitkLinear, 0.0, moving_image.GetPixelIDValue())\n    # Convert the registered image back to a Numpy array\n    registered_image = sitk.GetArrayFromImage(registered_image)\n    return registered_image\n```", "```py\nopt = RegistrationAlgorithm(rigid)\nl1_losses, ncc_values, ssim_values = opt.evaluate(opt.template, opt.registered_images)\nprint(\"L1 losses:\", f\"{np.mean(l1_losses):.2f}\")\nprint(\"Normalized cross-correlation values:\", f\"{np.mean(ncc_values):.2f}\")\nprint(\"Structural similarity index values:\", f\"{np.mean(ssim_values):.2f}\")\n```", "```py\nL1 losses: 0.14\nNormalized cross-correlation values: 0.56\nStructural similarity index values: 0.55\n```", "```py\nimages, template = retrieve_images()\nsummarise_registration(images, opt.registered_images, template)\n```", "```py\nvisualise_registration_results(opt.registered_images, images, template, l1_losses)\n```", "```py\ndef evaluate_registration(template_img: np.ndarray, registered_imgs: List[np.ndarray]):\n    \"\"\"\n    Evaluate the registration quality of multiple registered images with respect to a template image.\n    \"\"\"\n    l1_losses = []\n    ncc_values = []\n    ssim_values = []\n    l1_losses_excl_black = []\n    ncc_values_excl_black = []\n    ssim_values_excl_black = []\n\n    for i, registered_img in enumerate(registered_imgs):\n\n        # Create mask of non-black pixels in original image\n        mask = (registered_img.ravel() != 0.0)\n\n        # Compute L1 loss between the template and registered images\n        l1_loss = np.mean(np.abs(template_img - registered_img))\n        l1_losses.append(l1_loss)\n\n        # Compute L1 loss between the template and registered images, excluding black pixels\n        l1_loss_excl_black = np.mean(np.abs(template_img.ravel()[mask] - registered_img.ravel()[mask]))\n        l1_losses_excl_black.append(l1_loss_excl_black)\n\n        # Compute normalized cross-correlation between the template and registered images\n        ncc = np.corrcoef(template_img.ravel(), registered_img.ravel())[0,1]\n        ncc_values.append(ncc)\n\n        # Compute normalized cross-correlation between the template and registered images, excluding black pixels\n        ncc_excl_black = np.corrcoef(template_img.ravel()[mask], registered_img.ravel()[mask])[0,1]\n        ncc_values_excl_black.append(ncc_excl_black)\n\n        # Compute structural similarity index between the template and registered images\n        ssim_value = ssim(template_img, registered_img, data_range=registered_img.max() - registered_img.min())\n        ssim_values.append(ssim_value)\n\n        # Compute structural similarity index between the template and registered images, excluding black pixels\n        ssim_value_excl_black = ssim(template_img.ravel()[mask], registered_img.ravel()[mask], \n                                     data_range=registered_img.ravel()[mask].max() - registered_img.ravel()[mask].min())\n        ssim_values_excl_black.append(ssim_value_excl_black)\n\n    return l1_losses, ncc_values, ssim_values, l1_losses_excl_black, ncc_values_excl_black, ssim_values_excl_black\n\ndef summarise_registration(original_images, registered_images, template):\n\n    # Calculate metrics for original images\n    l1_losses, ncc_values, ssim_values, l1_losses_black, ncc_values_black, ssim_values_black = evaluate_registration(template, original_images)\n    l1_original, ncc_original, ssim_original = np.mean(l1_losses), np.mean(ncc_values), np.mean(ssim_values)\n    l1_black_original, ncc_black_original, ssim_black_original = np.mean(l1_losses_black), np.mean(ncc_values_black), np.mean(ssim_values_black)\n\n    # Calculate metrics for registered images\n    l1_losses, ncc_values, ssim_values, l1_losses_black, ncc_values_black, ssim_values_black = evaluate_registration(template, registered_images)\n    l1_registered, ncc_registered, ssim_registered = np.mean(l1_losses), np.mean(ncc_values), np.mean(ssim_values)\n    l1_black_registered, ncc_black_registered, ssim_black_registered = np.mean(l1_losses_black), np.mean(ncc_values_black), np.mean(ssim_values_black)\n\n    # Create dataframe\n    df_dict = {'original': {'l1': l1_original, 'ncc': ncc_original, 'ssim': ssim_original,\n                            'l1_excl_black': l1_black_original, 'ncc_excl_black': ncc_black_original,\n                            'ssim_excl_black': ssim_black_original}, \n               'registered': {'l1': l1_registered, 'ncc': ncc_registered, 'ssim': ssim_registered,\n                              'l1_excl_black': l1_black_registered, 'ncc_excl_black': ncc_black_registered,\n                              'ssim_excl_black': ssim_black_registered}}\n\n    return style_df(df_dict)\n```", "```py\nimages, template = retrieve_images()\nsummarise_registration(images, opt.registered_images, template)\n```", "```py\n# --- Load the sequence\nimages, template = retrieve_images()\nimage0, image1 = images[0], template\n\n# --- Convert the images to gray level: color is not supported.\n#image0 = rgb2gray(image0)\n#image1 = rgb2gray(image1)\n# --- Compute the optical flow\nv, u = optical_flow_tvl1(image0, image1)\n# --- Use the estimated optical flow for registration\nnr, nc = image0.shape\nrow_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc),\n                                     indexing='ij')\nimage1_warp = warp(image1, np.array([row_coords + v, col_coords + u]),\n                   mode='edge')\n# build an RGB image with the unregistered sequence\nseq_im = np.zeros((nr, nc, 3))\nseq_im[..., 0] = image1\nseq_im[..., 1] = image0\nseq_im[..., 2] = image0\n# build an RGB image with the registered sequence\nreg_im = np.zeros((nr, nc, 3))\nreg_im[..., 0] = image1_warp\nreg_im[..., 1] = image0\nreg_im[..., 2] = image0\n# build an RGB image with the registered sequence\ntarget_im = np.zeros((nr, nc, 3))\ntarget_im[..., 0] = image0\ntarget_im[..., 1] = image0\ntarget_im[..., 2] = image0\n# --- Show the result\nfig, (ax0, ax1, ax2) = plt.subplots(3, 1, figsize=(5, 10))\nax0.imshow(seq_im)\nax0.set_title(\"Unregistered sequence\")\nax0.set_axis_off()\nax1.imshow(reg_im)\nax1.set_title(\"Registered sequence\")\nax1.set_axis_off()\nax2.imshow(target_im)\nax2.set_title(\"Target\")\nax2.set_axis_off()\nfig.tight_layout()\n```", "```py\n# --- Compute the optical flow\nv, u = optical_flow_ilk(image0, image1, radius=15)\n# --- Compute flow magnitude\nnorm = np.sqrt(u ** 2 + v ** 2)\n# --- Display\nfig, (ax0, ax1) = plt.subplots(1, 2, figsize=(8, 4))\n# --- Sequence image sample\nax0.imshow(image0, cmap='gray')\nax0.set_title(\"Sequence image sample\")\nax0.set_axis_off()\n# --- Quiver plot arguments\nnvec = 20  # Number of vectors to be displayed along each image dimension\nnl, nc = image0.shape\nstep = max(nl//nvec, nc//nvec)\ny, x = np.mgrid[:nl:step, :nc:step]\nu_ = u[::step, ::step]\nv_ = v[::step, ::step]\nax1.imshow(norm)\nax1.quiver(x, y, u_, v_, color='r', units='dots',\n           angles='xy', scale_units='xy', lw=3)\nax1.set_title(\"Optical flow magnitude and vector field\")\nax1.set_axis_off()\nfig.tight_layout()\nplt.show()\n```", "```py\ndef optical_flow(template, img):\n    # calculate the vector field for optical flow\n    v, u = optical_flow_tvl1(template, img)\n    # use the estimated optical flow for registration\n    nr, nc = template.shape\n    row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc),\n                                         indexing='ij')\n    registered = warp(img, np.array([row_coords + v, col_coords + u]), mode='edge')\n    return registered\n\nopt = RegistrationAlgorithm(optical_flow)\n```", "```py\nimages, template = retrieve_images()\nsummarise_registration(images, opt.registered_images, template).loc[['l1', 'ncc', 'ssim']]\n```", "```py\nimages, template = retrieve_images()\nvisualise_registration_results(opt.registered_images, images, template, l1_losses)\n```", "```py\nimport SimpleITK as sitk\nfrom IPython.display import clear_output\nfrom IPython.display import Image\n\nimages, template = retrieve_images()\nelastixImageFilter = sitk.ElastixImageFilter()\nelastixImageFilter.SetFixedImage(sitk.GetImageFromArray(images[0]))\nelastixImageFilter.SetMovingImage(sitk.GetImageFromArray(template))\nelastixImageFilter.SetParameterMap(sitk.GetDefaultParameterMap(\"rigid\"))\nelastixImageFilter.Execute()\nclear_output()\nsitk.WriteImage(elastixImageFilter.GetResultImage(), 'test.tif')\n# load image with SimpleITK\nsitk_image = sitk.ReadImage('test.tif')\n# convert to NumPy array\nim = sitk.GetArrayFromImage(sitk_image)\nplt.imshow(im, cmap='gray');\n```", "```py\ndef simple_elastix_rigid(image, template):\n    elastixImageFilter = sitk.ElastixImageFilter()\n    elastixImageFilter.SetFixedImage(sitk.GetImageFromArray(image))\n    elastixImageFilter.SetMovingImage(sitk.GetImageFromArray(template))\n    elastixImageFilter.SetParameterMap(sitk.GetDefaultParameterMap(\"rigid\"))\n    elastixImageFilter.Execute()\n    clear_output()\n    sitk.WriteImage(elastixImageFilter.GetResultImage(), 'reg.tif')\n    # load image with SimpleITK\n    sitk_image = sitk.ReadImage('reg.tif')\n    # convert to NumPy array\n    registered_img = sitk.GetArrayFromImage(sitk_image)\n    # delete the tif file\n    os.remove('reg.tif')\n    return registered_img\n```", "```py\n# retrieve images to be registered, and the image to register to\nimages, template = retrieve_images()\n\n# perform the registration using SimpleElastix\nopt = RegistrationAlgorithm(simple_elastix_rigid)\n```", "```py\nl1_losses, ncc_values, ssim_values = opt.evaluate(opt.template, opt.registered_images)\nvisualise_registration_results(opt.registered_images, images, template, l1_losses)\n```", "```py\nimages, template = retrieve_images()\nsummarise_registration(images, opt.registered_images, template)\n```", "```py\ndef simple_elastix_affine(image, template):\n    elastixImageFilter = sitk.ElastixImageFilter()\n    elastixImageFilter.SetFixedImage(sitk.GetImageFromArray(image))\n    elastixImageFilter.SetMovingImage(sitk.GetImageFromArray(template))\n    elastixImageFilter.SetParameterMap(sitk.GetDefaultParameterMap(\"affine\"))\n    elastixImageFilter.Execute()\n    clear_output()\n    sitk.WriteImage(elastixImageFilter.GetResultImage(), 'reg.tif')\n    # load image with SimpleITK\n    sitk_image = sitk.ReadImage('reg.tif')\n    # convert to NumPy array\n    registered_img = sitk.GetArrayFromImage(sitk_image)\n    # delete the tif file\n    os.remove('reg.tif')\n    return registered_img\n```", "```py\n# retrieve images to be registered, and the image to register to\nimages, template = retrieve_images()\n\n# perform the registration using SimpleElastix\nopt = RegistrationAlgorithm(simple_elastix_affine)\nl1_losses, ncc_values, ssim_values = opt.evaluate(opt.template, opt.registered_images)\nvisualise_registration_results(opt.registered_images, images, template, l1_losses\n```", "```py\nimages, template = retrieve_images()\nsummarise_registration(images, opt.registered_images, template)\n```", "```py\ndef simple_elastix_nonrigid(image, template):\n\n    # Initialise the filter, as well as fixed and moving images\n    elastixImageFilter = sitk.ElastixImageFilter()\n    elastixImageFilter.SetFixedImage(sitk.GetImageFromArray(image))\n    elastixImageFilter.SetMovingImage(sitk.GetImageFromArray(template))\n\n    # Setup the initialisation and transforms \n    parameterMapVector = sitk.VectorOfParameterMap()\n    parameterMapVector.append(sitk.GetDefaultParameterMap(\"affine\"))\n    parameterMapVector.append(sitk.GetDefaultParameterMap(\"bspline\"))\n    elastixImageFilter.SetParameterMap(parameterMapVector)\n\n    # Execute and save\n    elastixImageFilter.Execute()\n    clear_output()\n    sitk.WriteImage(elastixImageFilter.GetResultImage(), 'reg.tif')\n    # load image with SimpleITK\n    sitk_image = sitk.ReadImage('reg.tif')\n    # convert to NumPy array\n    registered_img = sitk.GetArrayFromImage(sitk_image)\n    # delete the tif file\n    os.remove('reg.tif')\n    return registered_img\n```", "```py\n# retrieve images to be registered, and the image to register to\nimages, template = retrieve_images()\n\n# perform the registration using SimpleElastix\nopt = RegistrationAlgorithm(simple_elastix_nonrigid)\nl1_losses, ncc_values, ssim_values = opt.evaluate(opt.template, opt.registered_images)\nvisualise_registration_results(opt.registered_images, images, template, l1_losses)\n```", "```py\nimages, template = retrieve_images()\nsummarise_registration(images, opt.registered_images, template)\n```", "```py\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n```", "```py\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n        # Spatial transformer localization-network\n        self.localization = nn.Sequential(\n            nn.Conv2d(1, 8, kernel_size=7),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True),\n            nn.Conv2d(8, 10, kernel_size=5),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True)\n        )\n        # Regressor for the 3 * 2 affine matrix\n        self.fc_loc = nn.Sequential(\n            nn.Linear(10 * 188 * 188, 32),\n            nn.ReLU(True),\n            nn.Linear(32, 3 * 2)\n        )\n        # Initialize the weights/bias with identity transformation\n        self.fc_loc[2].weight.data.zero_()\n        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n\n    # Spatial transformer network forward function\n    def stn(self, x):\n        xs = self.localization(x)\n        xs = xs.view(-1, 10 * 188 * 188)\n        theta = self.fc_loc(xs)\n        theta = theta.view(-1, 2, 3)\n        grid = F.affine_grid(theta, x.size())\n        x = F.grid_sample(x, grid)\n        return x\n    def forward(self, x):\n        # transform the input\n        x = self.stn(x)\n        return x\n\nmodel = Net().to(device)\n```", "```py\ndef voxelmorph_loss_2d(source, target, source_weight=1, target_weight=1, smoothness_weight=0.001):\n    def gradient(x):\n        d_dx = x[:, :-1, :-1] - x[:, 1:, :-1]\n        d_dy = x[:, :-1, :-1] - x[:, :-1, 1:]\n        return d_dx, d_dy\n\n    def gradient_penalty(x):\n        d_dx, d_dy = gradient(x)\n        return (d_dx.abs().mean() + d_dy.abs().mean()) * smoothness_weight\n\n    reconstruction_loss = (source - target).abs().mean() * target_weight\n    smoothness_penalty = gradient_penalty(target)\n    return reconstruction_loss + smoothness_penalty\n```", "```py\nclass FundusDataset(Dataset):\n    def __init__(self, image_list, target_image):\n        self.image_list = image_list\n        self.target_image = target_image\n\n    def __len__(self):\n            return len(self.image_list)\n\n    def __getitem__(self, idx):\n        image = self.image_list[idx]\n        image = torch.from_numpy(image).float()\n        return image, self.target_image\n\n# Load your list of Numpy arrays of training images\ntraining_images, template = retrieve_images()\ntemplate_image = torch.from_numpy(template).float()\n# Create the dataset\ndataset = FundusDataset(training_images, template_image)\n# Create the data loader\ntrain_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n```", "```py\noptimizer = optim.SGD(model.parameters(), lr=0.05)\ncriterion = voxelmorph_loss_2d #nn.L1Loss() #nn.MSELoss()\n\ndef train(epoch):\n    model.train()\n    batch_loss = 0\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        data = data.unsqueeze(1)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output.reshape(output.shape[0], 768, 768), target)\n        batch_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n    if epoch % 1 == 0:\n        avg_loss = batch_loss / len(train_loader)\n        print('Train Epoch: {}, Average Loss: {:.6f}'.format(epoch, avg_loss))\nfor epoch in range(1, 5 + 1):\n    train(epoch)\n```", "```py\ndef convert_image_np(inp):\n    \"\"\"Convert a Tensor to numpy image.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    return inp\n\n# We want to visualize the output of the spatial transformers layer\n# after the training, we visualize a batch of input images and\n# the corresponding transformed batch using STN.\n\ndef visualize_stn():\n    with torch.no_grad():\n        # Get a batch of training data\n        data = next(iter(train_loader))[0].to(device)\n        data = data.unsqueeze(1)\n        input_tensor = data.cpu()\n        transformed_input_tensor = model.stn(data).cpu()\n        in_grid = convert_image_np(\n            torchvision.utils.make_grid(input_tensor))\n        out_grid = convert_image_np(\n            torchvision.utils.make_grid(transformed_input_tensor))\n        # Plot the results side-by-side\n        f, axarr = plt.subplots(1, 2, figsize=(20,20))\n        axarr[0].imshow(in_grid, cmap='gray')\n        axarr[0].set_title('Dataset Images')\n        axarr[1].imshow(out_grid, cmap='gray')\n        axarr[1].set_title('Transformed Images')\n# Visualize the STN transformation on some input batch\nvisualize_stn()\nplt.ioff()\nplt.show()\n```", "```py\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport random\nimport torchvision.transforms as transforms\n\ndef image_augmentation(images, base_index=0, n_aug=5):\n    # Convert the NumPy arrays to Pillow Image objects\n    items = [Image.fromarray(image).convert(\"RGBA\") for image in images]\n    # Define the image transformation pipeline\n    transform = transforms.Compose([\n        transforms.Resize(460),\n        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2),\n                                scale=(0.9, 1.1), shear=0,\n                                fillcolor=(128, 128, 128, 255)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n    # Generate the augmented images\n    new_items = []\n    for i in range(n_aug):\n        # Get the base image\n        base_item = items[base_index]\n        base_image = np.array(base_item)\n        # Apply the random transforms to the base image\n        transformed_item = transform(base_item)\n        # Convert the transformed image to a NumPy array and add it to the list of augmented images\n        transformed_image = np.transpose(transformed_item.numpy(), (1, 2, 0))\n        transformed_image = cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR)\n        new_items.append(transformed_image)\n    # Convert the augmented data back to NumPy arrays\n    new_images = [np.array(image) for image in new_items]\n    return new_images\n```", "```py\nfrom sklearn.cluster import KMeans\n\n# Assume you have a list of images stored as numpy arrays in a variable called \"images\"\nimages, template = retrieve_images()\n# Convert the list of images to a 2D numpy array\ndata = np.array(images)\nn_samples, height, width = data.shape\ndata = data.reshape(n_samples, height * width)\n# Set up an empty list to hold the within-cluster sum of squares (WCSS) values for each value of k\nwcss_values = []\n# Set up a range of values for k\nk_values = range(1, 11)\n# Loop over the values of k and fit a k-means model for each value\nfor k in k_values:\n    kmeans = KMeans(n_clusters=k, random_state=0)\n    kmeans.fit(data)\n\n    # Calculate the within-cluster sum of squares (WCSS)\n    wcss = kmeans.inertia_\n    wcss_values.append(wcss)\n\n# Plot the WCSS values against the number of clusters\nfig, ax = plt.subplots()\nax.plot(k_values, wcss_values, 'bo-')\nax.set_xlabel('Number of clusters (k)')\nax.set_ylabel('Within-cluster sum of squares (WCSS)')\nax.set_title('Elbow Plot')\nplt.show()\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import NearestNeighbors\n\n# Assume you have a list of images stored as NumPy arrays in a variable called \"images\"\nimages, template = retrieve_images()\n# First, flatten each image into a 1D array\nimage_vectors = np.array([image.flatten() for image in images])\n# Use k-means to cluster the image vectors\nkmeans = KMeans(n_clusters=3, random_state=0).fit(image_vectors)\ncluster_labels = kmeans.labels_\n# Use k-nearest neighbors to find the nearest images to each centroid\nn_neighbors = 5\nnn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(image_vectors)\ndistances, indices = nn.kneighbors(kmeans.cluster_centers_)\n# Plot the nearest images to each centroid\nfig, axs = plt.subplots(kmeans.n_clusters, n_neighbors, figsize=(15, 15))\nfor i in range(kmeans.n_clusters):\n    for j in range(n_neighbors):\n        axs[i][j].imshow(images[indices[i][j]], cmap='gray')\n        axs[i][j].axis('off')\n        axs[i][j].set_title(f\"Cluster {i}, Neighbor {j+1}\")\nplt.show()\n# Store the cluster labels and image labels in a dictionary\nlabels_dict = {}\nfor i in range(len(images)):\n    labels_dict[i] = {\"cluster_label\": cluster_labels[i]}\n```", "```py\n# Assume you have a list of images stored as NumPy arrays in a variable called \"images\"\nimages, template = retrieve_images()\n\n# First, flatten each image into a 1D array\nimage_vectors = np.array([image.flatten() for image in images])\n\n# Use k-means to cluster the image vectors\nkmeans = KMeans(n_clusters=3, random_state=0).fit(image_vectors)\ncluster_labels = kmeans.labels_\n\n# Use k-nearest neighbors to find the nearest images to each centroid\nn_neighbors = 5\nnn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(image_vectors)\ndistances, indices = nn.kneighbors(kmeans.cluster_centers_)\n\n# Store the images in each cluster\ncluster_0_images = []\ncluster_1_images = []\ncluster_2_images = []\nfor i, cluster_label in enumerate(cluster_labels):\n    if cluster_label == 0:\n        cluster_0_images.append(images[i])\n    elif cluster_label == 1:\n        cluster_1_images.append(images[i])\n    else:\n        cluster_2_images.append(images[i])\n\n# Print the number of images in each cluster\nprint(f\"Number of images in cluster 0: {len(cluster_0_images)}\")\nprint(f\"Number of images in cluster 1: {len(cluster_1_images)}\")\nprint(f\"Number of images in cluster 2: {len(cluster_2_images)}\")\n```", "```py\nNumber of images in cluster 0: 38\nNumber of images in cluster 1: 31\nNumber of images in cluster 2: 32\n```", "```py\ntrained_models = {}\n\nfor i, cluster_images in enumerate([cluster_0_images, cluster_1_images, cluster_2_images]):\n    # load the spatial transformer network\n    model = Net().to(device)\n    template_image = torch.from_numpy(template).float()\n    # Create the dataset\n    dataset = FundusDataset(cluster_images, template_image)\n    # Create the data loader\n    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n    optimizer = optim.SGD(model.parameters(), lr=0.05)\n    criterion = voxelmorph_loss_2d\n\n    print(f\"TRAINING CLUSTER {i}\")\n    print(\"-\"*50)\n    for epoch in range(1, 5 + 1):\n        train(epoch)\n\n    trained_models[f\"cluster_{i}_model\"] = model\n    print(\" \")\n```", "```py\nTRAINING CLUSTER 0\n--------------------------------------------------\nTrain Epoch: 1, Average Loss: 0.122363\nTrain Epoch: 2, Average Loss: 0.120482\nTrain Epoch: 3, Average Loss: 0.117854\nTrain Epoch: 4, Average Loss: 0.112581\nTrain Epoch: 5, Average Loss: 0.119771\n\nTRAINING CLUSTER 1\n--------------------------------------------------\nTrain Epoch: 1, Average Loss: 0.079963\nTrain Epoch: 2, Average Loss: 0.080274\nTrain Epoch: 3, Average Loss: 0.077222\nTrain Epoch: 4, Average Loss: 0.076657\nTrain Epoch: 5, Average Loss: 0.077101\n\nTRAINING CLUSTER 2\n--------------------------------------------------\nTrain Epoch: 1, Average Loss: 0.172036\nTrain Epoch: 2, Average Loss: 0.171105\nTrain Epoch: 3, Average Loss: 0.170653\nTrain Epoch: 4, Average Loss: 0.170199\nTrain Epoch: 5, Average Loss: 0.169759\n```"]