- en: The Two Faces of AI Alignment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI对齐的双重面貌
- en: 原文：[https://towardsdatascience.com/the-two-faces-of-ai-alignment-e58b0c11cc01](https://towardsdatascience.com/the-two-faces-of-ai-alignment-e58b0c11cc01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-two-faces-of-ai-alignment-e58b0c11cc01](https://towardsdatascience.com/the-two-faces-of-ai-alignment-e58b0c11cc01)
- en: Misaligned Models and Misaligned Agents
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不对齐的模型与不对齐的代理
- en: '[](https://medium.com/@maxhilsdorf?source=post_page-----e58b0c11cc01--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----e58b0c11cc01--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e58b0c11cc01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e58b0c11cc01--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----e58b0c11cc01--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maxhilsdorf?source=post_page-----e58b0c11cc01--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----e58b0c11cc01--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e58b0c11cc01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e58b0c11cc01--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----e58b0c11cc01--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e58b0c11cc01--------------------------------)
    ·12 min read·Jul 18, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----e58b0c11cc01--------------------------------)
    ·12分钟阅读·2023年7月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/95518eb41d8df5b41fc07d61b3b3ce53.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/95518eb41d8df5b41fc07d61b3b3ce53.png)'
- en: Image adapted from [Tara Winstead](https://www.pexels.com/de-de/foto/hande-verbindung-zukunft-roboter-8386434/).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片改编自[Tara Winstead](https://www.pexels.com/de-de/foto/hande-verbindung-zukunft-roboter-8386434/)。
- en: What is AI Alignment?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是AI对齐？
- en: Artificial Intelligence (AI) is no longer just a buzzword; it is a rapidly evolving
    field where intelligent systems are becoming increasingly integrated into our
    daily lives. From recommendation algorithms on Netflix to automating creative
    workflows with ChatGPT or Midjourney, AI is transforming various aspects of our
    world. However, this remarkable progress also presents significant challenges,
    with AI alignment being one of the most critical issues to address.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）不再只是一个流行词；它是一个快速发展的领域，其中智能系统正变得越来越融入我们的日常生活。从Netflix上的推荐算法到利用ChatGPT或Midjourney自动化创意工作流程，AI正在改变我们世界的各个方面。然而，这一显著进展也带来了重大挑战，其中AI对齐是最需要解决的关键问题之一。
- en: AI alignment is the process of ensuring that AI systems operate in a way that
    aligns with what humans consider desirable behavior. It’s like trying to teach
    a toddler to behave appropriately — just as you’d want the child to understand
    and respect your values, we need to hold AI systems to the same standard. However,
    as it turns out, we’re not always as good at this task as we think — neither for
    toddlers, nor for AIs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: AI对齐是确保AI系统以符合人类认为可取行为的方式操作的过程。这就像试图教一个幼儿如何适当地行为——正如你希望孩子理解并尊重你的价值观一样，我们也需要对AI系统保持同样的标准。然而，事实证明，我们在这项任务上并不像我们认为的那么擅长——无论是对幼儿还是对AI。
- en: AI Alignment in the Current Discourse
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前话语中的AI对齐
- en: Generative AI models like ChatGPT or Midjourney have been caught generating
    biased, offensive, or harmful content. These systems learn from the data they
    are fed, and if this data contains biases or harmful patterns, the system may
    unwittingly replicate them. The same applies to self-driving cars. While they
    hold the potential to save lives by reducing accidents caused by human error,
    there are some major ethical hurdles to overcome before we put the lives of ourselves
    and our loved ones into an AI’s hands.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型如ChatGPT或Midjourney被发现生成了有偏见、冒犯性或有害的内容。这些系统从它们接收到的数据中学习，如果这些数据包含偏见或有害的模式，系统可能会不自觉地复制这些模式。自驾车也是如此。虽然它们有可能通过减少人为错误造成的事故来挽救生命，但在我们把自己和亲人的生命交到AI手中之前，还有一些主要的伦理障碍需要克服。
- en: AI alignment is even more critical in the discourse about the potential threat
    of AI achieving artificial general intelligence (AGI), i.e., human-like intelligence
    generalizable to any kind of task. Just one year ago, AGI seemed like an unattainable
    sci-fi story to most data scientists, including me. Now, here we are, only a few
    months after the release of ChatGPT, with accomplished AI figures [leaving big
    tech research teams](https://apnews.com/article/ai-godfather-google-geoffery-hinton-fa98c6a6fddab1d7c27560f6fcbad0ad),
    [testifying for AI regulation in front of the U.S. Senate](https://www.youtube.com/watch?v=TO0J2Yw7usM),
    or [speaking up for a 6-month halt](https://www.dw.com/en/tech-experts-call-for-6-month-pause-on-ai-development/a-65174081)
    in the development of new AI systems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在关于人工智能可能实现人工通用智能（AGI）——即可以推广到任何任务的人类般智能——的潜在威胁的讨论中，AI对齐变得更加关键。仅仅一年前，AGI对大多数数据科学家，包括我在内，似乎还只是一个难以实现的科幻故事。现在，几个月后，在ChatGPT发布之后，我们已经看到一些杰出的AI人物[离开大型科技公司研究团队](https://apnews.com/article/ai-godfather-google-geoffery-hinton-fa98c6a6fddab1d7c27560f6fcbad0ad)、[在美国参议院面前作证呼吁AI监管](https://www.youtube.com/watch?v=TO0J2Yw7usM)，或者[呼吁对AI系统的发展暂停6个月](https://www.dw.com/en/tech-experts-call-for-6-month-pause-on-ai-development/a-65174081)。
- en: Whatever opinion you may have about these figures or their arguments, it seems
    inevitable to delve deeper into the topic of AI alignment. In this post, I argue
    that concerns about AI alignment need to be addressed from two different angles.
    Misalignment can affect either an AI model itself or an agent developed on the
    basis of an AI model. These two types of misalignment have drastically different
    implications and risks that require different strategies to overcome.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你对这些人物或他们的论点有何看法，深入探讨AI对齐的话题似乎是不可避免的。在这篇文章中，我认为对AI对齐的关注需要从两个不同的角度来解决。不对齐可能影响到AI模型本身或基于AI模型开发的代理。这两种类型的不对齐具有截然不同的影响和风险，需要不同的策略来克服。
- en: Misaligned Models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不对齐的模型
- en: A misaligned model occurs when an AI system’s understanding of the world is
    not in sync with reality. It’s like a GPS system that has outdated maps — it may
    lead you down a road that no longer exists or miss a new, more efficient route.
    This could happen if the AI is trained on inaccurate, incomplete, or outdated
    data. For example, a medical diagnosis AI trained mostly on data from male patients
    might struggle to accurately diagnose diseases in women.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当AI系统对世界的理解与现实不一致时，就会出现不对齐的模型。这就像一个地图过时的GPS系统——它可能会把你带到一条已经不存在的道路上，或者错过一条更新、更高效的路线。如果AI是在不准确、不完整或过时的数据上训练的，就可能发生这种情况。例如，一个主要基于男性患者数据训练的医疗诊断AI可能在准确诊断女性疾病时遇到困难。
- en: Misaligned Agents
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不对齐的代理
- en: Misaligned agents are AI systems that take actions not aligned with human values
    or goals. It’s like a well-trained dog that fetches the newspaper every morning
    but chews it up before you can read it. The dog is doing what it was trained to
    do (fetch the newspaper), but the outcome is not what you want. It’s a misaligned
    agent.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不对齐的代理是指那些采取的行动与人类价值观或目标不一致的AI系统。这就像一只训练有素的狗，每天早上都能捡到报纸，但在你阅读之前却咬碎了报纸。狗做了它被训练去做的事（捡报纸），但结果却不是你想要的。这就是一个不对齐的代理。
- en: Why the Distinction Matters
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么区分很重要
- en: It’s important to distinguish between misaligned models and misaligned agents
    because both require different methods for detecting and addressing misalignment.
    To illustrate this, suppose you ask ChatGPT a question, and it generates an incorrect
    fact, i.e., “hallucinates,” to answer your question. I would argue that at the
    core of this issue lies both a misaligned model and a misaligned agent.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 区分不对齐的模型和不对齐的代理是重要的，因为这两者需要不同的方法来检测和解决不对齐问题。为了说明这一点，假设你问ChatGPT一个问题，它生成了一个不正确的事实，即“幻觉”，来回答你的问题。我认为这个问题的核心既包括不对齐的模型，也包括不对齐的代理。
- en: If ChatGPT is a misaligned model, it makes errors due to a lack of information
    or a misinterpretation of observations made about the real world. We know that
    hallucination usually occurs when ChatGPT is asked very specific questions that
    may not have prominent answers in its training data. If ChatGPT hallucinates due
    to a lack of knowledge, it is clearly an issue with the misalignment of the model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果ChatGPT是一个不对齐的模型，它会因缺乏信息或误解对现实世界的观察而犯错。我们知道，当ChatGPT被问到非常具体的问题，而这些问题在其训练数据中可能没有显著答案时，通常会发生幻觉。如果ChatGPT因缺乏知识而产生幻觉，这显然是模型不对齐的问题。
- en: However, there is more to consider. If ChatGPT doesn’t know the answer to a
    question, hallucination is not the only possible response. It would be much better
    for the user if ChatGPT stated that it cannot answer the question due to a lack
    of knowledge. It can be presumed that ChatGPT’s tendency to wildly hallucinate
    can be partially attributed to its training process, where it was trained to provide
    answers perceived as helpful by the end user, but not necessarily truthful. In
    other words, ChatGPT simply doesn’t prioritize being truthful. If that is the
    case, it is a clear case of a misaligned agent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有更多需要考虑的因素。如果ChatGPT不知道某个问题的答案，幻觉并不是唯一的可能回应。对用户来说，ChatGPT声明由于缺乏知识无法回答问题要好得多。可以推测，ChatGPT的疯狂幻觉倾向部分可以归因于其训练过程，在训练过程中，它被训练成提供被最终用户认为有用的答案，但不一定是真实的。换句话说，ChatGPT根本不优先考虑真实。如果是这样，那就是一个明显的对齐失调问题。
- en: Now that we have seen that even a single incident of misalignment between AI
    and humans can reveal both kinds of misalignment, let’s discuss what we can or
    cannot do to address these problems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到即使是AI与人类之间的一次对齐失调事件也能揭示两种对齐失调的问题，让我们讨论一下我们可以或不能做些什么来解决这些问题。
- en: How We Can Address Misaligned Models
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们如何解决对齐失调的模型
- en: Detecting Misaligned Models
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测对齐失调的模型
- en: To detect a misaligned model, we need methods that make the behavior and flaws
    of the model transparent. One common approach for this is to conduct an extensive
    qualitative and quantitative evaluation of the model to detect flaws in its decision-making.
    Through this process, you can assess not only the model’s accuracy but also check
    whether the model is biased toward or less accurate for certain minorities. For
    deeper insights, Explainable AI methods can be employed to enhance the interpretability
    and transparency of the AI system, allowing for a better understanding of its
    inner workings.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测对齐失调的模型，我们需要使模型的行为和缺陷透明化的一些方法。一种常见的方法是对模型进行广泛的定性和定量评估，以检测其决策中的缺陷。通过这个过程，你可以评估模型的准确性，还可以检查模型是否对某些少数群体存在偏见或准确性较低。为了获得更深入的见解，可以采用可解释AI方法来增强AI系统的可解释性和透明性，从而更好地理解其内部运作。
- en: Data Quality
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据质量
- en: Once we detect hints of misalignment in the model, we can attempt to address
    this by crafting a more diverse and accurate training dataset. For instance, if
    a recruiting AI discriminates against women, we can adjust the training data to
    ensure that women are no longer underrepresented. However, tackling the misalignment
    issue when ChatGPT generates “hallucinations” or made-up facts is much more challenging.
    While we could address specific untruthful statements by fine-tuning ChatGPT with
    accurate texts about the relevant topic in the training data, this would only
    solve the misalignment for that particular topic. It would not solve the problem
    of hallucination as a whole.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们检测到模型中的对齐问题，我们可以尝试通过制作更加多样化和准确的训练数据集来解决。例如，如果招聘AI对女性存在歧视，我们可以调整训练数据，以确保女性不再被低估。然而，当ChatGPT生成“幻觉”或虚构的事实时，解决对齐问题要困难得多。虽然我们可以通过用关于相关主题的准确文本微调ChatGPT来解决特定的不真实陈述，但这只能解决该特定主题的对齐问题，并不能解决整体的幻觉问题。
- en: Transparency
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 透明性
- en: Addressing misaligned models on a larger scale involves rethinking the current
    machine learning paradigm, which often relies on teaching large black box models
    to identify correlations between features in the training data. Black box models
    pose challenges because assessing the alignment of a model based solely on its
    outputs is difficult. If ChatGPT were capable of truthfully and reliably communicating
    the facts it used and how it combined them to reach its conclusions, it would
    be much easier to verify its alignment with truth and human values.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在更大范围内解决对齐失调的模型涉及重新思考当前的机器学习范式，这通常依赖于教大型黑箱模型识别训练数据中特征之间的关联。黑箱模型带来了挑战，因为仅仅基于其输出评估模型的对齐性是困难的。如果ChatGPT能够真实可靠地传达它使用的事实及其如何将这些事实结合起来得出结论，那么验证其与真实和人类价值观的一致性将变得容易得多。
- en: Causality
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因果关系
- en: Another issue is that most state-of-the-art AI models lack the ability to think
    causally. Their functioning is based on learning correlations between features
    in the training data, which is fundamentally different from how humans think.
    For example, when it’s hot outside and we get sunburnt, we understand that the
    sun is the cause of the burn. An AI typically doesn’t distinguish between whether
    the sun causes the burn or the burn causes the sun. Surprisingly, AI systems can
    reliably solve complex problems without this kind of causal awareness. However,
    I would argue that a model lacking causal thinking can never fully comprehend
    the underlying mechanisms of the world, thus remaining inevitably misaligned.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，大多数先进的 AI 模型缺乏因果思维能力。它们的运作基于学习训练数据中特征之间的相关性，这与人类的思维方式根本不同。例如，当外面很热，我们晒伤了，我们知道阳光是导致晒伤的原因。AI
    通常不会区分是阳光导致了晒伤还是晒伤导致了阳光。令人惊讶的是，AI 系统能够可靠地解决复杂问题，而没有这种因果意识。然而，我认为一个缺乏因果思维的模型永远无法完全理解世界的潜在机制，因此不可避免地会出现不对齐。
- en: How to Address Misaligned Agents
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何解决不对齐的代理
- en: Detecting Misaligned Agents
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测不对齐的代理
- en: 'The difficulty of detecting misaligned agents can vary significantly. An illustrative
    example is when OpenAI researchers trained an AI to play the boat racing game
    “Coast Runner,” with the goal of maximizing the number of points collected. After
    a few days, they were astonished to find that the boat had completely ignored
    the race and instead circled around three “turbo” power-ups. The reason was clear:
    the power-ups appeared to yield more points than finishing the race.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 检测不对齐的代理的难度可以大相径庭。一个说明性例子是，当 OpenAI 研究人员训练一个 AI 玩船只竞速游戏“Coast Runner”时，目标是最大化收集到的积分。几天后，他们惊讶地发现这艘船完全忽略了比赛，而是绕着三个“加速”道具旋转。原因很明显：这些道具似乎能获得比完成比赛更多的积分。
- en: '![](../Images/c57b5a9ff3856e1f02196ae0233cc7e7.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c57b5a9ff3856e1f02196ae0233cc7e7.png)'
- en: Misaligned agent in “Coast Runner”. Screenshot from [this video](https://www.youtube.com/watch?v=tlOIHko8ySg).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: “Coast Runner”中的不对齐代理。截屏来自[这个视频](https://www.youtube.com/watch?v=tlOIHko8ySg)。
- en: However, not all cases of misaligned agents are as obvious. The challenge lies
    in the fact that, as long as we primarily deal with black-box models, we cannot
    fully understand or trust their intentions and values. Often, our understanding
    is derived from the training data, the reward/loss function the model optimizes,
    and qualitative evaluation post-training. Nonetheless, as AI systems grow increasingly
    powerful, even minor misalignments can lead to significant real-world harm. The
    truth is that we are still far from reliably detecting or preventing misalignment
    in AI agents.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有不对齐的代理情况都那么明显。挑战在于，只要我们主要处理黑箱模型，就无法完全理解或信任它们的意图和价值观。通常，我们的理解来源于训练数据、模型优化的奖励/损失函数以及训练后定性评估。然而，随着
    AI 系统变得越来越强大，即使是微小的不对齐也可能导致严重的现实世界危害。事实是，我们仍然远未可靠地检测或防止 AI 代理的不对齐。
- en: Why this Problem is so Hard to Tackle
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么这个问题如此难以解决
- en: 'Addressing misaligned agents is a complex task that requires a nuanced understanding
    of values and consequences. There are two main reasons why this challenge is particularly
    difficult:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 解决不对齐的代理是一项复杂的任务，需要对价值观和后果有细致的理解。这个挑战特别困难的两个主要原因是：
- en: Specifying human values in a manner that an AI system can comprehend and incorporate
    is a challenging endeavor.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以 AI 系统能够理解和纳入的方式指定人类价值观是一项具有挑战性的工作。
- en: Humans exhibit a wide range of diverse values, and there is no universal set
    of values that every individual subscribes to.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人类表现出广泛的多样化价值观，没有一个普遍适用的价值观集合能够满足每个人。
- en: Consequently, not only do we lack a clear consensus on how to teach an AI system
    to adhere to a specific set of values, but we also struggle to agree on which
    values should be imparted. As a result, AI systems need to be designed in a way
    that allows for the adoption of different value sets, ensuring alignment with
    the diverse range of users worldwide.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不仅缺乏明确的共识来教导 AI 系统遵循特定的价值观，而且对应该传达哪些价值观也存在分歧。因此，AI 系统需要以一种允许采纳不同价值观的方式进行设计，以确保与全球用户的多样化需求对齐。
- en: Reinforcement-Learning with Human Feedback (RLHF)
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有人类反馈的强化学习（RLHF）
- en: One explanation for the misalignment of an agent is exemplified by the well-known
    paperclip maximizer problem. Consider training an AI with the sole objective of
    maximizing paperclip production. As it becomes more competent at this task, it
    may view humans as obstacles to its objective. Humans could potentially turn it
    off, resulting in fewer paperclips. More importantly, humans are made of atoms,
    which can be used to produce even more paperclips.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一个代理不一致的解释可以通过著名的回形针最大化器问题来说明。考虑训练一个 AI，其唯一目标是最大化回形针的生产。随着其在这一任务上的能力增强，它可能会将人类视为其目标的障碍。人类可能会关闭它，从而减少回形针的数量。更重要的是，人类由原子构成，这些原子可以用来生产更多的回形针。
- en: Reinforcement-Learning with Human Feedback (RLHF) aims to address this problem
    by linking the AI’s objective to its friendliness toward humans. Let’s take ChatGPT
    as an example, which was also trained using RLHF. OpenAI had thousands of humans
    rank ChatGPT’s outputs based on their perceived “helpfulness.” They then trained
    an AI model, ironically, to take on the role of the human raters by learning from
    their responses. ChatGPT was subsequently trained to produce outputs that the
    (non-human) ranking AI would deem helpful.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 人工反馈强化学习（RLHF）旨在通过将 AI 的目标与其对人类的友好度联系起来来解决这个问题。以 ChatGPT 为例，它也是通过 RLHF 进行训练的。OpenAI
    让成千上万的人根据他们认为的“帮助程度”来排名 ChatGPT 的输出。然后，他们训练了一个 AI 模型，讽刺的是，这个模型扮演了人类评分者的角色，从他们的回应中学习。随后，ChatGPT
    被训练为产生被（非人类）排名 AI 认为有帮助的输出。
- en: 'RLHF is not without its flaws. Even when executed perfectly, it still faces
    the challenge that there is no universally agreed-upon value system among humans.
    One potential solution is to utilize RLHF to train AI models that are specifically
    tailored to a particular target group, such as a specific country or culture.
    However, there is another method for customizing an AI’s value system to specific
    needs: the system message.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: RLHF 并非没有缺陷。即使执行得再完美，它仍面临一个挑战：人类之间没有普遍认同的价值体系。一个潜在的解决方案是利用 RLHF 训练专门针对特定目标群体的
    AI 模型，例如某个特定国家或文化。然而，还有另一种方法可以定制 AI 的价值体系以满足特定需求：系统消息。
- en: The System Message
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统消息
- en: Did you know that ChatGPT doesn’t show you everything that is in its prompt?
    If you have ever used the ChatGPT web app through the OpenAI API, you have probably
    already experimented with the system message. The system message is a part of
    the prompt that is positioned at the beginning of the conversation history and
    typically not disclosed to the user. The default system message on the OpenAI
    website is “You are a helpful assistant.” It’s interesting to observe the changes
    when I inform ChatGPT that it is Donald Duck and deeply in love with his girlfriend,
    Daisy.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道 ChatGPT 不会向你展示其提示中的所有内容吗？如果你曾通过 OpenAI API 使用 ChatGPT 网络应用程序，你可能已经实验过系统消息。系统消息是对话历史开头的一部分，通常不会透露给用户。OpenAI
    网站上的默认系统消息是“你是一个有帮助的助手。”当我告诉 ChatGPT 它是唐老鸭并深深爱着他的女朋友黛丝时，观察到的变化很有趣。
- en: '![](../Images/61dc8b1087d957cbeb11bf6d09f2f3c0.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61dc8b1087d957cbeb11bf6d09f2f3c0.png)'
- en: Example how how the system message can be used to control the AI’s outputs.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 示例如何使用系统消息来控制 AI 的输出。
- en: While the system message is great for generating amusing conversations, it also
    serves as a powerful alignment tool. For instance, when I asked ChatGPT about
    its preference between beer and wine, using the system message “You are a German”
    resulted in a clear preference for beer, while the message “You are a Frenchman”
    led to a favoring of wine. As a German, I cannot deny that the former ChatGPT
    variant is more aligned with my personal beliefs. Beyond this trivial example,
    these two distinct ChatGPT “personalities” would likely respond differently to
    important political or ethical questions as well.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然系统消息非常适合生成有趣的对话，但它也作为一个强大的对齐工具。例如，当我询问 ChatGPT 对啤酒和葡萄酒的偏好时，使用系统消息“你是一个德国人”导致了明显的啤酒偏好，而消息“你是一个法国人”则偏向于葡萄酒。作为一个德国人，我不能否认前者的
    ChatGPT 变体更符合我的个人信念。除了这个琐碎的例子，这两种不同的 ChatGPT “个性”在面对重要的政治或伦理问题时也可能会有不同的回应。
- en: In Lex Fridman’s [interview](https://www.youtube.com/watch?v=L_Guz73e6fw) with
    Sam Altman, the CEO of OpenAI, Altman mentioned that GPT-4 was trained with a
    greater focus on the impact of the system message compared to GPT-3.5\. Additionally,
    he believes that leveraging the system message to tailor AI responses is a more
    effective solution for addressing alignment issues than training separate large
    models for different cultures or value systems. However, it is not surprising
    to hear the CEO of OpenAI recommend utilizing their models instead of building
    your own.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在Lex Fridman的[采访](https://www.youtube.com/watch?v=L_Guz73e6fw)中，OpenAI的首席执行官Sam
    Altman提到，相较于GPT-3.5，GPT-4在系统消息的影响方面有了更多的关注。此外，他认为利用系统消息来定制AI的回应是解决对齐问题的比训练不同文化或价值体系的大型模型更有效的方案。然而，听到OpenAI的首席执行官推荐使用他们的模型而不是自己构建模型，并不令人意外。
- en: Uncertainty-Awareness
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不确定性意识
- en: If you were to ask me to provide you with 10 fun facts about Michael Jackson,
    I would probably tell you that I don’t feel confident giving you this answer due
    to my limited knowledge on the topic. However, ChatGPT, in contrast, can respond
    to a question it doesn’t know the answer to with the same level of confidence
    and persuasiveness as it would to a simple question. In my view, this fundamental
    characteristic makes ChatGPT a misaligned agent.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你让我提供关于迈克尔·杰克逊的10个有趣的事实，我可能会告诉你，由于我对这个话题了解有限，我不确定能否给出答案。然而，相比之下，ChatGPT可以以与简单问题相同的自信和说服力回答它不知道答案的问题。在我看来，这一基本特征使得ChatGPT成为一个不对齐的代理。
- en: To understand this, let’s review how ChatGPT was trained. During the RLHF stage,
    the model is encouraged to generate responses that sound helpful to the (non-human)
    ranking system. However, this system does not consider the accuracy of the answers,
    but only their perceived helpfulness. Consequently, ChatGPT may respond with unwarranted
    confidence in order to appear more helpful, even when its knowledge or facts are
    incorrect.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，让我们回顾一下ChatGPT是如何训练的。在RLHF阶段，模型被鼓励生成对（非人类）排名系统听起来有帮助的回应。然而，这个系统并不考虑答案的准确性，只考虑其感知的有用性。因此，ChatGPT可能会以不必要的自信回应，以显得更有帮助，即使其知识或事实是错误的。
- en: To qualify as a misaligned agent, a model must pursue objectives that are not
    aligned with human goals or values. It is evident that ChatGPT prioritizes appearing
    confident over being truthful. This represents an obvious and concerning case
    of misalignment. Building complex AI systems that are uncertainty-aware is not
    an easy task, but if we aim to collaborate effectively with AI systems, it is
    crucial to teach them to recognize and communicate their uncertainty about the
    accuracy of their responses.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要成为一个不对齐的代理，模型必须追求与人类目标或价值观不一致的目标。显然，ChatGPT更注重表现出自信，而不是诚实。这代表了一个明显且令人担忧的不对齐案例。构建具备不确定性意识的复杂AI系统并非易事，但如果我们希望与AI系统有效合作，教会它们识别并传达对其回应准确性的疑虑是至关重要的。
- en: Future Perspectives
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来展望
- en: 'Are we truly ready for the AI transformation? I think that the answer to this
    question is strongly connected to our ability to build aligned AI systems. As
    we let AI deeper and deeper into our lives, jobs, and economies, our claim should
    be to make it safer along the way. However, it is not clear to me that this has
    been happening in the last 10 years. Of course, people are shocked when they find
    out that a recruitment system discriminates against women or that ChatGPT hallucinates
    false statements and conveys them with unmatched confidence. What I am missing,
    however, is a systematic debate about calling this by its name: the alignment
    problem.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否真正准备好迎接人工智能的变革？我认为这个问题的答案与我们构建对齐的人工智能系统的能力密切相关。随着人工智能越来越深入我们的生活、工作和经济中，我们的目标应该是使其在这个过程中更加安全。然而，我不清楚在过去的10年里是否发生了这样的变化。当然，当人们发现招聘系统歧视女性，或者ChatGPT产生虚假陈述并以无与伦比的自信传达时，他们会感到震惊。然而，我所缺少的是对这一问题进行系统性讨论，即对齐问题。
- en: The alignment problem involves two different kinds of alignment. While misaligned
    models present themselves through bias, false claims, and wrong predictions, misaligned
    agents are caught when their actions hint towards a conflict between their configuration
    and our values as humans. However, as we can learn from the most popular AI of
    all time, ChatGPT, both kinds of alignment are not mutually exclusive but can
    occur at the same time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐问题涉及两种不同的对齐方式。虽然不对齐的模型表现为偏见、虚假声明和错误预测，但不对齐的代理在其行为暗示其配置与我们作为人类的价值观之间存在冲突时被发现。然而，正如我们从最受欢迎的AI——ChatGPT中可以学到的那样，这两种对齐方式并不是互斥的，而是可以同时发生的。
- en: '[Eliezer Yudkowsky](https://www.youtube.com/watch?v=AaTRHFaaPG8), a well-known
    AI skeptic, argues that solving the alignment problem is the only way humans can
    avert their annihilation through their electronic “pets.” He thinks that we are
    in deep trouble because we might only get one shot at solving the alignment problem.
    Once a superhuman intelligence was developed, we would no longer be able to control
    or align it. However, Yudkowsky’s opinions are controversial, to say the least.
    Neither do we know whether superhuman intelligence can even be developed, nor
    is it obvious that any small degree of misalignment would automatically have catastrophic
    consequences.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[Eliezer Yudkowsky](https://www.youtube.com/watch?v=AaTRHFaaPG8)，一位著名的AI怀疑论者，认为解决对齐问题是人类避免通过电子“宠物”遭受灭绝的唯一途径。他认为我们面临深刻的危机，因为我们可能只有一次解决对齐问题的机会。一旦开发出超人类智能，我们将无法再控制或对齐它。然而，Yudkowsky的观点至少可以说是有争议的。我们既不知道超人类智能是否能被开发出来，也不清楚任何小的对齐问题是否会自动导致灾难性后果。'
- en: While I believe that demanding a temporary halt in the development of powerful
    AI systems is not feasible, I understand where this idea is coming from. We have
    seen a major increase in the capabilities of modern AI systems within the last
    10 years that AI alignment research has not been able to catch up to. However,
    solving the alignment problem is, in my estimation, a much safer bet on a positive
    return than building larger and larger black-box AI models. I’m not saying that
    we shouldn’t develop GPT-5, -6, and -7\. I’m saying we should actively engage
    in research and discourse around AI alignment to prepare ourselves for the future,
    regardless of how it may unfold.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我相信要求暂时停止开发强大AI系统是不现实的，但我理解这个想法的来源。在过去的10年里，我们已经看到现代AI系统能力的显著提升，而AI对齐研究尚未能跟上。然而，我认为解决对齐问题比构建越来越大的黑箱AI模型更安全。我的意思不是我们不应该开发GPT-5、-6和-7，而是我们应该积极参与AI对齐的研究和讨论，以准备迎接未来，无论未来如何展开。
- en: '**I hope found this post enjoyable and helpful!**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**我希望你觉得这篇文章有趣且有帮助！**'
- en: 'If you did, you might also like some of my other work about music AI or just
    AI in general:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢，你可能也会对我的一些其他关于音乐AI或AI的一般性工作感兴趣：
- en: '[Chatbots are About to Disrupt Music Search](/chatbots-are-about-to-disrupt-music-search-1e4a4cd7ba01)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聊天机器人即将颠覆音乐搜索](/chatbots-are-about-to-disrupt-music-search-1e4a4cd7ba01)'
- en: '[3 Things Decision Makers Should Know about AI Fairness](https://medium.datadriveninvestor.com/3-things-decision-makers-should-know-about-ai-fairness-f925fda0af0b)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策者应了解的AI公平性三件事](https://medium.datadriveninvestor.com/3-things-decision-makers-should-know-about-ai-fairness-f925fda0af0b)'
- en: '[How Meta’s AI Generates Music Based on a Reference Melody](/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Meta的AI如何根据参考旋律生成音乐](/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783)'
