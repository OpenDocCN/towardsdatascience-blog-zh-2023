# 机器学习图解：增量学习

> 原文：[https://towardsdatascience.com/machine-learning-illustrated-incremental-machine-learning-4d73747dc60c](https://towardsdatascience.com/machine-learning-illustrated-incremental-machine-learning-4d73747dc60c)

## 模型如何随着时间学习新信息，同时保持和建立在之前的知识基础上

[](https://medium.com/@shreya.rao?source=post_page-----4d73747dc60c--------------------------------)[![Shreya Rao](../Images/03f13be6f5f67783d32f0798f09a4f86.png)](https://medium.com/@shreya.rao?source=post_page-----4d73747dc60c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4d73747dc60c--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4d73747dc60c--------------------------------) [Shreya Rao](https://medium.com/@shreya.rao?source=post_page-----4d73747dc60c--------------------------------)

·发布于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----4d73747dc60c--------------------------------) ·阅读时间7分钟·2023年9月15日

--

欢迎回到《图解机器学习》系列。如果你阅读了系列中的其他[文章](https://medium.com/@shreya.rao/list/machine-learning-illustrated-dfb4532491ff)，你会知道套路。我们将一个（*听起来很枯燥*）的机器学习概念通过图示化的方式变得有趣！这篇文章将介绍一个名为**增量学习**的概念，在这个概念中，机器学习模型会随着时间的推移学习新信息，同时保持和建立在之前的知识基础上。但在深入之前，让我们先讨论一下今天的模型构建过程是什么样的。

在构建模型时，我们通常遵循一种称为**静态学习**的过程。在这个过程中，我们使用最新可用的数据来训练模型。在训练过程中，我们会调整和优化模型。一旦对其性能感到满意，我们就会部署它。这个模型会在生产中使用一段时间。然后我们会注意到模型的性能随着时间的推移变得越来越差。这时，我们会丢弃现有的模型，并使用最新的数据重新构建一个新的模型。我们反复执行这个过程。

![](../Images/07e8722405e2926bf8c48eebe746363e.png)

让我们用一个具体的例子来说明这一点。考虑以下假设场景。我们在2023年1月底开始构建一个欺诈检测模型。这个模型用于检测信用卡交易是否欺诈。我们使用过去一年（2022年1月到2022年12月）的所有信用卡交易数据来训练我们的模型，并用本月（2023年1月）的交易数据来测试模型。

![](../Images/993cd22d306048f39a9c11930a51c17e.png)

到下个月底，我们发现模型在面对新数据时表现不佳。因此我们构建了另一个模型，但这次使用过去一年的数据（2022年2月到2023年1月）进行训练，然后用当前月份的数据（2023年2月）进行测试。所有超出这些训练和测试周期的数据都被丢弃。

![](../Images/5e6e414b3ffc200024eca1265fc138ef.png)

下个月，我们再次注意到模型性能在面对新数据时表现不佳。于是，我们再次使用过去一年的数据构建了一个新模型。

![](../Images/198acd7c211542e6d589e5b9792b883c.png)

每当我们发现模型性能下降时，我们会重复这个过程。这不一定是在1个月后。也可能是在3个月、6个月甚至一年后。

**那我们为什么要这样批量处理数据呢？**

3个主要原因。

1.  概念漂移：随着时间的推移，我们会看到一种叫做概念漂移的现象，这意味着我们试图预测的内容会随时间变化，使用较旧的数据有时可能会适得其反。

1.  内存限制：我们的训练集越大，占用的内存就越多。因此，我们尝试限制输入到模型中的数据量。

1.  时间限制：与第二个原因类似，我们的训练数据越大，模型训练所需的时间就越长。（尽管这通常对我们构建的大多数模型来说不是一个大问题。可能会出现问题的地方是自然语言处理模型。）

**但如果我们不想丢弃所有旧模型和数据呢？** 丢弃旧模型意味着浪费了旧模型迄今为止积累的所有知识。理想情况下，我们希望找到一种方法来保留之前的知识，同时逐步添加来自新数据的信息。我们希望保留这种“制度性知识”，因为它对适应缓慢变化或重复出现的模式至关重要。

**这正是增量学习所做的事情。**

在增量学习中，模型逐步学习和增强其知识，而不会忘记以前获得的信息。它随着数据的增长而变得更加完善。

为了说明这一点，我们回到我们的欺诈模型示例。我们以与静态学习相同的方式开始。我们使用去年数据构建模型，但当下个月获得新数据时，我们不是从头开始构建新模型，而是将本月的新数据添加到现有模型中。然后我们在2个月、3个月等时重复这个过程。所以这里我们实际上不是在构建新模型，而是在构建相同模型的新版本。

![](../Images/15e361925e082f4e2240e842431111e9.png)

这可能是个好事，因为 a) 这是一种高效利用资源的方式，因为更少的数据存储 = 节省更多内存。每次迭代使用的内存更少，从而降低成本。 b) 这对动态数据很有用，现实世界中的大多数数据都是动态的，因为我们可以在获取新数据时持续更新预测，而不是每次都重新构建一个新模型。 c) 训练过程在更小的数据部分上进行，因此速度更快。

欺诈检测实际上是增量学习如何有益的一个很好的例子，以万事达卡的实时欺诈检测系统为例。每次交易时，万事达卡的系统会检查100多个变量（如交易大小、位置和商户类型）以评估欺诈的可能性。（来源：[DataCamp](https://www.datacamp.com/blog/what-is-incremental-learning)）该系统使用增量学习来适应欺诈活动模式的变化。在像金融欺诈这样的动态环境中，欺诈者不断调整他们的方法，概念漂移的挑战非常显著。因此，我们的模型必须迅速适应，以保持其性能并有效打击欺诈者及其不断变化的策略。

好消息是——增量学习已经被内置到我们一些最喜欢的模型中，比如XGBoost和CatBoost。实现起来非常简单！

> 我在之前的文章中解释了[XGBoost](/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb)和[CatBoost](/catboost-regression-break-it-down-for-me-16ed8c6c1eca)背后的数学细节。

让我们在真实数据上测试静态学习和增量学习，以比较性能。

我们将使用这个信用卡欺诈[数据集](https://www.kaggle.com/datasets/kartik2112/fraud-detection?select=fraudTrain.csv)（CC0）来构建模型。在进行一些特征清理和选择后，我们得到了如下数据集：

![](../Images/5ac4e5692ae31cf11cc5c656517d84a6.png)

其中**is_fraud**是我们的目标（y）列。

让我们从静态学习开始。我们构建了相同的12个XGBoost模型……

[PRE0]

…在接下来的12个一年期训练周期中：

![](../Images/0d1644fb3704136114a2801e5f698206.png)

在每次迭代或训练周期结束时，我们将训练日期提前一个月。然后，我们在接下来的一个月测试周期中测试每个模型，这些测试周期从其对应的训练周期结束时开始：

![](../Images/7ab05fb115abfbdbcd6971b03f36d127.png)

然后我们记录了12个AUC分数：

[PRE1]

> 我们记录这些分数，以便与我们从增量模型中获得的分数进行比较。记住，我们的AUC分数越高，模型的表现越好。

现在我们进入增量学习模型。**我们从在与静态学习相同的一年期间训练第一个模型开始。这是我们的基准模型。** 但对于接下来的11个模型，我们逐步将新月份的数据输入到已有的模型中。

![](../Images/78080de785cd2b992f8e2c994a8311c5.png)

因此，我们每次都从上次结束的地方继续训练模型。

这个模型看起来基本与之前相同，只是有一个小变化。

[PRE2]

在这里，我们使用参数`xgb_model`在当前构建的xgboost模型中声明之前的模型。通过保留之前训练的模型，训练过程变得更快、更高效，因为模型不需要每次都从头开始学习。

然后我们使用与静态模型相同的12个月测试期来测试12个模型…

![](../Images/7ab05fb115abfbdbcd6971b03f36d127.png)

…并记录AUC分数：

[PRE3]

现在是有趣的部分，我们来比较这两种过程的性能。在记录的11个AUC分数中（因为第一个分数是相同的，因为我们使用了相同的训练和测试数据），**增量学习在11次迭代中的7次中取得了更好的AUC分数**！

![](../Images/d91c1cb0aac3f4ca94852593f5283e2e.png)

尽管如此，仍然有一些警告：

+   增量学习面临过拟合的风险，因为它依赖于连续的数据流。风险在于，它可能会根据最近的数据过度调整其参数，这些数据可能无法准确代表整体分布。相比之下，状态学习可以考虑整个分布。

+   尽管增量学习可以处理不断变化的数据，但数据趋势的突变可能会带来挑战。因此，对于变化过于剧烈的数据，增量学习可能不适用。

+   增量学习面临一种现象，称为**灾难性遗忘**，即在学习新数据时旧知识会丧失，并且很难确定具体丢失了什么信息。

虽然有一些需要考虑的因素，但通过优化模型的每个版本，将这种方法集成到模型中是有益的。我们可以通过调整参数或改进特征选择来进一步提升结果。

以上就是关于增量学习的所有内容！一如既往，如果你有任何评论/问题/顾虑，请告诉我，也可以通过[LinkedIn](https://www.linkedin.com/in/shreyarao24/)与我联系，或通过*shreya.statistics@gmail.com*给我发邮件。

> 除非另有说明，所有图片均由作者提供。
