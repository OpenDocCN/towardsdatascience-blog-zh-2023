- en: Overfitting, Underfitting, and Regularization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合、欠拟合与正则化
- en: 原文：[https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62](https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62](https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62)
- en: Making Friends with AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与AI交朋友
- en: The bias-variance tradeoff, part 2 of 3
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差-方差权衡，第三部分中的第二部分
- en: '[](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[![Cassie
    Kozyrkov](../Images/ad18dd12979a4a3ec130bdf8b889af23.png)](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    [Cassie Kozyrkov](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[![Cassie
    Kozyrkov](../Images/ad18dd12979a4a3ec130bdf8b889af23.png)](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    [Cassie Kozyrkov](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    ·4 min read·Feb 15, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    ·阅读时长4分钟·2023年2月15日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'In [Part 1](http://bit.ly/quaesita_bivar1), we covered much of the basic terminology
    as well as a few key insights about the bias-variance formula (**MSE = Bias² +
    Variance**), including this paraphrase from [Anna Karenina](https://www.goodreads.com/work/quotes/2507928):'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一部分](http://bit.ly/quaesita_bivar1)中，我们覆盖了大部分基本术语以及关于偏差-方差公式的几个关键见解（**MSE
    = 偏差² + 方差**），包括来自[安娜·卡列尼娜](https://www.goodreads.com/work/quotes/2507928)的这段释义：
- en: All perfect models are alike, but each unhappy model can be unhappy in its own
    way.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有完美的模型都是相似的，但每个不完美的模型都有其独特的不完美方式。
- en: To make the most of *this* article, I suggest taking a look at [Part 1](http://bit.ly/quaesita_bivar1)
    to make sure you’re well-situated to absorb this one.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用*这篇*文章，我建议你先阅读[第一部分](http://bit.ly/quaesita_bivar1)，确保你为吸收这篇文章做好了准备。
- en: '![](../Images/6073e1755019bc63fad47ad5d1bed129.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6073e1755019bc63fad47ad5d1bed129.png)'
- en: Under vs over… fitting. Image by the author.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合与过拟合…… 图片由作者提供。
- en: What does overfitting/underfitting have to do with it?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合/欠拟合与此有何关系？
- en: Let’s say you have a [model](http://bit.ly/quaesita_emperorm) that is as good
    as you’re going to get for the information you have.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个[模型](http://bit.ly/quaesita_emperorm)，这是你能从现有信息中得到的最好模型。
- en: To have an even better model, you need better [data](http://bit.ly/quaesita_hist).
    In other words, more data (quantity) or *more relevant* data (quality).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得更好的模型，你需要更好的[数据](http://bit.ly/quaesita_hist)。换句话说，就是更多的数据（数量）或*更相关*的数据（质量）。
- en: When I say as *good* as you’re going to get, I mean in “good” terms of [MSE](http://bit.ly/quaesita_msefav)
    performance on data your model hasn’t seen before. (It’s supposed to [*pre*dict](http://bit.ly/quaesita_parrot),
    not *post*dict.) You’ve done a perfect job of getting what you can from the information
    you have — the rest is error you can’t do anything about with your information.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说你能得到的*最好*时，我指的是在模型未见过的数据上的[MSE](http://bit.ly/quaesita_msefav)性能。（它应该是[*预测*](http://bit.ly/quaesita_parrot)，而不是*后验*。）你已经从现有信息中尽力而为——剩下的误差是你无法通过信息解决的。
- en: Reality = Best Model + Unavoidable Error
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现实 = 最佳模型 + 不可避免的误差
- en: But here’s the problem… we’ve jumped ahead; **you don’t have this model yet.**
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但问题是……我们已经提前了；**你还没有这个模型。**
- en: 'All you have is a pile of old data to learn this model from. Eventually, if
    you’re smart, you’ll [validate this model](http://bit.ly/quaesita_idiot) on data
    it hasn’t seen before, but first you have to learn the model by finding useful
    patterns in data and trying to inch closer and closer to the stated objective:
    an MSE that’s as low as possible.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你只有一堆旧数据来学习这个模型。如果你足够聪明，你会在模型未见过的数据上[验证这个模型](http://bit.ly/quaesita_idiot)，但首先你必须通过发现数据中的有用模式，尽量接近目标：一个尽可能低的MSE。
- en: Unfortunately, during the [learning process](http://bit.ly/quaesita_mrbean),
    you don’t get to observe the MSE you’re after (the one that comes from reality).
    You only get to compute a shoddy version from your current training dataset.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在[学习过程中](http://bit.ly/quaesita_mrbean)，你无法观察到你期望的 MSE（即来自现实的那个）。你只能计算出来自当前训练数据集的粗略版本。
- en: '![](../Images/c20873c3f1bfa1837ca701dc6174fbfd.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c20873c3f1bfa1837ca701dc6174fbfd.png)'
- en: Photo by [Jason Leung](https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[Jason Leung](https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral)
    的照片，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Oh, and also, in this example “you” are not a human, you’re an [optimization
    algorithm](http://bit.ly/mfml_045) that was told by your human boss to twiddle
    the dials in the model’s settings until the MSE is as low as it will go.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，还有，在这个例子中，“你”不是一个人，你是一个[优化算法](http://bit.ly/mfml_045)，被你的人类老板指示调整模型设置中的旋钮，直到
    MSE 降到最低。
- en: You say, *“Sweet! I can do this!! Boss, if you give me an extremely flexible
    model with lots of settings to fiddle (*[*neural networks*](http://bit.ly/quaesita_emperor)*,
    anyone?), I can give you a perfect training MSE. No bias and no variance.”*
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你说，*“太好了！我能做到这一点！！老板，如果你给我一个具有许多设置的极其灵活的模型（*[*神经网络*](http://bit.ly/quaesita_emperor)*，怎么样？），我可以给你一个完美的训练
    MSE。没有偏差也没有方差。”*
- en: The way to get a better training MSE than the true model’s test MSE is to fit
    all the noise (errors you have no predictively-useful information about) along
    with the signal. How do you achieve this little miracle? By making the model more
    complicated. Connecting the dots, essentially.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得比真实模型的测试 MSE 更好的训练 MSE，你需要将所有噪声（你无法进行预测的错误）与信号一起拟合。如何实现这个小奇迹？通过使模型更复杂。本质上就是连接点。
- en: This is called [overfitting](http://bit.ly/quaesita_sydd). Such a model has
    an excellent training MSE but a whopper of a variance when you try to use it for
    anything practical. That’s what you get for trying to cheat by creating a solution
    with [more complexity than your information supports](http://bit.ly/mfml_049).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为[过拟合](http://bit.ly/quaesita_sydd)。这样的模型在训练 MSE 上表现优异，但在实际应用中会有巨大的方差。这就是试图通过创建一个[比信息支持的复杂度更高的解决方案](http://bit.ly/mfml_049)来作弊的结果。
- en: The boss is too smart for your tricks. Knowing that a [flexible](http://bit.ly/quaesita_emperor),
    complicated model allows you to score too well on your [training set](http://bit.ly/quaesita_mrbean),
    the boss changes the scoring function to penalize complexity. This is called [regularization](http://bit.ly/quaesita_059).
    (Frankly, I wish we had more regularization of engineers’ antics, to stop them
    from doing complicated things for complexity’s sake.)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 老板太聪明了，识破了你的把戏。知道一个[灵活的](http://bit.ly/quaesita_emperor)复杂模型会使你在[训练集](http://bit.ly/quaesita_mrbean)上得分过高，老板更改了评分函数，以惩罚复杂性。这被称为[正则化](http://bit.ly/quaesita_059)。
    （坦率地说，我希望我们能更多地正则化工程师的恶作剧，阻止他们为了复杂性而做复杂的事情。）
- en: Regularization essentially says, *“Each extra bit of complexity is going to
    cost you, so don’t do it unless it improves the fit by at least this amount…”*
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化本质上是说，*“每增加一点复杂度都要付出代价，所以除非它至少能改善拟合，否则不要这么做…”*
- en: If the boss regularizes too much — getting tyrannical about simplicity — your
    performance review is going to go terribly unless you oversimplify the model,
    so that’s what you end up doing.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果老板过度正则化——对简化过于严格——你的表现评估会很糟糕，除非你过度简化模型，否则你会这样做。
- en: This is called [underfitting](http://bit.ly/mfml_050). Such a model has an excellent
    training score (mostly because of all the simplicity bonuses it won) but a whopper
    of a bias in reality. That’s what you get for insisting that solutions should
    be simpler than your problem requires.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为[欠拟合](http://bit.ly/mfml_050)。这样的模型在训练分数上表现优异（主要是因为获得了所有简化奖励），但在现实中却有巨大的偏差。这就是坚持认为解决方案应比问题要求更简单的结果。
- en: And with that, we’re ready for [Part 3](http://bit.ly/quaesita_bivar3), where
    we bring it all together and cram the bias-variance tradeoff into a convenient
    nutshell for you.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就准备好了[第三部分](http://bit.ly/quaesita_bivar3)，在这一部分中，我们将所有内容整合在一起，把偏差-方差权衡压缩成一个方便的
    nutshell。
- en: Thanks for reading! How about a course?
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谢谢阅读！怎么考虑一下课程？
- en: 'If you had fun here and you’re looking for a leadership-oriented course designed
    to delight AI beginners and experts alike, [here’s a little something](https://bit.ly/funaicourse)
    I made for you:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在这里玩得很开心，并且你正在寻找一个旨在取悦 AI 初学者和专家的领导力导向课程，[这是我为你准备的一些东西](https://bit.ly/funaicourse)：
- en: '![](../Images/300b5280620ea948fc3dbffb708084d4.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/300b5280620ea948fc3dbffb708084d4.png)'
- en: 'Course link: [https://bit.ly/funaicourse](https://bit.ly/funaicourse)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 课程链接：[https://bit.ly/funaicourse](https://bit.ly/funaicourse)
- en: Looking for hands-on ML/AI tutorials?
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找实操性的机器学习/人工智能教程？
- en: 'Here are some of my favorite 10 minute walkthroughs:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我喜欢的一些10分钟快速演练：
- en: '[AutoML](https://console.cloud.google.com/?walkthrough_id=automl_quickstart)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AutoML](https://console.cloud.google.com/?walkthrough_id=automl_quickstart)'
- en: '[Vertex AI](https://bit.ly/kozvertex)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Vertex AI](https://bit.ly/kozvertex)'
- en: '[AI notebooks](https://bit.ly/kozvertexnotebooks)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 笔记本](https://bit.ly/kozvertexnotebooks)'
- en: '[ML for tabular data](https://bit.ly/kozvertextables)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[表格数据的机器学习](https://bit.ly/kozvertextables)'
- en: '[Text classification](https://bit.ly/kozvertextext)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本分类](https://bit.ly/kozvertextext)'
- en: '[Image classification](https://bit.ly/kozverteximage)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像分类](https://bit.ly/kozverteximage)'
- en: '[Video classification](https://bit.ly/kozvertexvideo)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[视频分类](https://bit.ly/kozvertexvideo)'
