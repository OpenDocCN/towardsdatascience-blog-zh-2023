["```py\n{\n  \"kind\": \"youtube#searchListResponse\",\n  \"etag\": \"h_RGyvb98m0yrxBgG0Q21J0ch94\",\n  \"nextPageToken\": \"CAIQAA\",\n  \"regionCode\": \"UK\",\n  \"pageInfo\": {\n    \"totalResults\": 19544,\n    \"resultsPerPage\": 10\n  },\n  \"items\": [\n    {\n      \"kind\": \"youtube#searchResult\",\n      \"etag\": \"N6_OLAdw4hCq2.....\",\n      \"id\": {\n        \"kind\": \"youtube#channel\",\n        \"channelId\": \"UCoV0b7wU.....\"\n      },\n      \"snippet\": {\n        \"publishedAt\": \"2016-11-07T04:54:33Z\",\n        \"channelId\": \"UCoV0b7....\",\n        \"title\": \"1 stoner 3 cats\",\n        \"description\": \"MUST BE 18 OR OLDER FOR THIS CHANNEL...\",\n        \"thumbnails\": {\n          \"default\": {\n            \"url\": \"https://yt3.ggpht.com/ytc/APkrFKZKfv...\"\n          },\n          \"medium\": {\n            \"url\": \"https://yt3.ggpht.com/ytc/APkrFKZKfv...\"\n          },\n          \"high\": {\n            \"url\": \"https://yt3.ggpht.com/ytc/APkrFKZKfvuGIwwg...\"\n          }\n        },\n        \"channelTitle\": \"1 stoner 3 cats\",\n        \"liveBroadcastContent\": \"upcoming\",\n        \"publishTime\": \"2016-11-07T04:54:33Z\"\n      }\n    },\n    ...\n  ],\n  \"prevPageToken\": null\n}\n```", "```py\nimport datetime\nimport logging\nfrom pyyoutube import Api  # pip3 install python-youtube\n\ndef save_log(log_filename: str, s_data: str):\n    \"\"\" Save string to the log file \"\"\"\n    with open(log_filename, \"a\", encoding=\"utf-8\") as log_out:\n        log_out.write(s_data + \"\\n\")\n\ndef search_by_keywords(api: Api, search_str: str, page_token: str):\n    \"\"\" Get YouTube channels list for a search phrase \"\"\"\n    count = 10\n    limit = 25000\n    parts = [\"snippet\"]\n    res = api.search_by_keywords(q=search_str, limit=limit, count=count,\n                                region_code=\"UK\",\n                                relevance_language=\"en\",\n                                search_type=\"channel\", \n                                order=\"title\",\n                                page_token=page_token, parts=parts,\n                                return_json=True)\n    return res\n\ndef get_channels(api: Api, search_str: str):\n    \"\"\" Get YouTube channels list and save results in CSV file \"\"\"\n    time_str = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n    log_file = f\"{search_str.replace(' ', '-')}-{time_str}.csv\"\n    logging.debug(f\"Log file name: {log_file}\")\n    save_log(log_file, \"channelId;publishedAt;title\")\n\n    res = search_by_keywords(api, search_str, page_token=None)\n    next_page_token = res[\"nextPageToken\"]\n    num_items = 0\n    while next_page_token is not None:\n        for item in res['items']:\n            title = item['snippet']['title'].replace(\";\", \" \").replace(\"  \", \" \")\n            description = item['snippet']['description'].replace(\";\", \" \").replace(\"  \", \" \")\n            log_str = f\"{item['id']['channelId']};{item['snippet']['publishedAt']};{title} {description}\"\n            logging.debug(log_str)\n            save_log(log_file, log_str)\n\n            num_items += 1\n\n        next_page_token = res[\"nextPageToken\"]\n        logging.debug(f\"{num_items} items saved to {log_file}\")\n\n        res = search_by_keywords(api, search_str, page_token=next_page_token)\n        next_page_token = res[\"nextPageToken\"]\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.DEBUG,\n                        format='[%(asctime)-15s] %(message)s')\n\n    key1 = \"XXXXX\"   \n    youtube_api = Api(api_key=key1)\n    get_channels(youtube_api, search_str=\"cats\")\n```", "```py\nchannelId;publishedAt;title\nUCoV0b7wUJ2...;2016-11-07T04:54:33Z;1 stoner 3 cats MUST BE ...\nUCbm5zxzNPh...;2013-08-07T12:34:48Z;10 Cats ...\nUCWflB-GzVa...;2013-09-25T10:39:41Z;13 Cats - Topic ...\nUCiNQyjPsO9-c2C7eOGZhYXg;2023-10-09T22:51:37Z;2 CATS NO RULES ...\n```", "```py\ndef get_channel_info(api: Any,\n                     file_out: str,\n                     channel_id: str,\n                     channel_title: str) -> int:\n    \"\"\" Get YouTube channel statistics \"\"\"\n    res = api.get_channel_info(channel_id=channel_id, parts=[\"statistics\"], return_json=True)\n    n_count = 0\n    if \"items\" in res:\n        time_str = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n        for item in res[\"items\"]:\n            ch_id = item[\"id\"]\n            statistics = item[\"statistics\"]\n            views = statistics[\"viewCount\"]\n            subscribers = statistics[\"subscriberCount\"]\n            videos = statistics[\"videoCount\"]\n            s_out = f\"{time_str};{ch_id};{channel_title};{views};{subscribers};{videos}\"\n            logging.debug(f\"Saving: {s_out}\")\n            save_log(file_out, s_out)\n            n_count += 1\n    return n_count\n```", "```py\napi = Api(api_key=\"...\")\nget_channel_info(api, \"cats_09_24.csv\",\n                 channel_id=\"UCbm5zxzNPh...\",\n                 channel_title=\"CATS NO RULES Its a Cats Life\")\n```", "```py\ntimestamp;channelId;title;views;subscribers;videos\n2023-10-09-19-42-19;UCoV0b7wUJ2...;1 stoner 3 cats MUST BE ...;14;2;6\n2023-10-09-19-42-19;UCbm5zxzNPh...;CATS NO RULES Its a Cats Life;24;5;3\n```", "```py\nscp pi@10.14.24.168:/home/pi/airflow/data/*.csv data\n```", "```py\nimport glob\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nchannel_files = glob.glob(\"data/channel*.csv\")\nchannels_data = []\nfor file_in in channel_files:\n    channels_data.append(pd.read_csv(file_in, delimiter=';',\n                                     parse_dates=['timestamp'],\n                                     date_format=\"%Y-%m-%d-%H-%M-%S\"))\n\ndf_channels = pd.concat(channels_data)\n```", "```py\ndef load_channels(files: List, subject: str) -> pd.DataFrame:\n    \"\"\" Load and combine dataframe from several files \"\"\"\n    dataframes = []\n    for csv in files:\n        df = pd.read_csv(csv, delimiter=\";\", parse_dates=[\"publishedAt\"])\n        df[\"subject\"] = subject\n        dataframes.append(df)\n    return pd.concat(dataframes).drop_duplicates(subset=[\"channelId\"])\n\nsmartphones = load_channels([\"smartphone-channels.csv\"], subject=\"Smartphones\")\ndogs = load_channels([\"dogs-channels.csv\"], subject=\"Dogs\")\ncats = load_channels([\"cats-channels.csv\"], subject=\"Cats\")\n...\n\nchannels_all = pd.concat([smartphones, makeup, photography,\n                          streetphotography, cats,\n                          dogs]).drop_duplicates(subset=[\"channelId\"])\n```", "```py\ndf_channels = df_channels.merge(\n                  channels_all[[\"channelId\", \"publishedAt\", \"subject\"]],\n                  on=['channelId'],\n                  how='left') \n```", "```py\ndf_channels_ = df_channels.drop_duplicates(subset=[\"channelId\"]).sort_values(by=['views'], ascending=False).copy()\ndf_channels_[\"views\"]  = df_channels_[\"views\"].apply(lambda val: f\"{val:,.0f}\")\ndf_channels_[\"subscribers\"]  = df_channels_[\"subscribers\"].apply(lambda val: f\"{val:,.0f}\")\ndisplay(df_channels_)\n```", "```py\ndisplay(df_channels_.style.format(thousands=\".\"))\n```", "```py\ndecimation = 10\ndf_channels__ = df_channels_.reset_index(drop=True).iloc[::decimation, :]\n\nsns.set(rc={'figure.figsize': (18, 6)})\nsns.set_style(\"whitegrid\")\nfig, ax = plt.subplots()\nsns.barplot(df_channels__, x=df_channels__.index, y=\"views\", width=0.9, ax=ax)\nax.set(title='YouTube channels views',\n       xticks=range(0, df_channels__.shape[0], 50),\n       ylim=(0, None),\n       xlabel='Channel â„–',\n       ylabel='Views Total')\nax.ticklabel_format(style='plain', axis=\"y\")\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nsns.despine(left=True)\nplt.show()\n```", "```py\ndisplay(df_channels_[[\"views\", \"subscribers\"]].quantile(\n    [0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]\n).style.format(\"{:,.0f}\"))\n```", "```py\ndf_channels_ = df_channels.drop_duplicates(subset=[\"channelId\"]).sort_values(by=['subscribers'], ascending=False).reset_index(drop=True)\ndisplay(df_channels_[df_channels_.shape[0]//2:])\n```", "```py\nupper_limit = 1_000_000\n\ndf_channels_ = df_channels.drop_duplicates(subset=[\"channelId\"]).copy()\ndf_channels_[\"subscribers_clipped\"] = df_channels[\"subscribers\"].clip(upper=upper_limit)\n\nsns.set(rc={'figure.figsize': (18, 8)})\nsns.set_style(\"white\")\npalette = sns.color_palette(\"bright\")\n\nfig, ax = plt.subplots()\n# Add scatter plot and average lines\nfor ind, subj_str in enumerate(df_channels_[\"subject\"].unique()):\n    df_subj = df_channels_[df_channels_[\"subject\"] == subj_str]\n    # Draw scatter plot\n    markers = [\"o\" , \"s\" , \"p\" , \"h\"]\n    sns.scatterplot(data=df_subj, x=\"publishedAt\", y=\"subscribers_clipped\",\n                    color=palette[ind],\n                    marker=markers[ind % len(markers)],\n                    label=subj_str,\n                    ax=ax)\n\n    # Draw average\n    col_avg = df_subj[\"subscribers\"].mean()\n    linestyles = [\"--\", \":\", \"-.\"]\n    linestyle = linestyles[ind % len(linestyles)]\n    ax.axhline(col_avg, color=palette[ind], label=subj_str + \" Avg\", linestyle=linestyle, linewidth=1.0, alpha=0.6)\n\nax.set(title='Channel Subscribers',\n       xlabel='Registration Date',\n       ylabel='Subscribers',\n       ylim=(0, upper_limit)\n       )\nax.ticklabel_format(style='plain', axis=\"y\")\nax.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\nax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nax.spines['top'].set_color('#EEEEEE')\nax.spines['right'].set_color('#EEEEEE')\nax.spines['bottom'].set_color('#888888')\nax.spines['left'].set_color('#888888')\nplt.legend(loc='upper right')\nplt.show()\n```", "```py\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndf_channels_ = df_channels.drop_duplicates(subset=[\"channelId\"]).copy()\n\nupper_limit = 100_000\nright_limit = 1000\n\nsns.set(rc={'figure.figsize': (18, 8)})\nsns.set_style(\"white\")\nnum_subjects = df_channels_[\"subject\"].nunique()\npalette = sns.color_palette(\"bright\")\nfig, ax = plt.subplots()\nfor ind, subj_str in enumerate(df_channels_[\"subject\"].unique()):\n    # Filter by subject\n    df_subj = df_channels_[df_channels_[\"subject\"] == subj_str].sort_values(by=['subscribers'], ascending=False)\n    # Draw scatter plot\n    markers = [\"o\" , \"s\" , \"p\" , \"h\"]\n    sns.scatterplot(data=df_subj, x=\"videos\", y=\"subscribers\",\n                    color=palette[ind],\n                    # palette=[palette[ind],\n                    # hue=\"subject\", \n                    marker=markers[ind % len(markers)],\n                    label=subj_str,\n                    ax=ax)\n\n    # Make linear interpolation\n    df_subj = df_subj[10:]   # Optional: remove top channels to exclude \"outliers\"\n    values_x = df_subj[\"videos\"].to_numpy().reshape((-1, 1))\n    values_y = df_subj[\"subscribers\"].to_numpy()\n    model = LinearRegression().fit(values_x, values_y)\n    x_val = np.array([0, right_limit])\n    y_val = model.predict(x_val.reshape((-1, 1)))    \n    # Draw\n    linestyles = [\"--\", \":\", \"-.\"]\n    ax.axline((x_val[0], y_val[0]), (x_val[1], y_val[1]),\n              linestyle=linestyles[ind % 3], linewidth=1,\n              color=palette[ind], alpha=0.5,\n              label=subj_str + \" Avg\")\n\nax.set(title='YouTube Subscribers',\n       xlabel='Videos In Channel',\n       ylabel='Subscribers',\n       xlim=(0, right_limit),\n       ylim=(0, upper_limit)\n       )\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nax.spines['top'].set_color('#EEEEEE')\nax.spines['right'].set_color('#EEEEEE')\nax.spines['bottom'].set_color('#888888')\nax.spines['left'].set_color('#888888')\nplt.legend(loc='upper right')\nplt.show()\n```", "```py\nchannels_data = []\n\nchannel_id = ...\ndf_channel_data = df_channels[df_channels[\"channelId\"] == channel_id][[\"timestamp\", \"views\", \"subscribers\", \"videos\"]].sort_values(by=['timestamp'], ascending=True).reset_index(drop=True).copy() \ndf_first_row = df_channel_data.iloc[[0]].values[0]        \ndf_channel_data = df_channel_data.apply(lambda row: row - df_first_row, axis=1)\ndf_channel_data[\"channelId\"] = channel_id\ndf_channel_data[\"days_diff\"] = df_channel_data[\"timestamp\"].map(lambda x: x.total_seconds()/(24*60*60), na_action=None)\ndf_channel_data[subj_str] = subj_str\nchannels_data.append(df_channel_data)\n```", "```py\nsns.lineplot(data=pd.concat(channels_data),\n             x=\"days_diff\", y=\"views\",\n             hue=\"channelId\", palette=palette, linestyle=linestyle,\n             legend=False)\n```", "```py\nfrom sklearn.ensemble import IsolationForest\n\ndf_channels_ = df_channels.sort_values(by=['videos'], ascending=False).drop_duplicates(subset=[\"channelId\"]).copy().reset_index(drop=True).copy()\ndf_channels_ = df_channels_[df_channels_[\"videos\"] > 10]\ndf_channels_[\"subscribers_per_video\"] = df_channels_[\"subscribers\"]/df_channels_[\"videos\"]\ndf_channels_[\"views_per_video\"] = df_channels_[\"views\"]/df_channels_[\"videos\"]\ndf_channels_[[\"subscribers_per_video\", \"views_per_video\"]] = df_channels_[[\"subscribers_per_video\", \"views_per_video\"]].apply(pd.to_numeric)\n\nX = df_channels_[[\"subscribers_per_video\", \"views_per_video\"]]\nmodel = IsolationForest(contamination=0.05, random_state=42).fit(X)\ndf_channels_['anomaly_scores'] = model.decision_function(X)\ndf_channels_['anomaly'] = model.predict(X)\n\n# Anomaly: Outlier (-1) or an inlier (1)\n# Anomaly_scores: The lower the score, the more abnormal is the sample\ndisplay(df_channels_.sort_values(by=['anomaly_scores'], ascending=True)[:30])\n```", "```py\nimport shap\n\nX = df_channels_[[\"subscribers_per_video\", \"views_per_video\"]]\ny_pred = model.predict(X)\nexplainer = shap.Explainer(model.predict, X)\nshap_values = explainer(X)\n\nshap.initjs()\n```", "```py\nshap.plots.waterfall(shap_values[786])\n```"]