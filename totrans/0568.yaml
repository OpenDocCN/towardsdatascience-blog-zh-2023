- en: Convolutional Neural Networks For Beginners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/convolutional-neural-networks-for-beginners-c1de55eee2b2](https://towardsdatascience.com/convolutional-neural-networks-for-beginners-c1de55eee2b2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fundamentals of convolutional neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mina.ghashami?source=post_page-----c1de55eee2b2--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----c1de55eee2b2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c1de55eee2b2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c1de55eee2b2--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----c1de55eee2b2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c1de55eee2b2--------------------------------)
    ·6 min read·Oct 17, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/81572a08a73278e57437c5f0d487cdca.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [unsplash.com](https://unsplash.com/photos/an-abstract-image-of-a-sphere-with-dots-and-lines-nGoCBxiaRO0)
  prefs: []
  type: TYPE_NORMAL
- en: I wrote this post as part of my preparation for one of the lectures I taught
    at [*Interview Kickstart*](https://www.interviewkickstart.com/)to prepare professionals
    to land jobs in top tech companies. If you are in the process of preparing for
    interviews or just strengthening your foundation, this post might help you too.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we look into convolutional neural networks and their basics and
    fundamentals. We will start from what a convolution operation is, and continue
    with what a convolution layer is and how convolutional networks are built.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Networks (CNNs) consist of several “convolutional layers”.
    These layers run the “convolution operation.” Convolution is a fundamental operation
    in signal and image processing. Let’s first see what this operation is.
  prefs: []
  type: TYPE_NORMAL
- en: What is a convolution operation?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Convolution is the mathematical operation between a kernel (filter) and an input
    feature map.
  prefs: []
  type: TYPE_NORMAL
- en: The kernel is usually a small matrix e.g. 3x3, or 5x5\. The input is always
    a feature map with height, width, and channels. How convolution operation works
    is that the *kernel slides over the input* *and computes the dot product between
    the kernel and local regions of input*. This dot product multiplication and summation
    produces a single value in the output feature map.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the filter slides over all locations, it generates a 2D activation map called
    *output feature map*. For each slide of filter (kernel) over the image or the
    input feature map, we compute the element-wise dot-product and sum them together.
    This gives one entry in the output map:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4484df02808970f0bc2630c05dc7adcc.png)'
  prefs: []
  type: TYPE_IMG
- en: convolution operation — image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we slide the filter to the right over another local region of the input
    map and it produces another entry into the output map:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b0e1243c611258cb3f15c66c418f53f0.png)'
  prefs: []
  type: TYPE_IMG
- en: convolution operation — image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'We slide it all to the right, until we no longer can slide it to the right,
    then we move back to the left-most side and slide it down by one entry:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/93b60ff996826db1f58b37f11039f271.png)'
  prefs: []
  type: TYPE_IMG
- en: convolution operation — image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'The last convolutional operation for this example would be at the right most
    bottom point:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1588d10f6e690f52185718d114ed6035.png)'
  prefs: []
  type: TYPE_IMG
- en: convolution operation — image by author
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s take a look at the convolutional layer, which is the key building
    block of a convolutional neural network (CNN).
  prefs: []
  type: TYPE_NORMAL
- en: What is a convolutional layer?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A convolutional layer like any other layer consists of multiple neurons. Each
    neuron in the convolutional layer has a set of weights defining its filter (kernel).
    This filter is convolved with the input (or the output of the previous layer)
    to generate a 2-dimensional activation map.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: During forward pass, the input to a neuron in a convolutional layer is a 3D
    volume with dimensions [height, width, channels]. Each neuron in the layer has
    a set of weights defining its convolutional kernel (filter).
  prefs: []
  type: TYPE_NORMAL
- en: This filter has a small spatial extent (e.g. 3x3) but extends fully along the
    input depth. Meaning that it is convolved (element-wise multiplied and summed)
    with the input and extends fully along the depth, and produces a 2D activation
    map as output. The dimensions of output for each neuron is [height, width, 1].
  prefs: []
  type: TYPE_NORMAL
- en: If we stack together the output map of all neurons in one convolutional layer,
    then we will have an output of dimension [height, width, channel]; where channel
    is the number of neurons in the layer. Channel is the depth of the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, lets look at parameters and hyper-parameters of this layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Parameters:** A layer’s parameters are the weights of the kernels that are
    initially initialized at random values, but during training they are learned and
    optimized.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hyper-parameters**: A layer’s hyper-parameters are the followings:'
  prefs: []
  type: TYPE_NORMAL
- en: 1) number of neurons in the layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2) filter size (e.g. 2x2, 3x3); usually all neurons in a layer have same size
    filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*3) Stride:* that is the number of steps to move the filter at each time to
    either right or down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*3) Zero-padding:*Zero-padding refers to the technique where the input to a
    convolutional layer is padded with zeros around its border. This helps preserve
    spatial resolution throughout the network; otherwise spatial information can otherwise
    get lost very quickly as depth increases. There are two main types of zero-padding:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*3–1) Same padding* — Pad so that the output size matches the input size. Requires
    padding of *(kernel_size — 1) / 2*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*3–2) Valid padding* — Use no padding. Output shrinks by *kernel_size — 1*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So if we are using a 3x3 kernel, we will zero-pad by 1 pixel on each dimension
    of the input. See the example below, where the input image is 5x5 and kernel is
    3x3\. Without zero padding the output activation map is 3x3\. As we see the spatial
    dimensions are not preserved.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bbaf94133313f2191baeed8cdc3c0907.png)'
  prefs: []
  type: TYPE_IMG
- en: without padding — image by author
  prefs: []
  type: TYPE_NORMAL
- en: But if we do zero padding, we preserve the spatial dimension of the input image.
    As we see below, the output activation map is 5x5.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/01d43f5d085ec5d65ae099a989394a89.png)'
  prefs: []
  type: TYPE_IMG
- en: with zero padding — image by author
  prefs: []
  type: TYPE_NORMAL
- en: What is a convolutional neural network?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Convolutional Neural Network (CNN) is a neural network that consists of multiple
    convolutional layers, pooling layers and fully connected layers. It is often to
    process grid-like topology, such as images.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The **convolutional layers** as we saw above apply a convolution operation to
    the input using a set of learnable filters. They together build feature map hierarchies.
  prefs: []
  type: TYPE_NORMAL
- en: The **pooling layers** (max pooling or average pooling) downsample the feature
    maps to reduce computation.
  prefs: []
  type: TYPE_NORMAL
- en: The **fully-connected layers** are often the last layers in a CNN where they
    connect all the neurons between layers and perform classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we see an image of a CNN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8d48a6707bab77486af48c83a23024af.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: This concludes topic of this post. In the next posts we will look at some famous
    CNN model architectures for image classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some terminology: every *channel* is called a feature map too. A *kernel* is
    called a filter too. The *receptive field* is the region in the input image that
    a neuron is looking and is extracting features from.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All neurons in a convolutional layer have the same kernel (filter) size. This
    is important so that we can stack together all output activation maps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CNNs can easily scale to large images as convolutional filters are only applied
    locally.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Number of neurons in a convolutional layer is the same as the number of filters
    or kernels. They define the number of channels in the output feature map.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Neurons in a convolutional layer have independent kernels; they do not share
    weights.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Convolutional neural networks (CNN) are grid-processing neural networks that
    consist of convolutional layers, pooling layers and fully connected layers. Each
    neuron in a convolutional layer corresponds to a filter (kernel). During forward
    pass, each filter is convolved with the input volume to produce a 2D activation
    map of that filter. Multiple filters produce multiple activation maps stacked
    in the depth dimension. Then pooling layer which is either max pooling or average
    pooling downsample this to a smaller size. At the end of the neural network there
    are one or few fully connected layers to help with image classification task.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have any questions or suggestions, feel free to reach out to me:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Email: mina.ghashami@gmail.com'
  prefs: []
  type: TYPE_NORMAL
- en: 'LinkedIn: [https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)'
  prefs: []
  type: TYPE_NORMAL
