- en: Practical Prompt Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实用的提示工程
- en: 原文：[https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4](https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4](https://towardsdatascience.com/practical-prompt-engineering-74e96130abc4)
- en: Tips and tricks for successful prompting with LLMs…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成功提示LLMs的技巧和窍门…
- en: '[](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----74e96130abc4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    ·15 min read·Jul 30, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----74e96130abc4--------------------------------)
    ·15分钟阅读·2023年7月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e25abf0c0a3c6577a9a7741aa923ce0d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e25abf0c0a3c6577a9a7741aa923ce0d.png)'
- en: (Photo by [Jan Kahánek](https://unsplash.com/@honza_kahanek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/g3O5ZtRk2E4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由[Jan Kahánek](https://unsplash.com/@honza_kahanek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)提供，来源于[Unsplash](https://unsplash.com/photos/g3O5ZtRk2E4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: Due to their text-to-text format, large language models (LLMs) are capable of
    solving a wide variety of tasks with a single model. Such a capability was originally
    demonstrated via zero and few-shot learning with models like [GPT-2](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)
    and [GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [5, 6]. When fine-tuned to align with human preferences and instructions, however,
    LLMs become even more compelling, enabling popular generative applications such
    as [coding assistants](https://cameronrwolfe.substack.com/i/93578656/evaluating-large-language-models-trained-on-code),
    [information-seeking dialogue agents](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback),
    and [chat-based search experiences](http://microsoft.com/en-us/bing?form=MW00X7&ef_id=_k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&OCID=AIDcmmf8m4fdss_SEM__k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&gclid=Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB&ch=).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其文本到文本的格式，大型语言模型（LLMs）能够用一个模型解决各种任务。这种能力最初通过像[GPT-2](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)和[GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)这样的模型的零样本和少样本学习得到了展示[5,
    6]。然而，当经过微调以符合人类的偏好和指示时，LLMs变得更具吸引力，推动了流行的生成应用，如[编码助手](https://cameronrwolfe.substack.com/i/93578656/evaluating-large-language-models-trained-on-code)、[信息寻求对话代理](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)和[基于聊天的搜索体验](http://microsoft.com/en-us/bing?form=MW00X7&ef_id=_k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&OCID=AIDcmmf8m4fdss_SEM__k_Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB_k_&gclid=Cj0KCQjwgLOiBhC7ARIsAIeetVB3LkqQ31NslKZ7qj1J1Sx3PYJltfeBZs6bYulrUtPSrChf8KLmmZMaAkoKEALw_wcB&ch=)。
- en: 'Due to the applications that they make possible, LLMs have seen a quick rise
    to fame both in research communities and popular culture. During this rise, we
    have also witnessed the development of a new, complementary field: *prompt engineering*.
    At a high-level, LLMs operate by *i)* taking text (i.e., a prompt) as input and
    *ii)* producing textual output from which we can extract something useful (e.g.,
    a classification, summarization, translation, etc.). The flexibility of this approach
    is beneficial. At the same time, however, we must determine how to properly construct
    out input prompt such that the LLM has the best chance of generating the desired
    output.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其能够实现的应用，LLMs 在研究界和大众文化中迅速崛起。在这一过程中，我们还见证了一个新的、互补的领域的出现：*提示工程*。从高层次看，LLMs
    通过 *i)* 以文本（即提示）作为输入和 *ii)* 生成文本输出，从中提取有用信息（例如，分类、摘要、翻译等）。这种方法的灵活性非常有利。然而，我们必须确定如何正确构造输入提示，以便
    LLM 能够生成所需的输出。
- en: Prompt engineering is an empirical science that studies how different prompting
    strategies can be use to optimize LLM performance. Although a variety of approaches
    exist, we will spend this overview building an understanding of the general mechanics
    of prompting, as well as a few fundamental (but incredibly effective!) prompting
    techniques like zero/few-shot learning and instruction prompting. Along the way,
    we will learn practical tricks and takeaways that can immediately be adopted to
    become a more effective prompt engineer and LLM practitioner.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是一门实证科学，研究不同的提示策略如何优化 LLM 性能。尽管存在各种方法，我们将通过本概述构建对提示的一般机制的理解，以及一些基本的（但极其有效的！）提示技术，如零样本/少样本学习和指令提示。在此过程中，我们将学习实用技巧，并获得可立即采纳的要点，以成为更有效的提示工程师和
    LLM 从业者。
- en: '![](../Images/1a0220b74f6f1c01275c291596366bf2.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a0220b74f6f1c01275c291596366bf2.png)'
- en: (created by author)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: （作者创建）
- en: '**Understanding LLMs.** Due to its focus upon prompting, this overview will
    not explain the [history](https://twitter.com/cwolferesearch/status/1639378997627826176?s=20)
    or [mechanics](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)
    of language models. To gain a better general understanding of language models
    (which is an important prerequisite for deeply understanding prompting), I’ve
    written a variety of overviews that are available. These overviews are listed
    below (in order of importance):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**理解大型语言模型（LLMs）。** 由于本文重点讨论提示技术，这里不会解释语言模型的[历史](https://twitter.com/cwolferesearch/status/1639378997627826176?s=20)或[机制](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)。为了更好地理解语言模型（这是深入理解提示的一个重要前提），我写了一些概述，供大家参考。以下是这些概述的列表（按重要性排序）：'
- en: Language Modeling Basics (GPT and GPT-2) [[link](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)]
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言建模基础（GPT 和 GPT-2）[[link](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)]
- en: The Importance of Scale for Language Models (GPT-3) [[link](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)]
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型规模的重要性（GPT-3）[[link](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)]
- en: Modern [[link](https://cameronrwolfe.substack.com/p/modern-llms-mt-nlg-chinchilla-gopher)]
    and Specialized [[link](https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica)]
    LLMs
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代 [[link](https://cameronrwolfe.substack.com/p/modern-llms-mt-nlg-chinchilla-gopher)]
    和专业化 [[link](https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica)]
    的 LLMs
- en: '[PaLM](https://cameronrwolfe.substack.com/p/palm-efficiently-training-massive),
    T5 (Part [One](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part)
    and [Two](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part-354)),
    LLaMA (Part [One](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone)
    and [Two](https://cameronrwolfe.substack.com/p/beyond-llama-the-power-of-open-llms))'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PaLM](https://cameronrwolfe.substack.com/p/palm-efficiently-training-massive)、T5（第
    [一部分](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part)
    和 [二部分](https://cameronrwolfe.substack.com/p/t5-text-to-text-transformers-part-354)）、LLaMA（第
    [一部分](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone) 和 [二部分](https://cameronrwolfe.substack.com/p/beyond-llama-the-power-of-open-llms)）'
- en: Prompting at a Glance
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示一览
- en: '![](../Images/914b11eef522b79e77115962b7e15d3d.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/914b11eef522b79e77115962b7e15d3d.png)'
- en: Language models can solve a variety of tasks using their generic, text-to-text
    format (from [1])
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型可以使用其通用的文本到文本格式解决各种任务（来自 [1]）
- en: 'Given the current hype around LLMs, we might ask ourselves: *what are the fundamental
    strengths of LLMs that make them so powerful?* Although there’s not a single answer
    to this question (e.g., [model scale](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners),
    [massive pre-training data](https://cameronrwolfe.substack.com/i/91134599/training-compute-optimal-llms),
    [human feedback](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback),
    etc.), one major strength of LLMs is their generic, text-to-text format. These
    models are experts at [next-token prediction](https://cameronrwolfe.substack.com/i/85568430/language-modeling),
    and so many different tasks can be solved by properly tuning and leveraging this
    skill!'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于当前对 LLM 的热度，我们可能会问自己：*LLM 的基本优势是什么，使它们如此强大？* 尽管这个问题没有单一的答案（例如，[模型规模](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)，[大规模预训练数据](https://cameronrwolfe.substack.com/i/91134599/training-compute-optimal-llms)，[人类反馈](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    等），LLM 的一个主要优势是其通用的文本到文本格式。这些模型擅长 [下一个词预测](https://cameronrwolfe.substack.com/i/85568430/language-modeling)，因此通过正确调整和利用这一技能可以解决许多不同的任务！
- en: To solve a task, all we need to do is *i)* provide textual input to the model
    that contains relevant information and *ii)* extract output from text returned
    by the model. Such a unified approach can be used for translation, summarization,
    question answering, classification, and more. However, the story is not (quite)
    that simple. Namely, the wording and structure of the prompt (i.e., the inputted
    text) provided to the LLM can significantly impact the model’s accuracy. In other
    words, *prompt engineering is a huge deal.*
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决一个任务，我们需要做的就是 *i)* 向模型提供包含相关信息的文本输入，并 *ii)* 从模型返回的文本中提取输出。这样统一的方法可以用于翻译、总结、问答、分类等。然而，事情并不（完全）那么简单。即，提供给
    LLM 的提示（即输入文本）的措辞和结构可以显著影响模型的准确性。换句话说，*提示工程非常重要。*
- en: What is prompt engineering?
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: “Prompt engineering is a relatively new discipline for developing and optimizing
    prompts to efficiently use LMs for a wide variety of applications and research
    topics.” *— from [2]*
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “提示工程是一个相对较新的学科，旨在开发和优化提示，以高效使用 LMs 处理各种应用和研究主题。” *— 来自 [2]*
- en: Given that properly crafting the contents of our prompt is important to achieving
    useful results with an LLM, prompt engineering has gained a lot of interest in
    recent months. However, it’s an empirical science — discovering the best-possible
    prompts is typically heuristic-based and requires experimentation. We can discover
    better prompts by [tracking and versioning](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)
    our prompts over time and testing different ideas to see what works.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于正确制作提示内容对与 LLM 获得有用结果至关重要，提示工程在最近几个月引起了很多关注。然而，这是一门经验科学——发现最佳提示通常是基于启发式的，需要实验。我们可以通过
    [跟踪和版本管理](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)我们的提示，测试不同的想法，来发现更好的提示。
- en: '![](../Images/149b3b2fec56875d26509c1e39e0b80c.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/149b3b2fec56875d26509c1e39e0b80c.png)'
- en: Prompting an LLM with instructions (created by author)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 用指令来提示 LLM（由作者创建）
- en: '**Components of a prompt.** There are a variety of options for how a prompt
    can be created. However, most prompts are comprised of the same few (optional)
    components:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示的组成部分。** 提示可以创建的选项有很多种。然而，大多数提示由相同的几个（可选）组件组成：'
- en: '*Input Data*: this is the actual data that the LLM is expected to process (e.g.,
    the sentence being translated or classified, the document being summarized, etc.).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输入数据*：这是 LLM 预计处理的实际数据（例如，要翻译或分类的句子，要总结的文档等）。'
- en: '*Exemplars*: one of the best ways to demonstrate the correct behavior to an
    LLM is to provide a few concrete examples of input-output pairs inside of the
    prompt.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*示例*：展示 LLM 正确行为的最佳方法之一是提供几个具体的输入-输出对作为提示。'
- en: '*Instruction*: instead of showing concrete exemplars of correct behavior in
    the prompt, we could just textually describe what to do via an instruction; see
    above.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指令*：我们可以通过指令在提示中用文字描述要做的事情，而不是展示具体的正确行为示例；见上文。'
- en: '*Indicators*: providing input to an LLM in a fixed and predictable structure
    is helpful, so we might separate different parts of our prompt by using indicators;
    see below.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指标*：以固定且可预测的结构向LLM提供输入是有帮助的，因此我们可以通过使用指标来分隔提示的不同部分；见下文。'
- en: '*Context*: Beyond the components described above, we may want to provide extra
    “context” or information to the LLM in some way.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*上下文*：除了上述描述的组件，我们可能还希望以某种方式向LLM提供额外的“上下文”或信息。'
- en: '![](../Images/d06bf9cbd0b01696444f4cfcd782607e.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d06bf9cbd0b01696444f4cfcd782607e.png)'
- en: Indicators can be used to structure prompts in a variety of ways (created by
    author)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 指标可以用来以多种方式结构化提示（由作者创建）
- en: '**General tips.** The details of prompt engineering differ a lot depending
    on the model being used and what task we are trying to solve. However, there are
    a few generally-accepted principles for prompt engineering that are helpful to
    keep in mind [1, 3].'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般提示。** 提示工程的细节根据所使用的模型和我们试图解决的任务差异很大。然而，有一些普遍接受的提示工程原则是有帮助的，要牢记这些原则 [1,
    3]。'
- en: '*Start simple*: start with a simple prompt, then slowly modify the prompt while
    tracking empirical results.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*从简单开始*：从简单的提示开始，然后逐步修改提示，同时跟踪经验结果。'
- en: '*Be direct*: if we want the LLM to match a specific style or format, we should
    state this clearly and directly. Stating exactly what you want gets the message
    across.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*直接*：如果我们希望LLM匹配特定的风格或格式，我们应当明确而直接地说明。准确地说出你想要什么可以传达信息。'
- en: '*Specificity*: ambiguity is the enemy of every prompt engineer. We should make
    the prompt detailed and specific without going overboard and providing an input
    that is too long (i.e., there are [limitations](https://platform.openai.com/docs/models/gpt-3)
    to how long the prompt can be!).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*具体性*：模糊性是每个提示工程师的敌人。我们应当使提示详细且具体，但不要过度提供过长的输入（即，提示的长度有 [限制](https://platform.openai.com/docs/models/gpt-3)！）。'
- en: '*Exemplars are powerful*: if describing what we want is difficult, it might
    be useful to provide concrete examples of correct output or behavior for several
    different inputs.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*示例是强大的*：如果描述我们想要的内容很困难，提供几个不同输入的正确输出或行为的具体示例可能会很有用。'
- en: '![](../Images/bf8809fbbb1b85d1a059cf3740534820.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf8809fbbb1b85d1a059cf3740534820.png)'
- en: Visualizing the context window for a language model (created by author)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型的上下文窗口可视化（由作者创建）
- en: '**The context window.** As we consider different prompting tips and approaches,
    we need to remember that we can only include a limited amount of information in
    our prompt. All LLMs have a pre-defined context window that sets a limit on the
    total number of tokens (i.e., words or sub-words in a textual sequence) that can
    be processed at a time. Context window size differs between models, but there
    is currently a strong push towards increasing context window sizes. For example,
    GPT-4 has a context window of 32K tokens, which is [4X bigger](https://platform.openai.com/docs/models/overview)
    than any prior model from OpenAI.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文窗口。** 当我们考虑不同的提示技巧和方法时，我们需要记住我们只能在提示中包含有限的数量的信息。所有LLM都有一个预定义的上下文窗口，设定了可以一次处理的总令牌数（即文本序列中的单词或子词）的限制。上下文窗口的大小在模型之间有所不同，但目前有强烈的推动力来增加上下文窗口的大小。例如，GPT-4
    的上下文窗口为 32K 令牌，比 OpenAI 之前的任何模型都要 [大 4 倍](https://platform.openai.com/docs/models/overview)。'
- en: Common Prompting Techniques
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的提示技术
- en: '![](../Images/3220b2cdf3baa56668d27fc8f96bcc47.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3220b2cdf3baa56668d27fc8f96bcc47.png)'
- en: The emergence of zero and few-shot learning (from [4, 5, 6])
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本和少样本学习的出现（来自 [4, 5, 6]）
- en: Although LLMs have seen a recent explosion due to popular models like [ChatGPT](https://openai.com/blog/chatgpt),
    prompting has been around [for a while](https://twitter.com/cwolferesearch/status/1639378997627826176?s=20).
    Originally, models like [GPT](https://cameronrwolfe.substack.com/i/85568430/improving-language-understanding-by-generative-pre-training-gpt)
    [4] were fine-tuned to solve downstream tasks. With the proposal of [GPT-2](https://cameronrwolfe.substack.com/i/85568430/language-models-are-unsupervised-multitask-learners-gpt)
    [5], we saw researchers start to use zero-shot learning to solve multiple downstream
    tasks with a single [foundation model](https://cameronrwolfe.substack.com/i/85568430/creating-foundation-models).
    Finally, GPT-3 showed us that language models become really good at few-shot learning
    as they grow in size. In this section, we will walk through these ideas to gain
    a better idea of how zero and few-shot learning work, as well as provide details
    on a few more complex prompting techniques.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM由于像[ChatGPT](https://openai.com/blog/chatgpt)这样的热门模型最近经历了爆炸性增长，但提示技术已经存在了[相当一段时间](https://twitter.com/cwolferesearch/status/1639378997627826176?s=20)。最初，像[GPT](https://cameronrwolfe.substack.com/i/85568430/improving-language-understanding-by-generative-pre-training-gpt)
    [4]这样的模型经过微调以解决下游任务。随着[GPT-2](https://cameronrwolfe.substack.com/i/85568430/language-models-are-unsupervised-multitask-learners-gpt)
    [5]的提出，我们看到研究人员开始使用零样本学习来用单一的[基础模型](https://cameronrwolfe.substack.com/i/85568430/creating-foundation-models)解决多个下游任务。最后，GPT-3向我们展示了随着模型规模的增大，语言模型在少样本学习方面变得非常出色。在本节中，我们将深入探讨这些思想，以更好地了解零样本和少样本学习的工作原理，并提供一些更复杂的提示技术的细节。
- en: Zero-Shot Learning
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零样本学习
- en: '![](../Images/d32631e3be2a49eae91f90c24acb9602.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d32631e3be2a49eae91f90c24acb9602.png)'
- en: (from [6])
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [6])
- en: The idea behind zero-shot learning is quite simple. We just feed a description
    of the task being solved and the relevant input data to an LLM and let it generate
    a result; see above. Due to the massive amount of pre-training data they observe,
    LLMs are often pretty capable of solving tasks in this way. Namely, they can leverage
    their knowledge base to solve a (relatively) large number of tasks; see the examples
    below (produced with [GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本学习的基本思想相当简单。我们只需将任务描述和相关的输入数据提供给LLM，并让它生成结果；见上文。由于观察到的大量预训练数据，LLM通常非常有能力以这种方式解决任务。也就是说，它们可以利用其知识库来解决（相对）大量的任务；请见下文示例（由[GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)生成）。
- en: '![](../Images/079e9678916528832a844a0673085c3d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/079e9678916528832a844a0673085c3d.png)'
- en: Zero-shot learning with GPT-3.5 (created by author)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本学习与GPT-3.5（作者创建）
- en: Zero-shot learning was explored extensively by models like GPT-2 and performs
    well in some cases. However, *what should we do if zero-shot learning does not
    solve our task?* In many cases, we can drastically improve the performance of
    an LLM by providing more specific and concrete information. In particular, we
    can start adding examples of desired output to the prompt, allowing the model
    to replicate patterns from data seen in the prompt.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本学习被像GPT-2这样的模型广泛探索，并在某些情况下表现良好。然而，*如果零样本学习无法解决我们的任务，我们应该怎么做？* 在许多情况下，我们可以通过提供更具体和明确的信息来大幅提高LLM的性能。特别是，我们可以开始在提示中添加期望输出的示例，让模型能够复制从提示中看到的数据模式。
- en: Few-Shot Learning
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少样本学习
- en: Beyond just a task description, we can augment our prompt with high-quality
    input-output examples. This technique forms the basis of few-shot learning, which
    attempts to improve LLM performance by providing explicit examples of correct
    behavior. If used properly and applied to the correct model, few-shot learning
    is incredibly effective, as demonstrated by the breakthrough capabilities of LLMs
    like [GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [6]; see below.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了任务描述之外，我们还可以通过高质量的输入输出示例来增强我们的提示。这种技术形成了少样本学习的基础，少样本学习试图通过提供明确的正确行为示例来提高大型语言模型（LLM）的性能。如果使用得当并应用于正确的模型，少样本学习非常有效，这一点通过如[GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [6]等LLM的突破性能力得到了证明；请见下文。
- en: '![](../Images/8760cfa248087a2512e44e35d54cea13.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8760cfa248087a2512e44e35d54cea13.png)'
- en: (from [3])
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [3])
- en: However, learning how to properly leverage the few-shot learning capabilities
    of LLMs can be complicated. *What examples should we include in the prompt? Is
    there a correct way to structure the prompt? Do changes to the prompt significantly
    affect the LLM?*
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，学习如何正确利用大型语言模型的少量示例学习能力可能很复杂。*我们应该在提示中包含哪些示例？是否有正确的提示结构方式？提示的变化是否会显著影响大型语言模型？*
- en: 'Most LLMs are sensitive to the manner in which the prompt is constructed, making
    prompt engineering both difficult and important. Although recent models like GPT-4
    seem to be less sensitive to small perturbations in the prompt [2], the research
    community [7] has provided us with some tips for properly using few-shot learning
    that are still helpful to understand:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数大型语言模型对提示的构造方式很敏感，这使得提示工程既困难又重要。尽管像 GPT-4 这样的最新模型似乎对提示中的小扰动不那么敏感 [2]，但研究社区
    [7] 给我们提供了一些有关如何正确使用少量示例学习的提示，这些提示仍然有助于理解：
- en: Exemplar ordering is important, and permuting few-shot examples can drastically
    change LLM performance. Including more few-shot examples does not solve this problem.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例的排序很重要，打乱少量示例的顺序可能会显著改变大型语言模型的表现。增加更多少量示例并不能解决这个问题。
- en: The distribution of labels in the few-shot examples matters and should match
    the actual distribution of data in the wild. Surprisingly, the correctness of
    labels is not as important.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少量示例中的标签分布很重要，应与实际的数据分布相匹配。令人惊讶的是，标签的正确性并不是那么重要。
- en: LLMs tend to be biased towards repeating the last of the few-shot examples (i.e.,
    recency bias).
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型倾向于重复最后一个少量示例（即近期效应）。
- en: Exemplars that are included in the prompt should be diverse and randomly ordered.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含在提示中的示例应该是多样化且随机排序的。
- en: '**Optimal data sampling.** Selecting examples that are diverse, randomly-ordered,
    and related to the test example is best. Beyond these basic intuitions, however,
    a significant amount of research has been done to determine how to select optimal
    exemplars for a prompt. For example, few-show learning samples can be chosen via
    diversity selection [8], uncertainty-based selection [9], or even selection based
    on similarity to the test example [10].'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**最佳数据采样。** 选择多样化、随机排序且与测试示例相关的示例是最好的。除此之外，还进行了大量研究，以确定如何为提示选择最佳示例。例如，少量学习样本可以通过多样性选择
    [8]、基于不确定性的选择 [9]，甚至是根据与测试示例的相似性进行选择 [10]。'
- en: '![](../Images/727b0fd0968d79861e6d9f4d24bec555.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/727b0fd0968d79861e6d9f4d24bec555.png)'
- en: (from [3])
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [3]）
- en: '**Few-shot learning vs. fine-tuning.** Prior to moving on, I want to address
    a notable [point of confusion](https://twitter.com/NaveenGRao/status/1650255798365462530?s=20).
    *Few-shot learning is not fine-tuning.* Few-shot learning presents examples to
    the LLM inside of the prompt, which can then be used as relevant context for generating
    the correct output. This process is referred to as “in-context learning”; see
    above. The model’s parameters are not modified by few-shot learning. In contrast,
    fine-tuning explicitly trains the model (i.e., updates its weights via backpropagation)
    over a chosen dataset.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**少量学习 vs. 微调。** 在继续之前，我想解决一个显著的 [混淆点](https://twitter.com/NaveenGRao/status/1650255798365462530?s=20)。*少量学习不是微调。*
    少量学习是在提示中向大型语言模型提供示例，这些示例可以作为生成正确输出的相关上下文。这个过程被称为“上下文学习”；见上文。模型的参数不会通过少量学习进行修改。相比之下，微调明确地训练模型（即通过反向传播更新其权重）在选定的数据集上。'
- en: Instruction Prompting
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指令提示
- en: '![](../Images/912eb44c92e90896a71a5e7ddd886249.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/912eb44c92e90896a71a5e7ddd886249.png)'
- en: Using an instruction tuned language model as a coding assistant (from [15])
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用调整过指令的语言模型作为编码助手（来源 [15]）
- en: 'Few-shot learning is incredibly powerful, but it has a notable drawback: *exemplars
    consume a lot of tokens*. Given that the context window of an LLM is limited,
    we might want to explore prompting methods that do not consume as many tokens.
    For example, *can we textually explain the correct behavior to an LLM?* The short
    answer is yes! This technique, which just includes a written instruction as part
    of the prompt, is known as instruction prompting, and it performs best with a
    particular type of LLM.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 少量学习非常强大，但它有一个显著的缺点：*示例消耗大量的标记*。由于大型语言模型的上下文窗口是有限的，我们可能需要探索不会消耗太多标记的提示方法。例如，*我们能否通过文字解释正确的行为给大型语言模型？*
    简短的回答是可以！这种技术，即将书面指令作为提示的一部分，包括在内，被称为指令提示，它在特定类型的大型语言模型上表现最佳。
- en: '**Instruction tuning and alignment.** Recent development of language models
    has heavily focused upon improving instruction following capabilities. Pre-trained
    LLMs are not good at following instructions out-of-the-box. However, teaching
    these models how to follow instructions makes them a lot better at accomplishing
    what the user wants (i.e., improves human [alignment](https://openai.com/blog/our-approach-to-alignment-research)).
    Instruction following LLMs power a variety of useful applications from information
    seeking dialogue agents (e.g., [ChatGPT](https://openai.com/blog/chatgpt)) to
    coding assistants (e.g., [Codex](https://cameronrwolfe.substack.com/i/93578656/evaluating-large-language-models-trained-on-code)
    [13]); see below.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**指令调优与对齐。** 最近，语言模型的发展主要集中在提高指令跟随能力上。预训练的LLM在开箱即用时并不擅长遵循指令。然而，教会这些模型如何遵循指令能使它们更好地完成用户的需求（即，改善人类[对齐](https://openai.com/blog/our-approach-to-alignment-research)）。遵循指令的LLM支持多种有用的应用，从信息检索对话代理（例如，[ChatGPT](https://openai.com/blog/chatgpt)）到编码助手（例如，[Codex](https://cameronrwolfe.substack.com/i/93578656/evaluating-large-language-models-trained-on-code)[13]）；见下文。'
- en: '![](../Images/3d74e918539cfd634dc24318e08a6f7c.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d74e918539cfd634dc24318e08a6f7c.png)'
- en: (from [13, 14])
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: （见[13, 14]）
- en: As has been [discussed extensively](https://cameronrwolfe.substack.com/i/91134599/a-primer-on-language-modeling)
    in prior posts, the first step in creating an LLM is pre-training the model using
    a [language modeling objective](https://cameronrwolfe.substack.com/i/85568430/language-modeling)
    over a large, unlabeled corpus of text. During this process, the model gains information
    and learns to accurately perform next-token prediction. However, the model’s output
    is not always interesting, compelling, or helpful, and the model usually struggles
    to comply with complex instructions. To encourage such behavior, we need to go
    [beyond basic pre-training](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在之前的帖子中[广泛讨论](https://cameronrwolfe.substack.com/i/91134599/a-primer-on-language-modeling)的那样，创建LLM的第一步是使用[语言建模目标](https://cameronrwolfe.substack.com/i/85568430/language-modeling)在大规模的未标记文本语料库上进行预训练。在此过程中，模型获取信息并学会准确地进行下一个词预测。然而，模型的输出并不总是有趣、引人入胜或有帮助，并且模型通常难以遵循复杂的指令。为了鼓励这种行为，我们需要[超越基本的预训练](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)。
- en: '**Creating instruction-following LLMs.** There are a couple of different approaches
    for teaching an LLM how how to follow instructions. For example, we can perform
    [instruction tuning](https://twitter.com/cwolferesearch/status/1652064977493057545?s=20)
    [12], or fine-tune the LLM over examples of dialogues that include instructions.
    Several notable models adopt this approach, such as [LLaMA](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone)
    (and [its variants](https://cameronrwolfe.substack.com/p/beyond-llama-the-power-of-open-llms))
    [15], all FLAN models [12], OPT-IML [16], and more. Alternatively, we could use
    the [three-step approach](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    comprised of [supervised fine-tuning (SFT)](https://cameronrwolfe.substack.com/i/93578656/refining-llm-behavior)
    and reinforcement learning from human feedback (RLHF); see below. This methodology
    has led to the creation of incredible models such as ChatGPT, [GPT-4](https://openai.com/research/gpt-4),
    [Sparrow](https://cameronrwolfe.substack.com/i/93578656/improving-alignment-of-dialogue-agents-via-targeted-human-judgements)
    [17], and more.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建遵循指令的LLM。** 有几种不同的方法可以教会LLM如何遵循指令。例如，我们可以进行[指令调优](https://twitter.com/cwolferesearch/status/1652064977493057545?s=20)[12]，或者在包含指令的对话示例上微调LLM。一些显著的模型采用了这种方法，比如[LLaMA](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone)（及其[变体](https://cameronrwolfe.substack.com/p/beyond-llama-the-power-of-open-llms)）[15]、所有FLAN模型[12]、OPT-IML[16]等。或者，我们可以使用由[监督微调（SFT）](https://cameronrwolfe.substack.com/i/93578656/refining-llm-behavior)和来自人类反馈的强化学习（RLHF）组成的[三步法](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)；见下文。这种方法已经创造出了令人惊叹的模型，如ChatGPT、[GPT-4](https://openai.com/research/gpt-4)、[Sparrow](https://cameronrwolfe.substack.com/i/93578656/improving-alignment-of-dialogue-agents-via-targeted-human-judgements)[17]等。'
- en: '![](../Images/1930f6d4b45842bdbc6598b6d91273d1.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1930f6d4b45842bdbc6598b6d91273d1.png)'
- en: Aligning LLMs based on human feedback (from [13])
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 基于人类反馈对LLM进行对齐（见[13]）
- en: '**crafting useful instructions.** If we have access to an LLM that has been
    trained to follow instructions, we can accomplish a lot by prompting the model
    with useful and informative instructions. Here are some key tips and ideas for
    using instruction prompting:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**制定有用的指令。** 如果我们能够访问到一个已经训练来遵循指令的LLM，我们可以通过给模型提供有用和信息丰富的指令来完成很多工作。以下是一些使用指令提示的关键技巧和想法：'
- en: Just like the rest of our prompt, the instruction should be specific and detailed.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像我们提示的其余部分一样，指令应该是具体和详细的。
- en: We should avoid telling the LLM to not do something in the prompt. Rather, we
    should focus on telling the LLM what to do.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应避免在提示中告诉LLM不要做某事。相反，我们应该专注于告诉LLM要做什么。
- en: Using an input structure with indicators that clearly identify the instruction
    within the prompt is helpful; see below.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用具有清晰指示的输入结构来识别提示中的指令是非常有帮助的；见下文。
- en: '![](../Images/cd645bcd6b8e83cf78f6877c427a45fb.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd645bcd6b8e83cf78f6877c427a45fb.png)'
- en: Different formats for instruction prompting (created by author)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 指令提示的不同格式（由作者创建）
- en: '**Role prompting.** Another interesting prompting technique that is tangentially
    related to instruction prompting is role prompting, which assigns a “role” or
    persona to the model. This role is assigned within the prompt via a textual snippet
    such as:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**角色提示。** 另一种与指令提示相关的有趣提示技术是角色提示，它给模型分配一个“角色”或人格。这个角色在提示中通过一个文本片段被分配，例如：'
- en: You are a famous and brilliant mathematician.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是一位著名且杰出的数学家。
- en: You are a doctor.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是一名医生。
- en: You are a musical expert.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是一个音乐专家。
- en: Interestingly, recent LLMs are able to assume and maintain such roles quite
    well throughout a dialogue [18]; see below.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，最近的LLM能够在对话中很好地承担和维持这些角色[18]；见下文。
- en: '![](../Images/9565b160964aebf82c685d04680e4931.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9565b160964aebf82c685d04680e4931.png)'
- en: Role prompting with LaMDA (from [18])
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 角色提示与LaMDA（来自[18]）
- en: Going further, role prompting isn’t just a fun trick. Providing a role to the
    LLM can actually improve performance (e.g., role prompting GPT-3 as a “brilliant
    mathematician” can [improve performance](https://learnprompting.org/docs/basics/roles)
    on arithmetic-based questions). However, role prompting only improves performance
    in certain cases.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 更进一步，角色提示不仅仅是一个有趣的技巧。给LLM提供一个角色实际上可以提高性能（例如，将GPT-3角色提示为“杰出的数学家”可以[提高性能](https://learnprompting.org/docs/basics/roles)
    在基于算术的问题上）。然而，角色提示仅在某些情况下能提高性能。
- en: “When assigning a role to the AI, we are giving it some context. This context
    helps the AI understand the question better. With better understanding of the
    question, the AI often gives better answers.” *— from* [*learnprompting.org*](https://learnprompting.org/)
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “当给AI分配一个角色时，我们给了它一些背景信息。这个背景帮助AI更好地理解问题。理解问题越好，AI通常会给出更好的答案。” *— 来自* [*learnprompting.org*](https://learnprompting.org/)
- en: '**Instruction prompting in the real world.** Prompting LLMs with instructions
    is an incredibly powerful tool that we can use for a variety of applications.
    To understand how to leverage this technique, we can look no further than the
    recent release of [ChatGPT plugins](https://openai.com/blog/chatgpt-plugins),
    which included an open-source [information retrieval API](https://github.com/openai/chatgpt-retrieval-plugin).
    Inside of this API, there are two specific modules provided for [extracting metadata
    from documents](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/services/extract_metadata.py)
    and [filtering personally identifiable information (PII)](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/services/pii_detection.py).
    Interestingly, these services are entirely LLM-based and use the prompts shown
    below.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**现实世界中的指令提示。** 用指令提示LLMs是一个非常强大的工具，我们可以用它来处理各种应用。为了理解如何利用这一技术，我们可以看看最近发布的[ChatGPT插件](https://openai.com/blog/chatgpt-plugins)，其中包括一个开源的[信息检索API](https://github.com/openai/chatgpt-retrieval-plugin)。在这个API内部，提供了两个特定的模块用于[从文档中提取元数据](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/services/extract_metadata.py)和[过滤个人身份信息（PII）](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/services/pii_detection.py)。有趣的是，这些服务完全基于LLM，并使用如下所示的提示。'
- en: '![](../Images/59bb362f9965d9a835e81c103b770630.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59bb362f9965d9a835e81c103b770630.png)'
- en: Prompts for metadata extraction and PII detection in the ChatGPT information
    retrieval API (created by author)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 用于从ChatGPT信息检索API中提取元数据和检测个人身份信息（由作者创建）
- en: 'Within these prompts, the LLM is provided with specific and detailed instructions
    regarding how to perform its desired task. Some notable aspects of the instructions
    are:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些提示中，LLM获得了有关如何执行期望任务的具体和详细指令。指令的一些显著方面包括：
- en: The desired output format (either json or true/false) is explicitly stated.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 期望的输出格式（无论是json还是true/false）明确说明。
- en: The instruction uses a structured format (i.e., bullet-separated list) to describe
    important information.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指令使用结构化格式（即，以项目符号分隔的列表）来描述重要信息。
- en: The task of the LLM (i.e., identifying PII or extracting metadata) is explicitly
    stated in the prompt.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM的任务（即识别PII或提取元数据）在提示中明确说明。
- en: Interestingly, these prompts tell the model what not to do on multiple occasions,
    which is typically advised against.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有趣的是，这些提示多次告诉模型不要做什么，这通常是不被建议的。
- en: Trusting an LLM to accurately perform critical tasks like PII detection might
    not be the best idea given their limitations. Nonetheless, such an approach demonstrates
    the incredible potential of instruction prompting. Instead of writing an entire
    program or service, we may be able to quickly solve a lot of tasks by just writing
    a prompt.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于LLMs的局限性，信任LLM准确执行如PII检测等关键任务可能不是最佳选择。不过，这种方法展示了指令提示的巨大潜力。与其编写整个程序或服务，我们或许可以通过编写一个提示来快速解决许多任务。
- en: Takeaways
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重点
- en: “Writing a really great prompt for a chatbot persona is an amazingly high-leverage
    skill and an early example of programming in a little bit of natural language”
    *—* [*Sam Altman*](https://twitter.com/sama/status/1627796054040285184?s=20)
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “为聊天机器人角色编写一个真正出色的提示是一个极具杠杆效应的技能，并且是用一点自然语言编程的早期示例” *—* [*Sam Altman*](https://twitter.com/sama/status/1627796054040285184?s=20)
- en: If we learn nothing else from this overview, we should know that constructing
    the correct prompt (i.e., prompt engineering) is a large part of successfully
    leveraging LLMs in practice. Language models, due to their text-to-text structure,
    are incredibly generic and can be used to solve a variety of tasks. However, we
    must provide these models with detailed and appropriate context for them to perform
    well. Although optimal prompting techniques differ depending on the model and
    tasks, there are many high-level takeaways that we can leverage to maximize chances
    of success.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从这次概述中学到的其他东西，我们应该知道构造正确的提示（即提示工程）是成功利用LLMs的关键部分。由于语言模型的文本到文本结构，它们非常通用，可以用来解决各种任务。然而，我们必须为这些模型提供详细和适当的上下文，以便它们表现良好。尽管最佳提示技术因模型和任务而异，但有许多高层次的要点可以帮助我们最大化成功的机会。
- en: '**from zero to few-shot learning.** Given their extensive pre-training (and,
    these days, fine-tuning) datasets, LLMs contain a ton of information and are capable
    of solving a variety of tasks out-of-the-box. To do this, we only provide the
    model with a task description and relevant input data, then the model is expected
    to generate the correct output. However, zero-shot learning can only perform so
    well due to the limited context provided to the model. To improve upon the performance
    of zero-shot learning, we should leverage few-show learning by inserting exemplars
    in the prompt.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**从零到少样本学习。** 由于其广泛的预训练（以及如今的微调）数据集，大型语言模型（LLMs）包含大量信息，并能够开箱即用地解决各种任务。为此，我们仅需向模型提供任务描述和相关输入数据，然后模型会生成正确的输出。然而，由于提供给模型的上下文有限，零样本学习的效果有限。为了提升零样本学习的表现，我们应该通过在提示中插入示例来利用少样本学习。'
- en: '**instruction-following LLMs.** Although it performs well, few-shot learning
    typically consumes a lot of tokens, which is a problem given the limited context
    window of most LLMs. To work around this, we can adopt an instruction prompting
    approach that provides a precise, textual description of the LLM’s desired behavior
    as opposed to capturing this behavior with concrete examples of correct output.
    Instruction prompting is powerful, but it requires a specific form of LLM that
    has been fine-tuned (e.g., via instruction tuning or RLHF) to work well. Pre-trained
    LLMs are not great at following instructions out of the box.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**指令跟随LLMs。** 尽管表现良好，少样本学习通常会消耗大量的tokens，这在大多数LLMs的上下文窗口有限的情况下是个问题。为了应对这一点，我们可以采用一种指令提示的方法，提供LLM期望行为的精确文本描述，而不是通过正确输出的具体示例来捕捉这种行为。指令提示是强大的，但它需要一种经过特定形式微调的LLM（例如，通过指令调优或RLHF）才能良好工作。预训练的LLMs在开箱即用时并不擅长跟随指令。'
- en: '**tips and tricks.** Prompt engineering comes with a variety of tricks and
    best practices that can be adopted. Typically, such techniques fluctuate with
    each new model release (e.g., GPT-4 is much better at handling unstructured prompts
    compared to prior models [2]), but a few principles have remained applicable for
    quite some time. First, we should always start with a simple prompt, then slowly
    add complexity. As we develop our prompt, we should aim to be specific and detailed,
    while avoiding being overly verbose (due to the limited context window). Finally,
    to truly maximize LLM performance, we usually need to leverage few-shot learning,
    instruction prompting, or a [more complex approach](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**技巧和窍门。** 提示工程有各种技巧和最佳实践可以采纳。通常，这些技巧会随着每次新模型发布而变化（例如，GPT-4 在处理非结构化提示方面比之前的模型
    [2] 更加出色），但一些原则已经适用了一段时间。首先，我们应该始终从简单的提示开始，然后逐渐增加复杂性。在发展我们的提示时，我们应当尽量具体和详细，同时避免过于冗长（由于有限的上下文窗口）。最后，为了真正最大化
    LLM 的性能，我们通常需要利用少样本学习、指令提示或 [更复杂的方法](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms)。'
- en: Closing Remarks
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束语
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. You can also check out my [other
    writings](https://medium.com/@wolfecameron) on medium! If you liked it, please
    follow me on [twitter](https://twitter.com/cwolferesearch) or subscribe to my
    [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/), where
    I help readers build a deeper understanding of topics in AI research via understandable
    overviews of popular papers.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢阅读这篇文章。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)， [Rebuy](https://www.rebuyengine.com/)
    的 AI 总监。我研究深度学习的实证和理论基础。你也可以查看我在 medium 上的 [其他文章](https://medium.com/@wolfecameron)！如果你喜欢这篇文章，请关注我的
    [twitter](https://twitter.com/cwolferesearch) 或订阅我的 [Deep (Learning) Focus 时事通讯](https://cameronrwolfe.substack.com/)，在这里我通过对流行论文的易懂概述，帮助读者深入理解
    AI 研究中的主题。
- en: Bibliography
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Raffel, Colin, et al. “Exploring the limits of transfer learning with a
    unified text-to-text transformer.” *The Journal of Machine Learning Research*
    21.1 (2020): 5485–5551.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Raffel, Colin 等。“使用统一的文本到文本变换器探索迁移学习的极限。” *机器学习研究杂志* 21.1 (2020)：5485–5551。'
- en: '[2] Saravia, Elvis, et al. “Prompt Engineering Guide”, [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
    (2022).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Saravia, Elvis 等。“提示工程指南”， [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
    (2022)。'
- en: '[3] Weng, Lilian. (Mar 2023). Prompt Engineering. Lil’Log. [https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Weng, Lilian. (2023年3月)。提示工程。Lil’Log。 [https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.)'
- en: '[4] Radford, Alec, et al. “Improving language understanding by generative pre-training.”
    (2018).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Radford, Alec 等。“通过生成性预训练提高语言理解。” (2018)。'
- en: '[5] Radford, Alec, et al. “Language Models are Unsupervised Multitask Learners.”'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Radford, Alec 等。“语言模型是无监督的多任务学习者。”'
- en: '[6] Brown, Tom, et al. “Language models are few-shot learners.” *Advances in
    neural information processing systems* 33 (2020): 1877–1901.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Brown, Tom 等。“语言模型是少样本学习者。” *神经信息处理系统进展* 33 (2020)：1877–1901。'
- en: '[7] Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021\.
    Calibrate before use: Improving few-shot performance of language models. ICML.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein 和 Sameer Singh. 2021年。使用前的校准：提高语言模型的少样本性能。ICML。'
- en: '[8] Su, Hongjin, et al. “Selective annotation makes language models better
    few-shot learners.” *arXiv preprint arXiv:2209.01975* (2022).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Su, Hongjin 等。“选择性标注使语言模型成为更好的少样本学习者。” *arXiv 预印本 arXiv:2209.01975* (2022)。'
- en: '[9] Diao, Shizhe, et al. “Active Prompting with Chain-of-Thought for Large
    Language Models.” *arXiv preprint arXiv:2302.12246* (2023).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Diao, Shizhe 等。“使用思维链的主动提示用于大型语言模型。” *arXiv 预印本 arXiv:2302.12246* (2023)。'
- en: '[10] Liu, Jiachang, et al. “What Makes Good In-Context Examples for GPT-$3
    $?.” *arXiv preprint arXiv:2101.06804* (2021).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Liu, Jiachang 等。“什么样的上下文示例对 GPT-$3 $? 有效。” *arXiv 预印本 arXiv:2101.06804*
    (2021)。'
- en: '[11] Wei, Jason, et al. “Chain of thought prompting elicits reasoning in large
    language models.” *arXiv preprint arXiv:2201.11903* (2022).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] Wei, Jason 等。“思维链提示在大型语言模型中引发推理。” *arXiv 预印本 arXiv:2201.11903* (2022)。'
- en: '[12] Wei, Jason, et al. “Finetuned language models are zero-shot learners.”
    *arXiv preprint arXiv:2109.01652* (2021).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] Wei, Jason, 等. “微调语言模型是零样本学习者。” *arXiv 预印本 arXiv:2109.01652* (2021)。'
- en: '[13] Chen, Mark, et al. “Evaluating large language models trained on code.”
    *arXiv preprint arXiv:2107.03374* (2021).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] Chen, Mark, 等. “评估训练于代码上的大型语言模型。” *arXiv 预印本 arXiv:2107.03374* (2021)。'
- en: '[14] Ouyang, Long, et al. “Training language models to follow instructions
    with human feedback.” *Advances in Neural Information Processing Systems* 35 (2022):
    27730–27744.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] Ouyang, Long, 等. “通过人类反馈训练语言模型以遵循指令。” *神经信息处理系统进展* 35 (2022): 27730–27744。'
- en: '[15] Touvron, Hugo, et al. “Llama: Open and efficient foundation language models.”
    *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[15] Touvron, Hugo, 等. “Llama：开放且高效的基础语言模型。” *arXiv 预印本 arXiv:2302.13971* (2023)。'
- en: '[16] Iyer, Srinivasan, et al. “OPT-IML: Scaling Language Model Instruction
    Meta Learning through the Lens of Generalization.” *arXiv preprint arXiv:2212.12017*
    (2022).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[16] Iyer, Srinivasan, 等. “OPT-IML：通过广义化视角扩展语言模型指令元学习。” *arXiv 预印本 arXiv:2212.12017*
    (2022)。'
- en: '[17] Glaese, Amelia, et al. “Improving alignment of dialogue agents via targeted
    human judgements.” *arXiv preprint arXiv:2209.14375* (2022).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[17] Glaese, Amelia, 等. “通过针对性的人工判断改善对话代理的对齐。” *arXiv 预印本 arXiv:2209.14375*
    (2022)。'
- en: '[18] Thoppilan, Romal, et al. “Lamda: Language models for dialog applications.”
    *arXiv preprint arXiv:2201.08239* (2022).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[18] Thoppilan, Romal, 等. “Lamda：对话应用的语言模型。” *arXiv 预印本 arXiv:2201.08239* (2022)。'
