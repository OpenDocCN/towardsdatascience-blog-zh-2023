- en: Forward and Backward Mapping for Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/forward-and-backward-mapping-for-computer-vision-833436e2472](https://towardsdatascience.com/forward-and-backward-mapping-for-computer-vision-833436e2472)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Forward Mapping and Backward Mapping applied to the transformation of images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@JavierMtz5?source=post_page-----833436e2472--------------------------------)[![Javier
    Martínez Ojeda](../Images/5b5df4220fa64c13232c29de9b4177af.png)](https://medium.com/@JavierMtz5?source=post_page-----833436e2472--------------------------------)[](https://towardsdatascience.com/?source=post_page-----833436e2472--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----833436e2472--------------------------------)
    [Javier Martínez Ojeda](https://medium.com/@JavierMtz5?source=post_page-----833436e2472--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----833436e2472--------------------------------)
    ·8 min read·May 25, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70e8ea23d3113c4bc92f03ce050b98d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vadim Bogulov](https://unsplash.com/@franku84?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: If you want to read this article without a Premium Medium account, you can do
    it from this friend link :)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[https://www.learnml.wiki/forward-and-backward-mapping-for-computer-vision/](https://www.learnml.wiki/forward-and-backward-mapping-for-computer-vision/)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this article two algorithms for image warping will be presented and explained:
    **forward mapping** and **backward mapping**. In addition to introducing these
    algorithms at a theoretical level, they will also be applied to real images to
    see the results and capabilities of each algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: In order to fully understand everything explained in this article it is necessary
    to be familiar with 2D transformation matrices, which were introduced and explained
    in [the previous article](https://medium.com/@JavierMtz5/2d-matrix-transformations-for-computer-vision-80b4a4f2120f).
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@JavierMtz5/2d-matrix-transformations-for-computer-vision-80b4a4f2120f?source=post_page-----833436e2472--------------------------------)
    [## 2D Matrix Transformations for Computer Vision'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling, Rotation and Translation through transformation matrices for Computer
    Vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@JavierMtz5/2d-matrix-transformations-for-computer-vision-80b4a4f2120f?source=post_page-----833436e2472--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As seen in the previous article, the way to apply transformations on images
    is to iterate over each of the pixels of the image and apply the transformation
    on each of them individually. However, there are certain use cases in which the
    transformations cannot be applied directly, since, for example, the new positions
    of some pixels might be outside the image domain. Another possible problem is
    that the new image could have empty pixels (white stripes), because it is difficult
    to map all pixels of the original image to all pixels of the new image after the
    transformation.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid some of these problems, the two algorithms that will be presented in
    this article, **forward mapping** and **backward mapping**, are used, which apply
    different techniques to transform the images correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Forward Mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The forward mapping process consists of the simple image transformation process
    that has been discussed in the introduction and in the previous article: it iterates
    over all the pixels of the image, and the corresponding transformation is applied
    to each pixel individually. However, those cases in which the new position of
    the transformed pixel falls outside the image domain, an example of which is shown
    below, must be taken into account.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1e994393d52e63a666940568c696591e.png)'
  prefs: []
  type: TYPE_IMG
- en: Transformed image’s pixels fall outside the original image domain. **Image by
    author**
  prefs: []
  type: TYPE_NORMAL
- en: To carry out the forward mapping process, first define a function that receives
    as parameters the original coordinates of a pixel. This function will apply a
    transformation to the original pixel coordinates, and return the new coordinates
    of the pixel after the transformation. The following code example shows the function
    for the rotation transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Once you have this function, you only need to iterate over each pixel of the
    image, apply the transformation and check if the new pixel coordinates are within
    the domain of the original image. If the new coordinates are within the domain,
    the pixel on the new coordinates of the new image will take the value that the
    original pixel had in the original image. If it falls outside the image, the pixel
    is omitted.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The result of applying a rotation transformation with foward mapping can be
    seen in the image below, where on the left is the original image, and on the right
    the transformed image. It is important to note that for this image the origin
    of coordinates is in the upper left corner, so the image rotates around that point
    anti-clockwise.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b8fe93b2a0a1854e1d9a6adb07f1bbf.png)'
  prefs: []
  type: TYPE_IMG
- en: Results of applying Forward Mapping. **Left image extracted from MNIST Dataset
    [1]. Full image by author**
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the result of the transformation, it can be seen how the transformed
    image does not have the full-black background that the original one has, but instead
    has many white stripes. This happens, as mentioned in the introduction, because
    the pixels of the original image do not always map to all the pixels of the new
    image. Since the new coordinates are calculated by rounding to the nearest pixel,
    this results in many intermediate pixels never receiving a value. In this case,
    as the new image is initialized with all pixels blank, the pixels that have not
    been given a value during the transformation will remain blank, generating those
    white stripes in the transformed image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, it should be noted that there is another notable problem: overlaps.
    This problem occurs when two pixels of the original image are transformed to the
    same pixel of the new image. For the code used in this article, if there are two
    pixels of the original image that map to the same pixel of the new image, the
    new pixel will take the value of the last original pixel that has been transformed,
    overwriting the value of the first one that was already set.'
  prefs: []
  type: TYPE_NORMAL
- en: Backward Mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The backward mapping algorithm arises from the need to eliminate the white stripes
    that are generated in the image due to the transformation, as well as the possible
    overlaps. As has been said, these stripes appear when not all the pixels of the
    transformed image take a value, because of rounding during the calculation of
    the new coordinates in the forward mapping process, and the overlaps occur when
    two or more pixels of the original image map to the same pixel of the new image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logic behind this algorithm is easy: instead of transforming each pixel
    of the original image to its new coordinates in the new image (forward), this
    time all the pixels of the new image are inversely transformed to pixels of the
    original image (backward). In this way, there will never be any pixel without
    value in the new image, since they will all take the value of a single pixel of
    the original image, thus solving both problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, the transformation that is applied to the coordinates of a pixel using
    a transformation matrix can be undone by following the same process with the inverse
    transformation matrix. This property of transformation matrices, together with
    its proof, can be seen in the figure below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8659bb90b475febb8cdd224d21ca1a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Transformations with Inverse Transformation Matrix and proof. **Image by author**
  prefs: []
  type: TYPE_NORMAL
- en: Taking into account this property, the algorithm consists of iterating over
    each pixel of the new image, and applying the inverse transformation to each of
    these pixel’s coordinates to know from which pixel of the original image they
    have to take the value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that the ***apply_inverse_transformation()*** function takes as input the
    coordinates in the new image, and returns the coordinates in the original image,
    instead of receiving the original coordinates and returning the new ones, as was
    the case for forward mapping.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The result of applying a rotation transformation with backward mapping can be
    seen in the image below, where on the left is the original image, and on the right
    the transformed image. As mentioned previously, the image rotates about the origin
    of coordinates, which is located in the upper left corner.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/12c1d821afb3dc25607c2f01c6e06dcb.png)'
  prefs: []
  type: TYPE_IMG
- en: Results of applying Backward Mapping. **Left image extracted from MNIST Dataset
    [1]. Full image by author**
  prefs: []
  type: TYPE_NORMAL
- en: In the image you can see how all those white stripes that appeared when applying
    forward mapping have disappeared when applying backward mapping. In fact you can
    see how the quality of the transformed image is quite good (we must take into
    account that the quality of the original image is not very good), so we can consider
    the backward mapping algorithm much better than forward mapping for those cases
    in which white stripes appear during the transformation.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forward mapping is a simple to implement and easy to understand algorithm, since
    it consists of the direct transformation of each pixel of the original image to
    the new image. However, this algorithm presents the overlapping problem, and the
    problem of leaving many pixels without value, which considerably lowers the quality
    of the transformed image. The backward mapping algorithm, whose implementation
    is just as straightforward as forward mapping, has much better results and solves
    both problems, because it gives a single value to all pixels of the new image.
  prefs: []
  type: TYPE_NORMAL
- en: As for the execution time of the algorithms, both have the same complexity,
    so it will generally always be a better idea to use the backward mapping algorithm,
    due to its better results. In an ideal scenario, the function in charge of applying
    the individual transformations on each pixel (called ***apply_transformation()***
    and ***apply_inverse_transformation()*** in this article) will not construct the
    transformation matrix, but will receive it as a parameter. This will save the
    execution time needed by the forward mapping algorithm to build the transformation
    matrix, and by the backward mapping algorithm to build the matrix and invert it.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, the backward mapping algorithm achieves very good results compared
    to forward mapping, both having practically the same execution time. However,
    it should be noted that both algorithms need a long time to carry out the transformation
    for high resolution images, although they are still very useful to establish the
    bases on which other more powerful transformation algorithms are built.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The image used along the article is extracted from the MNIST dataset **[1]**.
    The dataset is made available under a [Creative Commons Attribution-Share Alike
    3.0 license](https://creativecommons.org/licenses/by-sa/3.0/).
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**[1]** [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
  prefs: []
  type: TYPE_NORMAL
