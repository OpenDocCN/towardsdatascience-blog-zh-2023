["```py\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport os\n```", "```py\ndef get_first_parquet_from_path(path):\n    for (dir_path, _, files) in os.walk(path):\n        for f in files:\n            if f.endswith(\".parquet\"):\n                first_pq_path = os.path.join(dir_path, f)\n                return first_pq_path\n```", "```py\npath = 'APPLICATIONS_PARTITIONED'\nfirst_pq = get_first_parquet_from_path(path)\nfirst_pq\n#Output : APPLICATIONS_PARTITIONED/NAME_INCOME_TYPE=Commercial associate/CODE_GENDER=F/6183f182ab0b47c49cf56a3e09a3a7b1-0.parquet\n```", "```py\nfirst_ds = pq.read_table(first_pq)\nfirst_ds.num_rows, first_ds.num_columns, first_ds.schema\n```", "```py\nts=pq.read_metadata(first_pq)\nts.num_rows, ts.num_columns, pq.read_schema(first_pq)\n```", "```py\nparquet_file = pq.ParquetFile(first_pq)\nts=parquet_file.metadata.row_group(0)\nfor nm in range(ts.num_columns):\n    print(ts.column(nm))\n```", "```py\nbeautiful_df = pd.DataFrame()\nfor nm in range(ts.num_columns):\n    path_in_schema = ts.column(nm).path_in_schema\n    compressed_size = ts.column(nm).total_compressed_size\n    stats = ts.column(nm).statistics\n    min_value = stats.min\n    max_value = stats.max\n    physical_type = stats.physical_type\n    beautiful_df[path_in_schema] = pd.DataFrame([physical_type, min_value, max_value, compressed_size])\ndf = beautiful_df.T\ndf.columns = ['DTYPE', 'Min', 'Max', 'Compressed_Size_(KO)']\n```", "```py\ndef get_all_partitions(path):\n    partitions = {}\n    i = 0\n    for (_, partitions_layer, _) in os.walk(path):\n        if len(partitions_layer)>0:\n            key = partitions_layer[0].split('=')[0]\n            partitions[key] = sorted([partitions_layer[i].split('=')[1] for i in range(len(partitions_layer))])\n        else:\n            break\n    return partitions\n```", "```py\nps = get_all_partitions(path)\nps.keys(), ps.values()\n```", "```py\ndf_pensioner = pd.read_parquet('APPLICATIONS_PARTITIONED/NAME_INCOME_TYPE=Pensioner/')\n```", "```py\npq_table = pq.read_table('APPLICATIONS_PARTITIONED')\npq.write_to_dataset(pq_table, 'APPLICATIONS_REPARTITIONED', partition_cols=['NAME_INCOME_TYPE'])\n```", "```py\npartitions = get_all_partitions('APPLICATIONS_REPARTITIONED')\npartitions.keys(), partitions.values()\n```"]