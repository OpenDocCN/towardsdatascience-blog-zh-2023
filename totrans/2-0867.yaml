- en: 'Extracting Text from PDF Files with Python: A Comprehensive Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Python ä» PDF æ–‡ä»¶ä¸­æå–æ–‡æœ¬ï¼šå…¨é¢æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517](https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517](https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517)
- en: A complete process to extract textual information from tables, images, and plain
    text from a PDF file
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä» PDF æ–‡ä»¶ä¸­æå–è¡¨æ ¼ã€å›¾åƒå’Œçº¯æ–‡æœ¬çš„å®Œæ•´è¿‡ç¨‹
- en: '[](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[![George
    Stavrakis](../Images/50a2e9cac1e0af3e9a8402379d6a1f29.png)](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    [George Stavrakis](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[![George
    Stavrakis](../Images/50a2e9cac1e0af3e9a8402379d6a1f29.png)](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    [George Stavrakis](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    Â·17 min readÂ·Sep 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    Â·17åˆ†é’Ÿé˜…è¯»Â·2023å¹´9æœˆ21æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b9b1eb9c7f8d41e7811c0bdffa0143f2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9b1eb9c7f8d41e7811c0bdffa0143f2.png)'
- en: Photo by [Giorgio Trovato](https://unsplash.com/@giorgiotrovato?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº [Giorgio Trovato](https://unsplash.com/@giorgiotrovato?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: In the age of Large Language Models (LLMs) and [their wide-ranging applications](https://bit.ly/49i8JoP),
    from simple text summarisation and translation to predicting stock performance
    based on sentiment and financial report topics, the importance of text data has
    never been greater.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠå…¶ [å¹¿æ³›åº”ç”¨](https://bit.ly/49i8JoP) çš„æ—¶ä»£ï¼Œä»ç®€å•çš„æ–‡æœ¬æ€»ç»“å’Œç¿»è¯‘åˆ°åŸºäºæƒ…æ„Ÿå’Œè´¢åŠ¡æŠ¥å‘Šä¸»é¢˜é¢„æµ‹è‚¡ç¥¨è¡¨ç°ï¼Œæ–‡æœ¬æ•°æ®çš„é‡è¦æ€§æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½å¤§ã€‚
- en: There are many types of documents that share this kind of unstructured information,
    from web articles and blog posts to handwritten letters and poems. However, a
    significant portion of this text data is stored and transferred in PDF format.
    More specifically, it has been found that over 2 billion PDFs are opened in Outlook
    each year, while 73 million new PDF files are saved in Google Drive and email
    daily (2).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šç±»å‹çš„æ–‡æ¡£éƒ½åŒ…å«è¿™ç§éç»“æ„åŒ–çš„ä¿¡æ¯ï¼Œä»ç½‘é¡µæ–‡ç« å’Œåšå®¢å¸–å­åˆ°æ‰‹å†™ä¿¡ä»¶å’Œè¯—æ­Œã€‚ç„¶è€Œï¼Œå¤§é‡çš„æ–‡æœ¬æ•°æ®ä»¥ PDF æ ¼å¼å­˜å‚¨å’Œä¼ è¾“ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæ¯å¹´åœ¨ Outlook
    ä¸­æ‰“å¼€çš„ PDF è¶…è¿‡ 20 äº¿ä¸ªï¼Œè€Œæ¯å¤©åœ¨ Google Drive å’Œç”µå­é‚®ä»¶ä¸­ä¿å­˜çš„æ–° PDF æ–‡ä»¶è¾¾åˆ° 7300 ä¸‡ä¸ª (2)ã€‚
- en: Developing, therefore, a more systematic way to process these documents and
    extract information from them would give us the ability to have an automated flow
    and better understand and utilise this vast volume of textual data. And for this
    task, of course, our best friend could be none other than Python.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¼€å‘ä¸€ç§æ›´ç³»ç»Ÿçš„æ–¹æ³•æ¥å¤„ç†è¿™äº›æ–‡æ¡£å¹¶ä»ä¸­æå–ä¿¡æ¯å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿå®ç°è‡ªåŠ¨åŒ–æµç¨‹ï¼Œæ›´å¥½åœ°ç†è§£å’Œåˆ©ç”¨è¿™ä¸€å¤§æ‰¹æ–‡æœ¬æ•°æ®ã€‚ä¸ºäº†å®Œæˆè¿™ä¸€ä»»åŠ¡ï¼Œå½“ç„¶ï¼Œæˆ‘ä»¬æœ€å¥½çš„æœ‹å‹æ— ç–‘å°±æ˜¯
    Pythonã€‚
- en: 'However, before we start our process, we need to specify the different types
    of PDFs that are around these days, and more specifically, the three most frequently
    appearing:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ˜ç¡®ç°åœ¨å­˜åœ¨çš„ä¸åŒç±»å‹çš„ PDFï¼Œç‰¹åˆ«æ˜¯æœ€å¸¸è§çš„ä¸‰ç§ç±»å‹ï¼š
- en: '**Programmatically generated PDFs**: These PDFs are created on a computer using
    either W3C technologies such as HTML, CSS, and Javascript or another software
    like Adobe Acrobat. This type of file can contain various components, such as
    images, text, and links, which are all searchable and easy to edit.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç¨‹åºç”Ÿæˆçš„ PDF**ï¼šè¿™äº› PDF æ˜¯ä½¿ç”¨ W3C æŠ€æœ¯å¦‚ HTMLã€CSS å’Œ JavaScript æˆ–å…¶ä»–è½¯ä»¶å¦‚ Adobe Acrobat
    åœ¨è®¡ç®—æœºä¸Šåˆ›å»ºçš„ã€‚è¿™ç§ç±»å‹çš„æ–‡ä»¶å¯ä»¥åŒ…å«å„ç§ç»„ä»¶ï¼Œå¦‚å›¾åƒã€æ–‡æœ¬å’Œé“¾æ¥ï¼Œè¿™äº›éƒ½å¯ä»¥è¢«æœç´¢å’Œè½»æ¾ç¼–è¾‘ã€‚'
- en: '**Traditional scanned documents**: These PDFs are created from non-electronic
    mediums through a scanner machine or a mobile app. These files are nothing more
    than a collection of images stored together in a PDF file. Saying that, the elements
    appearing in these images, like the text, or links canâ€™t be selected or searched.
    Essentially, the PDF serves as a container for these images.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¼ ç»Ÿæ‰«ææ–‡æ¡£**ï¼šè¿™äº›PDFæ˜¯é€šè¿‡æ‰«æä»ªæˆ–ç§»åŠ¨åº”ç”¨ç¨‹åºä»éç”µå­ä»‹è´¨åˆ›å»ºçš„ã€‚è¿™äº›æ–‡ä»¶åªæ˜¯å­˜å‚¨åœ¨PDFæ–‡ä»¶ä¸­çš„å›¾åƒé›†åˆã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå›¾åƒä¸­å‡ºç°çš„å…ƒç´ ï¼Œå¦‚æ–‡æœ¬æˆ–é“¾æ¥ï¼Œæ— æ³•è¢«é€‰æ‹©æˆ–æœç´¢ã€‚æœ¬è´¨ä¸Šï¼ŒPDFä½œä¸ºè¿™äº›å›¾åƒçš„å®¹å™¨ã€‚'
- en: '**Scanned documents with OCR:** In this case, Optical Character Recognition
    (OCR) software is employed after scanning the document to identify the text within
    each image in the file, converting it into searchable and editable text. Then
    the software adds a layer with the actual text to the image, and that way you
    can select it as a separate component when browsing the file. (3)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¸¦æœ‰OCRçš„æ‰«ææ–‡æ¡£**ï¼šåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨æ‰«ææ–‡æ¡£åï¼Œä½¿ç”¨å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰è½¯ä»¶æ¥è¯†åˆ«æ–‡ä»¶ä¸­æ¯ä¸ªå›¾åƒä¸­çš„æ–‡æœ¬ï¼Œå°†å…¶è½¬æ¢ä¸ºå¯æœç´¢å’Œå¯ç¼–è¾‘çš„æ–‡æœ¬ã€‚ç„¶åï¼Œè½¯ä»¶åœ¨å›¾åƒä¸Šæ·»åŠ å®é™…æ–‡æœ¬çš„å±‚ï¼Œä»è€Œåœ¨æµè§ˆæ–‡ä»¶æ—¶å¯ä»¥å°†å…¶ä½œä¸ºå•ç‹¬çš„ç»„ä»¶é€‰æ‹©ã€‚'
- en: Even though nowadays more and more machines have OCR systems installed in them
    that identify the text from scanned documents, there are still documents that
    contain full pages in an image format. Youâ€™ve probably seen that when you read
    a great article and try to select a sentence, but instead you select the whole
    page. This can be a result of a limitation in the specific OCR machine or its
    complete absence. That way, in order not to leave this information undetected
    in this article, I tried to create a process that also considers these cases and
    takes the most out of our precious and information-rich PDFs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ç°åœ¨è¶Šæ¥è¶Šå¤šçš„æœºå™¨è£…æœ‰OCRç³»ç»Ÿæ¥è¯†åˆ«æ‰«ææ–‡æ¡£ä¸­çš„æ–‡æœ¬ï¼Œä½†ä»æœ‰ä¸€äº›æ–‡æ¡£åŒ…å«å…¨é¡µå›¾åƒæ ¼å¼ã€‚ä½ å¯èƒ½å·²ç»é‡åˆ°è¿‡è¿™ç§æƒ…å†µï¼Œå½“ä½ é˜…è¯»ä¸€ç¯‡ç²¾å½©çš„æ–‡ç« å¹¶è¯•å›¾é€‰æ‹©ä¸€ä¸ªå¥å­æ—¶ï¼Œå´é€‰æ‹©äº†æ•´é¡µã€‚è¿™å¯èƒ½æ˜¯ç‰¹å®šOCRæœºå™¨çš„é™åˆ¶æˆ–å®Œå…¨ç¼ºå¤±çš„ç»“æœã€‚å› æ­¤ï¼Œä¸ºäº†ä¸é—æ¼è¿™ç¯‡æ–‡ç« ä¸­çš„ä¿¡æ¯ï¼Œæˆ‘å°è¯•åˆ›å»ºä¸€ä¸ªä¹Ÿè€ƒè™‘è¿™äº›æƒ…å†µçš„è¿‡ç¨‹ï¼Œå¹¶å……åˆ†åˆ©ç”¨æˆ‘ä»¬å®è´µä¸”ä¿¡æ¯ä¸°å¯Œçš„PDFæ–‡ä»¶ã€‚
- en: The Theoretical Approach
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç†è®ºæ–¹æ³•
- en: 'With all these different types of PDF files in mind and the various items that
    compose them, itâ€™s important to perform an initial analysis of the layout of the
    PDF to identify the proper tool needed for each component. More specifically,
    based on the findings of this analysis, we will apply the appropriate method for
    extracting text from the PDF, whether itâ€™s text rendered in a corpus block with
    its metadata, text within images, or structured text within tables. In the scanned
    document without OCR, the approach that identifies and extracts text from images
    will perform all the heavy lifting. The output of this process will be a Python
    dictionary containing information extracted for each page of the PDF file. Each
    key in this dictionary will present the page number of the document, and its corresponding
    value will be a list with the following 5 nested lists containing:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½è¿™äº›ä¸åŒç±»å‹çš„PDFæ–‡ä»¶åŠå…¶ç»„æˆé¡¹ç›®ï¼Œè¿›è¡ŒPDFå¸ƒå±€çš„åˆæ­¥åˆ†ææ˜¯é‡è¦çš„ï¼Œä»¥ç¡®å®šæ¯ä¸ªç»„ä»¶æ‰€éœ€çš„é€‚å½“å·¥å…·ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæ ¹æ®è¿™é¡¹åˆ†æçš„ç»“æœï¼Œæˆ‘ä»¬å°†åº”ç”¨é€‚å½“çš„æ–¹æ³•æ¥æå–PDFä¸­çš„æ–‡æœ¬ï¼Œæ— è®ºæ˜¯å¸¦æœ‰å…ƒæ•°æ®çš„æ–‡æœ¬å—ã€å›¾åƒä¸­çš„æ–‡æœ¬è¿˜æ˜¯è¡¨æ ¼ä¸­çš„ç»“æ„åŒ–æ–‡æœ¬ã€‚åœ¨æ²¡æœ‰OCRçš„æ‰«ææ–‡æ¡£ä¸­ï¼Œè¯†åˆ«å’Œæå–å›¾åƒä¸­æ–‡æœ¬çš„æ–¹æ³•å°†æ‰¿æ‹…æ‰€æœ‰ç¹é‡çš„å·¥ä½œã€‚æ­¤è¿‡ç¨‹çš„è¾“å‡ºå°†æ˜¯ä¸€ä¸ªPythonå­—å…¸ï¼ŒåŒ…å«æå–çš„ä¿¡æ¯ï¼Œæ¯é¡µPDFæ–‡ä»¶çš„ä¿¡æ¯ã€‚æ­¤å­—å…¸ä¸­çš„æ¯ä¸ªé”®å°†è¡¨ç¤ºæ–‡æ¡£çš„é¡µç ï¼Œå¯¹åº”çš„å€¼å°†æ˜¯åŒ…å«ä»¥ä¸‹5ä¸ªåµŒå¥—åˆ—è¡¨çš„åˆ—è¡¨ï¼š
- en: The text extracted per text block of the corpus
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‰æ–‡æœ¬å—æå–çš„æ–‡æœ¬
- en: The format of the text in each text block in terms of font family and size
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ–‡æœ¬å—ä¸­çš„å­—ä½“å®¶æ—å’Œå¤§å°çš„æ ¼å¼
- en: The text extracted from the images on the page
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»é¡µé¢ä¸Šçš„å›¾åƒä¸­æå–çš„æ–‡æœ¬
- en: The text extracted from tables in a structured format
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»è¡¨æ ¼ä¸­ä»¥ç»“æ„åŒ–æ ¼å¼æå–çš„æ–‡æœ¬
- en: The complete text content of the page
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¡µé¢ä¸Šçš„å®Œæ•´æ–‡æœ¬å†…å®¹
- en: '![](../Images/ca4c55a64e4df3b288a1f84f84c3ff01.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca4c55a64e4df3b288a1f84f84c3ff01.png)'
- en: Image by the author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾åƒ
- en: That way, we can achieve a more logical separation of the extracted text per
    source component, and it can sometimes help us to more easily retrieve information
    that usually appears in the specific component (e.g., the company name in a logo
    image). In addition, the metadata extracted from the text, like the font family
    and size, can be used to easily identify text headers or highlighted text of greater
    importance that will help us further separate or post-process the text in multiple
    different chunks. Lastly, retaining the structured table information in a way
    that an LLM can understand will enhance significantly the quality of inferences
    made about relationships within the extracted data. Then these results can be
    composed as an output the all the textual information that appeared on each page.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°å¯¹æ¯ä¸ªæºç»„ä»¶æå–æ–‡æœ¬çš„æ›´åˆç†åˆ†ç¦»ï¼Œæœ‰æ—¶è¿™å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å®¹æ˜“åœ°æ£€ç´¢é€šå¸¸å‡ºç°åœ¨ç‰¹å®šç»„ä»¶ä¸­çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå¾½æ ‡å›¾åƒä¸­çš„å…¬å¸åç§°ï¼‰ã€‚æ­¤å¤–ï¼Œä»æ–‡æœ¬ä¸­æå–çš„å…ƒæ•°æ®ï¼Œå¦‚å­—ä½“ç³»åˆ—å’Œå¤§å°ï¼Œå¯ä»¥ç”¨äºè½»æ¾è¯†åˆ«æ–‡æœ¬æ ‡é¢˜æˆ–çªå‡ºæ˜¾ç¤ºçš„é‡è¦æ–‡æœ¬ï¼Œè¿™å°†å¸®åŠ©æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†ç¦»æˆ–å¯¹æ–‡æœ¬è¿›è¡Œå¤šå—åå¤„ç†ã€‚æœ€åï¼Œä»¥
    LLM å¯ä»¥ç†è§£çš„æ–¹å¼ä¿ç•™ç»“æ„åŒ–è¡¨æ ¼ä¿¡æ¯å°†æ˜¾è‘—æå‡å¯¹æå–æ•°æ®ä¸­å…³ç³»çš„æ¨æ–­è´¨é‡ã€‚ç„¶åï¼Œè¿™äº›ç»“æœå¯ä»¥ä½œä¸ºæ¯é¡µä¸Šå‡ºç°çš„æ‰€æœ‰æ–‡æœ¬ä¿¡æ¯çš„è¾“å‡ºã€‚
- en: You can see a flowchart of this approach in the images below.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥åœ¨ä¸‹å›¾ä¸­æŸ¥çœ‹è¿™ç§æ–¹æ³•çš„æµç¨‹å›¾ã€‚
- en: '![](../Images/d9d68fa706ebff6487d0560e120a2e07.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9d68fa706ebff6487d0560e120a2e07.png)'
- en: Image by the author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Installation of all the necessary libraries
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“
- en: 'Before we start this project, though, we should install the necessary libraries.
    We assume that you have Python 3.10 or above installed on your machine. Otherwise,
    you can install it from [here](https://www.python.org/). Then letâ€™s install the
    following libraries:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œåœ¨å¼€å§‹è¿™ä¸ªé¡¹ç›®ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥å®‰è£…å¿…è¦çš„åº“ã€‚æˆ‘ä»¬å‡è®¾æ‚¨çš„æœºå™¨ä¸Šå·²å®‰è£… Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚å¦åˆ™ï¼Œæ‚¨å¯ä»¥ä»[è¿™é‡Œ](https://www.python.org/)è¿›è¡Œå®‰è£…ã€‚ç„¶åè®©æˆ‘ä»¬å®‰è£…ä»¥ä¸‹åº“ï¼š
- en: '**PyPDF2**: To read the PDF file from the repository path.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyPDF2**ï¼šç”¨äºä»å­˜å‚¨åº“è·¯å¾„ä¸­è¯»å– PDF æ–‡ä»¶ã€‚'
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Pdfminer**: To perform the layout analysis and extract text and format from
    the PDF. (the .six version of the library is the one that supports Python 3)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pdfminer**ï¼šç”¨äºæ‰§è¡Œå¸ƒå±€åˆ†æå¹¶ä» PDF ä¸­æå–æ–‡æœ¬å’Œæ ¼å¼ã€‚ï¼ˆæ”¯æŒ Python 3 çš„åº“ç‰ˆæœ¬ä¸º .sixï¼‰'
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Pdfplumber**: To identify tables in a PDF page and extract the information
    from them.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pdfplumber**ï¼šç”¨äºè¯†åˆ« PDF é¡µä¸­çš„è¡¨æ ¼å¹¶ä»ä¸­æå–ä¿¡æ¯ã€‚'
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Pdf2image**: To convert the cropped PDF image to a PNG image.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pdf2image**ï¼šç”¨äºå°†è£å‰ªåçš„ PDF å›¾åƒè½¬æ¢ä¸º PNG å›¾åƒã€‚'
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**PIL**: To read the PNG image.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**PIL**ï¼šç”¨äºè¯»å– PNG å›¾åƒã€‚'
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Pytesseract**: To extract the text from the images using OCR technology'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pytesseract**ï¼šç”¨äºä½¿ç”¨ OCR æŠ€æœ¯ä»å›¾åƒä¸­æå–æ–‡æœ¬ã€‚'
- en: This is a little trickier to install because first, you need to install [Google
    Tesseract OCR](https://github.com/tesseract-ocr/tesseract), which is an OCR machine
    based on an LSTM model to identify line recognition and character patterns.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å®‰è£…è¿™ä¸ªç¨å¾®å¤æ‚ä¸€äº›ï¼Œå› ä¸ºé¦–å…ˆï¼Œæ‚¨éœ€è¦å®‰è£…[Google Tesseract OCR](https://github.com/tesseract-ocr/tesseract)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº
    LSTM æ¨¡å‹çš„ OCR æœºå™¨ï¼Œç”¨äºè¯†åˆ«è¡Œè¯†åˆ«å’Œå­—ç¬¦æ¨¡å¼ã€‚
- en: You can install this on your machine if you are a Mac user through **Brew**
    from your terminal, and you are good to go.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ˜¯ Mac ç”¨æˆ·ï¼Œå¯ä»¥é€šè¿‡ç»ˆç«¯ä¸­çš„ **Brew** åœ¨æ‚¨çš„æœºå™¨ä¸Šå®‰è£…è¿™äº›åº“ï¼Œå®‰è£…åæ‚¨å°±å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ã€‚
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For Windows users, you can follow these steps to install the [link](https://linuxhint.com/install-tesseract-windows/).
    Then, when you download and install the software, you need to add their executable
    paths to Environment Variables on your computer. Alternatively, you can run the
    following commands to directly include their paths in the Python script using
    the following code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº Windows ç”¨æˆ·ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§è¿™äº›æ­¥éª¤å®‰è£…[é“¾æ¥](https://linuxhint.com/install-tesseract-windows/)ã€‚ç„¶åï¼Œå½“æ‚¨ä¸‹è½½å¹¶å®‰è£…è½¯ä»¶æ—¶ï¼Œæ‚¨éœ€è¦å°†å…¶å¯æ‰§è¡Œè·¯å¾„æ·»åŠ åˆ°è®¡ç®—æœºçš„ç¯å¢ƒå˜é‡ä¸­ã€‚æˆ–è€…ï¼Œæ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œé€šè¿‡ä»¥ä¸‹ä»£ç ç›´æ¥åœ¨
    Python è„šæœ¬ä¸­åŒ…å«å…¶è·¯å¾„ï¼š
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then you can install the Python library
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ‚¨å¯ä»¥å®‰è£… Python åº“
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Lastly, we will import all the libraries at the beginning of our script.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å°†åœ¨è„šæœ¬å¼€å§‹æ—¶å¯¼å…¥æ‰€æœ‰åº“ã€‚
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: So now we are all set. Letâ€™s move to the fun part.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†ã€‚è®©æˆ‘ä»¬è¿›å…¥æœ‰è¶£çš„éƒ¨åˆ†ã€‚
- en: Documentâ€™s Layout Analysis with Python
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Python è¿›è¡Œæ–‡æ¡£å¸ƒå±€åˆ†æ
- en: '![](../Images/b317b2163ebef139cb95efcbfa2b8ffe.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b317b2163ebef139cb95efcbfa2b8ffe.png)'
- en: Image by the author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'For the preliminary analysis, we used the PDFMiner Python library to separate
    the text from a document object into multiple page objects and then break down
    and examine the layout of each page. PDF files inherently lack structured information,
    such as paragraphs, sentences, or words as seen by the human eye. Instead, they
    understand only the individual characters of the text along with their position
    on the page. That way, the PDFMiner tries to reconstruct the content of the page
    into its individual characters along with their position in the file. Then, by
    comparing the distances of those characters from others it composes the appropriate
    words, sentences, lines, and paragraphs of text. (4) To achieve that, the library:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåˆæ­¥åˆ†æï¼Œæˆ‘ä»¬ä½¿ç”¨äº†PDFMiner Pythonåº“å°†æ–‡æ¡£å¯¹è±¡ä¸­çš„æ–‡æœ¬åˆ†ç¦»ä¸ºå¤šä¸ªé¡µé¢å¯¹è±¡ï¼Œç„¶åæ‹†è§£å’Œæ£€æŸ¥æ¯ä¸ªé¡µé¢çš„å¸ƒå±€ã€‚PDFæ–‡ä»¶æœ¬è´¨ä¸Šç¼ºä¹ç»“æ„åŒ–ä¿¡æ¯ï¼Œä¾‹å¦‚æ®µè½ã€å¥å­æˆ–å•è¯ï¼Œå¦‚äººçœ¼æ‰€è§ã€‚ç›¸åï¼Œå®ƒä»¬åªç†è§£æ–‡æœ¬çš„å•ä¸ªå­—ç¬¦åŠå…¶åœ¨é¡µé¢ä¸Šçš„ä½ç½®ã€‚è¿™æ ·ï¼ŒPDFMinerå°è¯•å°†é¡µé¢å†…å®¹é‡å»ºä¸ºå…¶å•ä¸ªå­—ç¬¦åŠå…¶åœ¨æ–‡ä»¶ä¸­çš„ä½ç½®ã€‚ç„¶åï¼Œé€šè¿‡æ¯”è¾ƒè¿™äº›å­—ç¬¦ä¸å…¶ä»–å­—ç¬¦ä¹‹é—´çš„è·ç¦»ï¼Œå®ƒå°†ç»„æˆé€‚å½“çš„å•è¯ã€å¥å­ã€è¡Œå’Œæ®µè½æ–‡æœ¬ã€‚ï¼ˆ4ï¼‰ä¸ºå®ç°è¿™ä¸€ç‚¹ï¼Œè¯¥åº“ï¼š
- en: Separates the individual pages from the PDF file using the high-level function
    extract_pages() and converts them into **LTPage** objects.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é«˜é˜¶å‡½æ•°extract_pages()å°†PDFæ–‡ä»¶ä¸­çš„æ¯ä¸ªé¡µé¢åˆ†ç¦»ï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢ä¸º**LTPage**å¯¹è±¡ã€‚
- en: 'Then for each LTPage object, it iterates from each element from top to bottom
    and tries to identify the appropriate component as either:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå¯¹äºæ¯ä¸ªLTPageå¯¹è±¡ï¼Œå®ƒä»é¡¶éƒ¨åˆ°åº•éƒ¨è¿­ä»£æ¯ä¸ªå…ƒç´ ï¼Œå¹¶å°è¯•å°†é€‚å½“çš„ç»„ä»¶è¯†åˆ«ä¸ºï¼š
- en: '**LTFigure** which represents the area of the PDF that can present figures
    or images that have been embedded as another PDF document in the page.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LTFigure**è¡¨ç¤ºPDFä¸­å¯ä»¥å‘ˆç°åµŒå…¥ä¸ºå¦ä¸€ä¸ªPDFæ–‡æ¡£çš„å›¾å½¢æˆ–å›¾åƒçš„åŒºåŸŸã€‚'
- en: '**LTTextContainer** which represents a group of text lines in a rectangular
    area is then analysed further into a list of **LTTextLine** objects. Each one
    of them represents a list of **LTChar** objects, which store the single characters
    of text along with their metadata. (5)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LTTextContainer**è¡¨ç¤ºä¸€ä¸ªçŸ©å½¢åŒºåŸŸä¸­çš„æ–‡æœ¬è¡Œç»„ï¼Œéšåè¿›ä¸€æ­¥åˆ†æä¸º**LTTextLine**å¯¹è±¡çš„åˆ—è¡¨ã€‚æ¯ä¸ª**LTTextLine**å¯¹è±¡è¡¨ç¤ºä¸€ç³»åˆ—**LTChar**å¯¹è±¡ï¼Œè¿™äº›å¯¹è±¡å­˜å‚¨å•ä¸ªå­—ç¬¦åŠå…¶å…ƒæ•°æ®ã€‚ï¼ˆ5ï¼‰'
- en: '**LTRect** represents a 2-dimensional rectangle that can be used to frame images,
    and figures or create tables in an LTPage object.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LTRect**è¡¨ç¤ºä¸€ä¸ªäºŒç»´çŸ©å½¢ï¼Œå¯ç”¨äºæ¡†å®šå›¾åƒã€å›¾å½¢æˆ–åœ¨LTPageå¯¹è±¡ä¸­åˆ›å»ºè¡¨æ ¼ã€‚'
- en: Therefore, based on this reconstruction of the page and the classification of
    its elements either into **LTFigure**, which contains the images or figures of
    the page, **LTTextContainer**, which represents the textual information of the
    page, or **LTRect**, which will be a strong indication of the presence of a table,
    we can apply the appropriate function to better extract the information.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ ¹æ®é¡µé¢çš„é‡å»ºå’Œå…ƒç´ çš„åˆ†ç±»ï¼Œæ— è®ºæ˜¯**LTFigure**ï¼ˆåŒ…å«é¡µé¢ä¸­çš„å›¾åƒæˆ–å›¾å½¢ï¼‰ã€**LTTextContainer**ï¼ˆè¡¨ç¤ºé¡µé¢çš„æ–‡æœ¬ä¿¡æ¯ï¼‰è¿˜æ˜¯**LTRect**ï¼ˆå°†å¼ºçƒˆæŒ‡ç¤ºè¡¨æ ¼çš„å­˜åœ¨ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨é€‚å½“çš„å‡½æ•°ä»¥æ›´å¥½åœ°æå–ä¿¡æ¯ã€‚
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So now that we understand the analysis part of the process, letâ€™s create the
    functions needed to extract the text from each component.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬ç†è§£äº†è¿‡ç¨‹çš„åˆ†æéƒ¨åˆ†ï¼Œè®©æˆ‘ä»¬åˆ›å»ºæå–æ¯ä¸ªç»„ä»¶ä¸­æ–‡æœ¬æ‰€éœ€çš„å‡½æ•°ã€‚
- en: Define the function to extract text from PDF
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®šä¹‰æå–PDFä¸­æ–‡æœ¬çš„å‡½æ•°
- en: From here on, extracting text from a text container is really straightforward.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™é‡Œå¼€å§‹ï¼Œä»æ–‡æœ¬å®¹å™¨ä¸­æå–æ–‡æœ¬éå¸¸ç®€å•ã€‚
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: So to extract text from a text container, we simply use the **get_text**() method
    of the LTTextContainer element. This method retrieves all the characters that
    make up the words within the specific corpus box, storing the output in a list
    of text data. Each element in this list represents the raw textual information
    contained in the container.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè¦ä»æ–‡æœ¬å®¹å™¨ä¸­æå–æ–‡æœ¬ï¼Œæˆ‘ä»¬åªéœ€ä½¿ç”¨**get_text**()æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ£€ç´¢æ„æˆç‰¹å®šè¯­æ–™åº“æ¡†ä¸­çš„å•è¯çš„æ‰€æœ‰å­—ç¬¦ï¼Œå¹¶å°†è¾“å‡ºå­˜å‚¨åœ¨æ–‡æœ¬æ•°æ®åˆ—è¡¨ä¸­ã€‚è¯¥åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ ä»£è¡¨å®¹å™¨ä¸­åŒ…å«çš„åŸå§‹æ–‡æœ¬ä¿¡æ¯ã€‚
- en: 'Now, to identify this textâ€™s format, we iterate through the LTTextContainer
    object to access each text line of this corpus individually. In each iteration,
    a new **LTTextLine** object is created, representing a line of text in this chunk
    of corpus. We then examine whether the nested line element contains text. If it
    does, we access each individual character element as LTChar, which contains all
    the metadata for that character. From this metadata, we extract two types of formats
    and store them in a separate list, positioned correspondingly to the examined
    text:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä¸ºäº†è¯†åˆ«è¿™äº›æ–‡æœ¬çš„æ ¼å¼ï¼Œæˆ‘ä»¬éå†LTTextContainerå¯¹è±¡ï¼Œä»¥é€ä¸€è®¿é—®è¯¥è¯­æ–™åº“çš„æ¯ä¸€è¡Œæ–‡æœ¬ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„**LTTextLine**å¯¹è±¡ï¼Œè¡¨ç¤ºè¯¥è¯­æ–™åº“å—ä¸­çš„ä¸€è¡Œæ–‡æœ¬ã€‚ç„¶åæˆ‘ä»¬æ£€æŸ¥åµŒå¥—çš„è¡Œå…ƒç´ æ˜¯å¦åŒ…å«æ–‡æœ¬ã€‚å¦‚æœåŒ…å«ï¼Œæˆ‘ä»¬è®¿é—®æ¯ä¸ªå•ç‹¬çš„å­—ç¬¦å…ƒç´ ä½œä¸ºLTCharï¼Œå®ƒåŒ…å«è¯¥å­—ç¬¦çš„æ‰€æœ‰å…ƒæ•°æ®ã€‚ä»è¿™äº›å…ƒæ•°æ®ä¸­ï¼Œæˆ‘ä»¬æå–ä¸¤ç§æ ¼å¼ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªå•ç‹¬çš„åˆ—è¡¨ä¸­ï¼Œä¸è¢«æ£€æŸ¥çš„æ–‡æœ¬ç›¸å¯¹åº”ã€‚
- en: The font family of the characters, including whether the character is in bold
    or italic format
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­—ç¬¦çš„å­—ä½“å®¶æ—ï¼ŒåŒ…æ‹¬å­—ç¬¦æ˜¯å¦ä¸ºç²—ä½“æˆ–æ–œä½“æ ¼å¼
- en: The font size for the character
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­—ç¬¦çš„å­—ä½“å¤§å°
- en: Generally, characters within a specific chunk of text tend to have consistent
    formatting unless some are highlighted in bold. To facilitate further analysis,
    we capture the unique values of text formatting for all characters within the
    text and store them in the appropriate list.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç‰¹å®šæ–‡æœ¬å—ä¸­çš„å­—ç¬¦æ ¼å¼è¶‹äºä¸€è‡´ï¼Œé™¤éæœ‰äº›å­—ç¬¦ä»¥ç²—ä½“çªå‡ºæ˜¾ç¤ºã€‚ä¸ºäº†ä¾¿äºè¿›ä¸€æ­¥åˆ†æï¼Œæˆ‘ä»¬æ•è·æ–‡æœ¬ä¸­æ‰€æœ‰å­—ç¬¦çš„ç‹¬ç‰¹æ ¼å¼å€¼ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ç›¸åº”çš„åˆ—è¡¨ä¸­ã€‚
- en: '![](../Images/d29c147610491c54af199c2bcb946554.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d29c147610491c54af199c2bcb946554.png)'
- en: Image by the author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Define the function to extract text from Images
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®šä¹‰æå–å›¾åƒä¸­æ–‡æœ¬çš„å‡½æ•°
- en: Here I believe it is a more tricky part.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªæ›´æ£˜æ‰‹çš„éƒ¨åˆ†ã€‚
- en: '*How to handle text in images found in PDF?*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦‚ä½•å¤„ç†PDFä¸­æ‰¾åˆ°çš„å›¾åƒä¸­çš„æ–‡æœ¬ï¼Ÿ*'
- en: Firstly, we need to establish here that image elements stored in PDFs are not
    in a different format from the file, such as JPEG or PNG. That way in order to
    apply OCR software on them we need first to separate them from the file and then
    convert them into an image format.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œç¡®å®šï¼Œå­˜å‚¨åœ¨PDFä¸­çš„å›¾åƒå…ƒç´ ä¸æ–‡ä»¶çš„å…¶ä»–æ ¼å¼ï¼ˆå¦‚JPEGæˆ–PNGï¼‰æ²¡æœ‰ä¸åŒã€‚å› æ­¤ï¼Œä¸ºäº†å¯¹å®ƒä»¬åº”ç”¨OCRè½¯ä»¶ï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆå°†å®ƒä»¬ä»æ–‡ä»¶ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºå›¾åƒæ ¼å¼ã€‚
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To achieve this, we follow the following process:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éµå¾ªä»¥ä¸‹è¿‡ç¨‹ï¼š
- en: We use the metadata from the LTFigure object detected from PDFMiner to crop
    the image box, utilising its coordinates in the page layout. We then save it as
    a new PDF in our directory using the **PyPDF2** library.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ä»PDFMineræ£€æµ‹åˆ°çš„LTFigureå¯¹è±¡çš„å…ƒæ•°æ®æ¥è£å‰ªå›¾åƒæ¡†ï¼Œåˆ©ç”¨å…¶åœ¨é¡µé¢å¸ƒå±€ä¸­çš„åæ ‡ã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨**PyPDF2**åº“å°†å…¶ä¿å­˜ä¸ºæˆ‘ä»¬ç›®å½•ä¸­çš„æ–°PDFæ–‡ä»¶ã€‚
- en: Then we employ the **convert_from_file**() function from the **pdf2image** library
    to convert all PDF files in the directory into a list of images, saving them in
    PNG format.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨**pdf2image**åº“çš„**convert_from_file**()å‡½æ•°å°†ç›®å½•ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶è½¬æ¢ä¸ºå›¾åƒåˆ—è¡¨ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸ºPNGæ ¼å¼ã€‚
- en: Finally, now that we have our image files we read them in our script using the
    **Image** package of the **PIL** module and implement the **image_to_string**()
    function of pytesseract to extract text from the images using the tesseract OCR
    engine.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œç°åœ¨æˆ‘ä»¬æ‹¥æœ‰äº†å›¾åƒæ–‡ä»¶ï¼Œæˆ‘ä»¬ä½¿ç”¨**PIL**æ¨¡å—çš„**Image**åŒ…åœ¨è„šæœ¬ä¸­è¯»å–è¿™äº›å›¾åƒï¼Œå¹¶å®ç°pytesseractçš„**image_to_string**()å‡½æ•°ï¼Œä½¿ç”¨tesseract
    OCRå¼•æ“ä»å›¾åƒä¸­æå–æ–‡æœ¬ã€‚
- en: As a result, this process returns the text from the images, which we then save
    in a third list within the output dictionary. This list contains the textual information
    extracted from the images on the examined page.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè¿™ä¸ªè¿‡ç¨‹ä»å›¾åƒä¸­æå–æ–‡æœ¬ï¼Œç„¶åæˆ‘ä»¬å°†å…¶ä¿å­˜åœ¨è¾“å‡ºå­—å…¸ä¸­çš„ç¬¬ä¸‰ä¸ªåˆ—è¡¨ä¸­ã€‚è¿™ä¸ªåˆ—è¡¨åŒ…å«ä»è¢«æ£€æŸ¥é¡µé¢ä¸Šçš„å›¾åƒä¸­æå–çš„æ–‡æœ¬ä¿¡æ¯ã€‚
- en: Define the function to extract text from Tables
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®šä¹‰æå–è¡¨æ ¼ä¸­æ–‡æœ¬çš„å‡½æ•°
- en: In this section, we will extract a more logically structured text from tables
    on a PDF page. This is a slightly more complex task than extracting text from
    a corpus because we need to take into account the granularity of the information
    and the relationships formed between data points presented in a table.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä»PDFé¡µé¢ä¸Šçš„è¡¨æ ¼ä¸­æå–æ›´å…·é€»è¾‘ç»“æ„çš„æ–‡æœ¬ã€‚è¿™æ¯”ä»è¯­æ–™åº“ä¸­æå–æ–‡æœ¬è¦å¤æ‚ä¸€äº›ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦è€ƒè™‘ä¿¡æ¯çš„ç²’åº¦ä»¥åŠè¡¨æ ¼ä¸­å‘ˆç°çš„æ•°æ®ç‚¹ä¹‹é—´å½¢æˆçš„å…³ç³»ã€‚
- en: Although there are several libraries used to extract table data from PDFs, with
    [**Tabula-py**](https://pypi.org/project/tabula-py/) being one of the most well-known,
    we have identified certain limitations in their functionality.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æœ‰å‡ ä¸ªåº“ç”¨äºä»PDFä¸­æå–è¡¨æ ¼æ•°æ®ï¼Œ[**Tabula-py**](https://pypi.org/project/tabula-py/)æ˜¯æœ€è‘—åçš„ä¹‹ä¸€ï¼Œä½†æˆ‘ä»¬å‘ç°å®ƒä»¬çš„åŠŸèƒ½å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ã€‚
- en: The most glaring one in our opinion comes from the way that the library identifies
    the different rows of the table using the line-break special character \n in the
    tableâ€™s text. This works pretty well in most of the cases but it fails to capture
    correctly when the text in a cell is wrapped into 2 or more rows, leading to the
    addition of unnecessary empty rows and losing the context of the extracted cell.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çœ‹æ¥ï¼Œæœ€æ˜æ˜¾çš„é—®é¢˜æ¥è‡ªäºåº“ä½¿ç”¨æ¢è¡Œç¬¦\nè¯†åˆ«è¡¨æ ¼çš„ä¸åŒè¡Œã€‚è¿™åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ•ˆæœå¾ˆå¥½ï¼Œä½†å½“å•å…ƒæ ¼ä¸­çš„æ–‡æœ¬è¢«æ¢è¡Œæˆä¸¤è¡Œæˆ–æ›´å¤šè¡Œæ—¶ï¼Œå®ƒæ— æ³•æ­£ç¡®æ•æ‰ï¼Œå¯¼è‡´æ·»åŠ äº†ä¸å¿…è¦çš„ç©ºè¡Œå¹¶ä¸¢å¤±äº†æå–å•å…ƒæ ¼çš„ä¸Šä¸‹æ–‡ã€‚
- en: 'You can see the example below when we tried to extract the data from a table
    using tabula-py:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æŸ¥çœ‹ä¸‹é¢çš„ç¤ºä¾‹ï¼Œå½“æˆ‘ä»¬å°è¯•ä½¿ç”¨tabula-pyæå–è¡¨æ ¼æ•°æ®æ—¶ï¼š
- en: '![](../Images/e51d389d867366c2c04485ef945d1519.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e51d389d867366c2c04485ef945d1519.png)'
- en: Image by the author
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾åƒ
- en: Then, the extracted information is outputted in a Pandas DataFrame instead of
    a string. In most cases, this can be a desirable format but in the case of transformers
    that take into account text, these results need to be transformed before feeding
    into a model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå°†æå–çš„ä¿¡æ¯è¾“å‡ºä¸ºPandas DataFrameï¼Œè€Œä¸æ˜¯å­—ç¬¦ä¸²ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ä¸€ç§ç†æƒ³çš„æ ¼å¼ï¼Œä½†å¯¹äºè€ƒè™‘æ–‡æœ¬çš„transformersï¼Œè¿™äº›ç»“æœéœ€è¦åœ¨è¾“å…¥æ¨¡å‹ä¹‹å‰è¿›è¡Œè½¬æ¢ã€‚
- en: For this reason, to tackle this task we used the **pdfplumber** library for
    various reasons. Firstly, it is built on pdfminer.six which we used for our preliminary
    analysis, meaning that it contains similar objects. In addition, its approach
    to table detection is based on line elements along with their intersections that
    construct the cell that contains the text and then the table itself. That way
    after we identify a cell of a table, we can extract just the content inside the
    cell without carrying how many rows needed to be rendered. Then when we have the
    contents of a table, we will format it in a table-like string and store it in
    the appropriate list.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¸ºäº†å¤„ç†è¿™ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†**pdfplumber**åº“ã€‚é¦–å…ˆï¼Œå®ƒå»ºç«‹åœ¨æˆ‘ä»¬ç”¨äºåˆæ­¥åˆ†æçš„pdfminer.sixä¹‹ä¸Šï¼Œè¿™æ„å‘³ç€å®ƒåŒ…å«ç±»ä¼¼çš„å¯¹è±¡ã€‚æ­¤å¤–ï¼Œå®ƒçš„è¡¨æ ¼æ£€æµ‹æ–¹æ³•åŸºäºçº¿æ¡å…ƒç´ åŠå…¶äº¤ç‚¹ï¼Œè¿™äº›å…ƒç´ æ„å»ºäº†åŒ…å«æ–‡æœ¬çš„å•å…ƒæ ¼ä»¥åŠæ•´ä¸ªè¡¨æ ¼ã€‚è¿™æ ·ï¼Œåœ¨æˆ‘ä»¬è¯†åˆ«è¡¨æ ¼å•å…ƒæ ¼åï¼Œå¯ä»¥æå–å•å…ƒæ ¼å†…éƒ¨çš„å†…å®¹ï¼Œè€Œæ— éœ€è€ƒè™‘éœ€è¦æ¸²æŸ“å¤šå°‘è¡Œã€‚ç„¶åï¼Œå½“æˆ‘ä»¬æ‹¥æœ‰è¡¨æ ¼å†…å®¹æ—¶ï¼Œæˆ‘ä»¬ä¼šå°†å…¶æ ¼å¼åŒ–ä¸ºç±»ä¼¼è¡¨æ ¼çš„å­—ç¬¦ä¸²å¹¶å­˜å‚¨åœ¨é€‚å½“çš„åˆ—è¡¨ä¸­ã€‚
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To achieve that, we created two functions, **extract_table()** to extract the
    contents of the table into a list of lists, and **table_converter()** to join
    the contents of those lists in a table-like string.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸¤ä¸ªå‡½æ•°ï¼Œ**extract_table()**ç”¨äºå°†è¡¨æ ¼å†…å®¹æå–ä¸ºåˆ—è¡¨çš„åˆ—è¡¨ï¼Œ**table_converter()**ç”¨äºå°†è¿™äº›åˆ—è¡¨çš„å†…å®¹è¿æ¥æˆç±»ä¼¼è¡¨æ ¼çš„å­—ç¬¦ä¸²ã€‚
- en: 'In the **extract_table()** function:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨**extract_table()**å‡½æ•°ä¸­ï¼š
- en: We open the PDF file.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ‰“å¼€PDFæ–‡ä»¶ã€‚
- en: We navigate to the examined page of the PDF file.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¼èˆªåˆ°PDFæ–‡ä»¶çš„æ£€æŸ¥é¡µé¢ã€‚
- en: From the list of tables found on the page by pdfplumber, we select the desired
    one.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»pdfplumberæ‰¾åˆ°çš„é¡µé¢ä¸­çš„è¡¨æ ¼åˆ—è¡¨ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©æ‰€éœ€çš„è¡¨æ ¼ã€‚
- en: We extract the content of the table and output it in a list of nested lists
    representing each row of the table.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æå–äº†è¡¨æ ¼çš„å†…å®¹ï¼Œå¹¶å°†å…¶è¾“å‡ºä¸ºè¡¨ç¤ºæ¯è¡Œçš„åµŒå¥—åˆ—è¡¨ã€‚
- en: 'In the **table_converter()** function:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨**table_converter()**å‡½æ•°ä¸­ï¼š
- en: We iterate in each nested list and clean its context from any unwanted line
    breaks coming from any wrapped text.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éå†æ¯ä¸ªåµŒå¥—åˆ—è¡¨ï¼Œå¹¶æ¸…é™¤ä»»ä½•æ¥è‡ªæ¢è¡Œæ–‡æœ¬çš„å¤šä½™æ¢è¡Œç¬¦ã€‚
- en: We join each element of the row by separating them using the | symbol to create
    the structure of a tableâ€™s cell.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡ä½¿ç”¨|ç¬¦å·åˆ†éš”è¡Œä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œä»¥åˆ›å»ºè¡¨æ ¼å•å…ƒæ ¼çš„ç»“æ„ã€‚
- en: Finally, we add a line break at the end to move to the next row.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬åœ¨æœ«å°¾æ·»åŠ ä¸€ä¸ªæ¢è¡Œç¬¦ï¼Œä»¥ç§»åŠ¨åˆ°ä¸‹ä¸€è¡Œã€‚
- en: This will result in a string of text that will present the content of the table
    without losing the granularity of the data presented in it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†ç”Ÿæˆä¸€ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²ï¼Œå±•ç¤ºè¡¨æ ¼çš„å†…å®¹ï¼Œè€Œä¸ä¼šä¸¢å¤±å‘ˆç°çš„æ•°æ®çš„ç»†èŠ‚ã€‚
- en: Adding all together
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰å†…å®¹æ•´åˆåœ¨ä¸€èµ·
- en: Now that we have all the components of the code ready letâ€™s add them all up
    to a fully functional code. You can copy the code from here or you can find it
    along with the example PDF in my Github repo [here](https://github.com/g-stavrakis/PDF_Text_Extraction).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²å‡†å¤‡å¥½æ‰€æœ‰ä»£ç ç»„ä»¶ï¼Œè®©æˆ‘ä»¬å°†å®ƒä»¬æ•´åˆæˆä¸€ä¸ªå®Œæ•´çš„ä»£ç ã€‚ä½ å¯ä»¥ä»è¿™é‡Œå¤åˆ¶ä»£ç ï¼Œæˆ–è€…ä½ å¯ä»¥åœ¨æˆ‘çš„Githubä»“åº“[è¿™é‡Œ](https://github.com/g-stavrakis/PDF_Text_Extraction)æ‰¾åˆ°å®ƒåŠç¤ºä¾‹PDFã€‚
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The script above will:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šé¢çš„è„šæœ¬å°†ï¼š
- en: Import the necessary libraries.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼å…¥å¿…è¦çš„åº“ã€‚
- en: Open the PDF file using the **pyPDF2** library.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨**pyPDF2**åº“æ‰“å¼€PDFæ–‡ä»¶ã€‚
- en: Extract each page of the PDF and iterate the following steps.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æå–PDFçš„æ¯ä¸€é¡µï¼Œå¹¶æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚
- en: Examine if there are any tables on the page and create a list of them using
    **pdfplumner.**
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æŸ¥é¡µé¢ä¸Šæ˜¯å¦æœ‰è¡¨æ ¼ï¼Œå¹¶ä½¿ç”¨**pdfplumner**åˆ›å»ºä¸€ä¸ªè¡¨æ ¼åˆ—è¡¨ã€‚
- en: Find all the elements nested in the page and sort them as they appeared in its
    layout.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾é¡µé¢ä¸­åµŒå¥—çš„æ‰€æœ‰å…ƒç´ ï¼Œå¹¶æŒ‰å…¶åœ¨å¸ƒå±€ä¸­å‡ºç°çš„é¡ºåºå¯¹å®ƒä»¬è¿›è¡Œæ’åºã€‚
- en: 'Then for each element:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯¹æ¯ä¸ªå…ƒç´ ï¼š
- en: Examine if it is a text container, and does not appear in a table element. Then
    use the **text_extraction**() function to extract the text along with its format,
    else pass this text.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬å®¹å™¨ï¼Œå¹¶ä¸”ä¸å‡ºç°åœ¨è¡¨æ ¼å…ƒç´ ä¸­ã€‚ç„¶åä½¿ç”¨**text_extraction**()å‡½æ•°æå–æ–‡æœ¬åŠå…¶æ ¼å¼ï¼Œå¦åˆ™å¿½ç•¥æ­¤æ–‡æœ¬ã€‚
- en: Examine if it is an image, and use the **crop_image**() function to crop the
    image component from the PDF, convert it into an image file using the **convert_to_images**(),
    and extract text from it using OCR with the **image_to_text**() function.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ˜¯å¦ä¸ºå›¾åƒï¼Œå¹¶ä½¿ç”¨**crop_image**()å‡½æ•°ä»PDFä¸­è£å‰ªå›¾åƒç»„ä»¶ï¼Œä½¿ç”¨**convert_to_images**()å°†å…¶è½¬æ¢ä¸ºå›¾åƒæ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨OCRå’Œ**image_to_text**()å‡½æ•°æå–æ–‡æœ¬ã€‚
- en: 'Examine if it is a rectangular element. In this case, we examine if the first
    rect is part of a pageâ€™s table and if yes, we move to the following steps:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ˜¯å¦ä¸ºçŸ©å½¢å…ƒç´ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ£€æŸ¥ç¬¬ä¸€ä¸ªçŸ©å½¢æ˜¯å¦æ˜¯é¡µé¢è¡¨æ ¼çš„ä¸€éƒ¨åˆ†ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™è½¬åˆ°ä»¥ä¸‹æ­¥éª¤ï¼š
- en: Find the bounding box of the table in order not to extract its text again with
    the text_extraction() function.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾è¡¨æ ¼çš„è¾¹ç•Œæ¡†ï¼Œä»¥é¿å…ä½¿ç”¨text_extraction()å‡½æ•°å†æ¬¡æå–å…¶æ–‡æœ¬ã€‚
- en: Extract the content of the table and convert it into a string.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æå–è¡¨æ ¼å†…å®¹å¹¶å°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚
- en: Then add a boolean parameter to clarify that we extract text from Table.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åæ·»åŠ ä¸€ä¸ªå¸ƒå°”å‚æ•°ï¼Œä»¥æ¾„æ¸…æˆ‘ä»¬æ˜¯å¦ä»è¡¨æ ¼ä¸­æå–æ–‡æœ¬ã€‚
- en: This process will finish after the last LTRect that falls into the bounding
    box of the table and the next element in the layout is not a rectangular object.
    (All the other objects that compose the table will be passed)
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¿‡ç¨‹å°†åœ¨æœ€åä¸€ä¸ªLTRectè½åœ¨è¡¨æ ¼çš„è¾¹ç•Œæ¡†å†…ï¼Œå¹¶ä¸”å¸ƒå±€ä¸­çš„ä¸‹ä¸€ä¸ªå…ƒç´ ä¸æ˜¯çŸ©å½¢å¯¹è±¡åç»“æŸã€‚ï¼ˆæ‰€æœ‰ç»„æˆè¡¨æ ¼çš„å…¶ä»–å¯¹è±¡å°†è¢«å¿½ç•¥ï¼‰
- en: 'The outputs of the process will be stored in 5 lists per iteration, named:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è¿‡ç¨‹çš„è¾“å‡ºå°†æ¯æ¬¡è¿­ä»£å­˜å‚¨åœ¨5ä¸ªåˆ—è¡¨ä¸­ï¼Œå‘½åä¸ºï¼š
- en: 'page_text: contains the text coming from text containers in the PDF (placeholder
    will be placed when the text was extracted from another element)'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'page_text: åŒ…å«æ¥è‡ªPDFæ–‡æœ¬å®¹å™¨çš„æ–‡æœ¬ï¼ˆå½“æ–‡æœ¬ä»å¦ä¸€ä¸ªå…ƒç´ ä¸­æå–æ—¶ï¼Œå°†æ”¾ç½®å ä½ç¬¦ï¼‰'
- en: 'line_format: contains the formats of the texts extracted above (placeholder
    will be placed when the text was extracted from another element)'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'line_format: åŒ…å«ä¸Šé¢æå–çš„æ–‡æœ¬çš„æ ¼å¼ï¼ˆå½“æ–‡æœ¬ä»å¦ä¸€ä¸ªå…ƒç´ ä¸­æå–æ—¶ï¼Œå°†æ”¾ç½®å ä½ç¬¦ï¼‰'
- en: 'text_from_images: contains the texts extracted from images on the page'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'text_from_images: åŒ…å«ä»é¡µé¢ä¸Šçš„å›¾åƒæå–çš„æ–‡æœ¬'
- en: 'text_from_tables: contains the table-like string with the contents of tables'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'text_from_tables: åŒ…å«è¡¨æ ¼å†…å®¹çš„ç±»ä¼¼è¡¨æ ¼çš„å­—ç¬¦ä¸²'
- en: 'page_content: contains all the text rendered on the page in a list of elements'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'page_content: åŒ…å«ä»¥å…ƒç´ åˆ—è¡¨å½¢å¼å‘ˆç°çš„é¡µé¢ä¸Šæ‰€æœ‰æ–‡æœ¬'
- en: All the lists will be stored under the key in a dictionary that will represent
    the number of the page examined each time.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰åˆ—è¡¨å°†å­˜å‚¨åœ¨ä¸€ä¸ªå­—å…¸çš„é”®ä¸‹ï¼Œè¯¥å­—å…¸å°†è¡¨ç¤ºæ¯æ¬¡æ£€æŸ¥çš„é¡µé¢ç¼–å·ã€‚
- en: Afterwards, we will close the PDF file.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹åï¼Œæˆ‘ä»¬å°†å…³é—­PDFæ–‡ä»¶ã€‚
- en: Then we will delete all the additional files created during the process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†åˆ é™¤åœ¨è¿‡ç¨‹ä¸­åˆ›å»ºçš„æ‰€æœ‰é¢å¤–æ–‡ä»¶ã€‚
- en: Lastly, we can display the content of the page by joining the elements of the
    page_content list.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿æ¥page_contentåˆ—è¡¨çš„å…ƒç´ æ¥æ˜¾ç¤ºé¡µé¢å†…å®¹ã€‚
- en: Conclusion
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: This was one approach that I believe uses the best characteristics of many libraries
    and makes the process resilient to various types of PDFs and elements that we
    can encounter, with PDFMiner however do the most of the heavy lifting. Also, the
    information regarding the format of the text can help us with the identification
    of potential titles that can separate the text into distinct logical sections
    rather than just content per page and can help us to identify the text of greater
    importance.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ç§æ–¹æ³•ï¼Œæˆ‘è®¤ä¸ºå®ƒç»“åˆäº†è®¸å¤šåº“çš„æœ€ä½³ç‰¹æ€§ï¼Œä½¿è¿‡ç¨‹å¯¹å„ç§ç±»å‹çš„PDFå’Œæˆ‘ä»¬å¯èƒ½é‡åˆ°çš„å…ƒç´ å…·æœ‰å¼¹æ€§ï¼Œä½†ä¸»è¦ä¾èµ–PDFMinerè¿›è¡Œç¹é‡çš„å·¥ä½œã€‚æ­¤å¤–ï¼Œå…³äºæ–‡æœ¬æ ¼å¼çš„ä¿¡æ¯å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¯†åˆ«æ½œåœ¨çš„æ ‡é¢˜ï¼Œè¿™äº›æ ‡é¢˜å¯ä»¥å°†æ–‡æœ¬åˆ’åˆ†ä¸ºä¸åŒçš„é€»è¾‘éƒ¨åˆ†ï¼Œè€Œä¸ä»…ä»…æ˜¯æŒ‰é¡µé¢å†…å®¹ï¼Œå¹¶æœ‰åŠ©äºè¯†åˆ«æ›´é‡è¦çš„æ–‡æœ¬ã€‚
- en: However, there will always be more efficient ways to do this task and even though
    I believe that this approach is more inclusive, I am really looking forward to
    discussing with you new and better ways of tackling this problem.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæ€»ä¼šæœ‰æ›´é«˜æ•ˆçš„æ–¹æ³•æ¥å®Œæˆæ­¤ä»»åŠ¡ï¼Œå°½ç®¡æˆ‘è®¤ä¸ºè¿™ç§æ–¹æ³•æ›´å…·åŒ…å®¹æ€§ï¼Œæˆ‘éå¸¸æœŸå¾…ä¸æ‚¨è®¨è®ºæ–°çš„å’Œæ›´å¥½çš„è§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•ã€‚
- en: 'ğŸ“– References:'
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ“– å‚è€ƒæ–‡çŒ®ï¼š
- en: '[https://www.techopedia.com/12-practical-large-language-model-llm-applications](https://www.techopedia.com/12-practical-large-language-model-llm-applications)'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.techopedia.com/12-practical-large-language-model-llm-applications](https://www.techopedia.com/12-practical-large-language-model-llm-applications)'
- en: '[https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf](https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf)'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf](https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf)'
- en: '[https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR](https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR)
    technology reads text from, a searchable and editable PDF.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR](https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR)
    æŠ€æœ¯å¯ä»¥è¯»å–æ–‡æœ¬ï¼Œä»è€Œç”Ÿæˆå¯æœç´¢å’Œå¯ç¼–è¾‘çš„ PDFã€‚'
- en: '[https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1](https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1)'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1](https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1)'
- en: '[https://github.com/pdfminer/pdfminer.six](https://github.com/pdfminer/pdfminer.six)'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/pdfminer/pdfminer.six](https://github.com/pdfminer/pdfminer.six)'
