- en: Enhanced Large Language Models as Reasoning Engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/enhanced-large-language-models-as-reasoning-engines-582bff782113](https://towardsdatascience.com/enhanced-large-language-models-as-reasoning-engines-582bff782113)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----582bff782113--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----582bff782113--------------------------------)[](https://towardsdatascience.com/?source=post_page-----582bff782113--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----582bff782113--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----582bff782113--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----582bff782113--------------------------------)
    ·12 min read·Dec 23, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  prefs: []
  type: TYPE_NORMAL
- en: The recent exponential advances in natural language processing capabilities
    from large language models (LLMs) have stirred tremendous excitement about their
    potential to achieve human-level intelligence. Their ability to produce remarkably
    coherent text and engage in dialogue after exposure to vast datasets seems to
    point towards flexible, general purpose reasoning skills.
  prefs: []
  type: TYPE_NORMAL
- en: However, a growing chorus of voices urges caution against unchecked optimism
    by highlighting fundamental blindspots that limit neural approaches. LLMs still
    frequently make basic logical and mathematical mistakes that reveal a lack of
    systematicity behind their responses. Their knowledge remains intrinsically statistical
    without deeper semantic structures.
  prefs: []
  type: TYPE_NORMAL
- en: More complex reasoning tasks further expose these limitations. LLMs struggle
    with causal, counterfactual, and compositional reasoning challenges that require
    going beyond surface pattern recognition. Unlike humans who learn abstract schemas
    to flexibly recombine modular concepts, neural networks memorize correlations
    between co-occurring terms. This results in brittle generalization outside narrow
    training distributions.
  prefs: []
  type: TYPE_NORMAL
- en: The chasm underscores how human cognition employs structured symbolic representations
    to enable systematic composability and causal models for conceptualizing dynamics.
    We reason by manipulating modular symbolic concepts based on valid inference rules,
    chaining logical dependencies, leveraging mental simulations, and postulating
    mechanisms relating variables. The inherently statistical nature of neural networks
    precludes developing such structured reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: It remains mysterious how symbolic-like phenomena emerge in LLMs despite their
    subsymbolic substrate. But clearer acknowledgement of this “hybridity gap” is
    imperative. True progress requires embracing complementary strengths — the flexibility
    of neural approaches with structured knowledge representations and causal reasoning
    techniques — to create integrated reasoning systems.
  prefs: []
  type: TYPE_NORMAL
- en: We first outline the growing chorus of analyses exposing neural networks’ lack
    of systematicity, causal comprehension, and compositional generalization — underscoring
    differences from innate human faculties.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we detail salient facets of the “reasoning gap”, including struggles with
    modular skill orchestration, unraveling dynamics, and counterfactual simulation.
    We surface innate human capacities contemporary ML lacks, explaining resulting
    brittleness.
  prefs: []
  type: TYPE_NORMAL
- en: Seeking remedies, we discuss knowledge graphs as scaffolds for explicit conceptual
    relationships missing from statistical learning. We highlight approaches for structured
    knowledge injection — querying interfaces and vectorized graph embeddings — to
    contextualize neural generation.
  prefs: []
  type: TYPE_NORMAL
- en: We present techniques like dimensional typing in embeddings and parallel knowledge
    retrieval to improve inductive biases for logical deduction and efficient inference.
    Finally, we make the case for patiently cultivating high-quality knowledge graphs
    as strategic assets for enterprises pursuing substantive AI progress.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Reasoning Gap :'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](https://arxiv.org/abs/2311.18751?source=post_page-----582bff782113--------------------------------)
    [## Language Model Agents Suffer from Compositional Generalization in Web Automation'
  prefs: []
  type: TYPE_NORMAL
- en: Language model agents (LMA) recently emerged as a promising paradigm on muti-step
    decision making tasks, often…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2311.18751?source=post_page-----582bff782113--------------------------------)
    [](https://arxiv.org/abs/2305.20050?source=post_page-----582bff782113--------------------------------)
    [## Let's Verify Step by Step
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, large language models have greatly improved in their ability
    to perform complex multi-step reasoning…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2305.20050?source=post_page-----582bff782113--------------------------------)
    [](https://arxiv.org/abs/2304.03843?source=post_page-----582bff782113--------------------------------)
    [## Why think step by step? Reasoning emerges from the locality of experience
  prefs: []
  type: TYPE_NORMAL
- en: Humans have a powerful and mysterious capacity to reason. Working through a
    set of mental steps enables us to make…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2304.03843?source=post_page-----582bff782113--------------------------------)
    [](https://pub.aimind.so/can-llm-learn-to-reason-about-cause-and-effect-82a5f7b8cf5c?source=post_page-----582bff782113--------------------------------)
    [## Can LLM Learn to Reason About Cause and Effect?
  prefs: []
  type: TYPE_NORMAL
- en: Causal reasoning — the ability to understand and analyze the causal relationships
    between events — has long been…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: pub.aimind.so](https://pub.aimind.so/can-llm-learn-to-reason-about-cause-and-effect-82a5f7b8cf5c?source=post_page-----582bff782113--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: An emerging perspective explains many of the logical contradictions and lack
    of systematic generalization exhibited by LLMs as arising from a fundamental “reasoning
    gap” — the inability to spontaneously chain facts and inferences through intermediate
    reasoning steps.
  prefs: []
  type: TYPE_NORMAL
- en: Humans possess an intuitive capacity to make conceptual leaps using structured
    background knowledge and directing attention towards relevant pathways. We leverage
    existing schema and causal models linking concepts to stitch coherent narratives.
    For example, humans can reliably determine the climate in a country’s capital
    by using the capital relation to connect isolated facts — that Paris is the capital
    of France, and France has a temperate climate.
  prefs: []
  type: TYPE_NORMAL
- en: However, neural networks like LLMs accumulate only statistical associations
    between terms that co-occur frequently together in text corpora. Their knowledge
    remains implicit and unstructured. With no appreciation of higher order semantic
    relationships between concepts, they struggle to bridge concepts never seen directly
    linked during pre-training. Questions requiring reasoning through intermediate
    steps reveal this brittleness.
  prefs: []
  type: TYPE_NORMAL
- en: Newbenchmark tests specifically assess systematicity — whether models can combine
    known building blocks in novel ways. While LLMs achieve high accuracy when concepts
    they must relate already co-occur in training data, performance drops significantly
    when concepts appear separately despite influencing each other. The models fail
    to chain together their isolated statistical knowledge, unlike humans who can
    link concepts through indirect relationships.
  prefs: []
  type: TYPE_NORMAL
- en: This manifests empirically in LLMs’ inability to provide consistent logical
    narratives when queried through incremental prompt elaborations. Slight perturbations
    to explore new directions trigger unpredictable model failures as learned statistical
    associations break down. Without structured representations or programmatic operators,
    LLMs cannot sustain coherent, goal-oriented reasoning chains — revealing deficits
    in compositional generalization.
  prefs: []
  type: TYPE_NORMAL
- en: The “reasoning gap” helps explain counterintuitive LLM behavior. Their knowledge,
    encoded across billions of parameters through deep learning from surface statistical
    patterns alone, lacks frameworks for disciplined, interpretable logical reasoning
    that humans innately employ for conceptual consistency and exploration. This illuminates
    priorities for hybrid neurosymbolic approaches.
  prefs: []
  type: TYPE_NORMAL
- en: '**Compositional Reasoning**'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs still struggle with systematic combinatorial generalization — flexibly
    assembling novel solutions by recombining known skills. For example, separately
    learning to make coffee and toast does not directly enable orchestrating the joint
    routine. Humans intrinsically develop far richer modular, hierarchical representations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Causal Reasoning**'
  prefs: []
  type: TYPE_NORMAL
- en: While correlation comes naturally to statistics-driven models, unraveling causal
    mechanisms involving experiments, interventions and counterfactuals remains elusive
    without explicit conceptual frameworks. We possess innate construals of objects,
    agents and dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Temporal Reasoning**'
  prefs: []
  type: TYPE_NORMAL
- en: The sequential, transient nature of events, plans and narratives requires maintaining
    internal timelines, projecting into horizons. Yet LLMs display limited episodic
    memory to sustain coherence, lacking mental situational modeling.
  prefs: []
  type: TYPE_NORMAL
- en: '**Common Sense**'
  prefs: []
  type: TYPE_NORMAL
- en: Our expansive everyday frameworks encompassing objects, spaces and intuitive
    psychology provide testimony on plausibility when navigating the world. Failing
    to emulate this understanding of naive physics, pragmatics and social dynamics
    restricts exposed statistical knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: '**Meta-learning**'
  prefs: []
  type: TYPE_NORMAL
- en: Humans demonstrate meta-cognition around our own reasoning gaps, directing attention
    and deliberately seeking information to strengthen models. The opacity and lack
    of higher-order uncertainty or self-reflection limits controlled, strategic model
    improvement in neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: In totality, LLMs do not possess the schema induction, causal representations,
    simulation capacities, autoregressive prediction, social heuristics or metacognitive
    architectures underpinning versatile systematic generalization. Lacking structured
    inductive biases, combinatorial explosions render learning explicit compositions
    infeasible. The multitude of reasoning gaps hampers reaching human-like flexibility
    guided by understanding.
  prefs: []
  type: TYPE_NORMAL
- en: This further spotlights the urgent imperative of hybrid neurosymbolic paradigms
    that symbiotically combine innate neural capacities with structured compositionality
    and causal constraints. Such integration promises more robust, trustworthy systems
    that reason fluidly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enhancing Reasoning with Knowledge Graphs :'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----582bff782113--------------------------------)
    [## Vector Search Is Not All You Need'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/vector-search-is-not-all-you-need-ecd0f16ad65e?source=post_page-----582bff782113--------------------------------)
    [](https://medium.com/@alcarazanthony1/knowledge-graph-embeddings-as-a-bridge-between-symbolic-and-subsymbolic-ai-0f37c55de845?source=post_page-----582bff782113--------------------------------)
    [## Knowledge Graph Embeddings as a Bridge between Symbolic and Subsymbolic AI
  prefs: []
  type: TYPE_NORMAL
- en: The Resurgence of Structure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@alcarazanthony1/knowledge-graph-embeddings-as-a-bridge-between-symbolic-and-subsymbolic-ai-0f37c55de845?source=post_page-----582bff782113--------------------------------)
    [](https://ai.plainenglish.io/augmenting-large-language-models-with-hybrid-knowledge-architectures-24cd322b5be7?source=post_page-----582bff782113--------------------------------)
    [## Augmenting Large Language Models with Hybrid Knowledge Architectures
  prefs: []
  type: TYPE_NORMAL
- en: 'Tracing Vector Relevance with Symbolic Chains: A Balanced Approach for Robust
    Reasoning in Retrieval-Augmented…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ai.plainenglish.io](https://ai.plainenglish.io/augmenting-large-language-models-with-hybrid-knowledge-architectures-24cd322b5be7?source=post_page-----582bff782113--------------------------------)
    ![](../Images/2e2201b8836e2cddf909019bd6d4539a.png)
  prefs: []
  type: TYPE_NORMAL
- en: Schema by the author
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graphs offer a promising method for overcoming the “reasoning gap”
    plaguing modern large language models (LLMs). By explicitly modeling concepts
    as nodes and relationships as edges, knowledge graphs provide structured symbolic
    representations that can augment the flexible statistical knowledge within LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing explanatory connections between concepts empowers more systematic,
    interpretable reasoning across distant domains. LLMs struggle to link disparate
    concepts purely through learned data patterns. But knowledge graphs can effectively
    relate concepts not directly co-occurring in text corpora by providing relevant
    intermediate nodes and relationships. This scaffolding bridges gaps in statistical
    knowledge, enabling logical chaining.
  prefs: []
  type: TYPE_NORMAL
- en: Such knowledge graphs also increase transparency and trust in LLM-based inference.
    Requiring models to display full reasoning chains over explicit graph relations
    mitigates risks from unprincipled statistical hallucinations. Exposing the graph
    paths makes statistical outputs grounded in validated connections.
  prefs: []
  type: TYPE_NORMAL
- en: Constructing clean interfaces between innately statistical LLMs and structured
    causal representations shows promise for overcoming today’s brittleness. Combining
    neural knowledge breadth with external knowledge depth can nurture the development
    of AI systems that learn and reason both flexibly and systematically.
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Graph Querying and Graph Algorithms**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Knowledge graph querying and graph algorithms are powerful tools for extracting
    and analyzing complex relationships from large datasets. Here’s how they work
    and what they can achieve:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Knowledge Graph Querying:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Knowledge graphs organize information as entities (like books, people, or concepts)
    and relationships (like authorship, kinship, or thematic connection). Querying
    languages like SPARQL and Cypher enable the formulation of queries to extract
    specific information from these graphs. For example, the query mentioned in your
    example finds books related to “Artificial Intelligence” by matching book nodes
    connected to relevant topic nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Graph Algorithms:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Beyond querying, graph algorithms can analyze these structures in more profound
    ways. Some typical graph algorithms include:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pathfinding Algorithms (e.g., Dijkstra’s, A*): Find the shortest path between
    two nodes, useful in route planning and network analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Community Detection Algorithms (e.g., Louvain Method): Identify clusters or
    communities within graphs, helping in social network analysis and market segmentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Centrality Measures (e.g., PageRank, Betweenness Centrality): Determine the
    importance of different nodes in a network, applicable in analyzing influence
    in social networks or key infrastructure in transportation networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Recommendation Systems: By analyzing user-item graphs, these systems can make
    personalized recommendations based on past interactions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Large Language Models (LLMs) can generate queries for knowledge graphs based
    on natural language input. While they excel in understanding and generating human-like
    text, their statistical nature means they’re less adept at structured logical
    reasoning. Therefore, pairing them with knowledge graphs and structured querying
    interfaces can leverage the strengths of both: the LLM for understanding and contextualizing
    user input and the knowledge graph for precise, logical data retrieval.'
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating graph algorithms into the mix can further enhance this synergy.
    For instance, an LLM could suggest a community detection algorithm on a social
    network graph to identify influential figures within a specific interest group.
    However, the challenge lies in integrating these disparate systems in a way that
    is both efficient and interpretable.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1501f90a1aa1ef4c30bb76f3a95fe084.png)![](../Images/23375e373e6709e89610326af2e845ea.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Knowledge Graph Embeddings**'
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graph embeddings encode entities and relations as dense vector representations.
    These vectors can be dynamically integrated within LLMs using fused models.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a cross-attention mechanism can contextualize language model token
    embeddings by matching them against retrieved graph embeddings. This injects relevant
    external knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematically fusing these complementary vectors grounds the model, while allowing
    gradient flows across both components. The LLM inherits relational patterns, improving
    reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: So both querying and embeddings provide mechanisms for connecting structured
    knowledge graphs with the statistical capacities of LLMs. This facilitates interpretable,
    contextual responses informed by curated facts.
  prefs: []
  type: TYPE_NORMAL
- en: The path towards safe, performant, and explainable AI undoubtedly lies in architecting
    hybrid systems with distinct reasoning modules suited to their strengths while
    mitigating individual weaknesses through symbiotic integration. Knowledge graphs
    offer the structural scaffolding to elevate LLMs from pattern recognizers to context-aware,
    disciplined reasoners.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graph embeddings can be further enhanced by incorporating additional
    constraints and structure beyond just encoding factual entities and relationships.
    This provides useful inductive biases to orient semantic similarity and reasoning
    in more reliable ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dimensional Typing**'
  prefs: []
  type: TYPE_NORMAL
- en: Assigning dedicated dimensions in the embedding space to model specific hierarchical
    knowledge categories (like types, attributes, temporal bins etc.) allows interpreting
    vector arithmetic and symmetry operations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Logical Rules as Vector Equations**'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling logical rules like transitivity as vector equations over relation embeddings
    bakes in compliance with first-order logic when querying the vector space.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Entity Linking Regularization**'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a linkage loss that pulls together vector representations for the same
    real-world entities improves generalization across surface forms.
  prefs: []
  type: TYPE_NORMAL
- en: '**Temporal Ordering**'
  prefs: []
  type: TYPE_NORMAL
- en: Encoding time series knowledge by chronologically positioning entity embeddings
    assists in analogical reasoning over time.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, embellishing knowledge graph embeddings with structured inductive biases
    — whether through typed dimensions, vector logic, or temporal ordering — makes
    the vector arithmetic better comport with real-world constraints. This strengthens
    their ability to tackle complex reasoning tasks, providing useful scaffolds that
    can likewise elevate the performance of integrated language models.
  prefs: []
  type: TYPE_NORMAL
- en: The core benefit is infusing domain knowledge to orient the latent geometry
    in precise ways amplifies the reasoning capacity of connectionist models interacting
    with the vector space. Guiding the primitives the neural engine operates upon
    through structured initialization fosters more systematic compositional computation
    accessible through queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Complementary approches:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First retrieving relevant knowledge graph embeddings for a query before querying
    the full knowledge graph. This two-step approach allows efficient focus of graphical
    operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Vector Embedding Retrieval**'
  prefs: []
  type: TYPE_NORMAL
- en: Given a natural language query, relevant knowledge graph embeddings can be quickly
    retrieved using approximate nearest neighbor search over indexed vectors.
  prefs: []
  type: TYPE_NORMAL
- en: For example, using a query like “Which books discuss artificial intelligence”,
    vector search would identify embeddings of the Book, Topic, and AI Concept entities.
  prefs: []
  type: TYPE_NORMAL
- en: This focuses the search without needing to scan the entire graph, improving
    latency. The embeddings supply useful query expansion signals for the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2: Graph Query/Algorithm Execution**'
  prefs: []
  type: TYPE_NORMAL
- en: The selected entity embeddings suggest useful entry points and relationships
    for structured graphical queries and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, the matches for Book, Topic, and AI Concept cues exploration
    of BOOK-TOPIC and TOPIC-CONCEPT connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'Executing a query like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This traverses booked linked to AI topics to produce relevant results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, the high-level flow is:'
  prefs: []
  type: TYPE_NORMAL
- en: Use vector search to identify useful symbolic handles
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Execute graph algorithms seeded by these handles
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This tight coupling connects the strength of similarity search with multi-hop
    reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: The key benefit is focusing complex graph algorithms using fast initial embedding
    matches. This improves latency and relevance by avoiding exhaustive graph scans
    for each query. The combination enables scalable, efficient semantic search and
    reasoning over vast knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Paralell Querying of Multiple Graphs or the same Graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----582bff782113--------------------------------)
    [## Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and…'
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----582bff782113--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'The key idea behind using multiple knowledge graphs in parallel is to provide
    the language model with a broader scope of structured knowledge to draw from during
    the reasoning process. Let me expand on the rationale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Breadth**: No single knowledge graph can encapsulate all of humanity’s
    accrued knowledge across every domain. By querying multiple knowledge graphs in
    parallel, we maximize the factual information available for the language model
    to leverage.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reasoning Diversity**: Different knowledge graphs may model domains using
    different ontologies, rules, constraints etc. This diversity of knowledge representation
    exposes the language model to a wider array of reasoning patterns to learn.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Efficiency**: Querying knowledge graphs in parallel allows retrieving relevant
    information simultaneously. This improves latency compared to sequential queries.
    Parallel search allows more rapid gathering of contextual details to analyze.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Robustness**: Having multiple knowledge sources provides redundancy in cases
    where a particular graph is unavailable or lacks information on a specific reasoning
    chain.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Transfer Learning**: Being exposed to a multitude of reasoning approaches
    provides more transferable learning examples for the language model. This enhances
    few-shot adaptation abilities.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So in summary, orchestrating a chorus of knowledge graphs provides breadth and
    diversity of grounded knowledge to overcome limitations of individual knowledge
    bases. Parallel retrieval improves efficiency and robustness. Transfer learning
    across diverse reasoning patterns also accelerates language model adaption. This
    combination aims to scale structured knowledge injection towards more human-like
    versatile understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models as a fluid semantic glue between structured modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While vector search and knowledge graphs provide structured symbolic representations,
    large language models (LLMs) like GPT-3 offer unstructured yet adaptive semantic
    knowledge. LLMs have demonstrated remarkable few-shot learning abilities, quickly
    adapting to new domains with only a handful of examples.
  prefs: []
  type: TYPE_NORMAL
- en: This makes LLMs well-suited to act as a fluid semantic glue between structured
    modules — ingesting the symbolic knowledge, interpreting instructions, handling
    edge cases through generalization, and producing contextual outputs. They leverage
    their vast parametric knowledge to rapidly integrate with external programs and
    data representations.
  prefs: []
  type: TYPE_NORMAL
- en: We can thus conceive of LLMs as a dynamic, ever-optimizing semantic layer. They
    ingest forms of structured knowledge and adapt on the fly based on new inputs
    and querying contexts. Rather than replacing symbolic approaches, LLMs amplify
    them through rapid binding and contextual response generation. This fluid integration
    saves the effort of manually handling all symbol grounding and edge cases explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging the innate capacities of LLMs for semantic generalization allows
    structured programs to focus on providing logical constraints and clean interfaces.
    The LLM then handles inconsistencies and gaps through adaptive few-shot learning.
    This symbiotic approach underscores architecting AI systems with distinct reasoning
    faculties suited for their inherent strengths.
  prefs: []
  type: TYPE_NORMAL
- en: Structured Knowledge as AI’s Bedrock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The exponential hype around artificial intelligence risks organizations pursuing
    short-sighted scripts promising quick returns. But meaningful progress requires
    patient cultivation of high-quality knowledge foundations. This manifests in structured
    knowledge graphs methodically encoding human expertise as networked representations
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: Curating clean abstractions of complex domains as interconnected entities, constraints
    and rules is no trivial investment. It demands deliberate ontology engineering,
    disciplined data governance and iterative enhancement. The incremental nature
    can frustrate business leaders accustomed to rapid software cycles.
  prefs: []
  type: TYPE_NORMAL
- en: However, structured knowledge is AI’s missing pillar — curbing unbridled statistical
    models through grounding signals. Knowledge graphs provide the scaffolding for
    injectable domain knowledge, while enabling transparent querying and analysis.
    Their composable nature also allows interoperating with diverse systems.
  prefs: []
  type: TYPE_NORMAL
- en: All this makes a compelling case for enterprise knowledge graphs as strategic
    assets. Much like databases evolved from flexible spreadsheets, the constraints
    of structure ultimately multiply capability. The entities and relationships within
    enterprise knowledge graphs become reliable touchpoints for driving everything
    from conversational assistants to analytics.
  prefs: []
  type: TYPE_NORMAL
- en: In the rush to the AI frontier, it is tempting to let unconstrained models loose
    on processes. But as with every past wave of automation, thoughtfully encoding
    human knowledge to elevate machine potential remains imperative. Managed well,
    maintaining this structured advantage compounds over time across applications,
    cementing market leadership. Knowledge powers better decisions — making enterprise
    knowledge graphs indispensable AI foundations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f53b4b5d285671961d8cc6dfaf29b3df.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by Dall-E-3 by the Author
  prefs: []
  type: TYPE_NORMAL
