# 因果推断：准实验

> 原文：[https://towardsdatascience.com/causal-inference-quasi-experiments-36d35ca5f754](https://towardsdatascience.com/causal-inference-quasi-experiments-36d35ca5f754)

## 你的 PM 忘记运行 **A/B 测试**了… 现在怎么办？

[](https://ianhojy.medium.com/?source=post_page-----36d35ca5f754--------------------------------)[![Ian Ho](../Images/1b56c25ee3bedfb5c7369d4bfc93aa91.png)](https://ianhojy.medium.com/?source=post_page-----36d35ca5f754--------------------------------)[](https://towardsdatascience.com/?source=post_page-----36d35ca5f754--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----36d35ca5f754--------------------------------) [Ian Ho](https://ianhojy.medium.com/?source=post_page-----36d35ca5f754--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----36d35ca5f754--------------------------------) ·阅读时间 12 分钟·2023 年 8 月 9 日

--

![](../Images/a4b772f76b325ef375d908ed308e86ca.png)

图片来源：[Isaac Smith](https://unsplash.com/@isaacmsmith?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

*本文是关于使用准实验进行因果推断的系列文章中的第 1 部分（具体取决于我会啰嗦多少）。简而言之，第 1 部分将解释准实验的理由和方法，以及应用像 PSM 这样的办法时涉及的细微差别。在第 2 部分，我将更多地谈谈准实验的局限性以及基于这些实验做决策时需要注意的事项。我还会提出一个异质影响估计的框架，以帮助克服外推偏差。在第 3 部分… 我还不确定。*

*你可能也见过其他文章解释准实验，但我仍然会尝试以我的方式解释。请读一读。*

# 为什么因果推断？

开发和推出产品及功能的成本最终是通过对消费者的积极影响来证明的。因此，听到产品经理做出各种声明，如“我们很高兴宣布我们最新的功能发布导致了 12% 的收入增长！”并不令人意外。

听起来很棒，老实说，大多数高级管理人员很乐意接受这样的说法作为事实。今天我的目标是说服你深入了解这些主张背后的因果推断方法。掌握因果推断，你将能更好地评估产品和功能对用户和公司带来的影响。

让我们看看 ChatGPT 对于为什么因果推断对于产品是必要的有何看法：

> 因果推断赋予产品团队的能力是超越仅仅观察数据中的相关性，建立对驱动产品表现的因果机制的更深刻理解。（毫不意外，比我能说的任何东西都更加简明扼要）

这里值得特别提到的是相关性和因果性的问题。

> 相关性并不意味着因果性。（别翻白眼）

说实话，我们中的许多人说它并认为我们知道它的含义。当有人问我们是什么意思时，我们拿出一个搞笑的图表来证明我们的智力能力（看看这个[流行的虚假相关示例](https://www.tylervigen.com/spurious-correlations)），并自豪地宣称我们永远不会在日常影响评估工作中犯这样的错误。好吧，经验告诉我，许多*了解*这种谬误的人并不真正理解它在现实世界中的表现。这通常源于因果推断领域的基础薄弱。

![](../Images/edb5ab00d7a85dcdd44a4256ca123c79.png)

来源: [https://www.tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations) (CC BY 4.0)

那么，如果因果推断对客观评估我们在产品和功能上的投资回报很重要，我们该如何进行呢？

在其最无争议的形式中，因果推断通常通过 A/B 测试来操作（遗憾的是，这不是今天讨论的主题）。然而，现实情况是实验并不总是可用的。

# 准实验：为什么？

首先，有时我们只是忘记进行实验。这通常发生在产品团队*成功*地使用一部分实验用户证明了影响，然后继续向所有用户发布。在这个过程中，他们忘记保留一个控制组来评估普遍影响。

其次，有时实验根本不可能。例如，产品或功能可能涉及对用户高度可见的变化，或对用户高度敏感的变化。在这种情况下，用户体验占据主导地位，控制组的设置显然不现实。

这就是**准实验**派上用场的地方。与实际的 A/B 测试不同，这些准实验是回顾性进行的。一般来说，它涉及分析用户的一个子集，以在产品或功能发布后模拟进行实验。让我们通过一个例子深入了解具体情况。

想象一下你是一家电商公司的数据科学家，比如Shopee或Lazada。6个月前，你的公司普遍推出了一项你们CEO相信能增加平台用户支出的互动功能X。你的一位项目经理某天告诉你，CEO想知道功能上线对公司的影响。你提醒项目经理，由于这是一次普遍推出，没有控制组，所有用户都可以使用互动功能。因此，你的项目经理说：“这没问题。只需比较那些实际使用功能的用户（处理组：Treatment=1）与那些没有使用功能的用户（控制组：Treatment=0）。进行一些假设检验，瞧，支出差异就是功能X的影响。”

![](../Images/92dfe923786769946a2b0b5c04e98b62.png)

图片来源：作者

根据你项目经理的智慧，你计算了一下，发现处理组与“控制”组之间有+ $12 的差异。我们是如何得到+ $12的？

*2023年4月平均处理组支出：*

*$ (42 + 26) / 2 = $34*

*2023年4月平均控制组支出：*

*$ (36 + 20 + 19 + 13) / 4 = $22*

*支出差异 = $34 减去 $22 = $12*

你的项目经理对估算的提升感到满意，并为帮助确保团队的年度奖金给了你一个鼓励的拍背。

当你那晚躺在床上时，某些事情仍然困扰着你的良心。确实，这种方法存在混淆变量的问题。

ChatGPT 将 **混淆变量** 描述为：

> 混淆变量，也称为混杂因素，是指在研究中可能影响因变量（感兴趣的结果）和自变量（被研究的因素）的外部因素。这些变量可能导致关于自变量和因变量之间真实关系的误导或不正确的结论。

在这种情况下，潜在的混淆变量实际上是结果变量本身：用户支出。但这怎么可能呢？

如果那些在2023年2月花费更多的用户实际上更有可能在2023年3月使用这个新功能X，那么观察到的2023年4月+12%的支出提升实际上可能归因于支出偏好的固有差异，而不是功能X的使用本身。换句话说，如果功能X没有推出，处理组的用户可能在2023年4月依然会花费更多。

在这里，准实验可以帮助提供更可靠（和良心的）影响估计。

*我可以深入讨论混杂变量和偏差的统计学，但我不打算这样做，以便能够实际转到准实验。另一个你可能会疑惑的是，为什么随机化A/B测试不会受到混杂变量问题的影响。有关解释，请参见附录A。再次说明，这不是今天讨论的重点。此外，混杂变量的概念与遗漏变量偏差密切相关，虽然不完全相同，但如果你想了解更多* [*解释*](/omitted-variable-bias-and-what-can-we-do-about-it-344ac1477699) *有关OVB的内容。*

*不过，希望我还没有让你感到困惑。*

![](../Images/1e527c6e024bafe0161f009657697a69.png)

作者提供的图片：混杂关系的表示

# 准实验：怎么做？

这是一个高层次的概述，展示了准实验如何在没有随机化A/B测试的情况下克服混杂变量的问题。让我们继续使用产品特性X的推出作为例子。

对于处理组中的每2个用户，如果我们能瞥见一个平行宇宙，在那个宇宙中这2个用户没有使用特性X，那将会很棒。由于我们还没有生活在科幻世界中，接下来的最佳选择是通过统计方法来*估计*这个平行宇宙。

具体而言，这通过在控制组中筛选出与处理组用户在Feature X上线前最相似的4名用户来完成。换句话说，这些伪控制组将模拟处理组用户如果没有采用Feature X会如何表现。

在我们方便修改的示例中，我们会找出控制组中与我们的处理组在2023年2月（上线前）的花费最相似的用户。具体来说：

对于用户A，最接近的相似用户是用户C，因为他们都在2023年2月花费了$10。

对于用户B，最接近的相似用户是用户D，因为他们都在2023年2月花费了$8。

因此，我们**排除**了用户E和F的分析。

![](../Images/74c2678b9986101b5bc91735ee70664f.png)

作者提供的图片：将处理组与伪控制组进行匹配

**总结一下，为什么我们选择用户C来与用户A进行比较？鉴于2023年2月（上线前）相同的花费，我们推测如果没有Feature X的推出和使用，用户A实际上会是用户C。**

那我们该如何告诉我们的PM呢？以下是修正后的计算结果：

*2023年4月的处理组平均花费：*

*$ (42 + 26) / 2 = $ 34*

*2023年4月控制组的平均花费：*

*$ (36 + 20) / 2 = $28*

*花费差异 = $ 34 减去 $28 = $6*

如该示例所示，**使用Feature X的预估影响从$12的提升降至$6。** 不幸的是，对于你的PM来说，今年的奖金可能会比预期少一点。

当然，我在这里仔细调整了数值以证明我的观点，但实际上我在真实产品世界中见过更大比例的估计偏差。现在应该很清楚，拥有稳健的方法论在评估产品和特征决策的影响时是极其重要的。

*在这一点上，值得提醒读者注意这个例子中存在的混淆因果关系。具体来说，过去的支出是特征X使用与未来支出之间因果关系的一个混淆因子。重要的是，存在混淆关系，因为我们假设过去的支出是采用特征X的可能性的一个指标。在我们进一步讨论倾向评分匹配（PSM）时，这种可能性概念是非常重要的。*

# 倾向评分匹配

在上述特征X的方便例子中，我们只有一个混淆变量（2023年2月的过去支出）。通过***混淆***框架来看这个问题，可能还有许多其他属性会影响发布后使用特征X的可能性。其中一些属性可能是已知且可观察的，而其他一些可能仍然未知或不可观察。

在我以前的一个项目中，我们有几十个用户属性，希望用来将处理用户与伪控制用户匹配。你可以应用KNN模型来找到相似的用户，但当属性过多和用户搜索量过大时，很快会遇到性能问题。如果你有数值和分类值的混合，还会有定义*距离*的额外复杂性。

克服这个计算问题的一种方法是通过**降维**过程。至少对我来说，这实际上就是PSM所做的。

回忆一下我们之前将混淆关系建模为混淆因子影响采用特征X（处理）的可能性。因此，我们可以采取以下步骤来从我们的处理组中选择与伪控制组相似的子集：

1.  使用逻辑回归（或任何其他产生概率预测的二元分类模型）来建模处理（1或0）与全部潜在混淆因子（过去支出等）之间的关系。

1.  使用拟合的分类模型来预测每个用户属性/混淆因子下的处理（倾向评分）概率。

1.  根据估计的倾向评分将处理组中的用户与伪控制组中的用户匹配。因此，倾向评分匹配。

通过采取这些步骤，匹配过程变得更具计算效率。除了极其高效外，数学在正确的假设下也能很好地运作。（有关期望值性质的更多信息，请参阅这篇[文章](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3144483/)，如果你对[证明](http://users.nber.org/~rdehejia/!@$AEM/Topic%2009%20Matching%20Advanced/Topic%2009%20Propensity%20Score.pdf)感兴趣且仍未信服，可以在这里查看）。当然，这种方法也有权衡之处，我将在下一部分讨论其中的一些局限性。

对于R用户，有一个非常知名的库叫做[MatchIt](https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html)来实现这个功能，其中一个示例可以在[这里](https://ds4ps.org/PROG-EVAL-III/MatchingScores.html)找到。个人而言，除了我不喜欢R之外，我也不喜欢那些将过多计算隐藏在背后的库，所以我从未真正使用过这个包，而是自己编写了代码在PySpark中进行匹配，以更高效地处理大型数据集（数百万用户）。另有一个简单的Python示例教程，大家可以在[这里](/propensity-score-matching-a0d373863eec)查看。*如果你想了解更多关于我如何实现的内容，随时联系我*。

# 倾向得分匹配：局限性

我想避免花费太多时间展示PSM的实现，部分原因是已经有许多参考示例，但也因为我更感兴趣的是讨论进行这种影响估计时涉及的细微差别。应用PSM很简单，但理解其假设、注意事项和局限性只有通过经验和实验才能获得。

不理解混杂变量的PM很危险，但误用准实验方法的数据科学家可能更危险，特别是因为这种方法表面上看起来很直观。

在我的第二部分文章中，我将花更多时间讨论我在将PSM应用于现实世界示例中的经验教训。现在，以下是应用PSM时应始终牢记的一些重要局限性：

**可忽略的处理分配假设**

PSM依赖于“可忽略的处理分配”假设，这意味着所有影响处理概率（例如使用特征X的概率）和结果（例如未来支出）的混杂变量都已被充分测量并纳入倾向得分模型。如果存在未测量或不可观察的混杂因素，匹配可能无法充分解决估计偏差问题。

**样本重叠和共同支持**

PSM要求处理组和对照组之间的倾向评分分布有足够的重叠。在共同支持有限的情况下（即，两组中具有相似倾向评分的个体很少或没有），匹配变得具有挑战性，我们可能需要采用其他方法。尽管我不是R的粉丝，[MatchIt](https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html)的文档很好地解释了支持的考虑因素以及其他匹配方法。

**倾向评分估计中的选择偏倚**

倾向评分模型（例如，逻辑回归）的准确性取决于模型的正确规范。如果模型被错误指定或包含不相关的变量，可能会引入选择偏倚。估计倾向评分的方法选择可以极大地改变估计的影响。不同的估计方法可能会产生不同的匹配结果，从而得出不同的因果影响估计。

*关于预测倾向评分的模型的最后一点：在我与数据科学家讨论如何进行第1步（拟合逻辑回归模型）的过程中，许多人陷入了试图找到最佳模型以减少预测误差的困境。我不怪他们想这样做，这几乎是数据科学家的本能，想要在运行model.fit(X, y)时最小化RMSE。然而，同样值得记住的是，PSM建模的直接目标并不是获得最佳分类预测。相反，是找到一种计算上高效的方式来实现* [*属性平衡*](http://www2.stat.duke.edu/~fl35/teaching/640/Chap3.3_observational_PS.pdf) *和共同支持。因此，最适合的模型可能并不总是产生最佳的匹配结果。更多内容请参见第二部分文章。*

# 结论

始终记住我们在这里测量的内容是很重要的。对于那些熟悉统计学的人来说，我们是在克服使用平均处理效应（ATE）的偏倚，PSM仅返回处理组的平均处理效应（ATT）。有关更全面的讨论，请参阅此[链接](https://academic.oup.com/ejcts/article/53/6/1112/4978231)。因此，在将ATT估计结果推广到更广泛的人群时，请谨慎行事。（我会在后续讨论中保存这个话题）

最后，数据科学家通常在影响产品和特性的决策和评估方面拥有巨大的权力。因此，我认为数据科学家肩负着相应的责任，在进行影响估计时，必须使用最稳健和可靠的方法。第二部分见！

**附录A：随机化与混杂**

随机化是通过以相等的概率将每个个体分配到一个处理组（例如，对照组或处理组）来实现的。我们可以将处理分配表示为一个二元变量：

+   如果个体接受治疗，则T = 1，

+   如果个体在对照组，则T = 0。

随机分配的关键特性是治疗分配与任何潜在结果（Y）或协变量（X），包括观察到的和未观察到的，都是独立的。从数学上讲，我们可以将其表示为：

P(Y|T, X) = P(Y|T)

这意味着给定处理和协变量的情况下结果的概率与仅给定处理的情况下结果的概率相同。

# **参考文献**

[## 虚假相关](https://www.tylervigen.com/spurious-correlations?source=post_page-----36d35ca5f754--------------------------------)

### 发现相关性：寻找新的相关性。来自Tyler的说明：现在这项功能无法使用——抱歉！存在冲突…

[www.tylervigen.com](https://www.tylervigen.com/spurious-correlations?source=post_page-----36d35ca5f754--------------------------------) [## 统计入门：倾向评分匹配及其替代方法†](https://academic.oup.com/ejcts/article/53/6/1112/4978231?source=post_page-----36d35ca5f754--------------------------------)

### 摘要。倾向评分（PS）方法相对于传统的回归方法在控制…方面提供了某些优势。

[## 理解遗漏变量偏差](https://academic.oup.com/ejcts/article/53/6/1112/4978231?source=post_page-----36d35ca5f754--------------------------------) [## MatchIt：入门指南](/omitted-variable-bias-and-what-can-we-do-about-it-344ac1477699?source=post_page-----36d35ca5f754--------------------------------)

### 针对最普遍的偏差类型的逐步指南

[towardsdatascience.com](/omitted-variable-bias-and-what-can-we-do-about-it-344ac1477699?source=post_page-----36d35ca5f754--------------------------------) [## MatchIt：入门指南](https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html?source=post_page-----36d35ca5f754--------------------------------)

### Noah Greifer Ho等（2007年建议的MatchIt）用于改进参数统计模型…

[## MatchIt：入门指南](https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html?source=post_page-----36d35ca5f754--------------------------------)

*特别感谢：Shin Ler*
