# 推荐系统中的多任务学习：基础知识

> 原文：[https://towardsdatascience.com/multi-task-learning-in-recommender-systems-a-primer-508e661a2029](https://towardsdatascience.com/multi-task-learning-in-recommender-systems-a-primer-508e661a2029)

## 试图做到这一切的算法背后的科学和工程

[](https://medium.com/@samuel.flender?source=post_page-----508e661a2029--------------------------------)[![Samuel Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----508e661a2029--------------------------------)[](https://towardsdatascience.com/?source=post_page-----508e661a2029--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----508e661a2029--------------------------------) [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----508e661a2029--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----508e661a2029--------------------------------) ·阅读时长8分钟·2023年7月25日

--

![](../Images/14dcc1089b980b3a39af30f387ebe796.png)

[Mike Kononov](https://unsplash.com/@mikofilm?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 的照片

尽管多任务学习在计算机视觉和自然语言处理领域已经得到很好的应用，但在现代 [推荐系统](/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca) 中的使用仍然相对较新，因此理解还不够充分。

在这篇文章中，我们将深入探讨多任务推荐系统中的一些重要设计考虑因素和最新研究突破。我们将涵盖

+   为什么我们首先需要多任务推荐系统，

+   正向迁移和负向迁移：多任务学习者的关键挑战，

+   硬参数共享和专家建模，以及

+   辅助学习：为了提高主任务的性能而添加新任务的想法。

让我们开始吧。

## 为什么要使用多任务推荐系统？

多任务推荐系统的关键优势在于其能够同时解决多个业务目标。例如，在视频推荐系统中，我们可能希望优化点击量，但同时也要优化观看时长、点赞、分享、评论或其他形式的用户互动。在这种情况下，单一的多任务模型不仅比多个单任务模型在计算上更便宜，而且每个任务的预测准确性也可能更高。

即使在我们只想预测一个事件的情况下，比如电子商务推荐系统中的“购买”行为，我们仍然可以添加额外的任务，其唯一目的是提高主要任务的性能。我们称这些额外的任务为“辅助任务”，这种学习形式为“辅助学习”。在电子商务的例子中，除了“购买”之外，还可以学习“加入购物车”和“添加到列表”，因为这些事件彼此紧密相关：它们表示购物意图。

## 哪些任务可以很好地一起学习？

从高层次来看，预测第二个任务要么有助于第一个任务，要么产生相反的效果：使第一个任务的预测变得更差。我们称前者为“正向迁移”，后者为“负向迁移”。多任务学习的挑战在于仅学习那些具有正向迁移的任务，并避免负向迁移，因为后者可能会对模型性能产生不利影响。

多任务学习中的一个关键问题是哪些任务可以很好地一起学习。在许多情况下，我们可以凭借领域知识做出合理的猜测。我们在上面已经看到一个例子：“购买”和“加入购物车”都表示购物意图，因此应该在多任务学习者中表现良好（实际上，它们确实如此）。

然而，如果任务数量变得很大，我们可能需要算法上确定哪些任务应该一起学习，哪些应该分开学习。值得注意的是，这是一个NP难题，因为可能的任务分组数量随着任务数量的增加而呈指数级增长。这并不容易，但可以做到：在2020年的一篇 [论文](https://www.google.com/search?client=safari&rls=en&q=Which+Tasks+Should+Be+Learned+Together+in+Multi-task+Learning%3F&ie=UTF-8&oe=UTF-8) 中，斯坦福大学的作者使用“分支限界”算法解决了计算机视觉数据集上的任务分组问题，得出的解决方案优于多个单任务学习者和单一的多任务学习者。

![](../Images/44a1d96a0142deb474556d8877272549.png)

3种不同的多任务建模范式。图源自 [Ma et al 2018](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007)。

## 硬参数共享：多任务学习的幕后

构建多任务神经网络的最简单方法是一个被称为“硬参数共享”或“共享底部”的技术，在这种方法中，我们将一个共享底部模块与任务特定的顶部模块结合在一起。通过这种方式，底部模块可以学习任务通用的模式，而顶部模块则可以学习任务特定的模式。（“模块”在这里指的是具有特定激活函数的多层感知机（MLP））。

在最简单的情况下，任务特定模块可以是一个单一的输出神经元，用于进行预测。然而，在实践中，我们通常可以通过为每个任务添加一个专用模块来实现更好的性能，该模块可以学习数据的任务特定内部表示。

多任务学习者的输出将是一个预测列表，我们可以将其合并为最终损失，如

![](../Images/be7a7ca40e729ba6830d930fcdcf17d9.png)

其中p是预测值，y是标签，w是（可选的）任务特定权重，控制每个任务的相对重要性。

## 专家建模

硬参数共享也许是解决多任务学习问题最常见且最简单的方法，但它有一个主要缺点：我们必须提前决定网络的哪些部分应该共享，哪些不应该。这要求我们知道哪些任务能很好地一起学习，哪些不能，但实际上，我们可能无法提前获得这些信息。

进入“专家建模”，也称为“专家混合”（MoE），追溯到1991年一些AI大咖，如Robert Jacobs、Michael Jordan、Steven Nolan和Geoffrey Hinton的[论文](https://www.cs.toronto.edu/~hinton/absps/jjnh91.pdf)。MoE的关键思想是通过门控网络结合N个专家，根据输入数据选择最佳专家。在这里，

+   “专家”是一个处理数据的MLP，结果是一个嵌入或预测，并且

+   “门控网络”只是一个softmax函数：

![](../Images/fd228b1883eb57129a0e9dbceb2f367a.png)

其中x是输入数据，W是一个可学习的矩阵。换句话说，W（因此门控）学习根据输入数据选择正确的专家。

然而，MoE只使用一个门控，这在有多个任务的情况下可能效果不好，每个任务都需要自己的专家集。因此，多任务推荐系统的一个突破是用多个门控替代MoE中的单一门控，每个任务一个，结果就是“MMoE”，即“多门控专家混合”，在2018年由Google提出的[论文](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007)中介绍。

作者展示了MMoE在合成数据、普查数据以及大规模生产推荐数据集上均优于硬参数共享和MoE。MMoE特别适用于（相比于MoE）任务相关性较低的情况，突显了拥有多个门控的优势。

## 辅助学习

![](../Images/be210010812e4882cab810fdf7ad6c4a.png)

MetaBalance的关键思想是将辅助梯度缩放到与主要任务的梯度相匹配，如从左到右的图表过渡所示。图源自[He et al 2022](https://arxiv.org/abs/2203.06801)。

在许多推荐问题中，通过联合学习辅助任务可以改善主要任务的预测性能。例如，

+   在预测转化率时，当联合学习预测点击率的辅助任务时，预测性能会提高（[Ma et al 2018](https://dl.acm.org/doi/10.1145/3209978.3210104)），

+   当尝试预测用户评分时，预测性能在联合学习辅助任务预测项目元数据（如类别和标签）时会得到改善（[班萨尔等 2016](https://arxiv.org/abs/1609.02116)）。

+   当尝试预测新闻推送中的阅读时长时，预测性能会在联合学习辅助任务预测点击率时得到改善（[赵等 2021](https://arxiv.org/pdf/2102.07142.pdf)），仅举几个例子。在所有这些情况下，辅助任务的目的是不是在推理时使用预测，而仅仅是提升我们试图学习的主要任务的预测性能。

辅助学习之所以有效，是因为我们添加了梯度信号，这有助于模型在参数空间中找到最佳潜在最小值，而当主任务的梯度信号稀疏时，这种额外的信号尤为有用。例如，转换率远低于点击率，因此预计后者的梯度信号更丰富，可以补充前者。

然而，已显示辅助学习中的梯度可能高度不平衡，以至于辅助梯度要么主导学习，要么根本无关紧要。这是一个问题，假设“MetaBalance”的作者，2022 年提出的高级辅助学习算法[论文](https://arxiv.org/abs/2203.06801)来自 Meta。MetaBalance 的关键思想是将辅助梯度缩放到与主要任务梯度相同的数量级。

形式化地说：

[PRE0]

其中 `g_aux` 是来自辅助任务的梯度，`g_main` 是来自主要任务的梯度，r 是作者通过经验确定的超参数。论文中 r~0.7 似乎效果最佳：换句话说，当辅助任务的梯度与主要任务的梯度接近但不完全相同时，辅助任务帮助最大。

事实上，MetaBalance 展示了令人鼓舞的结果。作者考虑了两个电子商务购物数据集，其中目标是“购买”，辅助任务包括“点击”、“添加到购物车”和“添加到列表”。相较于单任务和普通（共享底层）多任务建模，MetaBalance 的改进是显著的。在一个问题中，他们将 NDGC@10 从 0.82（普通多任务）提高到 0.99（MetaBalance），提升了 17%！

## 总结

回顾一下：

+   多任务学习很重要，因为现代推荐系统通常需要同时优化多个业务目标。

+   不是所有任务都能很好地一起学习。任务可以互相帮助，产生正迁移，也可以相反——彼此对抗——产生负迁移。确定哪些任务可以一起学习是一个 NP-hard 问题！

+   硬参数共享（即“共享底层”）是解决多任务学习最简单和最常见的方法。这是建立稳固基线时应该首先尝试的方法。

+   专家建模，特别是MMoE，是当前解决多任务学习问题的最先进技术，同时能够减轻负迁移。

+   在辅助学习中，我们增加了额外的任务，其唯一目的是提高主要任务的性能。辅助学习在多个应用场景中已被证明能带来显著的建模改进，并且通过扩展辅助梯度可以进一步提升效果。

而这仅仅是冰山一角。在这个领域还有很多未解之谜：如何设计良好的辅助任务？辅助任务与主要任务的最佳比例是多少？最佳的专家数量是多少？它如何随着任务数量的增加而扩展？专家模块应该有多大？

请继续关注这个领域。新的突破无疑就在前方。

*对现代推荐系统仍感到好奇？请继续阅读：*

+   [推荐系统中的深度学习：入门指南](https://medium.com/towards-data-science/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca)

+   [现代推荐系统中的哈希：入门指南](https://medium.com/towards-data-science/hashing-in-modern-recommender-systems-a-primer-9c6b2cf4497a)

+   [学习排名：入门指南](https://medium.com/towards-data-science/learning-to-rank-a-primer-40d2ff9960af)

+   [解析 YouTube 的推荐算法](https://medium.com/towards-data-science/breaking-down-youtubes-recommendation-algorithm-94aa3aa066c6)

+   [推荐系统中的偏差：主要挑战与近期突破](https://medium.com/towards-data-science/biases-in-recommender-systems-top-challenges-and-recent-breakthroughs-edcda59d30bf)

+   [机器学习不仅预测未来，它还主动创造未来](/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9)
