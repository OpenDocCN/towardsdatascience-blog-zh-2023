- en: 'The Power of Bayesian Causal Inference: A Comparative Analysis of Libraries
    to Reveal Hidden Causality in Your Dataset.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-power-of-bayesian-causal-inference-a-comparative-analysis-of-libraries-to-reveal-hidden-d91e8306e25e](https://towardsdatascience.com/the-power-of-bayesian-causal-inference-a-comparative-analysis-of-libraries-to-reveal-hidden-d91e8306e25e)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Reveal the hidden causal variables in your data set by using the best-suited
    Bayesian causal inference library: a comparison with hands-on examples of five
    popular libraries.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://erdogant.medium.com/?source=post_page-----d91e8306e25e--------------------------------)[![Erdogan
    Taskesen](../Images/8e62cdae0502687710d8ae4bbcd8966e.png)](https://erdogant.medium.com/?source=post_page-----d91e8306e25e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d91e8306e25e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d91e8306e25e--------------------------------)
    [Erdogan Taskesen](https://erdogant.medium.com/?source=post_page-----d91e8306e25e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d91e8306e25e--------------------------------)
    ·20 min read·May 22, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9da363a089f70e5f5c65add731ae7d3b.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Alexander Schimmeck](https://unsplash.com/@alschim?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/Aohf8gqa7Zc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the causal effect of variables in systems or processes is very
    valuable. There are a number of Python libraries that can assist in determining
    causal relationships. ***I will compare five popular causal inference libraries
    in their functionality, ease of use, and flexibility.*** Each is accompanied by
    hands-on examples. The included libraries are [*Bnlearn*](https://github.com/erdogant/bnlearn)*,*
    [*Pgmpy*](https://github.com/pgmpy/pgmpy)*,* [*CausalNex*](https://github.com/quantumblacklabs/causalnex)*,*
    [*DoWhy*](https://github.com/py-why/dowhy),and [*CausalImpact*](https://github.com/jamalsenouci/causalimpact/).
    By the end of this blog, you will have a better understanding of these five causal
    inference libraries and determine which fits best for your use case.
  prefs: []
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Causal inference is to determine the cause-and-effect relationships between
    variables in a process or system. In general, we can separate variables into two
    distinct groups; ***driver and passenger variables***. Driver variables are those
    that *directly* influence the outcome or dependent variable, while passenger variables
    are those that do not have a direct effect but are correlated/ associated with
    the outcome variable.
  prefs: []
  type: TYPE_NORMAL
- en: The identification of ***driver variables*** can be crucial in projects such
    as predictive maintenance or in the security domain. The driver variables can
    help explain the causal relationship between the predictor and outcome variables.
    In contradiction, ***passenger variables*** do not have a direct effect on the
    outcome variable. However, they can still be useful as they can provide additional
    variation and thus understanding of the context in which the data was collected.
    *For example, if we find that engine failures are strongly correlated with location,
    we might suspect that there is an underlying driver variable that is causing the
    failure for a specific location.* Causal inference helps to make better decisions
    by identifying which variables to manipulate and which variables to monitor.
  prefs: []
  type: TYPE_NORMAL
- en: In causal inference, we not only seek to determine whether an event would occur,
    but also to understand the mechanism by which it occurs.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'However, causal inference analysis is a challenging task because it requires
    separating the effects of multiple variables, accounting for confounding variables,
    and dealing with uncertainty. Luckily, Python has several libraries that can help
    data scientists perform causal inference. In this article, I will compare the
    five most popular causal inference libraries in Python: [***Bnlearn***](https://github.com/erdogant/bnlearn)***,***
    [***Pgmpy***](https://github.com/pgmpy/pgmpy)***,*** [***DoWhy***](https://github.com/py-why/dowhy)***,***
    [***CausalNex***](https://github.com/quantumblacklabs/causalnex)***, and*** [***CausalImpact***](https://github.com/jamalsenouci/causalimpact/).'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you find this article about Bayesian causal learning helpful, you are welcome
    to* [*follow me*](http://erdogant.medium.com/) *because I write more about Bayesian
    statistics. If you are thinking of taking a Medium membership, you can support
    my work a little bit by using my* [*referral link*](https://medium.com/@erdogant/membership)*.
    It is the same price as a coffee for which you can read every month unlimited
    articles.*'
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of Five Causal Inference Libraries.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s go through each of the five packages and examine their functionality in
    terms of problem-solving capacity. To compare the libraries most consistently,
    I will use the same data set (when possible) across the five libraries, namely
    the *Census Income data* *set.* This multivariate data set contains 14 nodes,
    with 48842 instances (or samples) [1]. Each node contains two or more possible
    states and can be used to estimate whether having a graduate degree is important
    for making more than 50k annually. We can load the data set using the *Bnlearn
    library*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Library 1: Bnlearn for Python.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Bnlearn*** is a Python package that is suited for creating and analyzing
    Bayesian Networks, for *discrete, mixed, and continuous data sets* [2, 3]. It
    is designed to be ease-of-use and contains the most-wanted Bayesian pipelines
    for causal learning in terms of structure learning, parameter learning, and making
    inferences. There is a range of statistical tests that can be used by simply specifying
    the parameters during initialization. *Bnlearn* also contains various helper functions
    to transform data sets, derive the topological ordering of the (entire) graph,
    comparison of two graphs, and to make various insightful plots, among others.
    *More details about structure learning with bnlearn can be found here:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=post_page-----d91e8306e25e--------------------------------)
    [## A Step-by-Step Guide in detecting causal relationships using Bayesian Structure
    Learning in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: The starters guide to effectively determine causality across variables.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=post_page-----d91e8306e25e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: One of the great functionalities of *Bnlearn* is that it can learn the causal
    structure based on only the data set. There are six algorithms implemented for
    this task; `hillclimbsearch, exhaustivesearch, constraintsearch, chow-liu, naivebayes
    and TAN` and can be combined with scoring types `BIC, K2, BDEU`. Some methods
    require setting a root node, such as Tree-augmented Naive Bayes (`TAN`), which
    are recommended in case you know the outcome (or target) value. This will also
    dramatically lower the computational burden and is recommended in case you have
    many features. In addition, with the `independence test`, spurious edges can be
    easily pruned from the model. In the following example, I will use the `hillclimbsearch`
    method with scoring type `BIC` for structure learning. In this example, we will
    *not* define a target value but let the *Bnlearn* decide the entire causal structure
    purely on the data itself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: To determine the Directed Acyclic Graph (DAG), we need to specify the input
    data frame as shown in the code section above. After fitting a model, the results
    are stored in the `model` dictionary, which can be used for further analysis.
    An interactive plot of the causal structure is shown in Figure 1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c470eca0ffd89d1bd84e07a043ab375.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. Interactive plot for structure learning using Bnlearn for the *Census
    Income data* *set. In case the CPDs are learned, the tooltip will describe the
    estimated CPDs (image by author).*
  prefs: []
  type: TYPE_NORMAL
- en: With the learned DAG (Figure 1), we can estimate the conditional probability
    distributions (CPDs, see code section below), and make inferences using *do-calculus*.
    *Or in other words, we can start asking questions to our data.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Question 1:** What is the probability of having a salary > 50k given the
    education is Doctorate: `P(salary | education=Doctorate)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Intuitively, we may expect a high probability because the education is “*doctorate”*.
    Let’s find out the posterior probability from our Bayesian model. In the code
    section below we derived a probability of `P=0.7093`. This confirms that when
    education is *doctorate,* there is a higher probability of having a salary of
    >50K compared to *not having a doctorate education*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let's now ask the question of whether lower education also results in a lower
    probability of having a salary of >50K. We can easily change education in `HS-grad`
    and again ask the question.
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 2:** What is the probability of having a salary > 50k given the
    education is HS-grad: `*P(salary | education=*HS-grad*)*`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This results in a posterior probability of `P=0.1615` . Studying is thus very
    beneficial for a higher salary according to this data set. However, be aware that
    we did not use any other constraints as evidence that can influence the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Until this part, we used a single variable but all variables in the DAG can
    be used for *evidence*. Let’s make another more complex query.
  prefs: []
  type: TYPE_NORMAL
- en: '**Question 3:** What is the probability of being in a certain workclass given
    that education is Doctorate and the marital status is never-married. `P(workclass|
    education=Doctorate, marital-status=never-married)`.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In the code section below can be seen that this returns the probability for
    each *workclass*, with *workclass* being `private` having the highest probability:
    `P=0.5639`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Input data***: The input data can be discrete, continuous, or mixed data
    sets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advantages:** Contains the most wanted Bayesian pipelines for structure learning,
    parameter learning, and making inferences using *do-calculus*. Plots can be easily
    created and can be CPDs explored. Great for starters and experts that do not want
    to build the pipeline themselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Library 2: Pgmpy.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Pgmpy*** is a library that provides tools for Probabilistic Graphical Models.
    It contains implementations of various statistical approaches for Structure Learning,
    Parameter Estimation, Approximations (Sampling Based), and Exact inference. An
    advantage is that the core functions are low-level statistical functions which
    makes it flexible to build your own causal blocks. Although this is great, it
    requires a good knowledge of Bayesian modeling and can therefore be more difficult
    than libraries such as *Bnlearn* when you are just starting with Bayesian modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: In terms of functionality, the same results can be derived as shown with *Bnlearn*
    because some of the core functionalities of *Pgmpy* are also utilized in *Bnlearn.*
    However, in *pgmpy* you do need to build the entire pipeline yourself, including
    the transformation steps required for the data, but also the collection of the
    results and making the plots. In the code section below I will briefly demonstrate
    how to learn the causal structure with the `hillclimbsearch` estimator and scoring
    method `BIC`. Note that different estimators may require very different steps
    in the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: To make inferences on the data using do-calculus, we first need to estimate
    the CPDs as shown in the code section below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Input data***: The input data set must be discrete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advantages:** Contains fundamental building blocks that can be used to create
    your own Bayesian pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disadvantage**: Requires good knowledge of Bayesian modeling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Library 3: CausalNex.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***CausalNex*** is a Python library for learning causal models from data, identifying
    causal pathways, and estimating causal effects [5]. *Causalnex* supports *only*
    discrete distributions, whereas continuous features, or features with a large
    number of categories, should be discretized prior to fitting the Bayesian Network.
    It is described that: “*models typically fit poorly in case many variables are
    used”*. However, helper functionalities are provided to reduce the cardinality
    of categorical features. Let’s examine the possibilities of Causalnex using the
    *Census Income data* *set.* First, we need to make the data numeric, since this
    is what the underlying NOTEARS [7] algorithm expects. We can do this by label
    encoding non-numeric variables (see code section).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We can now apply the NOTEARS algorithm to learn the structure and visualize
    the causal model using the plot function. We need to apply thresholding to remove
    weaker edges and prevent having a fully connected graph. In addition, to avoid
    spurious edges, constraints on the edges can be included.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f0f8756492f19856ada7ee479124df78.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. Structure learning using Causalnex for the *Census Income data* *set.
    Labels without a node contained weaker edges that are removed using thresholding.
    (image by author).*
  prefs: []
  type: TYPE_NORMAL
- en: With the derived structure we can learn the conditional probability distribution
    (CPDs) and start making queries. However, there are a few additional steps to
    take, i.e., reducing the cardinality of categorical features, and discretizing
    numeric features. Note that we also need to specify the node states in the form
    of a dictionary to prevent manually converting numeric values into categorical
    labels. Although each step is important, for the sake of simplicity I will skip
    these steps to avoid many lines of code. For full details, I recommend reading
    the documentation manual [here](https://causalnex.readthedocs.io/en/latest/03_tutorial/01_first_tutorial.html).
    It also demonstrates how to use a few helper methods to make discretization easier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Input data***: The input data set must be discrete. Continuous data is not
    supported.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advantages:** Causal networks can be learned and inferences on the data can
    be performed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disadvantage**: Requires intensive pre-processing steps but helper functionalities
    are provided to reduce the cardinality of categorical features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Library 4: DoWhy.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***DoWhy***is a Python library for causal inference that supports explicit
    modeling and testing of causal assumptions [2, 3]. *In comparison to Bnlearn and
    Pgmpy, in the DoWhy library, it is obligatory to define both the outcome variable
    and the treatment variable.* The treatment variable is the variable of interest
    that you want to investigate the causal effect of, and the outcome variable is
    the variable that you want to measure the effect on. In addition, it is also recommended
    to provide a DAG, aka the causal relationships between the nodes. To create the
    causal graph for your dataset, you either need domain knowledge or you can connect
    each variable to the *target* and *treatment* variable. Note that the latter is
    automatically performed when no DAG is given. For this data set, I do not include
    a known structure and let *DoWhy* create edges between all variables to the *outcome*
    and *treatment* variable. The first code section shows the required pre-processing
    steps, and the second code section the creation of the causal model.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/235a7cef946f478e4c750264e1dde7a0.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. DoWhy created this DAG to model the *Census Income data* *set with
    the outcome variable being “salary”, and the treatment variable “Education” (image
    by author).*
  prefs: []
  type: TYPE_NORMAL
- en: As you may have noticed in the code section above, the treatment variable must
    be binary (set to Doctorate), and all categorical variables need to be encoded
    into numeric values. In the code section below we will be using the properties
    of the causal graph to identify the causal effect. The result may not be surprising.
    It shows that having a `Doctorate` *increases* the chances of a good `salary`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Input data***: Outcome variable, and Treatment variable. It is highly recommended
    to provide a causal DAG.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Requirements:*** The treatment variable must be binary, and all categorical
    variables need to be encoded into numeric values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**(dis)advantage:** The output contains many details which can be beneficial
    but make it also complicated to understand. Can not learn the causal DAG from
    the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Library 5: CausalImpact.**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***CausalImpact***is a Python package for causal inference using Bayesian structural
    ***time-series models*** [4]. The main goal is to infer the expected effect of
    a given intervention by analyzing differences between expected and observed time
    series data, such as Program Evaluation, or Treatment Effect Analysis. It makes
    the assumption that the response variable can be precisely modeled by linear regression.
    However, it must not be affected by the intervention that took place. For instance,
    if a company wants to infer what impact a given marketing campaign will have on
    its “*revenue*”, then its daily “*visits*” cannot be used as a covariate as the
    total visits might be affected by the campaign. In the following example, we will
    create 100 observations with a response variable `y` and a predictor `x1`. Note
    that in real use cases, we will have many more predictor variables. For demonstration,
    the *intervention effect* is created by changing the response variable by 10 units
    after timepoint 71.'
  prefs: []
  type: TYPE_NORMAL
- en: To estimate the causal effect, we first need to specify the pre-intervention
    period and post-intervention period. With the `run` function, we fit a time series
    model using MLE (default), and estimate the causal effect.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The Average column describes the average time during the post-intervention period.
    The Cumulative column sums up individual time points, which is a useful perspective
    if the response variable represents a flow quantity, such as queries, clicks,
    visits, installs, sales, or revenue. We see that in this example, there is a 100%
    probability of causal effect with a P-value of 0 which is correct because we included
    this in the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/011842c2ac16833a2efa718c358531f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. CausalImpact plot (image by author).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the plot (Figure 4), we can see three panels that can be described as follows:
    In Panel 1, we can see the data along with a counterfactual prediction specifically
    for the post-treatment period. In the second panel, is shown the difference between
    the observed data and the counterfactual predictions. This difference represents
    the estimated pointwise causal effect, as determined by the model. The bottom
    panel depicts the cumulative effect of the intervention by aggregating the pointwise
    contributions from the previous panel. It is important to note that the validity
    of these inferences relies on the assumption that the covariates were not influenced
    by the intervention themselves. Additionally, the model assumes that the relationship
    established between the covariates and the treated time series during the pre-period
    remains consistent throughout the post-period.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Input data***: Time series data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Requirements:*** The pre-intervention period and post-intervention period
    needs to be specified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advantage:** Can determine the causal effects on time-series data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall summary between the libraries.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have seen five libraries for learning causality, each with its own (dis)advantages
    and their focus to solve certain problems. A summary is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The ***BnLearn***library is suited in use cases where you have discrete, mixed,
    or continuous data sets and need to derive the causal DAG from the data (structure
    learning), do parameter learning (CPD estimations), or in cases where you aim
    to make inferences (*do-calculus*). The advantages are that many pre- and post-processing
    steps are solved within the pipelines which makes it less error-prone. It allows
    categorical (string) labels as input and can remove spurious edges using statistical
    tests (independence test). In addition, edges or nodes can also be whitelisted
    or blacklisted. Note that it is not possible to entirely customize the modeling
    part as most processing steps are performed within the pipelines, which may give
    less control to the user.
  prefs: []
  type: TYPE_NORMAL
- en: The ***Pgmpy*** library contains low-level statistical functions to create and
    combine various methods for structure learning, parameter learning, and inferences.
    It is flexible in usage but requires good knowledge of Bayesian modeling. Note
    that the *Bnlearn* library utilizes some functions from *Pgmpy* and has therefore
    overlapping functionality. Or in other words, if you aim to create customized
    pipelines, it is recommended to use *Pgmpy.* Otherwise, I recommend using *bnlearn.*
  prefs: []
  type: TYPE_NORMAL
- en: The ***CausalNex*** library can be used to derive the causal DAG from the data,
    and make inferences. Note that it only works on discrete data sets. After detecting
    a causal DAG, edges can be removed by thresholding. Unfortunately, it can not
    work with categorical labels and needs to be converted into numerical values.
    In addition, various intermediate preprocessing steps are required. For example,
    reducing the cardinality of categorical features, describing numeric features,
    and specifying all of the states that each node can take in the form of a dictionary.
    Although this gives more control to the user in the modeling part, the extra modeling
    adds a layer of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: The ***DoWhy*** approach is ideal in cases where you want to estimate the causal
    effect if you have an *outcome variable* together with a *treatment* variable.
    Ideal for use cases where you need A/B testing, such as determining the causes
    of hotel booking cancellations. The *outcome* can be set as *“cancelation”*, and
    *treatment* can be set as *“different room assigned”.* Another use case could
    be to estimate the effect of a member rewards program. Note that this library
    is not designed to learn the causal DAG from the data. However, it does need a
    causal DAG as input for the model which you need to provide manually.
  prefs: []
  type: TYPE_NORMAL
- en: '***CausalImpact***is a Python package for causal inference using Bayesian structural
    ***time-series models.*** Although it also computes causality, it is not comparable
    in functionality to the other libraries as it does not intend to create a causal
    DAG or make inferences on the data. The goal is to infer the expected effect of
    a given intervention by analyzing differences between expected and observed time
    series data, such as Program Evaluation, or Treatment Effect Analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: Final words.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Modeling your data for causality can be challenging for many reasons. It starts
    with choosing the right library that matches your specific use case for which
    we have seen a comparison of five popular causal inference libraries: *Bnlearn,
    Pgmpy, CausalNex, DoWhy, and CausalImpact*. Each library has its own (dis)advantages
    and is best suited for certain use cases. The libraries are compared in their
    functionalities, capabilities, and interpretability of the results using the same
    data set. Only for *CausalImpact,* a different data set is used as it could only
    model continuous values and required time series data.'
  prefs: []
  type: TYPE_NORMAL
- en: A grouping on functionality would cluster ***Bnlearn****,* ***Pgmpy****, and*
    ***CausalNex*** as they contain functionalities for structure learning, parameter
    learning, and making inferences. The second group is ***DoWhy*** and ***CausalImpact***
    which are designed to measure the causal effect of *treatment* variable(s) on
    an outcome variable *Y*, controlling for a set of features *X*. Besides the five
    causal libraries described here, more libraries are worth looking at, such as
    *EconML*, *Pyro*, and *CausalML*, which fall in the second group (causal effect
    of *treatment* variable on an *outcome* variable*)*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Be Safe. Stay Frosty.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Cheers E.***'
  prefs: []
  type: TYPE_NORMAL
- en: '*Disclaimer: I am the developer of the Python bnlearn library. Whatever your
    decision for a causal library is, make sure you fully understand the modeling
    part and can interpret the results.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you found this article about Bayesian causal learning helpful, you are
    welcome to* [*follow me*](http://erdogant.medium.com/) *because I write more about
    Bayesian statistics. If you are thinking of taking a Medium membership, you can
    support my work a little bit by using my* [*referral link*](https://medium.com/@erdogant/membership)*.
    It is the same price as a coffee for which you can read every month unlimited
    articles.*'
  prefs: []
  type: TYPE_NORMAL
- en: Software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bnlearn [Colab Notebook examples](https://erdogant.github.io/distfit/pages/html/Documentation.html#colab-notebook)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparison PDF file between eight Bayesian causality libraries.](https://erdogant.gumroad.com/l/Comparison_python_libraries_bayesian_causality?layout=profile)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s connect!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Let’s connect on LinkedIn](https://www.linkedin.com/in/erdogant/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Follow me on Github](https://github.com/erdogant)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Follow me on Medium](https://erdogant.medium.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Related work with Bayesian Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=post_page-----d91e8306e25e--------------------------------)
    [## A Step-by-Step Guide in detecting causal relationships using Bayesian Structure
    Learning in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: The starters guide to effectively determine causality across variables.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=post_page-----d91e8306e25e--------------------------------)
    [](/a-step-by-step-guide-in-designing-knowledge-driven-models-using-bayesian-theorem-7433f6fd64be?source=post_page-----d91e8306e25e--------------------------------)
    [## A step-by-step guide in designing knowledge-driven models using Bayesian theorem.
  prefs: []
  type: TYPE_NORMAL
- en: In case you don’t have data but there is experts knowledge. A starters guide
    to convert knowledge into computer-aided…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-step-by-step-guide-in-designing-knowledge-driven-models-using-bayesian-theorem-7433f6fd64be?source=post_page-----d91e8306e25e--------------------------------)
    [](/a-guide-to-find-the-best-boosting-model-using-bayesian-hyperparameter-tuning-but-without-c98b6a1ecac8?source=post_page-----d91e8306e25e--------------------------------)
    [## A Guide to Find the Best Boosting Model using Bayesian Hyperparameter Tuning
    but without…
  prefs: []
  type: TYPE_NORMAL
- en: Boosted decision tree algorithms may outperform other models but overfitting
    is a real danger. Fit your model using the…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/a-guide-to-find-the-best-boosting-model-using-bayesian-hyperparameter-tuning-but-without-c98b6a1ecac8?source=post_page-----d91e8306e25e--------------------------------)
    [](https://erdogant.medium.com/hands-on-guide-for-hyperparameter-tuning-with-bayesian-optimization-for-classification-models-2002224bfa3d?source=post_page-----d91e8306e25e--------------------------------)
    [## Hands-on Guide for Hyperparameter Tuning with Bayesian Optimization for Classification
    Models.
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to split the data, optimize hyperparameters, prevent overtraining,
    select the best model, and create…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: erdogant.medium.com](https://erdogant.medium.com/hands-on-guide-for-hyperparameter-tuning-with-bayesian-optimization-for-classification-models-2002224bfa3d?source=post_page-----d91e8306e25e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Census Income. (1996). UCI Machine Learning Repository. [https://doi.org/10.24432/C5S595](https://doi.org/10.24432/C5S595).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taskesen E, [A Step-by-Step Guide in detecting causal relationships using Bayesian
    Structure Learning in Python](/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5),
    Medium, 2021
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taskesen, E. (2020). [*Learning Bayesian Networks with the bnlearn Python Package.*](https://erdogant.github.io/bnlearn)
    (Version 0.3.22) [Computer software].
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Dowhy: [https://www.pywhy.org/dowhy/v0.8/getting_started/intro.html](https://www.pywhy.org/dowhy/v0.8/getting_started/intro.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Amit Sharma, Emre Kiciman. DoWhy: An End-to-End Library for Causal Inference.
    2020\. [https://arxiv.org/abs/2011.04216](https://arxiv.org/abs/2011.04216)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kay H. et al, [*Inferring causal impact using Bayesian structural time-series
    models*](https://research.google/pubs/pub41854/), 2015, Annals of Applied Statistics
    (247–274, vol9)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Xun Zheng et al, [*DAGs with NO TEARS: Continuous Optimization for Structure
    Learning*](https://proceedings.neurips.cc/paper_files/paper/2018/file/e347c51419ffb23ca3fd5050202f9c3d-Paper.pdf),
    32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal,
    Canada.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AI4I 2020 [Predictive Maintenance Dataset.](https://archive-beta.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset)
    (2020). UCI Machine Learning Repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
