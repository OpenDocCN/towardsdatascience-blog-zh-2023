- en: Introduction to Streaming Frameworks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流处理框架介绍
- en: 原文：[https://towardsdatascience.com/introduction-to-streaming-frameworks-d612583a3246](https://towardsdatascience.com/introduction-to-streaming-frameworks-d612583a3246)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/introduction-to-streaming-frameworks-d612583a3246](https://towardsdatascience.com/introduction-to-streaming-frameworks-d612583a3246)
- en: Understanding some of the key characteristics to consider when evaluating and
    comparing streaming technologies.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解在评估和比较流处理技术时需要考虑的一些关键特性。
- en: '[](https://pierpaoloippolito28.medium.com/?source=post_page-----d612583a3246--------------------------------)[![Pier
    Paolo Ippolito](../Images/981abb84149adab275473b76bdbde66f.png)](https://pierpaoloippolito28.medium.com/?source=post_page-----d612583a3246--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d612583a3246--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d612583a3246--------------------------------)
    [Pier Paolo Ippolito](https://pierpaoloippolito28.medium.com/?source=post_page-----d612583a3246--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pierpaoloippolito28.medium.com/?source=post_page-----d612583a3246--------------------------------)[![Pier
    Paolo Ippolito](../Images/981abb84149adab275473b76bdbde66f.png)](https://pierpaoloippolito28.medium.com/?source=post_page-----d612583a3246--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d612583a3246--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d612583a3246--------------------------------)
    [Pier Paolo Ippolito](https://pierpaoloippolito28.medium.com/?source=post_page-----d612583a3246--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d612583a3246--------------------------------)
    ·6 min read·Nov 8, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d612583a3246--------------------------------)
    ·阅读时长6分钟·2023年11月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dbb92cc79b1e109a4c0ceeb2602b29ef.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbb92cc79b1e109a4c0ceeb2602b29ef.png)'
- en: Photo by [Joao Branco](https://unsplash.com/@jfobranco?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Joao Branco](https://unsplash.com/@jfobranco?utm_source=medium&utm_medium=referral)
    提供的照片，[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: As data architectures are becoming more and more mature, streaming is no longer
    considered a luxury but a technology with a wide range of applications across
    different industries. Because of technical and resource limitations, batch processing
    was in fact always the preferred way to process and deliver applications, although
    with the development of micro-batch and native streaming frameworks in distributed
    systems based on Apache, high-scale streaming has now become much more accessible
    (Figure 1).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据架构变得越来越成熟，流处理不再被视为奢侈品，而是一项在不同行业中广泛应用的技术。由于技术和资源限制，批处理实际上一直是处理和交付应用程序的首选方式，但随着基于Apache的分布式系统中微批处理和原生流处理框架的发展，高规模流处理现在变得更加可及（见图1）。
- en: 'Some example applications for using streaming systems, can be processing: transaction
    data to spot anomalies, weather data, IoT data from remote locations, geo-location
    tracking, etc.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用流处理系统的一些示例应用包括：处理交易数据以发现异常、天气数据、来自远程位置的物联网数据、地理位置跟踪等。
- en: '![](../Images/bf3c7883342ec4cb1055f4bf4e27ce82.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf3c7883342ec4cb1055f4bf4e27ce82.png)'
- en: 'Figure 1: Batch vs Streaming (Image by Author).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：批处理与流处理（作者提供的图片）。
- en: Real-Time vs Micro-Batch Processing
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时处理与微批处理
- en: 'There are two key types of streaming processing systems: micro-batch and real-time:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理系统主要有两种类型：微批处理和实时处理：
- en: In real-time streaming processing, each record is processed as soon as it becomes
    available. This can therefore result in systems with a very low latency, ready
    to make immediate use of the incoming data (e.g. detecting fraudulent transactions
    in financial systems).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实时流处理过程中，每条记录都会在其可用时立即被处理。因此，这可能导致系统具有非常低的延迟，能够立即利用传入的数据（例如，在金融系统中检测欺诈交易）。
- en: In micro-batch processing systems, data points are instead not processed one
    by one but in small blocks and then returned after specific time intervals or
    once reached a maximum storage size. This type of approach favors therefore high
    throughput over low latency. Finally, micro-batch systems can be particularly
    useful if interested in performing complex operations such as aggregates (e.g.
    min, max, mean), joins, etc… on the fly before outputting the results in a storage
    system. Micro batch processing can therefore be considered a very good compromise
    between pure streaming and batch when performing for example hourly reporting
    tasks (e.g. mean weather temperature, etc.).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在微批处理系统中，数据点不是一个一个处理，而是以小块的形式处理，然后在特定时间间隔后或达到最大存储大小时返回。这种方法因此更倾向于高吞吐量而非低延迟。最后，如果有兴趣执行复杂的操作，例如在存储系统中输出结果之前进行聚合（如最小值、最大值、均值）、连接等操作，微批处理系统可以特别有用。因此，微批处理可以被认为是在执行例如每小时报告任务（如平均天气温度等）时的一个非常好的折衷方案。
- en: '![](../Images/56028732bd9dcc650e87a06e344a4861.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56028732bd9dcc650e87a06e344a4861.png)'
- en: 'Figure 2: Real Time vs Micro Batch processing (Image by Author).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：实时与微批处理（图片由作者提供）。
- en: Choosing a Streaming Framework
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择流处理框架
- en: 'Now that we have clarified the difference between micro-batch and real-time
    streaming processing, we are ready to examine some of the key points to keep into
    account:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经澄清了微批处理和实时流处理的区别，我们可以开始审查一些需要考虑的关键点：
- en: Latency
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟
- en: Throughput
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吞吐量
- en: Memory Usage
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存使用
- en: Scalability
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性
- en: Fault recovery
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障恢复
- en: Message Delivery Guarantees
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息传递保证
- en: Latency
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 延迟
- en: Latency can be defined as the time taken for a task to process one or more inputs
    and return an output (how long it takes for streaming records to be processed
    once they entered our system). If low latency is a primary constraint, streaming
    frameworks would then be our best choice. In micro-batch processing, inputs are
    in fact buffered before being consumed (therefore increasing lag time).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟可以定义为处理一个或多个输入并返回输出所需的时间（流记录进入系统后处理的时间）。如果低延迟是主要限制，则流处理框架将是我们的最佳选择。在微批处理中，输入实际上是在被消费之前缓存的（因此增加了延迟时间）。
- en: Throughput
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 吞吐量
- en: Throughput represents the aggregated rate of output data returned by our system.
    This can for example be represented by the amount of input data processed per
    second. For example, Apache Spark can use micro batch processing and by buffering
    the input data can be able to achieve high throughput rates. On the other hand,
    native streaming frameworks would then register lower throughput rates in order
    to optimize latency scores as much as possible.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 吞吐量表示系统返回的输出数据的汇总速率。例如，这可以通过每秒处理的输入数据量来表示。例如，Apache Spark可以使用微批处理，通过缓存输入数据能够实现高吞吐量速率。另一方面，原生流处理框架为了尽可能优化延迟评分，则会注册较低的吞吐量速率。
- en: Memory Usage
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存使用
- en: As streaming frameworks process lots of data every day, optimizing memory usage
    can be a very important factor in order to ensure the system would not get overwhelmed
    under heavy loads. Depending on the system architecture, these systems can in
    fact be designed to retain data for different amounts of time and if the data
    is either held for too long or large amounts are received all at the same time,
    then memory can become a big constraint. Evaluating memory usage optimization
    across different frameworks can therefore be a quite complicated task and highly
    dependent on the specifics of the project you might be working on. In this case,
    creating usage benchmarks with different examples of incoming loads could provide
    valuable insights in order to make a decision.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于流处理框架每天处理大量数据，优化内存使用可以是一个非常重要的因素，以确保系统在重负载下不会被压垮。根据系统架构，这些系统实际上可以设计成保留不同时间段的数据，如果数据保留时间过长或同时接收大量数据，则内存可能成为一个大限制。因此，评估不同框架的内存使用优化可能是一个相当复杂的任务，并且高度依赖于你所从事项目的具体情况。在这种情况下，使用不同示例的来流量创建使用基准可以提供有价值的见解，以便做出决策。
- en: Scalability
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性
- en: In parallel processing streaming frameworks, scalability can be represented
    by the system's ability to handle increasing amounts of work and evenly distribute
    jobs across the different working nodes available. This can for example be done
    by implementing a master-worker architecture, with master nodes designed to best
    plan task division between the worker nodes so that to avoid as much as possible
    to have worker nodes in idle while waiting for dependencies. Additionally, in
    highly scalable architectures, the system should automatically be able to understand
    when it is necessary or not to add/remove resources (e.g. worker nodes) in the
    cluster in order to respond to rising/declining workloads.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行处理流处理框架中，可扩展性可以通过系统处理不断增加的工作量并均匀分配任务到不同工作节点的能力来表示。例如，这可以通过实现主从架构来完成，其中主节点负责最优地规划任务在工作节点之间的分配，以尽可能避免工作节点在等待依赖项时闲置。此外，在高度可扩展的架构中，系统应该能够自动理解何时需要或不需要在集群中添加/删除资源（例如工作节点），以响应不断上升/下降的工作负载。
- en: Fault Recovery
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障恢复
- en: Another important consideration to keep into account is Fault recovery. This
    can in fact be defined as the ability of a system to be resilient and keep operating
    after the failure of one of its components. For example, if a worker node runs
    out of memory and is no longer functional, a new one should be automatically spun
    up in order to reduce downtime and it should be able to be able to pick up from
    a similar stage from where the other node left to not restart the whole process
    completely from scratch. When working with very large workloads in distributed
    systems, fault recovery represents a very important characteristic to keep in
    mind as failure might be more frequent than expected.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的重要因素是故障恢复。实际上，这可以定义为系统在其组件之一失败后能够保持弹性并继续操作的能力。例如，如果一个工作节点内存耗尽且不再功能正常，应该自动启动一个新的节点以减少停机时间，并且它应该能够从类似的阶段继续操作，以避免完全从头开始重启整个过程。在处理非常大的负载的分布式系统中，故障恢复是一个非常重要的特性，因为故障可能比预期的更频繁。
- en: Message delivery guarantees
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息交付保证
- en: 'Finally, every streaming framework can offer different input delivery guarantees.
    Three of the most important delivery guarantees are:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，每个流处理框架可以提供不同的输入交付保证。三个最重要的交付保证是：
- en: Exactly once delivery
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确一次交付
- en: At most once delivery
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至多一次交付
- en: At least once delivery
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少一次交付
- en: With Exactly once delivery, the system guarantees that every incoming input
    will be processed exactly once. With at most once instead, most of the inputs
    are expected to be processed but there is no warranty that an input will be processed
    if something goes wrong as part of the process. Ultimately, with at least once,
    every input is guaranteed to be processed and some messages might also end up
    being processed two or more times.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用“准确一次”交付，系统保证每个传入的输入将被处理一次。相反，使用“至多一次”交付，大多数输入预计将被处理，但如果过程中的某些事情出现问题，则无法保证输入会被处理。最终，使用“至少一次”交付，保证每个输入都会被处理，并且某些消息可能也会被处理两次或更多次。
- en: 'Two key criteria to keep in mind when choosing a message delivery method are:
    latency and computing costs. For example, exactly once would probably be the best
    choice from an accuracy point of view in most use cases, although this approach
    can easily add a lot of additional overhead costs (e.g. having a record history
    system to determine if an input was already processed or not and to recover in
    case of failure). Therefore, depending on the possible constraints for your application,
    other message delivery systems might provide more value for you.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 选择消息交付方法时需要记住的两个关键标准是：延迟和计算成本。例如，从准确性的角度来看，“一次交付”在大多数使用案例中可能是最佳选择，尽管这种方法很容易带来大量额外的开销（例如，需要一个记录历史系统来确定输入是否已经处理过，以及在发生故障时进行恢复）。因此，根据应用程序的可能约束，其他消息交付系统可能会为你提供更多价值。
- en: Apache Spark, Flink and Kafka
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark、Flink 和 Kafka
- en: 'Three of the most prominent Apache projects offering streaming capabilities
    are: Spark, Flink, and Kafka. Spark provides only micro batch processing, Flink
    both native streaming and batch, and Kafka just streaming.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 提供流处理功能的三个最显著的 Apache 项目是：Spark、Flink 和 Kafka。Spark 仅提供微批处理，Flink 提供原生流处理和批处理，而
    Kafka 仅提供流处理。
- en: Apache Spark is nowadays one of the most popular systems to run batch workloads
    and through its revamped Structured Streaming API is now gaining also more adoption
    for streaming tasks (with sub-second latency). Structured Streaming offers, in
    fact, an easier to use API, exactly once processing, built-in fault tolerance,
    and near real-time processing capabilities. If you are interested in learning
    more about Apache Spark, you can find more info about it in my [introduction](/getting-started-with-apache-spark-cb703e1b3ee9)
    and [optimization articles](/apache-spark-optimization-techniques-fa7f20a9a2cf).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Apache Spark 是最流行的批处理工作负载系统之一，通过其改进的结构化流处理 API 也越来越多地用于流处理任务（具有亚秒级延迟）。结构化流处理提供了更易于使用的
    API、精确一次处理、内置容错和接近实时的处理能力。如果你对了解更多关于 Apache Spark 的信息感兴趣，可以在我的[介绍文章](/getting-started-with-apache-spark-cb703e1b3ee9)和[优化文章](/apache-spark-optimization-techniques-fa7f20a9a2cf)中找到更多资料。
- en: Apache Flink can support both infinite (stream) and finite (batch) streams.
    On the contrary to Spark though, by default, the runtime is streaming instead
    of batch. Moreover, Flink is also able to perform stateful computations (taking
    advantage of data dependencies across time to perform aggregations, joins, etc.).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Flink 可以支持无限（流式）和有限（批处理）流。不过，与 Spark 相反的是，默认情况下，运行时是流式的而非批处理的。此外，Flink
    还能够执行有状态的计算（利用时间上的数据依赖进行聚合、连接等）。
- en: 'Finally, Apache Kafka is a specialized platform designed to perform streaming
    operations. It started in 2011 as a messaging queue system and is now a complete
    streaming framework with built in support for both computing and storage. Apache
    Kafka is composed of 4 key APIs: Kafka Streams, Producer, Consumer, and Connector.
    Using the Kafka Streams API can provide many advantages such as: out of the box
    great scalability, cluster management, automatic failover, etc…'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Apache Kafka 是一个专门设计用于执行流处理操作的平台。它始于2011年的一个消息队列系统，现在已经成为一个完整的流处理框架，内置了对计算和存储的支持。Apache
    Kafka 由4个关键 API 组成：Kafka Streams、Producer、Consumer 和 Connector。使用 Kafka Streams
    API 可以提供许多优势，如开箱即用的出色扩展性、集群管理、自动故障转移等。
- en: Additionally, if needed, different frameworks can also be used together in the
    same system in order to make the most of their best capabilities (e.g. using Kafka
    for streaming Storage and Flink for Computations).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果需要，可以在同一系统中结合使用不同的框架，以充分发挥它们的最佳功能（例如，使用Kafka进行流处理存储，使用Flink进行计算）。
- en: Contacts
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系方式
- en: 'If you want to keep updated with my latest articles and projects [follow me
    on Medium](https://pierpaoloippolito28.medium.com/subscribe) and subscribe to
    my [mailing list](http://eepurl.com/gwO-Dr). These are some of my contacts details:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想随时了解我的最新文章和项目，请[在 Medium 上关注我](https://pierpaoloippolito28.medium.com/subscribe)并订阅我的[邮件列表](http://eepurl.com/gwO-Dr)。以下是我的一些联系方式：
- en: '[Linkedin](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Linkedin](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146)'
- en: '[Personal Website](https://pierpaolo28.github.io/)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[个人网站](https://pierpaolo28.github.io/)'
- en: '[Medium Profile](https://towardsdatascience.com/@pierpaoloippolito28)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Medium 个人资料](https://towardsdatascience.com/@pierpaoloippolito28)'
- en: '[GitHub](https://github.com/pierpaolo28)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitHub](https://github.com/pierpaolo28)'
- en: '[Kaggle](https://www.kaggle.com/pierpaolo28)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kaggle](https://www.kaggle.com/pierpaolo28)'
