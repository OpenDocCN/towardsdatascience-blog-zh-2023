- en: 'Hands-on Generative AI with GANs using Python: DCGAN'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-dcgan-6077f0067ac3](https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-dcgan-6077f0067ac3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/a663051d751ad0481e8cc825db37cbd7.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vinicius "amnx" Amano](https://unsplash.com/@viniciusamano?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Improving synthetic image generation with convolutional layers in PyTorch
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----6077f0067ac3--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----6077f0067ac3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6077f0067ac3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6077f0067ac3--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----6077f0067ac3--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6077f0067ac3--------------------------------)
    ·5 min read·Apr 4, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In my [previous article](https://medium.com/towards-data-science/hands-on-generative-ai-with-gans-using-python-image-generation-9a62e591c7c6),
    we have seen how to **use GANs to generate images** of the type of MNIST dataset.
    We achieved good results and succeeded in our intent. However, the two networks
    G (generator) and D (discriminator) were composed mostly of dense layers. At this
    point, you will know that usually when working with images we use CNNs (convolutional
    neural networks) since they use convolutional layers. So let us see how to **improve
    our GANs by using** these types of layers. GANs that use **convolutional layers
    are called DCGANs**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: What is transposed deconvolution?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Typically when we work with CNNs we are used to working with convolutional layers.
    In this case, though we also need the “inverse” operation the transposed deconvolution,
    sometimes also called deconvolution.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**This operation allows us to upsample the feature space**. For example, if
    we have an image represented by a 5x5 grid we can “enlarge” this grid to make
    it 28x28.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: What you do in principle is quite simple, you **put zeros inside the elements
    of the initial feature map to enlarge it and then apply a normal convolution operation
    by using a certain kernel size, stride and padding**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we want to transform a 5x5 feature space to 8x8\. First,
    by inserting zeros we create a 9x9 feature space then by applying a 2x2 filter
    we shrink it again to 8x8\. Let’s look at a graphical example.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/535139b951ccdb3db31ae8af4dd2b93f.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: Transposed Convolution (Image By Author)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Also in this network, we are going to use batch-normalization layers, which
    help with the internal covariance shift problem. In a nutshell, what they do is
    normalize each batch before a layer so that there is no change in the distribution
    of the data during training.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个网络中，我们还将使用批量归一化层，它们有助于解决内部协方差偏移问题。简而言之，它们的作用是在每一层之前对每个批次进行归一化，以便在训练过程中数据的分布没有变化。
- en: Generator Architecture
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成器架构
- en: The generator will then be formed by a sequence of transposed convolutional
    layers, they will bring the initial random vector z to have the correct size of
    the image we want to produce in this case 28x28\. The depth of the feature maps
    on the other hand will go to be smaller and smaller, unlike the convolutional
    layers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器将由一系列转置卷积层构成，这些层将初始的随机向量z转换为我们想要生成的图像的正确尺寸，这里是28x28。另一方面，特征图的深度将变得越来越小，不像卷积层那样。
- en: '![](../Images/fbb92b40136d3758154fc8afaa7c6474.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbb92b40136d3758154fc8afaa7c6474.png)'
- en: Generator Architecture (Image By Author)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器架构（作者提供的图像）
- en: Discriminator Architecture
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器架构
- en: The discriminator, on the other hand, is a classical CNN network that has to
    classify images. So we will have a sequence of convolution layers until we reach
    a single number, the probability that the input is real or fake.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，判别器是一个经典的CNN网络，负责对图像进行分类。因此，我们将有一系列卷积层，直到我们得到一个单一的数字，即输入是实际的还是假的概率。
- en: '![](../Images/606ce895f0fbd8d31fbe815fa531d85c.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/606ce895f0fbd8d31fbe815fa531d85c.png)'
- en: Discriminator Architecture (Image By Author)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器架构（作者提供的图像）
- en: Let’s code!
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们开始编码吧！
- en: I am going to work on [Deepnote](https://deepnote.com/), but you can work on
    Google Colab if you prefer.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用[Deepnote](https://deepnote.com/)，但如果你愿意，你可以使用Google Colab。
- en: First, check if you have a GPU available on your hardware.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，检查你的硬件是否有可用的GPU。
- en: If you are working on Google Colab you would need to mount your drive. Let’s
    import also the necessary libraries.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在使用Google Colab，你需要挂载你的驱动器。让我们也导入必要的库。
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now we define the function to create the generator G network as we described
    earlier.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们定义创建生成器G网络的函数，如我们之前所描述的。
- en: To define the discriminator D instead, we use a Python class since we need the
    output of the forward method.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义判别器D，我们使用Python类，因为我们需要forward方法的输出。
- en: Now we can finally instantiate our G and D networks. Let’s also print the model
    to see the summary of the layers.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们终于可以实例化我们的G和D网络了。让我们还打印模型以查看层的摘要。
- en: As usual, we need to define the cost function and optimizers if we want to do
    network training.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，如果我们想进行网络训练，我们需要定义成本函数和优化器。
- en: The input vector z is a random vector, taken from some distribution that can
    be either uniform or normal in our case.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 输入向量z是一个随机向量，取自某种分布，在我们的情况下可以是均匀分布或正态分布。
- en: Now let’s define the train function of the discriminator D. As we also did in
    the previous article, **D must be trained on both real and fake images**. The
    real images are taken directly from the MNIST dataset while for the fake ones
    we create an input z on the fly, pass it to the generator G and take the output
    of G. The labels we can create ourselves knowing that they will be all ones for
    the real images and zeros for the fake ones. The **final loss will be the loss
    sum of the real images plus the fake ones**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们定义判别器D的训练函数。正如我们在前一篇文章中所做的那样，**D必须在真实图像和假图像上进行训练**。真实图像直接取自MNIST数据集，而对于假图像，我们会动态生成一个输入z，将其传递给生成器G，并获取G的输出。我们可以自己创建标签，知道真实图像的标签全为一，而假图像的标签全为零。**最终损失将是真实图像损失和假图像损失的总和**。
- en: The generator takes as input the output of the discriminator since it has to
    see if D has figured out whether it is a fake or real image. And based on that
    it calculates its loss.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器以判别器的输出作为输入，因为它必须查看D是否识别出图像是假的还是实际的。并根据此计算其损失。
- en: We are ready to import the dataset that will allow us to do network training.
    With PyTorch importing the MNIST dataset is very easy since it has methods already
    implemented to do this.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好导入数据集，这将使我们能够进行网络训练。使用PyTorch导入MNIST数据集非常容易，因为它已经实现了相关方法。
- en: Now that we have the dataset we can instantiate the dataloader.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了数据集，我们可以实例化数据加载器。
- en: Since at the end of the training, we would like to have an idea of how image
    generation is improved from time to time, we create a function that allows us
    to generate and save these images at each epoch.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在训练结束时，我们希望了解图像生成如何随着时间的推移而改进，我们创建了一个函数，允许我们在每个周期生成和保存这些图像。
- en: Finally, we are ready to start the training. Choose the number of epochs, for
    good results it should be around 100\. I only launched 10 and so I will have an
    *“uglier”* output.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们准备开始训练。选择周期数，为了获得良好的结果，应该设定在大约 100 个周期。我只进行了 10 个周期，所以我将得到一个*“更丑”*的输出。
- en: The training with 100 epochs should take about an hour, then of course it depends
    a lot on the hardware you have available.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 训练需要 100 个周期，大约需要一个小时，当然，这很大程度上取决于你所拥有的硬件。
- en: Let’s plot the results to see if the network has learned how to generate these
    synthetic images.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制结果，看看网络是否学会了如何生成这些合成图像。
- en: '![](../Images/7a8316c1412116c55fe95136c30337cc.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a8316c1412116c55fe95136c30337cc.png)'
- en: Synthetic Images (Image By Author)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 合成图像（作者提供的图像）
- en: Final Thoughts
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: In this paper we have gone beyond the simple GAN network by also including convolution
    operations that are very effective when working with images, thus creating what
    is called DCGAN. To create these synthetic images we built two networks a generator
    G and discriminator D that play an adversarial game. If this article was helpful
    to you follow me for my upcoming articles on generative networks! [😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们不仅使用了简单的 GAN 网络，还包括了在处理图像时非常有效的卷积操作，从而创建了所谓的 DCGAN。为了生成这些合成图像，我们构建了两个网络，一个生成器
    G 和一个判别器 D，它们进行对抗游戏。如果这篇文章对你有帮助，关注我以获取我即将发布的关于生成网络的文章！ [😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
- en: The End
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结尾
- en: '*Marcello Politi*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*马切洛·波利提*'
- en: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [Website](https://marcello-politi.super.site/)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[领英](https://www.linkedin.com/in/marcello-politi/)，[推特](https://twitter.com/_March08_)，[网站](https://marcello-politi.super.site/)'
