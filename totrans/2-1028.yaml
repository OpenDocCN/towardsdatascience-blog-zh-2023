- en: 'Hands-on Generative AI with GANs using Python: DCGAN'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-dcgan-6077f0067ac3](https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-dcgan-6077f0067ac3)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/a663051d751ad0481e8cc825db37cbd7.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vinicius "amnx" Amano](https://unsplash.com/@viniciusamano?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Improving synthetic image generation with convolutional layers in PyTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----6077f0067ac3--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----6077f0067ac3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6077f0067ac3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6077f0067ac3--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----6077f0067ac3--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6077f0067ac3--------------------------------)
    ¬∑5 min read¬∑Apr 4, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In my [previous article](https://medium.com/towards-data-science/hands-on-generative-ai-with-gans-using-python-image-generation-9a62e591c7c6),
    we have seen how to **use GANs to generate images** of the type of MNIST dataset.
    We achieved good results and succeeded in our intent. However, the two networks
    G (generator) and D (discriminator) were composed mostly of dense layers. At this
    point, you will know that usually when working with images we use CNNs (convolutional
    neural networks) since they use convolutional layers. So let us see how to **improve
    our GANs by using** these types of layers. GANs that use **convolutional layers
    are called DCGANs**.
  prefs: []
  type: TYPE_NORMAL
- en: What is transposed deconvolution?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Typically when we work with CNNs we are used to working with convolutional layers.
    In this case, though we also need the ‚Äúinverse‚Äù operation the transposed deconvolution,
    sometimes also called deconvolution.
  prefs: []
  type: TYPE_NORMAL
- en: '**This operation allows us to upsample the feature space**. For example, if
    we have an image represented by a 5x5 grid we can ‚Äúenlarge‚Äù this grid to make
    it 28x28.'
  prefs: []
  type: TYPE_NORMAL
- en: What you do in principle is quite simple, you **put zeros inside the elements
    of the initial feature map to enlarge it and then apply a normal convolution operation
    by using a certain kernel size, stride and padding**.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we want to transform a 5x5 feature space to 8x8\. First,
    by inserting zeros we create a 9x9 feature space then by applying a 2x2 filter
    we shrink it again to 8x8\. Let‚Äôs look at a graphical example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/535139b951ccdb3db31ae8af4dd2b93f.png)'
  prefs: []
  type: TYPE_IMG
- en: Transposed Convolution (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: Also in this network, we are going to use batch-normalization layers, which
    help with the internal covariance shift problem. In a nutshell, what they do is
    normalize each batch before a layer so that there is no change in the distribution
    of the data during training.
  prefs: []
  type: TYPE_NORMAL
- en: Generator Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The generator will then be formed by a sequence of transposed convolutional
    layers, they will bring the initial random vector z to have the correct size of
    the image we want to produce in this case 28x28\. The depth of the feature maps
    on the other hand will go to be smaller and smaller, unlike the convolutional
    layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fbb92b40136d3758154fc8afaa7c6474.png)'
  prefs: []
  type: TYPE_IMG
- en: Generator Architecture (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: Discriminator Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The discriminator, on the other hand, is a classical CNN network that has to
    classify images. So we will have a sequence of convolution layers until we reach
    a single number, the probability that the input is real or fake.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/606ce895f0fbd8d31fbe815fa531d85c.png)'
  prefs: []
  type: TYPE_IMG
- en: Discriminator Architecture (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs code!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I am going to work on [Deepnote](https://deepnote.com/), but you can work on
    Google Colab if you prefer.
  prefs: []
  type: TYPE_NORMAL
- en: First, check if you have a GPU available on your hardware.
  prefs: []
  type: TYPE_NORMAL
- en: If you are working on Google Colab you would need to mount your drive. Let‚Äôs
    import also the necessary libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now we define the function to create the generator G network as we described
    earlier.
  prefs: []
  type: TYPE_NORMAL
- en: To define the discriminator D instead, we use a Python class since we need the
    output of the forward method.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can finally instantiate our G and D networks. Let‚Äôs also print the model
    to see the summary of the layers.
  prefs: []
  type: TYPE_NORMAL
- en: As usual, we need to define the cost function and optimizers if we want to do
    network training.
  prefs: []
  type: TYPE_NORMAL
- en: The input vector z is a random vector, taken from some distribution that can
    be either uniform or normal in our case.
  prefs: []
  type: TYPE_NORMAL
- en: Now let‚Äôs define the train function of the discriminator D. As we also did in
    the previous article, **D must be trained on both real and fake images**. The
    real images are taken directly from the MNIST dataset while for the fake ones
    we create an input z on the fly, pass it to the generator G and take the output
    of G. The labels we can create ourselves knowing that they will be all ones for
    the real images and zeros for the fake ones. The **final loss will be the loss
    sum of the real images plus the fake ones**.
  prefs: []
  type: TYPE_NORMAL
- en: The generator takes as input the output of the discriminator since it has to
    see if D has figured out whether it is a fake or real image. And based on that
    it calculates its loss.
  prefs: []
  type: TYPE_NORMAL
- en: We are ready to import the dataset that will allow us to do network training.
    With PyTorch importing the MNIST dataset is very easy since it has methods already
    implemented to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the dataset we can instantiate the dataloader.
  prefs: []
  type: TYPE_NORMAL
- en: Since at the end of the training, we would like to have an idea of how image
    generation is improved from time to time, we create a function that allows us
    to generate and save these images at each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we are ready to start the training. Choose the number of epochs, for
    good results it should be around 100\. I only launched 10 and so I will have an
    *‚Äúuglier‚Äù* output.
  prefs: []
  type: TYPE_NORMAL
- en: The training with 100 epochs should take about an hour, then of course it depends
    a lot on the hardware you have available.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs plot the results to see if the network has learned how to generate these
    synthetic images.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a8316c1412116c55fe95136c30337cc.png)'
  prefs: []
  type: TYPE_IMG
- en: Synthetic Images (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this paper we have gone beyond the simple GAN network by also including convolution
    operations that are very effective when working with images, thus creating what
    is called DCGAN. To create these synthetic images we built two networks a generator
    G and discriminator D that play an adversarial game. If this article was helpful
    to you follow me for my upcoming articles on generative networks! [üòâ](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
  prefs: []
  type: TYPE_NORMAL
- en: The End
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Marcello Politi*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [Website](https://marcello-politi.super.site/)'
  prefs: []
  type: TYPE_NORMAL
