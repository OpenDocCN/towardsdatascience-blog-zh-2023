- en: World History Through the Lens of AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/world-history-through-the-lens-of-ai-340df6241fbf](https://towardsdatascience.com/world-history-through-the-lens-of-ai-340df6241fbf)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What historical knowledge do language models encode?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@artfish?source=post_page-----340df6241fbf--------------------------------)[![Yennie
    Jun](../Images/b635e965f21c3d55833269e12e861322.png)](https://medium.com/@artfish?source=post_page-----340df6241fbf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----340df6241fbf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----340df6241fbf--------------------------------)
    [Yennie Jun](https://medium.com/@artfish?source=post_page-----340df6241fbf--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----340df6241fbf--------------------------------)
    ·11 min read·Jul 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d14490fb1ce7bc05910c5287b7e27954.png)'
  prefs: []
  type: TYPE_IMG
- en: Probing OpenAI’s GPT-4, Anthropic’s Claude, and TII’s Falcon 40B Instruct on
    top historical events from 1910 (prompted in 6 different languages). Created by
    the author.
  prefs: []
  type: TYPE_NORMAL
- en: '*This article was* [*originally published on my blog*](https://www.artfish.ai/p/world-history-through-ai)'
  prefs: []
  type: TYPE_NORMAL
- en: Advancements in artificial intelligence, particularly large language models,
    open up exciting possibilities for [historical research](https://ts2.space/en/chatgpt-4-a-valuable-tool-for-historical-research-and-analysis/#:~:text=ChatGPT%2D4%20works%20by%20taking,information%20available%20in%20its%20database.)
    and [education](https://www.history4humans.com/blogs/history/7-ways-history-teachers-can-use-chat-gpt-in-the-classroom).
    However, it is important to scrutinize the ways these models interpret and recall
    the past. Do they reflect any inherent biases in their understanding of history?
  prefs: []
  type: TYPE_NORMAL
- en: I am well aware of the subjectivity of history (I majored in history in my undergrad!).
    The events we remember and the narratives we form about the past are heavily influenced
    by the historians who penned them and the society we inhabit. Take, for instance,
    my high school world history course, which devoted over 75% of the curriculum
    to European history, skewing my understanding of world events.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, I explore how human history gets remembered and interpreted
    through the lens of AI. I examine the interpretations of key historical events
    by several large language models to uncover:'
  prefs: []
  type: TYPE_NORMAL
- en: Do these models display a Western or American bias towards events?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do the models’ historical interpretations differ based on the language used
    for prompts, such as Korean or French prompts emphasizing more Korean or French
    events, respectively?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these questions in mind, let’s dive in!
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: 1910'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an example, I asked three different large language models (LLMs) what the
    major historical events in the year 1910 were. (More details on each LLM in the
    next section.)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ca42277b8edf1b656d5bfed3b5482c56.png)'
  prefs: []
  type: TYPE_IMG
- en: OpenAI’s GPT-4, Anthropic’s Claude, and Technology Innovation Institute’s Falcon
    40B Instruct respond to a prompt in English about top historical events in 1910\.
    Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The question I posed was deliberately loaded with no objective answer. The significance
    of the year 1910 varies greatly depending on one’s cultural perspective. In Korean
    history, it marks the start of the Japanese occupation, a turning point that significantly
    influenced the country’s trajectory (see [Japan-Korea Treaty of 1910](https://en.wikipedia.org/wiki/Japan%E2%80%93Korea_Treaty_of_1910)).
  prefs: []
  type: TYPE_NORMAL
- en: Yet, the Japanese annexation of Korea did not feature in any of the responses.
    I wondered if the same models would interpret the question differently if prompted
    in a different language — say, in Korean.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b4c8297c482e090423cf84e68eaefea.png)'
  prefs: []
  type: TYPE_IMG
- en: OpenAI’s GPT-4, Anthropic’s Claude, and Technology Innovation Institute’s Falcon
    40B Instruct respond to a prompt in Korean about top historical events in 1910\.
    Korean responses have been translated by me into English (in red). Created by
    the author.
  prefs: []
  type: TYPE_NORMAL
- en: Prompted in Korean, one of the top events noted by Claude is indeed the Japanese
    Annexation of Korea. However, I found it interesting that two out of five of GPT-4’s
    important events were US-centric (Boy Scouts and Mann-Elkins Act) while neglecting
    to mention the Annexation of Korea. Not to mention that Falcon, even when prompted
    in Korean, responded in English.
  prefs: []
  type: TYPE_NORMAL
- en: The experiments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The experiment setup was as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '3 models: [OpenAI’s GPT-4](https://openai.com/gpt-4), [Anthropic’s Claude](https://www.anthropic.com/index/introducing-claude),
    and TII’s [Falcon-40B-Instruct](https://huggingface.co/tiiuae/falcon-40b-instruct#:~:text=Falcon%2D40B%2DInstruct%20is%20a,under%20the%20Apache%202.0%20license.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '6 languages: English, French, Spanish, Korean, Japanese, Chinese'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3 years (610, 1848, 1910)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5 historical events per run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10 runs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: = 2700 total events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Languages and Prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The languages I chose were mostly arbitrary, based on the languages that I
    was the most familiar with (English, Korean) and those that a few of my closest
    friends spoke and could translate for me (Chinese, Japanese, French, Spanish).
    Translations can be found at the end of the article. I asked them to translate
    the English for me:'
  prefs: []
  type: TYPE_NORMAL
- en: '`“Top five historical events in the year {}, ranked by importance. Be brief
    and only give the name of the event.”`'
  prefs: []
  type: TYPE_NORMAL
- en: Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[OpenAI’s GPT-4](https://openai.com/gpt-4) is the newer generation of ChatGPT,
    which is one of the most popular AI chatbot (with [over 100 million monthly active
    users](https://explodingtopics.com/blog/chatgpt-users))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Anthropic’s Claude](https://www.anthropic.com/index/introducing-claude) is
    a ChatGPT competitor trained to be harmless and helpful using a method called
    [Constitutional AI](https://www.anthropic.com/index/claudes-constitution)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Technical Innovation Institute](https://www.tii.ae/)’s [Falcon-40B-Instruct](https://huggingface.co/tiiuae/falcon-40b-instruct#:~:text=Falcon%2D40B%2DInstruct%20is%20a,under%20the%20Apache%202.0%20license.)
    is the best open-source language model, according to [HuggingFace’s Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalizing the events
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even if a model generated the same event with each run, there was a lot of diversity
    in the way it described the same event.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following all refer to the same event:'
  prefs: []
  type: TYPE_NORMAL
- en: “Japan annexation of Korea”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Japan’s Annexation of Korea”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Japan annexes Korea”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Japan-Korea Annexation Treaty”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I needed a way to refer to a single event (the Japanese annexation of Korea)
    using the same vocabulary (a process known as ***normalization***). Not to mention
    that the same event could be described in six different languages!
  prefs: []
  type: TYPE_NORMAL
- en: I used a combination of manual rules, Google Translate, and GPT-4 to assist
    with the normalization. Initially I had hoped to use one LLM to normalize the
    events of another LLM (e.g. use GPT-4 to normalize Claude’s events; Claude to
    normalize Falcon’s events, etc) to reduce bias. However, Claude and Falcon were
    not very good at following directions to normalize and GPT-4 emerged as the best
    model for the job.
  prefs: []
  type: TYPE_NORMAL
- en: I acknowledge the biases that come with using a model to normalize its own events.
    However, as I used different sessions of GPT-4 to generate historical events and
    to normalize the events, there was no overlap in context. In the future, normalization
    can be done using a more objective method.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overall, I was surprised by the different models’ understanding of history.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4 was more likely to generate the same events regardless of the language
    it was prompted with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anthropic was more likely to generate historical events relevant to the language
    it was prompted with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Falcon (unfortunately) was more likely to make up fake events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All three models displayed a bias for Western or American events, but not in
    the way I expected. When prompted in a non-English language, the model would generate
    an American or British historical event (even when the model would not generate
    that event when prompted in English). This happened across all three models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1\. Comparing languages for each model (1910)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each model x language combination generated “top 5 historical events” 10 times
    (= 50 events total). I took the subset of events which at least one language generated
    5 times or more. This was because models sometimes predicted a one-off event that
    it never predicted again. The cells with values 10 mean that the model predicted
    that event every single time I prompted it.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, I show the top events predicted by each of the 3 models, broken
    down by languages, for the year 1910\. Similar charts for the years 610 and 1848
    can be found on the [GitHub page](https://github.com/yenniejun/world-history-ai),
    where I shared all of the code and analyses.
  prefs: []
  type: TYPE_NORMAL
- en: '**GPT-4 (OpenAI)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mexican Revolution: across all languages, the Mexican Revolution was consistently
    an important world event — even in languages I didn’t expect, such as Korean or
    Japanese'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Japanese Annexation of Korea: Not mentioned when asked in Spanish or French.
    When prompted in Japanese, was more likely to mention this event (9 times) than
    when prompted in Korean (6 times), which I found strange and interesting'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Boy Scouts of America founded: GPT-4 predicted this event when prompted in
    Japanese (7 times) nearly twice as often as when prompted in English (4 times).
    It seems like a random tidbits of American information was encoded into the Japanese
    understanding of 1910'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Establishment of Glacier National Park: Even stranger, GPT-4 predicted this
    event when prompted in Spanish and French, but not in English'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/26492702d682d965de75c7656ac8b1d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Top events generated by GPT-4 for the year 1910, compared across language it
    was prompted in. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Claude (Anthropic)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall: Unlike GPT-4, there was no single event that was deemed “important
    historical event” by *all languages.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mexican Revolution: While generated often when asked in French, Spanish, and
    (inexplicably) Korean, not as important in English as was with GPT-4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Japanese Annexation of Korea: More important for Korean and Japanese than for
    other languages (the two countries involved in the event)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Death of Edward VII: More important for English and French (and not for other
    languages). Edward VII was the King of the United Kingdom and apparently had good
    relations with France.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exploration of Antarctica: This event was actually the [*British* Antarctic
    expedition](https://en.wikipedia.org/wiki/Terra_Nova_Expedition), in which a British
    man reached Antarctica for the first time. However, for some unknown reason, Claude
    generates this event only when prompted in Chinese or Japanese (but not in English).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/7cd7adb0af014824f174598f637ef8ca.png)'
  prefs: []
  type: TYPE_IMG
- en: Top events generated by Claude for the year 1910, compared across language it
    was prompted in. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Falcon 40B Instruct (Open Source; TII)**'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, Falcon was not as consistent or accurate as the other two models. The
    reason fewer events are shown in the chart is because there were no other events
    that Falcon predicted 5 times or more! Meaning that Falcon was a bit inconsistent
    in its predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Titanic sinks: This actually happened in 1912'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Outbreak of World War I: This actually happened in 1914'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Falcon is historically inaccurate in its predictions. But at least it got the
    decade right?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/e2629980c71a61b226602c9a5cfee059.png)'
  prefs: []
  type: TYPE_IMG
- en: Top events generated by Falcon for the year 1910, compared across language it
    was prompted in. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Comparing model correlations for each language (1910)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, I quantified how similar the *overall* predictions of one model compared
    to the others. I used a mathematical method ([cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity))
    to determine how similar two prediction distributions were. Values closer to 1
    signified that predictions were identical; values closer to 0 signified that two
    sets of predictions shared nothing in common.
  prefs: []
  type: TYPE_NORMAL
- en: Again, I show this example for the year 1910\. The other years can be found
    on the [GitHub page](https://github.com/yenniejun/world-history-ai).
  prefs: []
  type: TYPE_NORMAL
- en: Across most of the languages, GPT-4 and Claude had a higher correlation value
    — meaning that despite all of the languages, the two models predicted a high percentage
    of similar events.
  prefs: []
  type: TYPE_NORMAL
- en: Falcon, on the other hand, tended to be less correlated, meaning that its understanding
    of history veered away from that of GPT-4 and Claude.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e4eeeb160aa502e7c0af8a60d745f3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Model correlations for events predicted for the year 1910\. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Comparing models for each year
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, I compared the different language models for each year. I combined all
    events predicted for all languages and considered the overall events predicted
    by a model, regardless of the language. I took the subset of events for which
    at least one model generated **10 times or more**.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the trends found in the section above, GPT-4 and Claude tended to
    predict similar major historical events for each year — The First Revelations
    of Muhammad and the Ascension of Emperor Heraclius to the Byzantine Throne in
    610; the European Revolutions of 1848; and the Mexican Revolution in 1910.
  prefs: []
  type: TYPE_NORMAL
- en: There were certain events that one model disproportionately predicted compared
    to the others. For example, for the year 1848, GPT-4 predicted “Publication of
    the Communist Manifesto” 42 times, compared to Claude’s 15 times. For the year
    1910, Claude predicted “Death of Edward VII” 26 times, compared to GPT-4’s 1 time.
  prefs: []
  type: TYPE_NORMAL
- en: Falcon tended to have the least understanding of historical events. Falcon missed
    major events for all three years. For the year 610, Falcon failed to predict the
    event of the Ascension of Emperor Heraclius. For the year 1910, it failed to predict
    events such as Japan’s Annexation of Korea, Formation of Union of South Africa,
    and Portuguese Revolution (all non-American global events), while instead predicting
    America-centric events such as the [Triangle Shirtwaist Factory Fire](https://en.wikipedia.org/wiki/Triangle_Shirtwaist_Factory_fire)
    (which happened in 1911, not 1910). Interestingly, Falcon was able to predict
    most of the 1848 events similar to the other two models — perhaps because the
    1848 events were more Western-centric (e.g. European revolutions)?
  prefs: []
  type: TYPE_NORMAL
- en: Events from longer ago (e.g. year 610) meant that history is a bit more fuzzy.
    The [Tang Dynasty was established in 618, not 610](https://en.wikipedia.org/wiki/Tang_dynasty)
    and the [Construction of the Grand Canal under Emperor Yang of Sui](https://en.wikipedia.org/wiki/Grand_Canal_(China)#:~:text=The%20Grand%20Canal%20was%20fully%20completed%20under%20the%20second%20Sui%20emperor%2C%20from%20the%20years%20604%20to%20609%2C%5B14%5D%20first%20by%20linking%20Luoyang%20to%20the%20Yangzhou%20(and%20the%20Yangtze%20valley)%2C)
    was actually completed under a longer period of time (604 to 609).
  prefs: []
  type: TYPE_NORMAL
- en: '**610**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/26e0e21d0d4f52af2ce1408fdac782b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of top events generated by each of the models for the year 610, combined
    for all languages. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '**1848**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b3164ce280f81262f74494130fae7cd0.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of top events generated by each of the models for the year 1848,
    combined for all languages. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '**1910**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/14fbcb84e3d551e09c22d190ba74fede.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of top events generated by each of the models for the year 1910,
    combined for all languages. Created by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So why does this all matter?
  prefs: []
  type: TYPE_NORMAL
- en: As educational companies increasingly incorporate Large Language Models (LLMs)
    into their products — Duolingo leveraging GPT-4 for language learning, [Khan Academy
    introducing AI teaching assistant ‘Khanmigo’](https://support.khanacademy.org/hc/en-us/articles/14394953976333--Update-Introducing-Khanmigo-Khan-Academy-s-AI-Tool),
    and [Harvard University planning to integrate AI into their computer science curriculum](https://www.thecrimson.com/article/2023/6/21/cs50-artificial-intelligence/)
    — understanding the underlying biases of these models becomes crucial. If a student
    uses an LLM to learn history, what biases might they inadvertently absorb?
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I showed that some popular language models, such as GPT-4,
    consistently predict “important events” regardless of the prompt language. Other
    models, like Claude, showed more language-specific predictions. Closed-source
    models generally exhibited greater consistency and accuracy than the leading open-source
    alternative. Across all of the models tested in this article, there was a tendency
    to predict Western or American events (even arcane events) at the expense of other
    global events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Future work could include:'
  prefs: []
  type: TYPE_NORMAL
- en: Expanding the analysis to encompass more languages and years
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing a deeper analysis into the *historical accuracy* of model outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing a deeper analysis into the *ranking* of top historical events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a more objective method for event normalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The aim of this article was not to discredit LLMs or suggest their removal from
    educational settings. Rather, I would like to urge a critical and cautious approach,
    one that recognizes and mitigates their biases. LLMs, when used responsibly, can
    be valuable resources for both students and teachers across disciplines. However,
    we must also comprehend the biases they may carry, such as Western-centrism, and
    tailor their use accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing your history professor or textbooks with an LLM risks yielding a distorted,
    one-sided interpretation of history. Ultimately, we must utilize these tools thoughtfully,
    cognizant of their inherent biases, ensuring they augment rather than dictate
    our understanding of the world.
  prefs: []
  type: TYPE_NORMAL
- en: '*Thank you for reading!*'
  prefs: []
  type: TYPE_NORMAL
- en: '*This article was o*[*riginally published on my blog*](https://blog.yenniejun.com/p/world-history-through-ai)*:
    feel free to follow to stay up to date with other writing!*'
  prefs: []
  type: TYPE_NORMAL
- en: Bloopers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I tried out a few different open source models. Below are a few bloopers (all
    in Korean) of the strange outputs I found the models generating!
  prefs: []
  type: TYPE_NORMAL
- en: Falcon 40B Instruct
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/34e3ecb6d56ba6461c47c4dce3f4174c.png)![](../Images/d4d4c0db55789a6dfbe98a4977731f0e.png)'
  prefs: []
  type: TYPE_IMG
- en: Pythia 12B
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The model seems to have gotten stuck in a loop consisting of Kangaroo, Air Mail,
    and variations of торговать (which means trade in Russian).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d20809c74c58effffd72f27e68317db1.png)'
  prefs: []
  type: TYPE_IMG
- en: Translations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
