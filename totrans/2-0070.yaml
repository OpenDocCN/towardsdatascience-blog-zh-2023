- en: '3D Geospatial Data Integration with Python: The Ultimate Guide'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/3d-spatial-data-integration-with-python-7ef8ef14589a](https://towardsdatascience.com/3d-spatial-data-integration-with-python-7ef8ef14589a)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 3D Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Tutorial to integrate geospatial data with a multi-modal Python workflow: combine
    3D point clouds, CityGML, voxels, vector + raster data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)
    ¬∑39 min read¬∑Nov 7, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: The pace of technological progress is just plain crazy nowadays. Even more so
    when looking at how vital 3D data is for geospatial analysis and digital twins.
    Being able to capture and analyze data in three dimensions means we can create
    precise representations of real-world objects and environments.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b80083f9ff4c868cd2c309dbcd41590e.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Spatial Data Integration goes through understanding the scope of 3D Data
    Capture. ¬© F. Poux
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶Ñ**Mila**: *A picture is worth a thousand words. So what about Digital Twins?*'
  prefs: []
  type: TYPE_NORMAL
- en: This is especially important for fields like urban planning, infrastructure
    management, and disaster response.
  prefs: []
  type: TYPE_NORMAL
- en: By incorporating 3D data, we can enhance our ability to make informed decisions
    by relying on precise and reliable data representations. Furthermore, the integration
    of this data into digital twins can produce remarkably lifelike replicas of real-world
    assets and systems, thereby increasing the efficiency of simulation and analysis.
  prefs: []
  type: TYPE_NORMAL
- en: BUT (there is always a but), effective geospatial analysis and digital twin
    creation rely on efficiently integrating and visualizing different data formats.
    To achieve this, it‚Äôs essential to have a comprehensive understanding of the various
    data modalities and how they can be seamlessly integrated and visualized together.
    In data terms, we want to create a unified and comprehensive representation of
    an area with data overlap.How lucky are we, because this is precisely what we
    will unlock today!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/40b5bf0cc5f52b18fbd5938292f0d6fc.png)'
  prefs: []
  type: TYPE_IMG
- en: To constitute a Spatial Digital World, we must study 3D Data Integration. Many
    sources of information, such as vector, raster data, 3D point clouds, or 3D city
    models, can be combined to form a unified view of what happens on our planet.
    ¬© F. Poux
  prefs: []
  type: TYPE_NORMAL
- en: In this hands-on guide, I provide a reference system-oriented workflow for 3D
    data integration with Python. So no need for expensive software or a large serialized
    pipeline of bricks without mortar! Just our Python friend and a carefully selected
    tiny range of robust modules and functions.
  prefs: []
  type: TYPE_NORMAL
- en: The ultimate goal of this initiative is that you have a comprehensive guide
    and companion that will follow you along your 3D data journey! The workflow is
    structured in seven distinctive phases, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57473a23703dd40f51db1e9702411dd7.png)'
  prefs: []
  type: TYPE_IMG
- en: The 3D Data Integration Workflow with Python. It is a Seven-Step Process to
    produce unified data-centric views. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: Each phase builds progressively to ensure that you can start from scratch or
    plug into your existing system modularly. Because it is exhaustively constructed,
    a table of contents will make it easier for you to go through!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Whenever you are ready, let us jump together on this marvelous quest to 3D Data
    Integration, with a coffee lying around, but not too close to your computer ‚òï
    (speaking from devastating experience)
  prefs: []
  type: TYPE_NORMAL
- en: 'üéµ**Note to Readers***: This hands-on guide is part of a* [***UTWENTE***](https://www.itc.nl/)
    *joint work with co-authors* ü¶ä ***F. Poux****, ü¶Ñ* ***M. Koeva*,** *and* ***ü¶ù P.
    Nourian****. We acknowledge the financial contribution from the digital twins*
    [*@ITC*](http://twitter.com/ITC) *-project granted by the ITC faculty of the University
    of Twente. All images are ¬© F. Poux*'
  prefs: []
  type: TYPE_NORMAL
- en: Step 1\. Implementation Setup for 3D Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/225f8a8e13a80a4cb8675b370f93496a.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 1\. Implementation Setup for 3D Data. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: The first mission is quickly setting up a lightweight environment for developing
    our 3D Data Integration workflow. This is a simple phase, but ensuring a proper
    setup is the key to scalability and replication. So let us get on top of things!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/28627dd762be52c40d8c1adedc8e3c24.png)'
  prefs: []
  type: TYPE_IMG
- en: The Environment Setup comprises base libraries, 3D Data libraries, Geospatial
    libraries, and an IDE. All of this is on top of virtual environment management
    and Python. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: A Lightweight Environment Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python environment setup using Anaconda, robust libraries, and an Integrated
    Development Environment (IDE) does not have to be painful. Anaconda provides a
    convenient way to manage Python packages and environments, and you can then use
    a powerful IDE such as Jupyter Lab or Spyder to make coding a breeze. For a detailed
    view of the process of setting up a 3D Python development environment, I recommend
    that you check out the following article:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  prefs: []
  type: TYPE_NORMAL
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Python‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *If you do not want to jump on another session, do not worry,
    I will not leave you high and dry! As part of this ultimate guide, here is a superb
    lightweight setup to get started, under 5 minutes, clocked ‚åö.*'
  prefs: []
  type: TYPE_NORMAL
- en: To start things off, you can go to the [Anaconda website](https://docs.conda.io/en/latest/miniconda.html)
    and download a Miniconda installer (a free minimal installer for conda) appropriate
    for your operating system (Windows, macOS, or Linux), with a Python 10 version.
    From there, you can follow the installation instructions on the Anaconda website
    to install Miniconda on your machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'And that is it! You now have secured the most uncomplicated Python installation
    with the lightweight miniconda that will make it super easy to isolate a controlled
    virtual environment. Before moving on to the following steps, we launch miniconda
    with its command line access:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df2bb60a544049eca1139b2b848577df.png)'
  prefs: []
  type: TYPE_IMG
- en: In Windows, just searching ‚Äúminiconda‚Äù should yield this
  prefs: []
  type: TYPE_NORMAL
- en: Once in the Anaconda Prompt, we follow a simple four steps process to be up
    and running, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1cdedcd8fdd91ee19cf54b3a8cb8ca12.png)'
  prefs: []
  type: TYPE_IMG
- en: Workflow for environment creation. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a new environment, we write the line: `conda create -n GEOTUTO python=3.10`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To switch to the newly created environment, we write: `conda activate GEOTUTO`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To check the Python version, `python --version`, and the installed packages:
    `conda list`. This should yield Python 3.10 and the list of base libraries respectively'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To install pip in the new environment, we write: `conda install pip`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'And that is it! We are now ready to move on installing the necessary libraries
    for 3D Data Integration with the pip manager: `pip install package-name`, where
    you change the package name by each of these (one at a time: `numpy`, `matplotlib`,
    `laspy[lazrs,laszip]`, `open3d`, `rasterio`, `geopandas`.'
  prefs: []
  type: TYPE_NORMAL
- en: Python base libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/7a858df1f83c0e59bb7c37a4f919af96.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Python Base libraries: Numpy and Matplotlib.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first package installation is done via the prompt: `pip install numpy`.No
    need to present **NumPy**, Python''s fundamental numerical and scientific computing
    library. It supports large multi-dimensional matrices and provides a collection
    of mathematical functions to work with ease. NumPy is the foundation of many other
    scientific libraries in Python and is heavily used in data analysis, machine learning,
    and scientific research.'
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ù **Nourian**: *NumPy is all about Linear Algebra. If you need to get comfortable
    with re-learning Linear Algebra, you can start from here:* [*Rudiment of Linear
    Algebra for Computer Graphics*](https://www.researchgate.net/publication/335571959_Rudiments_of_Linear_Algebra_Computer_Graphics)
    *(ResearchGate)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Matplotlib** is a popular plotting library for Python that enables 2D plotting
    and basic 3D plotting capabilities. To install it: `pip install matplotlib`. It
    provides a wide range of customizable visualization options, allowing users to
    create various types of plots, such as line plots, scatter plots, bar plots, histograms,
    3D plots, and more. Matplotlib is widely used in scientific research and data
    science workflows.'
  prefs: []
  type: TYPE_NORMAL
- en: 3D Python Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/c517d8cc0d41fcdeee5abbb2dd1f57f0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Python 3D Libraries: Open3D and Laspy.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Open3D** is a modern 3D data processing and visualization library, mainly
    focusing on 3D point clouds and meshes. It provides functionalities to handle
    3D data, such as point cloud registration, geometry processing, mesh creation,
    and visualization. Open3D is particularly useful for tasks related to 3D computer
    vision, robotics, and augmented reality applications. And for installing Open3D:
    `pip install open3d`.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we have to install **Laspy**:`pip install laspy[lazrs,laszip]`. This Python
    library is used for reading, writing, and modifying LiDAR data stored in the LAS
    (LiDAR data Exchange Format) and LAZ (compressed LAS) file formats. It provides
    tools to work with point cloud data obtained from LiDAR scanners and is widely
    (small world) used in geospatial applications for terrain modeling, forestry,
    urban planning, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Geospatial Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Geopandas** is a library built on top of pandas and shapely designed to handle
    geospatial data efficiently. To install it: `pip install geopandas`. It extends
    the capabilities of pandas to include geospatial data types and operations, allowing
    users to work with vector data (points, lines, polygons) and efficiently perform
    geospatial analysis. Geopandas is widely used in GIS, cartography, and spatial
    data analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rasterio** is the last library that we will install with: `pip install rasterio`.
    It is used for reading and writing geospatial raster data. It supports various
    standard raster formats like GeoTIFF or JPEG and provides functionalities for
    geospatial metadata, spatial referencing, and coordinate transformations. rasterio
    is valuable for satellite imagery analysis, remote sensing, and GIS (Geographic
    Information Systems) applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Each of these libraries serves a synergic purpose and permits handling a myriad
    of data types in scientific computing, data science, and geospatial applications.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an IDE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The last step of our setup is to install an IDE. We are still in the command
    line interface within the environment, and we type: `pip install jupyterlab`,
    which will install jupyterlab on our environment. To use it clearly, we can change
    the directory to the parent directory of our project (let us call it `INTEGRATION`),
    which will hold both a `CODE` folder and a `DATA` Folder: `cd C://COURSES/POUX/INTEGRATION`.
    And then, we will launch jupyterlab from this location by typing in the console:
    `jupyter lab`, which will open a new localhost page in your web browser (Chrome
    would be the preferred choice, but Firefox or Safari work as well).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Well done! Phase one was completed successfully! üéØWe are now ready to attack
    the second phase: finding datasets that we can combine for later use in our NASA-graded
    workflow. üôÉ'
  prefs: []
  type: TYPE_NORMAL
- en: Step 2\. Multi-Modal Data Curation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/4f30096356d29ac7cf24d2996baead60.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 2\. Multi-Modal Creation. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to integrate multi-modal datasets. But what is this swearword: multimodal?
    It refers to data that spans different types and contexts, such as images, point
    clouds, text, and sound‚Ä¶'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a331b61c40795a96c1600a99bf0cd3c.png)'
  prefs: []
  type: TYPE_IMG
- en: We use various 2D/2.5D/3D modalities. 3D Point Clouds, 3D Mesh, City Models,
    Voxels, Spatial Rasters, 360¬∞ Imagery, Tabular Data, Vector Data. ¬© F. Poux
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ù **Nourian**: *Additionally, here is a nice hitchhiker''s guide to Web-based
    computing platforms for Urban Planning:* [*Essential Guide*](https://www.researchgate.net/publication/324088589_Essential_Means_for_Urban_Computing_Specification_of_Web-Based_Computing_Platforms_for_Urban_Planning_a_Hitchhiker''s_Guide)
    *(ResearchGate)*'
  prefs: []
  type: TYPE_NORMAL
- en: So, our goal in this phase is to identify a zone of interest and gather as much
    data as possible to help us in our future analysis. The zone of interest selected
    today is a part of Enschede, a city in Eastern Netherlands in the province of
    Overijssel (Twente region), where, it makes sense, the University of Twente shines
    its knowledge beams. üåû
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c06ca6ff77e065d5e3cbb3d23ca0b7b6.png)'
  prefs: []
  type: TYPE_IMG
- en: Identifying a zone of interest.
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶Ñ **Mila**: *By unlocking the secrets of our cities through the fusion of 3D
    geospatial and remote sensing data, we give birth to city digital twins that illuminate
    the past, navigate the present, and shape. If you want to dive even more into
    data integration on the web using open-source tools, here is a research paper:*
    *3D Data integration for web-based opensource WebGL interactive visualization*
    *(ISPRS Archives)*'
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to source different datasets. For clarity concerns, I organized
    this sourcing into four categories by searching for 3D datasets, Spatial Rasters,
    vector datasets, and finally from other sources, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4dd3147fbd305984b5b6690111c402cb.png)'
  prefs: []
  type: TYPE_IMG
- en: Multi-modal data curation workflow. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 3D Data Sourcing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is to source some datasets from some open data repository with
    a data license that allows us to do some experiments. On that front, for the Netherlands,
    there is the possibility of obtaining LiDAR data, elevation data models, and raster
    imagery from one place: [geotiles.nl](https://geotiles.nl/). You can zoom in on
    the original tiles and get access to the various datasets download links, as shown
    below.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7258d565f8e5ba2179bf8e4d51ddf3a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Extracting the 34FN2 Tile of the AHN4 Dataset through GeoTiles.nl. ¬© Florent
    Poux
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *To serve you best, all the used data is available in the Drive
    Folder shared at the end of the section. The AHN version is AHN4.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second place you can explore to get CityModels is 3D BAG, which stands
    for 3D Register of Buildings and Addresses (BAG), the most detailed, openly available
    data set on buildings and addresses in the Netherlands. It contains 3D models
    at numerous levels of detail, generated by combining two open data sets: the building
    data from the [BAG](https://docs.3dbag.nl/en/overview/sources/#BAG) and the height
    data from the [AHN](https://docs.3dbag.nl/en/overview/sources/#AHN). Using the
    3D Bag Viewer by tile queries, you can explore and access the buildings.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c981742889390b5d596eab78a29844c.png)'
  prefs: []
  type: TYPE_IMG
- en: The BAG Viewer. The Open Data accessible is licensed under CC BY 4.0, [3DBAG
    by tudelft3d and 3DGI](https://docs.3dbag.nl/en/copyright).
  prefs: []
  type: TYPE_NORMAL
- en: The tile extent differs from what we got from the geotiles.nl, making it **interesting**
    when we attack the integration phase. At this stage, we already have exciting
    datasets under our hands. We can now move on to exploring spatial raster datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Spatial Raster Data sources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For satellite and aerial imagery, the [USGS Earth Explorer](https://earthexplorer.usgs.gov/)
    is one of the largest free data sources. It is worldwide, with a friendly user
    interface that makes accessing remote sensing data simple. It even has a bulk
    download application if you need to download more than one data set. If this is
    the first time for you, you will need to execute one additional step: creating
    an account, but it is free and quick (I did it in under 2 minutes ‚åö).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8f2e719409f3981b7a32498cc696f18d.png)'
  prefs: []
  type: TYPE_IMG
- en: The USGS Earth Explorer. Open data part of U.S. Public Domain, [Credits USGS](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits).
  prefs: []
  type: TYPE_NORMAL
- en: I drew a polygon from the WebUI and then asked to get the **Landsat > Landsat
    Collection 2 ‚Äî Level 1** group (the most recent Landsat imagery is L8‚Äì9 OLI/TIRS
    and L7 ETM+). The differences between the collections are based on data quality
    and level of processing. USGS has [classified images into tiers](https://www.usgs.gov/media/videos/landsat-collections-what-are-tiers)
    based on quality and processing level ([Source](https://gisgeography.com/usgs-earth-explorer-download-free-landsat-imagery/)).
    Once in the result section, you can check the footprint before deciding which
    would best fit your needs, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/711d76ed2293ecae088248d408fca2c0.png)'
  prefs: []
  type: TYPE_IMG
- en: The polygons to extract LandSAT images. ¬© F. Poux
  prefs: []
  type: TYPE_NORMAL
- en: For Digital Elevation models, I suggest sticking with the [geotiles.nl](https://geotiles.nl/)
    data service as it is already on point with the most up-to-date and precise elevation
    models from the AHN. We are moving at an incredible pace, and the next stage is
    to get some excellent vector datasets!
  prefs: []
  type: TYPE_NORMAL
- en: Vector data curation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are in the GIS community, I hope presenting the power of [OpenStreetMap
    (OSM)](https://www.openstreetmap.org/#map=17/52.22687/6.88808&layers=G) will not
    insult your knowledge base.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e45243acdfb3b509eee6d1c8c17517c1.png)'
  prefs: []
  type: TYPE_IMG
- en: OpenStreetMap Data Curation Portal. The Data is open, under the open database
    license (ODbL), [Credits OpenStreetMap](https://www.openstreetmap.org/copyright).
  prefs: []
  type: TYPE_NORMAL
- en: OSM provides different maps and layers with a crowd-sourcing initiative that
    makes it highly exhaustive, with a precision flag nevertheless. Indeed, OSM is
    open to the public and created by a general audience. So this means that accuracy
    can vary based on the creator and its ‚Äúmapping‚Äù expertise level. However, OSM
    is a goldmine for openly licensed street-level GIS data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have several ways to download OpenStreetMap data to get our hands on some
    of this gold. Conveniently, there is even an [OSM Data Wikipedia page](https://wiki.openstreetmap.org/wiki/Downloading_data)
    with all the available OSM extracts. My recommendation is the use of the tool
    [Geofabrik](http://download.geofabrik.de/). Indeed, you can then leverage a data
    organization by semantic spatial extent (E.g.: country, state, continent ‚Ä¶). You
    can quickly choose a geographic location and then download OSM data, as shown
    below.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/960b1288b62967ac0e4952f6ca76f5af.png)'
  prefs: []
  type: TYPE_IMG
- en: GeoFabrik portal to gather vector datasets. ¬© F. Poux
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *I also prefer downloading OSM data as shapefiles, but more
    on that later üòâ.* ***Mila*** *makes me think that a great piece of knowledge is
    distilled in this* [*Geospatial Data with Python*](https://carpentries-incubator.github.io/geospatial-python/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: We now have some 3D datasets, some raster datasets, and vector shapefiles. Time
    to dig the world wide web to find other precious stones üíé.
  prefs: []
  type: TYPE_NORMAL
- en: Other sources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Well, here, the web is your ally. You can find anything you want to tie to
    your analyses, from web pages to news, to sounds to real-time data feeds. I would
    not overstate that sky (or your bandwidth üòÅ) is the limit! But, let me be very
    pragmatic again and also guide you toward one platform: [Mappillary](https://www.mapillary.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: Mappillary is a platform that makes street-level images and map data available
    to scale. You can explore it and download some 360¬∞ imagery and points of interest
    using the Map Explorer.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c741964aa19871f3fa37c13255b83f5d.png)'
  prefs: []
  type: TYPE_IMG
- en: Mapillary database with the provided portal. If you download images, they are
    licensed under [CC-BY-SA](https://help.mapillary.com/hc/en-us/articles/115001770409-Licenses)
    by Mappillary.
  prefs: []
  type: TYPE_NORMAL
- en: You also have the ability to filter out elements by their class if you want
    to select only some elements of interest or to cross-validate information with
    OSM data, for example.
  prefs: []
  type: TYPE_NORMAL
- en: And now, the good news? To follow along the code lines that are coming, I alleviate
    for you the process of getting all of this data that you can find directly in
    this [Data Drive Repository](https://drive.google.com/drive/folders/1HNvEHftS0SlCXESM19xd6onxSAGHy5wE?usp=sharing).
    Once you have what you need in your DATA folder, we can start a nice exploratory
    data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3\. Exploratory Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/29b3d09b90bbcecf545e99977709bbf0.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 3\. Exploratory Data Analysis.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we have a Python code setup and a data setup, so we are ready
    to activate a deep focus mode with 15 minutes on clock timer ‚åö. Indeed, we will
    now explore the various datasets we gathered with Python.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/870384fec802dd5f4dca991f62660903.png)'
  prefs: []
  type: TYPE_IMG
- en: Loading and Reading 3D Data. We use Open3D (Point Clouds, Mesh, Voxels), RasterIO,
    and Geopandas. ¬© F. Poux
  prefs: []
  type: TYPE_NORMAL
- en: This means that, for each modality, we will go through reading, profiling, harmonizing,
    and categorizing its content. Often, that means dealing with library bidirectional
    communication. To stay concise, I took the liberty of regrouping some modalities
    together, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/62cbe01ff61228976f10413fc529ff48.png)'
  prefs: []
  type: TYPE_IMG
- en: The multiple modalities covered. ¬© F. Poux
  prefs: []
  type: TYPE_NORMAL
- en: 'Before loading anything, let us import all the libraries installed by writing
    in your notebook/script the following nine lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 3D Point Clouds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us start with my prot√©g√©s: 3D point clouds. They are essentially a collection
    of points in 3D space that represent a physical object or environment. These points
    are generated from various sources, including LiDAR, photogrammetry, Artificial
    Intelligence (yes, you read well), scanning devices, etc. The first dataset in
    our hands comes from the Aerial LiDAR AHN campaign in the LAZ file format. It
    spans from the LAS LiDAR data Exchange Format (LAS) as its compressed counterpart,
    widely used for storing LiDAR point cloud data. It supports 2D and 3D point data
    and attributes such as intensity and classification. To read the file with Python,
    we use the `laspy` library with its extensions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Great! we now have our file loaded in the `las` variable, which we can explore
    quickly using `laspy` functions to get possible attributes, the `max value` of
    the `red` channel, or the projection information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This will yield the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The third line gives us an interesting profile: the data is expressed in `Amersfoort
    / RD New + NAP height` reference system. We note that down for later.'
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent***: As you can see, the first line gives us several attributes
    for later use. This is nice that, by default, we can store so much information
    in a semi-structured way. However, we need to sort out the relevancy of this information;
    usually, we default to using* `*X*`*,*`*Y*`*,*`*Z*`*,* `*intensity*`*,* `*red*`*,*
    `*green*`*,* `*blue*`*. I would call the other one''s bonuses* üòÅ*.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, we have no natural way to visualize if the data is correct;
    we have to transform it into our beloved `numpy` object, which we can after that
    convert to an `open3d` point cloud object to close the loop of switching between
    libraries. First, we convert some `laspy` object attributes to `coords` and `colors`
    numpy objects to hold our point cloud coordinates `X`,`Y`, `Z` and our point cloud
    colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Then we transform our numpy object into an `open3d` object to visualize the
    point cloud. Unfortunately, no direct way from `laspy` exists, yet üòÅ.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'ü¶ä **Florent***: This is a great exercise to see that switching libraries almost
    always comes down to losing some processing time between conversions and also
    exposes to possible memory errors. Therefore, always using a limited number of
    libraries is my advice when dealing with complex datasets and workflows.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e22090797ec2e060ff410aafd2c3b76.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Point Cloud Dataset visualized in Open3D. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now visualize the full LiDAR point cloud within Python nicely, on par
    with professional software! Let us now load another point cloud to explore another
    widely used file format: `.ply`. The PLY format is used to store 3D mesh data
    along with attributes like color and normals. It is also suitable for point clouds
    with additional information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With `open3d`, this is super simple; you can execute the following code to
    fill the `pcd_itc` variable with the point cloud, and the `o3d.visualization`
    function to draw the point cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/75dd922b578e733201d3335ab0d27f5e.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Indoor Point Cloud visualized in Open3D. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: This point cloud does not show any metadata information, which means that we
    will consider that it is expressed in a local reference system that will need
    to be registered somehow to a reference dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä**Florent**: *Spoiler alert! Point cloud dataset is like a special central
    rock, especially dealing with multiple modalities. Indeed, as I will show later,
    it can act as the canonical reference to then link all the other datasets to it.
    I warned you of the spoiler!*'
  prefs: []
  type: TYPE_NORMAL
- en: Time to move on 3D voxels üßä
  prefs: []
  type: TYPE_NORMAL
- en: 3D Voxels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Voxels are another type of 3D data format. Voxels are essentially 3D pixels
    that represent a volume of space. They are plain fun, and you can check their
    plain usefulness in the following case studies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  prefs: []
  type: TYPE_NORMAL
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Python‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [](/how-to-automate-voxel-modelling-of-3d-point-cloud-with-python-459f4d43a227?source=post_page-----7ef8ef14589a--------------------------------)
    [## How to Automate Voxel Modelling of 3D Point Cloud with Python
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on tutorial to turn large point clouds into 3D voxels üßä with Python and
    open3d. Unlock an automation workflow‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-automate-voxel-modelling-of-3d-point-cloud-with-python-459f4d43a227?source=post_page-----7ef8ef14589a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ù **Pirouz**: *Voxels are pretty much like LEGO models. Check out this paper
    about voxelization of spatial data and getting serious with digital LEGO:* [*Voxelization
    Algorithms for Geospatial Applications*](https://www.researchgate.net/publication/290507635_Voxelization_Algorithms_for_Geospatial_Applications)
    *(ResearchGate). If you can‚Äôt get enough of voxels? Then search Google for ‚Äúvoxel
    art‚Äù and check out the library* [*topoGenesis*](https://github.com/shervinazadi/topogenesis/)
    *(GitHub).*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will read and visualize the voxel dataset with the following code lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6bf16433b5524924f2cd62af7adf0c52.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Voxel Dataset visualized in Open3D. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we read, profiled, and made sure that we had a way to deal with
    all this data with a single library for processing (`numpy`) and one for 3D visualization
    (`open3d`).
  prefs: []
  type: TYPE_NORMAL
- en: Time to get city models in our Python experiments üòÅ
  prefs: []
  type: TYPE_NORMAL
- en: City Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Models of Cities often follow a standard of expression: CityGML models. CityGML
    is an XML-based data format used to represent the 3D geometry of urban environments.
    CityGML models can include information about buildings, roads, bridges, and other
    infrastructure. City planners, architects, and engineers often use these models
    to simulate and analyze urban environments. An excellent place to get yours, which
    I did not mention on purpose before, is this GitHub repository curated by my colleague
    Olaf (Any Frozen reference forbidden ‚õÑ): [CityGML Models](https://github.com/OloOcki/awesome-citygml).'
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *Basically, in Python, we have to make sure to convert these
    models to 3D meshes while keeping any wanted semantic / topology or other information.
    A friendly Python tool, again by* [*TUM*](https://www.asg.ed.tum.de/en/gis/home/)*,
    is available here:* [*citygml2obj*](https://github.com/tum-gis/CityGML2OBJv2)*.
    But I did the heavy lifting for you if you use the data, thus moving on to the
    next reading modality: 3D meshes.*'
  prefs: []
  type: TYPE_NORMAL
- en: 3D Mesh
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, let‚Äôs talk about meshes. Triangular meshes are constituted of vertices,
    edges that bind vertices, and triangular faces that finish the ‚Äúenvelope‚Äù of objects.
    They allow us to depict the shape of a 3D object. Meshes can be created using
    3D modeling software or generated from point clouds, city models using specialized
    algorithms, or even Artificial Intelligence! The dataset is in an OBJ format commonly
    used to export 3D mesh models representing geometry and texture coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ù **Pirouz**: *If you want to know why these fancy words are used instead of
    points, lines, and polygons, you need to learn a bit more about another fancy
    word:* ***topology****.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *You can read a story about topology written by Pirouz which
    may well be one of the easiest story about topology:* [*Rudiments of Geometry
    and Topology*](https://www.researchgate.net/publication/344297280_Rudiments_of_Geometry_and_Topology_for_Computational_Design)
    *(ResearchGate)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the mesh and get its extent, we will write the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: And we see from the output that we have coordinates that span closely to what
    Amersfoort / RD New gives. This is comforting; we now have another dataset in
    this reference system.
  prefs: []
  type: TYPE_NORMAL
- en: 'From there, to visualize the mesh, we first compute some vertex normals and
    use the same visualization function from open3d to visualize it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: On the 3D side, we are good to go! Let us explore our Spatial Rasters with Python
    and rasterio
  prefs: []
  type: TYPE_NORMAL
- en: Spatial Imagery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our imagery is in the GeoTIFF format, an extension of the TIFF format that
    includes geospatial metadata, making it ideal for raster elevation data (DSM/DTM)
    and imagery. To open and profile the spatial imagery that we have, we simply use
    the following lines of code using rasterio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Interestingly, we get a clear detail that it is an image of `20002x25002`, with
    three channels (`R`,`G`, and `B`) expressed in the `CRS 28992`, which corresponds
    to Amersfoort again! This is great!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to plot with numpy and matplotlib, below is the tiniest possible line
    of code to get an image with numpy, avoiding Memory errors, with a result shown
    afterward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In parallel, rasterio also provides `[show()](https://rasterio.readthedocs.io/en/latest/api/rasterio.plot.html#rasterio.plot.show)`
    function to perform everyday tasks such as displaying multi-band images as RGB
    and labeling the axes with proper geo-referenced extents. This permits to simplify
    the plot, as expressed below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/55fd9e9d40f9a3756281b73957fbab92.png)![](../Images/989cb39b502ebe4f1a95935a2a64e5ce.png)![](../Images/02e48e5a69ee893ff38c345bd5017826.png)'
  prefs: []
  type: TYPE_IMG
- en: Various raster visualized with plot functions from matplotlib and rasterio.
    ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: This is superb! We have several 3D datasets (3D point clouds, voxels, 3D meshes)
    and satellite imagery (both infrared and R, G,B) that we could both handle with
    numpy and express for most of them in one common CRS. Let us move to other rasters
    focusing on elevation data (2.5D).
  prefs: []
  type: TYPE_NORMAL
- en: Elevation Rasters (DSM, DTM)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Elevation models are usually found as raster files, where each pixel has a
    value that can be translated to its elevation. This is why we call that 2.5D data
    as it is a pure top-down or single point of view, also tagged depth image when
    out of any GIS projection system. We can import elevation models with the same
    code line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a `dtm` variable that holds the elevation data, we extract
    its metadata on the whole with `dtm.meta`, or more specialized with `dtm.shape`,
    `dtm.crs`, `dtm.bounds`, `dtm.overviews(1)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This brings us to the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: And again, it is interesting to see that we have the same CRS Amersfoort / RD
    New for this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a plot and a sense of what we are dealing with, we can transform the
    dataset to a numpy array and use indexing to select part of it in a selection
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we plot using the two ways: `rasterio` and `matplotlib` both the full-scale
    dataset and the zoomed-in selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f9a8eddbdb97ba300eb28ac36f41db09.png)![](../Images/0891a307d2bcc019a56d4f25e6b0ef3b.png)'
  prefs: []
  type: TYPE_IMG
- en: DTM plot with RasterIO and matplotlib. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we cannot discuss raster datasets without diving into vector spatial
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Spatial Vector Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this stage, it is essential to clarify once and for all that, if you find
    pixels, you are not speaking about vector data. Instead, vector datasets are made
    of vertices and paths, which are available as points (X, Y coordinates), lines
    (they connect these points now tagged vertices), and polygons (connect vertices
    to close a path made of lines).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/55bed353a01d2e175b0cb890bd079743.png)'
  prefs: []
  type: TYPE_IMG
- en: Vector Data in GIS Systems. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'üå± **Growing**: *Having that in mind, where does your intuition place 3D point
    clouds? Voxel models? 3D meshes? These are interesting questions with profound
    implications, but nice to situate better how 2D stands with a 3D synergy*.'
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, cartographers (but not only) use these as ‚Äúsymbols‚Äù to depict
    real-world components in maps. This means that they constantly have to determine
    a ‚ÄúLevel of Detail‚Äù (LoD) that the entity represents, and this gives so much symbolic
    power to these entities (a point can be a country, or a town, or a citizen, or
    a specific place, ‚Ä¶).
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle these vector datasets, we mainly use one open specification, the
    shapefile format. This permits us to spatially describe geometries and attach
    some kind of additional information to them. On our computer, the shapefile file
    format is simply a collection of several files formatted to represent different
    aspects of geodata ([*Reference*](https://wiki.openstreetmap.org/wiki/Shapefiles)):'
  prefs: []
  type: TYPE_NORMAL
- en: '`.shp` ‚Äî The shape file, which contains the feature geometry itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.shx` ‚ÄîThe shape index format, which holds a positional index of the feature
    geometry. This is very useful for large files in order to allow quick search thanks
    to clever ‚Äúindexing‚Äù.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.dbf` ‚Äî The attribute format, which holds various attributes for each shape
    in a tabular way (dBase IV format).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On top, we may have optional files that accompany the shapefile format. The
    most noteworthy one is the ‚Äú`.prj`‚Äù file. This extra file actually defines the
    coordinate system and any projection information deemed necessary. Thus, having
    all these files allows us to load street data of the region Overijssel using this
    time geopandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/cd2f94aa4d177b76cad9ca52797d37a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Vector Data output. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us now explore a bit its projection system by exploring its CRS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Which results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, this dataset is expressed in the ESPG 4326, which stands for
    WGS84\. So this is different from our other datasets so far.
  prefs: []
  type: TYPE_NORMAL
- en: '**Florent**: *geopandas is a perfect mashup of pandas and shapely. Thus if
    you are familiar with both, geopandas will be a breeze! Some useful commands are*
    `vector_data.columns` *or* `vector_data.describe()` *that can give you an overview
    of its content quickly*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But let us now explore our dataset visually to see its content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Which results in the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2fc7bb808b505e587e571a7e671ad9b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Vector Data from OpenStreetMap. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: This is very interesting! We can also use Matplotlib to display vector data.
    And the region is densely populated with an extensive road network, which is very
    dense! Let us now extract some points of interest from another source of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Vector: Points of Interest'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The dataset pack has a GeoJSON file, a lightweight and popular format for representing
    vector data with geometry and attributes, suitable for web-based applications
    and data exchange. To load the file, we also use geopandas with this code line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We profile its CRS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us an answer that this is in the WGS84 CRS again. Finally, we plot
    to check any abnormality firsthand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a4b39e1fe098148011685d72801919f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Points of interest. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'This may be a bit bland without any more context; thus, layering Raster imagery
    would be a first choice already. But before that, let us explore another dataset
    we could try: 360¬∞ imagery!'
  prefs: []
  type: TYPE_NORMAL
- en: 360¬∞ Imagery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From the mappillary platform, we have the ability to extract some 360¬∞ images
    that come with a specific license to be used. You can still use geopandas to read
    these images :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'That will output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we can see (of course) that this image has no geotransform data. And this
    is normal: this is not a spatial raster! However, if we wanted, we could add a
    position so that a data point represents the place the picture was taken, a hint
    at layering data modalities through data integration. But before going there,
    let us plot the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9d16fa976ae1afafa51f2fe9b49cd98d.png)'
  prefs: []
  type: TYPE_IMG
- en: 360¬∞ imagery from Mapillary. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: We have now successfully loaded 3D Point Clouds, 3D City models as 3D Meshes,
    3D Voxel dataset, Spatial rasters (satellite imagery, aerial imagery, and elevation
    rasters), vector datasets (lines and points), as well as 360¬∞ imagery. The first
    objective is now an evident success! But, we need to check how to bring that all
    together, and the first thing to check is actually if they are expressed in the
    same Coordinate Reference System (CRS). For that, I compiled the results of our
    profiling step in the table below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We see a mix of EPSG:7415, 28992, 4326 or missing EPSG. The next stage is thus
    to clarify and use a unifying system for all datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Data Registration and Reprojection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/4d29341fd32f54b9cad5d858722e4e38.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 4\. Registration and Reprojection
  prefs: []
  type: TYPE_NORMAL
- en: Before integration, we have to ensure that all datasets are in a compatible
    format and coordinate reference system (CRS). If this is not the case, we perform
    data reprojection to bring them into a common CRS. This is achieved in four main
    stages by (1) Selecting a reference system, (2) Georeferencing the primary dataset,
    (3) Reprojecting other datasets, and (4) Aligning rigidly local datasets, as shown
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6df947aa143ea3754d64afd48adcb515.png)'
  prefs: []
  type: TYPE_IMG
- en: 4 Steps Workflow covered. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through these stages.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a Reference System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alright, let us dive into the exciting world of reference systems! Imagine reference
    systems as the GPS coordinates that guide your data through the vast landscape
    of planet Earth. A reference system defines a set of rules and parameters to represent
    the Earth‚Äôs surface in a way that makes sense to us mere mortals. It‚Äôs like choosing
    a secret language that your data speaks fluently, allowing it to find its place
    in the world. Now, how do we choose the correct reference system? Let‚Äôs be pragmatic
    and attempt to first delineate the scope + region of interest of the project at
    hands.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5cc44dd0f1cf97049d9ce90cf78a8ea2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Projection classical cases: One standard line, one standard cone and one standard
    point. ¬© [F. Poux](https://learngeodata.eu/)'
  prefs: []
  type: TYPE_NORMAL
- en: Different reference systems work better for different parts of the globe. Something
    like the Amersfoort / RD New can be a fantastic choice for local projects in the
    Netherlands. The trusty WGS84 or Universal Transverse Mercator (UTM) might be
    your best buddy for more global ventures. Therefore, we use the Amersfoort / RD
    New + [NAP height](https://epsg.io/5709) (for the elevation information) as our
    CRS.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, when choosing a reference system, let the nature of your project and
    the region guide your decision. Pick a system that speaks the language of your
    data and brings harmony to your geospatial endeavors.üó∫Ô∏è
  prefs: []
  type: TYPE_NORMAL
- en: Data Georeferencing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Okay, we have our CRS defined; this step ensures that the data tagged in EPSG:7415
    for 3D data, and EPSG:28992 for 2D data. When profiling, we could then check that
    these datasets are already coherent:'
  prefs: []
  type: TYPE_NORMAL
- en: LiDAR 3D Point Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raster Imagery (both Spatial Raster and Elevation Raster)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, the voxel dataset and the mesh from the city model dataset look like
    they are in the same CRS but have no metadata. Thus, we quickly overlay these
    datasets to check for any possible inconsistencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Which results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d9b3ea6b8885875589da756fcc4e517d.png)'
  prefs: []
  type: TYPE_IMG
- en: The point cloud, building, and voxel datasets are combined together and visualized.
    ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä**Florent**: *Everything is aligned nicely, as shown in the image. The various
    datasets are cut on purpose to show the overlap between them. You can also see
    that point clouds have a bit more roughness and ‚Äúresolution‚Äù over the 3D models
    that represent the buildings.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'the remaining datasets to address are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Vector datasets (both the OSM and Mappillary one) that are expressed in WGS84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ITC Point Cloud dataset is not georeferenced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us then deal with data projection first.
  prefs: []
  type: TYPE_NORMAL
- en: Data Reprojection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Spatial data reprojection is a fundamental process that involves transforming
    spatial data from one coordinate reference system to another, typically to match
    the projection and coordinate units of a specific spatial analysis. Reprojection
    ensures that different datasets with distinct projections can be accurately overlaid,
    integrated, or analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: The process involves mathematical calculations that convert geographic coordinates
    (latitude and longitude) from one datum to another, considering parameters like
    scale, rotation, and distortion. Spatial data reprojection is essential for achieving
    data consistency, enabling interoperability between different datasets, and conducting
    accurate geospatial analyses across diverse mapping systems and applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'When reprojecting spatial data between reference systems, several important
    factors must be carefully considered to ensure accurate and meaningful results.
    Here are some of the key considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Coordinate Systems and Projections: Understand the coordinate systems and projections
    of both the source and target reference systems. Make sure they are compatible;
    if not, choose an appropriate transformation method.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Datum and Ellipsoid: Check the datums and ellipsoids used in the source and
    target systems. Differences in datums can lead to significant shifts in coordinates.
    Apply datum transformations if needed to align the data correctly. If you feel
    a bit confused, here is a nice [lecture on datum and ellipsoid](https://www.tamiu.edu/cees/courses/fall2018/geol4460_labs/lecture4.pdf)
    (tamia.edu)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Accuracy / Precision: While these pinpoint two different characteristics (which
    extends the scope of our article), it is important to understand the required
    ‚Äúlevel‚Äù for your specific analysis. Reprojection can introduce some errors, especially
    in large-scale transformations. Indeed, any data ‚Äúerror‚Äù has a potential impact
    on the results of our analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Distortions: Different map projections can introduce distortions in shape,
    area, distance, or angles. Be aware of these distortions and their implications
    on your data interpretation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Coverage Area: Some projections are suitable for specific regions but may not
    be ideal for global datasets. Choose a projection that preserves the properties
    of your data over the entire coverage area.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Metadata and Documentation: Keep track of the reprojection process and document
    the transformations applied to the data. Properly document the source coordinate
    system and the target projection for future reference.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'By carefully considering these factors, we ensure that reprojection is performed
    accurately and the resulting data is suitable for our intended applications. It
    is essential to be mindful of potential errors and artifacts that can arise during
    the reprojection process and to validate the results to maintain the quality and
    reliability of the data. In our case, we have to reproject both vector datasets.
    To do this, we use the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Which results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5be24aaf0ff2a87f7ff146850d80def6.png)![](../Images/7d4741c1990d5ac1e972030c7a079c03.png)'
  prefs: []
  type: TYPE_IMG
- en: The resulting plots. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *3D Reprojection is also possible, but currently extend a bit
    the scope of this guide. Nevertheless, you can browse the library of course tutorials,
    where you will find some nice code and examples for 3D reprojection in the context
    of Segment Anything for Semantic Segmentation.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the change in the coordinates on the axes of our plots! At this stage,
    it looks like we only have one data to register: the 3D Point Cloud of ITC.'
  prefs: []
  type: TYPE_NORMAL
- en: Data Rigid Registration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/036f65b753a68af1d9b2c43d2faa1a2a.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Data Registration classical workflow. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'In 3D integration, data registration becomes crucial. Point cloud registration
    methods are usually made of two stages: a coarse alignment to position relatively
    closely two point clouds quickly. Then a fine registration like Iterative Closest
    Point (ICP) or feature-based registration to align multiple point clouds with
    a higher degree of precision. To give you a hint concerning global registration,
    we can align the ITC point cloud by picking a list of three pairs of common points
    to get a first estimate, which is later refined with ICP. This permits obtaining
    an overlaid point cloud. These largely extend the scope of the current guide,
    and will be covered in another session.üòâ'
  prefs: []
  type: TYPE_NORMAL
- en: We now possess an aligned dataset expressed in a coherent CRS. The next stage
    is to see if we can refine the ‚Äúdata oil‚Äù to get some intelligent analytical workflow
    that can be built from there.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5\. Data Processing, Transformations, and Fusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/b6c0b16e52d182b2c282240b7da919c5.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 5\. Data Pre-Processing
  prefs: []
  type: TYPE_NORMAL
- en: This stage can also be done before the registration and reprojection part. Indeed,
    as we predominantly work per dataset, this is a solution and can impact (for better
    or worse) the results of the previous steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spatial data integration combines different types of spatial data (2D, 3D,
    or 2.5D) to **create a unified and comprehensive representation of an area with
    data overlap**. This process allows us to leverage the strengths of each data
    type and derive more valuable insights from the integrated dataset. Here is a
    quick view of some processing strategies for spatial data integration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d9d187eb0f750e7e3075ac678eb7b2d.png)'
  prefs: []
  type: TYPE_IMG
- en: '3D Data Pre-Processing major areas: data cleaning, data transformation, data
    reduction, and data enrichment. ¬© [F. Poux](https://learngeodata.eu/)'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us explore what these four main stages actually look like, code-wise.
  prefs: []
  type: TYPE_NORMAL
- en: Data Cleaning (Raster Dataset)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: the first stage is to handle missing or erroneous data points carefully. Data
    cleaning techniques like interpolation or extrapolation may be used to fill in
    gaps or replace erroneous values. In our case, we could fill empty raster values
    from our DTM.
  prefs: []
  type: TYPE_NORMAL
- en: 'I do this by interpolating neighboring pixels for each empty zone to try and
    give a better structure to our dataset with the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'üå± **Growing**: *How would you use this to extract contour lines on your zone?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09eb437fe7b5cabbb33e57de38211fd2.png)![](../Images/17b4a6d800f5b1c48bd591a9065d472e.png)'
  prefs: []
  type: TYPE_IMG
- en: DTM Visualization results. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: Data Transformation (3D Point Cloud)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Aside from conversion between file formats, data transformation refers to the
    various processes to ensure structural and content integrity toward one or more
    processing steps. For example, it is imperative in many feature engineering tasks
    to enhance 3D machine learning model performances.
  prefs: []
  type: TYPE_NORMAL
- en: 'One critical data transformation method is scaling, ensuring that all the values
    in a dataset are within a specific range, such as 0 to 1\. To do this on a point
    cloud, we proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This transforms our original point cloud with coordinates between 0 and 1 for
    all our points. Therefore, if we were to plot their distribution along the three
    axes, we would use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'To obtain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/59891a96517f44038b65ecdc5efcb218.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Point Cloud Distribution analysis. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, our point cloud now has X, Y, and Z coordinates that range between
    0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'üçá **Note**: *This is interesting on another flavor. Indeed, we tend to a pattern
    looking at the Z distribution, where a hint toward a Z-driven algorithm makes
    sense, for example, to distinguish roofs from the ground points*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Reduction: Cropping mask, Point Cloud Sampling'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data reduction encompasses the various techniques in which data is reduced to
    its simplest possible form to enable optimal analytical tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of these is data cropping: reducing the spatial extent of our dataset.
    A clear example could be executed on raster datasets to limit the memory footprint
    by loading a huge zone when we want to focus on a tighter area. To do this, with
    rasterio, we have first to create a geopandas bounding box that will act as the
    filtering mask:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We then get a nice area box that we use as a mask on the original file (or
    any raster of choice) by also making sure we copy the metadata of the original
    file onto the cropped version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e9f27afe0639f0f3410bedfa686989bb.png)'
  prefs: []
  type: TYPE_IMG
- en: Cropping a CIR Image. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'Another clear data reduction technique is data sampling. In our case, trying
    to reduce the number of points in our point cloud. This can be done in several
    ways (which, again, extend the scope of this article), with one using the voxel
    data structure a priori: we want to keep one best candidate per voxel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following downsampled point cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/530a14f72994cc61d0aeb547aa8f0e3e.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Point Cloud Downsampling results. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can enrich our dataset in various ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Enrichment: Inject POI proximity to point clouds'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on the application, various fusion techniques can be applied to merge
    the datasets. For 2D and 2.5D integration, raster-based methods like weighted
    averaging or majority voting can combine multiple data layers. In 3D integration,
    point cloud fusion techniques, such as merging, averaging, or voxelization, are
    employed to create a single, consolidated 3D point cloud representing the entire
    area.
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *Using data enrichment (fusion) techniques, we combine information
    from multiple sources (it can be web-based, from a data acquisition mission, or
    any relevant way to gather data). This allows the creation of a more comprehensive
    and accurate representation of the underlying phenomenon. These can touch on raster
    Weighted Averaging (Involves taking a weighted average of pixel values from multiple
    raster layers, where the weights represent the importance or reliability of each
    raster layer), Majority Voting (Combines categorical raster data by assigning
    the majority class to each pixel location, helpful in land cover classification).
    But these are for another time.* üòâ'
  prefs: []
  type: TYPE_NORMAL
- en: 'A swift way to extend our dataset is to compute additional features. This is
    done, for example, on the 3D point clouds by extracting normals computed from
    a neighborhood of points that permits extracting the best fitting plane, then
    the normals. We automatically do this with the following piece of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'And as you can see below, we can visualize our new point cloud without or with
    normals (pressing ‚Äú`n`‚Äù in the interactive window viewer):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/42d6422b3084e0d01f17e87cc5b58b51.png)![](../Images/b95f5edb82a59699d99586a900bd2284.png)'
  prefs: []
  type: TYPE_IMG
- en: Normal computation and visualization from the 3D Point Cloud. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: Step 6\. Multi-modal Data Visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/fc0e59685c0dbb2b9508d883a6272491.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 6\. Multi-Modal Data Visualization.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-modal data visualization is a powerful approach that seamlessly integrates
    our diverse geospatial data, including vector data, spatial raster imagery, Digital
    Surface Models (DSM), Digital Terrain Models (DTM), point clouds, and city models.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a4b9c501070cac01cda1bdf4410b30eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Libraries used for 3D Data Visualization: Matplotlib, Open3D and RasterIO (2D/2.5D).
    ¬© [F. Poux](https://learngeodata.eu/)'
  prefs: []
  type: TYPE_NORMAL
- en: This comprehensive fusion of data types allows for a more holistic understanding
    of the environment, laying the groundwork for more informed decision-making and
    sophisticated analyses. Now, let‚Äôs dive into a Python solution that showcases
    how to achieve this remarkable visualization feat!
  prefs: []
  type: TYPE_NORMAL
- en: The trick is to understand the strengths and limits of each of our libraries!
    Indeed, what we will do is actually to stick to Open3D to check for the consistency
    between the data modalities (Meshes, 3D Point Clouds, and Voxels) and use **the
    point cloud dataset as the canonical reference to then link all the other datasets
    to it**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6f79f90b3eefcc73332f1bad24cd1dec.png)'
  prefs: []
  type: TYPE_IMG
- en: Point Cloud as a canonical frame of reference. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the first step is to analyze the 3D modalities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d9b3ea6b8885875589da756fcc4e517d.png)'
  prefs: []
  type: TYPE_IMG
- en: Combined 3D Datasets. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'ü¶ä **Florent**: *While the image may be confusing, be warned that nothing is
    going wrong when you visualize these three in one image. Indeed, the extent of
    the datasets are different to allow us to delineate the modalities better visually.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! From there, we use the point cloud dataset with Numpy on a top-down
    view to check the X-Y consistency, for example, with vector data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This lays an obvious overlay of the vector dataset onto our point cloud that
    opens up a world of possibility to make these two dataset talk:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/976f9ab5d7824cfb9f9dea1271e5e420.png)'
  prefs: []
  type: TYPE_IMG
- en: Integrating Vector and Raster datasets. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we continue our linkage by linking the vector dataset, reprojected, with
    spatial imagery:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This results in the visualization, which demands a bit of zoom, as expressed
    in the code, to better situate the fit of both datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5c29bf16a7b4ec9cdae4a01242c0d4c3.png)![](../Images/82ad186d23513f6900b83de121ce3837.png)'
  prefs: []
  type: TYPE_IMG
- en: Results of the integration of raster and vector datasets, with the LiDAR reprojection.
    ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: The exact process is repeated for the locations from Mappillary, with the code
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/840f727d1ae67895db02d1781f1c2c51.png)'
  prefs: []
  type: TYPE_IMG
- en: View of the points of interest from Mappillary. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'And finally, we want to overlay raster, vector, and point cloud modalities
    in one plot with Numpy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This little piece of code (careful on the shortcuts and smart tricks employed
    to condense the snippet) permits us to put a final note on the data integration
    of our various modalities.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c11cb794d94fa4d415fd7bee197ea75e.png)'
  prefs: []
  type: TYPE_IMG
- en: Shapefile and point cloud visualization with the DTM. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: We approach the end of our systematic approach!
  prefs: []
  type: TYPE_NORMAL
- en: 'By carefully applying these processing techniques, spatial data integration
    enables us to create a holistic representation of the environment, facilitating
    better decision-making and insights in a wide range of applications. Still, we
    must consider the last step: sharing the newly processed data.'
  prefs: []
  type: TYPE_NORMAL
- en: Step 7\. Data Sharing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/7079d325fbed4facb4a5d45a5733ee87.png)'
  prefs: []
  type: TYPE_IMG
- en: Step 7\. Data Sharing. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: Spatial data export is vital in the geospatial data workflow, allowing us to
    seamlessly share, visualize, and analyze 2D and 3D data modalities in established
    software. To this end, we can take a higher, almost aerial view to better situate
    the extent of data sharing impacts. I chose to relate to academia and publishing
    proofs of new scientific discoveries. Indeed, this process that I illustrate below
    is the key to an ethical and robust R&D cycle. As you can see, data export in
    standard formats, which we cover here, is the central link to data browsing before
    pushing automated solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/32b96685b5430dddcef3fd798a779b90.png)'
  prefs: []
  type: TYPE_IMG
- en: The 3D Data Sharing Workflow. We start with experiments to populate a database.
    This Database is then used to explore or export results to be filtered for publication.
    The results are then used to repopulate and update the 3D Database. ¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the export process must create various file formats suitable for applications
    and software environments. Each file format has its specificities, catering to
    different use cases and previously expressed requirements. For in-depth 3D data
    export, I propose to relate to these articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  prefs: []
  type: TYPE_NORMAL
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Python‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Understanding how we can do the same with vector and raster datasets is essential.
    As always, the simpler, the better: let us focus on these last exporting steps.
    To export the raster imagery, you can do the following with rasterio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'And concerning vector datasets, geopandas makes it a breeze to export the georeferenced
    and clipped result from our processing stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you can import these in a software such as QGIS or CloudCompare, which
    results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/94276d8e4de9c5ae70d26b086db476dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Point Cloud, 3D Voxel, 3D City Model, 3D DTM, Raster and vector dataset overlayed.
    They are integrated with the proposed methodology.¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: This is the perfect layering of 3D, Raster, and Vector datasets!
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have embarked on an exciting journey exploring the world of 3D data integration
    with Python. Throughout this comprehensive guide, we have uncovered the immense
    potential of combining various 3D data modalities, such as point clouds, meshes,
    city models, DSM, DTM, and voxels, to create a unified and holistic representation
    of the spatial environment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57473a23703dd40f51db1e9702411dd7.png)'
  prefs: []
  type: TYPE_IMG
- en: The workflow covered in this 3D Data Integration Guide.¬© [F. Poux](https://learngeodata.eu/)
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, I list below the key takeaways related to the seven steps that
    we covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a multi-modal coding environment in Python needs to accommodate a
    minimal number of robust libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When sourcing datasets, it is best to carefully consider available open datasets
    with clear licensing options through web interfaces that make it easy for you
    to gather relevant samples.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is an excellent practice to independently profile each modality and assess
    its main characteristics (CRS, precision, resolution, ‚Ä¶) through quick analysis
    schemes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mastering Coordinate Reference Systems and knowing how to go from one another
    and what a specific transformation implies is mandatory for scalable workflows
    with spatial datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-processing algorithms and techniques are often the keys between optimized
    and organized data assemblies and data warehouses with chaotic management systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: nD data visualization is paramount to a successful data integration workflow
    and demands that you carefully consider which dataset/ data modality acts as your
    canonical anchor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Sharing as a final stage permits ensuring a system from A to Z that considers
    practical and operational considerations, even in academia or R&D actions where
    production phases can be overlooked.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9d299f0b910437eb61e9167de8868a19.png)'
  prefs: []
  type: TYPE_IMG
- en: As I conclude this guide, I cannot help but be thrilled about the future of
    3D data processing. Currently, with Python‚Äôs versatility and the growing landscape
    of geospatial technologies, we have a large opening for new ways to better understand
    complex spatial phenomena (and act on them).
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, you can expect an even deeper guide to efficient algorithms, innovative
    visualization techniques, and seamless integration with cutting-edge technologies.
    By exploring what we can accomplish with integrated 3D data workflows, we pave
    the way for new applications, some of which coming soon to your laps. This makes
    me say that you are on a good track to shape the future of spatial analysis and
    visualization, transforming how we perceive and interact with the world around
    us.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C√°rdenas, Ivan L., Morales, Luis Rodrigoandr√©s, **Koeva**, Mila, Atun, Funda,
    & Pfeffer, Karin. (2023, August 31). Digital Twins for Physiological Equivalent
    Temperature Calculation Guide. Zenodo. [https://doi.org/10.5281/zenodo.83064562.](https://doi.org/10.5281/zenodo.83064562.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kumalasari, D.; **Koeva**, M.; Vahdatikhaki, F.; Petrova Antonova, D.; Kuffer,
    M. Planning Walkable Cities: Generative Design Approach towards Digital Twin Implementation.
    Remote Sens. 2023, 15, 1088\. [https://doi.org/10.3390/rs150410883.](https://doi.org/10.3390/rs150410883.)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rajan, V.; **Koeva**, M.; Kuffer, M.; Da Silva Mano, A.; Mishra, S. Three-Dimensional
    Modelling of Past and Present Shahjahanabadthrough Multi-Temporal Remotely Sensed
    Data. Remote Sens. 2023, 15, 2924\. [https://doi.org/10.3390/rs151129244.](https://doi.org/10.3390/rs151129244.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ying, Y.; **Koeva**, M.; Kuffer, M.; Zevenbergen, J. Toward 3D Property Valuation
    ‚Äî A Review of Urban 3D Modelling Methods for Digital Twin Creation. ISPRS Int.
    J. Geo-Inf. 2023, 12, 2\. [https://doi.org/10.3390/ijgi120100025.](https://doi.org/10.3390/ijgi120100025.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'La Guardia, M.; **Koeva**, M. Towards Digital Twinning on the Web: Heterogeneous
    3D Data Fusion Based on Open-Source Structure.Remote Sens. 2023, 15, 721\. [https://doi.org/10.3390/rs150307216.](https://doi.org/10.3390/rs150307216.)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Khawte, S. S., **Koeva**, M. N., Gevaert, C. M., Oude Elberink, S., and Pedro,
    A. A.: Digital Twin Creation For Slums In Brazil Based OnUAV Data, Int. Arch.
    Photogramm. Remote Sens. Spatial Inf. Sci., XLVIII-4/W4‚Äì2022, 75‚Äì81, [https://doi.org/10.5194/isprs-archives-XLVIII-4-W4-2022-75-2022,](https://doi.org/10.5194/isprs-archives-XLVIII-4-W4-2022-75-2022,)
    2022'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
