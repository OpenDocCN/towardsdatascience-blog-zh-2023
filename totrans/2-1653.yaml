- en: Pitfalls in Product Experimentation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 产品实验中的陷阱
- en: 原文：[https://towardsdatascience.com/pitfalls-in-product-experimentation-145d12bb139f](https://towardsdatascience.com/pitfalls-in-product-experimentation-145d12bb139f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pitfalls-in-product-experimentation-145d12bb139f](https://towardsdatascience.com/pitfalls-in-product-experimentation-145d12bb139f)
- en: '![](../Images/69c395fd20f7e52c33a86110cf56307b.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69c395fd20f7e52c33a86110cf56307b.png)'
- en: Image by pikisuperstar on Freepik (www.freepik.com)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 Freepik (www.freepik.com)
- en: Common to-not-do-lists often overlooked in product experimentation causing poor
    and unreliable results
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见的禁忌事项往往被忽视，这些在产品实验中导致结果不佳且不可靠
- en: '[](https://tanuwidjajaolivia.medium.com/?source=post_page-----145d12bb139f--------------------------------)[![Olivia
    Tanuwidjaja](../Images/52a56de28da9b782b57f1c3928655cfb.png)](https://tanuwidjajaolivia.medium.com/?source=post_page-----145d12bb139f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----145d12bb139f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----145d12bb139f--------------------------------)
    [Olivia Tanuwidjaja](https://tanuwidjajaolivia.medium.com/?source=post_page-----145d12bb139f--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://tanuwidjajaolivia.medium.com/?source=post_page-----145d12bb139f--------------------------------)[![Olivia
    Tanuwidjaja](../Images/52a56de28da9b782b57f1c3928655cfb.png)](https://tanuwidjajaolivia.medium.com/?source=post_page-----145d12bb139f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----145d12bb139f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----145d12bb139f--------------------------------)
    [Olivia Tanuwidjaja](https://tanuwidjajaolivia.medium.com/?source=post_page-----145d12bb139f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----145d12bb139f--------------------------------)
    ·8 min read·Jan 17, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----145d12bb139f--------------------------------)
    ·8分钟阅读·2023年1月17日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: We all know product experimentation is important, and **its benefits have largely
    been proven by organizations,** enabling data-driven decisions on products, features,
    and processes. [Google was testing 40 shades of blue](https://bambrick.com.au/blog/google-increased-revenue-200-million-just-finding-perfect-shade-blue/)
    on a link in the search results, and the right blue shade led to 200M in revenue.
    [Booking.com has acknowledged](https://hbr.org/2020/03/building-a-culture-of-experimentation)
    the scaling and transformation of the organization were made possible by numerous
    testing and experiments conducted there.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道产品实验很重要，**其好处已经被许多组织证明**，它使得基于数据的产品、功能和流程决策成为可能。[谷歌测试了40种蓝色](https://bambrick.com.au/blog/google-increased-revenue-200-million-just-finding-perfect-shade-blue/)，而正确的蓝色使其收入增加了2亿美元。[Booking.com
    已经承认](https://hbr.org/2020/03/building-a-culture-of-experimentation) 组织的扩展和转型是通过在这里进行的众多测试和实验得以实现的。
- en: However, product experiments, like any other statistical testing or experimentation,
    **are prone to pitfalls**. These are design and/or execution flaws, which might
    be hidden or unsuspected throughout the process. It is the duty of the data team
    — Product Data Analysts/Data Scientists —to guardrail experimentations execution
    and analysis to get reliable results. And hence it is important to understand
    the common pitfalls and how to treat them, as they might mislead the analysis
    results and conclusion.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，产品实验和其他统计测试或实验一样，**容易出现陷阱**。这些陷阱可能是设计和/或执行上的缺陷，在整个过程中可能被隐藏或未被察觉。数据团队——产品数据分析师/数据科学家——有责任保障实验执行和分析的可靠性。因此，了解常见陷阱及其处理方式非常重要，因为这些陷阱可能误导分析结果和结论。
- en: If the experiment is not configured and analysed properly, it might lead to
    poor and unreliable results, defeating the initial purpose of the experiment —
    which is for testing out the treatments and gauging the impact.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果实验没有被正确配置和分析，可能会导致结果不佳且不可靠，违背了实验最初的目的——即测试处理方法并评估其影响。
- en: Configuration pitfalls
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置陷阱
- en: Before looking into the statistical strategy and analysis, it is essential to
    ensure **the** **planning and designing of the overall experimentation** are done
    right. While the things here seem basic, there is a high chance of it being overlooked
    (*again, as it is so basic*) and eventually making us miss out on the experiment
    if not done properly.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看统计策略和分析之前，确保**整体实验的规划和设计**是正确的至关重要。尽管这些看起来很基础，但很有可能被忽视（*再说一次，因为它非常基础*），如果处理不当，最终会使我们错过实验。
- en: '**Optimizing for the wrong metrics.** Metrics selection drives the overall
    decision of whether the treatment changes are being rolled out or not. As a rule
    of thumb, [a metric for an experiment is ideally **relevant to business** and
    **movable/impacted by the treatment** given](https://medium.com/geekculture/selecting-the-right-metrics-to-be-tracked-5a427b94b725).
    (1) *If this metric goes up/down, would you be happy?* (2) *Suppose you’re a user
    that is given the treatment, would you do or not do activities that will impact
    the metric?*'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化错误指标。** 指标选择决定了处理变更是否被推广的整体决策。作为经验法则，[实验的指标理想上应该是**与业务相关**且**受处理影响/可移动**的](https://medium.com/geekculture/selecting-the-right-metrics-to-be-tracked-5a427b94b725)。
    (1) *如果这个指标上升/下降，你会感到高兴吗？* (2) *假设你是接受了处理的用户，你会做或不做会影响指标的活动吗？*'
- en: '**Not maximizing the variations potential.** In the theoretical world, A/B
    testing (or split testing) is a common term used. It’s [comparing **two versions**
    of something to figure out which performs better](https://hbr.org/2017/06/a-refresher-on-ab-testing).
    In the practical world, this can be further extended to more than two versions
    ([**A/B/n testing**](https://www.optimizely.com/optimization-glossary/abn-testing/))
    or testing for a combination of variables ([**multivariate testing**](https://www.optimizely.com/optimization-glossary/multivariate-testing/)).
    Having more variations is great to **maximize resource utilization** and the **possibility
    of getting the best decision option** outof the experiment. They come with some
    [side statistical effects](/a-practical-guide-to-product-experimentation-f9a6252c0e9e)
    (i.e increase in sample size requirement; familywise error rate), but it’s still
    something worth exploring.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未充分利用变体潜力。** 在理论世界中，A/B 测试（或分割测试）是一个常用术语。它是[比较**两个版本**以找出哪个表现更好](https://hbr.org/2017/06/a-refresher-on-ab-testing)。在实际世界中，这可以进一步扩展到两个以上的版本（[**A/B/n
    测试**](https://www.optimizely.com/optimization-glossary/abn-testing/)）或测试变量组合（[**多变量测试**](https://www.optimizely.com/optimization-glossary/multivariate-testing/)）。拥有更多的变体对于**最大化资源利用**和**获取最佳决策选项的可能性**非常有帮助。它们带来了一些[副统计效应](/a-practical-guide-to-product-experimentation-f9a6252c0e9e)（例如样本量需求增加；家庭误差率），但仍然值得探索。'
- en: '**Overlapping experiments.** There can be numerous experiments happening at
    the same time in the organization. Problems can occur when these different experiments
    are running on similar features as **they could interfere with each other** —
    affecting the same metrics on an overlapping subset of users. The metric increase
    from the experiment might actually not come from the treatment alone, but from
    another treatment from the overlapping experiment. **Organization-wide coordination
    (from experiment timing to targeting assignment)** can help to minimize this issue.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重叠实验。** 在组织内可能会同时进行许多实验。当这些不同的实验在相似的特征上运行时，可能会出现问题，因为**它们可能会相互干扰**——影响到重叠用户子集上的相同指标。实验的指标增加可能实际上不是单纯来自于处理本身，而是来自于重叠实验中的另一个处理。**全组织协调（从实验时间到目标分配）**可以帮助最小化这个问题。'
- en: '**Going directly to full rollout.** It might be tempting to run the experiment
    in full rollout right away to minimize the time needed and get the result as soon
    as possible. However, experiment changes are still “product releases” and things
    can go wrong in between. It is recommended to **approach the experiment with a
    staged rollout** to reduce the risk in these releases.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直接全面推广。** 可能会很诱人立即将实验全面推广，以最小化所需时间并尽快获得结果。然而，实验变更仍然是“产品发布”，中间可能会出现问题。建议**以分阶段推广的方式进行实验**，以降低这些发布的风险。'
- en: '![](../Images/c429368f7fb0b25fcd5ff0b3aff3f6b2.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c429368f7fb0b25fcd5ff0b3aff3f6b2.png)'
- en: Image by pch.vector on Freepik (www.freepik.com)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 pch.vector 提供于 Freepik (www.freepik.com)
- en: Having a [**product experiment platform**](https://engineering.atspotify.com/2020/10/spotifys-new-experimentation-platform-part-1/)
    can be a potential solution to prevent these pitfalls, ensuring standardized metrics
    and best practices on the process are implemented.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个[**产品实验平台**](https://engineering.atspotify.com/2020/10/spotifys-new-experimentation-platform-part-1/)可以成为预防这些陷阱的潜在解决方案，确保实施标准化的指标和最佳实践。
- en: Statistical pitfalls
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计陷阱
- en: Product experiment is [the process of continually ***testing hypotheses*** for
    ways to improve your product](https://www.hotjar.com/product-experimentation/).
    Hypothesis testing itself is essentially a form of **statistical inference**,
    and hence there are statistical principles to be followed in order to do product
    experiments properly.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 产品实验是[持续***测试假设***以改进您的产品的过程](https://www.hotjar.com/product-experimentation/)。假设测试本身本质上是一种**统计推断**，因此需要遵循统计原则以正确进行产品实验。
- en: Depending on the product context and use cases, experiments might be statistically
    more complicated and require some extra measures to be looked out for. Below are
    some of the common ones.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据产品的背景和使用情况，实验可能在统计上更复杂，需要注意一些额外的措施。以下是一些常见的问题。
- en: Experiment “peeking”
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验“窥探”
- en: When running an experiment, it is quite tempting to check on the results shortly
    straight away after the deployment, and draw (premature) conclusions, especially
    if the results look good or aligned with our hypothesis. This is called the experiment
    “peeking” problem.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行实验时，直接在部署后很快查看结果并得出（过早的）结论是非常诱人的，特别是当结果看起来良好或与我们的假设一致时。这被称为实验“窥探”问题。
- en: Experiment “peeking” occurs when **the outcome is erroneously called *before*
    the proper sample size has been reached**. Even if the initial results show statistical
    significance, the inference might be **coming purely out of chance** and is a
    flawed inference if drawn before reaching the proper sample size.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 实验“窥探”发生在**结果在达到适当的样本大小之前被错误地宣布*。即使初始结果显示统计显著性，这种推断也可能是**纯粹出于偶然**，如果在达到适当样本大小之前做出的推断，则是有缺陷的。
- en: The ideal way to tackle this is to confirm the sample size at the beginning
    of the test and **defer any conclusion before that sample value is reached**.
    However, in some cases reaching enough sample size might take too long and become
    not practical. One technique to explore in this case is [**sequential testing**](/unlocking-peeking-in-ab-tests-7847b9c2f6bb),
    where the final sample size is dynamic to the data we observe during the test.
    So if we observe more extreme results at the start, the test can be ended earlier.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的理想方法是**在测试开始时确认样本大小，并在达到该样本值之前**推迟任何结论。然而，在某些情况下，达到足够的样本大小可能需要很长时间，并且变得不实际。在这种情况下，可以探索的一种技术是[**顺序测试**](/unlocking-peeking-in-ab-tests-7847b9c2f6bb)，其中最终样本大小根据我们在测试过程中观察到的数据而动态调整。因此，如果我们在开始时观察到更极端的结果，测试可以提前结束。
- en: '![](../Images/c990da67fe40299b430a591647d740e5.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c990da67fe40299b430a591647d740e5.png)'
- en: Photo by [Hexandcube](https://unsplash.com/@hexandcube?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Hexandcube](https://unsplash.com/@hexandcube?utm_source=medium&utm_medium=referral)拍摄，图片来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Not setting the right null hypothesis
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 没有设定正确的零假设
- en: In product experiments, we set up a [null hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis)
    to be tested — rejected or not rejected — with the treatment given. A common classic
    null hypothesis is *no difference in the variable of interests* between the datasets
    (control group vs treatment group) analyzed. This is called a [**superiority test**](https://www.analytics-toolkit.com/glossary/superiority-test/),
    in which we expect some **superior discrepancy between the treatment and control
    groups —** expecting a positive change in thevariable of interest (e.g. means,
    proportions) of the treatment group in order to proceed with implementing the
    treatment.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在产品实验中，我们设定一个[**零假设**](https://en.wikipedia.org/wiki/Null_hypothesis)进行测试——即是否被拒绝——并给予处理。一个常见的经典零假设是*在分析的数据集（对照组与处理组）之间没有兴趣变量的差异*。这被称为[**优越性测试**](https://www.analytics-toolkit.com/glossary/superiority-test/)，其中我们期望处理组和对照组之间有一些**优越的差异——**期待处理组在兴趣变量（例如均值、比例）上有正向变化，以便继续实施处理。
- en: An alternative for this is the [**non-inferiority test**](https://blog.analytics-toolkit.com/2017/case-non-inferiority-designs-ab-testing/),
    in which we have reason to implement a tested variant as long as it is not substantially
    worse than the control. The null hypothesis in this test would be something along
    the line of “*the variable of interest in the variant is X% worse than the control,
    or more*”. In this test, we are good to proceed with implementing the treatment
    even if it is performing worse than the control, as long as it is still within
    the “margin of caring” range.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这方面的一个替代方法是[**非劣性检验**](https://blog.analytics-toolkit.com/2017/case-non-inferiority-designs-ab-testing/)，在这种检验中，只要测试变体没有比对照组差得太多，我们就有理由实施该变体。该检验中的原假设是“*变体中的兴趣变量比对照组差X%或更多*”。在此检验中，只要表现不如对照组的变体仍在“可接受范围”内，我们可以继续实施该处理。
- en: '![](../Images/deffec2475ea5accd4f8115c8a68f81e.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/deffec2475ea5accd4f8115c8a68f81e.png)'
- en: Illustration of superiority vs non-inferiority test (Image by Author)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 优越性与非劣性检验的示意图（图示作者）
- en: This non-inferiority test can be useful for changes that might cause some negative
    impacts (i.e testing the impact of removing a feature on booking conversion) or
    to check secondary metrics on an experiment that we can accept decreasing to a
    certain threshold for an increase in the primary metric.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 非劣性检验对于可能带来一些负面影响的变更（即测试移除某个功能对预订转化的影响）或检查实验中的次要指标是否可以接受降低到某个阈值以提高主要指标，都是有用的。
- en: Contamination
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 污染
- en: The commonly used hypothesis tests — z-test and t-test — runs under the [assumption](https://www.mathworks.com/help/stats/hypothesis-test-assumptions.html)
    that the data are ***independently*** sampled from a normal distribution. While
    in most cases this can be easily fulfilled by ensuring randomized non-duplicate
    assignments, it can be tricky in some cases.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的假设检验——z检验和t检验——假设数据是从一个**独立**的正态分布中抽样的。[假设](https://www.mathworks.com/help/stats/hypothesis-test-assumptions.html)大多数情况下，通过确保随机化和非重复分配可以很容易地满足这一条件，但在某些情况下可能会比较棘手。
- en: For example, [experimenting with delivery pricing in an on-demand delivery app](https://medium.com/@DoorDash/switchback-tests-and-randomized-experimentation-under-network-effects-at-doordash-f1d938ab7c2a).
    Though treatment is isolated to selected users, there might be some impact on
    the non-treatment group as well, as the delivery fleet is shared across the area
    (instead of per customer). This is called contamination or network effect, in
    which **different treatments of an experiment interfere with each other.**
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，关于[在按需配送应用中实验配送定价](https://medium.com/@DoorDash/switchback-tests-and-randomized-experimentation-under-network-effects-at-doordash-f1d938ab7c2a)。虽然处理是针对选定的用户，但由于配送车队在区域内共享（而不是按客户分配），也可能对非处理组产生影响。这被称为污染或网络效应，其中**实验的不同处理相互干扰**。
- en: One common solution is to utilize a “**switchback experiment**”. In this case,
    all the users in the experiment will be exposed to the same experience where randomization
    happens on a time interval and region (or other granularity where the treatment
    effect can be isolated). The metrics of interest will then be averaged across
    time intervals.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的解决方案是使用“**切换实验**”。在这种情况下，实验中的所有用户将接触到相同的体验，随机化发生在时间间隔和区域（或其他可以隔离处理效应的粒度）上。然后，感兴趣的指标将跨时间间隔进行平均。
- en: Multiple comparison problem
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重比较问题
- en: The multiple-comparison problem is a well-known issue in statistics. It occurs
    when one **considers a set of statistical inferences simultaneously** or infers
    a subset of parameters selected based on the observed values.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 多重比较问题是统计学中的一个著名问题。当**同时考虑一组统计推断**或推断基于观察值选择的参数子集时，就会发生这种问题。
- en: For example, we’re experimenting with the new UI page (treatment) compared to
    the old UI page (control) of an e-commerce platform. Instead of mainly testing
    on the booking conversion impact, we’re also checking it against numerous other
    (not-so-relevant) metrics like search-bar clicks, per-categories clicks, session
    duration, coupon usage rate, and so on. **As more attributes are compared, it
    becomes increasingly likely that the treatment and control groups will appear
    to differ on at least one attribute due to random** [**sampling error**](https://en.wikipedia.org/wiki/Sampling_error)
    **alone.**
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们正在对电子商务平台的新UI页面（处理组）与旧UI页面（对照组）进行实验。除了主要测试预订转化的影响外，我们还检查了许多其他（不太相关的）指标，如搜索框点击次数、每个类别的点击次数、会话时长、优惠券使用率等。**随着比较的属性增多，仅由于随机**
    [**抽样误差**](https://en.wikipedia.org/wiki/Sampling_error) **，处理组和对照组在至少一个属性上出现差异的可能性也越来越大。**
- en: To control this problem statistically, there are some approaches that can be
    used, like [**Bonferroni correction**](https://en.wikipedia.org/wiki/Bonferroni_correction)
    which lowers the p-value threshold that is needed to call a result significant.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在统计上控制这个问题，可以采用一些方法，例如 [**邦费罗尼校正**](https://en.wikipedia.org/wiki/Bonferroni_correction)，它降低了判断结果显著性所需的p值阈值。
- en: '![](../Images/df9a83e8e6979f626cb504dec527e030.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df9a83e8e6979f626cb504dec527e030.png)'
- en: Photo by [Clay Banks](https://unsplash.com/@claybanks?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Clay Banks](https://unsplash.com/@claybanks?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。
- en: Taking it to the next level
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升到一个新层次
- en: The common pitfalls above aside, product experiment results might still be not
    very ideal and reliable. There are still some caveats to consider and keep in
    mind when analyzing the experiment results.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 上述常见陷阱之外，产品实验结果可能仍然不够理想和可靠。在分析实验结果时，还需考虑和牢记一些警示点。
- en: '**Novelty effect**. When some changes are introduced in the product, users
    are typically curious to explore more, and hence drive the change in business
    metrics. However, this effect is temporary as the interest might normalize after
    a while as the change becomes less novel. With this in mind, it is often a good
    idea to establish a “**burn-in period**” in experiments and ignore the data collected
    in the initial period of the experiment.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新颖效应**。当产品中引入一些变化时，用户通常会对这些变化感到好奇，从而推动业务指标的变化。然而，这种效应是暂时的，因为兴趣可能会随着变化变得不再新颖而逐渐趋于正常。考虑到这一点，在实验中建立“**烧入期**”通常是一个好主意，并忽略实验初期收集的数据。'
- en: '**Consider seasonality**. Some product/feature usage might have a certain seasonal
    lifecycle that might impact experiments. For example, an entertainment site might
    see much higher traffic on weekends compared to weekdays. When running an experiment
    on the product, we can try to cover both weekends and weekdays to get holistic
    estimates of the treatment impact.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**考虑季节性**。某些产品/功能的使用可能有一定的季节性生命周期，这可能会影响实验。例如，娱乐网站在周末的流量可能会显著高于工作日。在进行产品实验时，我们可以尽量覆盖周末和工作日，以获得治疗影响的全面估计。'
- en: There is no single perfect easy way to run a product experiment, as it varies
    by population and treatment contexts. Also, not every real-world impact can be
    easily quantifiable. But still, ***product experiments done in a statistically
    right way can help bring scientific reasoning to a business decision***. It can
    be considered hand-in-hand with user research and product/business sense grained
    in the product domain experts — you as the PM or Data Analyst.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一种完美简单的方法来进行产品实验，因为它因人群和治疗背景的不同而有所变化。此外，并非所有现实世界的影响都可以轻易量化。但仍然，***以统计学正确的方式进行的产品实验可以帮助为业务决策提供科学依据***。这可以与用户研究和产品/业务领域专家的洞察（如你作为PM或数据分析师）相辅相成。
