["```py\ndef get_model():\n    return tf.keras.Sequential([\n        tf.keras.layers.InputLayer(input_shape=(28, 28)),\n        tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n        tf.keras.layers.Conv2D(\n          filters=12, kernel_size=(3, 3), activation=\"relu\"\n        ),\n        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        tf.keras.layers.Conv2D(\n          filters=24, kernel_size=(3, 3), activation=\"relu\"\n        ),\n        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n    ])\n\nmodel_baseline = get_model()\n\nmodel_baseline.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel_baseline.fit(\n    x_train, \n    y_train, \n    epochs=1,\n)\n```", "```py\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_baseline)\nmodel_baseline_tflite = converter.convert()\n\nwith open(\"model_baseline.tflite\", \"wb\") as f:\n    f.write(model_baseline_tflite)\n```", "```py\ndef evaluate_tflite_model(filename, x_test, y_test):\n    interpreter = tf.lite.Interpreter(model_path=filename)\n    interpreter.allocate_tensors()\n    input_index = interpreter.get_input_details()[0][\"index\"]\n    output_index = interpreter.get_output_details()[0][\"index\"]\n    y_pred = []\n    for test_image in x_test:\n        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n        interpreter.set_tensor(input_index, test_image)\n        interpreter.invoke()\n        output = interpreter.tensor(output_index)\n        y_pred.append(output()[0][0] >= 0.5)\n    return (y_pred == np.array(y_test)).mean()\n\ndef get_gzipped_model_size(file):\n    _, zipped_file = tempfile.mkstemp(\".zip\")\n    with zipfile.ZipFile(\n      zipped_file, \"w\", compression=zipfile.ZIP_DEFLATED\n    ) as f:\n        f.write(file)\n    return os.path.getsize(zipped_file)\n```", "```py\nmodel_baseline_acc = evaluate_tflite_model(\n    \"model_baseline.tflite\", x_test, y_test\n)\nmodel_baseline_size = get_gzipped_model_size(\"model_baseline.tflite\")\n\nprint(f\"Baseline accuracy: {model_baseline_acc}\")\nprint(f\"Baseline size: {model_baseline_size}\")\n```", "```py\nBaseline accuracy: 0.9852449095827994\nBaseline size: 14303\n```", "```py\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_baseline)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nmodel_quantized_tflite = converter.convert()\n\nwith open(\"model_quantized.tflite\", \"wb\") as f:\n    f.write(model_quantized_tflite)\n```", "```py\nmodel_quantized_acc = evaluate_tflite_model(\n    \"model_quantized.tflite\", x_test, y_test\n)\nmodel_quantized_size = get_gzipped_model_size(\"model_quantized.tflite\")\n\nprint(f\"Quantized accuracy: {model_quantized_acc}\")\nprint(f\"Quantized size: {model_quantized_size}\")\n```", "```py\nQuantized accuracy: 0.98526270824434\nQuantized size: 7483\n```", "```py\nbatch_size = 128\nepochs = 2\nvalidation_split = 0.1\n\nx_train_size = x_train.shape[0] * (1 - validation_split)\nend_step = np.ceil(x_train_size / batch_size).astype(np.int32) * epochs\n\npruning_params = {\n    \"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.50,\n        final_sparsity=0.80,\n        begin_step=0,\n        end_step=end_step,\n    )\n}\n```", "```py\nmodel_pruned = tfmot.sparsity.keras.prune_low_magnitude(\n  model_baseline, \n  **pruning_params,\n)\n\nmodel_pruned.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel_pruned.fit(\n    x_train, \n    y_train, \n    epochs=epochs,\n    validation_split=validation_split,\n    callbacks=[tfmot.sparsity.keras.UpdatePruningStep()],\n)\n\nmodel_pruned = tfmot.sparsity.keras.strip_pruning(model_pruned)\n```", "```py\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_pruned)\nmodel_pruned_tflite = converter.convert()\n\nwith open(\"model_pruned.tflite\", \"wb\") as f:\n    f.write(model_pruned_tflite)\n\nmodel_pruned_acc = evaluate_tflite_model(\n  \"model_pruned.tflite\", x_test, y_test\n)\nmodel_pruned_size = get_gzipped_model_size(\"model_pruned.tflite\")\n\nprint(f\"Pruned accuracy: {model_pruned_acc}\")\nprint(f\"Pruned size: {model_pruned_size}\")\n```", "```py\nPruned accuracy: 0.9840168019364943\nPruned size: 5862\n```", "```py\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_pruned)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nmodel_pruned_quantized_tflite = converter.convert()\n\nwith open(\"model_pruned_quantized.tflite\", \"wb\") as f:\n    f.write(model_pruned_quantized_tflite)\n\nmodel_pruned_quantized_acc = evaluate_tflite_model(\n  \"model_pruned_quantized.tflite\", x_test, y_test\n)\nmodel_pruned_quantized_size = get_gzipped_model_size(\n  \"model_pruned_quantized.tflite\"\n)\n\nprint(f\"Pruned + Quantized accuracy: {model_pruned_quantized_acc}\")\nprint(f\"Pruned + Quantized size: {model_pruned_quantized_size}\")\n```", "```py\nPruned + Quantized accuracy: 0.9840168019364943\nPruned + Quantized size: 3996\n```"]