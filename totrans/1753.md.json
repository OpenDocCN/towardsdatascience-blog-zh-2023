["```py\nfrom transformers import AutoModelForCausalLM,AutoTokenizer\nimport torch\nfrom accelerate import Accelerator\n```", "```py\nmodel_name = \"meta-llama/Llama-2-7b-hf\"\nhf_key = \"insertyourkeyhere\"\n```", "```py\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=0, load_in_8bit=True, token=hf_key)\n```", "```py\ntokeniser = AutoTokenizer.from_pretrained(model_name, token=hf_key)\nprompt = \"A great hobby to have is \"\ntoks = tokeniser(prompt, return_tensors=\"pt\")\n```", "```py\n%%time\nres = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\nres\n# OUPUT\n# CPU times: user 7.47 s, sys: 1.17 s, total: 8.64 s\n# Wall time: 16.4 s\n```", "```py\ntokeniser.batch_decode(res)\n# OUTPUT\n# ['<s> A great hobby to have is 3D printing.\\nYou can make whatever you want in 3D']\n```", "```py\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=0, torch_dtype=torch.bfloat16)\n```", "```py\n%%time\nres = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\nres\n# OUTPUT\n# CPU times: user 1.65 s, sys: 440 ms, total: 2.09 s\n# Wall time: 4.7 s\n```", "```py\ntokeniser.batch_decode(res)\n# OUTPUT\n# ['<s> A great hobby to have is 3D printing. Itâ€™s a fun way to create new things,']\n```", "```py\nmodel_name = 'TheBloke/Llama-2-7b-Chat-GPTQ'\n```", "```py\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=0, torch_dtype=torch.float16)\n```", "```py\ntokeniser = AutoTokenizer.from_pretrained(model_name, token=hf_key)\nprompt = \"A great hobby to have is \"\ntoks = tokeniser(prompt, return_tensors=\"pt\")\n```", "```py\n%%time\nres = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\nres\n# OUTPUT\n# CPU times: user 1.44 s, sys: 351 ms, total: 1.79 s\n# Wall time: 4.33 s\n```", "```py\ntokeniser.batch_decode(res)\n# OUTPUT\n# ['<s> A great hobby to have is 3D printing.\\n 3D printing is a fascinating hob']\n```", "```py\nmodel_name = 'TheBloke/Llama-2-13B-GPTQ'\n```", "```py\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=0, torch_dtype=torch.float16)\n```", "```py\ntokeniser = AutoTokenizer.from_pretrained(model_name, token=hf_key)\nprompt = \"A great hobby to have is \"\ntoks = tokeniser(prompt, return_tensors=\"pt\")\n```", "```py\n%%time\nres = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\nres\n# OUTPUT\n# CPU times: user 1.45 s, sys: 167 ms, total: 1.61 s\n# Wall time: 3.22 s\n```", "```py\ntokeniser.batch_decode(res)\n# OUTPUT\n# ['<s> A great hobby to have is 3D printing. It is a great way to create things that you want']\n```"]