- en: 'Finding Temporal Patterns in Twitter Posts: Exploratory Data Analysis with
    Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Twitter帖子中寻找时间模式：使用Python进行探索性数据分析
- en: 原文：[https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699](https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699](https://towardsdatascience.com/finding-temporal-patterns-in-twitter-posts-exploratory-data-analysis-with-python-8aac618c8699)
- en: Clustering of Twitter data with Python, K-Means, and t-SNE
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Python、K-Means和t-SNE对Twitter数据进行聚类
- en: '[](https://dmitryelj.medium.com/?source=post_page-----8aac618c8699--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----8aac618c8699--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8aac618c8699--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8aac618c8699--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----8aac618c8699--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page-----8aac618c8699--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----8aac618c8699--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8aac618c8699--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8aac618c8699--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----8aac618c8699--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8aac618c8699--------------------------------)
    ·17 min read·May 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8aac618c8699--------------------------------)
    ·17分钟阅读·2023年5月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3732b5836870992d47e361c0c7dd91e3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3732b5836870992d47e361c0c7dd91e3.png)'
- en: Tweet clusters t-SNE visualization, Image by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Tweet clusters t-SNE可视化，图像由作者提供
- en: 'In the article “[What People Write about Climate](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906)”
    I analyzed Twitter posts using natural language processing, vectorization, and
    clustering. Using this technique, it is possible to find distinct groups in unstructured
    text data, for example, to extract messages about ice melting or about electric
    transport from thousands of tweets about climate. During the processing of this
    data, another question arose: what if we could apply the same algorithm not to
    the messages themselves but to the time when those messages were published? This
    will allow us to analyze *when* and *how often* different people make posts on
    social media. It can be important not only from sociological or psychological
    perspectives but, as we will see later, also for detecting bots or users sending
    spam. Last but not least, almost everybody is using social platforms nowadays,
    and it is just interesting to learn something new about *us.* Obviously, the same
    algorithm can be used not only for Twitter posts but for any media platform.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在文章 “[人们对气候的看法](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906)”
    中，我使用自然语言处理、向量化和聚类分析了Twitter帖子。通过这种技术，可以在非结构化文本数据中找到不同的群体，例如，从数千条关于气候的推文中提取有关冰川融化或电动交通的消息。在处理这些数据时，另一个问题出现了：如果我们将相同的算法应用于这些消息发布的时间而不是消息本身会怎样？这将使我们能够分析*何时*和*多频繁*不同的人在社交媒体上发帖。这不仅从社会学或心理学的角度重要，正如我们稍后将看到的，还可以用来检测机器人或发送垃圾信息的用户。最后但同样重要的是，几乎每个人现在都在使用社交平台，因此了解有关*我们*的新事物是很有趣的。显然，相同的算法不仅可以用于Twitter帖子，还可以用于任何媒体平台。
- en: Methodology
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法论
- en: 'I will use mostly the same approach as described in the first part about Twitter
    data analysis. Our data processing pipeline will consist of several steps:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用与第一部分Twitter数据分析中描述的相似的方法。我们的数据处理流程将包括几个步骤：
- en: Collecting tweets including the specific hashtag and saving them in a CSV file.
    This was already done in the previous article, so I will skip the details here.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集包含特定标签的推文并将其保存到CSV文件中。这在之前的文章中已经完成，所以我在这里跳过详细说明。
- en: Finding the general properties of the collected data.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到收集的数据的一般属性。
- en: Calculating embedding vectors for each user based on the time of their posts.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用户发帖的时间计算每个用户的嵌入向量。
- en: Clustering the data using the K-Means algorithm.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用K-Means算法对数据进行聚类。
- en: Analyzing the results.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析结果。
- en: Let’s get started.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 1\. Loading the data
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 加载数据
- en: 'I will be using the [Tweepy](https://github.com/tweepy/tweepy) library to collect
    Twitter posts. More details can be found in the [first part](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906);
    here I will only publish the source code:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用[Tweepy](https://github.com/tweepy/tweepy)库来收集Twitter帖子。更多细节可以在[第一部分](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906)中找到；这里我只发布源代码：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Using this code, we can get all Twitter posts with a specific hashtag, made
    within the last 7 days. A **hashtag** is actually our search query, we can find
    posts about climate, politics, or any other topic. Optionally, a **language code**
    allows us to search posts in different languages. Readers are welcome to do extra
    research on their own; for example, it can be interesting to compare the results
    between English and Spanish tweets.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这段代码，我们可以获取在过去7天内发布了特定标签的所有Twitter帖子。**标签**实际上是我们的搜索查询，我们可以找到有关气候、政治或任何其他主题的帖子。可选地，**语言代码**允许我们搜索不同语言的帖子。读者可以自行进行额外的研究；例如，比较英语和西班牙语推文之间的结果可能会很有趣。
- en: 'After the CSV file is saved, let’s load it into the dataframe, drop the unwanted
    columns, and see what kind of data we have:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在保存CSV文件后，让我们将其加载到数据框中，删除不需要的列，并查看我们拥有的数据：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the same way, as in the first part, I was getting Twitter posts with the
    hashtag “#climate”. The result looks like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与第一部分相同，我获取了带有“#climate”标签的Twitter帖子。结果如下：
- en: '![](../Images/8cc93e1f47c6e1916488f9b693980bee.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cc93e1f47c6e1916488f9b693980bee.png)'
- en: 'We actually don’t need the text or user id, but it can be useful for “debugging”,
    to see how the original tweet looks. For future processing, we will need to know
    the day, time, and hour of each tweet. Let’s add columns to the dataframe:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上不需要文本或用户ID，但它对于“调试”是有用的，可以查看原始推文的样子。为了未来的处理，我们需要知道每条推文的日期、时间和小时。让我们向数据框添加列：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can easily verify the results:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松验证结果：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/6c5c6b124efd20ee663e207a8c46bce1.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c5c6b124efd20ee663e207a8c46bce1.png)'
- en: Now we have all the needed information, and we are ready to go.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了所有需要的信息，可以开始进行分析。
- en: 2\. General Insights
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 一般见解
- en: 'As we could see from the last screenshot, 199,278 messages were loaded; those
    are messages with a “#Climate” hashtag, which I collected within several weeks.
    As a warm-up, let’s answer a simple question: how many *messages per day* about
    climate were people posting on average?'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从最后的截图中我们可以看到，已加载了199,278条消息；这些是带有“#Climate”标签的消息，我在几周内收集的。作为热身，让我们回答一个简单的问题：人们平均每天发布多少*关于气候的消息*？
- en: 'First, let’s calculate the total number of days and the total number of users:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们计算总天数和用户总数：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As we can see, the data was collected over 46 days, and in total, 79,985 Twitter
    users posted (or reposted) at least one message with the hashtag “#Climate” during
    that time. Obviously, we can only count users who made at least one post; alas,
    we cannot get the number of *readers* this way.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，数据收集了46天，总共有79,985名Twitter用户在这段时间内发布了（或转发了）至少一条带有“#Climate”标签的消息。显然，我们只能计算至少发布过一条消息的用户；遗憾的是，我们无法通过这种方式获得*读者*的数量。
- en: 'Let’s find the **number of messages per day** for each user. First, let''s
    group the dataframe by user name:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们找出每个用户的**每日消息数量**。首先，我们按用户名对数据框进行分组：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The “size” column gives us the number of messages every user sent. I also added
    the “size_per_day” column, which is easy to calculate by dividing the total number
    of messages by the total number of days. The result looks like this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: “size”列显示了每个用户发送的消息数量。我还添加了“size_per_day”列，通过将消息总数除以总天数即可轻松计算。结果如下：
- en: '![](../Images/f0f72f6a06e8704f69f2bca72e646c10.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0f72f6a06e8704f69f2bca72e646c10.png)'
- en: 'We can see that the most active users are posting up to 18 messages per day,
    and the most inactive users posted only 1 message within this 46-day period (1/46
    = 0,0217). Let’s draw a **histogram** using NumPy and [Bokeh](https://github.com/bokeh/bokeh):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，最活跃的用户每天最多发布18条消息，而最不活跃的用户在这46天的时间里只发布了1条消息（1/46 = 0.0217）。让我们使用NumPy和[Bokeh](https://github.com/bokeh/bokeh)绘制**直方图**：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output looks like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](../Images/6c681d12d60108f5fb01f3d958b16705.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c681d12d60108f5fb01f3d958b16705.png)'
- en: Messages per day distribution, Image by author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 每日消息数量分布，图像由作者提供
- en: 'Interestingly, we can see only one bar. Of all 79,985 users who posted messages
    with the “#Climate” hashtag, almost all of them (77,275 users) sent, on average,
    less than a message per day. It looks surprising at first glance, but actually,
    how often do we post tweets about the climate? Honestly, I never did it in all
    my life. We need to zoom the graph a lot to see other bars on the histogram:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们只能看到一根柱子。在所有79,985名使用“#Climate”标签发布消息的用户中，几乎所有人（77,275名用户）的平均每天发送的消息不到一条。乍一看，这似乎很令人惊讶，但实际上，我们有多频繁地发布关于气候的推文呢？说实话，我一生中从未做过。我们需要将图表放大很多才能看到直方图上的其他柱子：
- en: '![](../Images/825861d365c0373497284a8e7a5701cf.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/825861d365c0373497284a8e7a5701cf.png)'
- en: Messages per day distribution with a higher zoom, Image by author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每天消息的分布情况（更高的缩放），图像由作者提供
- en: 'Only with this zoom level can we see that among all 79,985 Twitter users who
    posted something about “#Climate”, there are less than 100 “activists”, posting
    messages every day! Ok, maybe “climate” is not something people are making posts
    about daily, but is it the same with other topics? I created a helper function,
    returning the percentage of “active” users who posted more than N messages per
    day:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在这个缩放级别下，我们才能看到在所有79,985名关于“#Climate”发过消息的Twitter用户中，只有不到100名“活跃分子”每天发消息！好吧，也许“气候”不是人们每天发帖的内容，但其他话题是否也如此？我创建了一个辅助函数，返回每天发布超过N条消息的“活跃”用户的百分比。
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, using the same Tweepy code, I downloaded data frames for 6 topics from
    different domains. We can draw results with Bokeh:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用相同的Tweepy代码，我从不同领域下载了6个话题的数据框。我们可以用Bokeh绘制结果：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The results are interesting:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 结果很有趣：
- en: '![](../Images/fefbccf619e8c4e08665d8e803c97ed9.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fefbccf619e8c4e08665d8e803c97ed9.png)'
- en: Percentage of active users, who posted at least 1 message per day with a specific
    hashtag
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 每天发布至少1条消息的活跃用户百分比，使用特定标签
- en: The most popular hashtag here is “#Cats”. In this group, about 6.6% of users
    make posts daily. Are their cats just adorable, and they cannot resist the temptation?
    On the contrary, “#Humour” is a popular topic with a large number of messages,
    but the number of people who post more than one message per day is minimal. On
    more serious topics like “#War” or “#Politics”, about 1.5% of users make posts
    daily. And surprisingly, much more people are making daily posts about “#Space”
    compared to “#Humour”.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最受欢迎的标签是“#Cats”。在这个组中，大约6.6%的用户每天发帖。他们的猫只是太可爱了吗，无法抗拒诱惑？相反，“#Humour”是一个热门话题，消息量很大，但每天发多条消息的人数最少。在“#War”或“#Politics”这样的更严肃的话题中，大约1.5%的用户每天发帖。令人惊讶的是，相较于“#Humour”，更多人每天发布关于“#Space”的消息。
- en: 'To clarify these digits in more detail, let’s find the **distribution of the**
    **number of messages per user**; it is not directly relevant to message time,
    but it is still interesting to find the answer:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更详细地澄清这些数字，让我们找出**每个用户消息数量的分布**；虽然这与消息时间没有直接关系，但仍然有趣的是找到答案：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This method calculates the total number of messages posted by the most active
    users. The number itself can strongly vary for different topics, so I use percentages
    as both outputs. With this function, we can compare results for different hashtags:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法计算了最活跃用户发布的消息总数。具体的数量对于不同的话题可能会有很大的差异，因此我使用百分比作为输出。通过这个功能，我们可以比较不同标签的结果：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Because both axes are “normalized” to 0..100%, it is easy to compare results
    for different topics:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因为两个轴都被“标准化”为0..100%，所以很容易比较不同话题的结果：
- en: '![](../Images/4c25e26576d9833244f8e035df7f8706.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c25e26576d9833244f8e035df7f8706.png)'
- en: Distribution of messages made by most active users, Image by author
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最活跃用户的消息分布，图像由作者提供
- en: 'Again, the result looks interesting. We can see that the distribution is strongly
    skewed: 10% of the most active users are posting 50–60% of the messages (spoiler
    alert: as we will see soon, not all of them are humans;).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，结果看起来很有趣。我们可以看到分布有很强的偏斜：10%最活跃的用户发布了50-60%的消息（剧透：正如我们很快会看到的，并不是所有人都是人类；）。
- en: This graph was made by a function that is only about 20 lines of code. This
    “analysis” is pretty simple, but many additional questions can arise. There is
    a distinct difference between different topics, and finding the answer to why
    it is so is obviously not straightforward. Which topics have the largest number
    of active users? Are there cultural or regional differences, and is the curve
    the same in different countries, like the US, Russia, or Japan? I encourage readers
    to do some tests on their own.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表是通过一个只有大约20行代码的函数制作的。这个“分析”相当简单，但可能会出现许多额外的问题。不同话题之间有明显的区别，找出原因显然不是简单的。哪些话题有最多的活跃用户？是否存在文化或地域差异，不同国家如美国、俄罗斯或日本的曲线是否相同？我鼓励读者自己做一些测试。
- en: Now that we’ve got some basic insights, it’s time to do something more challenging.
    Let’s cluster all users and try to find some common patterns. To do this, first,
    we will need to convert the user’s data into embedding vectors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们获得了一些基本见解，是时候做一些更具挑战性的事情了。让我们对所有用户进行聚类，并尝试寻找一些共同模式。为此，首先，我们需要将用户的数据转换为嵌入向量。
- en: 3\. Making User Embeddings
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 创建用户嵌入
- en: An embedded vector is a list of numbers that represents the data for each user.
    In the previous article, I got embedding vectors from tweet words and sentences.
    Now, because I want to find patterns in the “temporal” domain, I will calculate
    embeddings based on the message time. But first, let’s find out what the data
    looks like.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入向量是表示每个用户数据的一系列数字。在上一篇文章中，我从推文的词汇和句子中获取了嵌入向量。现在，因为我想在“时间”领域找到模式，我将基于消息时间计算嵌入。但首先，让我们了解一下数据的样子。
- en: 'As a reminder, we have a dataframe with all tweets, collected for a specific
    hashtag. Each tweet has a user name, creation date, time, and hour:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，我们有一个包含所有推文的数据框，这些推文是为了特定的标签收集的。每条推文都有一个用户名、创建日期、时间和小时：
- en: '![](../Images/90d99e629110f08a3995fc557bc07d49.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90d99e629110f08a3995fc557bc07d49.png)'
- en: 'Let’s create a helper function to show all tweet times for a specific user:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个帮助函数来显示特定用户的所有推文时间：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The result looks like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来是这样的：
- en: '![](../Images/0cb0319250af198aaa71d9cde38b1de3.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cb0319250af198aaa71d9cde38b1de3.png)'
- en: Messages timeline for several users, Image by author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 几个用户的消息时间线，作者提供的图片
- en: Here we can see messages made by some users within several weeks, displayed
    on the 00–24h timeline. We may already see some patterns here, but as it turned
    out, there is one problem. The Twitter API does not return a time zone. There
    is a “timezone” field in the message body, but it is always empty. Maybe when
    we see tweets in the browser, we see them in *our local time*; in this case, the
    original timezone is just not important. Or maybe it is a limitation of the free
    account. Anyway, we cannot cluster the data properly if one user from the US starts
    sending messages at 2 AM UTC and another user from India starts sending messages
    at 13 PM UTC; both timelines just will not match together.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到一些用户在几周内发送的消息，显示在00-24小时的时间轴上。我们可能已经看到了一些模式，但事实证明，有一个问题。Twitter API
    不返回时区。消息正文中有一个“timezone”字段，但它总是为空。也许当我们在浏览器中查看推文时，我们看到的是*本地时间*；在这种情况下，原始时区就不那么重要了。或者这可能是免费账户的一个限制。无论如何，如果来自美国的一个用户在
    UTC 2 AM 开始发送消息，而来自印度的另一个用户在 UTC 13 PM 开始发送消息，两者的时间线将无法匹配在一起。
- en: 'As a workaround, I tried to “estimate” the timezone myself by using a simple
    empirical rule: most people are sleeping at night, and highly likely, they are
    not posting tweets at that time ;) So, we can find the 9-hour interval, where
    the average number of messages is minimal, and assume that this is a “night” time
    for that user.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 作为解决办法，我尝试通过使用一个简单的经验规则来“估计”时区：大多数人在夜间睡觉，很可能他们在那个时候不会发推文 ;) 因此，我们可以找到一个9小时的时间段，在这个时间段内消息的平均数量最少，并假设这是该用户的“夜间”时间。
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Practically, it works well in cases like this, where the “night” period can
    be easily detected:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这在可以轻松检测到“夜间”时间段的情况下效果良好：
- en: '![](../Images/a2ebdba49eda9097f43a0ee3abb9c137.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2ebdba49eda9097f43a0ee3abb9c137.png)'
- en: Messages timeline for the “active” user, Image by author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: “活跃”用户的消息时间线，作者提供的图片
- en: Of course, some people wake up at 7 AM and some at 10 AM, and without a time
    zone, we cannot find it. Anyway, it’s better than nothing, and as a “baseline”,
    this algorithm can be used.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有些人早上7点醒来，有些人则是早上10点，且没有时区信息，我们无法找到它。总之，这总比没有好，作为一个“基线”，这个算法可以使用。
- en: 'Obviously, the algorithm does not work in cases like that:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，算法在这种情况下不起作用：
- en: '![](../Images/08d984b9b9b2bce20ed31572b67dd3ce.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08d984b9b9b2bce20ed31572b67dd3ce.png)'
- en: Another user with only a few “active” hours, Image by author
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个只有几个“活跃”小时的用户，图像来源：作者
- en: In this example, we just don’t know if this user was posting messages in the
    morning, in the evening, or after lunch; there is no information about that. But
    it is still interesting to see that some users are posting messages only at a
    specific time of the day. In this case, having a “virtual offset” is still helpful;
    it allows us to “align” all user timelines, as we will see soon in the results.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们只是不知道这个用户是在早晨、晚上还是午餐后发布消息；对此没有信息。但仍然有趣的是看到一些用户仅在一天中的特定时间发布消息。在这种情况下，拥有一个“虚拟偏移”仍然有帮助；它使我们能够“对齐”所有用户时间线，正如我们在结果中即将看到的那样。
- en: 'Now let’s calculate the **embedding vectors**. There can be different ways
    of doing this. I decided to use vectors in the form of *[SumTotal, Sum00,.., Sum23]*,
    where *SumTotal* is the total amount of messages made by a user, and *Sum00..Sum23*
    are the total number of messages made by each hour of the day. We can use Panda’s
    *groupby* method with two parameters “user_name” and “hour”, which does almost
    all the needed calculations for us:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们计算**嵌入向量**。可以有不同的方法来做到这一点。我决定使用* [SumTotal, Sum00,.., Sum23]* 形式的向量，其中
    *SumTotal* 是用户发布的总消息量，而 *Sum00..Sum23* 是每天每小时发布的总消息数。我们可以使用Pandas的 *groupby* 方法，参数为“user_name”和“hour”，这几乎可以为我们完成所有需要的计算：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, the “get_vectorized_users” method is doing the calculation. After calculating
    each 00..24h vector, I use the “normalize” function to apply the “timezone” offset,
    as was described before.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“get_vectorized_users”方法正在进行计算。计算每个00..24小时向量后，我使用“normalize”函数来应用之前描述的“时区”偏移。
- en: 'Practically, the embedding vector for a relatively active user may look like
    this:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，对于一个相对活跃的用户，嵌入向量可能如下所示：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here 120 is the total number of messages, and the rest is a 24-digit array
    with the number of messages made within every hour (as a reminder, in our case,
    the data was collected within 46 days). For the inactive user, the embedding may
    look like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里120是消息的总数，其余部分是一个24位的数组，其中包含每小时发布的消息数量（作为提醒，在我们的案例中，数据是在46天内收集的）。对于不活跃的用户，嵌入可能如下所示：
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Different embedding vectors can also be created, and a more complicated scheme
    can provide better results. For example, it may be interesting to add a total
    number of “active” hours per day or to include a day of the week into the vector
    to see how the user’s activity varies between working days and weekends, and so
    on.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以创建不同的嵌入向量，更复杂的方案可能会提供更好的结果。例如，添加每天“活跃”小时的总数或将星期几包含到向量中，看看用户活动如何在工作日和周末之间变化，等等，可能会很有趣。
- en: 4\. Clustering
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 聚类
- en: 'As in the [previous article](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906),
    I will be using the K-Means algorithm to find the clusters. First, let’s find
    the optimum K-value using the [Elbow method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 和[上一篇文章](/what-people-write-about-climate-twitter-data-clustering-in-python-2fbbd2b95906)一样，我将使用K-Means算法来寻找聚类。首先，让我们使用[肘部法则](https://en.wikipedia.org/wiki/Elbow_method_(clustering))来找到最佳K值：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The result looks like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![](../Images/b34df2ca55cb19a1761efcc0581c1ba9.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b34df2ca55cb19a1761efcc0581c1ba9.png)'
- en: The Elbow graph for users embeddings, Image by author
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 用户嵌入的肘部图，图像来源：作者
- en: 'Let’s write the method to calculate the clusters and draw the timelines for
    some users:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写方法来计算聚类并绘制一些用户的时间线：
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This method is mostly the same as in the previous part; the only difference
    is that I draw user timelines for each cluster instead of a cloud of words.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法与前面部分大致相同，唯一的区别是我为每个聚类绘制用户时间线，而不是词云。
- en: 5\. Results
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 结果
- en: Finally, we are ready to see the results. Obviously, not all groups were perfectly
    separated, but some of the categories are interesting to mention. As a reminder,
    I was analyzing all tweets of users who made posts with the “#Climate” hashtag
    within 46 days. So, what clusters can we see in posts about climate?
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们准备查看结果。显然，并不是所有组都完美分开，但一些类别值得提及。作为提醒，我分析了所有在46天内发布了“#Climate”标签的用户的推文。那么，在气候相关的帖子中，我们可以看到哪些聚类呢？
- en: '**“Inactive” users,** who sent only 1–2 messages within a month. This group
    is the largest; as was discussed above, it represents more than 95% of all users.
    And the K-Means algorithm was able to detect this cluster as the largest one.
    Timelines for those users look like this:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**“非活跃”** 用户，他们在一个月内只发送了1–2条消息。这个群体是最大的；正如前面讨论的，它代表了所有用户的95%以上。而K-Means算法能够检测到这个群体是最大的。那些用户的时间线如下：'
- en: '![](../Images/b9a7612294f8fae79460a40b7584472b.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9a7612294f8fae79460a40b7584472b.png)'
- en: Messages timeline for several “inactive” users, Image by author
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 几个“非活跃”用户的消息时间线，图像来源于作者
- en: '**“Interested” users.** These users posted tweets every 2–5 days, so I can
    assume that they have at least some sort of interest in this topic.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**“感兴趣”** 用户。这些用户每2–5天发布一次推文，因此我可以假设他们对这个话题至少有一定的兴趣。'
- en: '![](../Images/f25f45be598e4dd4a90d8a86ade6cbdc.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f25f45be598e4dd4a90d8a86ade6cbdc.png)'
- en: Messages timeline for several “interested” users, Image by author
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 几个“感兴趣”用户的消息时间线，图像来源于作者
- en: '**“Active” users.** These users are posting more than several messages per
    day:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**“活跃”** 用户。这些用户每天发布超过几条消息：'
- en: '![](../Images/fe3b5d141c4b96feb09916f9c947bef3.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe3b5d141c4b96feb09916f9c947bef3.png)'
- en: Messages timeline for several “active” users, Image by author
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 几个“活跃”用户的消息时间线，图像来源于作者
- en: We don’t know if those people are just “activists” or if they regularly post
    tweets as a part of their job, but at least we can see that their online activity
    is pretty high.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道这些人是只是“积极分子”，还是将发布推文作为工作的一个部分，但至少我们可以看到他们的在线活动相当高。
- en: '**“Bots”**. These users are highly unlikely to be humans at all. Not surprisingly,
    they have the highest number of posted messages. Of course, I have no 100% proof
    that all those accounts belong to bots, but it is unlikely that any human can
    post messages so regularly without rest and sleep:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**“机器人”**。这些用户极不可能是人类。毫不奇怪，他们发布的消息数量最多。当然，我没有100%证据证明所有这些账户都属于机器人，但任何人类都不可能如此规律地发布消息而没有休息和睡眠：'
- en: '![](../Images/9c6ca5db4d9ea478479b09f2eaf0bffa.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c6ca5db4d9ea478479b09f2eaf0bffa.png)'
- en: Messages timeline for several “bots”, Image by author
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 几个“机器人”的消息时间线，图像来源于作者
- en: The second “user”, for example, is posting tweets at the same time of day with
    1-second accuracy; its tweets can be used as an NTP server :)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，第二个“用户”在一天中的同一时间发布推文，精确到1秒；他的推文可以用作NTP服务器 :)
- en: 'By the way, some other “users” are not really active, but their timeline looks
    suspicious. This “user” has not so many messages, and there is a visible “day/night”
    pattern, so it was not clustered as a “bot”. But for me, it looks unrealistic
    that an ordinary user can publish messages strictly at the beginning of each hour:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，一些其他的“用户”实际上并不活跃，但他们的时间线看起来很可疑。这个“用户”消息不多，而且存在明显的“日/夜”模式，所以它没有被聚类为“机器人”。但对我来说，普通用户严格在每小时开始时发布消息看起来不太现实：
- en: '![](../Images/67ad82d00a360cb8cadb920af2cd49ef.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67ad82d00a360cb8cadb920af2cd49ef.png)'
- en: Messages timeline for a user, Image by author
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用户的消息时间线，图像来源于作者
- en: Maybe the auto-correlation function can provide good results in detecting all
    users with suspiciously repetitive activity.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 也许自相关函数可以在检测所有可疑重复活动的用户方面提供良好的结果。
- en: '**“Clones”.** If we run a K-Means algorithm with higher values of K, we can
    also detect some “clones”. These clusters have identical time patterns and the
    highest silhouette values. For example, we can see several accounts with similar-looking
    nicknames that only differ in the last characters. Probably, the script is posting
    messages from several accounts in parallel:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**“克隆”**。如果我们用更高的K值运行K-Means算法，我们也可以检测到一些“克隆”。这些聚类具有相同的时间模式和最高的轮廓系数值。例如，我们可以看到几个相似的昵称的账户，只在最后几个字符上有所不同。可能，脚本正在并行从几个账户发布消息：'
- en: '![](../Images/1fa62d2f84bd579ee8fba7bf640190e7.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fa62d2f84bd579ee8fba7bf640190e7.png)'
- en: Messages timeline for several users with the same pattern, Image by author
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 几个具有相同模式的用户消息时间线，图像来源于作者
- en: 'As a last step, we can see clusters visualization, made by the t-SNE (t-distributed
    Stochastic Neighbor Embedding) algorithm, which looks pretty beautiful:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们可以看到由t-SNE（t-分布随机邻域嵌入）算法制作的聚类可视化，这看起来相当漂亮：
- en: '![](../Images/d6ce0f2adc9103efe1be82bb681c47cc.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6ce0f2adc9103efe1be82bb681c47cc.png)'
- en: t-SNE clusters visualization, Image by author
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE聚类可视化，图像来源于作者
- en: Here we can see a lot of smaller clusters that were not detected by the K-Means
    with K=5\. In this case, it makes sense to try higher K values; maybe another
    algorithm like [DBSCAN](https://medium.com/towards-data-science/how-dbscan-works-and-why-should-i-use-it-443b4a191c80)
    (Density-based spatial clustering of applications with noise) will also provide
    good results.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到很多较小的聚类，这些聚类没有被K-Means（K=5）检测到。在这种情况下，尝试更高的K值是有意义的；也许像 [DBSCAN](https://medium.com/towards-data-science/how-dbscan-works-and-why-should-i-use-it-443b4a191c80)（基于密度的空间聚类应用程序）这样的算法也会提供良好的结果。
- en: Conclusion
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Using data clustering, we were able to find distinctive patterns in tens of
    thousands of tweets about “#Climate”, made by different users. The analysis itself
    was made only by using the time of tweet posts. This can be useful in sociology
    or cultural anthropology studies; for example, we can compare the online activity
    of different users on different topics, figure out how often they make social
    network posts, and so on. Time analysis is language-agnostic, so it is also possible
    to compare results from different geographical areas, for example, online activity
    between English- and Japanese-speaking users. Time-based data can also be useful
    in psychology or medicine; for example, it is possible to figure out how many
    hours people are spending on social networks or how often they make pauses. And
    as was demonstrated above, finding patterns in users “behavior” can be useful
    not only for research purposes but also for purely “practical” tasks like detecting
    bots, “clones”, or users posting spam.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据聚类，我们能够在数万条关于“#气候”的推文中找到独特的模式，这些推文由不同的用户发布。分析本身仅仅是基于推文发布的时间进行的。这在社会学或文化人类学研究中可能会很有用；例如，我们可以比较不同用户在不同话题上的在线活动，弄清楚他们发帖的频率等等。时间分析是语言无关的，因此也可以比较不同地理区域的结果，例如英语和日语用户之间的在线活动。基于时间的数据也可能对心理学或医学有用；例如，可以弄清楚人们在社交网络上花费了多少时间或他们暂停的频率。正如上面所示，发现用户“行为”中的模式不仅对研究目的有用，而且对检测机器人、*克隆*或发布垃圾邮件的用户等纯粹的“实际”任务也很有帮助。
- en: Alas, not all analysis was successful because the Twitter API does not provide
    timezone data. For example, it would be interesting to see if people are posting
    more messages in the morning or in the evening, but without having a proper time,
    it is impossible; all messages returned by the Twitter API are in UTC time. But
    anyway, it is great that the Twitter API allows us to get large amounts of data
    even with a free account. And obviously, the ideas described in this post can
    be used not only for Twitter but for other social networks as well.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 可惜，并非所有的分析都成功，因为Twitter API没有提供时区数据。例如，看看人们是早上发消息更多还是晚上发消息更多将会很有趣，但由于没有适当的时间，无法实现；Twitter
    API返回的所有消息都是UTC时间。但无论如何，很高兴Twitter API即使在免费账户下也允许我们获取大量数据。而且，显然，这篇文章中描述的思想不仅可以用于Twitter，也可以用于其他社交网络。
- en: If you enjoyed this story, feel free [to subscribe](https://medium.com/@dmitryelj/membership)
    to Medium, and you will get notifications when my new articles will be published,
    as well as full access to thousands of stories from other authors.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这个故事，可以 [订阅](https://medium.com/@dmitryelj/membership) Medium，这样你会在我的新文章发布时收到通知，并且可以全面访问其他作者的成千上万的故事。
- en: Thanks for reading.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
