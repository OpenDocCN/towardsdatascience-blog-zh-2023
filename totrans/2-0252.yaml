- en: Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and Parallel Knowledge Graph Retrieval
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a](https://towardsdatascience.com/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)
    ·8 min read·Nov 18, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with just a handful of examples.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)
    [## Why RAG (Retrieval Augmented Generation) will become a cornerstone of system
    design using LLM…'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Recent advances in large language models (LLMs) like GPT-3 [1] have demonstrated
    powerful few-shot learning abilities —…
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ai.plainenglish.io](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: However, despite their advances, LLMs still face limitations in complex reasoning
    involving chaotic contexts overloaded with disjoint facts. To address this challenge,
    researchers have explored techniques like chain-of-thought prompting that guide
    models to incrementally analyze information. Yet on their own, these methods struggle
    to fully capture all critical details across vast contexts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: This article proposes a technique combining Thread-of-Thought (ToT) prompting
    with a Retrieval Augmented Generation (RAG) framework accessing multiple knowledge
    graphs in parallel. While ToT acts as the reasoning “backbone” that structures
    thinking, the RAG system broadens available knowledge to fill gaps. Parallel querying
    of diverse information sources improves efficiency and coverage compared to sequential
    retrieval. Together, this framework aims to enhance LLMs’ understanding and problem-solving
    abilities in chaotic contexts, moving closer to human cognition.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种将线程思维（Thread-of-Thought, ToT）提示与检索增强生成（Retrieval Augmented Generation,
    RAG）框架相结合的技术，该框架并行访问多个知识图谱。ToT作为思维的“骨架”来构建推理，而RAG系统则扩展了可用知识以填补空白。与顺序检索相比，信息来源的并行查询提高了效率和覆盖面。综合来看，这一框架旨在提升LLM在混乱情境中的理解和解决问题的能力，更接近于人类认知。
- en: We begin by outlining the need for structured reasoning in chaotic environments
    where both relevant and irrelevant facts intermix. Next, we introduce the RAG
    system design and how it expands an LLM’s accessible knowledge. We then explain
    integrating ToT prompting to methodically guide the LLM through step-wise analysis.
    Finally, we discuss optimization strategies like parallel retrieval to efficiently
    query multiple knowledge sources concurrently.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先概述了在相关和无关事实混合的混乱环境中对结构化推理的需求。接着，我们介绍了RAG系统设计及其如何扩展LLM的可访问知识。然后，我们解释了如何集成ToT提示，以系统地引导LLM进行逐步分析。最后，我们讨论了如并行检索等优化策略，以高效地同时查询多个知识来源。
- en: Through both conceptual explanation and Python code samples, this article illuminates
    a novel technique to orchestrate an LLM’s strengths with complementary external
    knowledge. Creative integrations such as this highlight promising directions for
    overcoming inherent model limitations and advancing AI reasoning abilities. The
    proposed approach aims to provide a generalizable framework amenable to further
    enhancement as LLMs and knowledge bases evolve.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过概念解释和Python代码示例，本文阐明了一种将LLM的优势与互补外部知识相结合的新技术。这种创造性的整合突显了克服模型固有限制并提升AI推理能力的有希望方向。所提出的方法旨在提供一个通用的框架，可随着LLM和知识库的发展进一步增强。
- en: The Need for Structured Reasoning
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化推理的需求
- en: While LLMs have made strides in language understanding, their reasoning abilities
    remain limited. When faced with complex contexts containing multiple disjoint
    facts, models often get lost or omit critical information.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM在语言理解上取得了进展，但其推理能力仍然有限。当面临包含多个不相关事实的复杂情境时，模型往往会迷失或遗漏关键信息。
- en: Chaotic contexts include both relevant facts needed to address the question/task,
    as well as irrelevant information unnecessary for the reasoning process.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混乱的情境包括处理问题/任务所需的相关事实，以及推理过程中不必要的无关信息。
- en: The relevant and irrelevant pieces are mixed together within the context rather
    than separated into clear sections.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相关和无关的内容混合在一起，而不是分隔成清晰的部分。
- en: There is no clear logical progression or grouping of the facts. The order may
    be completely random rather than building in a structured way.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 事实没有明确的逻辑进展或分组。顺序可能完全随机，而不是以结构化方式构建。
- en: The relevant and irrelevant details are deeply interwoven. For example, a key
    relevant sentence may be sandwiched between two irrelevant ones.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相关和无关的细节深度交织。例如，一个关键的相关句子可能夹在两个无关句子之间。
- en: The lack of structure means models cannot rely on the position or sequence of
    information to determine relevance. The pertinent facts can appear anywhere.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结构缺失意味着模型不能依赖信息的位置或顺序来确定相关性。相关事实可能出现在任何地方。
- en: There is a high density and volume of information packed into the context. Lots
    of facts jump out but few explicitly stand out as relevant.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上下文中包含的信息密度和体量很高。许多事实跳出来，但很少有明确突出的相关信息。
- en: The chaotic mixing of overload information obscures which details connect to
    each other in meaningful ways. It fragments the logical thread.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 信息过载的混乱混合使得哪些细节以有意义的方式相互关联变得模糊。它破坏了逻辑线索。
- en: Without a coherent thread to follow, models can easily lose track of key points
    that get drowned out by the chaos.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在没有连贯线索的情况下，模型很容易丧失关键点，被混乱所掩盖。
- en: The distractions disrupt the reasoning process, causing models to miss insights
    that require connecting multiple scattered details.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 干扰破坏了推理过程，使模型错过了需要连接多个分散细节的洞察。
- en: This makes it challenging to methodically build an understanding grounded in
    the relevant information. Reasoning gives way to randomness.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这使得基于相关信息有条理地构建理解变得具有挑战性。推理变得随机。
- en: In essence, chaotic contexts overload models with complex intersections of signal
    and noise. This entanglement strains even structured reasoning techniques, showing
    gaps that demand additional solutions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，混乱的背景使模型过载于信号和噪声的复杂交集。这种纠缠即使对结构化推理技术也造成了压力，显示出需要额外解决方案的差距。
- en: To address this, the Thread of Thought (ToT) prompting strategy was introduced.
    Inspired by human cognition, ToT guides models to methodically analyze contexts
    step-by-step. This technique improves comprehension and reasoning without retraining
    models.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，引入了线索提示（ToT）策略。受人类认知的启发，ToT 引导模型逐步分析上下文。这一技术提高了理解和推理能力，而无需重新训练模型。
- en: '[](https://paperswithcode.com/paper/thread-of-thought-unraveling-chaotic-contexts?source=post_page-----a4b8018b619a--------------------------------)
    [## Papers with Code - Thread of Thought Unraveling Chaotic Contexts'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://paperswithcode.com/paper/thread-of-thought-unraveling-chaotic-contexts?source=post_page-----a4b8018b619a--------------------------------)
    [## Papers with Code - 线索解锁混乱背景]'
- en: No code available yet.
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目前还没有代码。
- en: paperswithcode.com](https://paperswithcode.com/paper/thread-of-thought-unraveling-chaotic-contexts?source=post_page-----a4b8018b619a--------------------------------)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: paperswithcode.com](https://paperswithcode.com/paper/thread-of-thought-unraveling-chaotic-contexts?source=post_page-----a4b8018b619a--------------------------------)
- en: However, ToT prompting alone has limitations in extremely chaotic contexts.
    This article proposes complementing it with a RAG system accessing diverse knowledge
    sources in parallel.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，ToT 提示在极端混乱的背景下单独存在局限性。本文提出将其与访问多样知识源的 RAG 系统互补。
- en: Introducing the RAG System
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 RAG 系统
- en: Retrieval augmented generation (RAG) combines the capabilities of LLMs with
    scalable retrieval. Indexed knowledge sources allow models to adapt rapidly using
    few-shot learning instead of encoding all information statically.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）结合了 LLM 的能力和可扩展检索。索引的知识源允许模型快速适应，利用少量示例学习，而不是静态编码所有信息。
- en: 'We design a RAG system with multiple knowledge graphs (KGs) indexed using LLama
    index. For each KG, we:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一个具有多个知识图谱（KGs）的 RAG 系统，这些知识图谱通过 LLama 索引进行索引。对于每个 KG，我们：
- en: Create a query engine to retrieve relevant passages as contexts
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个查询引擎来检索相关段落作为上下文
- en: Build a tool to encapsulate the query engine
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个工具来封装查询引擎
- en: Construct an agent for the tool to interact with the LLM
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为工具构建一个与 LLM 互动的代理
- en: Combine all agents into a super agent orchestrating the KG tools
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有代理组合成一个超级代理，协调 KG 工具
- en: Querying diverse KGs in parallel expands available knowledge, while few-shot
    learning enables fast adaptation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 并行查询不同的 KGs 扩展了可用知识，而少量示例学习实现了快速适应。
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Integrating ToT Prompting
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整合 ToT 提示
- en: To enable structured reasoning, we integrate ToT prompting into the RAG system.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用结构化推理，我们将 ToT 提示集成到 RAG 系统中。
- en: 'The super agent prompts the LLM:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 超级代理提示 LLM：
- en: '*“Walk me through this context in manageable parts step-by-step, summarizing
    and analyzing as we go”*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*“逐步引导我通过这个上下文，将其分解为可管理的部分，并在过程中总结和分析”*'
- en: This initiates incremental analysis of retrieved passages.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这启动了对检索段落的增量分析。
- en: 'The agent then extracts the conclusion with:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，代理使用以下方式提取结论：
- en: '*“Therefore, the answer is:”*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*“因此，答案是：”*'
- en: Guiding the model through ToT reasoning with diverse knowledge enhances understanding
    and avoids overlooking critical facts.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 ToT 推理和多样知识的引导增强理解，避免忽视关键事实。
- en: Implementing Parallel Retrieval
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施并行检索
- en: 'To efficiently query multiple KGs, we leverage asynchronous parallel retrieval:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了高效查询多个 KGs，我们利用异步并行检索：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Querying KGs concurrently accelerates retrieval compared to sequential queries.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 与顺序查询相比，同时查询 KGs 可以加速检索。
- en: 'Not only the knowledge scope but also the underlying graph algorithms and embeddings
    used can provide complementary reasoning strengths. For example:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅知识范围，还包括所使用的底层图算法和嵌入可以提供互补的推理能力。例如：
- en: Graph algorithms optimized for traversal like Personalized PageRank can infer
    indirect connections between concepts. This supports more flexible associative
    reasoning.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化用于遍历的图算法，如个性化 PageRank，可以推断概念之间的间接联系。这支持更灵活的联想推理。
- en: Algorithms tuned for search (e.g. Approximate Nearest Neighbors) allow efficiently
    finding related entities. This aids precise factual lookups.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为搜索调优的算法（如近似最近邻）可以有效地找到相关实体。这有助于精确的事实查找。
- en: Knowledge graph embeddings translate symbols into vector spaces amenable for
    mathematical operations. This enables analogical reasoning and vector arithmetic.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识图谱嵌入将符号转换为适合数学操作的向量空间。这使得类比推理和向量运算成为可能。
- en: Multimodal embeddings combine text, images, audio and more. This supports visual-semantic
    reasoning.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多模态嵌入结合了文本、图像、音频等。这支持视觉语义推理。
- en: 'Similarly, constraints and training objectives for embeddings also influence
    reasoning:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，嵌入的约束和训练目标也会影响推理：
- en: Transitive embeddings improve logical deduction along chains of facts.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递嵌入通过事实链改善逻辑推理。
- en: Equivalent class embeddings group synonymous terms. This aids generalization.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等价类嵌入将同义词汇总在一起。这有助于泛化。
- en: Hierarchical embeddings capture taxonomic relationships between classes. This
    allows inheritance-based reasoning.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次嵌入捕捉类之间的分类关系。这允许基于继承的推理。
- en: By orchestrating diverse algorithms and embedding strategies, we engender different
    reasoning modalities within the same overarching framework. The language model
    can adaptively employ the appropriate reasoning style for each query. This augmented
    reasoning repertoire approaches the multifaceted inference capabilities of human
    cognition.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过协调不同的算法和嵌入策略，我们在同一个总体框架内创造了不同的推理模式。语言模型可以根据每个查询灵活地使用适当的推理风格。这种增强的推理能力接近于人类认知的多面推理能力。
- en: The RAG system’s flexible architecture enables interweaving knowledge graphs
    and reasoning engines tailored to different uses. This cohesive framework integrates
    hybrid reasoning under one roof, while keeping knowledge sources modular and expandable
    as needed.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 系统的灵活架构使得知识图谱和推理引擎可以根据不同的用途进行交织。这种紧密的框架将混合推理整合在一个屋檐下，同时保持知识来源的模块化和可扩展性。
- en: 'For example with a medical knowledge graph, we can leverage:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在医学知识图谱中，我们可以利用：
- en: Transitive embeddings to improve clinical decision making through logical deduction.
    This allows deducing new drug interactions from chains of known interactions.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递嵌入通过逻辑推理改善临床决策。这允许从已知交互链推断新的药物交互。
- en: Equivalent class embeddings to group synonymous medical terms. This aids generalization
    across different terminologies like layperson and expert terms.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等价类嵌入将同义医学术语分组。这有助于不同术语（如普通术语和专家术语）之间的泛化。
- en: Hierarchical embeddings to capture taxonomy of diseases, symptoms, and treatments.
    This enables inheritance-based reasoning, like inferring properties of a specific
    cancer from its parent cancer class.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次嵌入用于捕捉疾病、症状和治疗的分类。这使得基于继承的推理成为可能，比如从某个特定癌症推断其母类癌症的特性。
- en: Query Ontology First
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首先查询本体
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This allows first tapping into the ontology to get definitions and high-level
    knowledge about the query. The ontology results are appended to the original question
    to provide context.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许首先利用本体获取关于查询的定义和高层次知识。本体的结果被附加到原始问题上，以提供背景。
- en: The enhanced question containing ontology information is then fed to the super
    agent. This primes the RAG system with initial background before retrieving from
    the knowledge graphs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 增强的问题包含本体信息，然后输入到超级代理。这在从知识图谱中检索之前，为 RAG 系统提供初步背景。
- en: Querying the ontology first provides a “warm start” for the RAG system by establishing
    basic concepts and context. The knowledge graphs can then fill in more specific
    relational facts tailored to the grounded query.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 首先查询本体提供了 RAG 系统的“热启动”，通过建立基本概念和背景。知识图谱可以随后填充更具体的关系事实，以适应具体的查询。
- en: This technique combines top-down hierarchical reasoning from the ontology with
    bottom-up retrieval of granular knowledge. The ontology clarifies ambiguous or
    broad terminology, while the knowledge graphs provide in-depth information on
    refined query aspects.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术将本体的自上而下的层次推理与自下而上的详细知识检索结合起来。本体澄清了模糊或广泛的术语，而知识图谱则提供了关于精细查询方面的深入信息。
- en: Choreographing different knowledge sources in this staged manner allows smoothly
    flowing between levels of abstraction. This progresses from high-level concepts
    down to contextual details relevant for the question.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种阶段性的方法编排不同的知识源，能够在不同的抽象层次之间平滑流动。这从高层次概念逐渐推进到与问题相关的上下文细节。
- en: Conclusion
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This article proposed an approach to enhance large language models’ reasoning
    abilities in complex contexts by integrating Thread-of-Thought prompting with
    a Retrieval Augmented Generation system.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种方法，通过将思维线程（Thread-of-Thought）提示与检索增强生成系统（RAG）相结合，来增强大型语言模型在复杂背景下的推理能力。
- en: The Thread-of-Thought technique provides structured sequencing of thought to
    methodically analyze chaotic information. Meanwhile, the RAG framework expands
    accessible knowledge through parallel querying of diverse knowledge graphs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 思维线程技术提供了结构化的思维序列，用于系统地分析混乱的信息。与此同时，RAG框架通过并行查询不同的知识图谱来扩展可获取的知识。
- en: Together, this hybrid technique aims to orchestrate the strengths of LLMs with
    complementary external knowledge sources. Guiding the model to incrementally reason
    while drawing from rich contextual data augments its understanding.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这种混合技术旨在协调LLMs与互补的外部知识源的优势。引导模型在从丰富的上下文数据中汲取信息的同时逐步推理，增强了其理解能力。
- en: The proposed approach offers a generalizable framework to address inherent model
    limitations. As LLMs continue evolving along with knowledge bases, this technique
    provides a pathway to incrementally add structured reasoning capabilities.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 所提出的方法提供了一个通用框架来解决固有的模型限制。随着LLMs与知识库的不断发展，这种技术提供了一条逐步增加结构化推理能力的途径。
- en: While challenges remain in replicating multifaceted human reasoning, innovations
    in prompting strategies, knowledge grounding, and parallel architectures illuminate
    promising directions.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在复制多面的人的推理方面仍面临挑战，但在提示策略、知识基础和并行架构方面的创新揭示了有前景的方向。
- en: This article highlighted the value of creatively combining strengths of existing
    methods to achieve emergent capabilities greater than the sum of parts. As we
    learn more about choreographing LLMs’ aptitudes, meta-architectures akin to this
    proposal may become prevailing paradigms.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本文强调了创造性地结合现有方法的优势，以实现超越部分之和的 emergent 能力的价值。随着我们对LLMs能力的编排了解的深入，类似于本提案的元架构可能成为主流范式。
- en: Moving forward, adaptive utilization of LLMs along with structured knowledge
    and reasoning techniques remains a key pillar in advancing artificial intelligence.
    With sustained research exploring these intersections, the dream of human-like
    language understanding may gradually approach reality.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 向前发展，适应性地利用大型语言模型（LLMs）以及结构化知识和推理技术仍然是推动人工智能进步的关键支柱。随着持续研究探索这些交集，人类语言理解的梦想可能逐渐接近现实。
- en: '![](../Images/4db009311e011b5157b3d3d1eb5225f3.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4db009311e011b5157b3d3d1eb5225f3.png)'
- en: Image by the author
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
