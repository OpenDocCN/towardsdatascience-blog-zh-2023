- en: Vector Search Is Not All You Need
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量搜索并不是你所需的一切
- en: 原文：[https://towardsdatascience.com/vector-search-is-not-all-you-need-ecd0f16ad65e](https://towardsdatascience.com/vector-search-is-not-all-you-need-ecd0f16ad65e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/vector-search-is-not-all-you-need-ecd0f16ad65e](https://towardsdatascience.com/vector-search-is-not-all-you-need-ecd0f16ad65e)
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----ecd0f16ad65e--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----ecd0f16ad65e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ecd0f16ad65e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ecd0f16ad65e--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----ecd0f16ad65e--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----ecd0f16ad65e--------------------------------)[![安东尼·阿尔卡拉兹](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----ecd0f16ad65e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ecd0f16ad65e--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ecd0f16ad65e--------------------------------)
    [安东尼·阿尔卡拉兹](https://medium.com/@alcarazanthony1?source=post_page-----ecd0f16ad65e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ecd0f16ad65e--------------------------------)
    ·6 min read·Sep 18, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----ecd0f16ad65e--------------------------------)
    ·阅读时间6分钟·2023年9月18日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件被用来提升本文文本的语法、流畅性和可读性。*'
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Retrieval Augmented Generation (RAG) has revolutionized open-domain question
    answering, enabling systems to produce human-like responses to a wide array of
    queries. At the heart of RAG lies a retrieval module that scans a vast corpus
    to find relevant context passages, which are then processed by a neural generative
    module — often a pre-trained language model like GPT-3 — to formulate a final
    answer.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）已经革新了开放领域问答，使系统能够对各种查询生成类似人类的响应。RAG的核心是一个检索模块，它扫描大量语料库以找到相关的上下文段落，这些段落随后由神经生成模块（通常是预训练的语言模型，如GPT-3）处理，以制定最终答案。
- en: While this approach has been highly effective, it’s not without its limitations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法非常有效，但也不是没有局限性。
- en: One of the most critical components, the vector search over embedded passages,
    has inherent constraints that can hamper the system’s ability to reason in a nuanced
    manner. This is particularly evident when questions require complex multi-hop
    reasoning across multiple documents.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最关键的组成部分之一，即对嵌入段落的向量搜索，存在固有的限制，这可能会妨碍系统以细致的方式进行推理。这在需要跨多个文档进行复杂的多跳推理时尤为明显。
- en: 'Vector search refers to searching for information using vector representations
    of data. It involves two key steps:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索指的是使用数据的向量表示来搜索信息。这涉及两个关键步骤：
- en: '**Encoding data into vectors**'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**将数据编码为向量**'
- en: First, the data being searched is encoded into numeric vector representations.
    For text data like passages or documents, this is done using embedding models
    like BERT or RoBERTa. These models convert text into dense vectors of continuous
    numbers that represent the semantic meaning. Images, audio, and other formats
    can also be encoded into vectors using appropriate deep learning models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，被搜索的数据会被编码为数值向量表示。对于像段落或文档这样的文本数据，这通过诸如BERT或RoBERTa的嵌入模型来完成。这些模型将文本转换为表示语义意义的连续数字的稠密向量。图像、音频和其他格式也可以使用适当的深度学习模型编码为向量。
- en: 2\. **Searching using vector similarity**
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **使用向量相似性搜索**
- en: Once data is encoded into vectors, searching involves finding vectors similar
    to the vector representation of the search query. This relies on distance metrics
    like cosine similarity to quantify how close two vectors are and rank results.
    The vectors with the smallest distance (highest similarity) are returned as the
    most relevant search hits.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被编码为向量，搜索涉及到找到与搜索查询的向量表示相似的向量。这依赖于距离度量，如余弦相似度，以量化两个向量的接近程度并对结果进行排序。距离最小（相似度最高）的向量被返回为最相关的搜索结果。
- en: The key advantage of vector search is the ability to search for semantic similarity,
    not just literal keyword matches. The vector representations capture conceptual
    meaning, allowing more relevant yet linguistically distinct results to be identified.
    This enables a higher quality of search compared to traditional keyword matching.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索的主要优势在于能够搜索语义相似性，而不仅仅是字面上的关键词匹配。向量表示捕捉了概念意义，从而能够识别出更相关但语言上不同的结果。这使得搜索质量比传统的关键词匹配更高。
- en: However, transforming data into vectors and searching in high-dimensional semantic
    space also comes with limitations. Balancing the tradeoffs of vector search is
    an active area of research.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将数据转换为向量并在高维语义空间中进行搜索也存在局限性。平衡向量搜索的权衡是一个活跃的研究领域。
- en: In this article, we’ll dissect the limitations of vector search, exploring why
    it struggles to capture diverse relationships and intricate interconnections between
    documents. We’ll also delve into alternative techniques, such as knowledge graph
    prompting, that promise to overcome these shortcomings.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将剖析向量搜索的局限性，探讨它为何难以捕捉文档之间的多样关系和复杂的相互联系。我们还将深入研究如知识图谱提示等替代技术，这些技术有望克服这些不足之处。
- en: Understanding the strengths and weaknesses of our current AI tools is essential
    as they become increasingly integrated into our lives. This article aims to provide
    a balanced view of where vector search shines and where it falls short in augmenting
    the reasoning capabilities of large language models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们的生活中越来越多地整合AI工具，了解当前AI工具的优缺点是至关重要的。本文旨在提供对向量搜索在增强大语言模型推理能力方面的优缺点的全面视角。
- en: Semantic Gap Between Questions and Answers
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题与答案之间的语义差距
- en: In vector search, both the input question and passages in the corpus are encoded
    as dense vector representations. Relevant context is retrieved by finding passages
    with the highest semantic similarity to the question vector.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在向量搜索中，输入问题和语料库中的段落都被编码为密集的向量表示。通过找到与问题向量具有最高语义相似性的段落来检索相关的上下文。
- en: However, questions often have an indirect relationship to the actual answers
    they seek.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，问题往往与它们寻求的实际答案存在间接关系。
- en: The vector for “What is the capital of France?” may not necessarily have high
    similarity to a passage stating “Paris is the most populous city in France”.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: “法国的首都是什么？”的向量可能不一定与陈述“巴黎是法国人口最多的城市”的段落具有高度相似性。
- en: This semantic gap means that passages containing the answer may be overlooked.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种语义差距意味着包含答案的段落可能会被忽视。
- en: The embeddings fail to capture the inferential link between the question and
    answer.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入无法捕捉问题与答案之间的推理联系。
- en: Passage Granularity Matters
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 段落粒度的重要性
- en: In vector search systems, passages are typically represented by a single embedding
    vector. The granularity of these passages can vary.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在向量搜索系统中，段落通常由单一的嵌入向量表示。这些段落的粒度可以有所不同。
- en: If the passage is very large, like an entire document, it may encompass multiple
    concepts. Parts of the passage may be relevant, while other parts are not.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果段落非常大，例如整个文档，它可能包含多个概念。段落的某些部分可能相关，而其他部分则不相关。
- en: But with a single vector representing the entire passage, it is impossible to
    distinguish relevant sections from irrelevant ones. The passage as a whole may
    exhibit only weak similarity to the question vector.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但由于单个向量代表整个段落，因此无法区分相关部分和无关部分。整个段落可能与问题向量只有微弱的相似性。
- en: Conversely, using sentence-level chunks can help isolate concepts. But this
    increases the number of vectors in the index, adding computational overhead.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，使用句子级别的块可以帮助隔离概念。但这会增加索引中的向量数量，增加计算开销。
- en: There are inherent trade-offs between precision and tractability when choosing
    passage sizes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 选择段落大小时存在精度与可处理性之间的固有权衡。
- en: Struggle With Complex Reasoning
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对复杂推理的挑战
- en: Some questions demand synthesizing facts spread across multiple documents.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有些问题需要综合多个文档中的事实。
- en: For example, “What is the earliest historical record of winemaking?” may require
    piecing together dates from various sources.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，“酿酒的最早历史记录是什么？” 可能需要从不同来源拼凑日期。
- en: Vector search is ill-equipped for such multi-hop reasoning. Each passage is
    scored independently against the question. There is no mechanism to jointly analyze
    or connect information across separate results.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索对于这种多跳推理能力不足。每个段落独立地对问题进行评分。没有机制可以共同分析或连接不同结果中的信息。
- en: As questions get more complex, simple similarity search reaches its limits.
    The system struggles to collect and contextualize facts from different passages.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 随着问题变得越来越复杂，简单的相似性搜索达到了极限。系统难以从不同的段落中收集和上下文化事实。
- en: Black Box Model Workings
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 黑箱模型工作原理
- en: In standard vector search pipelines, it is opaque how initial retrieved passages
    are selected. The rankings depend on the inner workings of the semantic similarity
    model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准向量搜索流程中，如何选择初始检索的段落是不透明的。排名取决于语义相似性模型的内部工作。
- en: This lack of transparency makes results difficult to explain, verify, and improve.
    It also limits deployability for business-critical applications.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这种缺乏透明性使得结果难以解释、验证和改进，也限制了在业务关键应用中的部署。
- en: For increased oversight, the ranking algorithms should provide some interpretability
    into why certain passages are deemed relevant.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加监督，排名算法应提供一些可解释性，以说明为什么某些段落被认为是相关的。
- en: '**Modeling Diverse Relationships**'
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**建模多样关系**'
- en: A core limitation of standard vector search is its singular focus on semantic
    similarity.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 标准向量搜索的核心限制在于其单一关注语义相似性。
- en: However, real-world reasoning requires modeling diverse relationships between
    content.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现实世界的推理需要对内容之间的多样关系进行建模。
- en: '[](https://blog.gopenai.com/knowledge-graph-prompting-a-new-approach-for-multi-document-question-answering-ab5c4006a429?source=post_page-----ecd0f16ad65e--------------------------------)
    [## Knowledge Graph Prompting: A New Approach for Multi-Document Question Answering'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 知识图谱提示：一种用于多文档问答的新方法](https://blog.gopenai.com/knowledge-graph-prompting-a-new-approach-for-multi-document-question-answering-ab5c4006a429?source=post_page-----ecd0f16ad65e--------------------------------)'
- en: Multi-document question answering (MD-QA) involves answering questions that
    require synthesizing information across…
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多文档问答（MD-QA）涉及回答需要综合多篇信息的问题…
- en: blog.gopenai.com](https://blog.gopenai.com/knowledge-graph-prompting-a-new-approach-for-multi-document-question-answering-ab5c4006a429?source=post_page-----ecd0f16ad65e--------------------------------)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[blog.gopenai.com](https://blog.gopenai.com/knowledge-graph-prompting-a-new-approach-for-multi-document-question-answering-ab5c4006a429?source=post_page-----ecd0f16ad65e--------------------------------)'
- en: 'Knowledge graph overcomes this by explicitly encoding various connections into
    an interconnected graph structure. Specifically:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱通过明确编码各种连接到互联图结构中来克服这一点。具体而言：
- en: '*Topical relationships* — Passages are linked if they share rare or key keywords.
    This captures similarity in the topics discussed.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主题关系* — 如果段落共享稀有或关键关键词，则这些段落会被链接。这捕捉到讨论主题的相似性。'
- en: '*Semantic relationships* — Passage embeddings are compared to connect those
    with semantic proximity, even if they do not share terms.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*语义关系* — 段落嵌入被比较以连接那些语义上接近的段落，即使它们不共享相同的术语。'
- en: This goes beyond surface-level topic matching.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这超越了表面层次的主题匹配。
- en: '*Structural relationships* — Passages are connected to the specific sections,
    pages, or documents they appear in.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*结构关系* — 段落与它们出现的特定部分、页面或文档相连。'
- en: This encodes the contextual hierarchy.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这编码了上下文层次结构。
- en: '*Temporal relationships* — Passages discussing time-ordered events are linked
    chronologically.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*时间关系* — 讨论时间顺序事件的段落按时间顺序链接在一起。'
- en: This represents the flow of events.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这代表了事件的流动。
- en: '*Entity relationships* — Coreference links are added between passages referencing
    the same real-world entities.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实体关系* — 在引用相同现实世界实体的段落之间添加了指代链接。'
- en: This allows entity-centric reasoning.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许以实体为中心的推理。
- en: By incorporating these diverse signals beyond just semantic similarity, KGP
    provides a richer substrate for reasoning about interconnected information.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合这些超越语义相似性的多样信号，知识图谱提示（KGP）提供了一个更丰富的推理基础，用于关于互联信息的推理。
- en: '**Structural Relationships**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**结构关系**'
- en: In contrast, standard vector search lacks any notion of these structural relationships.
    Passages are treated atomically without any surrounding context.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，标准向量搜索没有这些结构关系的概念。段落被视为原子，没有任何周围的上下文。
- en: Knowledge graph’s modeling of structure relationships merits further discussion.
    By linking passages to the specific documents or sections they appear in, the
    contextual hierarchy of the information is encoded.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱对结构关系的建模值得进一步讨论。通过将段落链接到它们出现的特定文档或部分，信息的上下文层次被编码。
- en: This enables explicitly reasoning about the section a certain fact is contained
    in, the document it originates from, and the site it was published on.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得可以明确推理某一事实所在的部分、其来源的文档以及发布的网站。
- en: Encoding the hierarchical document structure provides useful inductive biases
    for determining importance, validity, and relevance when reasoning across passages.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对层次文档结构的编码为确定重要性、有效性和相关性提供了有用的归纳偏差，这在跨段落推理时尤为重要。
- en: '**Temporal Relationships**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间关系**'
- en: This inductive bias is wholly absent in isolated vector search. Vector similarity
    scores do not factor temporal dynamics in any way. Retrieved passages are disconnected
    snapshots lacking narrative flow.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在孤立的向量搜索中完全不存在这种归纳偏差。向量相似性评分没有考虑时间动态。检索到的段落是断裂的快照，缺乏叙事流。
- en: The explicit modeling of temporal relationships in KGP also provides significant
    advantages. Ordering passages chronologically based on the events they describe
    enables reasoning about unfolding narratives and timelines.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: KGP中时间关系的明确建模也带来了显著的优势。根据所描述事件的时间顺序排列段落，使得对展开的叙事和时间线进行推理成为可能。
- en: Knowledge graph overcomes this limitation by chaining events based on their
    relative timing. This unlocks richer reasoning capabilities.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱通过根据相对时间链接事件来克服这一局限性。这解锁了更丰富的推理能力。
- en: '**Entity Relationships**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**实体关系**'
- en: With standard vector search, these entity links are not directly modeled. Valuable
    knowledge around entities is lost in the passage embeddings.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准的向量搜索中，这些实体链接没有直接建模。有关实体的宝贵知识在段落嵌入中丢失。
- en: Knowledge graph’s ability to connect entity references is a powerful asset.
    Linking passages that discuss the same real-world entities, concepts, or people
    allows focused reasoning around those shared elements.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱连接实体引用的能力是一项强大的资产。链接讨论相同现实世界实体、概念或人物的段落，可以围绕这些共享元素进行重点推理。
- en: KGP preserves this signal, enabling entity-centric exploration of the knowledge
    graph. This provides structural advantages when aggregating facts about specific
    entities across documents.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: KGP保留了这一信号，使得可以以实体为中心探索知识图谱。这在跨文档聚合关于特定实体的事实时提供了结构性优势。
- en: Conclusion
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Vector search enables efficient approximate matching based on semantic similarity.
    However, it has clear limitations when used in isolation for the retrieval step
    in RAG systems.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索基于语义相似性实现了高效的近似匹配。然而，在RAG系统的检索步骤中，单独使用时存在明显的局限性。
- en: Employing hybrid approaches that combine vector search with graph-based knowledge
    representation, multi-step reasoning modules, and transparent ranking algorithms
    can help overcome these weaknesses.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 采用结合向量搜索与基于图谱的知识表示、多步推理模块和透明排名算法的混合方法可以帮助克服这些弱点。
- en: As always, there is no single solution — leveraging a diverse toolkit of techniques
    is key to robust retrieval for real-world question answering.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，没有单一的解决方案——利用多样化的技术工具包是实现现实世界问答系统的强大检索的关键。
- en: '![](../Images/45a8af157d31577aa016dfeff183c404.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45a8af157d31577aa016dfeff183c404.png)'
- en: This image was created using an AI image generation model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此图像是使用AI图像生成模型创建的。
- en: 'Sources :'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 来源：
- en: '[https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3](https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3](https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3)'
- en: '[https://labelbox.com/blog/how-vector-similarity-search-works/](https://labelbox.com/blog/how-vector-similarity-search-works/)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://labelbox.com/blog/how-vector-similarity-search-works/](https://labelbox.com/blog/how-vector-similarity-search-works/)'
- en: '[https://www.elastic.co/what-is/vector-search](https://www.elastic.co/what-is/vector-search)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.elastic.co/what-is/vector-search](https://www.elastic.co/what-is/vector-search)'
- en: '[https://kaushikshakkari.medium.com/open-domain-question-answering-series-part-7-the-rise-of-vector-databases-in-the-world-of-9d848a3f47d5](https://kaushikshakkari.medium.com/open-domain-question-answering-series-part-7-the-rise-of-vector-databases-in-the-world-of-9d848a3f47d5)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://kaushikshakkari.medium.com/open-domain-question-answering-series-part-7-the-rise-of-vector-databases-in-the-world-of-9d848a3f47d5](https://kaushikshakkari.medium.com/open-domain-question-answering-series-part-7-the-rise-of-vector-databases-in-the-world-of-9d848a3f47d5)'
- en: '[https://medium.com/@PolonioliAI/limitations-of-vectors-and-neural-search-4d81fd64482f](https://medium.com/@PolonioliAI/limitations-of-vectors-and-neural-search-4d81fd64482f)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://medium.com/@PolonioliAI/limitations-of-vectors-and-neural-search-4d81fd64482f](https://medium.com/@PolonioliAI/limitations-of-vectors-and-neural-search-4d81fd64482f)'
- en: '[https://medium.com/vector-database/frustrated-with-new-data-our-vector-database-can-help-e5c430b29be7](https://medium.com/vector-database/frustrated-with-new-data-our-vector-database-can-help-e5c430b29be7)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://medium.com/vector-database/frustrated-with-new-data-our-vector-database-can-help-e5c430b29be7](https://medium.com/vector-database/frustrated-with-new-data-our-vector-database-can-help-e5c430b29be7)'
- en: '[https://www.singlestore.com/blog/why-your-vector-database-should-not-be-a-vector-database/](https://www.singlestore.com/blog/why-your-vector-database-should-not-be-a-vector-database/)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.singlestore.com/blog/why-your-vector-database-should-not-be-a-vector-database/](https://www.singlestore.com/blog/why-your-vector-database-should-not-be-a-vector-database/)'
- en: '[https://clickhouse.com/blog/vector-search-clickhouse-p1](https://clickhouse.com/blog/vector-search-clickhouse-p1)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://clickhouse.com/blog/vector-search-clickhouse-p1](https://clickhouse.com/blog/vector-search-clickhouse-p1)'
- en: '[https://www.searchenginejournal.com/semantic-search-with-vectors/467574/](https://www.searchenginejournal.com/semantic-search-with-vectors/467574/)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.searchenginejournal.com/semantic-search-with-vectors/467574/](https://www.searchenginejournal.com/semantic-search-with-vectors/467574/)'
- en: '[https://www.usenix.org/system/files/osdi23-zhang-qianxi_1.pdf](https://www.usenix.org/system/files/osdi23-zhang-qianxi_1.pdf)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.usenix.org/system/files/osdi23-zhang-qianxi_1.pdf](https://www.usenix.org/system/files/osdi23-zhang-qianxi_1.pdf)'
- en: '[https://www.infoworld.com/article/3651360/solving-complex-problems-with-vector-databases.html](https://www.infoworld.com/article/3651360/solving-complex-problems-with-vector-databases.html)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.infoworld.com/article/3651360/solving-complex-problems-with-vector-databases.html](https://www.infoworld.com/article/3651360/solving-complex-problems-with-vector-databases.html)'
- en: '[https://people.eecs.berkeley.edu/~matei/papers/2020/sigir_colbert.pdf](https://people.eecs.berkeley.edu/~matei/papers/2020/sigir_colbert.pdf)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://people.eecs.berkeley.edu/~matei/papers/2020/sigir_colbert.pdf](https://people.eecs.berkeley.edu/~matei/papers/2020/sigir_colbert.pdf)'
- en: '[https://blog.futuresmart.ai/gpt-4-semantic-search-and-vector-databases-revolutionizing-question-answering](https://blog.futuresmart.ai/gpt-4-semantic-search-and-vector-databases-revolutionizing-question-answering)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://blog.futuresmart.ai/gpt-4-semantic-search-and-vector-databases-revolutionizing-question-answering](https://blog.futuresmart.ai/gpt-4-semantic-search-and-vector-databases-revolutionizing-question-answering)'
- en: '[https://blog.vespa.ai/constrained-approximate-nearest-neighbor-search/](https://blog.vespa.ai/constrained-approximate-nearest-neighbor-search/)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://blog.vespa.ai/constrained-approximate-nearest-neighbor-search/](https://blog.vespa.ai/constrained-approximate-nearest-neighbor-search/)'
- en: '[https://www.pinecone.io/learn/vector-search-filtering/](https://www.pinecone.io/learn/vector-search-filtering/)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.pinecone.io/learn/vector-search-filtering/](https://www.pinecone.io/learn/vector-search-filtering/)'
