["```py\n**What you will learn:\n---------------------------------------------------** 01\\. Advantages of t-SNE over PCA\n02\\. Disadvantages of t-SNE\n03\\. How t-SNE works\n04\\. Python implementation of t-SNE - TSNE() class\n05\\. Important arguments of TSNE() class\n06\\. KL divergence\n07\\. The MNIST data in tabular format\n08\\. Visualizing MNIST data using PCA\n09\\. Visualizing MNIST data using t-SNE\n10\\. PCA before t-SNE (Very special trick)\n11\\. Choosing the right value for perplexity\n12\\. Changing the right number of iterations\n13\\. Randomness of initialization\n14\\. PCA initialization\n15\\. Using a random state in random initialization\n\n**Other dimensionality reduction methods\n---------------------------------------------------**\n1\\. [Principal Component Analysis (PCA)](https://medium.com/data-science-365/3-easy-steps-to-perform-dimensionality-reduction-using-principal-component-analysis-pca-79121998b991)\n2\\. [Factor Analysis (FA)](/factor-analysis-on-women-track-records-data-with-r-and-python-6731a73cd2e0)\n3\\. [Linear Discriminant Analysis (LDA)](/lda-is-highly-effective-than-pca-for-dimensionality-reduction-in-classification-datasets-4489eade632)\n4\\. [Non-Negative Matrix Factorization (NMF)](/non-negative-matrix-factorization-nmf-for-dimensionality-reduction-in-image-data-8450f4cae8fa)\n5\\. [Autoencoders (AEs)](/how-autoencoders-outperform-pca-in-dimensionality-reduction-1ae44c68b42f)\n6\\. [Kernel PCA](/dimensionality-reduction-for-linearly-inseparable-data-5030f0dc0f5e)\n```", "```py\n# Import\nfrom sklearn.manifold import TSNE\n\n# Create an instance\nTSNE_model = TSNE(n_components=2, perplexity=30.0, learning_rate='auto',\n                  n_iter=1000, init='pca', random_state=None)\n```", "```py\nTSNE_transformed_data = TSNE_model.fit_transform(X)\n```", "```py\nfrom sklearn.datasets import fetch_openml\n\nmnist = fetch_openml('mnist_784', version=1)\nimage_data = mnist['data'][0:10000]\nlabels = mnist['target'][0:10000]\n\nprint(\"Data shape:\", image_data.shape)\nprint(\"Data type:\", type(image_data))\nprint()\nprint(\"Label shape:\", labels.shape)\nprint(\"Label type:\", type(labels))\n```", "```py\n# Normalize the pixel values\nimage_data = image_data.astype('float32') / 255\n```", "```py\nfrom sklearn.decomposition import PCA\n\nPCA_model = PCA(n_components=2)\nPCA_transformed_data = PCA_model.fit_transform(image_data)\n\nprint(\"PCA transformed data shape:\", PCA_transformed_data.shape)\nprint(\"PCA transformed data type:\", type(PCA_transformed_data))\n```", "```py\nfrom sklearn.manifold import TSNE\n\nTSNE_model = TSNE(n_components=2, perplexity=30.0)\nTSNE_transformed_data = TSNE_model.fit_transform(image_data)\n\nprint(\"TSNE transformed data shape:\", TSNE_transformed_data.shape)\nprint(\"TSNE transformed data type:\", type(TSNE_transformed_data))\n```", "```py\nPCA_model = PCA(n_components=100)\nPCA_transformed_data = PCA_model.fit_transform(image_data)\n\nTSNE_model = TSNE(n_components=2, perplexity=30.0)\nPCA_TSNE_transformed_data = TSNE_model.fit_transform(PCA_transformed_data)\n\nplt.figure(figsize=[7, 4.9])\n\nplt.scatter(PCA_TSNE_transformed_data[:, 0], PCA_TSNE_transformed_data[:, 1], \n            c=np.array(labels).astype('int32'), s=5, cmap='tab10')\n\nplt.title('Lower dimensional representation of MNIST data - TSNE after PCA')\nplt.xlabel('1st dimension')\nplt.ylabel('2nd dimension')\nplt.savefig(\"PCA_TSNE.png\")\n```", "```py\npca_all = PCA(n_components=784)\npca_all.fit(image_data)\n\nplt.figure(figsize=[5, 3.5])\nplt.grid()\nplt.plot(np.cumsum(pca_all.explained_variance_ratio_ * 100))\nplt.xlabel('Number of components')\nplt.ylabel('Explained variance')\n```", "```py\nperplexity_vals = np.arange(10, 220, 10)\nKL_divergences = []\n\nfor i in perplexity_vals:\n  TSNE_model = TSNE(n_components=2, perplexity=i, n_iter=500).fit(PCA_transformed_data)\n  KL_divergences.append(TSNE_model.kl_divergence_)\n\nplt.style.use(\"ggplot\") \nplt.figure(figsize=[5, 3.5])\nplt.plot(perplexity_vals, KL_divergences, marker='o', color='blue')\nplt.xlabel(\"Perplexity values\")\nplt.ylabel(\"KL divergence\")\n```", "```py\nfrom sklearn.manifold import TSNE\n\nTSNE_model = TSNE(n_components=2, perplexity=30.0, n_iter=250)\n```", "```py\nfrom sklearn.manifold import TSNE\n\nTSNE_model = TSNE(n_components=2, perplexity=30.0, init='random')\n```", "```py\nfrom sklearn.manifold import TSNE\n\nTSNE_model = TSNE(n_components=2, perplexity=30.0, init='pca')\n# or\nTSNE_model = TSNE(n_components=2, perplexity=30.0) # default\n```", "```py\nfrom sklearn.manifold import TSNE\n\nTSNE_model = TSNE(n_components=2, perplexity=30.0, init='random',\n                  random_state=42)\n```", "```py\nfrom sklearn.manifold import TSNE\n\nTSNE_model = TSNE(n_components=2, perplexity=30.0, init='random',\n                  random_state=0)\n```"]