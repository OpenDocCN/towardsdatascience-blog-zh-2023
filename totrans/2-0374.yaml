- en: 'Beta Distributions: A Cornerstone of Bayesian Calibration'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/beta-distributions-a-cornerstone-of-bayesian-calibration-801f96e21498](https://towardsdatascience.com/beta-distributions-a-cornerstone-of-bayesian-calibration-801f96e21498)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploring the Versatility of Beta Distributions in Bayesian Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@MahamsMultiverse?source=post_page-----801f96e21498--------------------------------)[![Maham
    Haroon](../Images/5a9ac82369ecbf7719b765ec160a70ef.png)](https://medium.com/@MahamsMultiverse?source=post_page-----801f96e21498--------------------------------)[](https://towardsdatascience.com/?source=post_page-----801f96e21498--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----801f96e21498--------------------------------)
    [Maham Haroon](https://medium.com/@MahamsMultiverse?source=post_page-----801f96e21498--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----801f96e21498--------------------------------)
    ·9 min read·Oct 28, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fc1f75d3aabe4b9031947d45a476263e.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Google DeepMind](https://unsplash.com/@googledeepmind?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/6Y4EzfSP5Tc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Hi there!
  prefs: []
  type: TYPE_NORMAL
- en: 'Distributions may not seem like a complex concept at first glance, but they
    are incredibly powerful and fundamental in the world of data analysis and statistics.
    Think about it this way: if you were to gather 50 shirts in various sizes and
    colors, you would have created a color distribution, a size distribution, and
    perhaps even a “how much does this shirt annoy you” distribution (jokingly, of
    course). The point is that as long as you have a category to measure, there’s
    a distribution waiting to be explored.'
  prefs: []
  type: TYPE_NORMAL
- en: So, what exactly is a distribution? It’s essentially a way to show how a category
    spreads across a scale of probabilities or likelihoods. You can figure this out
    either from the data you have or from what you know about a particular topic.
    You’ve probably heard of terms like the normal distribution, skewed distribution,
    long-tailed distribution, and so on — each of these describes how data points
    are shaped.
  prefs: []
  type: TYPE_NORMAL
- en: Today I wanted to touch on the Beta Distribution and specifically its application
    in Bayesian Calibration. Bayesian Calibration is an approach that updates Bayesian
    inference with new data to find the best-fitting values for a model’s parameters.
    It considers both the prior information available about these parameters and the
    likelihood of the observed data given those parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Before we dive into Bayesian Calibration with the Beta Distribution, let’s cover
    some technical details. Once we have those basics down, we’ll explore the Bayesian
    Calibration with Beta Distributions with an intriguing scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Beta Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The [beta distribution](https://ocw.mit.edu/courses/18-05-introduction-to-probability-and-statistics-spring-2014/d6d722fef1c4f36cf2525bfe0b4f905a_MIT18_05S14_Reading14a.pdf),
    denoted as Beta(α, β), is a probability distribution characterized by two parameters.
    Its probability density function (pdf) is expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f3eba5f4da479701085dac5897fe4efc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In this equation, both α and β represent the hyperparameters, and it’s important
    to note that they must always be greater than 0\. Additionally, for the purpose
    of this article, we will focus on integer values exclusively.
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin, let’s add a visual aid to see a colorful assortment of beta
    distribution PDFs with α and β ranging from 0.5 all the way to 50.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2fef7ab366e9285990c962c8f2ded3f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good idea of what a beta distribution looks like, let’s jump
    into a scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Our Scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our fictional company MM Manufacturing, is renowned for producing precision
    weights. Their system is top-notch, ensuring near-perfect calibration for the
    majority of their products. However, in recent times, an unusual issue has cropped
    up — a surge in customer complaints about weights that fall short of perfection.
    In response, MM Manufacturing introduced an additional layer of human verification
    to guarantee that every weight dispatched to customers is flawless.
  prefs: []
  type: TYPE_NORMAL
- en: But in order to analyze the trend in actual production weights, they tasked
    their Data Science team to analyze the likelihood of encountering these irregular
    weights and, more importantly, to monitor the distribution of such occurrences,
    in order to gain insight into the path to improved performance. Fortunately, all
    weights get their exact values recorded on a conveyor belt.
  prefs: []
  type: TYPE_NORMAL
- en: The Data Science team’s approach is rooted in Bayesian calibration. Every month,
    they update a beta distribution probability density function (pdf) to assess the
    anomaly in weights and how it has fared over time. To do this, they use data from
    the conveyor belt, serving as observations to ultimately determine the posterior.
    They also need to establish a prior, which can be based on historical data, domain
    knowledge, or a non-specific, uninformative distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the alpha (α) and beta (β) values in the beta distribution for the observable
    data or likelihood estimation, they opt for the following strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: α = Number of correctly calibrated weights + 1 (ensuring α > 0)
  prefs: []
  type: TYPE_NORMAL
- en: β = Number of incorrectly calibrated weights + 1 (ensuring β > 0)
  prefs: []
  type: TYPE_NORMAL
- en: As for their choice of prior, they initially select a uninformative one, represented
    by Beta(1,1) (uniform distribution as shown below), which minimizes influence
    of the prior on the posterior and place the primary reliance on observational
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cb1b2814df4f58acb4d24d5f9ffdd80.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: It maybe worthwhile to deviate a little bit to note the role of prior in this
    context
  prefs: []
  type: TYPE_NORMAL
- en: The Role of the Prior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the realm of Bayesian inference, the prior is where you can incorporate your
    perspective — well, not quite your opinion, but rather your informed perspective
    alongside previous observations. It comes in various forms, ranging from highly
    informative to completely uninformative, and it plays a crucial role in shaping
    the posterior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In our Bayesian calibration process, the posterior distribution is proportionally
    influenced by both the likelihood and the prior.
  prefs: []
  type: TYPE_NORMAL
- en: Posterior Distribution ∝ Likelihood × Prior
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the Beta distribution serves as a [conjugate prior](https://www.statlect.com/fundamentals-of-statistics/conjugate-prior)
    in Bayesian inference for many distribution. This means that if you’re dealing
    with distributions like [Bernoulli](https://en.wikipedia.org/wiki/Bernoulli_distribution),
    [binomial](https://en.wikipedia.org/wiki/Binomial_distribution), [negative binomial](https://en.wikipedia.org/wiki/Negative_binomial_distribution)
    and [geometric](https://en.wikipedia.org/wiki/Geometric_distribution), for the
    likelihood function then the resulting posterior will also belong to the Beta
    distribution family. In our case, the situation with anomalous weights the likelihood
    distribution is based on a success failure scenario much like a binomial distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s explore the options for the prior, considering the nature of the
    distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: Uninformative Prior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An uninformative prior has the least impact on the posterior, making it suitable
    when you possess minimal information about how the distribution should appear.
    In the Beta Distribution, examples of uninformative priors can include:'
  prefs: []
  type: TYPE_NORMAL
- en: Beta(0.5, 0.5) or [Jeffreys prior](https://www.statisticshowto.com/jeffreys-prior/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Beta(1, 1) or the uniform prior.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This choice is ideal when you want the likelihood to be the dominant factor
    without substantial influence from the prior.
  prefs: []
  type: TYPE_NORMAL
- en: Mildly Informative Prior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mildly informative priors convey some information to the posterior. In the Beta
    Distribution, options for mildly informative priors can be Beta(2, 2) and Beta(1,
    2).
  prefs: []
  type: TYPE_NORMAL
- en: These priors provide a gentle nudge to the posterior based on partial knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Informative Prior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you possess substantial information about the distribution and wish to
    make slight adjustments based on new observations, informative priors come into
    play. In the Beta Distribution context, informative priors could take the form
    of Beta(10, 10) and Beta(20, 2) and many values on the larger end. These priors
    carry more weight in shaping the posterior.
  prefs: []
  type: TYPE_NORMAL
- en: With a better understanding of the different types of priors and their roles,
    let’s return to our specific scenario of mapping the anomalous weights by MM Manufacturing
    into an observable posterior distribution
  prefs: []
  type: TYPE_NORMAL
- en: Python Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So let’s do a little bit of anomaly detection using the Beta Distribution prior
    and bayesian calibration just to make the concept clearer.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, to simulate the weights produced by the conveyor belt, we’ll generated
    synthetic data with 500 data points twice for the two scenarios below.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scenario 1: Bayesian Calibration the first time'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the first time calibration, we use an uninformative prior denoted as Beta(1,1).
    We define the likelihood Beta(α , β) where α, β are:'
  prefs: []
  type: TYPE_NORMAL
- en: α = correctly calibrated weights + 1 (since alpha should be > 0)
  prefs: []
  type: TYPE_NORMAL
- en: β = incorrectly calibrated weights + 1 (again for no events beta > 0)
  prefs: []
  type: TYPE_NORMAL
- en: We also generate our synthetic data where weight is considered correctly calibrated
    if the value is between 4.85 and 5.15, inclusive for a 5 pound weight and it’s
    incorrectly calibrated if weight lies outside these values.
  prefs: []
  type: TYPE_NORMAL
- en: We initially generate data with 10% anomalous values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As intended, our posterior is almost exactly like the likelihood so this wasn’t
    much of calibration. This also shows the impact of the uniform prior on the posterior.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1eea00dde9ed48d8507bf0822cca77a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The next month we have more data and now our prior is the posterior for previous
    month, similarly we could have had some information of the internal system and
    adjusted the prior accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scenario 2: Bayesian Calibration update'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assuming the MM Manufacturing paid attention and made some changes to the system,
    now only 6% of the weights are anomalous. Now we have a more informative prior
    given the posterior from our previous data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This time we see the impact of prior on the posterior and how much more defined
    the distribution is. The relation between prior, posterior and likelihood is much
    more clearly visible here.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/199d8cbfc32c61600ea2107f294b9c00.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Considering the two scenarios described above, it becomes evident that a variety
    of these outcomes can be leveraged to acquire insights into system performance,
    make comparisons to observe enhancements, and improve data calibration across
    a broad temporal spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: The Beta Distribution’s appeal lies in its adaptability and versatility in defining
    various distributions, while Bayesian Calibration’s strength lies in its ability
    to flexibly embrace and integrate intricate model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s talk about some other applications.
  prefs: []
  type: TYPE_NORMAL
- en: Other Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: No discussion about the Beta Distribution would be complete without recognizing
    its wide-ranging uses. It’s not just used in the realm of Bayesian inference and
    calibration, like we saw in the success-failure scenario earlier. The Beta Distribution
    also plays a crucial role in A/B testing, where it helps model the conversion
    rates of different web page or web app versions - a scenario similar to success
    and failure, just in a different context.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore the Beta Distribution can also come into play in risk analysis,
    where a probabilistic approach is highly informative for estimating the probability
    of success of a project.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In conclusion, the Beta Distribution, especially when applied in the context
    of Bayesian calibration, is an exceptionally valuable and elegant concept. It
    excels at handling the intricacies of a model while offering an intuitive approach
    to decision-making. Moreover, its relevance extends to a wide array of applications
    across various industries, where it plays a pivotal role in gaining valuable insights
    into the performance of the systems undergoing calibration.
  prefs: []
  type: TYPE_NORMAL
- en: The Beta Distribution is not just a theoretical concept; it’s a practical and
    valuable asset in the data scientist’s toolkit. Understanding its applications
    and adaptability opens doors to insights that can enhance decision-making and
    improve system performance. As you delve deeper into data science, remember the
    Beta Distribution’s significance in handling complex models and gaining valuable
    insights across various industries.
  prefs: []
  type: TYPE_NORMAL
- en: A cool way to visualize beta distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://mathlets.org/mathlets/beta-distribution/?source=post_page-----801f96e21498--------------------------------)
    [## Beta Distribution - MIT Mathlets'
  prefs: []
  type: TYPE_NORMAL
- en: The beta-distribution depends on two parameters.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: mathlets.org](https://mathlets.org/mathlets/beta-distribution/?source=post_page-----801f96e21498--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Don’t forget to read some of my other intriguing articles!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](/p-values-understanding-statistical-significance-in-plain-language-41a00ff68f23?source=post_page-----801f96e21498--------------------------------)
    [## P-Values: Understanding Statistical Significance in Plain Language'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the path to significant results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'towardsdatascience.com](/p-values-understanding-statistical-significance-in-plain-language-41a00ff68f23?source=post_page-----801f96e21498--------------------------------)
    [](/exploring-counterfactual-insights-from-correlation-to-causation-in-data-analysis-c3ee44d8e777?source=post_page-----801f96e21498--------------------------------)
    [## Exploring Counterfactual Insights: From Correlation to Causation in Data Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: Use of counterfactuals for informed decision-making in data science
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/exploring-counterfactual-insights-from-correlation-to-causation-in-data-analysis-c3ee44d8e777?source=post_page-----801f96e21498--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to share your thoughts in the comments.
  prefs: []
  type: TYPE_NORMAL
