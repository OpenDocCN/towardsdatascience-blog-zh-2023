- en: Making Language Models Similar to the Human Brain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/making-language-models-similar-to-human-brain-b6ea8270be08](https://towardsdatascience.com/making-language-models-similar-to-human-brain-b6ea8270be08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: NEUROSCIENCE | ARTIFICIAL INTELLIGENCE | NLP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is still a gap between LMs and the human brain in NLP, inspiring AI to
    the latter could fill it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----b6ea8270be08--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----b6ea8270be08--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b6ea8270be08--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b6ea8270be08--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----b6ea8270be08--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b6ea8270be08--------------------------------)
    ·14 min read·Mar 23, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a0a4abe6ce5e686b45b7af813a0a8778.png)'
  prefs: []
  type: TYPE_IMG
- en: image by the author using OpenAI DALL-E
  prefs: []
  type: TYPE_NORMAL
- en: There are thousands of vertebrate species on earth, but only one is capable
    of transmitting infinite concepts through language. Verbal transmission is fundamental
    to humans and has allowed them to shape the story how we know it.
  prefs: []
  type: TYPE_NORMAL
- en: Do language models fail to match this human capacity? Why?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A new study attempts to answer this question based on both language models
    and neuroscience:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.nature.com/articles/s41562-022-01516-2?source=post_page-----b6ea8270be08--------------------------------)
    [## Evidence of a predictive coding hierarchy in the human brain listening to
    speech - Nature Human…'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considerable progress has recently been made in natural language processing:
    deep learning algorithms are increasingly…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.nature.com](https://www.nature.com/articles/s41562-022-01516-2?source=post_page-----b6ea8270be08--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: How do artificial brains and natural brains speak?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In recent years we have seen that [language models](https://en.wikipedia.org/wiki/Language_model)
    (LMs) have made great strides in tasks such as [text generation](https://huggingface.co/tasks/text-generation),
    [translation](https://huggingface.co/tasks/translation), and completion. This
    is all thanks to a simple but effective idea: we can predict a word from its context.'
  prefs: []
  type: TYPE_NORMAL
- en: Although this idea seems so simple it is the basis of all LMs from BERT to ChatGPT.
    Each transformer is based on [embedding](https://www.tensorflow.org/text/guide/word_embeddings)
    and [self-attention](https://en.wikipedia.org/wiki/Self-attention) (which after
    all allows us to relate words in a sentence).
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----b6ea8270be08--------------------------------)
    [## Everything but everything you need to know about ChatGPT'
  prefs: []
  type: TYPE_NORMAL
- en: what is known, the latest news, what it is impacting, and what is changing.
    all in one article
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/data-driven-fiction/everything-but-everything-you-need-to-know-about-chatgpt-546af7153ee2?source=post_page-----b6ea8270be08--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Over the years, the authors have tried to detect whether there was a mapping
    between the activation of these patterns and the response in the human brain to
    speech and text. Several studies have shown that this mapping is linear, and depends
    on the ability of a model to be able to predict future words in the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, one study showed that it is even possible to be able to visualize
    with AI the images that a person observes. Showing that you can reconstruct from
    recordings of brain activity what a person sees.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/stable-diffusion-and-the-brain-how-ai-can-read-our-minds-45398b395ea9?source=post_page-----b6ea8270be08--------------------------------)
    [## Stable diffusion and the brain: how AI can read our minds'
  prefs: []
  type: TYPE_NORMAL
- en: Researchers were able to reconstruct images using fMRI data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/stable-diffusion-and-the-brain-how-ai-can-read-our-minds-45398b395ea9?source=post_page-----b6ea8270be08--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Have AI algorithms caught up with human capabilities?**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: No, and neither is our understanding of human language or associated brain processes
    is sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'Yet, a gap persists between humans and these algorithms: in spite of considerable
    training data, current language models are challenged by long story generation,
    summarization and coherent dialogue and information retrieval; they fail to capture
    several syntactic constructs and semantics properties and their linguistic understanding
    is superficial. ([source](https://www.nature.com/articles/s41562-022-01516-2))'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/62820cbfaf275256d75c118d89894b1a.png)'
  prefs: []
  type: TYPE_IMG
- en: “Even with substantial human context and the powerful GPT-2 Large language model,
    Beam Search (size 32) leads to degenerate repetition (highlighted in blue) while
    pure sampling leads to incoherent gibberish (highlighted in red)” source ([here](https://arxiv.org/pdf/1904.09751.pdf))
  prefs: []
  type: TYPE_NORMAL
- en: Examples, show how still LMs have problems in identifying the subject and its
    dependencies in nested phrases. In any case, the authors note that optimizing
    only for next-word prediction often leads to generating inconsistent and bland
    sequences ( and sometimes repetitive loops).
  prefs: []
  type: TYPE_NORMAL
- en: '[Predictive coding theory](https://en.wikipedia.org/wiki/Predictive_coding)
    potentially offers an explanation for why LMs still lag behind the human language.
    **What it is actually that?**'
  prefs: []
  type: TYPE_NORMAL
- en: According to the predictive coding hypothesis, the architecture of the cortex
    implements a top-down prediction algorithm that constantly anticipates incoming
    sensory stimuli. Each cortical area houses an internal model of the environment,
    which is generated by compiling the statistical regularities that govern past
    inputs. ([source](https://www.pnas.org/doi/full/10.1073/pnas.1117807108))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, the brain maintains (and constantly updates) a mental model
    of its surroundings. The brain has a representation that is [hierarchical of space](https://www.nature.com/articles/nrn2113)
    (or of a concept). In fact, the cortex is organized hierarchically from the simplest
    to the most complex
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the human brain does not predict the next word in a sequence but
    makes predictions on multiple timescales and different levels of representation
    going up the cortical hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b19efe0581ec614239bb13c75fb791cc.png)'
  prefs: []
  type: TYPE_IMG
- en: '“ Deep language algorithms are typically trained to predict words from their
    close contexts. Unlike these algorithms, the brain makes, according to predictive
    coding theory, (1) long-range and (2) hierarchical predictions.” image source:
    [here](https://www.nature.com/articles/s41562-022-01516-2), license: [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: In the context of language, this theory entails testable hypotheses, such as
    that the brain should continuously predict a hierarchy of linguistic representations
    ranging from phonemes (what sounds are likely to occur) to words and even phrases
    (what meaning is likely to be conveyed). ([source](https://www.nature.com/articles/s41562-023-01534-8))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For example, previous studies have shown that when [a participant hears the
    phrase “Once upon a … “](https://www.nature.com/articles/s41593-022-01026-4),
    one can track from brain recordings the word “time” (even before it is pronounced).
  prefs: []
  type: TYPE_NORMAL
- en: Although we have an idea of the basic principle, the process itself is unclear.
    In fact, we do not know how multiple levels of predictions are implemented in
    the brain during speech.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we care?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A better understanding of how this process works is the first step in being
    able to modify large language models. Making large LMs more similar to the human
    brain could allow us to reduce the discrepancy between humans and LMs. Third,
    as demonstrated earlier mapping relationships between brains and models allows
    us to also better understand the models themselves.
  prefs: []
  type: TYPE_NORMAL
- en: How to map a model to the brain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/1b4c80f7f845471d71693398b8135615.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Schematic depiction of the naturalistic story-listening paradigm and data provenance.
    source: [here](https://www.nature.com/articles/s41597-021-01033-3), license: [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: The first step is, could we map the activations of neural networks on the brain?
    There is a relationship between them?
  prefs: []
  type: TYPE_NORMAL
- en: The authors started by using the narratives dataset. A dataset that is composed
    of 345 subjects listening to a variety of stories (27 different ones) during a
    total of about 4.6 hours (more than 40,000 unique words).
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors define:'
  prefs: []
  type: TYPE_NORMAL
- en: '*w* as a sequence of *M* words (the words in the story that have been listened
    to by the subjects)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Y* as the fMRI recordings elicited by *w*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: X as the activations of a deep language model input with *w* (extracted from
    the 12th layer of GPT-2)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, the authors decided to quantify the similarity between the fMRI listening
    (Y) and the activations of a deep language algorithm (X) when the model was given
    the same story as input. To quantify this they created a so-called ‘brain score’.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/545f3c246bf071fb2e8fa089249d9a4d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: The authors took the same sequence of words from the story that the patient
    heard (the dataset contains the transcript and in alignment with the fMRI recording)
    and used it as input for a model. Therefore, for a word’s word’s vector was computed
    by inputting the network (the model predicts the next word given a sequence).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once this was obtained, the authors tried to map Y activation in response to
    the audio story and X pattern activation:'
  prefs: []
  type: TYPE_NORMAL
- en: To this end, we fitted a linear ridge regression *W* on a training set to predict
    the fMRI scans given the network’s activations. Then, we evaluated this mapping
    by computing the Pearson correlation between predicted and actual fMRI scans on
    a held-out set ([source](https://www.nature.com/articles/s41562-022-01516-2))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, they correlated X and Y after obtaining a linear projection
    of X.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/871702a0cd7561b762074cea40dc1c94.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: The results show in line with previous studies that [GPT-2](https://en.wikipedia.org/wiki/GPT-2)
    activations map accurately to areas distributed over the two hemispheres of the
    brain. The brain score peaked in the [auditory cortex](https://en.wikipedia.org/wiki/Auditory_cortex)
    and in the anterior temporal and superior temporal areas.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, this is not restricted to GPT-2 alone but is also valid for other
    transformer models that have been analyzed. In other words, this mapping can be
    generalized to other state-of-the-art LMs.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, these results confirm that deep language models linearly map onto brain
    responses to spoken stories. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec2))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/db11471fe17994d0928041ece002004a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: How does the brain predict long-range words?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/1d537d3b4aea4645e019a87741bfc4c0.png)'
  prefs: []
  type: TYPE_IMG
- en: photo [Jessica Yap](https://unsplash.com/fr/@jcyapsf) on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: The [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
    has replaced [recurrent neural networks](https://en.wikipedia.org/wiki/Recurrent_neural_network)
    (RNNs) because it is capable of modeling long-term dependency (those cases, in
    which the output depends on an input present in the past). This is all because
    of the [self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning))
    that has allowed it to be able to use much longer sequences as inputs.
  prefs: []
  type: TYPE_NORMAL
- en: As we have said, although LMs have made great strides there is a big gap between
    LMs and humans.
  prefs: []
  type: TYPE_NORMAL
- en: Normally, when reading a reading text, listening to a speech, or in a conversation,
    there are many long dependencies. The brain can often predict the next word or
    phrase, taking it out of context with ease. **But then how does the brain handle
    them?**
  prefs: []
  type: TYPE_NORMAL
- en: Next, we tested whether enhancing the activations of language models with long-range
    predictions leads to higher brain scores. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**In other words, if we add forecast representations can it improve our ability
    to predict the brain?**'
  prefs: []
  type: TYPE_NORMAL
- en: The authors have defined a **forecast window** which is containing information
    up to a number d of words in the future. The model remains the same, only the
    input in this case also has adjoined the forecast representations (forecast window).
    For a distance d (number of words), the forecast window is the concatenation of
    the network’s activations of seven successive words of the current word.
  prefs: []
  type: TYPE_NORMAL
- en: We do not concatenate the future words in the sequence but the model’s activations,
    so we do not provide the model with the future words in the sequence but with
    their representation.
  prefs: []
  type: TYPE_NORMAL
- en: The “forecast score” is simply “the gain in brain score when concatenating the
    forecast windows to the present GPT-2 activations.” Or in simple words having
    a representation of the next words as much as helps us predict brain activity.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5bd31bfb83d922f1cd0ca6392ece0b83.png)'
  prefs: []
  type: TYPE_IMG
- en: '**“c**, To test whether adding representations of future words improves this
    correlation. **d**, Top, a flat forecast score across distances indicates that
    forecast representations do not make the algorithm more similar to the brain.
    Bottom, by contrast, a forecast score peaking at *d* > 1 would indicate that the
    model lacks brain-like forecast. The peak of Fd indicates how far off in the future
    the algorithm would need to forecast representations to be most similar to the
    brain.” image source: [here](https://www.nature.com/articles/s41562-022-01516-2),
    license: [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: Our results show that F is maximal for a distance of *d* = 8 words and peaks
    in the areas typically associated with language processing (Fig. [2b–d](https://www.nature.com/articles/s41562-022-01516-2#Fig2)).
    For comparison, there are 2.54 words per second on average in the stimuli. Thus,
    8 words correspond to 3.15 s of audio (the time of two successive fMRI scans).
    ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In short, the authors noted several interesting things:'
  prefs: []
  type: TYPE_NORMAL
- en: Every word from zero up to 10 contributed to this forecasting effect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best window size is about eight words.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: random forecast representations did not help predict brain activity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You could even words generated by GPT-2 instead of the true words of the sequence
    (the future words). This showed a similar result but a smaller effect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d87439f9e725e082fd08fbc7f69f7290.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: Together, these results reveal long-range forecast representations in the brain
    representing a 23% (±9% across individuals) improvement in brain scores. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The authors in other words say that these data confirm that past and presented
    word representations account for a substantial proportion of the brain signals
    that are involved in language comprehension. Indeed, these signals map to previously
    defined regions as [the language network](https://www.nature.com/articles/nature17637).
  prefs: []
  type: TYPE_NORMAL
- en: Studies of cerebral anatomy have shown that the cortex is organized hierarchically.
    Inputs and information are processed in a hierarchical manner, so low-level acoustics,
    phonemes, and semantics are encoded by different structures in the brain according
    to a precise hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1c9e4dcb9b4eff59d37c7439a83143c0.png)'
  prefs: []
  type: TYPE_IMG
- en: example of how different regions are encoding different tasks in natural speech.
    source ([here](https://www.biorxiv.org/content/10.1101/2020.04.02.022822v4.full.pdf))
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the authors asked: “Do the different levels of this cortical hierarchy
    predict the same time window?”'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, they tested how the forecast scope varied along the cortical
    hierarchy. They then studied how different regions impacted the forecast score
    and how it varied at word distance d.
  prefs: []
  type: TYPE_NORMAL
- en: The results show that the prefrontal area forecast, on average, is further off
    in the future than temporal areas. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Having shown that there is a difference between regions, several questions remain.
    **How does this temporal difference relate to context? Is there a difference with
    respect to syntactic and semantic content?**
  prefs: []
  type: TYPE_NORMAL
- en: As has been shown, there is a hierarchical organization in how transformers
    encode the representation of language. For example, the various layers of [BERT](https://arxiv.org/abs/1810.04805)
    capture different representations. The lower layers capture information at the
    phrase level and then this is diluted. The various language information is learned
    in a hierarchical manner, with surface features learned in lower layers, syntactic
    features in middle layers, and semantic features in higher layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d93475012e78ea33120386e1dc6efcff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://hal.inria.fr/hal-02131630/document), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: For this, the authors calculated the forecast score but used different levels
    of GPT-2\. They then mapped these forecast scores by level onto the brain regions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8c3ab65570ce204b8ac40e0ee44bbe68.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: Together, these results suggest that the long-range predictions of frontoparietal
    cortices are more contextualized and of higher level than the short-term predictions
    of low-level brain regions. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, the different representation of the various layers of the model
    (which as we said above is different, and grows in complexity with the depth of
    the layer chosen) is mapped differently in the brain. There is a correspondence
    between the depth of the forecast and the cortical hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Low-level predictions (low-level information) are predicted and analyzed in
    different brain areas (superior temporal sulcus and gyrus, to be precise) from
    those that deal with high-level predictions (middle temporal, parietal, and frontal
    areas, which deal with predictions and integration of more complex information).
  prefs: []
  type: TYPE_NORMAL
- en: The authors then extracted syntactic and semantic forecast representations,
    for each word and its context they generated 10 possible futures that have the
    same syntax as the original sentence. Practically given a sentence beginning,
    they generated 10 continuations with different words but with the same syntactic
    properties (part of speech and dependency tree). However, these sentences have
    different semantics (i.e., different meanings).
  prefs: []
  type: TYPE_NORMAL
- en: 'They then extracted GPT-2 activations (layer 8) and averaged the ten possible
    futures in order to extract syntactic components common to the various futures.
    Further, they subtracted this averaging (syntactic representation) from the activation
    of the actual word sequence (so as to have the pure semantic representation).
    They then constructed a semantic and semantic separated forecasting window:'
  prefs: []
  type: TYPE_NORMAL
- en: We built the syntactic and semantic forecast windows by concatenating the syntactic
    and semantic components of seven consecutive future words, respectively. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/81ffa52cc138a3fe0d530ae2a5133947.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: This method allows activation to be decomposed into two components, one semantic
    and one syntactic. Once this was done, the authors calculated the forecast score,
    as seen before, showing that there is a difference in brain activity.
  prefs: []
  type: TYPE_NORMAL
- en: The results show that semantic forecasts are long range (*d** = 8) and involve
    a distributed network peaking in the frontal and parietal lobes. By contrast,
    syntactic forecasts (Fig. [4b](https://www.nature.com/articles/s41562-022-01516-2#Fig4))
    are relatively short range (*d** = 5) and localized in the superior temporal and
    left frontal areas (Fig. [4c,d](https://www.nature.com/articles/s41562-022-01516-2#Fig4)).
    ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'These results as the authors note indicate that the brain conducts multiple
    levels of prediction and different areas have different tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: the superior temporal cortex predominantly predicts short-term, shallow and
    syntactic representations whereas the inferior-frontal and parietal areas predominantly
    predict long-term, contextual, high-level and semantic representations. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/01fa4f53ce8eb2a249057af7f62039c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: Can we implement predictive coding inside an LM?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'They noticed him from previous results:'
  prefs: []
  type: TYPE_NORMAL
- en: These results show that concatenating present and future word representations
    of GPT-2 leads to a better modelling of brain activity, especially in frontoparietal
    areas. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Can these principles be translated into GPT-2 training?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, using fine-tuning can the model be taught to predict longer-range,
    more contextual, and higher-level representations? And if so, does this improve
    the brain mapping of the model?
  prefs: []
  type: TYPE_NORMAL
- en: To test this, the authors decided to fine-tune GPT-2 on Wikipedia. Instead of
    using the language modeling approach (where the next word is predicted given the
    previous word sequence), they decided to modify the objective training. They used
    in addition to the classical objective the high-level and long-range objective,
    the model must also predict high-level representations of words that are far off
    in the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: In detail, the model must not only predict the next word but also predict the
    representation of subsequent words. The model must also predict the hidden state
    of a non-fine-tuned GPT-2 (layer 8) model of a word at distance d=8 in the sequence.
    Then the model also learns long-term, high-level, and more contextualized representations
    for the next word in the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/19f2c423d9175083226986b344928e6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'image source: [here](https://www.nature.com/articles/s41562-022-01516-2), license:
    [here](https://creativecommons.org/licenses/by/4.0/)'
  prefs: []
  type: TYPE_NORMAL
- en: The results show that GPT-2 fine-tuned with high-level and long-range modelling
    best accounts for frontoparietal responses (Fig. [5](https://www.nature.com/articles/s41562-022-01516-2#Fig5),
    >2% gain in the IFG and angular/supramarginal gyri on average, all *P* < 0.001).
    These results further strengthen the role of frontoparietal areas in predicting
    long-range, contextual and high-level representations of language. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Simply put, providing this contextual representation makes the model better
    able to predict brain activity.
  prefs: []
  type: TYPE_NORMAL
- en: Parting thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/b55ef889f05d9b12aa5fa69c5c52cfc4.png)'
  prefs: []
  type: TYPE_IMG
- en: image by [Anete Lūsiņa](https://unsplash.com/fr/@anete_lusina) on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: This study poses interesting perspectives both in better understanding how the
    brain understands language and responds, and the links between neuroscience and
    machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: By better understanding these mechanisms, we can design models of artificial
    intelligence that are more similar to the human brain. Current LMs predict the
    next word given previous words, but the human brain takes into account context
    and future possibilities. In fact, the brain predicts sensor inputs, then compares
    its predictions with reality, and then updates its own inner model representation.
  prefs: []
  type: TYPE_NORMAL
- en: So future models might consider during training distant and abstract representations
    of future words. In this study, they showed that it was not even necessary to
    change the architecture of the model, but future models could instead readjust
    their structure to be more effective.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, as demonstrated in other contexts, it is true that a future observation
    (e.g., a future image to be classified) remains indeterminate, and its latent
    representation is much more stable. This is why methods such as contrastive learning
    have been shown to be much more effective. So if this has been shown to be effective
    why not implement it in LMs architectures and training that have more contextual
    information and have more information about latent representation of the future?
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors noted that however, this study is preliminary:'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the predictive coding architecture presently tested is rudimentary.
    A systematic generalization, scaling and evaluation of this approach on natural
    language processing benchmarks is necessary to demonstrate the effective utility
    of making models more similar to the brain. ([source](https://www.nature.com/articles/s41562-022-01516-2#Sec10))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In any case, since the transformer was published, the models have become larger
    but the structure has remained virtually the same. To obviate the current limitations
    of LMs we need modifications to the architecture and training. **And what better
    source of inspiration than the human brain?**
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have found this interesting:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can look for my other articles, you can also [**subscribe**](https://salvatore-raieli.medium.com/subscribe)
    to get notified when I publish articles, and you can also connect or reach me
    on[**LinkedIn**](https://www.linkedin.com/in/salvatore-raieli/)**.**
  prefs: []
  type: TYPE_NORMAL
- en: Here is the link to my GitHub repository, where I am planning to collect code
    and many resources related to machine learning, artificial intelligence, and more.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----b6ea8270be08--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: Tutorials on machine learning, artificial intelligence,
    data science…'
  prefs: []
  type: TYPE_NORMAL
- en: Tutorials on machine learning, artificial intelligence, data science with math
    explanation and reusable code (in python…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----b6ea8270be08--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'or you may be interested in one of my recent articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/google-med-palm-the-ai-clinician-a4482143d60e?source=post_page-----b6ea8270be08--------------------------------)
    [## Google Med-PaLM: The AI Clinician'
  prefs: []
  type: TYPE_NORMAL
- en: Google's new model is trained to answer medical questions. How?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'towardsdatascience.com](/google-med-palm-the-ai-clinician-a4482143d60e?source=post_page-----b6ea8270be08--------------------------------)
    [](https://medium.com/mlearning-ai/metas-llama-a-small-language-model-beating-giants-5065948e0b7f?source=post_page-----b6ea8270be08--------------------------------)
    [## META’s LLaMA: A small language model beating giants'
  prefs: []
  type: TYPE_NORMAL
- en: META open-source model will help us to understand how LMs biases arise
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/mlearning-ai/metas-llama-a-small-language-model-beating-giants-5065948e0b7f?source=post_page-----b6ea8270be08--------------------------------)
    [](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----b6ea8270be08--------------------------------)
    [## Stable diffusion to fill gaps in medical image data
  prefs: []
  type: TYPE_NORMAL
- en: A new study shows that stable diffusion could help with medical image analysis
    and rare diseases. How?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/stable-diffusion-to-fill-gaps-in-medical-image-data-b78a2a7d6c9d?source=post_page-----b6ea8270be08--------------------------------)
    [](/why-do-we-have-huge-language-models-and-small-vision-transformers-5d59ac36c1d6?source=post_page-----b6ea8270be08--------------------------------)
    [## Why Do We Have Huge Language Models and Small Vision Transformers?
  prefs: []
  type: TYPE_NORMAL
- en: Google ViT-22 paves the way for new large transformers and to revolutionize
    computer vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/why-do-we-have-huge-language-models-and-small-vision-transformers-5d59ac36c1d6?source=post_page-----b6ea8270be08--------------------------------)
  prefs: []
  type: TYPE_NORMAL
