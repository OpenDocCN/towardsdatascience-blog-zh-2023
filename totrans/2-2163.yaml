- en: Two Ways to Download and Access Llama 2 Locally
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸¤ç§æœ¬åœ°ä¸‹è½½å’Œè®¿é—® Llama 2 çš„æ–¹æ³•
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4](https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4](https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4)
- en: A step-by-step guide to using Llama 2 on your PC
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨ä½ çš„ PC ä¸Šä½¿ç”¨ Llama 2 çš„é€æ­¥æŒ‡å—
- en: '[](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    Â·10 min readÂ·Sep 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    Â·10 åˆ†é’Ÿé˜…è¯»Â·2023å¹´9æœˆ5æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8096320260dd4a194856f7b6ae2ee973.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8096320260dd4a194856f7b6ae2ee973.png)'
- en: Image by the author (Dreamstudio)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼šä½œè€…ï¼ˆDreamstudioï¼‰
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠ¨æœº
- en: Metaâ€™s latest release, Llama 2, is gaining popularity and is incredibly interesting
    for various use cases. It offers pre-trained and fine-tuned Llama 2 language models
    in different sizes, from 7B to 70B parameters. Llama 2 performs well in various
    tests, like reasoning, coding, proficiency, and knowledge benchmarks, which makes
    it very promising.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Meta æœ€æ–°å‘å¸ƒçš„ Llama 2 æ­£åœ¨è·å¾—è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ï¼Œå¹¶ä¸”å¯¹å„ç§ä½¿ç”¨åœºæ™¯éƒ½éå¸¸æœ‰è¶£ã€‚å®ƒæä¾›äº†ä¸åŒå¤§å°çš„é¢„è®­ç»ƒå’Œå¾®è°ƒçš„ Llama 2 è¯­è¨€æ¨¡å‹ï¼Œä»
    7B åˆ° 70B å‚æ•°ã€‚Llama 2 åœ¨æ¨ç†ã€ç¼–ç ã€èƒ½åŠ›å’ŒçŸ¥è¯†åŸºå‡†ç­‰å„ç§æµ‹è¯•ä¸­è¡¨ç°è‰¯å¥½ï¼Œè¿™ä½¿å®ƒéå¸¸æœ‰å‰æ™¯ã€‚
- en: 'In this article, weâ€™ll guide you through the step-by-step process of downloading
    Llama 2 on your PC. You have two options: the official Meta AI website or HuggingFace.
    Weâ€™ll also show you how to access it, so you can leverage its powerful capabilities
    for your projects. Letâ€™s dive in!'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é€æ­¥æŒ‡å¯¼ä½ åœ¨ PC ä¸Šä¸‹è½½ Llama 2 çš„è¿‡ç¨‹ã€‚ä½ æœ‰ä¸¤ä¸ªé€‰é¡¹ï¼šå®˜æ–¹çš„ Meta AI ç½‘ç«™æˆ– HuggingFaceã€‚æˆ‘ä»¬è¿˜ä¼šå±•ç¤ºå¦‚ä½•è®¿é—®å®ƒï¼Œä»¥ä¾¿ä½ å¯ä»¥åˆ©ç”¨å…¶å¼ºå¤§çš„åŠŸèƒ½æ¥æ”¯æŒä½ çš„é¡¹ç›®ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: Prerequisites
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‰ææ¡ä»¶
- en: '[Jupyter Notebook](https://jupyter.org/)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jupyter Notebook](https://jupyter.org/)'
- en: Nvidia T4 Graphics Processing Unit (GPU)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nvidia T4 å›¾å½¢å¤„ç†å•å…ƒ (GPU)
- en: Virtual Environment (Virtualenv)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è™šæ‹Ÿç¯å¢ƒ (Virtualenv)
- en: '[HuggingFace](https://huggingface.co/) account, libraries, & Llama models'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HuggingFace](https://huggingface.co/) è´¦æˆ·ã€åº“ä»¥åŠ Llama æ¨¡å‹'
- en: Python 3.10
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.10
- en: What to Consider Before Downloading Locally
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ¬åœ°ä¸‹è½½å‰éœ€è¦è€ƒè™‘çš„äº‹é¡¹
- en: Before you download the model to your local machine, consider a few things.
    First, make sure your computer has enough processing power and storage (loading
    a model from an SSD disk is much faster). Second, be prepared for some initial
    setup to get the model running. Lastly, if youâ€™re using this for work, check your
    companyâ€™s policies on downloading external software.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°æœºå™¨ä¹‹å‰ï¼Œè€ƒè™‘ä¸€äº›äº‹é¡¹ã€‚é¦–å…ˆï¼Œç¡®ä¿ä½ çš„è®¡ç®—æœºæœ‰è¶³å¤Ÿçš„å¤„ç†èƒ½åŠ›å’Œå­˜å‚¨ç©ºé—´ï¼ˆä» SSD ç£ç›˜åŠ è½½æ¨¡å‹è¦å¿«å¾—å¤šï¼‰ã€‚å…¶æ¬¡ï¼Œå‡†å¤‡è¿›è¡Œä¸€äº›åˆå§‹è®¾ç½®ä»¥ä½¿æ¨¡å‹è¿è¡Œã€‚æœ€åï¼Œå¦‚æœä½ æ˜¯å‡ºäºå·¥ä½œéœ€è¦ä½¿ç”¨æ­¤æ¨¡å‹ï¼Œè¯·æ£€æŸ¥å…¬å¸å…³äºä¸‹è½½å¤–éƒ¨è½¯ä»¶çš„æ”¿ç­–ã€‚
- en: Why Download Llama 2 Locally?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆè¦æœ¬åœ°ä¸‹è½½ Llama 2ï¼Ÿ
- en: 'There are a few good reasons why you might want to download the model to your
    own computer such as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½æœ‰å‡ ä¸ªå¾ˆå¥½çš„ç†ç”±å¸Œæœ›å°†æ¨¡å‹ä¸‹è½½åˆ°è‡ªå·±çš„è®¡ç®—æœºä¸Šï¼Œä¾‹å¦‚ï¼š
- en: '**Reduced Latency** By hosting Llama 2 in your environment, you minimize the
    latency associated with API calls to external servers.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‡å°‘å»¶è¿Ÿ** é€šè¿‡åœ¨ä½ çš„ç¯å¢ƒä¸­æ‰˜ç®¡ Llama 2ï¼Œä½ å¯ä»¥å°†ä¸å¤–éƒ¨æœåŠ¡å™¨çš„ API è°ƒç”¨ç›¸å…³çš„å»¶è¿Ÿé™åˆ°æœ€ä½ã€‚'
- en: '**Data Privacy** You can keep your private and sensitive information on your
    own ecosystem (on-premise or external cloud provider).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•°æ®éšç§** ä½ å¯ä»¥å°†ç§äººå’Œæ•æ„Ÿä¿¡æ¯ä¿å­˜åœ¨è‡ªå·±çš„ç”Ÿæ€ç³»ç»Ÿä¸­ï¼ˆæœ¬åœ°æˆ–å¤–éƒ¨äº‘æä¾›å•†ï¼‰ã€‚'
- en: '**Customization and Control** You have more control over the model. You can
    optimize the configuration of your machine, work on optimization techniques, fine-tune
    the model, and further integrate it into your ecosystem.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®šåˆ¶å’Œæ§åˆ¶** æ‚¨å¯¹æ¨¡å‹æ‹¥æœ‰æ›´å¤šæ§åˆ¶æƒã€‚æ‚¨å¯ä»¥ä¼˜åŒ–æœºå™¨çš„é…ç½®ï¼Œè¿›è¡Œä¼˜åŒ–æŠ€æœ¯çš„å·¥ä½œï¼Œå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶è¿›ä¸€æ­¥å°†å…¶é›†æˆåˆ°æ‚¨çš„ç”Ÿæ€ç³»ç»Ÿä¸­ã€‚'
- en: '**Offline Access** Depending on the use case the model may be hosted in a secure
    environment with no internet connection.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¦»çº¿è®¿é—®** æ ¹æ®ä½¿ç”¨æƒ…å†µï¼Œæ¨¡å‹å¯èƒ½æ‰˜ç®¡åœ¨æ²¡æœ‰äº’è”ç½‘è¿æ¥çš„å®‰å…¨ç¯å¢ƒä¸­ã€‚'
- en: Choosing Where to Get â€œLlama 2â€
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€‰æ‹©è·å–â€œLlama 2â€çš„æ¥æº
- en: Deciding where to get â€œLlama 2â€ is your choice based on what works best for
    you. Here are a few things to consider in order to make your choice.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å†³å®šä»å“ªé‡Œè·å–â€œLlama 2â€æ˜¯åŸºäºå¯¹æ‚¨æœ€åˆé€‚çš„é€‰æ‹©ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›è€ƒè™‘å› ç´ ï¼Œä»¥å¸®åŠ©æ‚¨åšå‡ºé€‰æ‹©ã€‚
- en: 'Metaâ€™s GitHub:'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Metaçš„GitHubï¼š
- en: When you get â€œLlama 2â€ from Metaâ€™s GitHub, youâ€™re getting it directly from the
    source. This gives you access to the newest updates. However, if you encounter
    issues, the community might not be as reactive as the one on HuggingFace. The
    documentation is good, but trying out the examples might need more coding.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ‚¨ä»Metaçš„GitHubè·å–â€œLlama 2â€æ—¶ï¼Œæ‚¨ç›´æ¥ä»æºå¤´è·å–ã€‚è¿™ä½¿æ‚¨å¯ä»¥è®¿é—®æœ€æ–°çš„æ›´æ–°ã€‚ç„¶è€Œï¼Œå¦‚æœé‡åˆ°é—®é¢˜ï¼Œç¤¾åŒºå¯èƒ½ä¸ä¼šåƒHuggingFaceé‚£æ ·ååº”è¿…é€Ÿã€‚æ–‡æ¡£å¾ˆå¥½ï¼Œä½†å°è¯•ç¤ºä¾‹å¯èƒ½éœ€è¦æ›´å¤šç¼–ç ã€‚
- en: 'Hugging Face:'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Faceï¼š
- en: Using Hugging Face is easy because it has a user-friendly platform with a reactive
    and strong community to assist you. It is compatible with multiple frameworks
    making it easier to integrate the model into your existing technology stack.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Hugging Face éå¸¸ç®€å•ï¼Œå› ä¸ºå®ƒå…·æœ‰ç”¨æˆ·å‹å¥½çš„å¹³å°å’Œååº”è¿…é€Ÿä¸”å¼ºå¤§çš„ç¤¾åŒºæ”¯æŒã€‚å®ƒå…¼å®¹å¤šä¸ªæ¡†æ¶ï¼Œä½¿å¾—å°†æ¨¡å‹é›†æˆåˆ°ç°æœ‰æŠ€æœ¯æ ˆä¸­å˜å¾—æ›´åŠ å®¹æ˜“ã€‚
- en: Therefore, I will suggest getting the model directly from Metaâ€™s GitHub if you
    are looking for customization and insights, or from Hugging Face for its ease
    of use, community support, and compatibility with various frameworks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¦‚æœæ‚¨éœ€è¦å®šåˆ¶å’Œè§è§£ï¼Œå»ºè®®ç›´æ¥ä»Metaçš„GitHubè·å–æ¨¡å‹ï¼›å¦‚æœéœ€è¦æ˜“ç”¨æ€§ã€ç¤¾åŒºæ”¯æŒå’Œä¸å„ç§æ¡†æ¶çš„å…¼å®¹æ€§ï¼Œå¯ä»¥é€‰æ‹©Hugging Faceã€‚
- en: 1ï¸âƒ£ Download Llama 2 from the Meta website
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ ä»Metaç½‘ç«™ä¸‹è½½Llama 2
- en: 'Step 1: Request download'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 1ï¼šè¯·æ±‚ä¸‹è½½
- en: 'One option to download the model weights and tokenizer of Llama 2 is the [Meta
    AI website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/).
    Before you can download the model weights and tokenizer you have to read and agree
    to the License Agreement and submit your request by giving your email address.
    Fill in the following information and accept the terms:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½Llama 2æ¨¡å‹æƒé‡å’Œåˆ†è¯å™¨çš„ä¸€ä¸ªé€‰é¡¹æ˜¯[Meta AIç½‘ç«™](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)ã€‚åœ¨ä¸‹è½½æ¨¡å‹æƒé‡å’Œåˆ†è¯å™¨ä¹‹å‰ï¼Œæ‚¨å¿…é¡»é˜…è¯»å¹¶åŒæ„è®¸å¯åè®®ï¼Œå¹¶é€šè¿‡æä¾›æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€æäº¤è¯·æ±‚ã€‚å¡«å†™ä»¥ä¸‹ä¿¡æ¯å¹¶æ¥å—æ¡æ¬¾ï¼š
- en: '![](../Images/f355ed05cf573afd2cd1008e4a0b33e4.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f355ed05cf573afd2cd1008e4a0b33e4.png)'
- en: Image by the author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: Once your request has been approved, you will be provided with a `signed URL`
    via email.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨çš„è¯·æ±‚è¢«æ‰¹å‡†ï¼Œæ‚¨å°†é€šè¿‡ç”µå­é‚®ä»¶æ”¶åˆ°ä¸€ä¸ª`signed URL`ã€‚
- en: 'Just a quick heads up! The link provided for downloading the model weights
    and tokenizer will only be valid for 24 hours and have a limited number of downloads.
    So, if you see any errors like â€œ403: Forbidden,â€ donâ€™t worry! You can simply request
    a new link by going back to the Meta AI website.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 'æä¸ªå°æé†’ï¼æä¾›çš„ä¸‹è½½æ¨¡å‹æƒé‡å’Œåˆ†è¯å™¨çš„é“¾æ¥ä»…åœ¨24å°æ—¶å†…æœ‰æ•ˆï¼Œå¹¶ä¸”ä¸‹è½½æ¬¡æ•°æœ‰é™ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨çœ‹åˆ°è¯¸å¦‚â€œ403: Forbiddenâ€çš„é”™è¯¯ï¼Œè¯·ä¸è¦æ‹…å¿ƒï¼æ‚¨å¯ä»¥é€šè¿‡è¿”å›Meta
    AIç½‘ç«™è¯·æ±‚ä¸€ä¸ªæ–°é“¾æ¥ã€‚'
- en: 'Step 2: Get the download.sh script'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2ï¼šè·å–download.shè„šæœ¬
- en: 'Before proceeding, ensure that you have both `wget` and `md5sum` installed.
    You find the download.sh script required for model download in [Metaâ€™s GitHub
    repository](https://github.com/facebookresearch/llama.git). Clone the repository
    and go to `llama` directory as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»§ç»­ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ç»å®‰è£…äº†`wget`å’Œ`md5sum`ã€‚æ‚¨å¯ä»¥åœ¨[Metaçš„GitHubä»“åº“](https://github.com/facebookresearch/llama.git)æ‰¾åˆ°æ‰€éœ€çš„download.shè„šæœ¬ã€‚å…‹éš†è¯¥ä»“åº“å¹¶æŒ‰å¦‚ä¸‹æ–¹å¼è¿›å…¥`llama`ç›®å½•ï¼š
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Ensure that you give execution permissions to the script by typing the following
    command:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¾“å…¥ä»¥ä¸‹å‘½ä»¤ç¡®ä¿æ‚¨èµ‹äºˆè„šæœ¬æ‰§è¡Œæƒé™ï¼š
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step 3: Start the download process'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 3ï¼šå¯åŠ¨ä¸‹è½½è¿‡ç¨‹
- en: To initiate the download process, you have to run the `download.sh` script.
    Throughout the process, you will be prompted to provide the URL that was sent
    by email as well as the model you want to download.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å¯åŠ¨ä¸‹è½½è¿‡ç¨‹ï¼Œæ‚¨éœ€è¦è¿è¡Œ`download.sh`è„šæœ¬ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿä¼šæç¤ºæ‚¨æä¾›é€šè¿‡ç”µå­é‚®ä»¶å‘é€çš„URLä»¥åŠæ‚¨å¸Œæœ›ä¸‹è½½çš„æ¨¡å‹ã€‚
- en: 'You have the option to download two distinct types of models:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€‰æ‹©ä¸‹è½½ä¸¤ç§ä¸åŒç±»å‹çš„æ¨¡å‹ï¼š
- en: '***pretrained*** â€” Llama-2â€“7b, Llama-2â€“13b, Llama-2â€“70b'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***é¢„è®­ç»ƒ*** â€” Llama-2â€“7b, Llama-2â€“13b, Llama-2â€“70b'
- en: '***fine-tuned chat*** â€” Llama-2â€“7b-chat, Llama-2â€“13b-chat, Llama-2â€“70b-chat'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***å¾®è°ƒçš„èŠå¤©*** â€” Llama-2â€“7b-chatï¼ŒLlama-2â€“13b-chatï¼ŒLlama-2â€“70b-chat'
- en: In my case, Iâ€™ll get Llama-2â€“7b & Llama-2â€“7b-chat.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æˆ‘è€Œè¨€ï¼Œæˆ‘ä¼šè·å¾— Llama-2â€“7b å’Œ Llama-2â€“7b-chatã€‚
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/5657df14b6be6c74df1d12f3360013a6.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5657df14b6be6c74df1d12f3360013a6.png)'
- en: If the download was successful you should find both the tokenizer and the models
    llama-2â€“7b and llama-2â€“7b-chat.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸‹è½½æˆåŠŸï¼Œä½ åº”è¯¥èƒ½æ‰¾åˆ°åˆ†è¯å™¨å’Œæ¨¡å‹ llama-2â€“7b åŠ llama-2â€“7b-chatã€‚
- en: '![](../Images/19983a212b2f144d840de1e53e655039.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19983a212b2f144d840de1e53e655039.png)'
- en: Image by the author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: '**Step 4: Prepare the local environment**'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 4ï¼šå‡†å¤‡æœ¬åœ°ç¯å¢ƒ**'
- en: 'For optimal isolation, itâ€™s advisable to establish a fresh local environment;
    personally, I use the Conda environment management system for this use case. Letâ€™s
    initiate the creation of a new Conda environment:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è·å¾—æœ€ä½³éš”ç¦»ï¼Œå»ºè®®å»ºç«‹ä¸€ä¸ªå…¨æ–°çš„æœ¬åœ°ç¯å¢ƒï¼›æˆ‘ä¸ªäººä½¿ç”¨ Conda ç¯å¢ƒç®¡ç†ç³»ç»Ÿã€‚è®©æˆ‘ä»¬å¼€å§‹åˆ›å»ºæ–°çš„ Conda ç¯å¢ƒï¼š
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Replace `yourenvname` with the name you want to give to the environment, and
    `3.10` with the preferred Python version. After creating the environment, you
    can activate it with:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨ä½ æƒ³è¦ç»™ç¯å¢ƒçš„åç§°æ›¿æ¢ `yourenvname`ï¼Œç”¨é¦–é€‰çš„ Python ç‰ˆæœ¬æ›¿æ¢ `3.10`ã€‚åˆ›å»ºç¯å¢ƒåï¼Œä½ å¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤æ¿€æ´»å®ƒï¼š
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, navigate to the cloned repository and install the needed libraries mentioned
    in the `requirements.txt`
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå¯¼èˆªåˆ°å…‹éš†çš„ä»“åº“å¹¶å®‰è£… `requirements.txt` ä¸­æåˆ°çš„æ‰€éœ€åº“ã€‚
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Hereâ€™s one more thing you need to do: install the project package in a way
    that lets you change the code and see the effects right away, without having to
    install it again. To make this happen, run this command:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€ä»¶äº‹ä½ éœ€è¦åšï¼šä»¥å…è®¸ä½ æ›´æ”¹ä»£ç å¹¶ç«‹å³æŸ¥çœ‹æ•ˆæœçš„æ–¹å¼å®‰è£…é¡¹ç›®åŒ…ï¼Œè€Œä¸å¿…é‡æ–°å®‰è£…ã€‚è¦å®ç°è¿™ä¸€ç‚¹ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now that weâ€™ve prepared everything, letâ€™s go ahead and run the model to see
    what happens.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†ï¼Œè®©æˆ‘ä»¬è¿è¡Œæ¨¡å‹çœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚
- en: 4\. Run inference with `torchrun`
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. ä½¿ç”¨ `torchrun` è¿è¡Œæ¨ç†
- en: Torchrun, a utility in PyTorch, simplifies distributed training by automating
    worker assignments, handling failures, supporting elastic setups, and offering
    features beyond `torch.distributed.launch` including custom entry points, parameter
    passing, and log capture.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Torchrun æ˜¯ PyTorch ä¸­çš„ä¸€ä¸ªå·¥å…·ï¼Œé€šè¿‡è‡ªåŠ¨åˆ†é…å·¥ä½œè€…ã€å¤„ç†æ•…éšœã€æ”¯æŒå¼¹æ€§è®¾ç½®å’Œæä¾›è¶…è¶Š `torch.distributed.launch`
    çš„åŠŸèƒ½ï¼ˆåŒ…æ‹¬è‡ªå®šä¹‰å…¥å£ç‚¹ã€å‚æ•°ä¼ é€’å’Œæ—¥å¿—æ•è·ï¼‰æ¥ç®€åŒ–åˆ†å¸ƒå¼è®­ç»ƒã€‚
- en: 'In the cloned repository you should see two examples: `example_chat_completion.py`and
    `example_text_completion.py.`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å…‹éš†çš„ä»“åº“ä¸­ï¼Œä½ åº”è¯¥çœ‹åˆ°ä¸¤ä¸ªç¤ºä¾‹ï¼š`example_chat_completion.py` å’Œ `example_text_completion.py`ã€‚
- en: Since both scripts are designed for distributed training, we are required to
    set up a few variables. You can simply export them as below or add them to your
    `.bashrc`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºä¸¤ä¸ªè„šæœ¬éƒ½è®¾è®¡ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®ä¸€äº›å˜é‡ã€‚ä½ å¯ä»¥åƒä¸‹é¢è¿™æ ·ç®€å•åœ°å¯¼å‡ºå®ƒä»¬ï¼Œæˆ–å°†å®ƒä»¬æ·»åŠ åˆ° `.bashrc` ä¸­ã€‚
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`RANK`: The rank of the current process in the distributed training group.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RANK`ï¼šåˆ†å¸ƒå¼è®­ç»ƒç»„ä¸­å½“å‰è¿›ç¨‹çš„ç­‰çº§ã€‚'
- en: '`WORLD_SIZE`: The total number of processes in the distributed group.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WORLD_SIZE`ï¼šåˆ†å¸ƒå¼ç»„ä¸­çš„æ€»è¿›ç¨‹æ•°ã€‚'
- en: '`MASTER_ADDR`: The address of the master node that coordinates the training.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MASTER_ADDR`ï¼šåè°ƒè®­ç»ƒçš„ä¸»èŠ‚ç‚¹åœ°å€ã€‚'
- en: '`MASTER_PORT`: The port number used to communicate with the master node.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MASTER_PORT`ï¼šç”¨äºä¸ä¸»èŠ‚ç‚¹é€šä¿¡çš„ç«¯å£å·ã€‚'
- en: 'To execute `torchrun`, we need to:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰§è¡Œ `torchrun`ï¼Œæˆ‘ä»¬éœ€è¦ï¼š
- en: define the `nproc-per-node` as the number of available GPUs,
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°† `nproc-per-node` å®šä¹‰ä¸ºå¯ç”¨çš„ GPU æ•°é‡ï¼Œ
- en: provide the `script.py`,
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æä¾› `script.py`ï¼Œ
- en: indicate the model checkpoint directory via `ckpt_dir`,
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ `ckpt_dir` æŒ‡å®šæ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•ï¼Œ
- en: specify the tokenizerâ€™s path using `tokenizer_path`.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `tokenizer_path` æŒ‡å®šåˆ†è¯å™¨çš„è·¯å¾„ã€‚
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Letâ€™s run `example_text_completion.py` where the initial prompt is :'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿è¡Œ `example_text_completion.py`ï¼Œå…¶ä¸­åˆå§‹æç¤ºä¸ºï¼š
- en: '![](../Images/f1122b768da07bf26d25a4ff783e2d6e.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1122b768da07bf26d25a4ff783e2d6e.png)'
- en: Image by the author
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/592106ab554f61bddbcd56e988247ae1.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/592106ab554f61bddbcd56e988247ae1.png)'
- en: Image by the author
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: And thatâ€™s all. You made it! Now you have the option to change the prompt and
    experiment with other models ğŸ˜ƒ.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ã€‚ä½ æˆåŠŸäº†ï¼ç°åœ¨ä½ å¯ä»¥æ›´æ”¹æç¤ºå¹¶å°è¯•å…¶ä»–æ¨¡å‹ ğŸ˜ƒã€‚
- en: '**A short recap:**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç®€çŸ­å›é¡¾ï¼š**'
- en: Visit the **Meta Official Site** and ask for download permission.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è®¿é—® **Meta å®˜æ–¹ç½‘ç«™** å¹¶ç”³è¯·ä¸‹è½½æƒé™ã€‚
- en: ''
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Visit [**the Llama 2 repository**](https://github.com/facebookresearch/llama)
    in GitHub and download the **download.sh** script.
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è®¿é—® [**Llama 2 ä»“åº“**](https://github.com/facebookresearch/llama) åœ¨ GitHub ä¸Šå¹¶ä¸‹è½½
    **download.sh** è„šæœ¬ã€‚
- en: ''
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Execute the download.sh** and provide the signed URL send by email :'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**æ‰§è¡Œ download.sh** å¹¶æä¾›é€šè¿‡ç”µå­é‚®ä»¶å‘é€çš„ç­¾å URLï¼š'
- en: https://download.llamameta.net/*?YOUR_SIGNED_URL and select the model weights
    to download
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: https://download.llamameta.net/*?YOUR_SIGNED_URL å¹¶é€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹æƒé‡
- en: ''
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Prepapare the environment**'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**å‡†å¤‡ç¯å¢ƒ**'
- en: ''
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Run interference** with torchrun'
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨ torchrun è¿›è¡Œå¹²é¢„**'
- en: 2ï¸âƒ£ Download Llama 2 from HuggingFace
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ ä» HuggingFace ä¸‹è½½ Llama 2
- en: 'Step 1: Request the download'
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 1ï¼šè¯·æ±‚ä¸‹è½½
- en: To begin, make sure you ask for a download on the [Meta AI website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)
    using the exact email address linked to your Hugging Face account. Accept the
    [license terms](https://ai.meta.com/llama/license/) and [acceptable use policy](https://ai.meta.com/llama/use-policy/).
    Once thatâ€™s done, you can ask for access to any of the models available on [Hugging
    Face](https://huggingface.co/meta-llama).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œç¡®ä¿ä½ åœ¨ [Meta AI ç½‘ç«™](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)
    ä¸Šç”¨ä¸ä½ çš„ Hugging Face å¸æˆ·å…³è”çš„ç¡®åˆ‡ç”µå­é‚®ä»¶åœ°å€è¯·æ±‚ä¸‹è½½ã€‚æ¥å—[è®¸å¯æ¡æ¬¾](https://ai.meta.com/llama/license/)å’Œ[å¯æ¥å—ä½¿ç”¨æ”¿ç­–](https://ai.meta.com/llama/use-policy/)ã€‚å®Œæˆåï¼Œä½ å¯ä»¥ç”³è¯·è®¿é—®
    [Hugging Face](https://huggingface.co/meta-llama) ä¸Šçš„ä»»ä½•å¯ç”¨æ¨¡å‹ã€‚
- en: Below you can find the list containing the models that are currently available.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯å½“å‰å¯ç”¨æ¨¡å‹çš„åˆ—è¡¨ã€‚
- en: '![](../Images/2bae9ef762dc58f83c6bf7d9a9140975.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2bae9ef762dc58f83c6bf7d9a9140975.png)'
- en: cc. Hugging Face
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: cc. Hugging Face
- en: Youâ€™ll receive an email from HuggingFace confirming the grated access.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†æ”¶åˆ°æ¥è‡ª HuggingFace çš„ç¡®è®¤è®¿é—®è®¸å¯çš„ç”µå­é‚®ä»¶ã€‚
- en: 'Step 2: Get the token from HuggingFace'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2ï¼šä» HuggingFace è·å–ä»¤ç‰Œ
- en: In case you donâ€™t have a HuggingFace account yet, you will need to create one.
    After creating the account, log in to HuggingFace. Once logged in, locate the
    `Profile` option positioned in the upper right corner and select `Settings`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿˜æ²¡æœ‰ HuggingFace è´¦æˆ·ï¼Œä½ éœ€è¦åˆ›å»ºä¸€ä¸ªã€‚åˆ›å»ºè´¦æˆ·åï¼Œç™»å½• HuggingFaceã€‚ç™»å½•åï¼Œæ‰¾åˆ°å³ä¸Šè§’çš„`Profile`é€‰é¡¹å¹¶é€‰æ‹©`Settings`ã€‚
- en: '![](../Images/de689ce4ccfa73399e2774658b8f29cb.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de689ce4ccfa73399e2774658b8f29cb.png)'
- en: Image by the author
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Choose the `Access Tokens` option and click the `New token` button in order
    to generate the token.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©`Access Tokens`é€‰é¡¹å¹¶ç‚¹å‡»`New token`æŒ‰é’®ä»¥ç”Ÿæˆä»¤ç‰Œã€‚
- en: '![](../Images/64575ff4e6fb9986513ef26906dc9ace.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64575ff4e6fb9986513ef26906dc9ace.png)'
- en: Image by the author
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Simply copy the token and return to your notebook. In the next step, weâ€™ll see
    how to access and download the model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: åªéœ€å¤åˆ¶ä»¤ç‰Œå¹¶è¿”å›åˆ°ä½ çš„ç¬”è®°æœ¬ä¸­ã€‚åœ¨ä¸‹ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•è®¿é—®å’Œä¸‹è½½æ¨¡å‹ã€‚
- en: 'Step 3: Authenticate to HuggingFace'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 3ï¼šå¯¹ HuggingFace è¿›è¡Œèº«ä»½éªŒè¯
- en: First, install `huggingface_hub`module developed by Hugging Face that enables
    you to interact with the Hugging Face Model Hub. The hub hosts various pre-trained
    models. Note that`huggingface_hub.login()` requires the `ipywidgets` package.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œå®‰è£… Hugging Face å¼€å‘çš„ `huggingface_hub` æ¨¡å—ï¼Œå®ƒä½¿ä½ èƒ½å¤Ÿä¸ Hugging Face Model Hub è¿›è¡Œäº¤äº’ã€‚è¯¥ä¸­å¿ƒæ‰˜ç®¡å„ç§é¢„è®­ç»ƒæ¨¡å‹ã€‚è¯·æ³¨æ„ï¼Œ`huggingface_hub.login()`
    éœ€è¦ `ipywidgets` åŒ…ã€‚
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, import `huggingface_hub` and login to Hugging Face as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå¯¼å…¥ `huggingface_hub` å¹¶æŒ‰å¦‚ä¸‹æ–¹å¼ç™»å½• Hugging Faceï¼š
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When you run `huggingface_hub.login()`, youâ€™ll be asked to provide your Hugging
    Face authentication token. Once youâ€™ve successfully authenticated, you can download
    llama models. Paste your token and click login. If authenticated you should see
    the following message.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ è¿è¡Œ `huggingface_hub.login()` æ—¶ï¼Œä½ ä¼šè¢«è¦æ±‚æä¾›ä½ çš„ Hugging Face èº«ä»½éªŒè¯ä»¤ç‰Œã€‚æˆåŠŸè®¤è¯åï¼Œä½ å¯ä»¥ä¸‹è½½ llama
    æ¨¡å‹ã€‚ç²˜è´´ä½ çš„ä»¤ç‰Œå¹¶ç‚¹å‡»ç™»å½•ã€‚å¦‚æœè®¤è¯æˆåŠŸï¼Œä½ åº”è¯¥ä¼šçœ‹åˆ°ä»¥ä¸‹æ¶ˆæ¯ã€‚
- en: After youâ€™ve been authenticated, you can go ahead and download one of the llama
    models. I will go for `meta-llama/Llama-2â€“7b-chat-hf` .
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨èº«ä»½éªŒè¯é€šè¿‡åï¼Œä½ å¯ä»¥ç»§ç»­ä¸‹è½½å…¶ä¸­ä¸€ä¸ª llama æ¨¡å‹ã€‚æˆ‘ä¼šé€‰æ‹©`meta-llama/Llama-2â€“7b-chat-hf`ã€‚
- en: 'Step 4: Download the Llama 2 Model'
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 4ï¼šä¸‹è½½ Llama 2 æ¨¡å‹
- en: Begin by installing the needed libraries.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆå®‰è£…æ‰€éœ€çš„åº“ã€‚
- en: 'You can check the GPU available as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼æ£€æŸ¥å¯ç”¨çš„ GPUï¼š
- en: To check your GPU details such as the driver version, CUDA version, GPU name,
    or usage metrics run the command `!nvidia-smi` in a cell.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ£€æŸ¥ä½ çš„ GPU è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚é©±åŠ¨ç‰ˆæœ¬ã€CUDA ç‰ˆæœ¬ã€GPU åç§°æˆ–ä½¿ç”¨æŒ‡æ ‡ï¼Œè¯·åœ¨å•å…ƒæ ¼ä¸­è¿è¡Œå‘½ä»¤ `!nvidia-smi`ã€‚
- en: 'Then, to download the model, we need to import all necessary libraries from
    PyTorch and Hugging Faceâ€™s Transformers, initialize the Llama-2â€“7b chat model
    and its tokenizer, and save them to our disk. Check the following example:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œä¸ºäº†ä¸‹è½½æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä» PyTorch å’Œ Hugging Face çš„ Transformers å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“ï¼Œåˆå§‹åŒ– Llama-2â€“7b
    èŠå¤©æ¨¡å‹åŠå…¶æ ‡è®°å™¨ï¼Œå¹¶å°†å®ƒä»¬ä¿å­˜åˆ°ç£ç›˜ã€‚è¯·æŸ¥çœ‹ä»¥ä¸‹ç¤ºä¾‹ï¼š
- en: Once the cell is executed you should see the models in the `huggingface` directory.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰§è¡Œå®Œå•å…ƒæ ¼åï¼Œä½ åº”è¯¥ä¼šåœ¨`huggingface`ç›®å½•ä¸‹çœ‹åˆ°æ¨¡å‹ã€‚
- en: Check the directory before moving further. What should be in there?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›ä¸€æ­¥æ“ä½œä¹‹å‰æ£€æŸ¥ç›®å½•ã€‚é‡Œé¢åº”è¯¥æœ‰ä»€ä¹ˆï¼Ÿ
- en: '`config.json`: Think of this as the manual for how your model operates.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.json`ï¼šå°†å…¶è§†ä¸ºæ¨¡å‹æ“ä½œçš„æ‰‹å†Œã€‚'
- en: '`pytorch_model.bin`: This is your model''s brain in PyTorch format.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytorch_model.bin`ï¼šè¿™æ˜¯ä½ çš„æ¨¡å‹åœ¨ PyTorch æ ¼å¼ä¸­çš„â€œå¤§è„‘â€ã€‚'
- en: 'Essential tokenizer files: `special_tokens_map.json` and `tokenizer_config.json`
    are like the dictionaries for your model''s language.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¿…éœ€çš„åˆ†è¯å™¨æ–‡ä»¶ï¼š`special_tokens_map.json` å’Œ `tokenizer_config.json` å°±åƒæ˜¯ä½ æ¨¡å‹è¯­è¨€çš„è¯å…¸ã€‚
- en: '`tokenizer.model` llama 2 tokenizer'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer.model` Llama 2 åˆ†è¯å™¨'
- en: 'Step 5: Load the Llama 2 model from the disk'
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ 5 æ­¥ï¼šä»ç£ç›˜åŠ è½½ Llama 2 æ¨¡å‹
- en: In case you have already your Llama 2 models on the disk, you should load them
    first.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å·²ç»å°† Llama 2 æ¨¡å‹å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼Œä½ åº”è¯¥å…ˆåŠ è½½å®ƒä»¬ã€‚
- en: 'To do so, you need :'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œä½ éœ€è¦ï¼š
- en: '`LlamaForCausalLM` which is like the brain of "Llama 2",'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LlamaForCausalLM` å°±åƒæ˜¯ "Llama 2" çš„å¤§è„‘ï¼Œ'
- en: '`LlamaTokenizer` which helps "Llama 2" understand and break down words.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LlamaTokenizer` æœ‰åŠ©äº "Llama 2" ç†è§£å’Œåˆ†è§£å•è¯ã€‚'
- en: the path of the models
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„è·¯å¾„
- en: We have reached the last step â€” testing the interference.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»åˆ°äº†æœ€åä¸€æ­¥â€”â€”æµ‹è¯•å¹²é¢„ã€‚
- en: 'Step6: Run interference using HuggingFace pipelines'
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ 6 æ­¥ï¼šä½¿ç”¨ HuggingFace ç®¡é“è¿›è¡Œå¹²é¢„
- en: We can assess interference by using the HuggingFace transformersâ€™ pipeline.
    By leveraging pipelines, you can quickly navigate through complex tasks.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ HuggingFace transformers çš„ç®¡é“æ¥è¯„ä¼°å¹²é¢„ã€‚åˆ©ç”¨ç®¡é“ï¼Œä½ å¯ä»¥å¿«é€Ÿå®Œæˆå¤æ‚ä»»åŠ¡ã€‚
- en: '`text-generation`: Specifies that the pipeline is for generating text.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-generation`ï¼šæŒ‡å®šç®¡é“ç”¨äºç”Ÿæˆæ–‡æœ¬ã€‚'
- en: '`model`: The pre-trained model youâ€™re using for text generation.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`ï¼šä½ ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„é¢„è®­ç»ƒæ¨¡å‹ã€‚'
- en: '`tokenizer`: The tokenizer used to process input text and decode model outputs.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼šç”¨äºå¤„ç†è¾“å…¥æ–‡æœ¬å’Œè§£ç æ¨¡å‹è¾“å‡ºçš„åˆ†è¯å™¨ã€‚'
- en: '`device_map=â€autoâ€`: This attempts to run the model on the best available device
    (e.g., GPU if available, otherwise CPU).'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map=â€autoâ€`ï¼šè¿™å°è¯•åœ¨æœ€ä½³å¯ç”¨è®¾å¤‡ä¸Šè¿è¡Œæ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œè‹¥å¯ç”¨åˆ™ä¸º GPUï¼Œå¦åˆ™ä¸º CPUï¼‰ã€‚'
- en: '`max_new_tokens=512`: Limits the generated output to 512 tokens.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens=512`ï¼šé™åˆ¶ç”Ÿæˆçš„è¾“å‡ºä¸º 512 ä¸ªæ ‡è®°ã€‚'
- en: '`num_return_sequences=1`: Requests only one generated sequence.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_return_sequences=1`ï¼šåªè¯·æ±‚ä¸€ä¸ªç”Ÿæˆçš„åºåˆ—ã€‚'
- en: '`eos_token_id=tokenizer.eos_token_id`: the end-of-sequence token ID.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token_id=tokenizer.eos_token_id`ï¼šåºåˆ—ç»“æŸæ ‡è®° IDã€‚'
- en: '*In my case, I wanted a few suggestions for a few rock bands, and the outcome
    is really good.*'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä»¥æˆ‘çš„æƒ…å†µä¸ºä¾‹ï¼Œæˆ‘æƒ³è¦ä¸€äº›æ‘‡æ»šä¹é˜Ÿçš„å»ºè®®ï¼Œç»“æœéå¸¸å¥½ã€‚*'
- en: '![](../Images/1317429912fe58f6b9a5566cdf76a850.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1317429912fe58f6b9a5566cdf76a850.png)'
- en: '**A short recap of downloading Llama from HuggingFace:**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä» HuggingFace ä¸‹è½½ Llama çš„ç®€çŸ­å›é¡¾ï¼š**'
- en: Visit the **Meta Official Site** and ask for download permission.
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è®¿é—®**Meta å®˜æ–¹ç½‘ç«™**å¹¶ç”³è¯·ä¸‹è½½æƒé™ã€‚
- en: ''
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Get the token from HuggingFace
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä» HuggingFace è·å–ä»¤ç‰Œ
- en: ''
  id: totrans-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Authenticate to HuggingFace
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è®¤è¯ HuggingFace
- en: ''
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Download the Llama 2 Model
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸‹è½½ Llama 2 æ¨¡å‹
- en: ''
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Load the Llama 2 model from the disk
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä»ç£ç›˜åŠ è½½ Llama 2 æ¨¡å‹
- en: ''
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Run interference using HuggingFace pipelines
  id: totrans-160
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ HuggingFace ç®¡é“è¿›è¡Œå¹²é¢„
- en: 'Final thoughts :'
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ€åçš„æ€è€ƒï¼š
- en: In this tutorial, we have seen how to download the Llama 2 models to our local
    PC. You have the option to further enhance the modelâ€™s performance by employing
    methods such as quantization, distillation, and other approaches that I will discuss
    in a subsequent article. Itâ€™s crucial to execute all these steps within a fresh
    virtual environment. Be sure to monitor the usage of your computerâ€™s memory during
    the process. A lot of weird errors can hide behind memory issues. If you want
    to download a quantized model be aware you may need to downgrade the `bitsandbytes`
    library to 0.39.1
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°å¦‚ä½•å°† Llama 2 æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ° PCã€‚ä½ è¿˜å¯ä»¥é€šè¿‡ä½¿ç”¨é‡åŒ–ã€è’¸é¦ç­‰æ–¹æ³•è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ€§èƒ½ï¼Œæˆ‘å°†åœ¨åç»­æ–‡ç« ä¸­è®¨è®ºè¿™äº›æ–¹æ³•ã€‚åŠ¡å¿…åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œæ‰€æœ‰è¿™äº›æ­¥éª¤ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œè¯·ç¡®ä¿ç›‘æ§è®¡ç®—æœºçš„å†…å­˜ä½¿ç”¨æƒ…å†µã€‚å¾ˆå¤šå¥‡æ€ªçš„é”™è¯¯å¯èƒ½éšè—åœ¨å†…å­˜é—®é¢˜åé¢ã€‚å¦‚æœä½ æƒ³ä¸‹è½½é‡åŒ–æ¨¡å‹ï¼Œè¯·æ³¨æ„ä½ å¯èƒ½éœ€è¦å°†
    `bitsandbytes` åº“é™çº§åˆ° 0.39.1
- en: Ever tried clicking the â€œclapâ€ button on Medium more than once? â¤ï¸
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ›¾ç»å°è¯•åœ¨ Medium ä¸Šç‚¹å‡»â€œç‚¹èµâ€æŒ‰é’®å¤šæ¬¡å—ï¼Ÿâ¤ï¸
- en: ''
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Letâ€™s be friends! âœ‹. Donâ€™t forget to [subscribe](https://medium.com/subscribe/@anna.bildea)!
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æˆä¸ºæœ‹å‹å§ï¼âœ‹ åˆ«å¿˜äº† [è®¢é˜…](https://medium.com/subscribe/@anna.bildea)!
- en: ''
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/)
    *&* [*X*](https://twitter.com/AnaBildea)!'
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*åœ¨* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/) *å’Œ*
    [*X*](https://twitter.com/AnaBildea) *æ‰¾åˆ°æˆ‘ï¼*'
- en: '*If you find my story compelling and wish to show support for my writing, I
    invite you to consider becoming a Medium member, where you can access a vast collection
    of Generative AI, Data Engineering, and Data Science articles.*'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦‚æœä½ è§‰å¾—æˆ‘çš„æ•…äº‹å¾ˆå¸å¼•äººï¼Œå¹¶å¸Œæœ›æ”¯æŒæˆ‘çš„å†™ä½œï¼Œæˆ‘é‚€è¯·ä½ è€ƒè™‘æˆä¸º Medium ä¼šå‘˜ï¼Œä½ å¯ä»¥è®¿é—®å¤§é‡çš„ç”Ÿæˆ AIã€æ•°æ®å·¥ç¨‹å’Œæ•°æ®ç§‘å­¦æ–‡ç« ã€‚*'
- en: '[](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)
    [## Join Medium with my referral link â€” Bildea Ana'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)
    [## ä½¿ç”¨æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium â€” Bildea Ana'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every storyâ€¦
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½œä¸º Medium çš„ä¼šå‘˜ï¼Œä½ çš„éƒ¨åˆ†ä¼šå‘˜è´¹å°†ç”¨äºæ”¯æŒä½ é˜…è¯»çš„ä½œè€…ï¼Œä½ ä¹Ÿå¯ä»¥å®Œå…¨è®¿é—®æ‰€æœ‰æ•…äº‹â€¦
- en: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)'
- en: See my collection of Generative AI, MLOps, and Responsible AI articles.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹æˆ‘å…³äºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ã€MLOps å’Œè´Ÿè´£ä»»äººå·¥æ™ºèƒ½çš„æ–‡ç« åˆé›†ã€‚
- en: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![Ana Bildea, åšå£«](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea, åšå£«](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: Generative AI
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼äººå·¥æ™ºèƒ½
- en: '[View list](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----8a432ed232a4--------------------------------)11
    stories![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----8a432ed232a4--------------------------------)11ç¯‡æ•…äº‹![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea, åšå£«](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea, åšå£«](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: MLOps - AI in Production
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps - äººå·¥æ™ºèƒ½ç”Ÿäº§
- en: '[View list](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----8a432ed232a4--------------------------------)4
    stories![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)![Ana
    Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----8a432ed232a4--------------------------------)4ç¯‡æ•…äº‹![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)![Ana
    Bildea, åšå£«](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea, åšå£«](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: Responsible AI
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½
- en: '[View list](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----8a432ed232a4--------------------------------)1
    story![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----8a432ed232a4--------------------------------)1ç¯‡æ•…äº‹![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)'
