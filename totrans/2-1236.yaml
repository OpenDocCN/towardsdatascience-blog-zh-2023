- en: How to Send SLURM Jobs to a Cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-send-a-slurm-job-to-a-cluster-dd1cf021c7ac](https://towardsdatascience.com/how-to-send-a-slurm-job-to-a-cluster-dd1cf021c7ac)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A tutorial on how to send SLURM jobs to a cluster, especially for deep learning
    and data science
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@francoisporcher?source=post_page-----dd1cf021c7ac--------------------------------)[![François
    Porcher](../Images/9ddb233f8cadbd69026bd79e2bd62dea.png)](https://medium.com/@francoisporcher?source=post_page-----dd1cf021c7ac--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dd1cf021c7ac--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dd1cf021c7ac--------------------------------)
    [François Porcher](https://medium.com/@francoisporcher?source=post_page-----dd1cf021c7ac--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dd1cf021c7ac--------------------------------)
    ·8 min read·Aug 21, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f7cbe849c11f034a957dfc2a26cf82fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [imgix](https://unsplash.com/@imgix?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: So you are used to train Deep Learning models with the free GPUs of Google Colab,
    but you are ready to level up and harness the power of a cluster, and you have
    no idea how to do that? You’re in the right place! 🚀
  prefs: []
  type: TYPE_NORMAL
- en: During my Research internship in Neurosciences at Cambridge University, I was
    training large models for Computer Vision tasks, and the free GPU provided by
    Google were not enough, so I decided to use the local cluster.
  prefs: []
  type: TYPE_NORMAL
- en: However very little documentation was available and I had to ask for the scripts
    of other people to try to understand them, and more or less compiled several things
    that were useful for me. Now I have compiled everything that is necessary to run
    basic python scripts. This guide is the one I wish I had during my time there.
  prefs: []
  type: TYPE_NORMAL
- en: A typical Machine Learning Use case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s say you want to train a bird classifier, with 500 different classes and
    high resolution pictures. Something that would never run on Google colab.
  prefs: []
  type: TYPE_NORMAL
- en: The very first thing you need to do is ensure your deep learning model training
    script is prepared. This script should contain the necessary code for loading
    your dataset, defining your neural network architecture, and setting the training
    loop.
  prefs: []
  type: TYPE_NORMAL
- en: You should be able to run this script from your terminal.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example let’s say you have a script called `train_bird_classifier.py`,
    you should be able to run it with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This script could look like something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: And instead of running this script on your local computer or Google Colab, we
    are going to run in on a Powerful Cluster. That way you can train larger models
    and faster!
  prefs: []
  type: TYPE_NORMAL
- en: What is SLURM?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SLURM stands for Simple Linux Utility for Resource Management.
  prefs: []
  type: TYPE_NORMAL
- en: It is an open-source **job scheduler** used on supercomputers and computing
    clusters to allocate computational resources for jobs. It’s a workload manager
    that manages, schedules, and supervises the execution of jobs on a cluster of
    machines.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f34f819cbc749f9c6b74e9f3bcec949.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Michał Parzuchowski](https://unsplash.com/@mparzuchowski?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine a bustling train station with multiple tracks and trains coming and
    going. Each train (representing a job) requires specific resources: a platform,
    a departure time, a certain number of cars, and a route. SLURM is like the master
    controller of the station, ensuring each train gets its required resources without
    collisions, delays, or wasting valuable track space.'
  prefs: []
  type: TYPE_NORMAL
- en: It efficiently manages and schedules trains, ensuring they depart and arrive
    in the most optimal way, **maximizing the usage of the station’s capacity**. In
    the world of supercomputers and clusters, SLURM performs a similar orchestration,
    ensuring every computational job is executed smoothly and resourcefully.
  prefs: []
  type: TYPE_NORMAL
- en: How Does SLURM Work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Submission**: Users write scripts that specify their job’s requirements and
    the tasks to be executed. These scripts are submitted using the `sbatch` command.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Queuing**: The submitted jobs are placed in a queue. SLURM uses its scheduling
    algorithms to prioritize these jobs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Resource Allocation**: SLURM checks the resources (like nodes, CPUs, memory)
    available in the cluster and assigns them to jobs based on the job’s requirements
    and its priority in the queue.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Execution**: Once the resources are allocated, the job starts running. During
    its execution, the resources assigned to the job can’t be used by other jobs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Completion**: After the job finishes, the resources are freed and returned
    to the pool, ready to be assigned to other jobs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that you know what is SLURM, here is an overview of the following steps
    we are going to do:'
  prefs: []
  type: TYPE_NORMAL
- en: 0\. Prepare your script you want to execute on the cluster
  prefs: []
  type: TYPE_NORMAL
- en: Write the bash file that calls your script
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Submit your job to the queue
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Optional): Monitor your job'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. Write your bash script
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Your script needs to be a bash file, so it has a `.sh` extension at the end
    of the filename. For example `train_classifier.sh`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your script should always start with a shebang (`#!`) followed by the path
    to the interpreter, usually `/bin/bash` for SLURM scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This line tells the system to execute the script using the Bash shell.
  prefs: []
  type: TYPE_NORMAL
- en: Adding SLURM Directives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`#SBATCH`: In SLURM scripts, `#SBATCH` is a prefix for SLURM-specific directives,
    which provide instructions to the SLURM scheduler. These directives are not executed
    as regular shell commands, but they are read and interpreted by the SLURM scheduler
    to understand how to handle the job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s a breakdown of the most useful directives to write in a script:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Job Name:** (this will be visible on the queue on jobs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'With our example it could be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Account:** If you have GPU credits, they will be used from the account you
    specify.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-A` specifies the account (or project) the job is associated with. This is
    useful for job accounting purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Requeue Setting:** This directive prevents the job from being requeued after
    a failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Partition:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-p` defines the partition (or queue) in which the job should be scheduled.
    A cluster can have different partitions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Nodes and Tasks:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: These directives request a single node (`--nodes=1`) and a single task or CPU
    core (`--ntasks=1`) for the job.
  prefs: []
  type: TYPE_NORMAL
- en: '**GPUs:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--gres` specifies generic resources required by the job. Here, it''s requesting
    one GPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**Email Notifications:** This defines the email address to which SLURM will
    send notifications related to the job.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Job Duration:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--time` sets a limit on the total run time of the job. If the job doesn''t
    complete in 12 hours, SLURM will terminate it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Loading the environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you send your job, you probably have a virtual environment to load. For
    example to load a conda environment you would add:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Running the script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Almost there! Now you just need to specify from which path you want to run
    the scripts, and run the scripts. We do this with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Recap of our `.sh` script so far
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of our bird classifier, it could look like something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 2\. Submit your job
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you have finished to write your script, you are ready to submit your job
    to the queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `sbatch` (stands for submit batch) command to submit the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: That’s it! Your job has been sent to the queue and if there is no error, it
    will be executed!
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Monitor your job
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have submitted your job, it is not being executed right away, it is
    first added to the queue. You can monitor several things about the job you sent
    (its position in the queue, how many jobs are sent, since how much time is it
    being executed).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can monitor this with the `squeue` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: You can also ask detailed information about a specific job with `scontrol show
    job`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If you send several jobs having the same name (it can happen if you submit
    the same job several times with slight variations), you can use `grep`. For instance,
    if you want to search for all jobs with the name “my_job” in the `squeue` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 4\. Cancel a job
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you need to cancel a job, use the `scancel` command in your Shell followed
    by the job ID (you can get it with `squeue`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Please note, if you submit a job and then modify your source code before the
    job starts executing, it will use the latest version of your script at the time
    of execution, not the version from when you submitted the job.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Submitting a SLURM job to a cluster might seem daunting at first, but once you
    get the hang of it, it becomes an integral part of the HPC experience.
  prefs: []
  type: TYPE_NORMAL
- en: Always remember to respect the cluster’s guidelines and resource limits, be
    patient, and continue learning to optimize your workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Hope this guide has helped you!
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks for reading! Before you go:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have checked the notebook on [Google colab.](https://drive.google.com/file/d/1JeZuu11A2ZdkyXD2vKyzJa3weCMOlskn/view?usp=share_link)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check my [compilation of AI tutorials](https://github.com/FrancoisPorcher/awesome-ai-tutorials)
    on Github
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://github.com/FrancoisPorcher/awesome-ai-tutorials?source=post_page-----dd1cf021c7ac--------------------------------)
    [## GitHub - FrancoisPorcher/awesome-ai-tutorials: The best collection of AI tutorials
    to make you a…'
  prefs: []
  type: TYPE_NORMAL
- en: The best collection of AI tutorials to make you a boss of Data Science! - GitHub
    …
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/FrancoisPorcher/awesome-ai-tutorials?source=post_page-----dd1cf021c7ac--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Y*ou should get my articles in your inbox.* [***Subscribe here.***](https://medium.com/@francoisporcher/subscribe)
  prefs: []
  type: TYPE_NORMAL
- en: '*If you want to have access to premium articles on Medium, you only need a
    membership for $5 a month. If you sign up* [***with my link***](https://medium.com/@francoisporcher/membership)*,
    you support me with a part of your fee without additional costs.*'
  prefs: []
  type: TYPE_NORMAL
- en: If you found this article insightful and beneficial, please consider following
    me for more in-depth content! Your support helps me continue producing content
    that aids our collective understanding.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'References:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Yoo, A. B., Jette, M. A., & Grondona, M. (2003). SLURM: Simple Linux Utility
    for Resource Management. *In Job Scheduling Strategies for Parallel Processing*
    (pp. 44–60). Springer, Berlin, Heidelberg. [Link to the paper (if available online)](https://chat.openai.com/URL_HERE)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: SLURM Workload Manager — Official Documentation. [SLURM Documentation](https://slurm.schedmd.com/documentation.html)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Oak Ridge National Laboratory. (Year). *SLURM Training Materials*. Retrieved
    from [Link to training materials](https://chat.openai.com/URL_HERE)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
