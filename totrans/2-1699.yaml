- en: Prompt Engineering Guide
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程指南
- en: 原文：[https://towardsdatascience.com/prompt-engineering-guide-for-data-analysts-54f480ba4d98](https://towardsdatascience.com/prompt-engineering-guide-for-data-analysts-54f480ba4d98)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/prompt-engineering-guide-for-data-analysts-54f480ba4d98](https://towardsdatascience.com/prompt-engineering-guide-for-data-analysts-54f480ba4d98)
- en: '![](../Images/7eb4d92c8f54e60146f7dd4ba68cb20b.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7eb4d92c8f54e60146f7dd4ba68cb20b.png)'
- en: Photo by [Emiliano Vittoriosi](https://unsplash.com/@emilianovittoriosi?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Emiliano Vittoriosi](https://unsplash.com/@emilianovittoriosi?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Principles, Techniques, and Applications to Harness the Power of Prompts in
    LLMs as a Data Analyst
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原则、技术和应用，以作为数据分析师利用LLM中的提示力量
- en: '[](https://tanuwidjajaolivia.medium.com/?source=post_page-----54f480ba4d98--------------------------------)[![Olivia
    Tanuwidjaja](../Images/52a56de28da9b782b57f1c3928655cfb.png)](https://tanuwidjajaolivia.medium.com/?source=post_page-----54f480ba4d98--------------------------------)[](https://towardsdatascience.com/?source=post_page-----54f480ba4d98--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----54f480ba4d98--------------------------------)
    [Olivia Tanuwidjaja](https://tanuwidjajaolivia.medium.com/?source=post_page-----54f480ba4d98--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://tanuwidjajaolivia.medium.com/?source=post_page-----54f480ba4d98--------------------------------)[![Olivia
    Tanuwidjaja](../Images/52a56de28da9b782b57f1c3928655cfb.png)](https://tanuwidjajaolivia.medium.com/?source=post_page-----54f480ba4d98--------------------------------)[](https://towardsdatascience.com/?source=post_page-----54f480ba4d98--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----54f480ba4d98--------------------------------)
    [Olivia Tanuwidjaja](https://tanuwidjajaolivia.medium.com/?source=post_page-----54f480ba4d98--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----54f480ba4d98--------------------------------)
    ·7 min read·May 7, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----54f480ba4d98--------------------------------)
    ·阅读时间7分钟·2023年5月7日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[Large Language Model (LLM)](https://www.youtube.com/watch?v=iR2O2GPbB0E) is
    on the rise, driven by the popularity of [ChatGPT by OpenAI](https://openai.com/blog/chatgpt)
    which took the internet by storm. As a practitioner in the data field, I look
    for ways to best utilize this technology in my work, especially for insightful-yet-practical
    work as a Data Analyst.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[大型语言模型 (LLM)](https://www.youtube.com/watch?v=iR2O2GPbB0E) 的崛起得益于[OpenAI 的
    ChatGPT](https://openai.com/blog/chatgpt)的流行，这一技术引发了互联网的轰动。作为数据领域的从业者，我寻找最佳方法来在工作中利用这一技术，特别是在数据分析师的富有洞察力却实用的工作中。'
- en: LLMs can solve tasks without additional model training via “prompting” techniques,
    in which the **problem is presented to the model as a text prompt**. Getting to
    “**the right prompts**” are important to ensure the model is providing high-quality
    and accurate results for the tasks assigned.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: LLM可以通过“提示”技术解决任务，而无需额外的模型训练，其中**问题以文本提示的形式呈现给模型**。获取“**正确的提示**”对于确保模型为分配的任务提供高质量和准确的结果非常重要。
- en: In this article, I will be sharing the principles of prompting, techniques to
    build prompts, and the roles Data Analysts can play in this “prompting era”.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将分享提示的原则、构建提示的技巧，以及数据分析师在这个“提示时代”中可以发挥的角色。
- en: What is prompt engineering?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: Quoting [Ben Lorica from Gradient Flow](https://gradientflow.com/the-future-of-prompt-engineering-getting-the-most-out-of-llms/),
    “**prompt engineering is the art of crafting effective input prompts to elicit
    the desired output from foundation models**.” It’s the iterative process of developing
    prompts that can effectively leverage the capabilities of existing generative
    AI models to accomplish specific objectives.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 引用[Ben Lorica from Gradient Flow](https://gradientflow.com/the-future-of-prompt-engineering-getting-the-most-out-of-llms/)，
    “**提示工程是设计有效输入提示以引出基础模型期望输出的艺术**。” 这是一个迭代过程，通过开发能够有效利用现有生成型 AI 模型的提示来实现特定目标。
- en: Prompt engineering skills can help us understand the capabilities and limitations
    of a large language model. **The prompt itself acts as an input to the model,
    which signifies the impact on the model output.** A good prompt will get the model
    to produce desirable output, whereas working iteratively from a bad prompt will
    help us understand the limitations of the model and how to work with it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程技能可以帮助我们理解大型语言模型的能力和局限性。**提示本身作为模型的输入，这影响了模型的输出。** 一个好的提示将使模型产生期望的输出，而从一个不好的提示开始逐步工作将帮助我们了解模型的局限性及如何与之合作。
- en: 'Isa Fulford and Andrew Ng in the [ChatGPT Prompt Engineering for Developers
    course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    mentioned two main principles of prompting:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Isa Fulford 和 Andrew Ng 在 [ChatGPT 提示工程开发者课程](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    中提到了提示的两个主要原则：
- en: 'Principle 1: **Write clear and specific instructions**'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原则 1：**编写清晰而具体的指令**
- en: 'Principle 2: **Give the model time to “think”**'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原则 2：**给模型时间“思考”**
- en: I think prompting is *like giving instructions to a naive “machine kid”*.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我认为提示*就像是给一个天真的“机器小孩”下指令*。
- en: The child is very intelligent, but you need to be **clear about what you need**
    from it (by providing explanations, examples, specified output format, etc) and
    **give it some space to digest and process it** (specify the problem-solving steps,
    ask it to slowly process it). The child, given its exposure, can also be *very
    creative and imaginary* in providing answers — which we call a [hallucination
    of the LLM](https://thestack.technology/the-big-hallucination-large-language-models-consciousness/).
    Understanding the context and providing the right prompt might help in avoiding
    this problem.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 孩子非常聪明，但你需要**清楚你需要什么**（通过提供解释、示例、指定的输出格式等）并且**给予他一些时间来消化和处理**（指定解决问题的步骤，要求他慢慢处理）。孩子在得到相应的暴露之后，也可以在提供答案时表现出*非常有创意和想象力*——这被称为[LLM
    的幻觉](https://thestack.technology/the-big-hallucination-large-language-models-consciousness/)。理解上下文并提供正确的提示可能有助于避免这个问题。
- en: Prompt Engineering Techniques
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程技术
- en: Prompt engineering is a growing field, with research on this topic rapidly increasing
    from 2022 onwards. Some of the state-of-the-art prompting techniques commonly
    used include n-shot prompting, chain-of-thought (CoT) prompting, and generated
    knowledge prompting.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是一个不断发展的领域，自 2022 年以来，这方面的研究迅速增加。一些常用的最先进的提示技术包括 n-shot 提示、思维链（CoT）提示和生成知识提示。
- en: '*A sample Python notebook demonstrating these techniques* *is shared under*
    [*this GitHub project.*](https://github.com/oliviatan29/prompt-engineering)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*一个演示这些技术的 Python 笔记本* *可以在* [*这个 GitHub 项目中找到。*](https://github.com/oliviatan29/prompt-engineering)'
- en: '**1\. N-shot prompting (Zero-shot prompting, Few-shot prompting)**'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1\. N-shot 提示（Zero-shot 提示、Few-shot 提示）**'
- en: Known for its variation like Zero-shot prompting and Few-shot prompting, the
    N in N-shot prompting represents the number of “training” or clues given to the
    model to make predictions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: N-shot 提示以其变体如 Zero-shot 提示和 Few-shot 提示而闻名，其中 N 代表给模型的“训练”或提示的数量，以便进行预测。
- en: '**Zero-shot prompting** is where a model makes predictions **without any additional
    training.** This works for common straightforward problems like classification
    (i.e. sentiment analysis, spam classification), text transformation (i.e. translation,
    summarizing, expanding), and simple text generation on which the LLM has been
    largely trained.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**Zero-shot 提示** 是模型在**没有任何额外训练的情况下**进行预测。这适用于分类（即情感分析、垃圾邮件分类）、文本转换（即翻译、总结、扩展）以及LLM
    已经广泛训练的简单文本生成。'
- en: '![](../Images/506a7bd75f299d281a79c711e7f63a67.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/506a7bd75f299d281a79c711e7f63a67.png)'
- en: 'Zero-shot prompting: Straightforwardly ask the model on sentiment (Image by
    Author)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 零-shot 提示：直接询问模型关于情感的问题（图像作者提供）
- en: '**Few-shot prompting** uses a **small amount of data** (typically between two
    and five) **to adapt its output** based on these small examples. These examples
    are meant to steer the model to better performance for a more context-specific
    problem.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**Few-shot 提示** 使用**少量数据**（通常在两个到五个之间）**来调整其输出**，基于这些小示例。这些示例旨在引导模型在更具上下文特定的问题上表现更好。'
- en: '![](../Images/b9d3dfc9576322375ef78cec97c31c4f.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9d3dfc9576322375ef78cec97c31c4f.png)'
- en: 'Few-shot prompting: Give examples of how we expect the model output to be'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Few-shot 提示：提供我们期望模型输出的示例
- en: 2\. Chain-of-Thought (CoT) prompting
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 思维链（CoT）提示
- en: '[Chain-of-Thought prompting](https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html)
    was introduced by Google researchers in 2022\. In the *Chain-of-Thought prompting*,
    the model is prompted to **produce intermediate reasoning steps before giving
    the final answer** to a multi-step problem. The idea is that a model-generated
    chain of thought would mimic an intuitive thought process when working through
    a multi-step reasoning problem.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03c679acfed8e015cadabbfde18c7164.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: Chain-of-Thought prompting helps in driving the model to break down problems
    accordingly
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: This method enables models to decompose multi-step problems into intermediate
    steps, enabling them to solve complex reasoning problems that are not solvable
    with standard prompting methods.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'Some further variations of Chain-of Thought prompting include:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[Self-consistency prompting](https://arxiv.org/pdf/2203.11171.pdf): Sample
    multiple diverse reasoning paths and **select the most consistent answers**. By
    utilizing a majority voting system, the model can arrive at more accurate and
    reliable answers.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Least-to-Most prompting (LtM)](https://arxiv.org/abs/2205.10625): Specify
    the chain of thought to first break a problem into a series of simpler subproblems
    and then **solve them in sequence**. Solving each subproblem is facilitated by
    the answers to previously solved subproblems. This technique is inspired by real-world
    educational strategies for children.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Active Prompting](https://arxiv.org/abs/2302.12246): **Scaling the CoT approach**
    by determining which questions are the most important and helpful ones for human
    annotation. It first calculates the uncertainty among the LLM’s predictions, then
    select the most uncertain questions, and these questions are selected for human
    annotation before being put into a CoT prompt.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3\. Generated knowledge prompting
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The idea behind the [generated knowledge prompting](https://arxiv.org/pdf/2110.08387.pdf)
    is to ask the LLM to **generate potentially useful information** about a given
    question/prompt, and then **leverage that provided knowledge** as additional input
    for generating a final response.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: For example, say you want to write an article about cybersecurity, particularly
    cookie theft. Before asking the LLM to write the article, you can ask it to generate
    some danger and protection against cookie theft. This will help the LLM write
    a more informative blog post.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/63b735ddbcebc6a4f71b74db8974c0a1.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: 'Generated knowledge prompting: (1) Ask the model to generate some content'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ffc1680c472203be05e038dde1a2beb5.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: 'Generated knowledge prompting: (2) Use the generated content as input to the
    model'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Additional tactics
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On top of the above-specified techniques, you can also use these tactics below
    to make the prompting more effective
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '**Use delimiters** like triple backticks (```), angle brackets (<>), or tags
    (<tag> </tag>) to indicate distinct parts of the input, making it cleaner for
    debugging and avoiding prompt injection.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用分隔符** 如三重反引号（```）、尖括号（<>）或标签（<tag> </tag>）来指示输入的不同部分，使其在调试时更清晰，并避免提示注入。'
- en: '**Ask for structured output** (i.e. HTML/JSON format), this is useful for using
    the model output for another machine processing.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**要求结构化输出**（即 HTML/JSON 格式），这对于将模型输出用于其他机器处理非常有用。'
- en: Specify the **intended tone of the text** to get the tonality, format, and length
    of model output that you need. For example, you can instruct the model to formalize
    the language, generate not more than 50 words, etc.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定 **预期的文本语气** 以获得所需的模型输出的语气、格式和长度。例如，你可以指示模型将语言正式化，生成不超过 50 个字等。
- en: Modify the model’s **temperature parameter** to play around the model’s degree
    of randomness. The higher the temperature, the model’s output would be random
    than accurate, and even hallucinate.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改模型的 **温度参数** 以调整模型的随机性。温度越高，模型输出会越随机而不准确，甚至可能产生幻觉。
- en: '*A sample Python notebook demonstrating these techniques* *is shared under*
    [*this GitHub project.*](https://github.com/oliviatan29/prompt-engineering)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*一个展示这些技术的 Python 示例笔记本* *在* [*这个 GitHub 项目中共享。*](https://github.com/oliviatan29/prompt-engineering)'
- en: '![](../Images/e6afbdbdd508428b09ef83b6f52eb01d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6afbdbdd508428b09ef83b6f52eb01d.png)'
- en: Photo by [Camylla Battani](https://unsplash.com/@camylla93?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Camylla Battani](https://unsplash.com/@camylla93?utm_source=medium&utm_medium=referral)
    拍摄，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The Role of Analysts in Prompt Engineering
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析师在提示工程中的角色
- en: As you can possibly infer from the examples above, prompt engineering requires
    a very specific technical communication craft. While you still require business
    context and problem-solving skills, it is still a new kind of craft that is not
    entirely covered as part of a [conventional data analytics skillset](https://medium.com/towards-data-science/how-does-a-remarkable-data-analyst-look-like-dd0e4326c670).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从上述示例中可能推断出的那样，提示工程需要非常具体的技术沟通技巧。虽然你仍然需要业务背景和问题解决技能，但这仍然是一种新的工艺，并不完全包含在 [传统数据分析技能集](https://medium.com/towards-data-science/how-does-a-remarkable-data-analyst-look-like-dd0e4326c670)中。
- en: 'Data Analysts can leverage their context knowledge, problem-solving skills,
    and statistical/technical capabilities, with the addition of effective communication
    for prompt engineering. These are the key tasks related to prompt engineering
    (and LLMs) which potentially be done by Analysts:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析师可以利用他们的上下文知识、问题解决技能以及统计/技术能力，再加上有效的沟通来进行提示工程。这些是与提示工程（和 LLM）相关的关键任务，可能由分析师完成：
- en: '**Specifying LLM problems to be solved**. With an understanding of the LLM
    concepts, we can define the actions to be executed by the model (i.e. whether
    it is text classification, generation, or transformation problem) and the right
    question with reference points to be put as the prompts.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指定要解决的 LLM 问题**。了解 LLM 概念后，我们可以定义模型要执行的操作（即是文本分类、生成还是转换问题）以及要作为提示的正确问题和参考点。'
- en: '**Iterative prompting**. In developing a data model, oftentimes we go through
    an iterative process. After building the initial model, we evaluate the result,
    refine it, and retry it along the way. Similarly for a prompt, we analyze where
    the result does not give what you want, and refine it with clearer instructions,
    additional examples, or specified steps. This requires critical reasoning which
    most Data Analysts are already good at.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代提示**。在开发数据模型时，我们通常会经历一个迭代过程。在构建初始模型后，我们评估结果，进行优化，并在过程中重新尝试。对于提示也是如此，我们分析结果与期望不符的地方，并通过更清晰的指令、额外的示例或特定的步骤进行优化。这需要批判性思维，而大多数数据分析师已经擅长这一点。'
- en: '**Prompt versioning and management**. With iterative prompting, you will end
    up with numerous prompt attempts, and the identified model capabilities and/or
    limitations. It is important to keep track of and document these findings for
    team learning and continuous improvement, as with any other existing data analysis.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示版本控制和管理**。通过迭代提示，你将得到大量的提示尝试和识别出的模型能力和/或限制。重要的是记录这些发现以供团队学习和持续改进，就像其他现有的数据分析一样。'
- en: '**Designing for safe-prompting**. Although it has shown impressive capabilities,
    LLM is still in a very early stage and is prone to loopholes and limitations.
    There is this [hallucination problem](https://thestack.technology/the-big-hallucination-large-language-models-consciousness/)
    where models provide highly misleading information, and also [prompt injection](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)
    risk of getting untrusted text is used as part of the prompt. Depending on the
    use case of the model and prompting, Analysts can advise programmatic safeguards
    to limit the prompt usage and analysis of problematic prompting detection.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设计安全提示**。尽管表现出令人印象深刻的能力，LLM 仍处于非常早期的阶段，容易出现漏洞和局限性。存在[幻觉问题](https://thestack.technology/the-big-hallucination-large-language-models-consciousness/)，模型提供高度误导性的信息，以及[提示注入](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)的风险，其中不可信的文本作为提示的一部分使用。根据模型和提示的使用情况，分析师可以建议编程保护措施，以限制提示的使用和问题提示的检测。'
- en: On top of leveraging the existing skills, Analysts need to **hone their communication
    skills and the ability to break down problems** to provide better prompts.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了利用现有技能外，分析师还需要**磨练沟通技巧和分解问题的能力**，以提供更好的提示。
- en: Conclusion
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Large Language Models have shown promising results in performing numerous types
    of language tasks, and **prompt engineering is the key to unlocking these capabilities**.
    Prompt engineering is about communicating effectively with an AI to achieve desired
    results.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型在执行各种语言任务方面显示出了令人鼓舞的结果，而**提示工程是解锁这些能力的关键**。提示工程是与 AI 有效沟通以实现预期结果的过程。
- en: Several techniques can be used to do prompt engineering, but the foundational
    principle is consistent. It is about providing clear instructions to the model
    and helping it in digesting and processing these instructions. **Data Analysts
    can leverage their context knowledge and problem-solving skills to frame the right
    prompts and leverage their technical capabilities for designing prompt safeguards**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用几种技术进行提示工程，但基本原则是一致的。这涉及向模型提供明确的指令，并帮助其理解和处理这些指令。**数据分析师可以利用他们的背景知识和解决问题的技能来框定正确的提示，并利用他们的技术能力来设计提示保护措施**。
- en: 'For further resources on prompt engineering, check out:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 欲获取更多有关提示工程的资源，请查看：
- en: '[ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/chatgpt-prompt-eng)
    (DeepLearning.AI course)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT 提示工程课程](https://learn.deeplearning.ai/chatgpt-prompt-eng)（DeepLearning.AI
    课程）'
- en: '[LearnPrompting.org](https://learnprompting.org/docs/intro)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LearnPrompting.org](https://learnprompting.org/docs/intro)'
- en: '[PromptingGuide.ai](https://www.promptingguide.ai/)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PromptingGuide.ai](https://www.promptingguide.ai/)'
- en: '[OpenAI applications documentation](https://platform.openai.com/examples)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI 应用文档](https://platform.openai.com/examples)'
- en: '[The Future of Prompt Engineering: Getting The Most Out of LLMs](https://gradientflow.com/the-future-of-prompt-engineering-getting-the-most-out-of-llms/)
    (Gradient Flow article)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提示工程的未来：最大限度地发挥 LLM 的潜力](https://gradientflow.com/the-future-of-prompt-engineering-getting-the-most-out-of-llms/)（Gradient
    Flow 文章）'
- en: I believe this area will grow even further in the next few years, and I’m excited
    to see and take part in the evolution.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信这个领域在接下来的几年中会进一步发展，我很兴奋能够见证并参与这场演变。
