- en: Decoding Auto-GPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/decoding-auto-gpt-fae16ff1ee75](https://towardsdatascience.com/decoding-auto-gpt-fae16ff1ee75)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The Mechanics of an **Autonomous** GPT-4
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)[![Maarten
    Grootendorst](../Images/58e24b9cf7e10ff1cd5ffd75a32d1a26.png)](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)
    [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)
    ·8 min read·Aug 8, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ccce7f423325fb2990f06b6a85bc947e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: There have been many interesting, complex, and innovative solutions since the
    release of ChatGPT. The community has explored countless possibilities for improving
    its capabilities.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: One of those is the well-known [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)
    package. With more than **140k stars**, it is one of the highest-ranking repositories
    on Github!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/47bcc2b61fc850759406607d46b2e448.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
- en: Auto-GPT’s number of stars on Github. Retrieved from star-history.com
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Auto-GPT is an attempt at making GPT-4 fully **autonomous**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Auto-GPT gives GPT-4 the power to make its own decisions
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It sounds incredible and it definitely is! But how does it work?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we will go through Auto-GPT’s architecture and explore how it
    can reach autonomous behavior.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: The Architecture
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Auto-GPT has an overall architecture, or a main loop of sorts, that it uses
    to model autonomous behavior.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by describing this overall after which we will go through each
    step in-depth:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b5f05f9f213c9fd03d615fed94a6648.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: The main cyclical loop that describes Auto-GPT main’s autonomous behavioral
    mechanism.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'The core of Auto-GPT is a cyclical sequence of steps:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the **prompt** with summarized information
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GPT-4 proposes an **action**
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The action is **executed**
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Embed** both the input and output of this cycle'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save embeddings to a **vector database**
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These 5 steps make up the core of Auto-GPT and represent its main autonomous
    behavior.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Before we go through each step in-depth, there is a step before this cyclical
    sequence, namely **initializing the agent**.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 0\. Initializing the Agent
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before Auto-GPT completes a task fully autonomous, it first needs to initialize
    an **Agent**. This agent essentially describes who GPT-4 is and what goal it should
    pursue
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say that we want Auto-GPT to create a **recipe for vegan chocolate**.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'With that goal in mind, we need to give GPT-4 a bit of context about what an
    agent should be and what it should achieve:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8501a4534e2d7a1f8b5225d99593e41c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: 'Prompt: Create sub-goals and a name for our Agent.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a prompt defining two things:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Create **5 highly effective goals** (these can be updated later on)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an appropriate **role-based name** (_GPT)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The name helps GPT-4 to continuously remember what it should model. The sub-goals
    are especially helpful to make small tasks for it to achieve.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we give an example of what the desired output should be:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/561098a39fbbf7494190604c759d992f.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: 'Prompt: GPT-4 works much better if we provide it with an example of the desired
    output.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Giving examples to any generative Large Language Model works really well. By
    describing what the output should look like, it more easily generates accurate
    answers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'When we pass this prompt to GPT-4 using Auto-GPT, we get the following response:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d970a4adac0e66e1d2b807d2a680f10f.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: GPT-4 created a description of **RecipeGPT** for us!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: It seems that GPT-4 has created a description of **RecipeGPT** for us. We can
    give this context to GPT-4 as a **system prompt** so that it continuously remembers
    its purpose.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Now that Auto-GPT has created a description of its agent, along with clear goals,
    it can start by taking its first autonomous action.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 1\. First Prompt
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The very first step in its cyclical sequence is creating the prompt that triggers
    an action.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/11f292d65655d4fa7ed8cbc8348f9a08.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: The first step in Auto-GPT’s autonomous cycle. We ask GPT-4 to use a single
    command based on a system prompt and a summary of events that happened in the
    past.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompt consists of three components:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: System Prompt
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Call to Action
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will go into the summary a bit later but the call to action is nothing more
    than asking GPT-4 which command it should use. The commands GPT-4 can use are
    defined in its **System Prompt**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: System Prompt
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The system prompt is the context that we give to GPT-4 so that it remembers
    certain guidelines that it should follow.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/024e942b605d6147de555b6abea2c401.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: The format of the system prompt.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown above, it consists of **six guidelines**:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: The goals and description of the initialized **Agent**
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Constrains** it should adhere to'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Commands** it can use'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resources** it has access to'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluation** steps'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example of a valid **JSON** output
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last five steps are essentially constraints the Agent should adhere to.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a more in-depth overview of what these guidelines and constraints generally
    look like:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68a2472fee1ebf891ddde6670d773b3d.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
- en: The constraints that are given in the system prompt.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the system prompt sketches the boundaries in which GPT-4 can
    act. For example, in *“Resources”,* it describes that GPT-4 can use GPT-3.5 Agents
    for the delegation of simple tasks. Similarly, *“Evaluation,”* tells GPT-4 that
    it should continuously self-criticize its own behavior to improve upon its next
    actions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Example of the First Prompt
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Together, the very first prompt looks a bit like the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3fa3a09bac37d892796ec859bd373dec.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: 'The full first prompt. Note the three components: System prompt, summary, and
    call to action.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Notice that in blue *“I was created”* is mentioned. Typically, this would contain
    a summary of all the actions it has taken. Since it was just created, it has no
    action taken before and the summary is nothing more than *“I was created”*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. GPT-4 Proposes an Action**'
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In step 2, we give GPT-4 the prompt we defined in the previous step. It can
    then propose an action to take which should adhere to the following format:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d67b46daaf0b8fb09398db89784aeea.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: The second step in Auto-GPT’s autonomous cycle. GPT-4 executes the previous
    command and uses a framework called ReACT to demonstrate complex output.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see six individual steps being mentioned:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Thoughts
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reasoning
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plan
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Criticism
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speak
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Action
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These steps describe a format of prompting called Reason and ACT (**ReACT**).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: ReACT is one of Auto-GPT’s superpowers!
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ReACT allows for GPT-4 to mimic self-criticism and demonstrate more complex
    reasoning than what is possible if we just ask the model directly.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f4e63816bf2e6227c1aeea98249a3bc6.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
- en: A basic and illustrative example of ReACT. Most GPT models would get this question
    right with the basic prompt but it demonstrates how you could use ReACT for more
    complex questions.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we ask GPT-4 a question using the ReACT framework, we ask GPT-4 to
    output individual thoughts, actions, and observations before coming to a conclusion.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: By having the model mimic extensive reasoning, it tends to give more accurate
    answers compared to directly answering the question.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, Auto-GPT has extended the base ReACT framework and generates
    the following response:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cda528db7142676e6b4166132a19f5fa.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: The ReACT framework as used by Auto-GPT
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, it follows the ReACT pipeline that we described before but includes
    additional criticism and reasoning steps.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: It proposes to **search the web** to extract more information about popular
    recipes.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Execute Action
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After having generated a response, in valid JSON format. We can extract what
    the **RecipeGPT** wants to do. In this case, it calls for a web search:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c7fa15cb60dfc77a715e91e24b90c07a.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: The next action as proposed by GPT-4.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'and in turn, will execute searching the web:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/31b6ef621b9c64174ff6fc063eedd73a.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
- en: The third step in Auto-GPT’s autonomous cycle. Auto-GPT executes the previously
    proposed behavior.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: This action it can take, searching the web, is simply a tool at its disposal
    that generates a file containing the main body of the page.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Since we explained to GPT-4 in its system prompt that it can use web search,
    it considers this a valid action.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Auto-GPT is as autonomous as the number of tools it possesses
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do note that if the only tool at its disposal is searching the web, then we
    can start to argue how autonomous such a model really is!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Either way, we *save the output to a file* for later use.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Embed Everything!
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every step Auto-GPT has taken thus far is vital information for any next steps
    to take. Especially when it needs to take dozens of steps, for example for [taking
    over the world](https://www.youtube.com/@ChaosGPT), remembering what it has done
    thus far is important.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: One method of doing so is by embedding the prompts and output it has generated.
    This allows us to convert text into numerical representations (embeddings) that
    we can save later on.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a220ef903d1c500864650ac14cd456f7.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: The fourth step in Auto-GPT’s autonomous cycle. Embed every relevant text it
    has seen thus far. Input, output, observations, actions, etc.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: These embeddings are generated using OpenAI’s *text-embedding-ada-002* model
    which works tremendously well across [many use cases](https://huggingface.co/spaces/mteb/leaderboard).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Vector Database + Summarization
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After having generated the embeddings, we need a place to store them. [Pinecone](https://pinecone.io/)
    is often used to create the vector database but many other systems can be used
    as long as you can easily find similar vectors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a9deac81005d34d3ae61547f6c6b96da.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: The fifth step in Auto-GPT’s autonomous cycle. Save all embeddings in a vector
    database such that they can easily be accessed and searched for.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The vector database allows us to quickly find information for an input query.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'We can query the vector database to find all steps it has taken thus far. Using
    that information, we ask GPT-4 to create a **summary** of all actions it has taken
    thus far:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f1a6782a5aa64ddb3065b0d6b3022589.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
- en: Create a summary of everything that has happened thus far using the vector database
    and GPT-4.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: This summary is then used to construct the prompt as we did in step 1.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: That way, it can *“remember”* what it has done thus far and think about the
    next steps to be taken.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: This completes the very first cycle of Auto-GPT’s autonomous behavior!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Do it all over again!
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you might have guessed, the cycle continues from where we started, asking
    GPT-4 to take action based on a history of actions.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e979f9aac8d9b60dadf8999b1f1172b.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: Auto-GPT’s cycle of Autonomy.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Auto-GPT will continue until it has reached its goal or when you interrupt it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: During this cyclical process, it can keep track of estimated costs in order
    to make sure you do not spend too much on your Agent.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: In the future, especially with the release of [Llama2](https://huggingface.co/meta-llama/Llama-2-7b),
    I expect and hope that local models can reliably be used in Auto-GPT!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，特别是随着[Llama2](https://huggingface.co/meta-llama/Llama-2-7b)的发布，我期望并希望本地模型能在Auto-GPT中可靠地使用！
- en: Thank you for reading!
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you are, like me, passionate about AI and/or Psychology, please feel free
    to add me on [**LinkedIn**](https://www.linkedin.com/in/mgrootendorst/), follow
    me on [**Twitter**](https://twitter.com/MaartenGr), or subscribe to my [**Newsletter**](http://maartengrootendorst.substack.com/).
    You can also find some of my content on my [**Personal Website**](https://maartengrootendorst.com/).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你和我一样，对AI和/或心理学充满热情，请随时在[**LinkedIn**](https://www.linkedin.com/in/mgrootendorst/)上添加我，关注我的[**Twitter**](https://twitter.com/MaartenGr)，或订阅我的[**Newsletter**](http://maartengrootendorst.substack.com/)。你也可以在我的[**Personal
    Website**](https://maartengrootendorst.com/)上找到我的一些内容。
- en: '*All images without a source credit were created by the author*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有没有来源注明的图片均由作者创作*'
