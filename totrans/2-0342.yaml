- en: 'Auto-Sklearn: How To Boost Performance and Efficiency Through Automated Machine
    Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/auto-sklearn-how-to-boost-performance-and-efficiency-through-automated-machine-learning-2db116eafc8](https://towardsdatascience.com/auto-sklearn-how-to-boost-performance-and-efficiency-through-automated-machine-learning-2db116eafc8)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how to leverage AutoML to maximize the outcome of your machine learning
    workflows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://thomasdorfer.medium.com/?source=post_page-----2db116eafc8--------------------------------)[![Thomas
    A Dorfer](../Images/9258a1735cee805f1d9b02e2adf01096.png)](https://thomasdorfer.medium.com/?source=post_page-----2db116eafc8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2db116eafc8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2db116eafc8--------------------------------)
    [Thomas A Dorfer](https://thomasdorfer.medium.com/?source=post_page-----2db116eafc8--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2db116eafc8--------------------------------)
    ·6 min read·Apr 11, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0f74ab8af9c187dadb32d4f6575137dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: Many of us are familiar with the challenge of selecting a suitable machine learning
    model for a specific prediction task, given the [vast number](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)
    of models to choose from. On top of that, we also need to find optimal hyperparameters
    in order to maximize our model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: These challenges can largely be overcome through automated machine learning,
    or [AutoML](https://www.automl.org/automl/). I say *largely* because, despite
    its name, the process is not *fully* automated and still requires some manual
    tweaking and decision-making by the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Essentially, AutoML frees the user from the daunting and time-consuming tasks
    of data preprocessing, model selection, hyperparameter optimization, and ensemble
    building. As a result, this toolkit not only saves precious time for the experts,
    but also enables non-technical users to break into the field of machine learning.
    In the words of the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: Automated Machine Learning provides methods and processes to make Machine Learning
    available for non-Machine Learning experts, to improve efficiency of Machine Learning
    and to accelerate research on Machine Learning.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While there are many AutoML packages out there, such as [AutoWEKA](http://www.cs.ubc.ca/labs/beta/Projects/autoweka/),
    [Auto-PyTorch](https://github.com/automl/Auto-PyTorch), or [MLBoX](https://github.com/AxeldeRomblay/MLBox),
    this article will focus on [**Auto-Sklearn**](https://automl.github.io/auto-sklearn/master/)
    — a library built on top of the popular [scikit-learn](https://scikit-learn.org/stable/index.html)
    package.
  prefs: []
  type: TYPE_NORMAL
- en: What is Auto-Sklearn?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Auto-Sklearn is a Python-based, open-source library that automates machine learning
    processes such as data and feature preprocessing, algorithm selection, hyperparameter
    optimization, and ensemble building. In order to achieve this high degree of automation,
    the library leverages recent advances in Bayesian optimization and also takes
    into account past performance on similar datasets.
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, it improves upon previous methods in three key ways. First,
    it introduces the concept of warm start [**Bayesian optimization**](https://en.wikipedia.org/wiki/Bayesian_optimization),
    which allows for efficient hyperparameter tuning across multiple datasets by leveraging
    information learned from previous runs. Additionally, it enables **automatic**
    [**ensemble construction**](https://en.wikipedia.org/wiki/Ensemble_learning) of
    the models considered by Bayesian optimization, further improving model performance.
    Finally, Auto-Sklearn comes with a highly parameterized machine learning framework
    that incorporates high-performing classifiers and preprocessors from [**scikit-learn**](https://scikit-learn.org/stable/),
    allowing for flexible and customizable model building.
  prefs: []
  type: TYPE_NORMAL
- en: In total, Auto-Sklearn contains 16 classifiers, 14 feature preprocessing methods,
    and numerous data preprocessing methods, which collectively give rise to a hypothesis
    space with 122 hyperparameters. These numbers are constantly evolving with new
    releases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of this library is pretty straightforward. In fact, the
    trickiest part is its [installation](https://automl.github.io/auto-sklearn/master/installation.html)
    as it is incompatible with Windows and reportedly also has some issues on Mac.
    It is therefore recommended to run it on a Linux operating system (pro-tip: [Google
    Colab](https://colab.research.google.com/) runs on Linux, so you can use that
    as your experimentation playground).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once installed, Auto-Sklearn can be run with just four lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: However, some manual tweaking and parameterization is still recommended to align
    the user’s intent with the model’s output. Let’s now have a look at how Auto-Sklearn
    can be used in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Practical Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we’ll compare the performance of a single classifier with default
    parameters — in this case, I chose a [decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)
    — with the one of Auto-Sklearn. To do so, we’ll be using the publicly available
    *Optical Recognition of Handwritten Digits* [dataset](https://archive-beta.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits),
    whereby each sample consists of an 8x8 image of a digit — hence, dimensionality
    is 64\. In total, this dataset is comprised of 1797 samples that are assigned
    to 10 unique classes (~180 samples per class).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some samples of this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/50fc6f670063bfbdae631f9a20093d36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the Author. License information for data usage: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset can be loaded into Python and split into train and test sets as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Benchmark: Decision Tree Classifier'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s train a simple decision tree with default parameters on this dataset
    and see how well it performs under these circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This simple approach yields an accuracy of 86.67% — decent, but not exactly
    extraordinary. Let’s see if we can outperform this result with Auto-Sklearn.
  prefs: []
  type: TYPE_NORMAL
- en: Auto-Sklearn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before running this, let’s define some parameters first:'
  prefs: []
  type: TYPE_NORMAL
- en: '`time_left_for_this_task`: time limit in seconds for the total duration of
    the search. The higher this limit, the higher the chances of finding better models.
    The default value is 3600, which corresponds to 1 hour.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`per_run_time_limit`: time limit for a single call to the machine learning
    model. If the algorithm exceeds this limit, model fitting will be terminated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ensemble_size`: Number of models added to the ensemble. This can be set to
    1 if no ensemble fit is desired.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now we can fit a model using Auto-Sklearn. We will let the task run for 3 minutes
    and will limit the time for a single model call to 30 seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This gives us an accuracy of 98.67% — a remarkable increase from our simplistic
    benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can obtain some further insights into the training process with the `sprint.statistics()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f088f5426c0218432796e8cf3c8a54ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, we can see that our best validation score was 98.88%, that 23
    out of 30 algorithms successfully ran, 6 timed out, and 1 exceeded the memory
    limit. Based on that, we could increase the time limit parameters to see if that
    would increase performance even further.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `leaderboard()` method, we can also visualize a table of results
    for all evaluated models (FYI: this table was visualized in a lollipop plot, which
    is the feature image of this article):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b7eba448c86deccd959512b63c67a71b.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'More details about the individual models that went into the ensemble can be
    obtained through the `show_models()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/611ce8a49552f5a59c40bed9eeb79e63.png)'
  prefs: []
  type: TYPE_IMG
- en: Only showing 2 out of 15 models here. Screenshot by the Author.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** While ensembles can certainly boost model performance and robustness,
    they do have some downsides such as increased complexity, increased training time,
    and lack of interpretability. Ensemble fitting can be deactivated as follows:
    `ensemble_size=1`.'
  prefs: []
  type: TYPE_NORMAL
- en: Auto-Sklearn 2.0 — What’s New?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Last year, various improvements to Auto-Sklearn were released in a [paper](https://www.jmlr.org/papers/volume23/21-0992/21-0992.pdf)
    titled *“Auto-Sklearn 2.0: Hands-free AutoML via Meta-Learning”*. Among the major
    improvements are (1) **early stopping**, which increases efficiency and ensures
    that a result is obtained even if the training times out, (2) **improved model
    selection strategies**, which includes the integration of multiple approaches
    to approximate the generalization error and the addition of [Bayesian Optimization
    and Hyperband (BOHB)](https://www.automl.org/blog_bohb/), a versatile tool for
    hyperparameter optimization at scale, and (3) automated policy selection through
    meta-learning that relieves the user from choosing the configuration of the AutoML
    system.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To summarize, Auto-Sklearn is a powerful and user-friendly library that relieves
    the user from the rather challenging and time-consuming tasks of data and feature
    preprocessing, model selection, hyperparameter tuning, and, if desired, ensemble
    building. This has been shown to dramatically increase performance and efficiency
    of various machine learning tasks. Despite the requirement of *some* user input,
    Auto-Sklearn is reasonably automated and, consequently, also allows novices and
    non-technical users to implement sophisticated machine learning solutions in just
    a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Interested in trying it yourself? Check out the [many examples](https://automl.github.io/auto-sklearn/master/examples/index.html)
    made available by the AutoML community.
  prefs: []
  type: TYPE_NORMAL
- en: More Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[AutoML | Auto-Sklearn](https://www.automl.org/automl/auto-sklearn/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Documentation:* [auto-sklearn — AutoSklearn 0.15.0 documentation (automl.github.io)](https://automl.github.io/auto-sklearn/master/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Auto-Sklearn Paper:* [Efficient and Robust Automated Machine Learning (neurips.cc)](https://proceedings.neurips.cc/paper_files/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Auto-Sklearn 2.0 Paper:* [[2007.04074] Auto-Sklearn 2.0: Hands-free AutoML
    via Meta-Learning (arxiv.org)](https://arxiv.org/abs/2007.04074)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Auto-Sklearn 2.0 Blog:* [AutoML | Auto-Sklearn 2.0: The Next Generation](https://www.automl.org/auto-sklearn-2-0-the-next-generation/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liked this article?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s connect! You can find me on [Twitter](https://twitter.com/ThomasADorfer),
    [LinkedIn](https://www.linkedin.com/in/thomasdorfer/) and [Substack](https://thomasdorfer.substack.com/).
  prefs: []
  type: TYPE_NORMAL
- en: If you like to support my writing, you can do so through a [Medium Membership](https://thomasdorfer.medium.com/membership),
    which provides you access to all my stories as well as those of thousands of other
    writers on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@thomasdorfer/membership?source=post_page-----2db116eafc8--------------------------------)
    [## Join Medium with my referral link - Thomas A Dorfer'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Thomas A Dorfer (and thousands of other writers on Medium).
    Your membership fee directly supports…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@thomasdorfer/membership?source=post_page-----2db116eafc8--------------------------------)
  prefs: []
  type: TYPE_NORMAL
