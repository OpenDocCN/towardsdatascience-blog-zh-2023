# 开源LLMs的历史：早期阶段（第一部分）

> 原文：[https://towardsdatascience.com/the-history-of-open-source-llms-early-days-part-one-d782bcd8f7e8](https://towardsdatascience.com/the-history-of-open-source-llms-early-days-part-one-d782bcd8f7e8)

## 理解GPT-Neo、GPT-J、GLM、OPT、BLOOM等…

[](https://wolfecameron.medium.com/?source=post_page-----d782bcd8f7e8--------------------------------)[![Cameron R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----d782bcd8f7e8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d782bcd8f7e8--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d782bcd8f7e8--------------------------------) [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----d782bcd8f7e8--------------------------------)

·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d782bcd8f7e8--------------------------------) ·阅读时间20分钟·2023年11月7日

--

![](../Images/05d30e1fd65a03fd2cb858285b0d7f58.png)

（图片由 [Chris Lawton](https://unsplash.com/@chrislawton?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) 提供，来自 [Unsplash](https://unsplash.com/photos/stack-of-six-brown-hardbound-books-9T346Ij4kGk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)）

语言建模的研究有着悠久的历史，可以追溯到类似GTP和GPT-2的模型，甚至是早于现代变换器基础语言模型的RNN技术（例如，[ULMFit](https://arxiv.org/abs/1801.06146)）。尽管历史悠久，但语言模型在相对最近才变得流行。第一次流行的兴起来自于GPT-3的提出，[1]展示了通过自监督预训练和上下文学习的结合，可以在许多任务中实现令人印象深刻的少量学习性能；见下文。

![](../Images/3052b7fe6011e83507c05a91e32c5cda.png)

（来自 [1]）

在此之后，GPT-3获得的认可促使了大量大型语言模型（LLMs）的提出。不久之后，语言模型对齐的研究导致了更为出色的模型的创建，如InstructGPT [19]，以及最著名的其姊妹模型ChatGPT。这些模型的出色表现引发了对语言建模和生成式AI的广泛兴趣。

尽管非常强大，但许多早期 LLM 研究中的发展有一个共同特点——*它们是闭源的*。当语言模型首次开始获得广泛认可时，许多最强大的 LLM 只能通过付费 API 访问（例如，[OpenAI API](https://openai.com/blog/openai-api)），而研究和开发这些模型的能力仅限于特定的个人或实验室。这种方法明显不同于典型的 AI 研究实践，后者通常鼓励开放和思想共享，以促进前进的进步。

> “这种受限的访问限制了研究人员理解这些大型语言模型如何以及为何工作的能力，阻碍了改进其鲁棒性和缓解已知问题（如偏见和毒性）的努力。” *——来自 [4]*

**这一概述。** 尽管最初强调的是专有技术，LLM 研究社区慢慢开始创建流行语言模型如 GPT-3 的开源变体。尽管首批开源语言模型在性能上落后于最佳的专有模型，但它们为 LLM 研究中的改进透明度奠定了基础，并催化了许多更强大的后续模型的发展（例如，Falcon [10] 和 [LLaMA-2](https://ai.meta.com/llama/)）。

这一概述是一个三部分系列的一部分，探索开源语言模型的历史。在这里，我们将了解这一历史的开端，包括若干初步尝试创建开源语言模型的努力。尽管这些模型在性能上有所欠缺，但它们对理解至关重要，因为随后的开源 LLM 革命完全基于这些模型。在系列的接下来的两部分中，我们将深入了解最近的开源 LLM 以及如何使用模仿和对齐技术来提高它们的性能。

![](../Images/b4a5c7276cf2250f14c9aa6ede26289b.png)

（来自 [12, 20]）

# 语言模型的机制

开源 LLM 研究催化了透明度和思想共享，创造了一个研究人员能够更快地合作和创新的环境。简单来说，*开源 LLM 研究的美在于它让我们有可能研究这些令人难以置信的模型，并深入理解它们的工作原理*。没有隐藏在付费 API 或黑箱中的未知技巧。开源 LLM 允许我们查看代码，进行实验，甚至尝试我们自己的想法和修改——我们对基础模型拥有完全的访问权限！

> “AI 社区的更广泛领域需要访问这些模型，以便进行可重复的研究，并共同推动该领域的发展。” *——来自 [4]*

但要深入理解这些模型，我们首先需要了解它们的基本工作原理。在本节中，我们将概述这些理念，尝试提供对大型语言模型（LLMs）的（相对）全面理解。

## 语言建模目标

![](../Images/c5c67554d791155729ae174c08d04176.png)

使用语言建模目标进行预训练（由作者创建）

语言建模的核心是下一个令牌预测（也称为标准语言建模目标），它用于训练几乎所有的语言模型。为了使用下一个令牌预测训练语言模型，我们需要一个大规模的原始文本语料库。利用这个语料库，我们通过* i)* 从数据集中抽取一些文本和* ii)* 训练模型以预测下一个单词来训练模型；见上文。因为真实的下一个令牌总是可以从原始文本中推断出来，所以下一个令牌预测是一种自监督学习的方法。

**什么是令牌？** 可以大致将下一个令牌预测理解为在给定前几个单词作为上下文的情况下预测序列中的下一个单词。然而，这种类比并不完全准确，因为令牌和单词并不完全相等。当语言模型接收文本作为输入时，原始文本首先被分词（即，转换为离散的单词或子单词序列）；见下文。

![](../Images/6c211f85a2ac29498592c09a5374c7cd.png)

将原始文本转换为令牌序列（由作者创建）

与语言模型相关联的分词器通常具有固定大小的词汇表，或可以从文本序列中创建的可用令牌集合。

**预测下一个令牌。** 一旦创建了令牌序列，语言模型就具有一个嵌入层，为分词器词汇表中的每个令牌存储一个唯一且可学习的向量嵌入。利用这个嵌入层，我们可以将输入序列中的每个令牌转换为相应的向量嵌入，形成令牌向量序列；见下文。

![](../Images/625fd4aecf4cab6c12ca2f211743b89d.png)

对原始文本数据进行分词和嵌入（由作者创建）

在每个令牌上添加位置嵌入后，我们可以将这个令牌向量序列传递给仅解码器的变换器（更多解释将随后介绍），它将这些令牌向量进行转换（无双关意味），并为每个令牌生成相应的输出向量。值得注意的是，输出向量的数量与输入向量的数量相同；见下文。

![](../Images/ba20b8238f80f8417a7af042de5c78dd.png)

使用仅解码器的变换器处理令牌（由作者创建）

现在我们为每个令牌有了输出表示，我们准备进行下一个令牌预测了！对于序列中的每个令牌，我们只需取其输出令牌向量并使用它来预测序列中接下来的令牌！下面展示了这一过程的示意图。在实际应用中，这一目标同时在序列中的所有令牌（以及在一个小批量中的所有序列）上进行计算，以最大化效率。

![](../Images/2e4f766f68636c5671f11d86eec16030.png)

计算下一个令牌预测训练目标（由作者创建）

由于使用了因果（或掩蔽）自注意，每个输出令牌向量在计算其表示时只考虑当前令牌以及序列中其之前的令牌。如果我们使用双向自注意，每个输出令牌向量将通过查看整个向量序列来计算，这将允许模型作弊，通过仅仅复制序列中接下来的令牌来解决下一个令牌预测。因此，*掩蔽自注意是下一个令牌预测所必需的*。但是，自注意到底是什么，更根本地说，变换器是什么？接下来我们将深入探讨。

**一个快速说明。** “语言模型”这一术语有时可能被用来指代那些不仅专注于执行下一个令牌预测的模型。例如，BERT [18] 被一些人认为是“语言模型”，但它是使用[Cloze](https://en.wikipedia.org/wiki/Cloze_test)风格的目标进行训练的，并不是生成模型。因此，专注于下一个令牌预测的语言模型通常被称为“因果”语言模型。在这里，我们将这两个术语交替使用，指代那些专注于下一个令牌预测的模型。

## 变换器架构及其变体

![](../Images/d4063e56b4061772fa70fc6774e8504c.png)

(来自 [17])

所有语言模型都使用某种变体的变换器架构。这种架构（如上图所示）最初在[17]中提出，用于解决序列到序列任务。然而，它随后被扩展以解决各种不同的问题，从评估文本的语义相似性到图像分类。在其原始形式中，变换器架构有两个组成部分：

+   *编码器*：每个块执行双向自注意和一个逐点前馈变换，这些操作之间通过残差连接和LayerNorm分隔。

+   *解码器*：每个块执行因果自注意，[交叉注意](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html#cross-attention)（即跨编码器和解码器令牌的自注意），以及一个逐点前馈变换，每个部分之间通过残差连接和LayerNorm分隔。

当架构的两个组件都存在时，编码器处理输入序列并生成一个输出序列。然后，解码器生成自己的输出序列，输入为编码器的输出序列。换句话说，编码器处理整个输入序列以形成解码器在生成输出时使用的表示。整体上，转换器接受一个序列作为输入并生成一个新的序列作为输出。

![](../Images/ff8ee0466c2a6832b16e3a042577e9d5.png)

（来源于 [17]）

**仅解码器和仅编码器的转换器。** 几乎所有因果语言模型都使用仅解码器转换器作为其基础架构，这只是一个普通的转换器，其编码器部分被移除；见上文。此外，由于缺少编码器（即，我们不能关注不存在的编码器），每个解码器块的交叉注意力部分也被移除！或者，可以通过仅使用架构中的编码器部分来形成仅编码器架构。仅编码器架构（例如，BERT [18]）在解决各种判别自然语言任务方面表现出色，但它们不用于生成文本。要了解更多信息，请查看[这里](/language-understanding-with-bert-c17a453ada1a)的链接。

**为什么选择解码器？** 选择仅解码器架构（与仅编码器或完整的编码器-解码器转换器相比）用于大语言模型并非随意决定。相反，这一选择是由于训练语言模型时使用下一个词预测。解码器中使用的掩码自注意力确保模型在预测下一个词时无法向前查看序列。否则，下一个词预测将变得非常简单，因为模型可以直接复制下一个词；见下文。

![](../Images/3d35c55158d6953194bda3c49b455440.png)

因果自注意力用于下一个词预测（作者创建）

为了在不作弊的情况下进行下一个词预测，无论是仅编码器还是编码器-解码器转换器，都必须避免在其输入序列中包含任何真实的下一个词。为此，我们可以 *i)* 处理一个前缀，并 *ii)* 预测跟随该前缀的词。然而，这种方法效率较低，因为我们一次只能预测一个下一个词。相比之下，只有解码器的模型由于使用掩码自注意力，可以处理整个词序列，并将语言建模目标应用于序列中的每个词。此外，一些论文 [12] 实际上表明，仅解码器架构在下一个词预测中表现最佳。

**我们如何生成文本？** 鉴于上面概述的仅解码器架构，生成文本遵循简单的自回归过程。我们只需不断预测下一个词，将此词添加到输入中，并重复进行；见下文。

![](../Images/0eb74f1f7b9395dd27740f1c6cf3e9b5.png)

使用语言模型生成文本（作者创建）

## 训练和使用语言模型

为了全面理解语言模型，我们需要快速探索这些模型在实际中通常是如何训练和使用的。尽管在这一领域做了大量的研究，但大多数语言模型都是按照 [19] 中提出的一些标准技术进行训练的；详见下文。

![](../Images/39249c2721cd023c5fa54ec2e5dfdcda.png)

LLM 训练组件（来自 [19]）

语言模型可以通过多种不同方式进行学习。在这里，我们将重点讨论预训练、对齐和上下文学习，这些方法共同涵盖了训练大型语言模型（LLM）和在实际应用中使用它所需的大部分内容。

**预训练。** 预训练过程是创建 LLM 的初步且计算开销最大的步骤。从一个随机初始化的 LLM 开始，我们必须使用语言建模目标对这个模型进行训练——在从各种不同来源中整理出的海量原始文本语料库上。之前的研究 [1] 向我们展示，通过在一个大型数据集上对一个非常大的模型（即，参数很多）进行预训练，我们可以获得一个 [基础模型](https://crfm.stanford.edu/)，它可以通过执行下一个 token 预测来准确地解决各种不同的任务。为了获得最佳结果，我们需要在数据和模型规模方面进行扩展。

**我们还需要什么？** 仅仅经历预训练的语言模型可以是强大的。看看 GPT-3 [1] 和 Chinchilla [15] 的一些例子。然而，LLM 直到像 ChatGPT 这样的模型提出后才突然流行起来是有原因的——*仅仅进行下一个 token 预测并不是非常有趣*。通常，预测统计上正确的下一个 token，虽然生成了合理的文本，却会产生重复、简单且通常不太有用的输出。我们需要某种方法来使 LLM 生成对我们人类更有帮助和更有趣的输出！

![](../Images/c4bb95493aad5c7c6ec0d92b5ab366d0.png)

（来自 [19]）

对齐是指对LLM进行微调的过程，以更好地符合人类用户的期望。这主要通过两种技术实现：监督微调（SFT）和/或来自人类反馈的强化学习（RLHF）。LLM的期望行为很大程度上取决于其部署的上下文或应用。然而，对齐是一种通用工具，可以用来随意地微调LLM，使其表现出特定的行为；详见上文。近期研究表明，模型在对齐过程中不会学习到新的信息。相反，这个过程只是教会模型如何正确地格式化或呈现其从预训练过程中已经获得的知识。

**实际应用 LLM。** 在我们对语言模型进行预训练和微调（或对齐）之后，最后一步是将模型专门化为我们所需的应用。这一过程可能需要对领域特定的数据进行额外的微调。然而，并不总是需要更多的训练，因为我们可以通过使用上下文学习来完成很多工作；见下文。

![](../Images/072087b61567a23057e21513b694a91d.png)

（来自 [1]）

简而言之，上下文学习指的是使用一个单一的通用基础模型（例如，预训练的 LLM）来解决各种不同的问题。鉴于语言模型的通用文本到文本结构，这实际上是相当容易做到的。我们只需构建一个可以作为输入提供给 LLM 的文本问题解决提示；见下文。

![](../Images/2ddf4727d70335b75398cbbc03591665.png)

解决算术问题的不同提示变体（由作者创建）

然后，LLM 应该生成我们问题的答案作为输出。因此，我们可以通过仅仅修改输入提示来解决许多不同的问题！构建有效提示以解决问题的过程称为提示工程，我们在之前的文章中对此进行了广泛探讨：

+   实用提示工程 [[link](/practical-prompt-engineering-74e96130abc4)]

+   高级提示工程 [[link](/advanced-prompt-engineering-f07f9e55fe01)]

# 开源 LLM 的初步尝试

鉴于 [预训练的高成本](https://www.mosaicml.com/blog/gpt-3-quality-for-500k)，研究社区花了一些时间才开始追求创建开源 LLM，使得像 GPT-3 这样的专有模型成为标准。然而，一旦提出了最初的几个模型，闸门就打开了，开源 LLM 的研究迅速推进（几乎 *过于* 迅速）。我们将在这里了解一些早期模型，而更多最近的开源 LLM 将在系列的未来部分中介绍。

## [GPT-NeoX-20B](https://arxiv.org/abs/2204.06745) [6]

第一个开源 LLM 之一——一个名为 GPT-NeoX-20B 的 200 亿参数模型[6]——由 [EleutherAI](https://www.eleuther.ai/) 创建。GPT-NeoX-20B 是在初始的 GPT-Neo 模型（27 亿参数）[22] 之后创建的，经过 [the Pile](https://huggingface.co/datasets/EleutherAI/pile) 进行预训练，并在各种自然语言基准测试中表现出色的少量示例学习性能（可与 GPT-3 相媲美）。尽管与 GPT-3（即 200 亿参数对比 1750 亿参数）相比，这个模型在某种程度上较小，但它在当时是最大的开源语言模型。此外，所有训练和评估模型的代码都与其权重一起以 [Apache 2.0 许可证](https://www.planetcrust.com/what-does-apache-2-0-license-mean) 发布，允许商业使用。

![](../Images/464b0594abbfedc8df9295cfbbc47328.png)

（来自 [8]）

**模型。** GPT-NeoX-20B [6] 使用了标准的仅解码器变换器架构，但进行了以下两项更改：

+   RoPE 嵌入

+   并行注意力和前馈层

改进了标准位置嵌入，RoPE嵌入（如上所示）提供了一种将位置信息注入自注意力操作的新方法。这种方法在绝对位置和相对位置信息之间找到了更好的平衡，并由于其在处理长序列任务中的表现能力，被用于多种其他模型（例如PaLM [9]和Falcon-40B [10]）。此外，使用并行注意力和前馈层（见下文）使训练吞吐量提高了15%，性能下降最小。

![](../Images/e8925011b742dda3dc495518dd9b76ea.png)

并行执行注意力层和前馈层（由作者创建）

有趣的是，为GPT-NeoX-20B创建了一个自定义分词器。这个分词器与GPT-2的分词器[11]相当，但它是从头开始在Pile（一个大型多样的文本语料库）上训练的，并且经过修改以更一致地分词空白字符。因此，最终的分词器除了在高质量语料库上进行训练外，还特别有效于分词代码（即，代码中有很多空白字符！）。因此，几种开源模型（例如MPT-7B [5]）即使在今天也采用了这个分词器。

![](../Images/71f8929ce4bdba04222ea1cbbed33238.png)

（来自 [6]）

**性能。** GPT-NeoX-20B与GPT-3和其他开源模型（如 [GPT-J](https://www.eleuther.ai/artifacts/gpt-j)）进行了比较。在这些评估中，我们看到GPT-NeoX-20B在常见的语言建模任务上表现相当好（即使与专有模型相比）；见上文。值得注意的是，GPT-3往往实现了最佳性能。然而，GPT-NeoX-20B相对于其规模表现相当好，甚至在参数数量相近的专有模型中也表现优异。

![](../Images/b10f5839e8a9ffc18e19a389388b406f.png)

（来自 [6]）

GPT-NeoX-20B的性能虽然不是最先进的，但在其规模下表现出乎意料地好，即使与近期模型相比也是如此！

## [开放预训练变换器（OPT）语言模型](https://arxiv.org/abs/2205.01068) [4]

![](../Images/40a10d026d0ee315ab08580a8211ab62.png)

OPT版本的组件（由作者创建）

在之前的概述中，我们深入讨论了开放预训练变换器（OPT）库的细节。请见 [这里](/understanding-the-open-pre-trained-transformers-opt-library-193a29c14a15) 的链接。

OPT由[Meta AI](https://ai.meta.com/)提出，旨在将强大的LLMs民主化地提供给公众，包括几个不同的LLMs，规模从1.25亿到1750亿参数不等。这些模型在由[Reddit](https://arxiv.org/abs/2001.08435)、[the Pile](https://arxiv.org/abs/2101.00027)和[BooksCorpus](https://yknzhu.wixsite.com/mbweb)等来源编制的精选数据集上进行预训练，而这个套件中的最大模型——OPT-175B——是首批真正的*大型*开源语言模型之一。此外，这些模型还配有一个[代码库](https://github.com/facebookresearch/metaseq)和一个详细记录所有模型预训练过程的日志。尽管OPT模型[不用于商业](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/MODEL_LICENSE.md)，但它们是对LLMs开放研究的巨大资源。

**影响。** OPT语言模型是首次大规模努力使庞大的语言模型对研究社区可访问的——*LLMs现在完全对任何人开放*，而不是隐藏在API后面。此外，OPT的开源训练代码提供了一个高效的训练框架，使用了像[FSDP](https://engineering.fb.com/2021/07/15/open-source/fsdp/)和[张量并行](https://github.com/NVIDIA/Megatron-LM?fbclid=IwAR3SvXpTaLseZacJv_Bntwg0czNNYj8hEhcho3R_mo8ABDS8zmszw4mdZ3E)等常见技术。这段代码实现了比NVIDIA直接发布的研究[3]高出17%的资源利用率，是训练LLMs的极佳资源。

![](../Images/0552d7057a25f7f263fc74ffc6965c5f.png)

（来源于[5]）

训练[笔记](https://github.com/facebookresearch/metaseq/tree/main/projects/OPT/chronicles?fbclid=IwAR3qONxU4mENL_HAVcf9LJCwwqijGCVMk87C8Sm9_q3y6TZS3kZiY6Fd5dY)和[日志](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf?fbclid=IwAR1gSseT67AGnNprJRdiW91Pf7eW1b82Z3pYshE4CYGT_-AKVnCUdaIdmm8)与OPT相关，提供了大量（先前未知的）对LLM训练过程的见解。通过这些资源，我们可以更好地理解训练LLM的全部成本以及在此过程中可能遇到的许多困难（例如，损失峰值、硬件故障以及其他“中途”训练调整）。这些训练LLM的困难成为了讨论的话题，并且已经通过随后的开源LLM工作（大部分）得到解决；详见上述内容。

![](../Images/eeedf7b8ce8fd018b3f9256b75bc0a90.png)

（来源于[4]）

**它的表现如何？** OPT-175B 在提议时与当时流行的模型进行了广泛比较，并发现其在零样本和少样本学习设置下的性能与 GPT-3 相当；详见上文。总体而言，OPT 的性能并不突出——*该模型被普遍认为在质量上落后于专有模型*。尽管其表现平平，然而，OPT 对 AI 研究而言是一个巨大的进步，并显著提升了对开源 LLM 的兴趣。这一影响不容低估，因为它出现在专有模型主导地位被接受为新标准的时期。

## [BLOOM: 一个开放的多语言语言模型](https://bigscience.huggingface.co/blog/bloom) [12]

> “学术界、非营利组织和小型公司的研究实验室发现创建、研究甚至使用 LLM 非常困难，因为只有少数具备必要资源和专有权利的工业实验室才能完全访问它们。” *—来自 [12]*

在[12]中提出，BLOOM 是一个 1760 亿参数的 LLM，它作为一个大规模开放协作的 AI 研究项目（即，超过 1000 名研究人员参与！），称为[大科学研究工作坊](https://bigscience.huggingface.co/)。该工作坊持续了一年（2021 年 5 月至 2022 年 5 月），其目标是创建 *i)* 一个大规模的多语言文本数据集，以及 *ii)* 一个在该数据集上训练的大型多语言语言模型。最终生成的模型，略大于 GPT-3，并在[负责任 AI 许可证](https://bigscience.huggingface.co/blog/the-bigscience-rail-license)（RAIL）下开源，可以生成 46 种不同语言[8](https://cameronrwolfe.substack.com/p/the-history-of-open-source-llms-early#footnote-8-135273362)和 13 种编程语言的文本。

**为训练 BLOOM 开发的数据集**，称为[ROOTS 语料库](https://arxiv.org/abs/2303.03915)，由 498 个 HuggingFace 数据集组成，包含超过 1.6 TB 的文本，涵盖 46 种自然语言和 13 种编程语言。该数据集在不同语言中的分布如下图所示。

![](../Images/086efab8d0133082762b58c2ac406cf9.png)

(来自 [12])

在获得原始数据后，作者应用了不同的质量过滤器管道，以去除非自然语言的文本。使用的具体过滤组件在[12]的第 3.1.3 节中进一步阐述，根据数据源的不同而有所变化。然而，整体管道的共同目标是尽可能多地过滤掉低质量文本。

![](../Images/7d2bd4c46a9310ef6a98766cfb9c9a3b.png)

(来自 [12])

**BLOOM 使用的架构** 是标准的解码器单一 Transformer。然而，如上所示，对该架构进行了少许修改，例如：

+   *ALiBi* [13]：这帮助模型将训练中见过的上下文长度泛化到更长的上下文长度。

+   *嵌入层归一化*：在模型的嵌入层后添加了额外的[层归一化](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)，这在经验上发现能够提高训练稳定性。

总体而言，这个模型与大多数LLM并没有太大区别。有趣的是，[12]中的作者对不同类型的变换器架构（例如，仅编码器模型、编码器-解码器模型和仅解码器模型）进行了广泛分析，发现仅解码器模型（几乎所有因果语言模型都使用这种模型）在预训练后表现最佳。

> “我们的结果显示，预训练后，因果解码器模型表现最佳——验证了选择最先进LLM的决策。” *— 来源于 [12]*

**它表现如何？** 与其他开源LLM相比，BLOOM的表现相对较好。在自然语言基准测试中，它的结果与OPT相当或有所改进，并且由于其在多语言语料库上进行训练，通常在机器翻译任务中表现优异；见下文。

![](../Images/a931372cfd9177c919402852aa8c24b3.png)

(来源于 [12])

然而，BLOOM的表现低于顶级专有模型。例如，我们在下方的HumanEval基准测试结果中看到，该模型的编码能力远远落后于Codex [14]等替代品。此外，当我们将BLOOM与Chinchilla [15]和PaLM [9]等模型进行比较时，我们很快发现开源模型的性能逊色于其专有对应物。换句话说，*在BLOOM提出时，开源LLM的研究仍然滞后*。

![](../Images/52f1b3c499c80044940a223632231145.png)

(来源于 [12])

## 其他显著模型

我们尝试覆盖早期开源LLM研究中提出的几个显著模型。但仍有一些模型未包含在本概述中，值得一提。让我们快速了解其中的一些。

**GPT-J [21]** 是一个60亿参数的仅英语因果语言模型，在GPT-NeoX-20B [6]之前提出。与GPT-NeoX-20B类似，该模型在Pile上进行预训练。在发布时，GPT-J-6B是最大的公开GPT-3风格语言模型。

![](../Images/faed1a07b5d94c956ac692853a70d524.png)

(来源于 [20])

**GLM [20]** 更像是一个预训练目标，而不是一个语言模型。该工作探索了通过提出自回归空白填充目标来统一不同的预训练技术（例如BERT、T5和GPT）的想法。换句话说，我们以自回归方式预测句子中的掩码词，类似于语言模型；见上文。结果模型相当小（<10亿参数），在几个流行的自然语言处理基准测试中表现优于BERT、T5和GPT。

# 我们接下来要做什么？

![](../Images/d1a8829aad7d90260ea20581ae9b7e16.png)

开源LLM研究的发展（由作者创建）

鉴于早期对开源LLMs的尝试产生的模型表现远不如专有对手，我们不禁要问：*我们应该做什么来提升这些模型？* 随着这一研究领域的发展，我们看到主要投入了两个方向的努力：

1.  创建更好的基础LLMs

1.  微调开源LLMs（即对齐和模仿）

由于开源LLMs对所有人开放，这些领域的研究进展速度令人震惊——*我们在不到一年的时间里从OPT进展到了接近最先进的模型（如LLaMA-2或Falcon-40B [10]）*！

> “我们认为，提升开源模型的最高杠杆行动是应对开发更好的基础语言模型这一艰巨挑战” *— 出自[16]*

上述两条研究方向在此期间是并行探索的，每条方向都产生了对AI从业者有用的技术。在本调查的接下来的两个部分中，我们将概述这些领域及其关键贡献，探讨最初对开源LLMs的尝试如何演变成极其强大的模型，如LLaMA-2。

## 连接我！

非常感谢阅读这篇文章。我是[Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/)的AI总监。我研究深度学习的实证和理论基础。如果你喜欢这个概述，请订阅我的[Deep (Learning) Focus通讯](https://cameronrwolfe.substack.com/)，我通过从基础开始的相关主题概述帮助读者理解AI研究。你也可以在[X](https://twitter.com/cwolferesearch)和[LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/)上关注我，或查看我在medium上的[其他文章](https://medium.com/@wolfecameron)！

## 参考文献

[1] Brown, Tom, 等. “语言模型是少样本学习者。” *神经信息处理系统进展* 33 (2020)：1877–1901。

[2] Rae, Jack W., 等. “语言模型的扩展：方法、分析与训练gopher的见解。” *arXiv预印本 arXiv:2112.11446* (2021)。

[3] Smith, Shaden, 等. “使用deepspeed和megatron训练megatron-turing nlg 530b，一个大规模生成语言模型。” *arXiv预印本 arXiv:2201.11990* (2022)。

[4] Zhang, Susan, 等. “OPT: 开源预训练变换器语言模型。” *arXiv预印本 arXiv:2205.01068* (2022)。

[5] “介绍MPT-7B：开源商业可用LLMs的新标准。” *MosaicML*，2023年5月5日， [www.mosaicml.com/blog/mpt-7b.](http://www.mosaicml.com/blog/mpt-7b.)

[6] Black, Sid, 等. “Gpt-neox-20b：一个开源自回归语言模型。” *arXiv预印本 arXiv:2204.06745* (2022)。

[7] Gao, Leo, 等. “The pile: 一个800GB的多样文本数据集用于语言建模。” *arXiv预印本 arXiv:2101.00027* (2020)。

[8] Su, Jianlin, 等. “Roformer: 带旋转位置嵌入的增强变换器。” *arXiv预印本 arXiv:2104.09864* (2021)。

[9] Chowdhery, Aakanksha 等. “Palm：通过路径扩展语言建模。” *arXiv 预印本 arXiv:2204.02311* (2022)。

[10] “介绍 Falcon LLM”，*技术创新研究所*，2023年6月7日，[https://falconllm.tii.ae/.](https://falconllm.tii.ae/.)

[11] Radford, Alec 等. “语言模型是无监督的多任务学习者。”

[12] Scao, Teven Le 等. “Bloom：一个 176b-参数的开放访问多语言模型。” *arXiv 预印本 arXiv:2211.05100* (2022)。

[13] Press, Ofir, Noah A. Smith 和 Mike Lewis. “短期训练，长期测试：具有线性偏差的注意力机制实现输入长度外推。” *arXiv 预印本 arXiv:2108.12409* (2021)。

[14] Chen, Mark 等. “评估训练有代码的大型语言模型。” *arXiv 预印本 arXiv:2107.03374* (2021)。

[15] Hoffmann, Jordan 等. “训练计算最优的大型语言模型。” *arXiv 预印本 arXiv:2203.15556* (2022)。

[16] Gudibande, Arnav 等. “模仿专有 llms 的虚假承诺。” *arXiv 预印本 arXiv:2305.15717* (2023)。

[17] Vaswani, Ashish 等. “注意力机制是你所需的一切。” *神经信息处理系统进展* 30 (2017)。

[18] Devlin, Jacob 等. “Bert：用于语言理解的深度双向转换器预训练。” *arXiv 预印本 arXiv:1810.04805* (2018)。

[19] Ouyang, Long 等. “训练语言模型以遵循指令和人类反馈。” *神经信息处理系统进展* 35 (2022)：27730–27744。

[20] Du, Zhengxiao 等. “Glm：自回归空白填充的通用语言模型预训练。” *arXiv 预印本 arXiv:2103.10360* (2021)。

[21] Ben Wang 和 Aran Komatsuzaki. GPT-J-6B：一个拥有 60 亿参数的自回归语言模型，2021。

[22] Sid Black, Leo Gao, Phil Wang, Connor Leahy 和 Stella Biderman. 2021\. GPT-Neo：使用 MeshTensorflow 的大规模自回归语言建模。
