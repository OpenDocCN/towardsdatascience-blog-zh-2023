- en: Here Is What I Learned Using Apache Airflow over 6 Years
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/here-is-what-i-learned-using-apache-airflow-over-6-years-15d88b9922d9](https://towardsdatascience.com/here-is-what-i-learned-using-apache-airflow-over-6-years-15d88b9922d9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A journey with Apache Airflow from experiment to production hassle-free
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://chengzhizhao.medium.com/?source=post_page-----15d88b9922d9--------------------------------)[![Chengzhi
    Zhao](../Images/186bba91822dbcc0f926426e56faf543.png)](https://chengzhizhao.medium.com/?source=post_page-----15d88b9922d9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----15d88b9922d9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----15d88b9922d9--------------------------------)
    [Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----15d88b9922d9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----15d88b9922d9--------------------------------)
    ·8 min read·Jan 9, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e84fe2488de04a2676a5ff7e1454684.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Karsten Würth](https://unsplash.com/@karsten_wuerth?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/UbGYPMbMYP8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Apache Airflow is undoubtedly the most popular open-source project for data
    engineering for years. It gains popularity at the right time with [The Rise Of
    Data Engineer](https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603),
    and the core concept of making code as the first-class citizen instead of drag
    and drop for data pipeline (aka. ETL) is a milestone. The Apache Airflow became
    an Apache Incubator project in March 2016 and became the top project in January
    2019\. I have worked on Apache Airflow since 2017 as a user. Along the way, I
    also contributed to Apache Airflow. Today, I want to share my journey with Airflow
    and what I learned over 6 years.
  prefs: []
  type: TYPE_NORMAL
- en: '**What is Airflow**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Airflow is a platform created by the community to programmatically author, schedule
    and monitor workflows. — [Airflow Offical Documentation](https://airflow.apache.org/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Apache Airflow is developed by [Maxime Beauchemin](https://medium.com/@maximebeauchemin),
    who is an ex-Airbnb and ex-Facebook. He developed Airflow at Airbnb (*you can
    tell from the project name*). However, the core idea that inspired him was an
    internal tool used at Facebook.
  prefs: []
  type: TYPE_NORMAL
- en: The primary users of Apache Airflow are data engineers or engineer who needs
    to schedule workflows, mainly the ETL (Extraction, Transformation, Loading) jobs.
    Those ETL jobs are usually run at a daily or hourly cadence. The jobs themselves
    perform data manipulation to get insights from unstructured raw data.
  prefs: []
  type: TYPE_NORMAL
- en: Why is Airflow so Popular?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I worked on Apache Airflow since 2017 before it became widespread as a must-have
    skill for any data engineer. I still recall the early days of how much effort
    we have “hacked” into the system of the Airflow scheduler to get it to work stable
    as an early adopter. If you want to learn more, I wrote article years back.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/making-meetup/data-pipeline-infrastructure-at-meetup-with-fewer-nightmares-running-apache-airflow-on-kubernetes-54cb8cdc69c3?source=post_page-----15d88b9922d9--------------------------------)
    [## Data Pipeline Infrastructure at Meetup with Fewer Nightmares: Running Apache
    Airflow on Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: Meetup Data Platform Infrastructure — a Starting Point
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/making-meetup/data-pipeline-infrastructure-at-meetup-with-fewer-nightmares-running-apache-airflow-on-kubernetes-54cb8cdc69c3?source=post_page-----15d88b9922d9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Airflow shines from the beginning as an incubating project. It enhances and
    stabilizes along the way. Here are a couple of reasons I noted that made Airflow
    so fascinating initially:'
  prefs: []
  type: TYPE_NORMAL
- en: Code First
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Coding (especially in Python) is a new norm for a data engineer. However, writing
    a data pipeline 10 years ago was mostly drag & drop in UI-based tools like SSIS
    or Informatica. The drag & drop is easy in the first place. However, it will soon
    get to a point where it is hard to scale the development cycle, and the UI sometimes
    is trickier to drag and buggy when you drop the box.
  prefs: []
  type: TYPE_NORMAL
- en: Coding is a good way of abstraction. We can write the DAG with all the logic
    in Python code, share it, and deploy it. It fits the purpose well. It forces some
    people who only know SQL to learn Python, but it is rewarding.
  prefs: []
  type: TYPE_NORMAL
- en: Nice Visualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: No matter how much code we put together, as an orchestrator, it needs some way
    to visualize the process. Ultimately, a nice visualization looks engaging and
    solves multiple problems. It’s manageable to catch failures, understand dependencies,
    and monitor job states.
  prefs: []
  type: TYPE_NORMAL
- en: As an end user, the visualization isn’t something you need to polish like a
    dashboard. Once the coding is done, Airflow handles the rest and takes visualization
    for you. Your DAG can be visualized in seven different views, each with its focus.
    The most common ones I use daily are [Grid view](https://airflow.apache.org/docs/apache-airflow/stable/ui.html#grid-view)
    (used to be tree) and [Graph view](https://airflow.apache.org/docs/apache-airflow/stable/ui.html#graph-view).
  prefs: []
  type: TYPE_NORMAL
- en: On the UI, you can perform tasks such as restarting a job, resetting states
    for some tasks within a DAG, checking the failure log, or examining the long-running
    job. Although UI doesn’t provide us with 100% functionalities, it covers the day-to-day
    use case.
  prefs: []
  type: TYPE_NORMAL
- en: Extensibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To enable more people to use it as an ETL orchestration tool, the project has
    to be extensible to allow other projects to integrate easily. The richness of
    integration sets the foundation for Airflow to become one of the top Apache projects.
    Furthermore, Airflow allows user to write their own `PythonOperator` which further
    encourages developers to build their logic by code instead of waiting for a new
    upgrade of a plugin to accomplish their ETL needs.
  prefs: []
  type: TYPE_NORMAL
- en: The great extensibility also expands more innovative projects and plugins to
    onboard within Airflow’s ecosystem. The core idea of using plugins is to avoid
    everyone reinventing the wheel to write your logic yourselves. It also helps services
    or products provide seamless integration with end users.
  prefs: []
  type: TYPE_NORMAL
- en: 'The comprehensive Airflow plugins make it harder for the end users to migrate
    to something else. For example, EDI 835: Electronic Remittance Advice is a special
    format that provides claim payment information in the healthcare industry. It
    requires special parsing logic to read it correctly. Those types of use cases
    for specific domains make it a great “moat” for Airflow to be competitive.'
  prefs: []
  type: TYPE_NORMAL
- en: Community
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the end, Airflow is part of the Apache foundation. We all know what it means
    to be an Apache top-tier project. The fame speaks for itself in attracting organic
    traffic for more people to try Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: The community is growing healthily. In StackOverflow, you can find over 9k questions
    tagged [Airflow]. Airflow has its yearly hosted [AirflowSummit](https://airflowsummit.org/).
    The company [astronomer.io](https://docs.astronomer.io/learn?utm_term=airflow&utm_campaign=ch.sem_br.nonbrand_tp.prs_tgt.airflow-general_mt.xct_rgn.namer_lng.eng_dv.all_con.airflow-general&utm_source=google&utm_medium=sem&gclid=CjwKCAiAwc-dBhA7EiwAxPRylOkLoT8HZFAl1bT--Q42KXOwFm2d4a9fv8wnLEAAgAePgiOnkJVkkRoCd2EQAvD_BwE),
    which backed Airflow, also provides great documentation and certification. Its
    Slack was active since the early days when I joined back in 2017, and now it has
    25k+ people joined.
  prefs: []
  type: TYPE_NORMAL
- en: My journey of using Airflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When I joined [Meetup](https://www.meetup.com), Airflow was an experimental
    tool brought by a principal engineer as a proof of concept back in April 2017.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of Airflow by that time aimed to resolve multiple issues when
    we had a custom Scala-based ETL. I still admire people who have built complex
    dependencies of DAG logic to make the ETL works in the first place. But we all
    know ETL will fail some days. That’s the headache part of the custom Scala-based
    ETL. Not easy to debug and restart a job, and you’d need to be extremely careful
    to make the job idempotent.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, we figured out a way to run Airflow 1.7 and deployed with new Python
    code for POC. It went exponentially well. Since Airflow 1.9 and the Kubernetes
    executor were introduced, Airflow was at a much more mature stage. I also contributed
    to the Airflow project and gained insights into the internal core code. On production,
    we encountered fewer issues than early days, and we can focus more on improving
    the scalability and onboarding more use cases.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are still a few things I wish I had known earlier to avoid some
    time-consuming investigation.
  prefs: []
  type: TYPE_NORMAL
- en: The Learnings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Not leveraging macros in the first place**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You read it right. I don’t know the macro concept at the early stage of Airflow.
    So all of the Jinja templates like `{{ ds }}` I didn’t leverage it in the first
    place. On a new day, to trigger the ETL, it just uses the python function `date()-1`
    .
  prefs: []
  type: TYPE_NORMAL
- en: The biggest problem is backfilling, I hacked it using Airflow’s parameter, but
    users have to provide that information and only allow backfill a day at a time.
    The entire process becomes a nontrivial process. After carefully reading the Airflow
    documentation, it turns out the macros are perfect for getting jobs’ metadata.
    We backfill as simple as clearing the existing dag without additional parameter
    hacks.
  prefs: []
  type: TYPE_NORMAL
- en: '**ETL in EST**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The date is critical in any data system. Our data system is partitioned by EST.
    It’s by EST!!! If you were in the same boat as I was, you’d understand how much
    pain I had during the daylight change. Everything breaks!
  prefs: []
  type: TYPE_NORMAL
- en: We had multiple DAG dependencies using the [external_task_sensor](https://airflow.apache.org/docs/apache-airflow/1.10.3/_api/airflow/sensors/external_task_sensor/index.html#module-airflow.sensors.external_task_sensor),
    which relies on **execution_delta —** time difference with the previous execution
    to look at. Think about a case where you have some task finished, then suddenly
    the pending tasks +1/-1 hour becomes chaotic to manage. I have to build a solution
    to avoid that. It’s not fun to maintain. If you start building any data system,
    I’d suggest sticking with UTC time whenever possible for simplicity and peace
    of mind.
  prefs: []
  type: TYPE_NORMAL
- en: Be gentle in scheduling the DAG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Airflow is not a data streaming solution.** This has been mentioned at the
    beginning of the Airflow official documentation in the [Beyond The Horizon](https://airflow.apache.org/docs/apache-airflow/1.10.1/#beyond-the-horizon)
    section.'
  prefs: []
  type: TYPE_NORMAL
- en: One reason is Airflow doesn’t pass data between tasks. You’d need to find external
    storage when it comes to that part. The Airflow architecture doesn’t start with
    a streaming design. If you have a job that needs to trigger every minute, Airflow
    can accomplish that, but it won’t scale well. For the data streaming use case,
    use Flink/Spark for data streaming purposes, and don’t overload that into Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason that is not mentioned often is Airflow scheduler is a beast for
    updating all the states of your DAGs. It scans for the next potential DAGs to
    get it triggered by its execution date when it hits the wall clock. Even when
    the Airflow scheduler is down, the states must be materialized to track the state.
    Massive state updates are going behind the scenes in an OLTP database, which Airflow
    still recommends using [**MySQL** or **Postgres**](https://airflow.apache.org/docs/apache-airflow/1.10.1/howto/initialize-database.html?highlight=database#initializing-a-database-backend)**.**
    In this case, [scheduler_heartbeat_sec](https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html#scheduler-heartbeat-sec)
    needs to be config properly, and the default is 5 seconds. This value can be the
    knob to tune.
  prefs: []
  type: TYPE_NORMAL
- en: When we are to the point where we have hundreds of DAGs and thousands of tasks,
    jobs are slowly getting scheduled and running. Increasing this value to more than
    60 seconds will cool down the Airflow scheduler. To learn more about the Airflow
    scheduler, I have written an article [Airflow Schedule Interval 101](/airflow-schedule-interval-101-bbdda31cc463)
    to help you learn more.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/airflow-schedule-interval-101-bbdda31cc463?source=post_page-----15d88b9922d9--------------------------------)
    [## Airflow Schedule Interval 101'
  prefs: []
  type: TYPE_NORMAL
- en: The airflow schedule interval could be a challenging concept to comprehend,
    even for developers work on Airflow for a…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/airflow-schedule-interval-101-bbdda31cc463?source=post_page-----15d88b9922d9--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Final Thoughts**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Airflow is a remarkable open-source project for data engineers. As I
    look back, many concepts are leading implementations that paved the road for its
    popularity and success today. Many companies add Airflow as the required skill
    for data engineer hiring. It’s a fortune for me to get involved with Apache Airflow
    early and witness the project grow. Some new projects have started to challenge
    Apache Airflow, for example, [mage-ai](https://github.com/mage-ai/mage-ai) and
    [Perfect](https://docs-v1.prefect.io/). I will cover them in future posts.
  prefs: []
  type: TYPE_NORMAL
- en: The creator of Airflow, [Maxime](https://medium.com/@maximebeauchemin), who
    is also the creator of [Apache Superset](https://superset.apache.org/), is one
    of the most admirable data engineers in those two projects. Below is the talk
    he gave back in 2015 about the best practices for Airflow. It’s still a good reference
    to use Airflow today and learn about the Airflow design philosophy.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices with Airflow- an open source platform for workflows & schedules
    | By [Maxime Beauchemin](https://medium.com/@maximebeauchemin)
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope this story is helpful to you. This article is **part of a series** of
    my engineering & data science stories that currently consist of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chengzhi Zhao](../Images/51b8d26809e870b4733e4e5b6d982a9f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----15d88b9922d9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Data Engineering & Data Science Stories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://chengzhizhao.medium.com/list/data-engineering-data-science-stories-ddab37f718e7?source=post_page-----15d88b9922d9--------------------------------)53
    stories![](../Images/8b5085966553259eef85cc643e6907fa.png)![](../Images/9dcdca1fc00a5694849b2c6f36f038d4.png)![](../Images/2a6b2af56aa4d87fa1c30407e49c78f7.png)'
  prefs: []
  type: TYPE_NORMAL
- en: You can also [**subscribe to my new articles**](https://chengzhizhao.medium.com/subscribe)
    or become a [**referred Medium member**](https://chengzhizhao.medium.com/membership)who
    gets unlimited access to all the stories on Medium.
  prefs: []
  type: TYPE_NORMAL
- en: In case of questions/comments, **do not hesitate to write in the comments**
    of this story or **reach me directly** through [Linkedin](https://www.linkedin.com/in/chengzhizhao/)
    or [Twitter](https://twitter.com/ChengzhiZhao).
  prefs: []
  type: TYPE_NORMAL
