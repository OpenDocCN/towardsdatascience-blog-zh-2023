- en: 'Visualized Linear Algebra to Get Started with Machine Learning: Part 2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/visualized-linear-algebra-to-get-started-with-machine-learning-part-2-2ef075edb28b](https://towardsdatascience.com/visualized-linear-algebra-to-get-started-with-machine-learning-part-2-2ef075edb28b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/d2e76020c623b0941be9848041656cea.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Master elements of linear algebra, start with simple and visual explanations
    of basic concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----2ef075edb28b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ef075edb28b--------------------------------)
    ·7 min read·Feb 28, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this article, we continue the work we started in *“*[*Visualized Linear
    Algebra to Get Started with Machine Learning: Part 1*](https://medium.com/towards-data-science/visualized-linear-algebra-to-get-started-with-machine-learning-part-1-245c2b6487f0)*”.*
    We tackle new concepts of linear algebra in a simple and intuitive way. These
    articles are intended to introduce you to the world of linear algebra and make
    you understand how strongly the study of this subject and other mathematical subjects
    is related to data science.'
  prefs: []
  type: TYPE_NORMAL
- en: Index
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solve Equations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinants
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced Changing Basis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eigenvalues and Eigenvectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating Eigenvalues and Eigenvectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solve Equations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s finally try to understand how to solve equations simultaneously. You will
    by now have become familiar with writing equations compactly using matrices and
    vectors, as in this example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09673025fc7f3d880a1ce35412382170.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: Finding the vector of unknowns r = [a,b], is quite straightforward; we only
    need to **multiply the left and right sides of the equation by the inverse of
    matrix A**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e6c91c9ef24ce3dc06eb7a65d177e3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Solve Equation (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: We see that **A^-1 and A cancel**, **since multiplication for a matrix by its
    inverse always gives the identity matrix** (that is, the matrix that has all 1’s
    on the main diagonal and zero elsewhere). And so we find the value of r.
  prefs: []
  type: TYPE_NORMAL
- en: But in order to do this we have to **compute A^-1 which may not be too simple**.
    Often programming languages have algorithms already implemented that are very
    efficient in calculating the inverse matrix, so you will always have to use those.
    But in case you want to learn how to do this calculation by hand you will have
    to use [Gaussian Elimination](https://en.wikipedia.org/wiki/Gaussian_elimination).
  prefs: []
  type: TYPE_NORMAL
- en: This is for **example how you compute the inverse by using numpy** in Python.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Determinants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The determinant is another fundamental concept in line algebra. It is often
    taught in college how to calculate it but not what it is. **We can associate a
    value with each matrix, and that value is precisely the determinant.** However,
    **you can think of the determinant as the area of the deformed space.**
  prefs: []
  type: TYPE_NORMAL
- en: We have seen how each matrix is simply a deformation of space. Let us give an
    example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e783be648bf40855df37309cedbfda8.png)'
  prefs: []
  type: TYPE_IMG
- en: Determinant (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: If we calculate the area of the new space, as shown in the figure, **this area
    is precisely the determinant associated with the starting matrix**. In this case
    the determinant = a*d.
  prefs: []
  type: TYPE_NORMAL
- en: Certainly, we have matrices that can describe somewhat more complex deformations
    of space, and in that case, it may not be so trivial to calculate the area i.e.,
    the determinant.
  prefs: []
  type: TYPE_NORMAL
- en: For this, **there are known formulas for calculating the determinant.** For
    example, let us see the formula for calculating the determinant of a 2x2 matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/215de97a712e2fcfb7393c1fc7caa723.png)'
  prefs: []
  type: TYPE_IMG
- en: Compute Determinant od 2x2 Matrix (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: You can look [here](https://www.mathsisfun.com/algebra/matrix-determinant.html)
    to learn how to calculate the determinant in general cases with larger matrices.
  prefs: []
  type: TYPE_NORMAL
- en: If you think about it, however, **there are transformations that do not create
    any area**. Let’s look at the following example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/711fd2225466327da0bf2273a9ad3aea.png)'
  prefs: []
  type: TYPE_IMG
- en: Det equal zero (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the **matrix does not allow us to create any area, so we have
    a determinant equal to zero**.
  prefs: []
  type: TYPE_NORMAL
- en: But what is the use of knowing the determinant? We have seen that to solve simultaneous
    equations we need to be able to calculate the inverse of a matrix.
  prefs: []
  type: TYPE_NORMAL
- en: But **the inverse of a matrix does not exist if the determinant is equal to
    zero**! That is why it is important to know how to calculate it, to know if there
    are solutions to the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**You can think of the inverse matrix, as a way of transforming the space back
    to the original space**. But when a matrix causes, not an area but only a segment
    to be created, and then makes us go from 2d to 1d space, the inverse matrix does
    not have enough information and will never be able to make us go back to the original
    space in 2d from that in 1d.'
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Changing Basis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already seen in the previous article the basic example of changing the
    basis, but now let’s look at a somewhat more complex example.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s **imagine the existence of two worlds**, **ours and Narnia’s**. In our
    world, we use the vectors e1 and e2 as our reference vectors, as the basis. Thanks
    to these vectors we are able to create others and assign coordinates to them.
    For example, we can create the vectors [1,1], and [3,1].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ced0f6c5e3f2dce29e7f0a53b63fab1a.png)'
  prefs: []
  type: TYPE_IMG
- en: Our world (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: In the world of Narnia though, they use different vectors as a base. Can you
    guess which ones they use? Just the ones we call [1,1] and [3,1].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3cdd01b4b9e834aa7e37e036b3e57158.png)'
  prefs: []
  type: TYPE_IMG
- en: Narnia’s world (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: The people of Narnia will then use this basis of theirs to define other vectors
    of space, for example, they may define the vector [3/2, 1/2].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/594255b6dd8c12cbacc2db9eead5b12c.png)'
  prefs: []
  type: TYPE_IMG
- en: Vector In Narnian’s world (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, now what I want to find out is: **how do I define that red vector based
    on the coordinates of my world**?'
  prefs: []
  type: TYPE_NORMAL
- en: We have already seen this, we take the vectors that form the basis of Narnia
    but expressed in the coordinates of my world, so [1,1] and [3,1]. We put them
    in a matrix and multiply this matrix by the red vector.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f0e3f981b508bd3d92bbb1841c67841a.png)'
  prefs: []
  type: TYPE_IMG
- en: Changing Basis (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we ask: **can we do the reverse as well? Can I express a vector of my world
    according to the coordinates they use in Narnia? Of course!**'
  prefs: []
  type: TYPE_NORMAL
- en: '**It will suffice to do the same process but change the point of view**. But
    why do we do all this? **Very often when we have to describe vectors or transformations,
    we have a much simpler notation if we use a different basis.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Suppose we want to apply an R-transformation to a vector. But this transformation
    turns out to be difficult to apply. Then we can first transform my vector into
    a vector in the world of Narnia by applying the matrix N. After that we apply
    the desired transformation R. And then we bring everything back to our original
    world with N^-1.**'
  prefs: []
  type: TYPE_NORMAL
- en: This is something that can be very useful and make life easier when we are dealing
    with complex transformations. I hope I have at least given you some insight; there
    is so much more to talk about.
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvalues and Eigenvectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already repeated several times that **applying a linear transformation
    (a matrix) to a vector transforms that vector.**
  prefs: []
  type: TYPE_NORMAL
- en: However, there are cases in which the vector remains in the same initial direction.
    Think for example the case where we simply **scale the space**. If we visualize
    **the horizontal and the vertical vector these remain in the same direction although
    they get longer or shorter.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a9fcacf9021dc43981ee78278c454d08.png)'
  prefs: []
  type: TYPE_IMG
- en: Scale Space (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: We see in the image above that the linear transformation applied here is that
    of scaling. But if we try to understand what happens to each individual vector
    we notice that the red vectors still maintain the same direction.
  prefs: []
  type: TYPE_NORMAL
- en: '**These vectors that maintain the same direction are called Eigenvectors of
    the matrix that described this transformation.**'
  prefs: []
  type: TYPE_NORMAL
- en: In particular, the vertical red vector has remained unchanged, so let’s say
    it has eigenvalue =1 while the other red vector has doubled so let’s say it has
    eigenvalue =2.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously depending on the matrix, and thus the transformation, the number of
    eigenvectors may vary.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating Eigenvalues and Eigenvectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us now try to convert what we have expressed in words into a mathematical
    formula. So eigenvectors are those vectors to which when a matrix is applied they
    do not change, at most they lengthen or shorten.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aeaff76b7e9cc98b998ba7a59f3312ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Calculate Eigenvectors (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: In the formula A is a matrix, x is a vector and lambda is a scalar. If the condition
    is satisfied we say that x is an eigenvector of A with the corresponding eigenvalue
    lambda.
  prefs: []
  type: TYPE_NORMAL
- en: By solving the previous equation we can find the value of the eigenvalues that
    solve the equation, let’s see how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7481cdb1a52ac0969491638a87c28dd6.png)'
  prefs: []
  type: TYPE_IMG
- en: Characteristic polynomial (Image By Author=
  prefs: []
  type: TYPE_NORMAL
- en: Once the eigenvalues have been found, it will suffice to substitute them into
    the following equation to find the eigenvectors.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dfda3d33ac32db54c7ed4f57de91be54.png)'
  prefs: []
  type: TYPE_IMG
- en: Find eigenvectors (Image By Author)
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope you have found some useful insights in this article and that you have
    understood them without too much effort. The purpose is to get a little familiar
    with these terms and linear algebra elements. In this way, I hope that the next
    time you go to look at the documentation of sklearn or some library you will be
    able to better understand what that particulate function you are using is actually
    doing! [😊](https://emojipedia.org/smiling-face-with-smiling-eyes/)
  prefs: []
  type: TYPE_NORMAL
- en: The Ends
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Marcello Politi*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [CV](https://march-08.github.io/digital-cv/)'
  prefs: []
  type: TYPE_NORMAL
