- en: 'Unraveling the Design Pattern of Physics-Informed Neural Networks: Part 05'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'æ­ç¤ºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„è®¾è®¡æ¨¡å¼: ç¬¬05éƒ¨åˆ†'
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)
- en: Harnessing automated hyperparameter optimization for effective PINN
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ©ç”¨è‡ªåŠ¨åŒ–è¶…å‚æ•°ä¼˜åŒ–æå‡PINNæ•ˆæœ
- en: '[](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    Â·9 min readÂ·Jun 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    Â·é˜…è¯»æ—¶é—´9åˆ†é’ŸÂ·2023å¹´6æœˆ4æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/33b724900a8fa118517e377c2e46f3fb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33b724900a8fa118517e377c2e46f3fb.png)'
- en: Photo by [Drew Patrick Miller](https://unsplash.com/@drewpatrickmiller?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[Drew Patrick Miller](https://unsplash.com/@drewpatrickmiller?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Welcome to the 5th blog of this series, where we continue our exciting journey
    of exploring ***design patterns*** of physics-informed neural networks (PINN)ğŸ™Œ
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿æ¥åˆ°æœ¬ç³»åˆ—çš„ç¬¬5ç¯‡åšå®¢ï¼Œæˆ‘ä»¬ç»§ç»­æ¢ç´¢ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNï¼‰çš„***è®¾è®¡æ¨¡å¼***ä¹‹æ—…ğŸ™Œ
- en: Have you ever wondered if the best architecture for physics-informed neural
    networks can be automatically searched? It turns out there is a way to do that,
    as indicated by the paper we will be talking about today.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æ˜¯å¦æ›¾ç»æƒ³è¿‡ï¼Œç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„æœ€ä½³æ¶æ„æ˜¯å¦å¯ä»¥è‡ªåŠ¨æœç´¢ï¼Ÿäº‹å®è¯æ˜ï¼Œæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¦‚æˆ‘ä»¬ä»Šå¤©è¦è®¨è®ºçš„è®ºæ–‡æ‰€ç¤ºã€‚
- en: Same as usual, letâ€™s start with a discussion of the issues at hand, followed
    by the solutions brought forward, the benchmarking process, as well as the strengths
    and weaknesses of the proposed technique. We will end the blog with some potential
    future opportunities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä»è®¨è®ºå½“å‰é—®é¢˜å¼€å§‹ï¼Œç„¶åä»‹ç»æå‡ºçš„è§£å†³æ–¹æ¡ˆã€åŸºå‡†æµ‹è¯•è¿‡ç¨‹ä»¥åŠæ‰€ææŠ€æœ¯çš„ä¼˜ç¼ºç‚¹ã€‚åšå®¢æœ€åå°†æ¢è®¨ä¸€äº›æ½œåœ¨çš„æœªæ¥æœºä¼šã€‚
- en: 'In case you are also interested in other PINN design patterns covered in this
    series, feel free to catch up here:'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹æœ¬ç³»åˆ—ä¸­æ¶µç›–çš„å…¶ä»–PINNè®¾è®¡æ¨¡å¼æ„Ÿå…´è¶£ï¼Œå¯ä»¥åœ¨è¿™é‡Œè·Ÿè¿›ï¼š
- en: ''
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 01: ä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 02: åŠ¨æ€è§£åŒºé—´æ‰©å±•](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: ''
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 03: training PINN with gradient boosting](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 03: ç”¨æ¢¯åº¦æå‡è®­ç»ƒPINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 04: æ¢¯åº¦å¢å¼ºPINNå­¦ä¹ ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: ''
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 06ï¼šå› æœ PINN è®­ç»ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 07ï¼šä½¿ç”¨ PINN è¿›è¡Œä¸»åŠ¨å­¦ä¹ ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Letâ€™s dive in!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ï¼
- en: 1\. Paper at a glance ğŸ”
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. è®ºæ–‡æ¦‚è§ˆ ğŸ”
- en: '**Title**: Auto-PINN: Understanding and Optimizing Physics-Informed Neural
    Architecture'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‡é¢˜**ï¼šAuto-PINNï¼šç†è§£å’Œä¼˜åŒ–ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œæ¶æ„'
- en: '**Authors**: Y. C. Wang, X. T. Han, C. Y. Chang, D. C. Zha, U. Braga-Neto,
    X. Hu'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½œè€…**ï¼šY. C. Wang, X. T. Han, C. Y. Chang, D. C. Zha, U. Braga-Neto, X. Hu'
- en: '**Institutes**: Texas A&M University, Rice University'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœºæ„**ï¼šå¾·å…‹è¨æ–¯å†œå·¥å¤§å­¦ï¼Œè±æ–¯å¤§å­¦'
- en: 'Link: [arXiv](https://arxiv.org/abs/2205.13748)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é“¾æ¥ï¼š[arXiv](https://arxiv.org/abs/2205.13748)
- en: 2\. Design pattern ğŸ¨
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. è®¾è®¡æ¨¡å¼ ğŸ¨
- en: 2.1 Problem ğŸ¯
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 é—®é¢˜ ğŸ¯
- en: In the application of Physics-Informed Neural Networks (PINNs), it comes as
    no surprise that the neural network hyperparameters, such as network depth, width,
    the choice of activation function, etc, all have significant impacts on the PINNsâ€™
    efficiency and accuracy.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNsï¼‰çš„åº”ç”¨ä¸­ï¼Œç¥ç»ç½‘ç»œè¶…å‚æ•°ï¼Œå¦‚ç½‘ç»œæ·±åº¦ã€å®½åº¦ã€æ¿€æ´»å‡½æ•°çš„é€‰æ‹©ç­‰ï¼Œéƒ½ä¼šå¯¹ PINN çš„æ•ˆç‡å’Œå‡†ç¡®æ€§äº§ç”Ÿæ˜¾è‘—å½±å“ï¼Œè¿™å¹¶ä¸ä»¤äººæ„å¤–ã€‚
- en: 'Naturally, people would resort to **AutoML** (more specifically, neural architecture
    search) to automatically identify the optimal network hyperparameters. But before
    we can do that, there are two questions that need to be addressed:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶ï¼Œäººä»¬ä¼šæ±‚åŠ©äº**AutoML**ï¼ˆæ›´å…·ä½“åœ°è¯´ï¼Œç¥ç»æ¶æ„æœç´¢ï¼‰æ¥è‡ªåŠ¨è¯†åˆ«æœ€ä½³ç½‘ç»œè¶…å‚æ•°ã€‚ä½†åœ¨æ­¤ä¹‹å‰ï¼Œæœ‰ä¸¤ä¸ªé—®é¢˜éœ€è¦è§£å†³ï¼š
- en: How to effectively navigate the vast search space?
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•æœ‰æ•ˆåœ°åœ¨å¹¿é˜”çš„æœç´¢ç©ºé—´ä¸­å¯¼èˆªï¼Ÿ
- en: How to define a proper search objective?
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•å®šä¹‰åˆé€‚çš„æœç´¢ç›®æ ‡ï¼Ÿ
- en: 'This latter point is due to the fact that PINN is usually seen as an â€œunsupervisedâ€
    problem: no labeled data is needed since the training is guided by minimizing
    the ODE/PDE residuals.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åè€…çš„åŸå› åœ¨äº PINN é€šå¸¸è¢«è§†ä¸ºä¸€ä¸ªâ€œæ— ç›‘ç£â€é—®é¢˜ï¼šç”±äºè®­ç»ƒæ˜¯é€šè¿‡æœ€å°åŒ– ODE/PDE æ®‹å·®æ¥æŒ‡å¯¼çš„ï¼Œå› æ­¤ä¸éœ€è¦æ ‡è®°æ•°æ®ã€‚
- en: '![](../Images/b054003291a6248de678f76d6c53354e.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b054003291a6248de678f76d6c53354e.png)'
- en: PINN workflow. PINNsâ€™ performance is highly sensitive to the network structure.
    One promising way to address this issue is by leveraging AutoML for automatic
    hyperparameter tuning. (Image by this blog author)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: PINN å·¥ä½œæµã€‚PINN çš„æ€§èƒ½å¯¹ç½‘ç»œç»“æ„éå¸¸æ•æ„Ÿã€‚è§£å†³è¿™ä¸€é—®é¢˜çš„ä¸€ä¸ªæœ‰å‰é€”çš„æ–¹æ³•æ˜¯åˆ©ç”¨ AutoML è¿›è¡Œè‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜ã€‚ï¼ˆå›¾ç‰‡ç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: To better understand those two issues, the authors have conducted extensive
    experiments to investigate the PINN performanceâ€™s sensitivity with respect to
    the network structure. Letâ€™s now take a look at what they have found.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å¥½åœ°ç†è§£è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œä½œè€…è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œä»¥è°ƒæŸ¥ PINN æ€§èƒ½å¯¹ç½‘ç»œç»“æ„çš„æ•æ„Ÿæ€§ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä»–ä»¬å‘ç°äº†ä»€ä¹ˆã€‚
- en: 2.2 Solution ğŸ’¡
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 è§£å†³æ–¹æ¡ˆ ğŸ’¡
- en: The first idea proposed in the paper is that **the training loss can be used
    as the surrogate for the search objective**, as it highly correlates with the
    final prediction accuracy of the PINN. This addresses the issue of defining a
    proper optimization target for hyperparameter search.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡æå‡ºçš„ç¬¬ä¸€ä¸ªè§‚ç‚¹æ˜¯**è®­ç»ƒæŸå¤±å¯ä»¥ä½œä¸ºæœç´¢ç›®æ ‡çš„æ›¿ä»£æŒ‡æ ‡**ï¼Œå› ä¸ºå®ƒä¸ PINN çš„æœ€ç»ˆé¢„æµ‹å‡†ç¡®æ€§é«˜åº¦ç›¸å…³ã€‚è¿™è§£å†³äº†ä¸ºè¶…å‚æ•°æœç´¢å®šä¹‰åˆé€‚ä¼˜åŒ–ç›®æ ‡çš„é—®é¢˜ã€‚
- en: The second idea is that **there is no need to optimize all network hyperparameters
    simultaneously**. Instead, we can adopt a **step-by-step decoupling strategy**
    to, for example, first search for the optimal activation function, then fix the
    choice of the activation function and find the optimal network width, then fix
    the previous decisions and optimize network depth, and so on. In their experiments,
    the authors demonstrated that this strategy is very effective.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªè§‚ç‚¹æ˜¯**æ— éœ€åŒæ—¶ä¼˜åŒ–æ‰€æœ‰ç½‘ç»œè¶…å‚æ•°**ã€‚ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨**é€æ­¥è§£è€¦ç­–ç•¥**ï¼Œä¾‹å¦‚ï¼Œé¦–å…ˆæœç´¢æœ€ä½³æ¿€æ´»å‡½æ•°ï¼Œç„¶åå›ºå®šæ¿€æ´»å‡½æ•°çš„é€‰æ‹©ï¼Œå¯»æ‰¾æœ€ä½³ç½‘ç»œå®½åº¦ï¼Œå†å›ºå®šä¹‹å‰çš„å†³å®šå¹¶ä¼˜åŒ–ç½‘ç»œæ·±åº¦ï¼Œä¾æ­¤ç±»æ¨ã€‚åœ¨ä»–ä»¬çš„å®éªŒä¸­ï¼Œä½œè€…è¯æ˜äº†è¿™ä¸€ç­–ç•¥éå¸¸æœ‰æ•ˆã€‚
- en: With those two ideas in mind, letâ€™s see how we can execute the search in detail.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†è¿™ä¸¤ä¸ªè§‚ç‚¹ï¼Œæˆ‘ä»¬æ¥è¯¦ç»†çœ‹çœ‹å¦‚ä½•æ‰§è¡Œæœç´¢ã€‚
- en: 'First of all, which network hyperparameters are considered? In the paper, the
    recommended search space is:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè€ƒè™‘å“ªäº›ç½‘ç»œè¶…å‚æ•°ï¼Ÿåœ¨è®ºæ–‡ä¸­ï¼Œæ¨èçš„æœç´¢ç©ºé—´æ˜¯ï¼š
- en: '**Width**: number of neurons in each hidden layer. The considered range is
    [8, 512] with a step of 4 or 8.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®½åº¦**ï¼šæ¯ä¸ªéšè—å±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡ã€‚è€ƒè™‘çš„èŒƒå›´æ˜¯[8, 512]ï¼Œæ­¥é•¿ä¸º4æˆ–8ã€‚'
- en: '**Depth**: number of hidden layers. The considered range is [3, 10] with a
    step of 1.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ·±åº¦**ï¼šéšè—å±‚çš„æ•°é‡ã€‚è€ƒè™‘çš„èŒƒå›´æ˜¯[3, 10]ï¼Œæ­¥é•¿ä¸º1ã€‚'
- en: '**Activation function**: Tanh, Sigmoid, ReLU, and [Swish](https://paperswithcode.com/method/swish).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¿€æ´»å‡½æ•°**ï¼šTanhã€Sigmoidã€ReLUï¼Œä»¥åŠ[Swish](https://paperswithcode.com/method/swish)ã€‚'
- en: '**Changing point**: the portion of the epochs using Adam to the total training
    epochs. The considered values are [0.1, 0.2, 0.3, 0.4, 0.5]. In PINN, itâ€™s a common
    practice to first use Adam to train for certain epochs and then switch to L-BFGS
    to keep training for some epochs. This changing point hyperparameter determines
    the timing of the change.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å˜åŒ–ç‚¹**ï¼šä½¿ç”¨Adamçš„å‘¨æœŸå æ€»è®­ç»ƒå‘¨æœŸçš„æ¯”ä¾‹ã€‚è€ƒè™‘çš„å€¼ä¸º[0.1, 0.2, 0.3, 0.4, 0.5]ã€‚åœ¨PINNä¸­ï¼Œé€šå¸¸çš„åšæ³•æ˜¯é¦–å…ˆä½¿ç”¨Adamè®­ç»ƒè‹¥å¹²å‘¨æœŸï¼Œç„¶ååˆ‡æ¢åˆ°L-BFGSç»§ç»­è®­ç»ƒè‹¥å¹²å‘¨æœŸã€‚æ­¤å˜åŒ–ç‚¹è¶…å‚æ•°å†³å®šäº†åˆ‡æ¢çš„æ—¶æœºã€‚'
- en: '**Learning rate**: a fixed value of 1e-5, as it has a small effect on the final
    architecture search results.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å­¦ä¹ ç‡**ï¼šå›ºå®šå€¼ä¸º1e-5ï¼Œå› ä¸ºå®ƒå¯¹æœ€ç»ˆçš„æ¶æ„æœç´¢ç»“æœå½±å“è¾ƒå°ã€‚'
- en: '**Training epochs**: a fixed value of 10000, as it has a small effect on the
    final architecture search results.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒå‘¨æœŸ**ï¼šå›ºå®šå€¼ä¸º10000ï¼Œå› ä¸ºå®ƒå¯¹æœ€ç»ˆçš„æ¶æ„æœç´¢ç»“æœå½±å“è¾ƒå°ã€‚'
- en: 'Secondly, letâ€™s examine the proposed procedure in detail:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶æ¬¡ï¼Œè®©æˆ‘ä»¬è¯¦ç»†å®¡æŸ¥æå‡ºçš„è¿‡ç¨‹ï¼š
- en: The first search target is the *activation function*. To achieve that, we sample
    the width and depth parameter space and calculate the losses for all width-depth
    samples under different activation functions. These results can give us ideas
    of which activation function is the dominant one. Once decided, we fix the activation
    function for the following steps.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªæœç´¢ç›®æ ‡æ˜¯*æ¿€æ´»å‡½æ•°*ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é‡‡æ ·å®½åº¦å’Œæ·±åº¦å‚æ•°ç©ºé—´ï¼Œå¹¶è®¡ç®—ä¸åŒæ¿€æ´»å‡½æ•°ä¸‹æ‰€æœ‰å®½åº¦-æ·±åº¦æ ·æœ¬çš„æŸå¤±ã€‚è¿™äº›ç»“æœå¯ä»¥ä¸ºæˆ‘ä»¬æä¾›å“ªä¸ªæ¿€æ´»å‡½æ•°æ˜¯ä¸»å¯¼çš„çº¿ç´¢ã€‚ä¸€æ—¦å†³å®šï¼Œæˆ‘ä»¬å°†åœ¨åç»­æ­¥éª¤ä¸­å›ºå®šæ¿€æ´»å‡½æ•°ã€‚
- en: '![](../Images/e70feda925ce7e4e1ad55422943f9095.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e70feda925ce7e4e1ad55422943f9095.png)'
- en: The first step is to identify the dominant activation function. (Image by this
    blog author)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥æ˜¯è¯†åˆ«ä¸»å¯¼çš„æ¿€æ´»å‡½æ•°ã€‚ï¼ˆå›¾ç‰‡ç”±åšå®¢ä½œè€…æä¾›ï¼‰
- en: The second search target is the *width*. More specifically, we are looking for
    a couple of width intervals where PINN performs well.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªæœç´¢ç›®æ ‡æ˜¯*å®½åº¦*ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å¯»æ‰¾å‡ ä¸ªPINNè¡¨ç°è‰¯å¥½çš„å®½åº¦åŒºé—´ã€‚
- en: '![](../Images/2417264fc5c89ffe09c62dba799b2279.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2417264fc5c89ffe09c62dba799b2279.png)'
- en: The second step is to identify the promising intervals for the network width.
    (Image by this blog author)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ­¥æ˜¯è¯†åˆ«ç½‘ç»œå®½åº¦çš„æœ‰å‰æ™¯åŒºé—´ã€‚ï¼ˆå›¾ç‰‡ç”±åšå®¢ä½œè€…æä¾›ï¼‰
- en: The third search target is the *depth*. Here, we only consider width varying
    within the best-performing intervals determined from the last step, and we would
    like to find the best K width-depth combinations where PINN performs well.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰ä¸ªæœç´¢ç›®æ ‡æ˜¯*æ·±åº¦*ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åªè€ƒè™‘åœ¨ä¸Šä¸€æ­¥ç¡®å®šçš„æœ€ä½³è¡¨ç°åŒºé—´å†…å˜åŒ–çš„å®½åº¦ï¼Œå¹¶å¸Œæœ›æ‰¾åˆ°PINNè¡¨ç°è‰¯å¥½çš„æœ€ä½³Kä¸ªå®½åº¦-æ·±åº¦ç»„åˆã€‚
- en: '![](../Images/f37b81dfa8baf9b6797c43c68b6e824d.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f37b81dfa8baf9b6797c43c68b6e824d.png)'
- en: The third step is to identify the top-K best-performing width-depth combinations.
    (Image by this blog author)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰æ­¥æ˜¯è¯†åˆ«è¡¨ç°æœ€å¥½çš„å®½åº¦-æ·±åº¦ç»„åˆçš„å‰Kåã€‚ï¼ˆå›¾ç‰‡ç”±åšå®¢ä½œè€…æä¾›ï¼‰
- en: The final search target is the *changing point*. We simply search for the best
    changing point for each of the top-K configurations identified from the last step.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€ç»ˆæœç´¢ç›®æ ‡æ˜¯*å˜åŒ–ç‚¹*ã€‚æˆ‘ä»¬ä»…éœ€ä¸ºä¸Šä¸€æ­¥è¯†åˆ«çš„å‰Kä¸ªé…ç½®ä¸­çš„æ¯ä¸€ä¸ªå¯»æ‰¾æœ€ä½³å˜åŒ–ç‚¹ã€‚
- en: '![](../Images/b2c971e519b77efebc33fc216a95519c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2c971e519b77efebc33fc216a95519c.png)'
- en: The final step is to identify the best changing point. (Image by this blog author)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€æ­¥æ˜¯è¯†åˆ«æœ€ä½³å˜åŒ–ç‚¹ã€‚ï¼ˆå›¾ç‰‡ç”±åšå®¢ä½œè€…æä¾›ï¼‰
- en: The outcome of this search procedure is **K different PINN structures**. We
    can either select the best-performing one out of those K candidates or simply
    use all of them to form a K-ensemble PINN model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€æœç´¢è¿‡ç¨‹çš„ç»“æœæ˜¯**Kç§ä¸åŒçš„PINNç»“æ„**ã€‚æˆ‘ä»¬å¯ä»¥ä»è¿™äº›Kä¸ªå€™é€‰ä¸­é€‰æ‹©è¡¨ç°æœ€å¥½çš„ä¸€ä¸ªï¼Œæˆ–ç®€å•åœ°ä½¿ç”¨æ‰€æœ‰è¿™äº›æ¨¡å‹å½¢æˆä¸€ä¸ªK-ensemble PINNæ¨¡å‹ã€‚
- en: Notice that several tuning parameters need to be specified in the above-presented
    procedure (e.g., number of width intervals, number of K, etc.), which would depend
    on the available tuning budget.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œä¸Šè¿°è¿‡ç¨‹éœ€è¦æŒ‡å®šè‹¥å¹²è°ƒä¼˜å‚æ•°ï¼ˆå¦‚å®½åº¦åŒºé—´çš„æ•°é‡ã€Kçš„æ•°é‡ç­‰ï¼‰ï¼Œè¿™å°†å–å†³äºå¯ç”¨çš„è°ƒä¼˜é¢„ç®—ã€‚
- en: As for the specific optimization algorithms used in individual steps, off-the-shelf
    AutoML libraries can be employed to complete the task. For example, the authors
    in the paper used [Tune package](https://docs.ray.io/en/latest/tune/index.html)
    for executing the hyperparameter tuning.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³äºå…·ä½“ä¼˜åŒ–ç®—æ³•çš„ä½¿ç”¨ï¼Œå¯ä»¥åˆ©ç”¨ç°æˆçš„AutoMLåº“æ¥å®Œæˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œè®ºæ–‡ä¸­çš„ä½œè€…ä½¿ç”¨äº†[Tune package](https://docs.ray.io/en/latest/tune/index.html)æ¥æ‰§è¡Œè¶…å‚æ•°è°ƒä¼˜ã€‚
- en: 2.3 Why the solution might work ğŸ› ï¸
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 ä¸ºä»€ä¹ˆè§£å†³æ–¹æ¡ˆå¯èƒ½æœ‰æ•ˆ ğŸ› ï¸
- en: By decoupling the search of different hyperparameters, the scale of the search
    space can be greatly decreased. This not only substantially decreases the search
    complexity, but also significantly increases the chance of locating a (near) optimal
    network architecture for the physical problems under investigation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è§£è€¦ä¸åŒè¶…å‚æ•°çš„æœç´¢ï¼Œæœç´¢ç©ºé—´çš„è§„æ¨¡å¯ä»¥å¤§å¤§ç¼©å°ã€‚è¿™ä¸ä»…å¤§å¤§é™ä½äº†æœç´¢å¤æ‚æ€§ï¼Œè¿˜æ˜¾è‘—æé«˜äº†ä¸ºç ”ç©¶ä¸­çš„ç‰©ç†é—®é¢˜æ‰¾åˆ°ï¼ˆè¿‘ï¼‰æœ€ä¼˜ç½‘ç»œæ¶æ„çš„å¯èƒ½æ€§ã€‚
- en: Also, using the training loss as the search objective is both simple to implement
    and desirable. As the training loss (mainly constituted by PDE residual loss)
    highly correlates with the PINN accuracy during inference (according to the experiments
    conducted in the paper), identifying an architecture that delivers minimum training
    loss will also likely lead to a model with high prediction accuracy.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä½¿ç”¨è®­ç»ƒæŸå¤±ä½œä¸ºæœç´¢ç›®æ ‡æ—¢ç®€å•æ˜“è¡Œåˆä»¤äººæœŸæœ›ã€‚ç”±äºè®­ç»ƒæŸå¤±ï¼ˆä¸»è¦ç”±PDEæ®‹å·®æŸå¤±æ„æˆï¼‰ä¸æ¨ç†è¿‡ç¨‹ä¸­çš„PINNå‡†ç¡®æ€§é«˜åº¦ç›¸å…³ï¼ˆæ ¹æ®è®ºæ–‡ä¸­è¿›è¡Œçš„å®éªŒï¼‰ï¼Œè¯†åˆ«å‡ºèƒ½æä¾›æœ€å°è®­ç»ƒæŸå¤±çš„æ¶æ„ä¹Ÿå¯èƒ½ä¼šå¯¼è‡´ä¸€ä¸ªé«˜é¢„æµ‹å‡†ç¡®åº¦çš„æ¨¡å‹ã€‚
- en: 2.4 Benchmark â±ï¸
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 åŸºå‡†æµ‹è¯• â±ï¸
- en: The paper considered a total of 7 different benchmark problems. All problems
    are forward problems where PINN is used to solve the PDEs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡è€ƒè™‘äº†æ€»å…±7ä¸ªä¸åŒçš„åŸºå‡†é—®é¢˜ã€‚æ‰€æœ‰é—®é¢˜éƒ½æ˜¯æ­£å‘é—®é¢˜ï¼ŒPINNç”¨äºæ±‚è§£PDEã€‚
- en: Heat equation with Dirichlet boundary condition. This type of equation describes
    the heat or temperature distribution in a given domain over
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰Dirichletè¾¹ç•Œæ¡ä»¶çš„çƒ­æ–¹ç¨‹ã€‚è¿™ç±»æ–¹ç¨‹æè¿°äº†ç»™å®šåŒºåŸŸå†…çš„çƒ­é‡æˆ–æ¸©åº¦åˆ†å¸ƒã€‚
- en: time.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ—¶é—´ã€‚
- en: '![](../Images/4baa6f65157c0e3740d7b95632c2b11a.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4baa6f65157c0e3740d7b95632c2b11a.png)'
- en: Heat equation with Neumann boundary conditions.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰Neumannè¾¹ç•Œæ¡ä»¶çš„çƒ­æ–¹ç¨‹ã€‚
- en: '![](../Images/7ceb8b43195cdc1210a823a443906a72.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ceb8b43195cdc1210a823a443906a72.png)'
- en: Wave equation, which describes the propagation of oscillations in a space, such
    as mechanical and electromagnetic waves. Both Dirichlet and Neumann conditions
    are considered here.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¢åŠ¨æ–¹ç¨‹ï¼Œæè¿°äº†ç©ºé—´ä¸­æŒ¯åŠ¨çš„ä¼ æ’­ï¼Œå¦‚æœºæ¢°æ³¢å’Œç”µç£æ³¢ã€‚è¿™é‡Œè€ƒè™‘äº†Dirichletå’ŒNeumannæ¡ä»¶ã€‚
- en: '![](../Images/863da3e4ee07cc436fd1d948a0c6f4e4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/863da3e4ee07cc436fd1d948a0c6f4e4.png)'
- en: Burgers equation, which has been leveraged to model shock flows, wave propagation
    in combustion chambers, vehicular traffic movement, and more.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burgersæ–¹ç¨‹ï¼Œå·²è¢«ç”¨æ¥æ¨¡æ‹Ÿå†²å‡»æµã€ç‡ƒçƒ§å®¤ä¸­çš„æ³¢åŠ¨ä¼ æ’­ã€äº¤é€šæµåŠ¨ç­‰ã€‚
- en: '![](../Images/ccb5818acb93b826e62f1637680b1f1b.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccb5818acb93b826e62f1637680b1f1b.png)'
- en: Advection equation, which describes the motion of a scalar field as it is advected
    by a known velocity vector field.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æµæ–¹ç¨‹ï¼Œæè¿°äº†æ ‡é‡åœºåœ¨å·²çŸ¥é€Ÿåº¦çŸ¢é‡åœºçš„ä½œç”¨ä¸‹çš„è¿åŠ¨ã€‚
- en: '![](../Images/af451ca8c4d7d29e6ce8c86244de3eaa.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af451ca8c4d7d29e6ce8c86244de3eaa.png)'
- en: Advection equation, with different boundary conditions.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æµæ–¹ç¨‹ï¼Œå…·æœ‰ä¸åŒçš„è¾¹ç•Œæ¡ä»¶ã€‚
- en: '![](../Images/966c71e45e89ed8449727b345a07ba24.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/966c71e45e89ed8449727b345a07ba24.png)'
- en: Reaction equation, which describes chemical reactions.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ååº”æ–¹ç¨‹ï¼Œæè¿°åŒ–å­¦ååº”ã€‚
- en: '![](../Images/97b592caefa99d168ae75a97f3ebe41d.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97b592caefa99d168ae75a97f3ebe41d.png)'
- en: 'The benchmark studies yielded that:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºå‡†ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼š
- en: The proposed Auto-PINN shows stable performance for various PDEs.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æå‡ºçš„Auto-PINNåœ¨å„ç§PDEé—®é¢˜ä¸­è¡¨ç°ç¨³å®šã€‚
- en: For most cases, Auto-PINN is able to identify the neural network architecture
    with the smallest error values.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒAuto-PINNèƒ½å¤Ÿè¯†åˆ«å‡ºå…·æœ‰æœ€å°è¯¯å·®å€¼çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚
- en: The search trials are fewer with the Auto-PINN approach.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Auto-PINNæ–¹æ³•çš„æœç´¢å°è¯•æ¬¡æ•°è¾ƒå°‘ã€‚
- en: 2.5 Strengths and Weaknesses âš¡
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 ä¼˜åŠ¿å’ŒåŠ£åŠ¿ âš¡
- en: '**Strengths** ğŸ’ª'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¼˜åŠ¿** ğŸ’ª'
- en: Significantly reduced computational cost for performing neural architecture
    search for PINN applications.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜¾è‘—é™ä½äº†è¿›è¡ŒPINNåº”ç”¨çš„ç¥ç»æ¶æ„æœç´¢çš„è®¡ç®—æˆæœ¬ã€‚
- en: Improved likelihood of identifying a (near) optimal neural network architecture
    for different PDE problems.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé«˜äº†è¯†åˆ«é€‚ç”¨äºä¸åŒPDEé—®é¢˜çš„ï¼ˆè¿‘ï¼‰æœ€ä¼˜ç¥ç»ç½‘ç»œæ¶æ„çš„å¯èƒ½æ€§ã€‚
- en: '**Weaknesses** ğŸ“‰'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**åŠ£åŠ¿** ğŸ“‰'
- en: The effectiveness of using the training loss value as the search objective might
    depend on the specific characteristics of the PDE problem at hand, as the benchmarks
    are performed only for a specific set of PDEs.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è®­ç»ƒæŸå¤±å€¼ä½œä¸ºæœç´¢ç›®æ ‡çš„æœ‰æ•ˆæ€§å¯èƒ½ä¾èµ–äºç‰¹å®šçš„PDEé—®é¢˜ç‰¹å¾ï¼Œå› ä¸ºåŸºå‡†æµ‹è¯•ä»…é’ˆå¯¹ç‰¹å®šçš„ä¸€ç»„PDEè¿›è¡Œã€‚
- en: Data sampling strategy influences Auto-PINN performance. While the paper discusses
    the impact of different data sampling strategies, it does not provide a clear
    guideline on how to choose the best strategy for a given PDE problem. This could
    potentially add another layer of complexity to the use of Auto-PINN.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®é‡‡æ ·ç­–ç•¥å½±å“ Auto-PINN çš„æ€§èƒ½ã€‚å°½ç®¡è®ºæ–‡è®¨è®ºäº†ä¸åŒæ•°æ®é‡‡æ ·ç­–ç•¥çš„å½±å“ï¼Œä½†å¹¶æœªæä¾›å¦‚ä½•é€‰æ‹©é€‚åˆç‰¹å®š PDE é—®é¢˜çš„æœ€ä½³ç­–ç•¥çš„æ˜ç¡®æŒ‡å—ã€‚è¿™å¯èƒ½ä¸ºä½¿ç”¨
    Auto-PINN å¢æ·»äº†å¦ä¸€å±‚å¤æ‚æ€§ã€‚
- en: 2.6 Alternatives ğŸ”€
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 æ›¿ä»£æ–¹æ¡ˆ ğŸ”€
- en: The conventional out-of-box AutoML algorithms can also be employed to tackle
    the problem of hyperparameter optimization in Physics-Informed Neural Networks
    (PINNs). Those algorithms include *Random Search*, *Genetic Algorithms*, *Bayesian
    optimization*, etc.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿçš„ç°æˆ AutoML ç®—æ³•ä¹Ÿå¯ä»¥ç”¨äºè§£å†³ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNsï¼‰çš„è¶…å‚æ•°ä¼˜åŒ–é—®é¢˜ã€‚è¿™äº›ç®—æ³•åŒ…æ‹¬ *éšæœºæœç´¢*ã€*é—ä¼ ç®—æ³•*ã€*è´å¶æ–¯ä¼˜åŒ–* ç­‰ã€‚
- en: Compared to those alternative algorithms, the newly proposed Auto-PINN is specifically
    designed for PINN. This makes it a unique and effective solution for optimizing
    PINN hyperparameters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸é‚£äº›æ›¿ä»£ç®—æ³•ç›¸æ¯”ï¼Œæ–°æå‡ºçš„ Auto-PINN ä¸“é—¨ä¸º PINN è®¾è®¡ã€‚è¿™ä½¿å¾—å®ƒæˆä¸ºä¼˜åŒ– PINN è¶…å‚æ•°çš„ç‹¬ç‰¹ä¸”æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚
- en: 3 Potential Future Improvements ğŸŒŸ
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 ä¸ªæ½œåœ¨çš„æœªæ¥æ”¹è¿› ğŸŒŸ
- en: 'There are several possibilities to further improve the proposed strategy:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰å‡ ä¸ªå¯èƒ½çš„æ–¹å¼æ¥è¿›ä¸€æ­¥æ”¹è¿›æ‰€æè®®çš„ç­–ç•¥ï¼š
- en: Incorporating more sophisticated data sampling strategies, such as adaptive-
    and residual-based sampling methods, to improve the search accuracy and the model
    performance.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“åˆæ›´å¤æ‚çš„æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä¾‹å¦‚è‡ªé€‚åº”å’ŒåŸºäºæ®‹å·®çš„é‡‡æ ·æ–¹æ³•ï¼Œä»¥æé«˜æœç´¢ç²¾åº¦å’Œæ¨¡å‹æ€§èƒ½ã€‚
- en: To learn more about how to optimize the residual points distribution, check
    out [this blog](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)
    in the PINN design pattern series.
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¦äº†è§£æ›´å¤šå…³äºå¦‚ä½•ä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒçš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ [è¿™ç¯‡åšå®¢](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)
    è¿™æ˜¯ PINN è®¾è®¡æ¨¡å¼ç³»åˆ—ä¸­çš„ä¸€ç¯‡æ–‡ç« ã€‚
- en: More benchmarking on the search objective, to assess if training loss value
    is indeed a good surrogate for various types of PDEs.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æœç´¢ç›®æ ‡è¿›è¡Œæ›´å¤šçš„åŸºå‡†æµ‹è¯•ï¼Œä»¥è¯„ä¼°è®­ç»ƒæŸå¤±å€¼æ˜¯å¦ç¡®å®æ˜¯å„ç§ç±»å‹ PDE çš„è‰¯å¥½ä»£ç†ã€‚
- en: Incorporating other types of neural networks. The current version of Auto-PINN
    is designed for multilayer perceptron (MLP) architectures only. Future work could
    explore convolutional neural networks (CNNs) or recurrent neural networks (RNNs),
    which could potentially enhance the capability of PINNs in solving more complex
    PDE problems.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çº³å…¥å…¶ä»–ç±»å‹çš„ç¥ç»ç½‘ç»œã€‚ç›®å‰ç‰ˆæœ¬çš„ Auto-PINN ä»…ä¸ºå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰æ¶æ„è®¾è®¡ã€‚æœªæ¥çš„å·¥ä½œå¯ä»¥æ¢ç´¢å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰æˆ–é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNsï¼‰ï¼Œè¿™äº›å¯èƒ½å¢å¼º
    PINNs è§£å†³æ›´å¤æ‚ PDE é—®é¢˜çš„èƒ½åŠ›ã€‚
- en: Transfer learning in Auto-PINN. For instance, architectures that perform well
    on certain types of PDE problems could be used as starting points for the search
    process on similar types of PDE problems. This could potentially speed up the
    search process and improve the performance of the model.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Auto-PINN ä¸­çš„è¿ç§»å­¦ä¹ ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›ç±»å‹çš„ PDE é—®é¢˜ä¸Šè¡¨ç°è‰¯å¥½çš„æ¶æ„å¯ä»¥ä½œä¸ºç±»ä¼¼ç±»å‹ PDE é—®é¢˜æœç´¢è¿‡ç¨‹çš„èµ·ç‚¹ã€‚è¿™å¯èƒ½åŠ å¿«æœç´¢è¿‡ç¨‹å¹¶æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
- en: 4 Takeaways ğŸ“
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 ä¸ªæ”¶è· ğŸ“
- en: 'In this blog, we looked at how to efficiently tune PINN model hyperparameters
    with the Auto-PINN approach. Here are the highlights of the design pattern proposed
    in the paper:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•ä½¿ç”¨ Auto-PINN æ–¹æ³•æœ‰æ•ˆè°ƒä¼˜ PINN æ¨¡å‹è¶…å‚æ•°ã€‚ä»¥ä¸‹æ˜¯è®ºæ–‡ä¸­æå‡ºçš„è®¾è®¡æ¨¡å¼çš„äº®ç‚¹ï¼š
- en: '[Problem]: How to automatically tune PINNsâ€™ model hyperparameters?'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[é—®é¢˜]: å¦‚ä½•è‡ªåŠ¨è°ƒä¼˜ PINNs çš„æ¨¡å‹è¶…å‚æ•°ï¼Ÿ'
- en: '[Solution]: **Customized Neural Architecture Search**, where the training loss
    is used as the search objective and a step-by-step decoupling strategy is employed
    to effectively narrow the search space.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è§£å†³æ–¹æ¡ˆ]: **å®šåˆ¶åŒ–ç¥ç»æ¶æ„æœç´¢**ï¼Œåœ¨è¯¥æ–¹æ³•ä¸­ï¼Œè®­ç»ƒæŸå¤±è¢«ç”¨ä½œæœç´¢ç›®æ ‡ï¼Œå¹¶é‡‡ç”¨é€æ­¥è§£è€¦ç­–ç•¥æ¥æœ‰æ•ˆç¼©å°æœç´¢ç©ºé—´ã€‚'
- en: '[Potential benefits]: 1\. More efficient search with significantly reduced
    computational cost. 2\. Improved likelihood to identify the (near) optimal neural
    network hyperparameters for different types of PDE problems.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ½œåœ¨å¥½å¤„]: 1\. æ›´é«˜æ•ˆçš„æœç´¢ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚2\. æé«˜è¯†åˆ«ä¸åŒç±»å‹ PDE é—®é¢˜çš„ï¼ˆè¿‘ä¼¼ï¼‰æœ€ä¼˜ç¥ç»ç½‘ç»œè¶…å‚æ•°çš„å¯èƒ½æ€§ã€‚'
- en: 'As usual, I have prepared a PINN design card to summarize the takeaways:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€å¦‚æ—¢å¾€ï¼Œæˆ‘å‡†å¤‡äº†ä¸€å¼  PINN è®¾è®¡å¡æ¥æ€»ç»“æ”¶è·ï¼š
- en: '![](../Images/50de7543bac39e0495455ac5c882c868.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50de7543bac39e0495455ac5c882c868.png)'
- en: PINN design pattern proposed in the paper. (Image by this blog author)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡ä¸­æå‡ºçš„ PINN è®¾è®¡æ¨¡å¼ã€‚ï¼ˆå›¾åƒç”±è¯¥åšå®¢ä½œè€…æä¾›ï¼‰
- en: 'I hope you found this blog useful! To learn more about PINN design patterns,
    feel free to check out other posts in this series:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›æ‚¨è§‰å¾—è¿™ç¯‡åšå®¢å¯¹æ‚¨æœ‰ç”¨ï¼è¦äº†è§£æ›´å¤šå…³äº PINN è®¾è®¡æ¨¡å¼çš„å†…å®¹ï¼Œè¯·éšæ—¶æŸ¥çœ‹æœ¬ç³»åˆ—çš„å…¶ä»–æ–‡ç« ï¼š
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 01ï¼šä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 02ï¼šåŠ¨æ€è§£ç©ºé—´åŒºé—´æ‰©å±•](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: '[PINN design pattern 03: PINN training with gradient boost](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 03ï¼šä½¿ç”¨æ¢¯åº¦æå‡çš„ PINN è®­ç»ƒ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 04ï¼šæ¢¯åº¦å¢å¼ºçš„ PINN å­¦ä¹ ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 06ï¼šå› æœ PINN è®­ç»ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 07ï¼šä½¿ç”¨ PINN çš„ä¸»åŠ¨å­¦ä¹ ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Looking forward to sharing more insights with you in the upcoming blogs!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸå¾…åœ¨å³å°†å‘å¸ƒçš„åšå®¢ä¸­ä¸æ‚¨åˆ†äº«æ›´å¤šè§è§£ï¼
- en: Reference ğŸ“‘
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒ ğŸ“‘
- en: '[1] Wang et al., Auto-PINN: Understanding and Optimizing Physics-Informed Neural
    Architecture, [arXiv](https://arxiv.org/abs/2205.13748), 2022.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Wang et al., Auto-PINN: ç†è§£å’Œä¼˜åŒ–ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œæ¶æ„, [arXiv](https://arxiv.org/abs/2205.13748),
    2022.'
