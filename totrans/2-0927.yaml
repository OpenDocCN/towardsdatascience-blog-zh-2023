- en: Frequentist vs. Bayesian Statistics with Tensorflow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/frequentist-vs-bayesian-statistics-with-tensorflow-fbba2c6c9ae5](https://towardsdatascience.com/frequentist-vs-bayesian-statistics-with-tensorflow-fbba2c6c9ae5)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Probabilistic deep learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@luisroque?source=post_page-----fbba2c6c9ae5--------------------------------)[![LuÃ­s
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----fbba2c6c9ae5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fbba2c6c9ae5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fbba2c6c9ae5--------------------------------)
    [LuÃ­s Roque](https://medium.com/@luisroque?source=post_page-----fbba2c6c9ae5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fbba2c6c9ae5--------------------------------)
    Â·10 min readÂ·Jan 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article belongs to the series â€œProbabilistic Deep Learningâ€. This weekly
    series covers probabilistic approaches to deep learning. The main goal is to extend
    deep learning models to quantify uncertainty, i.e. know what they do not know.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The frequentist approach to statistics is based on the idea of repeated sampling
    and long-run relative frequency. It involves constructing hypotheses about a population
    and testing them using sample data. On the other hand, the Bayesian approach is
    based on subjective probability and involves updating an initial belief about
    a population using collected data. Both methods have their strengths and limitations
    and which one to use depends on the problem and analysis goals. In this article,
    we will explore the differences between the frequentist and the Bayesian approach
    and discuss how they can be implemented using TensorFlow and TensorFlow Probability.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'Articles published so far:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[Gentle Introduction to TensorFlow Probability: Distribution Objects](https://medium.com/towards-data-science/gentle-introduction-to-tensorflow-probability-distribution-objects-1bb6165abee1)'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Gentle Introduction to TensorFlow Probability: Trainable Parameters](https://medium.com/towards-data-science/gentle-introduction-to-tensorflow-probability-trainable-parameters-5098ea4fed15)'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Maximum Likelihood Estimation from scratch in TensorFlow Probability](/maximum-likelihood-estimation-from-scratch-in-tensorflow-probability-2fc0eefdbfc2)'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Probabilistic Linear Regression from scratch in TensorFlow](/probabilistic-linear-regression-from-scratch-in-tensorflow-2eb633fffc00)'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Probabilistic vs. Deterministic Regression with Tensorflow](https://medium.com/towards-data-science/probabilistic-vs-deterministic-regression-with-tensorflow-85ef791beeef)'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Frequentist vs. Bayesian Statistics with Tensorflow](https://medium.com/towards-data-science/frequentist-vs-bayesian-statistics-with-tensorflow-fbba2c6c9ae5)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ä½¿ç”¨ TensorFlow è¿›è¡Œé¢‘ç‡å­¦ä¸è´å¶æ–¯ç»Ÿè®¡æ¯”è¾ƒ](https://medium.com/towards-data-science/frequentist-vs-bayesian-statistics-with-tensorflow-fbba2c6c9ae5)'
- en: '![](../Images/a4570c7be657d4edef2f441ce79f6f04.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4570c7be657d4edef2f441ce79f6f04.png)'
- en: 'Figure 1: Moto for today: there is not a unique way to look at probabilities
    ([source](https://unsplash.com/photos/V3qzwMY2ak0)).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1ï¼šä»Šå¤©çš„åº§å³é“­ï¼šçœ‹å¾…æ¦‚ç‡çš„æ–¹å¼æ²¡æœ‰å”¯ä¸€ç­”æ¡ˆï¼ˆ[æ¥æº](https://unsplash.com/photos/V3qzwMY2ak0)ï¼‰ã€‚
- en: We develop our models using TensorFlow and TensorFlow Probability. TensorFlow
    Probability is a Python library built on top of TensorFlow. We are going to start
    with the basic objects that we can find in TensorFlow Probability and understand
    how can we manipulate them. We will increase complexity incrementally over the
    following weeks and combine our probabilistic models with deep learning on modern
    hardware (e.g. GPU).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ TensorFlow å’Œ TensorFlow Probability æ¥å¼€å‘æˆ‘ä»¬çš„æ¨¡å‹ã€‚TensorFlow Probability æ˜¯ä¸€ä¸ªåŸºäº
    TensorFlow çš„ Python åº“ã€‚æˆ‘ä»¬å°†ä» TensorFlow Probability ä¸­å¯ä»¥æ‰¾åˆ°çš„åŸºæœ¬å¯¹è±¡å¼€å§‹ï¼Œå¹¶ç†è§£å¦‚ä½•æ“ä½œå®ƒä»¬ã€‚æ¥ä¸‹æ¥çš„å‡ å‘¨æˆ‘ä»¬å°†é€æ­¥å¢åŠ å¤æ‚æ€§ï¼Œå¹¶å°†æˆ‘ä»¬çš„æ¦‚ç‡æ¨¡å‹ä¸ç°ä»£ç¡¬ä»¶ï¼ˆä¾‹å¦‚
    GPUï¼‰ä¸Šçš„æ·±åº¦å­¦ä¹ ç»“åˆèµ·æ¥ã€‚
- en: As usual, the code is available on my [GitHub](https://github.com/luisroque/probabilistic_deep_learning_with_TFP).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å¸¸ï¼Œä»£ç å¯ä»¥åœ¨æˆ‘çš„[GitHub](https://github.com/luisroque/probabilistic_deep_learning_with_TFP)ä¸Šæ‰¾åˆ°ã€‚
- en: Frequentist vs. Bayesian Approach to Problems
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¢‘ç‡å­¦ä¸è´å¶æ–¯æ–¹æ³•çš„æ¯”è¾ƒ
- en: Frequentist statistics and Bayesian statistics are two main approaches to statistical
    inference, which is the process of using data to draw conclusions about a population.
    Both approaches are used to estimate unknown quantities, make predictions, and
    test hypotheses, but they differ in their interpretation of probability and how
    they incorporate prior knowledge and evidence.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: é¢‘ç‡å­¦ç»Ÿè®¡å’Œè´å¶æ–¯ç»Ÿè®¡æ˜¯ç»Ÿè®¡æ¨æ–­çš„ä¸¤ç§ä¸»è¦æ–¹æ³•ï¼Œç»Ÿè®¡æ¨æ–­æ˜¯åˆ©ç”¨æ•°æ®å¯¹æ€»ä½“å¾—å‡ºç»“è®ºçš„è¿‡ç¨‹ã€‚è¿™ä¸¤ç§æ–¹æ³•éƒ½ç”¨äºä¼°è®¡æœªçŸ¥é‡ã€è¿›è¡Œé¢„æµ‹å’Œæ£€éªŒå‡è®¾ï¼Œä½†åœ¨æ¦‚ç‡çš„è§£é‡ŠåŠå¦‚ä½•èå…¥å…ˆéªŒçŸ¥è¯†å’Œè¯æ®æ–¹é¢æœ‰æ‰€ä¸åŒã€‚
- en: In frequentist statistics, probability is interpreted as the long-run relative
    frequency of an event in an infinite number of trials. This approach is based
    on the idea that the true value of a population parameter is fixed, but is unknown
    and must be estimated from data. In this framework, statistical inferences are
    drawn from the observed data by making assumptions about the underlying data-generating
    process and using techniques such as point estimation, confidence intervals, and
    hypothesis testing.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é¢‘ç‡å­¦ç»Ÿè®¡ä¸­ï¼Œæ¦‚ç‡è¢«è§£é‡Šä¸ºäº‹ä»¶åœ¨æ— é™æ¬¡è¯•éªŒä¸­çš„é•¿æœŸç›¸å¯¹é¢‘ç‡ã€‚è¿™ç§æ–¹æ³•åŸºäºä¸€ä¸ªè§‚ç‚¹ï¼Œå³æ€»ä½“å‚æ•°çš„çœŸå®å€¼æ˜¯å›ºå®šçš„ï¼Œä½†æœªçŸ¥ä¸”å¿…é¡»é€šè¿‡æ•°æ®è¿›è¡Œä¼°è®¡ã€‚åœ¨è¿™ä¸ªæ¡†æ¶ä¸‹ï¼Œç»Ÿè®¡æ¨æ–­æ˜¯é€šè¿‡å¯¹è§‚å¯Ÿæ•°æ®è¿›è¡Œå‡è®¾æ¥ä»ä¸­å¾—å‡ºçš„ï¼Œä½¿ç”¨ç‚¹ä¼°è®¡ã€ç½®ä¿¡åŒºé—´å’Œå‡è®¾æ£€éªŒç­‰æŠ€æœ¯ã€‚
- en: On the other hand, Bayesian statistics interprets probability as a measure of
    belief or degree of certainty about an event. This approach allows for the incorporation
    of prior knowledge and evidence into statistical analysis through the use of Bayesâ€™
    theorem. In this framework, the true value of a population parameter is treated
    as a random variable and is updated as new data is collected. This results in
    a full distribution over the parameter space, known as a posterior distribution,
    which can be used to make probabilistic predictions and to quantify uncertainty.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œè´å¶æ–¯ç»Ÿè®¡å°†æ¦‚ç‡è§£é‡Šä¸ºå¯¹äº‹ä»¶çš„ä¿¡å¿µæˆ–ç¡®å®šæ€§çš„ç¨‹åº¦ã€‚è¿™ç§æ–¹æ³•å…è®¸é€šè¿‡ä½¿ç”¨è´å¶æ–¯å®šç†å°†å…ˆéªŒçŸ¥è¯†å’Œè¯æ®èå…¥ç»Ÿè®¡åˆ†æã€‚åœ¨è¿™ä¸ªæ¡†æ¶ä¸‹ï¼Œæ€»ä½“å‚æ•°çš„çœŸå®å€¼è¢«è§†ä¸ºéšæœºå˜é‡ï¼Œå¹¶éšç€æ–°æ•°æ®çš„æ”¶é›†è€Œæ›´æ–°ã€‚è¿™å¯¼è‡´äº†ä¸€ä¸ªå…³äºå‚æ•°ç©ºé—´çš„å®Œæ•´åˆ†å¸ƒï¼Œç§°ä¸ºåéªŒåˆ†å¸ƒï¼Œè¿™å¯ä»¥ç”¨æ¥è¿›è¡Œæ¦‚ç‡é¢„æµ‹å¹¶é‡åŒ–ä¸ç¡®å®šæ€§ã€‚
- en: One key difference between the two approaches is how they handle uncertainty.
    In frequentist statistics, uncertainty is quantified through the use of confidence
    intervals, which provide an estimate of the likely range of the true population
    parameter based on the observed data. In Bayesian statistics, uncertainty is represented
    by the full posterior distribution, which allows for a more complete characterization
    of the uncertainty surrounding the true value of the parameter.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„ä¸€ä¸ªå…³é”®åŒºåˆ«æ˜¯å®ƒä»¬å¤„ç†ä¸ç¡®å®šæ€§çš„æ–¹å¼ã€‚åœ¨é¢‘ç‡å­¦ç»Ÿè®¡ä¸­ï¼Œä¸ç¡®å®šæ€§é€šè¿‡ä½¿ç”¨ç½®ä¿¡åŒºé—´æ¥é‡åŒ–ï¼Œè¿™äº›åŒºé—´æä¾›äº†åŸºäºè§‚å¯Ÿæ•°æ®çš„çœŸå®æ€»ä½“å‚æ•°çš„å¯èƒ½èŒƒå›´çš„ä¼°è®¡ã€‚åœ¨è´å¶æ–¯ç»Ÿè®¡ä¸­ï¼Œä¸ç¡®å®šæ€§é€šè¿‡å®Œæ•´çš„åéªŒåˆ†å¸ƒæ¥è¡¨ç¤ºï¼Œè¿™ä½¿å¾—å¯¹å‚æ•°çœŸå®å€¼çš„ä¸ç¡®å®šæ€§è¿›è¡Œæ›´å…¨é¢çš„æè¿°æˆä¸ºå¯èƒ½ã€‚
- en: Another difference is that Bayesian statistics allows for the incorporation
    of prior knowledge, which can be particularly useful in cases where there is limited
    data or when the data-generating process is complex. However, the choice of prior
    distribution can significantly influence the results of a Bayesian analysis, and
    it is important to choose a prior that is appropriate for the problem at hand.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The Problem
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an example of applying a frequentist approach to a problem, consider the
    task of estimating the mean income of a population based on a sample of data.
    In this case, the goal is to use the sample data to make inferences about the
    true mean income of the population (we are going to assume that the standard deviation
    of the income of the population is known for now).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Letâ€™s generate some data:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/bb1676894082a75eb3e8d331a522c244.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Histogram of the sample mean of the income of the population â€” synthetically
    generated data.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The Frequentist Way
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One way to approach this problem using a frequentist approach is through point
    estimation. Point estimation involves using a single point estimate, such as the
    sample mean, to represent the unknown population parameter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'The sample mean, *ğœ‡*Ì‚, is a commonly used point estimate for the population
    mean, *ğœ‡*. It is calculated as the sum of the sample values, *ğ‘¥*1,*ğ‘¥*2,â€¦,*ğ‘¥ğ‘›*,
    divided by the sample size, *ğ‘›*:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8683864dfca212802019de01e5c0e3d.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: However, point estimates alone do not provide a complete characterization of
    the uncertainty surrounding the estimate. To quantify this uncertainty, we can
    use a confidence interval. A confidence interval is an estimate of the likely
    range of the true population parameter based on the observed data, and it is constructed
    by adding and subtracting a margin of error from the point estimate. The margin
    of error is determined by the desired level of confidence and the sample size,
    and it reflects the variability in the sample data. For example, a 95% confidence
    interval indicates that we are 95% confident that the true population parameter
    falls within the interval.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'A confidence interval for the population mean is constructed by adding and
    subtracting a margin of error, *ğ‘š*, to the point estimate:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1660d16b740375d1eba7e5e97c1aa79f.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: 'The margin of error is determined by the desired level of confidence, 1âˆ’*ğ›¼*,
    and the sample size, *ğ‘›*. It reflects the variability in the sample data and is
    typically calculated using the standard error, *ğ‘†ğ¸*, of the point estimate:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/69cc8f472cbbd1706ff712d9cd3bf4b7.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: where *ğ‘¡*1âˆ’*ğ›¼*2,*ğ‘›*âˆ’1 is the critical value of the *ğ‘¡*-distribution with *ğ‘›*âˆ’1
    degrees of freedom for the desired level of confidence.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard error of the sample mean is calculated as the standard deviation
    of the sample, *ğœ*, divided by the square root of the sample size:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa7358e49e38f104231074c38e6eda34.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can define a helper function to plot our predicting mean and confidence interval
    overlayed on the sampled data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/8018f59799dbb1fe66945a8ded152fc7.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Mean and confidence interval for the estimated parameter using a
    frequentist approach.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: The Bayesian Way
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As an example of applying a Bayesian approach to a problem, consider the task
    of estimating the mean income of a population based on a sample of data. In this
    case, the goal is to use the sample data and any available prior knowledge to
    make inferences about the true mean income of the population.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to approach this problem using a Bayesian approach is through the use
    of Bayesâ€™ theorem, which allows us to update our belief about the value of the
    population mean income based on the observed data. Bayesâ€™ theorem states that
    the posterior probability of a hypothesis given some data is equal to the prior
    probability of the hypothesis multiplied by the likelihood of the data given the
    hypothesis, normalized by the marginal probability of the data. This can be written
    mathematically as:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5104070b345c851739bee6f11763fb64.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: where *ğœƒ* is the population mean income, *ğ‘¥* is the observed data (i.e., the
    sample of income values), and *ğ‘ƒ*(*ğœƒ*|*ğ‘¥*), *ğ‘ƒ*(*ğ‘¥*|*ğœƒ*), *ğ‘ƒ*(*ğœƒ*), and *ğ‘ƒ*(*ğ‘¥*)
    are the posterior probability, likelihood, prior probability, and marginal probability,
    respectively.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: To apply this approach to the income example, we must first specify a prior
    distribution over the population mean income, *ğ‘ƒ*(*ğœƒ*). This prior distribution
    represents our belief about the value of the population mean income before we
    observe the data. The choice of prior distribution will depend on any available
    prior knowledge and the characteristics of the data-generating process. For example,
    if we have strong prior knowledge that the population mean income is normally
    distributed with a mean of 45,000 and a standard deviation of 5,000, we could
    use a normal prior distribution with these parameters.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The likelihood function, *ğ‘ƒ*(*ğ‘¥*|*ğœƒ*), represents the probability of observing
    the sample data, *ğ‘¥*, given a particular value of the population mean income,
    *ğœƒ*. Since the sample data are assumed to be independent and identically distributed
    (i.i.d.), the likelihood function is simply the product of the individual probability
    density functions of the sample values. For example, if the sample data are normally
    distributed with a known standard deviation, *ğœ*, the likelihood function is a
    normal distribution with mean equal to the population mean income, *ğœƒ*, and standard
    deviation equal to the sample standard deviation:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cdf307247325c7851dde09709c019f0d.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we use Bayesâ€™ theorem to compute the posterior distribution:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5a7e464737f73240911ed517243fcaa1.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: The posterior distribution can be used to make probabilistic predictions and
    to quantify the uncertainty surrounding the estimate of the population mean income.
    For example, we can use the posterior distribution to compute the posterior mean
    and posterior standard deviation as estimates of the population mean income and
    the uncertainty around the estimate, respectively.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: As we saw above, the posterior distribution is a result of multiplying two Gaussian
    distributions. For us to accomplish that, we need to introduce one more concept
    â€” conjugate distributions. In our case, we have a normal-normal conjugate family
    which is a parametric family of distributions where the prior distribution and
    the likelihood function are both normal distributions. This class of models has
    several attractive properties, including the ability to analytically compute the
    posterior distribution and the closed-form solution for the maximum a posteriori
    (MAP) estimate.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'The posterior distribution is defined as the distribution of the model parameters
    (in this case, the mean *ğœ‡* and standard deviation *ğœ* of the normal distribution)
    given the observed data *ğ‘¦*. The mean and standard deviation of the posterior
    distribution can be calculated using the following equations:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ffab0505eda21264e5334da4daa4c4b1.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
- en: where *ğœ‡*0 and *ğœ*2_0 are the mean and variance of the prior distribution, respectively,
    *ğœ‡_ğ‘™* and *ğœ2_l* are the mean and the variance of the likelihood function and
    *ğ‘›* is the sample size.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: These equations assume that the prior distribution and the likelihood function
    are both normal distributions, as is the case in a normal-normal conjugate model.
    If the prior and likelihood are not normal, or if the posterior distribution does
    not have a closed-form solution, these parameters can be approximated using techniques
    such as Markov Chain Monte Carlo (MCMC) sampling.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: We are ready to implement our new equations.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see how updating our prior belief with data resulted in our posterior
    distribution.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/54e2b201408727822e8af4ab347490a6.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Prior, Likelihood and Posterior probability functions.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Finally, as we did for the frequentist case, we can plot our estimate for the
    mean of the population. Notice that we are actually computing the credible interval
    and not the confidence interval with the Bayesian approach.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/0e3221655e11c5b959a0c870598ba212.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Mean and credible interval for the estimated parameter using a Bayesian
    approach'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, the frequentist and Bayesian approaches are two different ways
    of analyzing data and making predictions. The frequentist approach is based on
    the idea of statistical significance and involves constructing hypotheses about
    a population and testing them using sample data. The Bayesian approach is based
    on subjective probability and involves updating an initial belief about a population
    using collected data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Using TensorFlow and TensorFlow Probability, we demonstrated how to compute
    the mean and confidence interval for the frequentist approach and the mean and
    credible interval for the Bayesian approach. Both approaches can be useful for
    different types of problems and it is important to understand the strengths and
    limitations of each one in order to choose the most appropriate method for a given
    situation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ TensorFlow å’Œ TensorFlow Probabilityï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•è®¡ç®—é¢‘ç‡å­¦æ´¾æ–¹æ³•çš„å‡å€¼å’Œç½®ä¿¡åŒºé—´ï¼Œä»¥åŠè´å¶æ–¯æ–¹æ³•çš„å‡å€¼å’Œå¯ä¿¡åŒºé—´ã€‚è¿™ä¸¤ç§æ–¹æ³•åœ¨ä¸åŒç±»å‹çš„é—®é¢˜ä¸­éƒ½å¯èƒ½æœ‰ç”¨ï¼Œå› æ­¤äº†è§£æ¯ç§æ–¹æ³•çš„ä¼˜ç¼ºç‚¹å¯¹äºé€‰æ‹©æœ€é€‚åˆçš„æ–¹æ¡ˆè‡³å…³é‡è¦ã€‚
- en: 'Keep in touch: [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿æŒè”ç³»ï¼š[LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
