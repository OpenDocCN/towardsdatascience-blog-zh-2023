- en: Improving Diffusers Package for High-Quality Image Generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进 Diffusers 包以生成高质量图像
- en: 原文：[https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4](https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4](https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4)
- en: Overcoming token size limitations, custom model loading, LoRa support, textual
    inversion support, and more
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 克服 token 大小限制、自定义模型加载、LoRa 支持、文本反转支持等
- en: '[](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Andrew
    Zhu (Shudong Zhu)](../Images/46f07a875a42bcc4e0c262aea5e2a504.png)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    [Andrew Zhu (Shudong Zhu)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Andrew
    Zhu (Shudong Zhu)](../Images/46f07a875a42bcc4e0c262aea5e2a504.png)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    [Andrew Zhu (Shudong Zhu)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    ·15 min read·Apr 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    ·15 分钟阅读·2023年4月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ec28506deb9273669dd315b83ff91aec.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec28506deb9273669dd315b83ff91aec.png)'
- en: Goodbye Babel, generated by Andrew Zhu using Diffusers in pure Python
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 再见 Babel，由 Andrew Zhu 使用纯 Python 中的 Diffusers 生成
- en: '[Stable Diffusion WebUI from AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
    has proven to be a powerful tool for generating high-quality images using the
    Diffusion model. However, while the WebUI is easy to use, data scientists, machine
    learning engineers, and researchers often require more control over the image
    generation process. This is where the [diffusers](https://github.com/huggingface/diffusers)
    package from huggingface comes in, providing a way to run the Diffusion model
    in Python and allowing users to customize their models and prompts to generate
    images to their specific needs.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[AUTOMATIC1111 的 Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
    已被证明是一个强大的工具，可以使用 Diffusion 模型生成高质量图像。然而，尽管 WebUI 使用简单，数据科学家、机器学习工程师和研究人员通常需要对图像生成过程有更多控制。这时，来自
    huggingface 的 [diffusers](https://github.com/huggingface/diffusers) 包就派上了用场，它提供了一种在
    Python 中运行 Diffusion 模型的方法，并允许用户自定义模型和提示，以生成符合他们具体需求的图像。'
- en: 'Despite its potential, the Diffusers package has several limitations that prevent
    it from generating images as good as those produced by the Stable Diffusion WebUI.
    The most significant of these limitations include:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管具有潜力，Diffusers 包仍有几个限制，阻碍了它生成与 Stable Diffusion WebUI 相媲美的图像。这些限制中最显著的包括：
- en: The inability to use custom models in the `.safetensor` file format;
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无法使用 `.safetensor` 文件格式中的自定义模型；
- en: The 77 prompt token limitation;
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 77 个提示 token 的限制；
- en: A lack of LoRA support;
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏 LoRA 支持；
- en: And the absence of image scale-up functionality (also known as HighRes in Stable
    Diffusion WebUI);
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及缺少图像放大功能（在 Stable Diffusion WebUI 中也称为 HighRes）；
- en: Low performance and high VRAM usage by default.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下性能低且 VRAM 使用高。
- en: This article aims to address these limitations and enable the Diffusers package
    to generate high-quality images comparable to those produced by the Stable Diffusion
    WebUI. With the enhancement solutions provided, data scientists, machine learning
    engineers, and researchers can enjoy greater control and flexibility in their
    image generation processes while also achieving exceptional results. In the following
    sections, we will explore the various strategies and techniques that can be used
    to overcome these limitations and unlock the full potential of the Diffusers package.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在解决这些限制，并使Diffusers包能够生成与Stable Diffusion WebUI产生的图像相媲美的高质量图像。通过提供的增强解决方案，数据科学家、机器学习工程师和研究人员可以在图像生成过程中享有更大的控制和灵活性，同时实现卓越的结果。在接下来的部分中，我们将探讨各种策略和技术，这些策略和技术可以用来克服这些限制，并释放Diffusers包的全部潜力。
- en: Note that please follow this link to install all required CUDA and Python packages
    if it is your first time running Stable Diffusion.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果这是你第一次运行Stable Diffusion，请按照此[链接](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)安装所有所需的CUDA和Python包。
- en: '[](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)
    [## Installation'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 安装](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)'
- en: Install 🤗 Diffusers for whichever deep learning library you're working with.
    🤗 Diffusers is tested on Python 3.7+…
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为你正在使用的深度学习库安装🤗 Diffusers。🤗 Diffusers已在Python 3.7+上测试过…
- en: huggingface.co](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[huggingface.co](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)'
- en: 1\. Load Up Local Model files in .safetensor Format
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 加载本地的.safetensor格式模型文件
- en: 'Users can easily spin up diffusers to generate an image like this:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以轻松启动diffusers来生成这样的图像：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You may not satisfy with either the output image or the performance. Let’s
    deal with the problems one by one. First, let’s load up a custom model in `.safetensor`
    format located anywhere on your machine. you **can’t** just load the model file
    like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能对输出的图像或性能不满意。让我们逐个解决这些问题。首先，让我们加载一个`.safetensor`格式的自定义模型，该模型位于你计算机上的任何位置。你**不能**像这样直接加载模型文件：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here are the detailed steps to covert `.safetensor` file to diffusers format:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是将`.safetensor`文件转换为diffusers格式的详细步骤：
- en: '**Step 1**. Pull all diffusers code from GitHub'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1**。从GitHub拉取所有diffusers代码'
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Step 2**. Under the `scripts` folder locate the [file](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py):
    `convert_original_stable_diffusion_to_diffusers.py`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤2**。在`script`文件夹下找到[文件](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py)：`convert_original_stable_diffusion_to_diffusers.py`'
- en: In your terminal, run this command to convert `.safetensor` file to Diffusers
    format. Remember to change the `— checkpoint_path` value to represent your case.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中运行此命令将`.safetensor`文件转换为Diffusers格式。记得将`— checkpoint_path`值更改为你的情况。
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Step 3**. Now you can load up the pipeline using the newly converted model
    file, here is the complete code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤3**。现在你可以使用新转换的模型文件加载管道，下面是完整代码：'
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You should be able to convert and use any models you download from huggingface
    or civitai.com.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够转换并使用你从huggingface或civitai.com下载的任何模型。
- en: '![](../Images/a205baa885ec1cb4bb289043bcc75c7d.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a205baa885ec1cb4bb289043bcc75c7d.png)'
- en: Cat playing piano generated by the above code
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由上述代码生成的弹钢琴的猫
- en: 2\. Boost the Performance of Diffusers
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 提升Diffusers的性能
- en: Generating high-quality images can be a time-consuming process even for the
    latest 3xxx and 4xxx Nvidia RTX GPUs. By default, Diffuers package comes with
    non-optimized settings. Two solutions can be applied to greatly boost performance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 生成高质量图像可能是一个耗时的过程，即使对于最新的3xxx和4xxx Nvidia RTX GPU也是如此。默认情况下，Diffuers包的设置是未优化的。可以应用两种解决方案来大幅提升性能。
- en: Here is the interaction speed before applying the following solution, only about
    2.x iterations per second in RTX 3070 TI 8G RAM to generate a 512x512 image
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用以下解决方案之前的交互速度如下：在RTX 3070 TI 8G RAM中生成一个512x512图像的速度大约为每秒2.x次迭代。
- en: '![](../Images/523fd850a9008a5879b938236e13116f.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/523fd850a9008a5879b938236e13116f.png)'
- en: '**Use Half Precision Weights**'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用半精度权重**'
- en: The first solution is to use half precision weights. Half precision weights
    use 16-bit floating-point numbers instead of the traditional 32-bit numbers. This
    reduces the memory required for storing weights and speeds up computation, which
    can significantly improve the performance of the Diffusers package.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个解决方案是使用半精度权重。半精度权重使用16位浮点数代替传统的32位浮点数。这减少了存储权重所需的内存，并加快了计算速度，这可以显著提高Diffusers包的性能。
- en: According to this [video](https://www.youtube.com/watch?v=9tpLJpqxdE8&ab_channel=NVIDIADeveloper),
    reducing float precision from FP32 to FP16 will also enable the Tensor Cores.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个[视频](https://www.youtube.com/watch?v=9tpLJpqxdE8&ab_channel=NVIDIADeveloper)，将浮点精度从FP32减少到FP16也会启用Tensor
    Cores。
- en: I had another article to test out how fast GPU Tensor cores can boost the computation
    speed.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我还有另一篇文章来测试GPU Tensor Cores能多快提升计算速度。
- en: '[](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
    [## How Fast GPU Computation Can Be'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
    [## GPU计算能有多快'
- en: A comparison of matrix arithmetic calculation in CPU and GPU with Python and
    PyTorch
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU和GPU在Python和PyTorch中进行矩阵运算比较
- en: towardsdatascience.com](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)'
- en: Here is how to enable FP16 in diffusers, Just adding two lines of code will
    boost the performance by 500%, with almost no image quality impacts.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何在diffusers中启用FP16，只需添加两行代码即可将性能提升500%，几乎没有图像质量影响。
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now the iteration speed boosts to 10.x iteration per second. A **5x times faster**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在迭代速度提升至每秒10.x次，**快了5倍**。
- en: '![](../Images/e365ff233687b79a64d433c7508b776d.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e365ff233687b79a64d433c7508b776d.png)'
- en: '**Use Xformers**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用Xformers**'
- en: '[Xformers](https://github.com/facebookresearch/xformers) is an open-source
    library that provides a set of high-performance transformers for various natural
    language processing (NLP) tasks. It is built on top of PyTorch and aims to provide
    efficient and scalable transformer models that can be easily integrated into existing
    NLP pipelines. (Nowadays, are there any models that don’t use Transformer? :P)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[Xformers](https://github.com/facebookresearch/xformers)是一个开源库，提供了一组高性能的变换器，适用于各种自然语言处理（NLP）任务。它基于PyTorch构建，旨在提供高效且可扩展的变换器模型，这些模型可以轻松集成到现有的NLP流程中。（如今，还有哪些模型不使用Transformer？:P）'
- en: Install Xformers by `pip install xformers` , then we can easily switch diffusers
    to use xformers by one line code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pip install xformers`安装Xformers，然后我们只需一行代码即可轻松切换diffusers使用xformers。
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This one-line code boosts performance by another 20%.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行代码性能提升了另外20%。
- en: '![](../Images/d31f5865af53b4ed32364192c78b7d52.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d31f5865af53b4ed32364192c78b7d52.png)'
- en: 3\. Remove the 77 prompt tokens limitation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 移除77个提示符的限制
- en: In the current version of Diffusers, there is a limitation of 77 prompt tokens
    that can be used in the generation of images.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前版本的Diffusers中，生成图像时有77个提示符的限制。
- en: Fortunately, there is a solution to this problem. By using the “`lpw_stable_diffusion`”
    pipeline provided by the community, you can unlock the 77 prompt token limitation
    and generate high-quality images with longer prompts.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，针对这个问题有一个解决方案。通过使用社区提供的“`lpw_stable_diffusion`”管道，你可以解锁77个提示符的限制，并生成高质量的长提示图像。
- en: 'To use the “`lpw_stable_diffusion`” pipeline, you can use the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用“`lpw_stable_diffusion`”管道，可以使用以下代码：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this code, we are initializing a new DiffusionPipeline object using the “`from_pretrained`”
    method. We are specifying the path to the pre-trained model and setting the “`custom_pipeline`”
    argument to “`lpw_stable_diffusion`”. This tells Diffusers to use the “`lpw_stable_diffusion`”
    pipeline, which unlocks the 77 prompt token limitation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们使用“`from_pretrained`”方法初始化一个新的DiffusionPipeline对象。我们指定了预训练模型的路径，并将“`custom_pipeline`”参数设置为“`lpw_stable_diffusion`”。这告诉Diffusers使用“`lpw_stable_diffusion`”管道，从而解锁77个提示符的限制。
- en: 'Now, let’s use a long prompt string to test it out. Here is the complete code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用一个长提示字符串来测试一下。以下是完整的代码：
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And you will get an image like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你将获得如下图像：
- en: '![](../Images/7b1e72d61d933d3acdae9a6b8ceb0da2.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b1e72d61d933d3acdae9a6b8ceb0da2.png)'
- en: Goodby Babel, generated by Andrew Zhu using diffusers
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Goodby Babel，由Andrew Zhu使用diffusers生成
- en: 'If you still see a warning message like: `Token indices sequence length is
    longer than the specified maximum sequence length for this model ( *** > 77 )
    . Running this sequence through the model will result in indexing errors.` It
    is normal, you can just ignore it.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然看到类似的警告信息：`Token indices sequence length is longer than the specified maximum
    sequence length for this model ( *** > 77 ) . Running this sequence through the
    model will result in indexing errors.` 这很正常，你可以忽略它。
- en: 4\. Use Custom LoRA with Diffusers
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 使用自定义 LoRA 与扩散器
- en: Despite the claims of [LoRA support](https://huggingface.co/docs/diffusers/training/lora)
    in Diffusers, users still face limitations when it comes to loading local LoRA
    files in the `.safetensor` file format. This can be a significant obstacle for
    users to use the LoRA from the community.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 [LoRA 支持](https://huggingface.co/docs/diffusers/training/lora) 在 Diffusers
    中有所声称，但用户在加载本地 `.safetensor` 文件格式的 LoRA 文件时仍面临限制。这对用户使用社区 LoRA 可能是一个重大障碍。
- en: To overcome this limitation, I have created a function that allows users to
    load LoRA files with weighted numbers in real time. This function can be used
    to load LoRA files and their corresponding weights to a Diffusers model, enabling
    the generation of high-quality images with LoRA data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这一限制，我创建了一个允许用户实时加载带有权重的 LoRA 文件的函数。这个函数可以用来将 LoRA 文件及其对应的权重加载到 Diffusers
    模型中，从而生成高质量的 LoRA 数据图像。
- en: 'Here is the function body:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这是函数主体：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The logic is extracted from the [convert_lora_safetensor_to_diffusers.py](https://github.com/huggingface/diffusers/blob/main/scripts/convert_lora_safetensor_to_diffusers.py)
    of the diffusers git repo.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑提取自 diffusers git 仓库的 [convert_lora_safetensor_to_diffusers.py](https://github.com/huggingface/diffusers/blob/main/scripts/convert_lora_safetensor_to_diffusers.py)。
- en: 'Take one of the famous [LoRA:MoXin](https://civitai.com/models/12597/moxin)
    for example. you can use the `__load_lora` function like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以著名的 [LoRA:MoXin](https://civitai.com/models/12597/moxin) 为例。你可以像这样使用 `__load_lora`
    函数：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The prompt will generate an image like this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 提示将生成类似这样的图像：
- en: '![](../Images/0c2db814c9d57b74bd9cdcf193ee1ce4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c2db814c9d57b74bd9cdcf193ee1ce4.png)'
- en: a branch of flower, generated by Andrew Zhu using diffusers
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一枝花，由 Andrew Zhu 使用扩散器生成
- en: You can call multiple times of `__load_lora()` to load several LoRAs for one
    generation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以多次调用`__load_lora()`来为一次生成加载多个 LoRA。
- en: With this function, you can now load LoRA files with weighted numbers in real
    time and use them to generate high-quality images with Diffusers. The LoRA loading
    is pretty fast, usually taking only 1–2 seconds, way better than converting and
    using(which will generate another model file in GB size).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此功能，你现在可以实时加载带有权重的 LoRA 文件，并用它们生成高质量的图像。LoRA 加载速度非常快，通常只需 1-2 秒，比转换和使用（这会生成一个
    GB 大小的模型文件）要好得多。
- en: 5\. Use Custom Textural Inversions with Diffusers
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 使用自定义纹理反演与扩散器
- en: Using custom Texture Inversions with Diffusers package can be a powerful way
    to generate high-quality images. However, the [official documentation of Diffusers](https://huggingface.co/docs/diffusers/training/text_inversion)
    suggests that users need to train their own Textual Inversions which can take
    up to an hour on a V100 GPU. This may not be practical for many users who want
    to generate images quickly.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Diffusers 包中的自定义纹理反演是一种生成高质量图像的强大方法。然而，[Diffusers 的官方文档](https://huggingface.co/docs/diffusers/training/text_inversion)
    提到，用户需要训练自己的文本反演，这可能需要在 V100 GPU 上花费一个小时。这对于许多希望快速生成图像的用户来说可能不切实际。
- en: So I investigated it and found a solution that can enable diffusers to use a
    textual inversion just like in Stable Diffusion WebUI. Below is the function I
    created to load a custom Textual Inversion.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我进行了调查并找到了一个解决方案，使扩散器能够像在 Stable Diffusion WebUI 中一样使用文本反演。以下是我创建的用于加载自定义文本反演的函数。
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the `load_textual_inversion()` function, you need to provide the following
    arguments:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `load_textual_inversion()` 函数中，你需要提供以下参数：
- en: '`learned_embeds_path`: Path to the pre-trained textual inversion model file
    in .pt or .bin format.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learned_embeds_path`：预训练文本反演模型文件的路径，格式为 .pt 或 .bin。'
- en: '`text_encoder`: Text encoder object obtained from the Diffusion Pipeline.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`：从扩散管道获得的文本编码器对象。'
- en: '`tokenizer`: Tokenizer object obtained from the Diffusion Pipeline.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`：从扩散管道获得的分词器对象。'
- en: '`token`: Optional argument specifying the prompt token. By default, it is set
    to None. it is the keyword that will trigger the textual inversion in your prompt'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`：可选参数，指定提示词令牌。默认设置为 None。它是会在提示中触发文本反演的关键词。'
- en: '`weight`: Optional argument specifying the weight of the textual inversion.
    By default, I set it to 0.5\. you can change to other value as needed.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight`: 可选参数，指定文本反演的权重。默认情况下，我将其设置为0.5，你可以根据需要更改为其他值。'
- en: 'You can now use the function with a diffusers pipeline like this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以使用类似这样的diffusers管道功能：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here is the result of applying an [Empire Style](https://civitai.com/models/2032/empire-style)
    Textual Inversion.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是应用[帝国风格](https://civitai.com/models/2032/empire-style)文本反演的结果。
- en: '![](../Images/f2f7296d2aa833114ac96d08f3556338.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2f7296d2aa833114ac96d08f3556338.png)'
- en: The left’s modern street turns to an old London style.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 左边的现代街道变成了旧伦敦风格。
- en: 6\. Upscale Images
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 放大图像
- en: Diffusers package is great for generating high-quality images, but image upscaling
    is not its primary function. However, the Stable-Diffusion-WebUI offers a feature
    called HighRes, which allows users to upscale their generated images to 2x or
    4x. It would be great if Diffusers users could enjoy the same feature. After some
    research and testing, I found that the SwinRI model is an excellent option for
    image upscaling, and it can easily upscale images to 2x or 4x after they are generated.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Diffusers包非常适合生成高质量图像，但图像放大不是其主要功能。然而，Stable-Diffusion-WebUI提供了一个名为HighRes的功能，允许用户将生成的图像放大到2倍或4倍。如果Diffusers用户也能享受相同的功能，那就太好了。经过一些研究和测试，我发现SwinRI模型是图像放大的优秀选择，可以轻松将图像放大到2倍或4倍。
- en: To use the SwinRI model for image upscaling, we can use the code from the GitHub
    repository of [JingyunLiang/SwinIR](https://github.com/JingyunLiang/SwinIR). If
    you just want codes, downloading `models/network_swinir.py`, `utils/util_calculate_psnr_ssim.py`
    and `main_test_swinir.py` is enough. Following the readme guideline, you can upscale
    images like magic.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用SwinRI模型进行图像放大，我们可以使用[JingyunLiang/SwinIR](https://github.com/JingyunLiang/SwinIR)的GitHub存储库中的代码。如果你只需要代码，下载`models/network_swinir.py`，`utils/util_calculate_psnr_ssim.py`和`main_test_swinir.py`即可。按照readme指南，你可以像魔法一样放大图像。
- en: Here is a sample of how well SwinRI can scale up an image.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是SwinRI如何出色放大图像的一个示例。
- en: '![](../Images/b977daec46ca853876ed6c25563a0159.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b977daec46ca853876ed6c25563a0159.png)'
- en: 'Left: original image, Right: 4x SwinRI upscaled image'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧：原始图像，右侧：4倍SwinRI放大图像
- en: Many other open-source solutions can be used to improve image quality. Here
    list three other models that I tried that return wonderful results.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 许多其他开源解决方案可以用来改善图像质量。这里列出了我尝试过的另外三种返回优秀结果的模型。
- en: '**RealSR**: [https://github.com/jixiaozhong/RealSR](https://github.com/jixiaozhong/RealSR)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RealSR**: [https://github.com/jixiaozhong/RealSR](https://github.com/jixiaozhong/RealSR)'
- en: RealSR can scale up an image 4 times almost as good as SwinRI, and its execution
    performance is the fastest, instead of invoking PyTorch and CUDA. The author compiles
    the code and CUDA usage to binary directly. My observations reveal that the RealSR
    can upscale a mage in about just 2–4 seconds.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: RealSR可以将图像放大4倍，几乎与SwinRI一样好，并且执行性能最快，不需要调用PyTorch和CUDA。作者将代码和CUDA使用直接编译为二进制文件。我的观察发现，RealSR可以在大约2–4秒内放大图像。
- en: '**CodeFormer**: [https://github.com/sczhou/CodeFormer](https://github.com/sczhou/CodeFormer)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CodeFormer**: [https://github.com/sczhou/CodeFormer](https://github.com/sczhou/CodeFormer)'
- en: CodeFormer is good at restoring blurred or broken faces, it can also remove
    noise and enhance background details. This solution and algorithm is widely used
    in other applications, including Stable-Diffusion-WebUI
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: CodeFormer擅长修复模糊或破损的面孔，它还可以去除噪声和增强背景细节。这种解决方案和算法在其他应用中也得到了广泛使用，包括Stable-Diffusion-WebUI。
- en: '**GFPGAN:** [https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GFPGAN:** [https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)'
- en: Another powerful open-source solution that archives amazing results of face
    restoration, and it is fast too. GFPGAN is also integrated into Stable-Diffusion-WebUI.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个强大的开源解决方案，能够实现惊人的面部修复效果，而且速度也很快。GFPGAN还集成到了Stable-Diffusion-WebUI中。
- en: '[Updated by April 19, 2023]'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[更新于2023年4月19日]'
- en: Found that the SD 1.5 and all extended models can’t handle well with generating
    a high-resolution image by simply using the text2img pipeline. In practice, I
    found that the Diffusers text2img pipeline will easily generate twisted and broken
    images even at 1920x1080, the same settings and prompt can generate good images
    at 800x600.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 发现SD 1.5及所有扩展模型在仅使用text2img管道生成高分辨率图像时效果不好。在实践中，我发现Diffusers text2img管道即使在1920x1080下也会容易生成扭曲和破损的图像，相同的设置和提示可以在800x600下生成良好的图像。
- en: 'I found Diffusers’ img2img pipeline can function as a great image high-resolution
    fix solution. here are the overall steps to implement img2img pipeline as an image
    high-resolution fix solution:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现 Diffusers 的 img2img 流程可以作为一个很好的图像高分辨率修复解决方案。以下是将 img2img 流程作为图像高分辨率修复解决方案的总体步骤：
- en: Generate a low-resolution image using the text2img pipeline
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 text2img 流程生成低分辨率图像
- en: Upsize the image to whatever resolution you want (max size depends on your VRAM
    size). `img = img.resize((width,height))` . The test shows that my 8G VRAM RTX
    3070 Ti can handle upscaling a 800x600 3 times to 2400x1800\. Note that at this
    step, no image upscaling or fixing happening, just upsize the image to the size
    you want.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像放大到你想要的分辨率（最大尺寸取决于你的 VRAM 大小）。`img = img.resize((width,height))` 。测试显示我的
    8G VRAM RTX 3070 Ti 能处理将 800x600 放大 3 倍到 2400x1800。在这一步骤中，请注意没有图像放大或修复，只是将图像放大到你想要的尺寸。
- en: 'Then feed the new manually upsized `img` to the img2img pipeline with the same
    prompt, negative prompt, and additional setting: `strength` into the call, you
    will see the input get upscaled like magic.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后将新的手动放大 `img` 以相同的提示、负面提示和额外设置 `strength` 传递到 img2img 流程中，你会看到输入像魔法一样被放大。
- en: The img2img will slightly change the image content, take a face as an example,
    it will not only upscale the image and somewhat change the face a little bit.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: img2img 会稍微改变图像内容，以面部为例，它不仅会放大图像，还会稍微改变面部。
- en: '![](../Images/7527d699ce47ca6f85c6b30f975efb7e.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7527d699ce47ca6f85c6b30f975efb7e.png)'
- en: Face HighRes upscale using Diffuses img2img pipeline, image generated by the
    author
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Diffuses img2img 流程进行面部高分辨率放大，图像由作者生成
- en: 7\. Optimize Diffusers CUDA Memory Usage
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 优化 Diffusers CUDA 内存使用
- en: 'When using Diffusers to generate images, it’s important to consider the CUDA
    memory usage, especially when you want to load other models to further process
    the generated images. If you try to load another model like SwinIR to upscale
    images, you might encounter a `RuntimeError: CUDA out of memory` due to the Diffuser
    model still occupying the CUDA memory.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '使用 Diffusers 生成图像时，重要的是要考虑 CUDA 内存使用，特别是当你想加载其他模型来进一步处理生成的图像时。如果你尝试加载另一个模型如
    SwinIR 以放大图像，你可能会遇到 `RuntimeError: CUDA out of memory`，因为 Diffuser 模型仍然占用 CUDA
    内存。'
- en: 'To mitigate this issue, there are several solutions to optimize CUDA memory
    usage. The following two solutions I found work the best:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解这个问题，有几种解决方案可以优化 CUDA 内存使用。我发现以下两种解决方案效果最好：
- en: Sliced Attention for Additional Memory Savings
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 切片注意力用于额外的内存节省
- en: Sliced attention is a technique that reduces the memory usage of self-attention
    mechanisms in transformers. By partitioning the attention matrix into smaller
    blocks, the memory requirements are reduced. This technique can be used with the
    Diffusers package to reduce the memory footprint of the Diffuser model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 切片注意力是一种减少变换器中自注意力机制内存使用的技术。通过将注意力矩阵分割成较小的块，减少了内存需求。这种技术可以与 Diffusers 包一起使用，以减少
    Diffuser 模型的内存占用。
- en: 'To use it in Diffusers, simply one line code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Diffusers 中使用它，只需一行代码：
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Model offloading to CPU
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型转移到 CPU
- en: Usually, you won’t have two models running at the same time, the idea is to
    offload the model data to the CPU memory temporarily and free up CUA memory space
    for other models, and only load up to VRAM when you start using the model.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你不会同时运行两个模型，目的是将模型数据暂时转移到 CPU 内存中，释放 CUDA 内存空间给其他模型，只有在开始使用模型时才加载到 VRAM 中。
- en: 'To use dynamically offload data to CPU memory in Diffusers, use this line code:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Diffusers 中动态将数据转移到 CPU 内存中，请使用以下代码：
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: After applying this, whenever Diffusers finish the image generation task, the
    model data will be offloaded to CPU memory automatically until the next time calling.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 应用此方法后，每当 Diffusers 完成图像生成任务时，模型数据将自动转移到 CPU 内存中，直到下一次调用。
- en: For more performance and VRAM optimization for Diffusers with PyTorch 2.0, please
    check out this article I wrote up as a supplement to this article.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更多关于 PyTorch 2.0 的 Diffusers 性能和 VRAM 优化的信息，请查看我写的这篇文章，作为对本文的补充。
- en: '[](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
    [## Performance Testing Note of Diffusers With PyTorch 2.0'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
    [## 使用 PyTorch 2.0 进行扩散模型性能测试笔记'
- en: Test various methods to boost Stable Diffusion package Diffusers' performance
    and lower VRAM usage
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试各种方法以提升 Stable Diffusion 包 Diffusers 的性能并降低 VRAM 使用
- en: betterprogramming.pub](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[betterprogramming.pub](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)'
- en: Summary
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: The article discusses how to improve the performance and capabilities of the
    Diffusers package, The article covers several solutions to common issues faced
    by Diffusers users, including loading local `.safetensor` models, boosting performance,
    removing the 77 prompt tokens limitation, using custom LoRA and Textual Inversion,
    upscaling images, and optimizing CUDA memory usage.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 文章讨论了如何提升Diffusers包的性能和功能，涵盖了Diffusers用户面临的几个常见问题的解决方案，包括加载本地`.safetensor`模型、提升性能、移除77个提示令牌限制、使用自定义LoRA和Textual
    Inversion、图像放大和优化CUDA内存使用。
- en: By applying these solutions, Diffusers users can generate high-quality images
    with better performance and more control over the process. The article also includes
    code snippets and detailed explanations for each solution.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用这些解决方案，Diffusers用户可以生成高质量的图像，具有更好的性能和更多的过程控制。文章还包括每个解决方案的代码片段和详细解释。
- en: If you can successfully apply these solutions and code in your case, there could
    be an additional benefit, which I benefit a lot, is that you may implement your
    own solutions by reading the Diffusers source code and understand better how Stable
    Diffusion works. To me, learning, finding, and implementing these solutions is
    a fun journey. Hope these solutions can also help you and wish you enjoy with
    Stable Diffusion and diffusers package.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能成功应用这些解决方案和代码，可能会有额外的好处，我受益匪浅，你可以通过阅读Diffusers源代码实现你自己的解决方案，更好地理解Stable
    Diffusion的工作原理。对我来说，学习、发现和实施这些解决方案是一段有趣的旅程。希望这些解决方案也能帮助你，并希望你在使用Stable Diffusion和diffusers包时感到愉快。
- en: 'Here provide the prompt that generates the heading image:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供生成标题图像的提示：
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Size: **600 * 800**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 尺寸：**600 * 800**
- en: 'Seed: **3977059881**'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 种子：**3977059881**
- en: 'Scheduler (or Sampling method): **DPMSolverMultistepScheduler**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器（或采样方法）：**DPMSolverMultistepScheduler**
- en: 'Sampling steps: **25**'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 采样步骤：**25**
- en: 'CFG Scale (or Guidance Scale): **7.5** SwinRI model: **003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: CFG规模（或指导尺度）：**7.5** SwinRI模型：**003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth**
- en: License and Code Reuse
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 许可证和代码重用
- en: The solutions provided in this article were achieved through extensive source
    reading, later night testing, and logical design. It is important to note that
    at the time of writing (April 2023), loading LoRA and Textual Inversion solutions
    and code included in this article are the only working versions across the internet.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 文章中提供的解决方案是通过广泛的源代码阅读、深夜测试和逻辑设计实现的。需要注意的是，在撰写本文时（2023年4月），加载LoRA和Textual Inversion解决方案和代码是互联网上唯一有效的版本。
- en: If you find the code presented in this article useful and want to reuse it in
    your project, paper, or article, please reference back to this Medium article.
    The code presented here is licensed under the MIT license, which permits you to
    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
    of the software, subject to the conditions of the license.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现本文中展示的代码有用，并希望在你的项目、论文或文章中重用，请参考这篇Medium文章。这里展示的代码遵循MIT许可证，这允许你在遵守许可证条款的条件下，使用、复制、修改、合并、发布、分发、再许可和/或出售软件的副本。
- en: Please note that the solutions presented in this article may not be the optimal
    or most efficient way to achieve the desired results, and are subject to change
    as new developments and improvements are made. It is always recommended to thoroughly
    test and validate any code before implementing it in a production environment.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，本文中提出的解决方案可能不是实现期望结果的最佳或最有效的方法，随着新发展和改进，可能会有所变化。始终建议在将任何代码应用于生产环境之前，彻底测试和验证代码。
- en: 'Book: Using Stable Diffusion with Python'
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 书籍：使用Python的Stable Diffusion
- en: The article provided a glimpse into the potential of Stable Diffusion controlling
    using Python. Delving deeper into this interdisciplinary field requires a comprehensive
    guide that not only explains the theory but also demonstrates practical applications
    through Python programming.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 文章提供了对使用Python控制Stable Diffusion潜力的初步了解。深入探讨这个跨学科领域需要一个全面的指南，不仅解释理论，还通过Python编程展示实际应用。
- en: Thus, I am thrilled to announce the release of my book, “[Using Stable Diffusion
    with Python](https://www.amazon.com/Using-Stable-Diffusion-Python-Generation/dp/1835086373).”
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我很高兴地宣布我的书籍“[用 Python 使用稳定扩散](https://www.amazon.com/Using-Stable-Diffusion-Python-Generation/dp/1835086373)”的发布。
- en: '![](../Images/d86f8ba31c642e1d9042ef8d70ed379f.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d86f8ba31c642e1d9042ef8d70ed379f.png)'
- en: Using Stable Diffusion with Python
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 用 Python 使用稳定扩散
- en: This book is a culmination of the latest research, experimentation, and dedication
    to making complex AI concepts accessible to everyone (using Python). Whether you
    are a beginner programmer intrigued by the power of Python, a seasoned engineer
    looking to expand your toolkit, or a scientist eager to delve into mathematical
    modeling, this book is designed to cater to your needs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是最新研究、实验和致力于使复杂的 AI 概念对所有人（使用 Python）可及的终极成果。不论你是对 Python 强大功能感兴趣的初学者程序员、寻求扩展工具包的经验工程师，还是渴望深入数学建模的科学家，本书都旨在满足你的需求。
- en: Within its pages, you will find detailed explanations of the mathematical foundations
    of Stable Diffusion, coupled with clear, step-by-step tutorials on how to use
    these models withPython. From setting up your Python environment to running the
    Diffusion models, visualizing results, every aspect is covered with meticulous
    attention to detail.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在书中，你将找到稳定扩散的数学基础的详细解释，以及如何使用这些模型与 Python 的清晰逐步教程。从设置 Python 环境到运行扩散模型、可视化结果，每一个方面都以细致的注意力进行覆盖。
- en: I hope you like it.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢它。
- en: References
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[diffusers github repository](https://github.com/huggingface/diffusers)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[diffusers github 仓库](https://github.com/huggingface/diffusers)'
- en: '[Issue: Overcoming the 77 token limit in diffusers](https://github.com/huggingface/diffusers/issues/2136)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问题：克服 diffusers 中的 77 个 token 限制](https://github.com/huggingface/diffusers/issues/2136)'
- en: '[Diffusers memory and speed](https://huggingface.co/docs/diffusers/optimization/fp16)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Diffusers 内存和速度](https://huggingface.co/docs/diffusers/optimization/fp16)'
- en: '[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)'
- en: '[Deliberate model download](https://civitai.com/models/4823/deliberate)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[刻意模型下载](https://civitai.com/models/4823/deliberate)'
