- en: ChatGPT — Handle With Care
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chat-gpt3-handle-with-care-8b6634781608](https://towardsdatascience.com/chat-gpt3-handle-with-care-8b6634781608)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Behind the Hype — Understanding what ChatGPT can do and what it cannot do, is
    critical to make the most of the technology. A recent research paper from the
    Center of Artificial Intelligence Research of Hong Kong University weights the
    limits and strengths of the OpenAi algorithm.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://misclassified.medium.com/?source=post_page-----8b6634781608--------------------------------)[![Giovanni
    Bruner](../Images/95283ba8cd3e700cdcb592975c501c47.png)](https://misclassified.medium.com/?source=post_page-----8b6634781608--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8b6634781608--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8b6634781608--------------------------------)
    [Giovanni Bruner](https://misclassified.medium.com/?source=post_page-----8b6634781608--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8b6634781608--------------------------------)
    ·6 min read·Mar 13, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ffc519eec3fa34c4ea5ccb1ca9d769bb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: Photo by [Possessed Photography](https://unsplash.com/@possessedphotography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'First, it came the language model. The intuition was easy: the next word in
    a sequence of words can be modeled with a probability distribution and is heavily
    dependent on the previous words. Words are part of a vocabulary, a limited corpus
    (170,000 tokens in the English vocabulary). Each word has a limited amount of
    meanings. A sequence of words, following a slow-changing, inner set of metadata:
    a grammar. Which is a predictable structure. You can expect a verb to be followed
    by a noun and not by another verb. Grammar and Meaning, act as constraints to
    limit the amount of randomness in the next word prediction. Which is arguably
    an easier task than predicting the next day''s share price value of a thousand
    companies. Plus, language models are by nature auto-regressive, the next word
    prediction depends on the previous words, and there are not that many latent,
    unobservable, variables to account for.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: For all those reasons language models are amenable to pre-trained models and
    **transfer learning**. The key feature unlocking the new AI revolution. Transfer
    Learning means that you can use a model pre-trained by somebody else, say on 20
    GB of Wikipedia articles, without having to retrain it with your own data, just
    by making a few adjustments to fit to your problem.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: How is that possible? Well, your language problem is unlikely to require the
    use of grammar and a vocabulary that is completely different from what you can
    find on Wikipedia. Transfer learning started a new AI summer just when people
    started arguing about a second AI winter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained models became larger and faster, with performance improving alongside
    the increase in the number of parameters and the amount of data used. It was empirically
    found that the performance of language models would scale when the size of those
    models increased. Up to an upper bound of computational power to be accounted
    for. Computer chips are as capable as they get. Something had to happen for language
    models to keep growing. A way to efficiently parallelize training across many
    machines is a no-nonsense way. The advent of Transformers.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d6f7b0f4625c887b78cb0cf6d929582d.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: Photo by [Aditya Vyas](https://unsplash.com/@aditya1702?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: The Transformers Language Models, released by a Google Brain team, nailed an
    impressive series of ingenious improvements to traditional language sequence models.
    The crux of it was an extensive usage of Multi Head Self-Attention and a model
    architecture designed to run on several concurrent GPUs. The Attention Mechanism
    massively improves the task of predicting the next word in a language model, spreading
    information from all the words in a sequence in a more efficient way than traditional
    recurrent neural networks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Transformers allowed the pre-training of large, very large, language models.
    That went from the 1.5 Billion parameters of GPT 2, released in 2019 to the 175
    Billion parameters of GPT3 in 2020\. Paving the way to the phenomenal release
    of ChatGPT in 2022 and the era of Large Language Models (LLM)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT excels at many things, but beware of hallucinations.
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This was a rather long introduction, but important to put things in context.
    Language models are not black magic, nor Artificial Generic Intelligence. They
    will not overtake humanity any time soon. They are incredibly useful tools, excelling
    at predicting the next word in a sequence. As with any tool invented by humans,
    they can cause damage if we don’t read the manual and the fine print.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Words are limited and have a limited set of meanings, they come together in
    a predictable way, following a grammar structure. However, information, which
    is how meanings combine, is not finite and is not necessarily predictable. Large
    Language Models like ChatGPT can create new information, completely made up. Which
    in turn generates new narratives of unchecked facts. They have a parametric memory,
    with no access to an external knowledge base. We have seen that they are good
    at probabilities, but they don’t have an inner mechanism to tell a truth from
    a lie. In a few words, they can hallucinate.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Check out below. Here I’m asking ChatGPT about myself, pretending to be a famous
    Data Scientist.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/57af5cbc1bdab36c6b3ebe9cb7aaf809.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT gets it right. Possibly I’m famous to my mom, but no more than that.
    But then I get offended and I completely make up extra information about myself.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/71f18f6a68766699eb6b9f439b8f8ab1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: Image by the Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Of course, I’m not a Kaggle Grandmaster (I wish I was), yet the AI apologizes
    to me.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The sudden popularity of ChatGPT is unprecedented in this field, thanks to an
    interface to interact with, retaining accumulated knowledge. The dialog interface
    uses Reinforcement Learning with Human Feedback (RCHF). Problem is that the accumulated
    knowledge may be grounded on follow-up questions and corrections that are blatantly
    untrue.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Yejin Bang, Pascale Fung, and their team of PHDs released a few weeks ago an
    extensive framework to quantitatively evaluate models such as ChatGPT on publicly
    available sets. As a Zero-Shot learner — a model that can answer any question
    without being explicitly fine-tuned for that task — ChatGPT results as State of
    The Art on the majority of tasks. With big improvements in question answering,
    sentiment analysis, and misinformation detection.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5cc89a7d05f863ef5f43b25544e463a.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: 'Image from paper: [https://arxiv.org/pdf/2302.04023.pdf](https://arxiv.org/pdf/2302.04023.pdf)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to reasoning, by far one of the most debated features, researchers
    found that ChatGPT is very good at deductive reasoning and very bad at inductive
    reasoning and at solving Math problems.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Deductive reasoning takes you from general premises to a specific conclusion
    and works well when the premises have enough information to anchor you to the
    solution. The algorithm was found to have superior performance in those reasoning
    tasks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/000b77ef38e431bf1ea48196cca9645d.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: 'The image was taken from Pascale Fung Youtube Video: [https://www.youtube.com/watch?v=ORoTJZcLXek](https://www.youtube.com/watch?v=ORoTJZcLXek)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Induction is the inverse process. It’s about drawing information from data to
    infer a general conclusion. Whilst deductive thinking is the intellectual process
    you follow when you have to test a theory, inductive thinking is what takes you
    to frame a theory. In other words, you can expect ChatGPT to come up with some
    sample data given a lot of detailed premises, but don’t expect it to come up with
    a generalized rule given some sample data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: In practice, ChatGPT is not capable (at the moment) to draw an idea of the world,
    the same way a human would do.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Yejin Bang at all**, A Multitask, Multilingual, Multimodal Evaluation of
    ChatGPT on Reasoning, Hallucination, and Interactivity, [https://arxiv.org/pdf/2302.04023.pdf](https://arxiv.org/pdf/2302.04023.pdf)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '**Pascale Fung,** ChatGPT: What It Can and Cannot Do by Prof. Pascale Fung,
    [https://www.youtube.com/watch?v=ORoTJZcLXek](https://www.youtube.com/watch?v=ORoTJZcLXek)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: A**shish Vaswani at all**, Attention is All You Need, [https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**阿希什·瓦斯瓦尼**等人，注意力机制就是你所需要的，[https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf)'
