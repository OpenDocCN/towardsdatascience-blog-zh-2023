["```py\n!pip install cmake\n!pip install dlib\n!pip install deepface\n```", "```py\n!pip install dlib\n!pip install deepface\n```", "```py\nfrom deepface import DeepFace\n```", "```py\nimage1 = 'Keanu_Reeves_(crop_and_levels)_(cropped).jpg'\n```", "```py\nimage2 = 'Reuni√£o_com_o_ator_norte-americano_Keanu_Reeves_(46806576944)_(cropped).jpg'\n```", "```py\nimage3 = 'Jet_Li_2009_(cropped).jpg'\n```", "```py\nimage4 = 'Denzel_Washington_2018.jpg'\n```", "```py\nimage5 = 'Smiling_girl.jpg'\n```", "```py\nDeepFace.verify(img1_path = image1,  # Keanu Reeves\n                img2_path = image2)  # Keanu Reeves\n```", "```py\n{'verified': True,\n 'distance': 0.17842618501190277,\n 'threshold': 0.4,\n 'model': 'VGG-Face',\n 'detector_backend': 'opencv',\n 'similarity_metric': 'cosine',\n 'facial_areas': {'img1': {'x': 42, 'y': 61, 'w': 144, 'h': 144},\n  'img2': {'x': 73, 'y': 57, 'w': 103, 'h': 103}},\n 'time': 0.27}\n```", "```py\nDeepFace.verify(img1_path = image1,   # Keanu Reeves\n                img2_path = image3)   # Jet Li\n```", "```py\n{'verified': False,\n 'distance': 0.4034869302977028,\n 'threshold': 0.4,\n 'model': 'VGG-Face',\n 'detector_backend': 'opencv',\n 'similarity_metric': 'cosine',\n 'facial_areas': {'img1': {'x': 42, 'y': 61, 'w': 144, 'h': 144},\n  'img2': {'x': 20, 'y': 49, 'w': 164, 'h': 164}},\n 'time': 0.27}\n```", "```py\nembeddings = DeepFace.represent(img_path = image1)  # Keanu Reeves\nembeddings\n```", "```py\n[{'embedding': [0.00948819238692522,\n   -0.010876820422708988,\n   -0.0013923903461545706,\n   0.01534500066190958,\n   ...\n   -0.014694824814796448,\n   -0.015208861790597439,\n   0.005312952678650618,\n   ...],\n  'facial_area': {'x': 42, 'y': 61, 'w': 144, 'h': 144}}]\n```", "```py\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\n\nim = Image.open(image1)\nfig, ax = plt.subplots()\n\n# display the image\nax.imshow(im)\n\n# draw a rectangle around the face\nface_coord = embeddings[0]['facial_area']\nrect = patches.Rectangle((face_coord['x'], face_coord['y']), \n                         face_coord['w'], face_coord['h'], \n                         linewidth = 2, \n                         edgecolor = 'r', \n                         facecolor = 'none')\n\n# add the patch to the axes\nax.add_patch(rect)\n```", "```py\nDeepFace.find(img_path = image1,    # the image to compare against\n              db_path = \"Faces\",    # folder containing all the images\n              enforce_detection = False)[0]\n```", "```py\nDeepFace.analyze(img_path = image4, \n                 actions = [\"age\", \"gender\", \"emotion\", \"race\"])\n```", "```py\n[{'age': 35,\n  'region': {'x': 31, 'y': 46, 'w': 117, 'h': 117},\n  'gender': {'Woman': 0.015357557276729494, 'Man': 99.98464584350586},\n  'dominant_gender': 'Man',\n  'emotion': {'angry': 0.3038950626725033,\n   'disgust': 3.667220231060474e-11,\n   'fear': 2.3939014472247897,\n   'happy': 1.2440780556642484e-05,\n   'sad': 87.49081939349405,\n   'surprise': 6.846103949403675e-05,\n   'neutral': 9.81130493418037},\n  'dominant_emotion': 'sad',\n  'race': {'asian': 7.334453304675418,\n   'indian': 3.1661530981155095,\n   'black': 85.50387534522267,\n   'white': 0.09932484836949994,\n   'middle eastern': 0.03912873741168454,\n   'latino hispanic': 3.8570622418559934},\n  'dominant_race': 'black'}]\n```", "```py\nDeepFace.analyze(img_path = image5, \n                 actions = [\"age\", \"gender\", \"emotion\", \"race\"])\n```", "```py\n[{'age': 26,\n  'region': {'x': 377, 'y': 140, 'w': 558, 'h': 558},\n  'gender': {'Woman': 99.66641068458557, 'Man': 0.3335847519338131},\n  'dominant_gender': 'Woman',\n  'emotion': {'angry': 1.31229280062393e-10,\n   'disgust': 2.1887400676449618e-26,\n   'fear': 3.8267408134914985e-22,\n   'happy': 99.99999403953517,\n   'sad': 2.6514247764822096e-14,\n   'surprise': 2.245952144279152e-17,\n   'neutral': 6.961274993922523e-06},\n  'dominant_emotion': 'happy',\n  'race': {'asian': 3.0054475969609733,\n   'indian': 4.536693711482729,\n   'black': 0.7851633247927815,\n   'white': 41.17996289491211,\n   'middle eastern': 23.323961892600284,\n   'latino hispanic': 27.168768902870287},\n  'dominant_race': 'white'}]\n```", "```py\nmodels = [\"VGG-Face\", \"Facenet\", \"OpenFace\", \"DeepFace\", \"ArcFace\"]\nDeepFace.verify(image1, \n                image2, \n                model_name = models[1])  # change to Facenet\n```", "```py\nembeddings = DeepFace.represent(img_path = image1,\n                                model_name = models[1])\n```", "```py\nDeepFace.find(img_path = image1, \n              db_path = \"Faces\",\n              model_name = models[1],\n              enforce_detection = False)[0]\n```"]