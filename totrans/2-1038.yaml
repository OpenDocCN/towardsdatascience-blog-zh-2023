- en: Healthcare Data Is Inherently Biased
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/healthcare-is-inherently-biased-b60bf00d4af7](https://towardsdatascience.com/healthcare-is-inherently-biased-b60bf00d4af7)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here’s how to not get duped by it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://stefanygoradia.medium.com/?source=post_page-----b60bf00d4af7--------------------------------)[![Stefany
    Goradia](../Images/dfbf98c4fd0d277ebb6b0f77ad64ead4.png)](https://stefanygoradia.medium.com/?source=post_page-----b60bf00d4af7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b60bf00d4af7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b60bf00d4af7--------------------------------)
    [Stefany Goradia](https://stefanygoradia.medium.com/?source=post_page-----b60bf00d4af7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b60bf00d4af7--------------------------------)
    ·10 min read·Jan 19, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Normally when you think of bias, you might think about a person’s beliefs that
    inadvertently shape their assumptions and approach. This is certainly one definition.
  prefs: []
  type: TYPE_NORMAL
- en: But bias also refers to how the very data we use for insights can be unsuspectingly
    skewed and incomplete, distorting the lens through which we see everything.
  prefs: []
  type: TYPE_NORMAL
- en: M**any — if not most —** of the datasets we use in healthcare are inherently
    biased and could easily lead us astray if we aren’t careful.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I’ll specifically focus on three major concepts afflicting healthcare data and
    that may even be low-key invalidating your entire analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86ebe2d55d0a27995076b8973336255d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kaleb Nimz](https://unsplash.com/@kalebnimz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'In an earlier [article](https://medium.com/towards-data-science/is-healthcare-analytics-right-for-you-320897b34409),
    I wrote about the types of bias I’ve encountered in my healthcare analytics career
    and how they are a challenge for data practitioners in the field. The biggest
    themes for me being: **personal bias, data bias, and confirmation bias.**'
  prefs: []
  type: TYPE_NORMAL
- en: Four days after I published that article, a mentor sent me [this JAMA article
    about sampling bias in healthcare claims data and how it is exacerbated by social
    determinants of health (SDOH) in certain regions](https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2800118).
  prefs: []
  type: TYPE_NORMAL
- en: 'The article’s conclusion really stood out to me:'
  prefs: []
  type: TYPE_NORMAL
- en: '[The study highlights] the importance of investigating sampling heterogeneity
    of large health care claims data to evaluate how sampling bias might compromise
    the accuracy and generalizability of results.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Importantly, investigating these biases or accurately reweighting the data will
    require data external data sources outside of the claims database itself.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'TLDR:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Imbalance of patients or members represented in large healthcare datasets
    can make your results non-generalizable or (in some cases) flat out invalid.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**SDOH data could help.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s unpack this.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'But first, a quote from the brilliant Cassie Kozyrkov: *“the AI bias trouble
    starts — but doesn’t end — with definition. ‘Bias’ is an overloaded term which
    means remarkably different things in different contexts.”* Read more about it
    in her article with lots of other breadcrumbs to related articles, “[What is bias?](/what-is-ai-bias-6606a3bcb814)”'
  prefs: []
  type: TYPE_NORMAL
- en: 'As healthcare analysts, we need to be on the lookout for:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**1\. Sampling/Selection Bias.**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Sampling bias** is *when some members of a population are systematically
    more likely to be selected in a sample than others.* **Selection bias** *can be
    introduced via the methods used to select the [study]* [*population*](https://www.scribbr.com/methodology/population-vs-sample/)
    *of interest, the* [*sampling methods*](https://www.scribbr.com/methodology/sampling-methods/)*,
    or the recruitment of participants (aka, flawed design in how you select what
    you’re including). [*[*1*](https://www.scribbr.com/research-bias/sampling-bias/)*]*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I’m using the terms somewhat colloquially. The definition of Sampling/Selection
    bias makes sense in the traditional survey/sample/research design.
  prefs: []
  type: TYPE_NORMAL
- en: '**But.. red flag #1: “Population” means something VERY specific in data, and
    equally as specific (but different) in healthcare, and they might be the same
    or they might not, depending on the thing.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In the context of healthcare, they can refer to how construct our analyses
    and our inclusions/exclusions to understand a certain “population.” In healthcare,
    we use populations of interest to refer to many different groups of interest depending
    on the study, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Lines of business (LOB) such as patients with coverage from a government payer
    (Medicaid, Medicare); commercial lines (employer groups, retail or purchased via
    the exchange); self-insured (self-funded groups, usually large employers paying
    for their own healthcare claims of employees), etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sub-lines of business, or groups. For instance, Medicaid may consist of multiple
    sub-groups representing different levels of eligibility, coverage, benefits, or
    types of people/why they qualified for the program ([Temporary Assistance for
    Needy Families (TANF)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&cd=&cad=rja&uact=8&ved=2ahUKEwjZm4Xy-Mf8AhWIhIkEHUzVBaIQFnoECBQQAQ&url=https%3A%2F%2Fwww.acf.hhs.gov%2Fofa%2Fprograms%2Ftemporary-assistance-needy-families-tanf&usg=AOvVaw38iikaX9W0oCb2UgotU2hA)
    vs. Medicaid expansion for adults)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demographics (certain groups, males or females, certain regions, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditions (examining certain chronic conditions, top disease states of interest
    or those driving the highest costs to the system, those that Medicare focuses
    on, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sub-groups of some combination of the above, for instance: Medicaid, TANF,
    looking at mothers vs. newborns'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cross-group comparison of some combination of the above, for instance: Medicaid,
    TANF, new mothers and their cost/utilization/outcomes trends vs. Commercial, self-insured,
    new mothers and their cost/utilization/outcomes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any sub- or cross-combination of the above, plus a lot more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, design of the analysis and the “population” in question can
    get complex very quickly. This doesn’t necessarily mean that the data is not usable
    or that results will always be dicey. It does reaffirm that being aware of this
    kind of bias is paramount to ensuring you’re considering all angles and analyzing
    accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Flag #2: If someone in healthcare says the data contains the entire population
    of interest… does it, really? Maybe...**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**A slight caveat for health insurers:** one common talking point is that a
    health insurer can analyze their “entire population” because they receive claims
    for every member in their charge, and they can avoid sampling fallacies. This
    could *potentially* be a sound talking point, depending on the use case. But in
    general, I’ll caution you to remember that even that data is inherently biased
    because it: a) only includes any members/patients who actually *had* an incident/event
    for which the insurer processed a subsequent claim and b) the data itself tends
    to over/underrepresent certain groups who are more likely to have chronic health
    problems, adverse social determinants of health, seek care, be reflective of the
    type of demographics your organization tends to serve or that you have a larger
    book of business in, etc. More on that with the article summary, below.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. U*ndercoverage Bias***'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '***Undercoverage bias*** *occurs when a part of the population is excluded
    from your sample.* *[*[*1*](https://www.scribbr.com/research-bias/undercoverage-bias/)*]*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Again, this definition make sense in the traditional survey/sample/research
    design. In the context of healthcare, it can bite us in a tangible way (wasted
    money, wasted effort, shame, having no impact or change in outcomes, *or…* all
    of the above) if we are not careful.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from the purest definition above, I also think about this in the context
    of not being able to see anything that happens “outside of your four walls.” We
    (generally) only have access to the data our organization has generated, which
    inherently is only part of the entire picture. This is not a deal breaker *depending*
    on what kind of analysis you’re doing and why, but another major flag to be aware
    of. Our [patients / members / employees / residents / etc.] may not act similarly
    or even represent [all patients / other groups / other types of employer s / other
    regions / etc.]
  prefs: []
  type: TYPE_NORMAL
- en: '**Flag #3: your data only shows what your organization has done internally,
    so it cannot always be used to infer what your competitors’ truths might look
    like, what your communities’ truths might look like, what happens to patients
    when they visit a different healthcare provider that is not you, or if any one
    health plan member’s behavior is anything like another member’s based on personal,
    regional, societal, occupational, or behavioral differences (data we usually do
    not have), to name a few. All of this must be considered as you’re seeking conclusions.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As more healthcare organizations are shifting focus to make a broader difference
    in the **communities** they serve more holistically (versus on their specific
    **patients**), we might be missing a whole ’lotta pieces of the data puzzle—again,
    data that tells us what is happening “outside our four walls.”
  prefs: []
  type: TYPE_NORMAL
- en: All this said, some of our analyses may not be so reliant on knowing that, per
    se. Some of this could be addressed by augmenting our own internal data with external
    data from outside our four walls to fill in more of the picture. Some of us have
    recognized this for awhile and are working on data sharing/collaboration or tapping
    into additional feeds such as health information exchange (HIE) or purchased benchmark
    data to compare our own population to so we can understand how differently ours
    looks or acts. Bear in mind that those datasets may suffer from these same biases
    on a broader scale (see that [JAMA article](https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2800118),
    in fact), but all of these are great first steps towards at least understanding
    and recognizing any underlying “gotchas.”
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Historical Bias or Systemic biases.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Historical bias** occurs when socio-cultural prejudices and beliefs are mirrored
    into systematic processes [that are then reflected in the data]. *[3]* **Systemic
    biases** result from institutions operating in ways that disadvantage certain
    groups. *[2]*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This becomes particularly challenging when data from historically-biased sources
    are used for data science models or analyses. It is also particularly important
    when you’re analyzing historically broken systems, such as healthcare.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is such a hot topic that NIST is developing an [AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework).
    NIST talks about human and systemic biases in their special publication, [*Towards
    a Standard for Identifying and Managing Bias in Artificial Intelligence*](https://doi.org/10.6028/NIST.SP.1270),
    which is where this image hails from:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/161ded9e6c1445fd88eaf5fa99948e07.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image credit: N. Hanacek/NIST (public domain).*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In healthcare, over-and-under-representation of certain diseases (or just sick
    people in general, because that’s who consumes healthcare), demographics, people
    of a certain group or sub-group, utilization patterns (or lack thereof), health/quality/mortality/engagement/satisfaction
    and many other trends or outcomes that we see in our healthcare data are all reflective
    of the way in which the broken healthcare system operates. This is a highly nuanced
    topic with a lot of different facets, to be explored in more depth in a later
    article. But suffice it to say:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Flag #4: The healthcare system is broken and existing societal constructs greatly
    impact health and outcomes, opportunities (or lack thereof), barriers, and behaviors.
    This is irrefutably reflected in healthcare data in many different ways.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Cue the Health Equity initiatives.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How can SDOH data help?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part is not a slam dunk to address everything I’ve outlined, but I thought
    it was interesting enough to call out specifically as we are talking about Health
    Equity and SDOH more and more in health analytics lately.
  prefs: []
  type: TYPE_NORMAL
- en: The [JAMA article](https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2800118)’s
    authors sought to understand potential bias in large, commercially-available databases
    comprised of aggregate claims from multiple commercial insurers. These kinds of
    datasets are commonly used by organizations for clinical research, competitive
    intelligence, and even benchmarking. The authors analyzed one common such set
    — the [Optum Clinformatics Data Mart (CDM)](https://www.optum.com/content/dam/optum/resources/productSheets/Clinformatics_for_Data_Mart.pdf)
    — which is derived from several large commercial and Medicare Advantage health
    plans and licensed commercially for various use cases.
  prefs: []
  type: TYPE_NORMAL
- en: At a zip code level, the authors analyzed the representation of individuals
    in the CDM as compared to Census estimates and the SDOH variability seen for said
    zip codes. I will note that the datasets they’re using are from 2018; this is
    another major issue with most healthcare data you can get your hands on, but for
    another day.
  prefs: []
  type: TYPE_NORMAL
- en: 'The article finds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Even after adjusting for state-level variation, our fancy pants statistical
    methods] found that inclusion in CDM was associated with zip codes that had wealthier,
    older, more educated, and disproportionately White residents.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The socioeconomic and demographic features correlated with overrepresentation
    in claims data have also been shown to be effect modifiers across a diverse spectrum
    of health outcomes.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Importantly, investigating these biases or accurately reweighting the data will
    require data external data sources outside of the claims database itself.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**TLDR (again):**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**The claims data was disproportionately skewed towards representing more educated,
    affluent, and White** patients**.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**The specific SDOH factors impacting people at the zip code level (and sub-zip)
    have well-documented influence on differences in health outcomes.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Reweighting/normalizing the data requires additional data beyond just the
    claims.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Some might call that data “outside your four walls.”
  prefs: []
  type: TYPE_NORMAL
- en: So now what?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Your #1 goal: Awareness.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I’ve solely put forth these ideas as a guide for you to *start thinking* about
    any underlying “gotchas.” Start by asking yourself and others questions. Start
    thinking about it as you’re designing your next analysis. Start making sure you
    fully understand how and where the results will be used, what the intent is, and
    listing the risks upfront. Start understanding the different types of bias and
    how they might impact you. If you want to read about 29 other types of bias, further
    broken down into more subtypes, check out this helpful [**knowledge base article
    on Scribbr about research bias**](https://www.scribbr.com/category/research-bias/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Your #2 goal: Do not let this cause analysis paralysis.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While it is important to keep this top of mind, it is even more important that
    we don’t get so hung up on it that we get analysis paralysis. As analysts, **knowing
    the nuances and then deciding where to draw that line in the sand** will arguably
    be the hardest part of your job: deciding which insights are still valuable or
    meaningful *despite* these nuances, and when to lean in to (or away from?) the
    soundness of the conclusion, will be absolutely paramount to your success and
    your organization’s success.'
  prefs: []
  type: TYPE_NORMAL
- en: Most likely, the outcome will probably land somewhere in the middle, so it will
    is your goal to understand the nuances, communicate them clearly, and provide
    directionally appropriate guidance to the extent that you can while being a good
    steward against potential misinterpretation.
  prefs: []
  type: TYPE_NORMAL
- en: This article highlights a subset of biases that are not unique to healthcare,
    but are very unique in how they apply in healthcare.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What other types of bias have you encountered in your healthcare or analytics
    career?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Stefany Goradia](https://www.linkedin.com/in/stefanygoradia/) is VP of Health
    Lab at [RS21](https://rs21.io/), a data science company with a Health Lab devoted
    exclusively to healthcare + community.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: She has spent her career on the front lines of healthcare analytics and delivering
    value to internal and external customers. She writes about how to interpret healthcare
    data, communicate it to stakeholders, and use it to support informed decision
    making and execution.
  prefs: []
  type: TYPE_NORMAL
- en: '**Like health data and healthcare analytics?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Follow me on [**Medium**](https://medium.com/@stefanygoradia)and [**LinkedIn**](https://www.linkedin.com/in/stefanygoradia/)
  prefs: []
  type: TYPE_NORMAL
- en: '**Like my style?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Learn more about my background and passion for data at [**stefanygoradia.bio**](https://stefanygoradia.bio/)
  prefs: []
  type: TYPE_NORMAL
- en: 'Some other good reference articles about bias:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://www.scribbr.com/category/research-bias/?source=post_page-----b60bf00d4af7--------------------------------)
    [## [1] Types of Bias in Research | Definition & Examples'
  prefs: []
  type: TYPE_NORMAL
- en: Research bias results from any deviation from the truth, causing distorted results
    and wrong conclusions. Bias can…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.scribbr.com](https://www.scribbr.com/category/research-bias/?source=post_page-----b60bf00d4af7--------------------------------)
    [](https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights?source=post_page-----b60bf00d4af7--------------------------------)
    [## [2] There's More to AI Bias Than Biased Data, NIST Report Highlights
  prefs: []
  type: TYPE_NORMAL
- en: As a step toward improving our ability to identify and manage the harmful effects
    of bias in artificial intelligence…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.nist.gov](https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights?source=post_page-----b60bf00d4af7--------------------------------)
    [](https://www.metabase.com/blog/6-most-common-type-of-data-bias-in-data-analysis?source=post_page-----b60bf00d4af7--------------------------------)
    [## [3] The 6 most common types of bias when working with data
  prefs: []
  type: TYPE_NORMAL
- en: You’re trying to make a good decision, and decide to take a look at your data
    to help you make your call. You’ve got…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.metabase.com](https://www.metabase.com/blog/6-most-common-type-of-data-bias-in-data-analysis?source=post_page-----b60bf00d4af7--------------------------------)
    [](https://www.statice.ai/post/data-bias-types?source=post_page-----b60bf00d4af7--------------------------------)
    [## 8 types of data bias that can wreck your machine learning models - Statice
  prefs: []
  type: TYPE_NORMAL
- en: 'Biased data: chances are you know the term well. Maybe you''re the one who''s
    very skeptical about using data that is…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.statice.ai](https://www.statice.ai/post/data-bias-types?source=post_page-----b60bf00d4af7--------------------------------)
    [](https://kozyrkov.medium.com/data-inspired-5c78db3999b2?source=post_page-----b60bf00d4af7--------------------------------)
    [## ata-Driven? Think again
  prefs: []
  type: TYPE_NORMAL
- en: The psychological habit most people lack and why you can’t hope to use data
    to guide your actions effectively without…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: kozyrkov.medium.com](https://kozyrkov.medium.com/data-inspired-5c78db3999b2?source=post_page-----b60bf00d4af7--------------------------------)
    [](/overcoming-confirmation-bias-during-covid-19-51a64205eceb?source=post_page-----b60bf00d4af7--------------------------------)
    [## Overcoming confirmation bias during COVID-19
  prefs: []
  type: TYPE_NORMAL
- en: How your brain is messing with you during the pandemic and what you can do about
    it
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/overcoming-confirmation-bias-during-covid-19-51a64205eceb?source=post_page-----b60bf00d4af7--------------------------------)
    [](https://achonaonline.com/features/2020/11/ai-bias-causes-problems-for-underrepresented-groups/?source=post_page-----b60bf00d4af7--------------------------------)
    [## AI Bias Causes Problems for Underrepresented Groups
  prefs: []
  type: TYPE_NORMAL
- en: '"Whether many recognize it or not, bias is a pervasive aspect of human thoughts
    and experiences. However, what was once…'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: achonaonline.com](https://achonaonline.com/features/2020/11/ai-bias-causes-problems-for-underrepresented-groups/?source=post_page-----b60bf00d4af7--------------------------------)
  prefs: []
  type: TYPE_NORMAL
