- en: 'SHAP: Explain Any Machine Learning Model in Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SHAP：在 Python 中解释任何机器学习模型
- en: 原文：[https://towardsdatascience.com/shap-explain-any-machine-learning-model-in-python-72f0bea35f7c](https://towardsdatascience.com/shap-explain-any-machine-learning-model-in-python-72f0bea35f7c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/shap-explain-any-machine-learning-model-in-python-72f0bea35f7c](https://towardsdatascience.com/shap-explain-any-machine-learning-model-in-python-72f0bea35f7c)
- en: '![](../Images/4b8cc3946e79898437b4c129844a6099.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b8cc3946e79898437b4c129844a6099.png)'
- en: Photo by [Priscilla Du Preez](https://unsplash.com/@priscilladupreez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Priscilla Du Preez](https://unsplash.com/@priscilladupreez?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Your Comprehensive Guide to SHAP, TreeSHAP, and DeepSHAP
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 您的 SHAP、TreeSHAP 和 DeepSHAP 综合指南
- en: '[](https://louis-chan.medium.com/?source=post_page-----72f0bea35f7c--------------------------------)[![Louis
    Chan](../Images/6d8df9a478e929dd521059631f26e081.png)](https://louis-chan.medium.com/?source=post_page-----72f0bea35f7c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----72f0bea35f7c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----72f0bea35f7c--------------------------------)
    [Louis Chan](https://louis-chan.medium.com/?source=post_page-----72f0bea35f7c--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://louis-chan.medium.com/?source=post_page-----72f0bea35f7c--------------------------------)[![Louis
    Chan](../Images/6d8df9a478e929dd521059631f26e081.png)](https://louis-chan.medium.com/?source=post_page-----72f0bea35f7c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----72f0bea35f7c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----72f0bea35f7c--------------------------------)
    [Louis Chan](https://louis-chan.medium.com/?source=post_page-----72f0bea35f7c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----72f0bea35f7c--------------------------------)
    ·13 min read·Jan 11, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----72f0bea35f7c--------------------------------)
    ·阅读时间 13 分钟·2023年1月11日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动机
- en: Story Time!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 故事时间！
- en: Imagine you have trained a machine learning model to predict the default risk
    of mortgage applicants. All is good, and the performance is excellent too. But
    how does the model work? How does the model come to the predicted value?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你训练了一个机器学习模型来预测抵押贷款申请者的违约风险。一切都很好，性能也很出色。但模型是如何工作的？模型是如何得出预测值的？
- en: We stood there and said that the model considers several variables and the multi-dimensional
    relationship and pattern are too complex to be explained in plain words.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们站在那里说模型考虑了几个变量，而这些多维关系和模式复杂到用简单的语言无法解释。
- en: 'That’s where model explainability could save the day. Among the algorithms
    that can dissect machine learning models, SHAP is one of the more agnostic players
    in the field. In this blog, we will dive deep into the following items:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是模型可解释性可以拯救局面的地方。在可以剖析机器学习模型的算法中，SHAP 是该领域中较为中立的算法之一。在这篇博客中，我们将深入探讨以下内容：
- en: What are Shapley values?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 Shapley 值？
- en: How to calculate them?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何计算 Shapley 值？
- en: How to use it in Python?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Python 中使用它？
- en: How does SHAP support local and global explanability?
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP 如何支持局部和全局可解释性？
- en: What visualizations are available in the SHAP library?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP 库中有哪些可用的可视化？
- en: How do the common variants of SHAP work? — TreeSHAP & DeepSHAP
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP 的常见变体如何工作？— TreeSHAP 和 DeepSHAP
- en: How does LIME compare against SHAP?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME 与 SHAP 相比如何？
- en: Shapley Values
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Shapley 值
- en: '**Let’s Play a Game**'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**让我们玩个游戏**'
- en: When a team of eleven players goes on to win the World Cup, who is the most
    valuable player? Shapley value is a decomposition algorithm that objectively distributes
    the final result to a pool of factors. In explaining a machine learning model,
    Shapley values can be understood as the significance of individual input features’
    contribution to the model’s predicted values.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当一支由十一名球员组成的球队赢得世界杯时，谁是最有价值的球员？Shapley 值是一种分解算法，客观地将最终结果分配给一组因素。在解释机器学习模型时，Shapley
    值可以理解为单个输入特征对模型预测值的贡献程度。
- en: A Quick Example — How does Shapley value work?
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速示例 — Shapley 值是如何工作的？
- en: 'For simplicity’s sake, let’s say we have three attacking players, each with
    a different expected number of goals. We also know that these three players don’t
    always work well with each other, which means depending on the combination of
    the three players, the number of expected goals may be different:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，假设我们有三名进攻球员，每名球员有不同的预期进球数。我们还知道这三名球员并不总是相互配合良好，这意味着根据这三名球员的组合，预期进球数可能会有所不同：
- en: '![](../Images/b7a0ef8020c3dda0e8c4a0500369bb6d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7a0ef8020c3dda0e8c4a0500369bb6d.png)'
- en: Image by Author
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: As a baseline, we play none of these three players i.e. number of features **f**
    = 0 and the expected number of goals of the team will be 0.5\. Each of the arrow
    that goes down the matrice indicates a possible stepwise increment when including
    a new feature (or including a player in our case).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基准，我们不使用这三名球员，即特征数 **f** = 0，团队的预期进球数将是 0.5。每一个箭头向下的矩阵表示包含一个新特征（或在我们情况下是一个新球员）时可能的逐步增量。
- en: 'Following the idea of stepwise expansion of player set, that means we can compute
    the marginal change for each of the arrow. For example, when we move from playing
    none of the players (indicated with the empty set symbol ∅) to playing player
    1 only, the marginal change is:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循逐步扩展玩家集的思路，这意味着我们可以计算每一个箭头的边际变化。例如，当我们从不使用任何玩家（用空集符号 ∅ 表示）移动到仅使用玩家 1 时，边际变化是：
- en: '![](../Images/b3c017351d1df630bc3d7fc3c0972a96.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3c017351d1df630bc3d7fc3c0972a96.png)'
- en: Image by Author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'To obtain the overall contribution of Player 1 among all three players, we
    would have to repeat the same calculation for every scenario where a marginal
    contribution for Player 1 is possible:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得玩家 1 在所有三名玩家中的总体贡献，我们需要对每一个可能出现玩家 1 边际贡献的情景重复相同的计算：
- en: '![](../Images/f5c920c7c8a54aeedc0d499a97b903c3.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5c920c7c8a54aeedc0d499a97b903c3.png)'
- en: Image by Author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'With all the marginal changes, we then calculate the weights for them using
    the following formula:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过所有边际变化，我们可以使用以下公式计算它们的权重：
- en: '![](../Images/24eaa6281e74f24513e672fb12f5f0f7.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24eaa6281e74f24513e672fb12f5f0f7.png)'
- en: Image by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Or, to put it even simpler: it is just the reciprocal of the number of all
    edges pointing into the same row. That means:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，简单来说：这只是指向同一行的所有边的数量的倒数。这意味着：
- en: '![](../Images/3c971d8db5d2fa450580b35a98df399d.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c971d8db5d2fa450580b35a98df399d.png)'
- en: Image by Author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'With this, we can now calculate the SHAP value of Player 1 for the expected
    goals:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们现在可以计算玩家 1 的 SHAP 值，以获得预期进球数：
- en: '![](../Images/7ef883cc260650be2c53bbb5a33bf179.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ef883cc260650be2c53bbb5a33bf179.png)'
- en: Image by Author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Repeating for the other two players and we will have:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对另外两名玩家进行相同的操作，我们将得到：
- en: SHAP of Player 1 = -0.1133
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玩家 1 的 SHAP = -0.1133
- en: SHAP of Player 2 = -0.0233
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玩家 2 的 SHAP = -0.0233
- en: SHAP of Player 3 = +0.4666
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玩家 3 的 SHAP = +0.4666
- en: If I were the head coach, I would have only played Player 3 in this case.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我是主教练，我在这种情况下只会使用玩家 3。
- en: This is very similar to another operator called Choquet Integral for those of
    you who are math-savvier.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这与另一种操作符 Choquet Integral 非常相似，对于那些数学更精通的朋友。
- en: Computational Complexity
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算复杂度
- en: With the above example of only 3 features, we would need to consider 8 different
    models, each with a different input feature set to explain all the features fully.
    In fact, for a full feature set of ***N*** features, the total number of subsets
    would be ***2^N***. Hence, we should be careful with the expected run time when
    using SHAP to explain machine learning models trained with a tall and, more importantly,
    wide dataset.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以上述仅有 3 个特征的例子为例，我们需要考虑 8 个不同的模型，每个模型有不同的输入特征集，以全面解释所有特征。事实上，对于一个完整的***N***特征集，总子集的数量将是***2^N***。因此，在使用
    SHAP 解释训练有大量且更重要的是宽数据集的机器学习模型时，我们需要注意预期的运行时间。
- en: In the following sections, we will first dive into how we can use SHAP in Python
    before diverting most of our attention to different variants of SHAP that aim
    at tackling the complexity of SHAP either with approximation techniques or techniques
    that are model topology specific.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将首先深入探讨如何在 Python 中使用 SHAP，然后将大部分注意力转向 SHAP 的不同变体，这些变体旨在通过近似技术或针对模型拓扑特定的技术来应对
    SHAP 的复杂性。
- en: '![](../Images/8d69685bb2e9b910bf9a717de10d7121.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d69685bb2e9b910bf9a717de10d7121.png)'
- en: Pascal Triangle — Image from [Wikipedia](https://commons.wikimedia.org/wiki/File:Pascal_triangle.svg)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Pascal 三角形 — 图片来源于 [维基百科](https://commons.wikimedia.org/wiki/File:Pascal_triangle.svg)
- en: SHAP in Python
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 中的 SHAP
- en: Next, let’s look at how to use SHAP in Python
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探讨如何在 Python 中使用 SHAP。
- en: SHAP (**SH**apley **A**dditive ex**P**lanations) is a python library compatible
    with most machine learning model topologies. Installing it is as simple as `pip
    install shap`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP (**SH**apley **A**dditive ex**P**lanations) 是一个兼容大多数机器学习模型拓扑的 Python 库。安装非常简单，只需
    `pip install shap`。
- en: SHAP provides two ways of explaining a machine learning model — global and local
    explainability.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 提供了两种解释机器学习模型的方法——全局解释和本地解释。
- en: '**Local Explainability with SHAP**'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**使用 SHAP 进行本地可解释性**'
- en: Local explainability attempts to explain the driving forces behind a specific
    prediction. In SHAP, that’s what the individual Shapley values are used for, as
    illustrated in the quick example in an earlier section.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本地可解释性试图解释特定预测背后的驱动因素。在 SHAP 中，个体 Shapley 值就是用来做这个的，如早期部分的快速示例所示。
- en: 'In SHAP’s arsenal, two visualizations are implemented to explain individual
    predictions: waterfall graph and force graph. While the waterfall graph gives
    you a better understanding of a stepwise derivation to the prediction results,
    the force graph is designed to provide a sense of the relative strength of the
    features’ contribution to the deviations in prediction results.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SHAP 的工具集中，有两种可视化方法用于解释个体预测：瀑布图和力图。瀑布图让你更好地理解逐步推导预测结果的过程，而力图旨在提供特征对预测结果偏差的相对贡献强度。
- en: '**Note:** Both visualizations included an overall expected prediction value
    (or base value). That can be understood as the average model output across the
    training set.'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 两种可视化都包括了一个整体期望预测值（或基准值）。这可以理解为训练集上模型输出的平均值。'
- en: '**Waterfall Plot**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**瀑布图**'
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/aad08e9d4a8df18232c490a7f1dac70e.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aad08e9d4a8df18232c490a7f1dac70e.png)'
- en: Image from [SHAP GitHub page](https://github.com/slundberg/shap) (MIT license)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [SHAP GitHub 页面](https://github.com/slundberg/shap)（MIT 许可证）
- en: On the y-axis, you can find the feature’s name and value
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 y 轴上，你可以找到特征的名称和值。
- en: On the x-axis, you can find the base value `E[f(X)] = 22.533` that indicates
    the average predicted values across the training set
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 x 轴上，你可以找到基准值 `E[f(X)] = 22.533`，这表示训练集上的平均预测值。
- en: A red bar in this plot shows the feature’s positive contribution to the predicted
    value
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图中红色条形表示特征对预测值的正贡献。
- en: A blue bar in this plot shows the feature’s negative contribution to the predicted
    value
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图中蓝色条形表示特征对预测值的负贡献。
- en: The label on the bars indicates the deviation from the model’s base prediction
    value attributed to the parameter. For example, the AGE = 65.2 has marginally
    contributed +0.19 to the prediction’s deviation from the base value of 22.533
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条形上的标签表示归因于参数的模型基准预测值的偏差。例如，AGE = 65.2 对预测值的偏差从基准值 22.533 上贡献了 +0.19。
- en: The bars are in descending order of the absolute importance of its impact on
    the predicted value
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条形按其对预测值的绝对重要性降序排列。
- en: '**Force Plot**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**力图**'
- en: '[PRE1]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/a212dc9849b0b8279fc962f673c1312d.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a212dc9849b0b8279fc962f673c1312d.png)'
- en: Image from [SHAP GitHub page](https://github.com/slundberg/shap) (MIT license)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [SHAP GitHub 页面](https://github.com/slundberg/shap)（MIT 许可证）
- en: On the x-axis, you can find the base value. That indicates the approximate location
    of the average predicted values across the training set.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 x 轴上，你可以找到基准值。这表示训练集上平均预测值的大致位置。
- en: On the x-axis, you can also find the model output with a bolded numeral. That
    indicates the predicted value for this record.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 x 轴上，你还可以找到用粗体数字标记的模型输出。这表示该记录的预测值。
- en: At the bottom of the chart, you can find the feature’s name and value, labelled
    either in red or blue.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图表底部，你可以找到特征的名称和值，标记为红色或蓝色。
- en: All the red bars on the left of the model output are the features that have
    contributed positively to the prediction’s deviation from the base value. The
    names of the feature are at the bottom of the bars. The length of the bar indicates
    the features’ contributions.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有在模型输出左侧的红色条形是对预测偏离基准值有正面贡献的特征。特征的名称在条形的底部。条形的长度表示特征的贡献。
- en: All the blue bars on the right of the model output are the features that have
    contributed negatively to the prediction’s deviation from the base value. The
    names of the feature are at the bottom of the bars. The length of the bar indicates
    the features’ contributions.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型输出右侧的所有蓝色条形图表示对预测偏离基准值产生负面贡献的特征。特征的名称位于条形图底部。条形图的长度表示特征的贡献。
- en: '**Global Explainability with SHAP**'
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**SHAP 的全球可解释性**'
- en: Global explainability can be understood as understanding the overall importance
    of each feature in the model across the entire dataset and providing a general
    knowledge of the data and the underlying patterns. Due to the fuzziness in decomposing
    individual predictions’ contributions and aggregating across the data, there is
    more than one way to attempt global explainability. Examples include information
    gain, aggregated weights, permutation-based feature importance, and Shapley values.
    SHAP focuses on the last one, of course.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 全球可解释性可以理解为在整个数据集中理解每个特征的整体重要性，并提供对数据和潜在模式的一般了解。由于分解个体预测贡献和在数据中聚合的模糊性，尝试全球可解释性的方法不止一种。示例包括信息增益、汇总权重、基于置换的特征重要性和
    Shapley 值。SHAP 当然专注于最后一个。
- en: SHAP provides a visualization in which we can look into the average Shapley
    values of a feature across the dataset. Unlike other mechanisms that provide a
    measure of importance using statistically more complex interpretations, SHAP’s
    global explainability delivers an immediately understandable impact by allowing
    you to say that, on average, the feature relationship pushes the prediction value
    about 1.0 higher for data records with “Class 1” than data records with “Class
    0”.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 提供了一种可视化方法，我们可以查看特征在数据集中的平均 Shapley 值。与其他使用统计上更复杂解释来提供重要性度量的机制不同，SHAP 的全球可解释性通过让你能够说，平均而言，特征关系使得“Class
    1”数据记录的预测值比“Class 0”数据记录高约 1.0，从而提供了一个立即可理解的影响。
- en: '![](../Images/1fbd124497685590b241fb212c7024b0.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fbd124497685590b241fb212c7024b0.png)'
- en: Image from [SHAP GitHub page](https://github.com/slundberg/shap) (MIT license)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来自[SHAP GitHub 页面](https://github.com/slundberg/shap)（MIT 许可证）
- en: SHAP’s global explainability feature allows us to troubleshoot or investigate
    model bias. Taking the image above as an example, Age is generally a very significant
    feature. Could this be a sign that the model is biased towards specific age groups
    unnecessarily? Also, could one of the very important features be a potential data
    leak? All these questions allow us to improve the model before deploying a more
    responsible and robust machine-learning model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 的全球可解释性功能允许我们排查或调查模型偏差。以上面的图像为例，年龄通常是一个非常重要的特征。这是否可能表明模型对特定年龄组存在不必要的偏见？此外，一个非常重要的特征是否可能是潜在的数据泄露？所有这些问题都使我们在部署更负责任且强健的机器学习模型之前，能够改进模型。
- en: '**Note:** If you are interested in learning more about responsible AI, I have
    also written a piece on how we can approach that using 5 easy steps.'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 如果你有兴趣了解更多关于负责任的人工智能，我还写了一篇关于如何通过 5 个简单步骤来实现这一目标的文章。'
- en: '[](https://pub.towardsai.net/unlock-the-power-of-responsible-ai-5-steps-to-ensure-ethical-systems-a5aeeb5ff65c?source=post_page-----72f0bea35f7c--------------------------------)
    [## Unlock the Power of Responsible AI: 5 Steps to Ensure Ethical Systems'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 解锁负责任的人工智能：确保伦理系统的 5 个步骤](https://pub.towardsai.net/unlock-the-power-of-responsible-ai-5-steps-to-ensure-ethical-systems-a5aeeb5ff65c?source=post_page-----72f0bea35f7c--------------------------------)'
- en: 5 Steps for Building Responsible AI Systems
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负责任的人工智能系统的 5 个步骤
- en: pub.towardsai.net](https://pub.towardsai.net/unlock-the-power-of-responsible-ai-5-steps-to-ensure-ethical-systems-a5aeeb5ff65c?source=post_page-----72f0bea35f7c--------------------------------)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[pub.towardsai.net](https://pub.towardsai.net/unlock-the-power-of-responsible-ai-5-steps-to-ensure-ethical-systems-a5aeeb5ff65c?source=post_page-----72f0bea35f7c--------------------------------)'
- en: Another visualization that SHAP supports is a stacked version of the force graph
    in the local explainability section. By stacking the force charts, we can visualise
    the interactions between the model and the features that are given different input
    values. This gives us a clustering view based on Shapley values and provides us
    with perspectives on how the model sees the data. This can be very powerful for
    revising and validating hypotheses and underlying business logic. There might
    also be chances that you would find new ways of segregating your data after analysing
    all the Shapley values!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP支持的另一种可视化是局部可解释性部分的力图堆叠版本。通过堆叠力图，我们可以可视化模型与不同输入值的特征之间的交互。这为我们提供了基于Shapley值的聚类视图，并提供了模型如何看待数据的视角。这对修正和验证假设以及基础业务逻辑非常有用。在分析所有Shapley值后，你可能还会发现数据分割的新方法！
- en: '[PRE2]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/214a53d8c8a8380f90f009b863baac61.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/214a53d8c8a8380f90f009b863baac61.png)'
- en: Image from [SHAP GitHub page](https://github.com/slundberg/shap) (MIT license)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于[SHAP GitHub页面](https://github.com/slundberg/shap)（MIT许可证）
- en: Variations of SHAP
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SHAP的变体
- en: '**TreeSHAP**'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**TreeSHAP**'
- en: '**Pros:** Efficient and accurate algorithm for computing Shapley values of
    tree-based models.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优点：** 高效且准确的算法，用于计算基于树模型的Shapley值。'
- en: '**Cons:** Only applicable to tree-based models.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺点：** 仅适用于基于树的模型。'
- en: Unlike the original SHAP, TreeSHAP is tree-based machine learning model-specific.
    This means TreeSHAP will only work on models such as decision trees, random forests,
    gradient-boosting machines etc.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 与原始SHAP不同，TreeSHAP是特定于基于树的机器学习模型的。这意味着TreeSHAP仅适用于决策树、随机森林、梯度提升机等模型。
- en: TreeSHAP is specific to tree models because it takes advantage of the tree structures
    for computing accurate Shapley values more efficiently than SHAP. As these structures
    do not exist in other model topologies, TreeSHAP is only restricted to tree-based
    models.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: TreeSHAP特定于树模型，因为它利用树结构来更高效地计算准确的Shapley值。由于这些结构在其他模型拓扑中不存在，因此TreeSHAP仅限于基于树的模型。
- en: 'TreeSHAP can calculate Shapley values using interventional and tree path dependent
    approaches. This can be specified in the `feature_perturbation` parameter. The
    tree path dependent approach calculates the changes in conditional expectation
    recursively. Let’s use a simple decision tree that accepts 2 features **(x, y)**
    as an example:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: TreeSHAP可以通过干预和树路径依赖的方法计算Shapley值。这可以在`feature_perturbation`参数中指定。树路径依赖方法递归地计算条件期望的变化。我们以一个接受2个特征**(x,
    y)**的简单决策树为例：
- en: '![](../Images/b029f92e885c46074b756e3264103f3d.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b029f92e885c46074b756e3264103f3d.png)'
- en: Example Decision Tree — Image by Author
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 示例决策树 — 作者提供的图片
- en: 'In the example above, we have a decision tree that contains 7 nodes, accepts
    two features **(x, y)** to predict **z** and has been trained with **8** training
    samples. To compute the **local** contribution of **y** to the prediction of **z**
    in a coalition **(x=10, y=5)**, we need to consider the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，我们有一个包含7个节点的决策树，接受两个特征**(x, y)**来预测**z**，并且已经用**8**个训练样本进行了训练。为了计算在联盟**(x=10,
    y=5)**中**y**对**z**预测的**局部**贡献，我们需要考虑以下因素：
- en: For **(x=10, y=5)**, the model will go from Node 1 to Node 3 and reach Node
    6\. As Node 6 is a leaf node, the model is certain that the prediction is **z=4**.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于**(x=10, y=5)**，模型将从节点1移动到节点3并到达节点6。由于节点6是叶节点，模型确定预测为**z=4**。
- en: For **(x=10)**, the model will go from Node 1 to Node 3\. However, as Node 3
    is not a leave node, the expected predicted value can be inferred as a weighted
    sum of all the leaf nodes of Node 3\. Among the 5 training samples that went through
    Node 3, two are predicted to have **z=4** while the others are predicted to have
    **z=24**. The weighted sum is **4*(2/5) + 24*(3/5)=1.6 + 14.4 = 16**.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于**(x=10)**，模型将从节点1移动到节点3。然而，由于节点3不是叶节点，预测值可以推断为节点3所有叶节点的加权和。在通过节点3的5个训练样本中，有两个预测为**z=4**，而其他的预测为**z=24**。加权和为**4*(2/5)
    + 24*(3/5)=1.6 + 14.4 = 16**。
- en: The marginal contribution of **y** in the prediction of **z** for the coalition
    **(x=10, y=5)** can be calculated as **Prediction(x=10, y=5) — Prediction(x=10)
    = 4–16= -12**.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在联盟**(x=10, y=5)**中，**y**对**z**预测的边际贡献可以计算为**Prediction(x=10, y=5) — Prediction(x=10)
    = 4–16= -12**。
- en: '**Note:** The negative contribution here does not mean the feature **y** is
    unimportant, but rather that feature **y** has pushed the prediction value by
    **-12**.'
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 这里的负贡献并不意味着特征**y**不重要，而是特征**y**将预测值推高了**-12**。'
- en: By continuing the process across all the features, TreeSHAP will obtain all
    the Shapley values and provide both local explainability (using the method above)
    and global explainability (average out all the local explainability results across
    the training set)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对所有特征继续这一过程，TreeSHAP 将获得所有 Shapley 值，并提供局部可解释性（使用上述方法）和全局可解释性（对训练集中的所有局部可解释性结果进行平均）
- en: As its name suggests, the interventional approach calculates the Shapley values
    by artificially adjusting the value of the feature of interest. In our case above,
    that can be to change **y** from 5 to 4\. To estimate the sensitivity, TreeSHAP
    will need to repeatedly use a background set/training set as reference points
    (This will be touched on again when we discuss LIME in the final section) with
    linear runtime complexity. Hence, when using the interventional approach, we should
    be more mindful of the scalability of TreeSHAP.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，干预方法通过人为调整感兴趣特征的值来计算 Shapley 值。在我们上述的例子中，这可能是将**y**从 5 改为 4。为了估计敏感性，TreeSHAP
    需要反复使用背景集/训练集作为参考点（当我们在最后一节讨论 LIME 时会再次提到），其线性运行时间复杂度。因此，在使用干预方法时，我们应更加关注 TreeSHAP
    的可扩展性。
- en: '[PRE3]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**DeepSHAP**'
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**DeepSHAP**'
- en: '**Pros:** Efficient algorithm for approximating Shapley values of deep learning
    or neural network based models. Compatible with Tensorflow and PyTorch'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优点：** 高效的算法，用于近似深度学习或基于神经网络的模型的 Shapley 值。兼容 Tensorflow 和 PyTorch'
- en: '**Cons:** Only applicable to deep learning or neural network based models.
    Less accurate than SHAP due to the approximation nature of the algorithm'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺点：** 仅适用于深度学习或基于神经网络的模型。由于算法的近似特性，比 SHAP 的准确性低。'
- en: We can’t skip neural networks when discussing explainability. DeepSHAP is a
    combination of SHAP and DeepLIFT that aims at cracking the philosophy behind deep
    learning models. It is specifically designed for deep learning models, which makes
    DeepSHAP only applicable to neural network based models.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论可解释性时，我们不能忽视神经网络。DeepSHAP 是 SHAP 和 DeepLIFT 的结合，旨在揭示深度学习模型背后的哲学。它专为深度学习模型设计，这使得
    DeepSHAP 仅适用于基于神经网络的模型。
- en: DeepSHAP tries to approximate the Shapley values. A relatively primitive way
    of explaining DeepSHAP is that it attempts to assign local marginal contribution
    of feature **x** using gradients or partial derivatives with a meaningful background/reference
    point (e.g. pitch black for image recognition models, 0% for predicting one’s
    chance to get-rich-quick).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSHAP 试图近似 Shapley 值。解释 DeepSHAP 的一种相对原始的方法是，它试图通过使用梯度或偏导数来分配特征**x**的局部边际贡献，前提是使用一个有意义的背景/参考点（例如，图像识别模型的全黑背景，预测暴富机会的
    0%）。
- en: 'Note: There is a further research released on a generalised version of DeepSHAP
    — G-DeepSHAP. Feel free to give it a read here in [arxiv](https://arxiv.org/pdf/2105.00108.pdf).'
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：有进一步研究发布了 DeepSHAP 的通用版本——G-DeepSHAP。你可以在[arxiv](https://arxiv.org/pdf/2105.00108.pdf)阅读。
- en: '[PRE4]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: LIME — Alternative to SHAP
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LIME — SHAP 的替代方法
- en: LIME(Local Interpretable Model-Agnostic Explanations) is an alternative to SHAP
    for explaining predictions. It is a model-agnostic approach with a default assumption
    in kernel size (size of local neighbourhood considered when explaining individual
    prediction) for approximating a feature’s contribution to a local instance. In
    general, choosing a smaller kernel size, the results provided by LIME will lean
    towards local interpretation of how the values of the features have contributed
    to the prediction. (i.e. larger kernel size tends to provide a more global view)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: LIME（局部可解释模型无关解释）是解释预测的 SHAP 的替代方法。它是一种模型无关的方法，默认假设内核大小（解释个体预测时考虑的局部邻域的大小）来近似特征对局部实例的贡献。一般来说，选择较小的内核大小时，LIME
    提供的结果将更倾向于局部解释特征值对预测的贡献。（即，较大的内核大小往往提供更全局的视角）
- en: However, the choice of kernel size should be carefully decided dependent on
    the data and the pattern. Hence, when using LIME, we should consider adjusting
    the kernel size accordingly to obtain a reasonable interpretation of the machine
    learning model.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，内核大小的选择应根据数据和模式仔细决定。因此，在使用 LIME 时，我们应考虑相应地调整内核大小，以获得对机器学习模型的合理解释。
- en: 'To give it a try, we can install and use the package with:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试一下，我们可以安装并使用该软件包：
- en: '[PRE5]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Conclusion
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: 'As a final recap, here is a quick summary of everything discussed in this blog
    post:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后总结一下，这里是对本文讨论内容的简要总结：
- en: SHAP is a game theory based approach for explaining machine learning models
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP 是一种基于博弈论的方法，用于解释机器学习模型。
- en: SHAP considers all possible combinations of features to evaluate the impact
    of every feature
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP 考虑所有可能的特征组合以评估每个特征的影响。
- en: SHAP value of a feature **f** for a local prediction instance is a weighted
    sum of the marginal changes due to the inclusion of the feature across all the
    possible combination of features that includes **f**
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征 **f** 对于本地预测实例的 SHAP 值是由于特征的引入在包含 **f** 的所有可能特征组合中的边际变化的加权总和。
- en: The marginal changes are weighted according to the reciprocal of ***f* × *C(F,
    f)*** for ***F*** to be the number of features considered by the actual model
    and ***f*** to be the number of features considered when calculating the marginal
    changes
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边际变化的权重根据 ***f* × *C(F, f)*** 的倒数进行，其中 ***F*** 是实际模型考虑的特征数量，而 ***f*** 是计算边际变化时考虑的特征数量。
- en: As SHAP considers all possible combinations of features, hence the algorithm
    does not scale linearly and would suffer from the curse of dimensionality
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于 SHAP 考虑了所有可能的特征组合，因此算法不会线性扩展，会受到维度灾难的影响。
- en: 'Several variants of SHAP have been commonly used to address SHAP’s computational
    complexity:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了应对 SHAP 的计算复杂性，已经常用几种 SHAP 的变体：
- en: '![](../Images/a90b907281ededff895eaac6034aaa42.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a90b907281ededff895eaac6034aaa42.png)'
- en: Image by Author
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: We should consider using TreeSHAP for tree-based models and DeepSHAP for deep
    learning based models
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该考虑对基于树的模型使用 TreeSHAP，对基于深度学习的模型使用 DeepSHAP。
- en: LIME is an alternative to SHAP that is also model agnostic that approximates
    a feature’s contribution
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME 是一种替代 SHAP 的模型无关方法，用于近似特征的贡献。
- en: Explanation by LIME can be significantly different depending on the choice of
    kernel size
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME 的解释可以根据内核大小的选择显著不同。
- en: That’s about it for this comprehensive tour into SHAP. I hope you have found
    this helpful for pushing your content to the next level or getting started as
    a writer. If you have enjoyed the read, you can also support me by subscribing
    to Medium using my affiliate link below. This has been a platform where I have
    found lots of enjoyable reads. Even if you are perfectly content with not subscribing,
    you can also support me and my creation using claps.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 SHAP 的这次全面介绍就是这些了。我希望你发现这些内容对提升你的写作水平或开始写作有所帮助。如果你喜欢这篇文章，你也可以通过下面的我的附属链接订阅
    Medium 来支持我。这是一个我发现了很多有趣读物的平台。即使你完全不打算订阅，你也可以通过点“赞”来支持我和我的创作。
- en: '[](https://louis-chan.medium.com/membership?source=post_page-----72f0bea35f7c--------------------------------)
    [## Join Medium with my referral link — Louis Chan'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://louis-chan.medium.com/membership?source=post_page-----72f0bea35f7c--------------------------------)
    [## 通过我的推荐链接加入 Medium — Louis Chan'
- en: Read every story from Louis Chan (and thousands of other writers on Medium).
    Your membership fee directly supports…
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读 Louis Chan 的每一个故事（以及 Medium 上成千上万的其他作家的故事）。你的会员费直接支持…
- en: louis-chan.medium.com](https://louis-chan.medium.com/membership?source=post_page-----72f0bea35f7c--------------------------------)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: louis-chan.medium.com](https://louis-chan.medium.com/membership?source=post_page-----72f0bea35f7c--------------------------------)
- en: Last but definitely not least, if I have missed/mistaken anything critical,
    please feel free to drop a comment or send me a DM through LinkedIn. Let’s keep
    the knowledge flowing and get better at this domain together!
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但绝对不是最不重要的，如果我遗漏或误解了任何关键内容，请随时在评论中指出或通过 LinkedIn 给我发消息。让我们一起保持知识的流动，共同在这个领域中进步！
- en: '[](https://www.linkedin.com/in/louis-chan-b55b9287?source=post_page-----72f0bea35f7c--------------------------------)
    [## Louis Chan — Lead GCP Data & ML Engineer — Associate Director — KPMG UK |
    LinkedIn'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/louis-chan-b55b9287?source=post_page-----72f0bea35f7c--------------------------------)
    [## Louis Chan — 主任级 GCP 数据与 ML 工程师 — 副总监 — KPMG 英国 | LinkedIn'
- en: Ambitious, curious and creative individual with a strong belief in inter-connectivity
    between branches of knowledge and a…
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有抱负、好奇且富有创意的个人，坚信知识领域之间的相互联系。
- en: www.linkedin.com](https://www.linkedin.com/in/louis-chan-b55b9287?source=post_page-----72f0bea35f7c--------------------------------)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: www.linkedin.com](https://www.linkedin.com/in/louis-chan-b55b9287?source=post_page-----72f0bea35f7c--------------------------------)
- en: References
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Lundberg, Scott M., and Su-In Lee. “A Unified Approach to Interpreting Model
    Predictions.” Advances in Neural Information Processing Systems, 2017.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lundberg, Scott M., 和 Su-In Lee. “统一的模型预测解释方法。” 神经信息处理系统进展，2017。
- en: Lundberg, Scott, and Su-In Lee. “Consistent Individualized Feature Attribution
    for Tree Ensembles.” arXiv preprint arXiv:1802.03888, 2018.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lundberg, Scott, 和 Su-In Lee. “一致的个性化特征归因用于树集成。” arXiv 预印本 arXiv:1802.03888,
    2018.
- en: Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. “Why Should I Trust
    You? Explaining the Predictions of Any Classifier.” Proceedings of the 22nd ACM
    SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ribeiro, Marco Tulio, Sameer Singh, 和 Carlos Guestrin. “我为什么应该相信你？解释任何分类器的预测。”
    第22届 ACM SIGKDD 国际知识发现与数据挖掘大会论文集, 2016.
- en: 'Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. “Anchors: High-Precision
    Model-Agnostic Explanations.” arXiv preprint arXiv:1802.07814, 2018.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Ribeiro, Marco Tulio, Sameer Singh, 和 Carlos Guestrin. “Anchors: 高精度模型无关解释。”
    arXiv 预印本 arXiv:1802.07814, 2018.'
