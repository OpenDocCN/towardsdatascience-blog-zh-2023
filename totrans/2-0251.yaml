- en: Achieving Greater Self-Consistency in Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现大型语言模型的更大自我一致性
- en: 原文：[https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7](https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7](https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7)
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[![安东尼·阿尔卡拉斯](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)[![面向数据科学](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [安东尼·阿尔卡拉斯](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    ·8 min read·Dec 1, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    ·8分钟阅读·2023年12月1日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件用于增强本文文本的语法、流畅性和可读性。*'
- en: When LLMs are used to evaluate qualities like the correctness, accuracy, or
    relevance of a piece of text, consistency is paramount. If an LLM exhibits inconsistent
    judgements, then its evaluations become unreliable and untrustworthy.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM用于评估文本的正确性、准确性或相关性等质量时，一致性至关重要。如果LLM表现出不一致的判断，那么其评估就会变得不可靠和不可信。
- en: If an LLM evaluates the reasoning quality of arguments, but contradicts itself
    by rating an invalid argument as more logically sound than a perfectly valid one,
    then it fails as an arbiter of reason. Its evaluations lose credibility due to
    the model’s own lack of logical consistency.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果LLM评估论证的推理质量，但通过将无效的论证评为比完全有效的论证更有逻辑，从而自相矛盾，那么它就无法作为理性的仲裁者。由于模型自身缺乏逻辑一致性，其评估失去可信度。
- en: When such inconsistencies appear, there is no stable basis for comparison between
    the LLM’s assessments of different pieces of text. If the model arbitrarily contradicts
    itself, then sentences cannot be reliably ranked against one another based on
    the model’s inconsistent scorings.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当出现这种不一致性时，就没有稳定的基础来比较LLM对不同文本的评估。如果模型随意自相矛盾，那么句子无法根据模型的不一致评分可靠地排序。
- en: In essence, inconsistency destroys the grounds for comparison that evaluations
    aim to provide in the first place. If an LLM cannot demonstrate consistent application
    of assessment criteria, then using it to evaluate text loses all effectiveness
    and utility.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，不一致性破坏了评估旨在提供的比较基础。如果一个LLM不能展示一致的评估标准应用，那么使用它来评估文本就失去了所有的有效性和实用性。
- en: So, consistency in judgement and evaluation is mandatory for LLMs employed to
    score or judge textual qualities and features. Without a high level of stability
    in its assessments, grounded in a consistent understanding of concepts being evaluated,
    the basis for comparison falls apart when leveraging LLM output as a form of evaluation
    or scoring.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于被用于评分或评判文本质量和特征的LLM来说，一致性是必需的。如果评估没有高水平的稳定性，并且基于对被评估概念的一致理解，那么在将LLM输出作为评估或评分形式时，比较的基础就会崩溃。
- en: Sampling multiple solutions reveals consistency between outputs strongly correlates
    with quality. However, existing consistency techniques rely on extracting and
    matching closed-form answers, restricting their applicability. This article explores
    methods to enhance self-consistency without such constraints, while also grounding
    decisions in real-world knowledge.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 采样多个解决方案表明，输出之间的一致性与质量有很强的相关性。然而，现有的一致性技术依赖于提取和匹配封闭形式的答案，限制了其适用性。本文探讨了在没有这些限制的情况下提高自我一致性的方法，同时也将决策建立在现实世界知识上。
- en: '![](../Images/8f1bb2f51d372d80a08c389810cc3436.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f1bb2f51d372d80a08c389810cc3436.png)'
- en: Image by the author
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: '**The Need for Self-Consistency**'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**自洽性的需求**'
- en: Despite rapid progress, logical failures and falsehoods continue hindering reliable
    reasoning in state-of-the-art models. For complex multi-step analysis or free-form
    generation, models often contradict themselves or invent unsupported facts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了迅速的进展，逻辑失败和虚假信息仍然阻碍了最先进模型中的可靠推理。对于复杂的多步骤分析或自由形式生成，模型往往会自相矛盾或编造没有支持的事实。
- en: This manifests in two key ways — inconsistent open-ended generation, and incoherent
    inferences. When performing open-ended tasks, models generate conflicting outputs
    when sampled multiple times on the same input. Meanwhile for chained reasoning,
    models draw irrational conclusions that violate basic transitive properties.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这表现为两个关键方面——不一致的开放式生成和不连贯的推理。在执行开放式任务时，模型在同一输入上多次采样时生成冲突的输出。与此同时，对于链式推理，模型得出违反基本传递性质的非理性结论。
- en: For example, a model may determine A > B and B > C in a ranking comparison,
    but then inaccurately assess C > A, resulting in circular contradictions. Such
    failures to preserve transitive coherence fundamentally undermine reliability.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，模型可能在排名比较中确定A > B和B > C，但随后不准确地评估C > A，导致循环矛盾。这种未能保持传递一致性的问题从根本上削弱了可靠性。
- en: Techniques like self-consistency help address inconsistency by sampling multiple
    candidate solutions and selecting outputs that display consensus. The key insight
    is that consensus acts as an effective proxy measure for quality and coherence.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 像自洽性这样的技术通过采样多个候选解决方案并选择显示共识的输出来帮助解决不一致性。关键的见解是共识作为质量和连贯性的有效代理度量。
- en: However, existing self-consistency approaches rely on strict answer formats
    to allow extraction and comparison across responses. This significantly restricts
    their applicability to open-ended tasks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现有的自洽性方法依赖于严格的答案格式，以便在响应之间进行提取和比较。这大大限制了它们在开放式任务中的适用性。
- en: Advancing internal self-consistency requires a two-pronged approach. First,
    consistency techniques like USC eliminate format constraints to enable open-ended
    selection. Meanwhile, contrastive ranking methods enforce logical constraints
    on latent representations, ensuring models preserve ordering relationships during
    multi-step inference.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 提升内部自洽性需要双管齐下的方法。首先，一致性技术如USC消除了格式限制，允许开放式选择。同时，对比排序方法对潜在表示施加逻辑约束，确保模型在多步骤推理过程中保持顺序关系。
- en: However, solely enhancing internal consistency without grounding in structured
    external knowledge remains insufficient for accurate reasoning. Language models
    lack the dynamic updates, logical expressiveness, and empirical verifiability
    crucially needed to inform interpretations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅增强内部一致性而不依赖于结构化的外部知识仍不足以实现准确推理。语言模型缺乏动态更新、逻辑表达能力和经验验证，这些都是解释所需的关键因素。
- en: Advancing reliability therefore necessitates improving self-consistency across
    diverse tasks while integrating structured repositories of world knowledge. Consistency
    techniques should operate flexibly across free-form outputs, coupled with frameworks
    leveraging rich semantic representations to inform decisions with logic-driven,
    externally-verified facts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，提升可靠性需要在各种任务中提高自洽性，同时整合结构化的世界知识库。一致性技术应在自由形式输出中灵活运作，并结合利用丰富语义表示的框架，以逻辑驱动的、外部验证的事实来指导决策。
- en: This combination of model-internal consensus and structured external grounding
    complements strengths of each approach to replicate multifaceted human reasoning.
    Only their orchestration can overcome inherent limitations, incrementally advancing
    AI capabilities towards matching diverse and fluid cognition.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型内部共识与结构化外部基础的结合补充了每种方法的优势，以复制多方面的人类推理。只有它们的协同作用才能克服固有的局限性，逐步推进AI能力，以匹配多样且流动的认知。
- en: Introducing Universal Self-Consistency
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入通用自洽性
- en: '[](https://arxiv.org/abs/2311.17311?source=post_page-----6e6cb5f3c5b7--------------------------------#:~:text=Universal%20Self%2DConsistency%20for%20Large%20Language%20Model%20Generation,-Xinyun%20Chen%2C%20Renat&text=Self%2Dconsistency%20with%20chain%2Dof,large%20language%20models%20%28LLMs%29.)
    [## Universal Self-Consistency for Large Language Model Generation'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 通用自一致性用于大型语言模型生成](https://arxiv.org/abs/2311.17311?source=post_page-----6e6cb5f3c5b7--------------------------------#:~:text=Universal%20Self%2DConsistency%20for%20Large%20Language%20Model%20Generation,-Xinyun%20Chen%2C%20Renat&text=Self%2Dconsistency%20with%20chain%2Dof,large%20language%20models%20%28LLMs%29.)'
- en: Self-consistency with chain-of-thought prompting (CoT) has demonstrated remarkable
    performance gains on various…
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用链式思维提示（CoT）的自一致性在各种任务上表现出显著的性能提升……
- en: arxiv.org](https://arxiv.org/abs/2311.17311?source=post_page-----6e6cb5f3c5b7--------------------------------#:~:text=Universal%20Self%2DConsistency%20for%20Large%20Language%20Model%20Generation,-Xinyun%20Chen%2C%20Renat&text=Self%2Dconsistency%20with%20chain%2Dof,large%20language%20models%20%28LLMs%29.)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: arxiv.org](https://arxiv.org/abs/2311.17311?source=post_page-----6e6cb5f3c5b7--------------------------------#:~:text=Universal%20Self%2DConsistency%20for%20Large%20Language%20Model%20Generation,-Xinyun%20Chen%2C%20Renat&text=Self%2Dconsistency%20with%20chain%2Dof,large%20language%20models%20%28LLMs%29.)
- en: Chen 2023 et al. proposes Universal Self-Consistency (USC) to enable self-consistency
    without answer extraction across diverse applications. USC relies on the language
    model’s own capability to select the most consistent response from multiple candidate
    solutions it originally produced.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 陈2023等人提出了**通用自一致性**（USC），以在不同应用场景中实现自一致性，而无需从中提取答案。USC依赖于语言模型自身的能力，从其最初生成的多个候选解中选择最一致的回答。
- en: Specifically, USC concatenates all sampled responses into a context, then constructs
    a prompt asking the model to choose the one with highest consensus. Eliminating
    specialized aggregation logic, USC is applicable even to free-form generation
    tasks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，USC将所有采样的回答连接成一个上下文，然后构建一个提示，要求模型选择其中共识度最高的回答。通过消除专业的聚合逻辑，USC即使在自由形式生成任务中也适用。
- en: Experiments demonstrate USC matches performance of standard self-consistency
    on mathematical reasoning and code generation benchmarks which permit answer extraction.
    Crucially, USC also improves open-ended question answering, summarization, and
    creative writing where existing techniques falter.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 实验表明，USC在允许提取答案的数学推理和代码生成基准测试中的表现与标准自一致性相匹配。至关重要的是，USC还改善了开放式问答、总结和创意写作，这些领域现有技术存在不足。
- en: Augmenting Reasoning with External Knowledge
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过外部知识增强推理
- en: While USC offers framework-agnostic consistency, external knowledge remains
    vital for accurate and robust reasoning. Language models lack the dynamic updates,
    factual integrity, and logical expressiveness of curated knowledge repositories.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管USC提供了与框架无关的一致性，但外部知识对于准确和稳健的推理仍然至关重要。语言模型缺乏策划知识库的动态更新、事实完整性和逻辑表现力。
- en: Knowledge graphs allow incorporating empirically-grounded details and interlinked
    factual relations, enabling more consistent interpretation of situations per the
    latest information. They facilitate accessing contextual empirical evidence to
    substantiate decisions instead of relying solely on innate biases embedded in
    model weights.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱允许结合经验基础的细节和相互关联的事实关系，根据最新信息提供更一致的情境解读。它们有助于访问上下文的经验证据，以支持决策，而不是仅依赖于模型权重中嵌入的固有偏见。
- en: Additionally, knowledge graphs manage the evolution of facts over time, ensuring
    reasoning relies on the most up-to-date information. They also encapsulate domain
    logic to explicitly encode rules, constraints, and ontological taxonomies. This
    allows sound deductive reasoning undiscernible from model training data alone.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，知识图谱管理着事实随时间的演变，确保推理依赖于最新的信息。它们还封装了领域逻辑，以显式编码规则、约束和本体分类法。这使得合理的推理无法仅从模型训练数据中辨别。
- en: Empirically, retrieval-augmented generation using external knowledge graphs
    demonstrates more consistent output by grounding responses in verified facts rather
    than hallucinations. Parallel querying of knowledge graphs — even duplicate copies
    — further improves consistency by accumulating evidence from multiple perspectives.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 经验上，利用外部知识图谱的检索增强生成通过将回答建立在已验证的事实上而不是幻觉上，展示了更一致的输出。知识图谱的并行查询——即使是重复副本——通过从多个角度积累证据进一步提高了一致性。
- en: Orchestrating USC’s structured reasoning with a retrieval-augmented system leverages
    external knowledge to engender a modular hybrid architecture. USC contributes
    the reasoning “backbone” while parallel retrieval supplies relevant factual details
    from trustworthy knowledge repositories, enhancing interpretation consistency.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 USC 的结构化推理与检索增强系统的协调，可以利用外部知识来形成一个模块化的混合架构。USC 提供了推理的“骨干”，而并行检索则从可信的知识库中提供相关的事实细节，增强了解释的一致性。
- en: Augmenting Consistency with Seeded Sampling
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用种子采样增强一致性
- en: '[](https://github.com/openai/openai-cookbook/blob/main/examples/Deterministic_outputs_with_the_seed_parameter.ipynb?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [## openai-cookbook/examples/Deterministic_outputs_with_the_seed_parameter.ipynb
    at main ·…'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/openai/openai-cookbook/blob/main/examples/Deterministic_outputs_with_the_seed_parameter.ipynb?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [## openai-cookbook/examples/Deterministic_outputs_with_the_seed_parameter.ipynb
    在 main 分支下 ·…](https://github.com/openai/openai-cookbook/blob/main/examples/Deterministic_outputs_with_the_seed_parameter.ipynb?source=post_page-----6e6cb5f3c5b7--------------------------------)'
- en: Examples and guides for using the OpenAI API. Contribute to openai/openai-cookbook
    development by creating an account…
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 OpenAI API 的示例和指南。通过创建账户来贡献 openai/openai-cookbook 的开发…
- en: github.com](https://github.com/openai/openai-cookbook/blob/main/examples/Deterministic_outputs_with_the_seed_parameter.ipynb?source=post_page-----6e6cb5f3c5b7--------------------------------)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/openai/openai-cookbook/blob/main/examples/Deterministic_outputs_with_the_seed_parameter.ipynb?source=post_page-----6e6cb5f3c5b7--------------------------------)
- en: In open-ended generation tasks, consistency between solutions strongly correlates
    with quality. However, large language models exhibit inherent randomness that
    produces variation across outputs.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在开放式生成任务中，解决方案之间的一致性与质量强相关。然而，大型语言模型展示了固有的随机性，这会导致输出的变异。
- en: To mitigate this, OpenAI’s Chat Completions API provides a seed parameter that
    seeds the random number generator for deterministic sampling. Using the same seed
    and parameters will yield identical or very similar outputs each time.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解这一问题，OpenAI 的 Chat Completions API 提供了一个种子参数，该参数用于种子随机数生成器以进行确定性采样。使用相同的种子和参数，每次将产生相同或非常相似的输出。
- en: This allows combining Universal Self-Consistency, which has the model select
    the most consistent response from candidates, with seeded sampling to evaluate
    the exact same responses across requests.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得将通用自我一致性（Universal Self-Consistency），即模型从候选中选择最一致的响应，与种子采样结合起来，以在请求之间评估完全相同的响应成为可能。
- en: There remains a small chance of variation from non-determinism in computers.
    Additionally, changes to the system_fingerprint indicate backend updates affecting
    determinism across requests.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机中仍然存在因非确定性带来的微小变异机会。此外，对系统_fingerprint 的更改表示后端更新影响了请求的确定性。
- en: Besides seeding, factors like lower temperature and careful prompt engineering
    also reduce variability in model-generated text. Overall, seeded sampling lets
    us harness consistency for improved reliability.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 除了种子采样外，较低的温度和仔细的提示工程也能减少模型生成文本的变异性。总体而言，种子采样使我们能够利用一致性来提高可靠性。
- en: By choreographing seeded candidates with USC-based selection, we construct solutions
    methodically grounded in both external knowledge and sampling determinism. This
    manifests emergent capabilities surpassing individual techniques.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过与 USC 基于选择的种子候选进行编排，我们系统地构建了既基于外部知识又基于采样确定性的解决方案。这体现了超越单一技术的涌现能力。
- en: Contrastive-consistent ranking (CCR)
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对比一致性排名（CCR）
- en: While previous sections focus on classification and open-ended generation, consistency
    in rankings elicited from language models is also vital. Recent work explores
    contrast-consistent ranking (CCR), which adapts Contrast-Consistent Search (CCS)
    to impose logical constraints on mapping item representations to a consistent
    scale.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的部分侧重于分类和开放式生成，但从语言模型中引出的排名一致性也是至关重要的。最近的工作探索了对比一致排名（CCR），它适应了对比一致搜索（CCS）来对映射项目表示施加逻辑约束，以实现一致的尺度。
- en: CCR probes item vectors to find this consistent ranking direction without supervision.
    Experiments on prompting baselines and CCR variants demonstrate improved consistency
    and generalization.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: CCR 探测项目向量，以无监督的方式找到一致的排名方向。对提示基线和 CCR 变体的实验显示出改进的一致性和泛化能力。
- en: By extending consistency-based techniques like USC to rankings, CCR offers a
    way to limit unpredictability and align model outputs across diverse tasks. Both
    aim to improve reliability by selecting solutions or rankings judged internally
    coherent by the model itself.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将基于一致性的技术如 USC 扩展到排名，CCR 提供了一种限制不可预测性并使模型输出在多样任务中对齐的方法。两者都旨在通过选择模型自身认为内部一致的解决方案或排名来提高可靠性。
- en: '[](https://arxiv.org/abs/2309.06991?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [## Unsupervised Contrast-Consistent Ranking with Language Models'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arxiv.org/abs/2309.06991?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [## 无监督对比一致性排名与语言模型'
- en: Language models contain ranking-based knowledge and are powerful solvers of
    in-context ranking tasks. For instance…
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言模型包含基于排名的知识，并且是处理上下文排名任务的强大解决器。例如……
- en: arxiv.org](https://arxiv.org/abs/2309.06991?source=post_page-----6e6cb5f3c5b7--------------------------------)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: arxiv.org](https://arxiv.org/abs/2309.06991?source=post_page-----6e6cb5f3c5b7--------------------------------)
- en: CCR probing trains an additional “probe” model to find a latent ranking direction
    in the vector space of a fixed language model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: CCR 探测训练一个额外的“探测”模型，以在固定的语言模型的向量空间中找到潜在的排名方向。
- en: It does not directly prompt or finetune the language model itself.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不会直接提示或微调语言模型本身。
- en: The language model is used to simply generate vector representations of items
    through input prompts.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型仅用于通过输入提示生成项目的向量表示。
- en: These item vectors are then fed into the CCR probe, which is trained on an unsupervised
    loss function to map representations onto a consistent ranking scale.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些项目向量随后被输入到 CCR 探测器中，该探测器在无监督损失函数上进行训练，将表示映射到一致的排名尺度上。
- en: So in summary, CCR probing introduces an external probe model that wraps the
    language model to perform ranking in its vector space. The language model remains
    static. Only the additional probe model is trained with contrastive objectives
    to uncover inherent rankings.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，CCR 探测引入了一个外部探测模型，该模型将语言模型包装起来，以在其向量空间中进行排序。语言模型保持静态。只有额外的探测模型在对比目标下进行训练，以揭示内在的排名。
- en: Technical Architecture
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术架构
- en: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [## Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and…'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [## 在混乱上下文中通过思维线程提示和……实现结构化推理'
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with…
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）展现了令人印象深刻的少样本学习能力，能够快速适应新任务……
- en: towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----6e6cb5f3c5b7--------------------------------)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=post_page-----6e6cb5f3c5b7--------------------------------)
- en: We implement a RAG system accessing multiple knowledge graphs indexed with vector
    search for fast fact retrieval. Query engines interface the indexes and encapsulate
    passage search. Helper tools wrap engines, facilitating integration. Separate
    agents house tools, interfacing the LLM. A super-agent oversees tool coordination.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了一个 RAG 系统，通过向量搜索访问多个知识图以进行快速事实检索。查询引擎接口到索引，并封装段落搜索。辅助工具包装引擎，促进集成。独立代理负责工具的接口，与
    LLM 进行对接。超级代理负责工具协调。
- en: The system leverages Thread-of-Thought (ToT) prompting for structured reasoning
    over retrieved passages. ToT guides the model through step-wise analysis, enhancing
    understanding. Parallel asynchronous retrieval allows simultaneously querying
    all graphs, accelerating context accumulation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 系统利用思维线程（ToT）提示进行结构化推理，对检索的段落进行分析。ToT 指导模型通过逐步分析，增强理解。并行异步检索允许同时查询所有图，加速上下文积累。
- en: Multimodal knowledge graphs using diverse algorithms and embeddings provide
    varied perspectives. Personalized PageRank traversal supports flexible inference
    along indirect connections. Approximate nearest neighbor search enables efficient
    lookups. Embeddings enable analogical reasoning via vector arithmetic.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多种算法和嵌入的多模态知识图提供了不同的视角。个性化 PageRank 遍历支持沿间接连接进行灵活推理。近似最近邻搜索实现了高效的查找。嵌入通过向量运算实现类比推理。
- en: We implement a staged retrieval approach, first querying a domain ontology to
    establish basic concepts and terminology related to the question. Ontologies provide
    formal definitions and high-level relationships between entities, allowing grounded
    understanding before retrieving full knowledge graphs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实施了一种分阶段的检索方法，首先查询领域本体以建立与问题相关的基本概念和术语。本体提供了正式的定义和实体之间的高层次关系，在检索完整的知识图谱之前实现了基础理解。
- en: The ontology results are appended to the original question to provide context.
    This enhanced query is then used to retrieve passages from the multiple knowledge
    graphs. Seeding retrieval with ontology information primes the RAG system for
    more consistent and relevant passages tailored to the grounded aspects.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本体结果附加到原始问题中以提供背景。这个增强的查询随后用于从多个知识图谱中检索段落。通过本体信息种子检索，可以为RAG系统提供更一致和相关的段落，这些段落是针对具体基础方面量身定制的。
- en: This technique combines top-down hierarchical reasoning from the ontology with
    complementary bottom-up factual details from knowledge graphs. The ontology clarifies
    ambiguous or broad terminology, while knowledge graphs provide in-depth relational
    information on refined query focuses.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这一技术将本体的自上而下的层级推理与知识图谱中互补的自下而上的事实细节相结合。本体澄清了模糊或广泛的术语，而知识图谱提供了对细化查询焦点的深入关系信息。
- en: Choreographing different knowledge sources in this staged manner allows smoothly
    transitioning between levels of abstraction for reinforced consistency. Retrieval
    flows from high-level ontology concepts down to specific contextual passages pertinent
    for the question.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种分阶段的方式编排不同的知识来源，可以在抽象层次之间平滑过渡，增强一致性。检索从高层次的本体概念流向与问题相关的特定背景段落。
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Impact
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响
- en: Combining USC and RAG complements consistency-based thinking with grounding
    in external knowledge. USC contributes the reasoning structure while RAG expands
    information breadth. Together these offset LLM limitations to better replicate
    human cognition.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 结合USC和RAG将基于一致性的思维与外部知识的基础结合起来。USC提供了推理结构，而RAG扩展了信息的广度。这些结合起来弥补了LLM的局限性，更好地复制了人类认知。
- en: This orchestration also enhances accuracy, speed, and coverage. Retrieved facts
    fill knowledge gaps for sound decisions. Parallel knowledge access accelerates
    understanding. Different knowledge graphs broaden conceptual connections considered.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编排还提高了准确性、速度和覆盖范围。检索到的事实填补了知识空白，以做出合理的决策。并行知识访问加速了理解。不同的知识图谱拓宽了考虑的概念连接。
- en: Through modular augmentation, we gracefully scale emergent capabilities beyond
    inherent model aptitudes. As LLMs and knowledge bases mature, this composable
    paradigm will facilitate progressively advancing AI reasoning abilities.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模块化增强，我们优雅地扩展了新兴能力超越固有模型的适应性。随着LLM和知识库的发展，这种可组合的范式将促进AI推理能力的逐步提升。
