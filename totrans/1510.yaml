- en: 'Meta-Heuristics Explained: Ant Colony Optimization'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/meta-heuristics-explained-ant-colony-optimization-d016fe925108](https://towardsdatascience.com/meta-heuristics-explained-ant-colony-optimization-d016fe925108)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/ed465df790b8c3b0f8a86cb4e678961f.png)'
  prefs: []
  type: TYPE_IMG
- en: Ants following pheromone trails. Image created with Dall·E by the author.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to a lesser-known heuristic based on the behavior of ants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://hennie-de-harder.medium.com/?source=post_page-----d016fe925108--------------------------------)[![Hennie
    de Harder](../Images/3e4f2cccd6cb976ca3f8bf15597daea8.png)](https://hennie-de-harder.medium.com/?source=post_page-----d016fe925108--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d016fe925108--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d016fe925108--------------------------------)
    [Hennie de Harder](https://hennie-de-harder.medium.com/?source=post_page-----d016fe925108--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d016fe925108--------------------------------)
    ·7 min read·Sep 4, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '**In the world of optimization algorithms, there are a plethora of methods
    inspired by the wonders of the natural world. From genetic algorithms based on
    evolution to the cooling strategies of simulated annealing, these algorithms have
    demonstrated their efficacy in solving complex problems. However, nestled in this
    diverse landscape of nature-inspired algorithms lies a lesser-known gem — Ant
    Colony Optimization. We will explore this heuristic algorithm that draws inspiration
    from the ingenious foraging behaviors of ants.**'
  prefs: []
  type: TYPE_NORMAL
- en: Ant colony optimization (ACO) is a fun algorithm to play around with and the
    core is surprisingly simple. In this post, you will learn the basics and understand
    the main ideas behind the algorithm. In a following post, we will code the algorithm
    and use it to solve several real world problems. Let’s start!
  prefs: []
  type: TYPE_NORMAL
- en: Using Ants in Optimization Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you know by now, ACO is inspired by the behavior of ants. The algorithm mimics
    the way ants search for food and communicate with each other to find the shortest
    path between their nest and a food source. You can use the algorithm to find good
    paths through [graphs](/optimizing-connections-mathematical-optimization-within-graphs-7364e082a984)
    or for solving assignment type problems.
  prefs: []
  type: TYPE_NORMAL
- en: A population of artificial ants is used in ACO. They explore the solution space
    by constructing solutions step by step. Each ant builds a solution by selecting
    the next component based on a *probability distribution*. This probability distribution
    is influenced by *the quality of the components* (e.g. length of the path), and
    by *the pheromone trails left by other ants*. The pheromone trails represent a
    form of communication between ants, allowing them to follow paths that have been
    successful in the past.
  prefs: []
  type: TYPE_NORMAL
- en: At the beginning of the algorithm, the pheromone trail on each component is
    initialized to a small value. As the ants construct solutions, they deposit pheromone
    on the components they use. The amount of pheromone deposited is proportional
    to the quality of the solution. Components that are part of good solutions are
    reinforced with more pheromone, making them more attractive to other ants.
  prefs: []
  type: TYPE_NORMAL
- en: Over time, the pheromone trails on less attractive components evaporate, reducing
    their attractiveness and encouraging exploration of other parts of the solution
    space. In this way, the algorithm converges to a good solution by exploiting the
    most promising areas of the search space while also exploring new areas.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2ba5e7d2015b09f3d6f5fb7cd890a132.png)'
  prefs: []
  type: TYPE_IMG
- en: 'ACO visualized: ants start at their nest in the search for food. In the beginning
    they are exploring all trails, but soon they discover the fastest route and avoid
    long and dead end trails. Image by author.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Real world ants can get lost when they follow a pheromone trail, e.g.
    when the pheromone trail [is gone](https://www.youtube.com/watch?v=vsWsQLJAbMk)
    for some reason, or when by accident the trail is [a circle](https://www.youtube.com/watch?v=LEKwQxO4EZU).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hyperparameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Hyperparameters are used to control the behavior of the algorithm. Here are
    important hyperparameters of ACO:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of iterations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the number of times the ants construct solutions before the algorithm
    terminates. You can as well use other termination criteria, e.g. when the solution
    isn’t improved for a while, you can decide to stop running. Or you can set a time
    limit.
  prefs: []
  type: TYPE_NORMAL
- en: '**Number of ants**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The number of artificial ants used in every iteration of the algorithm. A larger
    number of ants can lead to better exploration of the search space, but will also
    increase the computational time.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pheromone evaporation rate (rho)**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This parameter controls the rate at which pheromone evaporates from the trails
    and takes a value between 0 and 1\. A higher decay rate can encourage more exploration
    of the search space, while a lower decay rate can lead to more exploitation of
    good solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Initial pheromone level (tau)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This value corresponds to the initial amount of pheromone on the trails. A higher
    initial pheromone level can encourage more exploitation of good solutions, while
    a lower initial pheromone level can encourage more exploration of the search space.
    You can use specific values for tau to create a warm start.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pheromone importance** **(alpha)**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alpha (≥ 0) determines the influence of the pheromone level (tau) in selecting
    the next component of the graph. If the value is higher, the algorithm is more
    reactive to changes in the search space, while a lower rate can help to prevent
    premature convergence.
  prefs: []
  type: TYPE_NORMAL
- en: Cost importance (beta)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Beta (≥ 0) is comparable with alpha. Instead of determining the influence of
    the pheromone level, it determines the influence of the cost (eta) for selecting
    the next graph component. More on this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of hyperparameters will depend on the specific problem and the available
    computational resources. It is necessary to experiment with different hyperparameter
    settings to find the best combination for a given problem.
  prefs: []
  type: TYPE_NORMAL
- en: Pseudocode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Below the pseudocode of the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'First, you need to initialize the algorithm with the details of the problem
    and the hyperparameters. The actual algorithm consists of a few important steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the edge attractiveness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This determines how attractive a certain edge is for an ant. It depends on tau
    (pheromone level per edge), eta (cost per edge), alpha (pheromone importance)
    and beta (cost importance).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s call the matrix attractiveness per edge `A`. The update rule for an edge
    `(i, j)` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you set beta to 5 for example, and alpha to 1, the attractiveness of an edge
    is more influenced by the cost than by the pheromone level.
  prefs: []
  type: TYPE_NORMAL
- en: Updating tau
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Over time, the pheromone trail evaporates (controlled by hyperparameter rho).
    So we need to update the pheromone level for every iteration. All values are multiplied
    by `(1-rho)`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Finding an ant trail
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step is the most important one, and it uses all information to find a trail
    for one ant.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ant starts in a start node, and selects a neighbor of the current node
    based on the edge attractiveness `A`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the edge attractiveness is used as weights for selecting the
    next node. If the ant reaches an end node, the pheromone trail (tau) is updated
    for the edges in the solution, based on the score of the solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: It is possible that an ant gets stuck before reaching an end node. In that case
    the ant is ignored, which means that the pheromone trail will not be updated for
    this ant.
  prefs: []
  type: TYPE_NORMAL
- en: When to use ACO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Originally, [ACO](http://www.cs.yale.edu/homes/lans/readings/routing/dorigo-ants-1999.pdf)
    was developed for solving problems that involve finding the shortest path on a
    graph, but since then ACO is applied to other types of problems.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of optimization problems where ACO is used successfully, include the
    [traveling salesman problem](https://ieeexplore.ieee.org/document/585892), the
    [vehicle routing problem](https://people.idsia.ch/~luca/tr-idsia-06-99.pdf), [task
    scheduling in cloud computing](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7355287),
    [communication networks](https://arxiv.org/abs/1105.5449), [graph coloring](https://www.jstor.org/stable/3010428)
    and for [folding proteins](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-6-30).
    One advantage of ACO is that it can handle large and complex problems with many
    variables and constraints. Another advantage is that it can find good solutions
    quickly and efficiently, often outperforming other optimization algorithms. But
    the major benefit of ACO is that the algorithm can adapt if a problem changes
    over time. This is because the algorithm is capable of continuously exploring
    and adapting to new solutions as they become available. Examples of problems where
    this is really useful are transportation systems in busy areas or network routing.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the dynamic nature of problems, ACO is particularly effective at solving
    combinatorial optimization problems, which involve finding the best combination
    of discrete variables. Maybe you already figured out by now, but ACO can handle
    nonlinear optimization problems, which involve objective functions that are not
    linear and may have multiple local optima. In such cases, ACO can help to identify
    global optima by exploring the solution space more thoroughly.
  prefs: []
  type: TYPE_NORMAL
- en: However, like any tool, ACO requires careful calibration. The choice of hyperparameters
    plays a critical role in its performance. Fine-tuning these parameters is essential
    to get the best performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e87ed06774e2db5253149d65d48354ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Prabir Kashyap](https://unsplash.com/@i__prabir?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In my next post, we will take a hands-on approach, implementing ACO and witnessing
    its power in action. Whether you’re a seasoned algorithm enthusiast or a curious
    beginner, ACO promises to be a fascinating and rewarding adventure in the field
    of nature-inspired optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Stay tuned to witness the ants unraveling complex optimization challenges!
  prefs: []
  type: TYPE_NORMAL
- en: Related
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/bigdatarepublic/embracing-the-unknown-lessons-from-chaos-theory-for-data-scientists-a992e8478600?source=post_page-----d016fe925108--------------------------------)
    [## Embracing the Unknown: Lessons from Chaos Theory for Data Scientists'
  prefs: []
  type: TYPE_NORMAL
- en: Insights for understanding the limits of predictive models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'medium.com](https://medium.com/bigdatarepublic/embracing-the-unknown-lessons-from-chaos-theory-for-data-scientists-a992e8478600?source=post_page-----d016fe925108--------------------------------)
    [](/an-introduction-to-a-powerful-optimization-technique-simulated-annealing-87fd1e3676dd?source=post_page-----d016fe925108--------------------------------)
    [## An Introduction to a Powerful Optimization Technique: Simulated Annealing'
  prefs: []
  type: TYPE_NORMAL
- en: Explanation, parameters, strengths, weaknesses and use cases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/an-introduction-to-a-powerful-optimization-technique-simulated-annealing-87fd1e3676dd?source=post_page-----d016fe925108--------------------------------)
    [](/mathematical-optimization-heuristics-every-data-scientist-should-know-b26de0bd43e6?source=post_page-----d016fe925108--------------------------------)
    [## Mathematical Optimization Heuristics Every Data Scientist Should Know
  prefs: []
  type: TYPE_NORMAL
- en: Local search, genetic algorithms and more.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/mathematical-optimization-heuristics-every-data-scientist-should-know-b26de0bd43e6?source=post_page-----d016fe925108--------------------------------)
  prefs: []
  type: TYPE_NORMAL
