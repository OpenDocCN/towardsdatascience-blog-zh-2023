- en: A Marriage of Machine Learning and Optimization Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习与优化算法的结合
- en: 原文：[https://towardsdatascience.com/a-marriage-of-machine-learning-and-optimization-algorithms-e6c680454f06](https://towardsdatascience.com/a-marriage-of-machine-learning-and-optimization-algorithms-e6c680454f06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-marriage-of-machine-learning-and-optimization-algorithms-e6c680454f06](https://towardsdatascience.com/a-marriage-of-machine-learning-and-optimization-algorithms-e6c680454f06)
- en: How pattern detection and pattern exploitation might elevate each other to a
    new level
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模式检测和模式利用如何将彼此提升到一个新的层次
- en: '[](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)[![Wouter
    van Heeswijk, PhD](../Images/9c996bccd6fdfb6d9aa8b50b93338eb9.png)](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------)
    [Wouter van Heeswijk, PhD](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)[![Wouter
    van Heeswijk, PhD](../Images/9c996bccd6fdfb6d9aa8b50b93338eb9.png)](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------)
    [Wouter van Heeswijk, PhD](https://wvheeswijk.medium.com/?source=post_page-----e6c680454f06--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------)
    ·12 min read·Dec 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e6c680454f06--------------------------------)
    ·阅读时间 12 分钟·2023年12月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a9b9c8c0940005f58cb100e812a31d72.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9b9c8c0940005f58cb100e812a31d72.png)'
- en: Instead of benchmark optimization- and machine learning algorithms against each
    other, we should consider how they can strengthen each other [Photo by [Wedding
    Dreamz](https://unsplash.com/@wedding_dreamz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应将基准优化和机器学习算法相互比较，而应考虑它们如何相互加强 [图片由 [Wedding Dreamz](https://unsplash.com/@wedding_dreamz?utm_source=medium&utm_medium=referral)
    提供，在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上]
- en: Although most of us don’t see it, optimization algorithms (OAs) are at work
    everywhere. They plan shelve stocking for our grocery stores, create airport schedules,
    and give us the shortest route to our holiday destination. **Exact algorithms
    in particular do very well at exploiting known structures** — e.g., convex structures
    — finding solutions even in massive decision spaces with many constraints. Over
    the past decades, the combination of hardware- and algorithmic improvements yielded
    massive speed-ups in the order of millions. A planning task that might have taken
    a computer months to complete in the 90’s could just take a second today.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们大多数人看不到，但优化算法（OAs）无处不在。它们为我们的超市规划货架，为机场制定航班时间表，并为我们提供前往度假目的地的最短路线。**特别是精确算法在利用已知结构方面表现优异**
    — 例如，凸结构 — 即使在具有众多约束的大型决策空间中也能找到解决方案。在过去几十年中，硬件和算法的改进相结合，带来了数百万倍的速度提升。一个可能在90年代需要几个月才能完成的规划任务，如今可能只需一秒钟。
- en: Similarly, machine learning (ML) has taken an incredible flight in the last
    decade or so. MuZero showed the capability to learn superhuman game-playing policies
    without knowing the games’ rules, Graph Neural Networks learn complex relations
    unperceivable to the human eye, and Transformers gave rise to ChatGPT and its
    competitors. **The commonality is that these algorithms are all able to detect
    patterns from their environment**, be it text databases or video games. Novel
    and highly complicated architectures are introduced on a regular basis, often
    solving new problems and offering unparalleled performance. Despite all successes
    and breakthroughs, for many real-world problems, end-to-end ML struggles to achieve
    competitive results. Tailored OAs often still beat ML, but may require substantial
    computational time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，机器学习（ML）在过去十年左右取得了惊人的进展。MuZero 展现了在不知道游戏规则的情况下学习超人类游戏策略的能力，图神经网络学习了人眼无法感知的复杂关系，而变换器（Transformers）催生了
    ChatGPT 及其竞争对手。**这些算法的共同点在于它们都能够从环境中检测模式**，无论是文本数据库还是视频游戏。新颖且极其复杂的架构不断被引入，通常解决新的问题并提供无与伦比的性能。尽管取得了诸多成功和突破，对于许多现实世界的问题，端到端的机器学习仍难以取得竞争性结果。定制的优化算法通常仍然优于机器学习，但可能需要大量的计算时间。
- en: There is no need for the two approaches to compete though. Interestingly, **optimization
    algorithms excel at *exploiting* patterns, whereas machine learning shines at
    *detecting* patterns.** Instead of pitting them against each other as benchmarks
    and see which one outperforms the other, wouldn’t it make sense to marry the two
    complementary halves instead?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法并不需要竞争。有趣的是，**优化算法擅长于*利用*模式，而机器学习则在*检测*模式方面表现出色。** 不如将它们作为补充的两个部分结合起来，而不是对比它们的优劣，是否更有意义？
- en: When merging optimization and machine learning, it often boils down to **statistical
    learning being used to improve optimization routines** in one form or another.
    This way, we can speed up the search by exploiting patterns that we learned. The
    development of such integrated solutions has become an emerging research field
    in recent years, with many exciting possibilities ahead.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在合并优化和机器学习时，通常归结为**统计学习被用来以某种形式改进优化例程**。这样，我们可以通过利用学到的模式来加速搜索。这种集成解决方案的开发近年来已成为一个新兴的研究领域，未来有许多令人兴奋的可能性。
- en: How can we integrate machine learning and optimization algorithms?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们如何将机器学习和优化算法结合起来？
- en: 'We established that OA is good at exploiting structures and ML is good at detecting
    them, so there is a natural synergy. Still, what concretely would constitute a
    marriage between OA and ML? Broadly, we might classify in the following four categories:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定了优化算法擅长利用结构，而机器学习擅长检测结构，因此它们之间存在自然的协同效应。然而，具体来说，什么构成了优化算法与机器学习之间的结合？广义上，我们可以将其分类为以下四个类别：
- en: '**I.** **OA** **provides input to ML.** OA may offer a heuristic solution that
    can further be improved using ML, or it might perform a computationally intense
    preprocessing step in the algorithmic pipeline.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**I.** **优化算法（OA）为机器学习（ML）提供输入。** 优化算法可能提供一个启发式解决方案，该方案可以通过机器学习进一步改进，或者它可能在算法管道中执行计算密集型的预处理步骤。'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**II. ML provides input to OA.** For instance, ML may suggest a starting solution
    for a warm start, or learn problem structures for OA to exploit.'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**II. 机器学习（ML）为优化算法（OA）提供输入。** 例如，机器学习可以建议一个用于热启动的起始解决方案，或者学习问题结构供优化算法利用。'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**III.** **ML is used to accelerate OA.** ML may be used to iteratively detect
    structures, which aid OAsolvers in finding solutions more quickly.'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**III.** **机器学习（ML）用于加速优化算法（OA）。** 机器学习可以用于迭代检测结构，帮助优化算法更快地找到解决方案。'
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**IV.** **OA solves subroutines in ML**. Routines such as tree search or action
    space evaluation may be efficiently performed using OA.'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**IV.** **优化算法（OA）解决机器学习中的子例程。** 像树搜索或动作空间评估这样的例程可以通过优化算法高效执行。'
- en: Let’s offer a bit of practical interpretation to this. In part due to increasing
    logging and utilization of data, algorithmic pipelines tend to get increasingly
    complex. They often are composed of multiple tasks, some more suitable for OA,
    others for ML. Thus, it has become very natural for one paradigm providing input
    to the other.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对此进行一些实际的解释。由于数据记录和利用的增加，算法管道变得越来越复杂。它们通常由多个任务组成，有些更适合优化算法，有些则更适合机器学习。因此，一个范式向另一个范式提供输入已经变得非常自然。
- en: Furthermore, companies often repeatedly solve variants of a specific problem.
    For example, a transport company might solve a vehicle routing problem daily,
    dealing with variable yet comparable instances in terms of customers, time windows
    and load sizes. If general-purpose solvers would take advantage of these similarities,
    the OA algorithms could run more efficiently.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，公司通常会重复解决特定问题的变体。例如，运输公司可能每天解决一次车辆路径问题，处理在客户、时间窗口和负载大小方面变量但可比的实例。如果通用求解器能够利用这些相似性，优化算法的运行效率将会提高。
- en: Finally, since ML as an end-to-end paradigm is often not yet competitive with
    OA, it often helps to optimize some subroutines. Typically, this speeds up the
    ML algorithms and enhances there competitiveness.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于机器学习作为端到端的范式通常尚未与优化算法相竞争，因此优化某些子程序往往会有所帮助。这通常会加速机器学习算法并增强其竞争力。
- en: 'In general, combining OA and ML makes sense when:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，当以下情况成立时，结合优化算法和机器学习是有意义的：
- en: OA (or human expertise) is too slow to offer solutions within reasonable time
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化算法（或人类专家）在合理的时间内提供解决方案的速度太慢。
- en: There is room to improve upon heuristic solutions, or it is unknown how good
    (or bad) they actually are
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启发式解决方案仍有改进的空间，或者尚不清楚它们实际效果如何（好或差）。
- en: Good solutions still need to be identified
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仍需识别良好的解决方案。
- en: There is need for a fast approximative solution
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一种快速的近似解决方案。
- en: The algorithmic pipeline involves elements of both pattern detection and pattern
    exploration
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法流程涉及模式检测和模式探索的元素。
- en: We proceed to contextualize optimization algorithms and machine learning, before
    offering some illustrative examples.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将优化算法和机器学习进行背景化处理，然后提供一些说明性的例子。
- en: Optimization algorithms
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化算法
- en: A brief introduction to optimization algorithms is in order. To align with the
    ML integration, we crudely categorize in **exact algorithms (optimal solutions
    but slow)** and **heuristics (suboptimal solutions but faster)**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有必要简要介绍优化算法。为了与机器学习集成一致，我们粗略地将其分类为**精确算法（最优解但速度较慢）**和**启发式方法（次优解但更快）**。
- en: Exact algorithms
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确算法
- en: Exact algorithms are powerful techniques employed in optimization problems,
    capable of finding **provably optimal solutions** within a feasible solution space.
    Commonly, problems are formulated as **mathematical programs** (e.g., linear or
    quadratic programs), which can be solved using optimization software such as CPLEX,
    SCIP or Gurobi. These solvers systematically explore the solution space and guarantee
    that the best solution is identified.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 精确算法是用于优化问题的强大技术，能够在可行的解决方案空间内找到**可证明的最优解**。通常，问题被表述为**数学规划**（例如，线性或二次规划），可以使用如
    CPLEX、SCIP 或 Gurobi 等优化软件进行求解。这些求解器系统地探索解决方案空间，并保证找到最佳解。
- en: Although powerful out of the box, there is a limit to the solution spaces that
    can be handled. For very large problems, we often need to put substantial design
    effort into designing decompositions and **branch-, price- and/or cut schemes**
    to reduce search complexity and efficiently navigate through the solution space,
    while preserving optimality guarantees.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现成的方案功能强大，但可以处理的解决方案空间是有限的。对于非常大的问题，我们通常需要投入大量设计工作来设计**分支、定价和/或裁剪方案**，以减少搜索复杂性并有效地导航解决方案空间，同时保留最优性保证。
- en: Heuristics
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启发式方法
- en: Heuristics offer an alternative problem-solving approach, **sacrificing optimality
    guarantees for computational efficiency**. Heuristics are particularly useful
    for large-scale or complex problems, for which finding optimal solutions is impractical
    within a reasonable timeframe.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 启发式方法提供了一种替代问题解决方案，**以牺牲最优性保证换取计算效率**。启发式方法特别适用于大规模或复杂问题，这些问题在合理的时间框架内寻找最优解是不切实际的。
- en: Basic heuristics provide quick, **rule-of-thumb solutions**. They typically
    yield suboptimal results, but often return decent solutions in limited computational
    time. Examples include nearest-neighbor insertions or 2-opt swaps.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 基本启发式方法提供快速的**经验规则解决方案**。它们通常会产生次优结果，但通常会在有限的计算时间内返回不错的解决方案。例子包括最近邻插入或2-opt交换。
- en: Metaheuristics employ higher-level **strategies that guide the search for solutions**,
    often incorporating elements of randomness and adaptability. Examples include
    genetic algorithms, simulated annealing, and particle swarm optimization. Metaheuristics
    are more intense in terms of tuning effort and runtime, but tend to offer superior
    results compared to basic heuristics.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We discuss two paradigms of machine learning; demonstration learning and experience
    learning. Although **strongly related to existing classifications in terms of
    (un)supervised- and reinforcement learning**, we here aim to connect more to the
    optimization context.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Demonstration learning
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Demonstration learning minimizes the distance between a provided expert policy
    and predicted policy (supervised). It can be seen as a **teacher-student model**,
    in which the student (the ML model) aims to mimic the teacher (e.g., an exact
    algorithm, a tailored heuristic, or human-crafted solutions). Note that this form
    of learning therefore requires theoretical or empirical knowledge in some form.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: The differences between the solution predicted by the ML model and the known
    expert solution allows to compute a loss function, which the algorithm subsequently
    aims to minimize. If an ML algorithm is shown many **examples of high-quality
    solutions**, we hope it can ultimately replicate those.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: The downside of demonstration learning is that it **cannot beat the expert policy**.
    If the expert policy is suboptimal, so is the predicted policy. Therefore, demonstration
    learning only makes sense if acquiring the original solutions takes too long,
    and one strives to get the same solutions in a fraction of the time. However,
    if generating example solutions takes prohibitively long, the idea fails as well.
    This puts demonstration learning in a bit of a precarious position.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Demonstration learning is a form of **imitation learning**. We try to reproduce
    the same decision the expert offers, but faster.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/55f40c53f950c314c07bb614ff28d44a.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: In demonstration learning, the ML algorithm aims to mimic expert solutions as
    closely as possible [Photo by [Andre Mouton](https://unsplash.com/@andremouton?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Experience learning
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In contrast to demonstration learning, experience learning utilizes observations
    yielded by deployed policies, with the aim of improving them. This form of learning
    is typically associated with reinforcement learning (RL), which **iteratively
    executes and improves policies** based on observed rewards gained from its environment.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Compared to demonstration learning, **experience learning requires no prior
    knowledge** on solution quality or structure. The downside is that — in its purest
    form — it **leverages no information about the environment**, interacting with
    it strictly through state, action and reward. Common problems associated with
    experience learning are getting stuck in local optima, the need to appropriately
    define rewards, and extensively explore the solution space.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Experience learning utilizes feedback signals from its environment in order
    to improve its decision-making policies over time.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/c12e61460615fc47c93f3297103f50ad.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: In experience learning, an ML algorithm aims to improve its decision-making
    policies through interactions with its environment [Photo by [Alex Kondratiev](https://unsplash.com/@alexkondratiev?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Note that both forms of learning have substantial drawbacks, which in part explains
    why **end-to-end machine learning still struggles** on real-world problems. Thus,
    the integration of OA and ML is indeed mutually beneficial.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Of course it is possible — or perhaps even preferable — to apply both forms
    of learning in a single pipeline. An example would be to (i) generate an initial
    solution through demonstration learning, (ii) improve with an optimization solver,
    and (iii) use experience learning to guide the search for the optimal solution.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Examples of MO-OA
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time for some concrete examples. Below follow three representative examples
    based on academic studies.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: I. Learning to branch
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perhaps the best-studied example that integrates OA and ML is learning to branch,
    or more specifically, deploying ML to guide branch-and-bound algorithms. For those
    unfamiliar with the concept: **branch-and-bound solves integer problems by systematically
    exploring a very large search tree**, pruning proven suboptimal or unpromising
    branches based on established bounds. If the relaxation of a subproblem does not
    contain the optimal solution, neither will its adjacent integers.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'Although branch-and-bound is a renowned algorithm to solve large action spaces
    to optimality, underneath the hood some fairly **rudimentary heuristic choices**
    are made:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '**Variable selection**: *Which variable to branch on next.* A common decision
    rule is to simply branch on the most ‘fractional’ (closest to 0.5) variable.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Node selection**: *Which of the currently open nodes to process first.* Extremes
    are to always explore the most promising node (best-first) or to always fully
    explore a node’s subtree (depth-first).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/be1c69afb096d40365c90a3a67b1b5af.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
- en: Example of branch-and-bound procedure. The choices which node to explore next
    and which variable to branch on are typically based on heuristic rules [image
    from [WikiMedia](https://commons.wikimedia.org/wiki/File:Microsoft_Edge_1_27_2020_1_35_41_AM_(2).png)]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Truth be told, this simplification does not do justice to more sophisticated
    heuristics developed over the years. Nonetheless, despite the guarantee to ultimately
    find the optimal solution, the actual **search procedure is not as intelligent**
    as one might expect it to be, which is the price paid for solvers being general-purpose.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Given that the **tree search is sequential and highly dynamic**, it seems sensible
    to replace static heuristic rules with dynamic learning-based ones. For instance,
    dynamic features of nodes, branches and trees could be designed to predict suitable
    variables and nodes, with their values being learned by ML.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: A number of solutions have been proposed in the past years, ranging from offline
    demonstration learning to online experience learning. An intuitive example is
    that of [upper confidence bounds](https://medium.com/towards-data-science/seven-exploration-strategies-in-reinforcement-learning-you-should-know-8eca7dec503b),
    **balancing exploration and exploitation** based on the node’s perceived value
    and the number of time it has been visited.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: The example of learning to branch illustrates that ML can be deployed in the
    context of exact algorithms, potentially **speeding up search procedures** **without
    compromising** **optimality guarantees**.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Example based on Lodi & Zarpellon (2017) and Balcan et al. (2018)
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: II. Learning routing with GNN
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instances for routing problems are commonly represented by graphs. Customer
    locations and travel distances are obvious properties reflected in such graphs,
    yet nodes and arcs can have all kinds of labels, such as time windows and traffic
    densities. Graph Neural Networks (GNNs) are a powerful technique to **embed and
    meaningfully represent such graphs** in the problem context.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b21c261c272dd47e01255bda6b1390d5.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
- en: The vehicle routing problem is a classical combinatorial optimization problem,
    exploding exponentially in size with the number of nodes [image from [WikiMedia](https://en.wikipedia.org/wiki/Vehicle_routing_problem#/media/File:Figure_illustrating_the_vehicle_routing_problem.png)]
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, routes are generated using exact solvers (e.g., the Concorde
    TSP Solver) or metaheuristics (e.g., Hybrid Genetic Search). However, these solvers
    require fairly **long runtimes**, with exact algorithms failing to offer solutions
    at all for large instances.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Instead of running optimization algorithms for hours and hours every time we
    encounter a new problem instance, we might learn to replicate them by detecting
    the patterns in their solutions. This example is a form of **demonstration learning**,
    trying to minimize the performance gap between the computationally-intensive optimal
    solutions and the ML-generated solutions. Some quality loss is incurred in the
    process, but solutions can be generated in a much friendlier timeframe.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: By running GNNs on the solutions, it is possible to estimate the **probabilities
    that edges will be included in the solutions**. Subsequently, a sparse heatmap
    is constructed that retains the most promising edges. Guided by this heatmap,
    a dynamic programming subroutine is run for stepwise construction of the routes.
    If a route is dominated by others, it can be pruned.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Example based on Kool et al. (2019) and Kool et al. (2022)
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: III. Mathematical programming for large action spaces
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this final case, mathematical programming is deployed as a subroutine in
    reinforcement learning, with the purpose of handling large action spaces.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Combinatorial optimization problems have the tendency to very quickly **explode
    in size**, e.g., the number of sequences to visit a set of nodes is the factorial
    of the nodes. They often require handling **many constraints**, such as the capacity
    and maximum driving time of a truck or time windows at the customer nodes. Enumerating
    all actions and running feasibility checks becomes cumbersome very quickly.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: If the problem structure allows, the **one-step decision problem can be formulated
    as a linear program**. Such programs can be solved very efficiently, vastly scaling
    up the size of action spaces that vanilla RL algorithms — which rely on explicit
    enumeration — could handle.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e86df850a3efd84b0ca5578b4ab7acb8.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: Linear programming can efficiently explore large action spaces with constraints
    [image via [WikiMedia](https://commons.wikimedia.org/wiki/File:Linear_optimization_in_a_2-dimensional_polytope.svg)]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The integration between OA and ML does not end there. Next, consider the approximation
    of Q-values. In many modern RL applications, this is done through a[**Deep Q-network**](https://medium.com/towards-data-science/a-minimal-working-example-for-deep-q-learning-in-tensorflow-2-0-e0ca8a944d5e),
    which by definition perform a nonlinear transformation on its input. However,
    ReLU activation functions can be embedded in the objective function through piecewise
    linear functions, supported by a set of additional constraints.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Another OA layer? Instead of searching the full action space, we may impose
    domain restrictions and **local branching** to control the action space, exploring
    only the neighborhood in which we suspect (based on Q-values) the best action
    resides.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Example based on Van Heeswijk, W.J.A. & La Poutré (2020) and Akkerman et al.
    (2023)
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As you see, the opportunities for integrating machine learning and optimization
    algorithms are vast and diverse. It has been an active research area for years,
    with lots of potential yet to be unlocked.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '**TL;DR**'
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both machine learning and optimization algorithms have flaws in terms of computational
    times, performance guarantees, knowledge utilization, etc. Given the nature of
    both paradigms, they may naturally complement each other.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning specializes in **pattern detection**, optimization algorithms
    specialize in pattern **exploitation**. They can be combined to build powerful
    algorithmic pipelines.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, companies often repeatedly solve a single problem with relatively
    limited variance. **Extracting patterns from solution data** (i.e., statistical
    learning)can boost existing exact methods or heuristics.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning can be used in the form of **demonstration learning** (approximating
    solutions of optimization algorithms in a fraction of the time) or **experience
    learning** (interacting with the environment to iteratively enhance policies).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*You may also like the following articles:*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[](/using-linear-programming-to-boost-your-reinforcement-learning-algorithms-994977665902?source=post_page-----e6c680454f06--------------------------------)
    [## Using Linear Programming to Boost Your Reinforcement Learning Algorithms'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Large and high-dimensional action spaces are often computational bottlenecks
    in Reinforcement Learning. Formulating…
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/using-linear-programming-to-boost-your-reinforcement-learning-algorithms-994977665902?source=post_page-----e6c680454f06--------------------------------)
    [](/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=post_page-----e6c680454f06--------------------------------)
    [## Five Ways To Handle Large Action Spaces in Reinforcement Learning
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Action spaces, particularly in combinatorial optimization problems, may grow
    unwieldy in size. This article discusses…
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=post_page-----e6c680454f06--------------------------------)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '*For those interested in machine learning for combinatorial optimization, I
    can warmly recommend the following keynote speech by Prof. Andrea Lodi:*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Akkerman, F., Luy, J., Van Heeswijk, W.J.A., & Schiffer, M. (2023). Handling
    Large Discrete Action Spaces via Dynamic Neighborhood Construction. *arXiv preprint
    arXiv:2305.19891*.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Balcan, M. F., Dick, T., Sandholm, T., & Vitercik, E. (2018, July). Learning
    to branch. In *International Conference on Machine Learning* (pp. 344–353). PMLR.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Khalil, E., Le Bodic, P., Song, L., Nemhauser, G., & Dilkina, B. (2016, February).
    Learning to branch in mixed integer programming. In *Proceedings of the AAAI Conference
    on Artificial Intelligence* (Vol. 30, №1).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Kool, W., Van Hoof, H., & Welling, M. (2019). Attention, learn to solve routing
    problems!. International Conference on Learning Representations 2019.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'Kool, W., Van Hoof, H., Gromicho, J., & Welling, M. (2022, June). Deep policy
    dynamic programming for vehicle routing problems. In *International conference
    on integration of constraint programming, artificial intelligence, and operations
    research* (pp. 190–213). Cham: Springer International Publishing.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'Lodi, A., & Zarpellon, G. (2017). On learning and branching: a survey. *Top*,
    *25*, 207–236.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Parmentier, A., & T’kindt, V. (2023). Structured learning based heuristics to
    solve the single machine scheduling problem with release times and sum of completion
    times. *European Journal of Operational Research*, *305*(3), 1032–1041.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Parmentier, A. 和 T’kindt, V.（2023）。基于结构学习的启发式方法解决具有释放时间和完成时间总和的单台机器调度问题。*欧洲运筹学期刊*，*305*(3)，1032–1041。
- en: 'Santana, Í., Lodi, A., & Vidal, T. (2023, May). Neural Networks for Local Search
    and Crossover in Vehicle Routing: A Possible Overkill?. In *International Conference
    on Integration of Constraint Programming, Artificial Intelligence, and Operations
    Research* (pp. 184–199). Cham: Springer Nature Switzerland.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Santana, Í., Lodi, A., 和 Vidal, T.（2023年5月）。车辆路径中的局部搜索和交叉的神经网络：可能的过度杀伤？在*约束编程、人工智能与运筹学集成国际会议*（第184–199页）。Cham：Springer
    Nature Switzerland。
- en: Van Heeswijk, W.J.A. van & La Poutré, H.L. (2020, December). Deep reinforcement
    learning in linear discrete action spaces. In *2020 Winter Simulation Conference
    (WSC)* (pp. 1063–1074). IEEE.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Van Heeswijk, W.J.A. van 和 La Poutré, H.L.（2020年12月）。线性离散动作空间中的深度强化学习。在*2020年冬季模拟会议（WSC）*（第1063–1074页）。IEEE。
- en: Vazacopoulos, A. (2020). Combining machine learning and mathematical optimization
    integration using Python. Via [LinkedIn](https://www.linkedin.com/pulse/combining-machine-learning-mathematical-optimization-vazacopoulos/).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Vazacopoulos, A.（2020）。使用 Python 结合机器学习和数学优化集成。通过 [LinkedIn](https://www.linkedin.com/pulse/combining-machine-learning-mathematical-optimization-vazacopoulos/)。
