- en: 'Unraveling the Design Pattern of Physics-Informed Neural Networks: Part 03'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Supercharging PINN‚Äôs performance with gradient boost training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----fe365ef480d9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fe365ef480d9--------------------------------)
    ¬∑7 min read¬∑May 25, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6135269a240dcb1660a418ff2ece06d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Haithem Ferdi](https://unsplash.com/@haithemfrd_off?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the 3rd blog of this series, where we continue our exciting journey
    of exploring design patterns of physics-informed neural networks (PINN).
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we will look into training PINNs with gradient boosting, an exciting
    fusion of neural networks and gradient boosting algorithms üöÄ.
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, I will structure this blog in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: the **problem**, the specific problem the proposed strategy is trying to address;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the **solution**, the key components of the proposed strategy, how it is implemented,
    and why it might work;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the **benchmark**, what physical problems are evaluated, and what‚Äôs the associated
    performance;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the **strengths & weaknesses**, under which conditions the proposed strategy
    can be effective, while also highlighting its potential limitations;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the **alternatives**, other approaches proposed to address a similar problem,
    thus providing a broader perspective on potential solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As this series continues to expand, the collection of PINN design patterns
    grows even richer*üôå* Here‚Äôs a sneak peek at what awaits you:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 05: automated hyperparameter tuning](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let‚Äôs dive in!
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Paper at a glance:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Title**: Ensemble learning for physics informed neural networks: a Gradient
    Boosting approach'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authors**: Z. Fang, S. Wang, P. Perdikaris'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Institutes**: University of Pennsylvania'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Link: [arXiv](https://arxiv.org/abs/2302.13143)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. Design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 2.1 Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Naive PINNs are known to have difficulties in simulating physical processes
    that are **sensitive to small changes** in the input and require a high degree
    of accuracy to accurately capture their dynamics. Examples of those physical systems
    include multi-scale problems and singular perturbation problems, which are highly
    relevant to domains like fluid dynamics and climate modeling.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c0c53c2bc5db304471361d09715678ea.png)'
  prefs: []
  type: TYPE_IMG
- en: PINN workflow. Naive PINNs often encounter challenges in solving complicated
    PDEs. One promising way to address this issue is by training PINNs with **boosting**
    algorithms. (Image by this blog author)
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It turns out, the same issue is also experienced by other machine learning
    algorithms, and a promising way to resolve this issue is by adopting the ‚ÄúGradient
    Boosting‚Äù method. Therefore, a natural question arises: can we mimic the gradient
    boosting algorithm to train PINNs? The paper has given a positive answer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Boosting is a general machine learning algorithm that can be succinctly expressed
    in the following iterative form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/419bb6b8157f439a5f8987d14ddea480.png)'
  prefs: []
  type: TYPE_IMG
- en: At each boosting round, an incremental model *h‚Çò*(‚Ä¢) is derived and added (discounted
    by a learning rate *œÅ‚Çò*) on top of the predictor from the last iteration f*‚Çò_*‚ÇÅ(‚Ä¢),
    such that the accuracy of f*‚Çò*(‚Ä¢) could be ‚Äúboosted‚Äù.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if we replace f*‚Çò_*‚ÇÅ(‚Ä¢), f*‚Çò*(‚Ä¢), and *h‚Çò*(‚Ä¢) as physics-informed neural
    networks, we can realize training PINNs with boosting algorithm. A diagram to
    showcase the training process is given below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b64b778fb6547d151cce05fbce42ac17.png)'
  prefs: []
  type: TYPE_IMG
- en: PINN models are trained in sequence to iteratively minimize the loss. Only the
    blocks marked green are trainable. The loss is the usual PINN loss, i.e., PDE
    loss, boundary condition loss, etc. (Image by this blog author)
  prefs: []
  type: TYPE_NORMAL
- en: In the paper‚Äôs implementation, the architecture and the hyperparameters of the
    additive PINN model *h‚Çò*(‚Ä¢) are **pre-determined**. This is different from the
    original gradient-boosting algorithm, as the original algorithm would utilize
    gradient descent to find the optimal *h‚Çò*(‚Ä¢) form. However, the authors claimed
    that using pre-selected *h‚Çò*(‚Ä¢)s can still mimic the behavior of boosting algorithm,
    but with significantly reduced computational complexity.
  prefs: []
  type: TYPE_NORMAL
- en: According to the numerical experiments conducted in the paper, usually, 3~5
    PINNs are good enough to deliver satisfactory results. For setting the learning
    rate *œÅ‚Çò*, the suggested way would be to set the initial *œÅ* as 1, and exponentially
    decay the *œÅ* valueas *m* increases.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Why the solution might work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the proposed solution mimics the mechanism of the traditional ‚ÄúGradient
    Boosting‚Äù, it automatically inherits all the nice things offered by the approach:
    by sequentially adding weak models, each new model is able to correct the mistakes
    made by the previous models, thus iteratively improving the overall performance.
    This makes the approach especially effective for challenging problems such as
    multi-scale or singular perturbation problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, for boosting algorithm, a ‚Äústrong‚Äù model can still be achieved even
    if the component model at each boosting stage is relatively ‚Äúweak‚Äù. This property
    has the benefit of making the overall PINN model less sensitive to hyperparameter
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Benchmark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The paper benchmarked the performance of the proposed strategy on four diverse
    problems, each representing a distinct mathematical challenge:'
  prefs: []
  type: TYPE_NORMAL
- en: '1D singular perturbation problem: singular perturbation problems are special
    cases where certain terms in the equations become disproportionately small or
    large, leading to different behaviors that are challenging to model. These problems
    often occur in many areas of science and engineering, such as fluid dynamics,
    electrical circuits, and control systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/a0b40711ff07f2c2b15330f851ed0257.png)'
  prefs: []
  type: TYPE_IMG
- en: Œµ = 1e-4.
  prefs: []
  type: TYPE_NORMAL
- en: '2D convection-dominated diffusion equation: this equation models physical phenomena
    where the convection effect (transport due to bulk motion) is much stronger than
    the diffusion effect (transport due to concentration gradients). These types of
    problems occur in various areas like meteorology (where wind disperses pollutants)
    and oceanography (where ocean currents transport heat).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/157a22f3dd284e136c5c623f11f2c3ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Œµ = 1e-3, Œ© = (0, 1)¬≤.
  prefs: []
  type: TYPE_NORMAL
- en: '2D convection-dominated diffusion problem (featuring curved streamlines and
    an interior boundary layer): this is a more complex variant of the previous problem
    where the flow pattern is curved, and there is a significant boundary layer within
    the problem domain. These complications require a more sophisticated numerical
    approach and make the problem more representative of real-world challenges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/57593bb173e4a291c3dd1b3df5d3b0fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Œµ = 1e-4, Œ© = (0, 1)¬≤, Œ≤ = eÀ£(sin(y), cos(y)).
  prefs: []
  type: TYPE_NORMAL
- en: '2D nonlinear reaction-diffusion equation (time-dependent): this equation models
    reactions combined with the diffusion of substances, but it‚Äôs also nonlinear and
    changes over time. These types of problems are common in fields like biology and
    chemistry, where substances interact and spread in a medium, and the reaction
    rates can change over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/d08d9a7aca98a97d0d1eff4fecb243c5.png)![](../Images/d229e29e4ce533bab423d60fced24704.png)'
  prefs: []
  type: TYPE_IMG
- en: Œ© = (0, 2œÄ), periodic boundary conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The benchmark studies yielded that:'
  prefs: []
  type: TYPE_NORMAL
- en: the proposed algorithm showed substantial accuracy improvements across all test
    cases compared with naive PINNs;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the proposed algorithm showed robustness, with little sensitivity to the hyperparameter
    choices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.5 Strengths and Weaknesses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: üëç**Strengths**
  prefs: []
  type: TYPE_NORMAL
- en: Significantly improved accuracy compared to a single PINN.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robust against the choice of network structure and arrangement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fewer efforts are required for fine-tuning hyperparameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flexible and can be easily integrated with other PINNs techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: üëé**Weaknesses**
  prefs: []
  type: TYPE_NORMAL
- en: Not suitable for solving conservation laws with derivative blow-ups (e.g., inviscid
    Burgers‚Äô equation, Sod shock tube problem, etc.), which is due to the lack of
    sensitivity of these equations‚Äô solutions to PDE loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations in terms of scalability, as it may require more computational resources
    and time to train multiple neural networks in sequence.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.6 Alternatives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since this is the first paper that introduces the boosting algorithm to the
    PINN domain, there is currently no similar work as the current paper.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, in terms of enhancing the PINN‚Äôs capability of modeling challenging
    physical processes, the paper specifically mentioned the work of [Krishnapriyan
    et al.](https://arxiv.org/abs/2109.01050) There, the strategy is to divide the
    time domain into sub-intervals, and PINNs are built progressively to model each
    of the sub-intervals (similar to the idea covered in the [previous blog](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)).
  prefs: []
  type: TYPE_NORMAL
- en: The current paper compared Krishnapriyan‚Äôs approach with the newly proposed
    one in the last benchmark case study (section 2.4 above). The results showed that
    the proposed boosting approach is able to achieve 4 times lower error.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Potential Future Improvements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Further improvements of the proposed strategy include investigating the optimal
    sequential combination of the neural networks, mixing and matching with other
    types of neural network architectures in the gradient boosting training iterations,
    as well as integrating other best practices of PINN training (e.g., residual points
    generation) into the gradient boosting training framework.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog, we looked at a new PINN training paradigm via boosting-based ensemble
    learning. This topic is highly relevant as it enhances PINNs‚Äô capability to tackle
    challenging problems like multi-scale and singular perturbation problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, here are the takeaways from the design pattern proposed in this paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Problem]: How to enhance PINNs‚Äô capability to solve challenging problems?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Solution]: **Gradient boosting**, where multiple ‚Äúweak‚Äù PINNs are trained
    in sequence to iteratively improve the overall performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Potential benefits]: 1\. Able to solve challenging problems for naive PINN.
    2\. Fewer efforts for hyperparameter tuning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is another PINN design card:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e721a39dd529d97d43c9e855957a3e6.png)'
  prefs: []
  type: TYPE_IMG
- en: PINN design pattern proposed in the paper. (Image by this blog author)
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope you found this blog usefulüòÉIf you want to learn more about PINN design
    patterns, feel free to check out other posts in this series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PINN design pattern 05: Hyperparameter tuning for PINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking forward to sharing more insights with you in the upcoming blogs!
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Fang et al., Ensemble learning for physics informed neural networks: a
    Gradient Boosting approach, [arXiv](https://arxiv.org/abs/2302.13143), 2023.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Krishnapriyan et al., Characterizing possible failure modes in physics-informed
    neural networks, [arXiv](https://arxiv.org/abs/2109.01050), 2021.'
  prefs: []
  type: TYPE_NORMAL
