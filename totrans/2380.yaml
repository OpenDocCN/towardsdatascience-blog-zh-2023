- en: Why There Kind of Is Free Lunch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/why-there-kind-of-is-free-lunch-56f3d3c4279f](https://towardsdatascience.com/why-there-kind-of-is-free-lunch-56f3d3c4279f)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: On The Universality of Patterns in Neuroscience and Artificial Intelligence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://manuel-brenner.medium.com/?source=post_page-----56f3d3c4279f--------------------------------)[![Manuel
    Brenner](../Images/f62843c79a9b378494cb83caf3ddc792.png)](https://manuel-brenner.medium.com/?source=post_page-----56f3d3c4279f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----56f3d3c4279f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----56f3d3c4279f--------------------------------)
    [Manuel Brenner](https://manuel-brenner.medium.com/?source=post_page-----56f3d3c4279f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----56f3d3c4279f--------------------------------)
    ·11 min read·Jun 27, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '**‘There ain’t no such thing as a free lunch.’'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Robert A. Henlein**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The “No Free Lunch” theorem in the realm of machine learning reminds me of Gödel’s
    incompleteness theorem within the world of mathematics.
  prefs: []
  type: TYPE_NORMAL
- en: While these theorems are frequently cited, they are seldom explained in depth,
    and the implications for real-world applications often remain unclear. Just as
    Gödel’s theorem became a thorn in the early 20th-century mathematicians’ belief
    in a complete and self-consistent formal system, the “No Free Lunch” theorems
    challenge our faith in the efficacy of general machine learning algorithms. Yet,
    these theorems’ impact on everyday practical applications can often be small,
    and most practitioners proceed unencumbered by these theoretical constraints.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b23f215331e0286b91dc5fbb0799a27.png)'
  prefs: []
  type: TYPE_IMG
- en: A machine learner realizing there might be free lunch after all, as envisioned
    by DALL-E.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I want to explore what the “No Free Lunch” theorem states and
    delve into its associations with vision, transfer learning, neuroscience, and
    artificial general intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: The **“No Free Lunch”** theorem(s), [proposed by Wolpert and Macready in 1997](https://ieeexplore.ieee.org/document/585893)
    and often used in the context of machine learning, **state that no one algorithm
    is universally the best for all possible problems**. There’s no magical, one-size-fits-all
    solution. An algorithm might work exceptionally well for one task but could perform
    poorly on another.
  prefs: []
  type: TYPE_NORMAL
- en: A fundamental objective of machine learning is to discern meaningful patterns
    within disparate data. An algorithm’s effectiveness, however, often depends on
    the specific nature of the data at hand. It may prove really useful for one type
    of data, but less effective when applied to another.
  prefs: []
  type: TYPE_NORMAL
- en: This becomes apparent when considering the different types of data we might
    encounter. Something as simple as a coin flip generates a simple probabilistic
    distribution of two patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, practically more significant examples, such as image data
    or text data, are much more complex. The universe of potential patterns grows
    exponentially with the number of pixels, making the array of possible configurations
    in a 500x500 image already unimaginably large:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6c2462b503031fc51a4cd4ebd82b3ea.png)'
  prefs: []
  type: TYPE_IMG
- en: Given the size of this space, how can we still learn anything meaningful from
    data?
  prefs: []
  type: TYPE_NORMAL
- en: An important part of the answer is that most samples of interest are not sampled
    uniformly from the space of all possible samples, but come with a large amount
    of pre-existing structure when compared to random sampling.
  prefs: []
  type: TYPE_NORMAL
- en: Language data serves as another classic example. The sum of all words in any
    given language consists of a subset of patterns that lives in a much lower-dimensional
    space when contrasted against the set of all possible combinations of letters,
    something that was used in the first simple statistical models of language (I
    explored this in more depth in my article on [Markov chains](/understanding-markov-chains-cbc186d30649)).
  prefs: []
  type: TYPE_NORMAL
- en: For machine learners, it’s great news that there are some recurring patterns
    in many types of input data. It means that we can train models that learn to extract
    these patterns, and possibly even re-use the models to extract similar patterns
    in different applications.
  prefs: []
  type: TYPE_NORMAL
- en: The technique of **transfer learning** makes explicit use of the fact that most
    real-world problems share some common structures.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning uses pre-trained models, which have already learned patterns
    from a large dataset, to adapt and **“fine-tune”** to a different but related
    task. A model trained to recognize objects in images could have learned low-level
    features like edges and color gradients and high-level features like shapes. These
    learned features could then be applied to a related task, such as recognizing
    handwritten digits or classifying tumors in medical images.
  prefs: []
  type: TYPE_NORMAL
- en: Hubel and Wiesel figured this out when they discovered that the visual cortex
    is composed of hierarchical layers which deal with increasingly complex patterns,
    winning them the Nobel Prize in 1981\. Since the advent of Convolutional Neural
    Networks (CNNs), their work has been widely discussed in relation to machine learning
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In the primary visual cortex, for instance, simple cells detect edges and gradients
    of color, while complex cells aggregate the outputs of these simple cells to recognize
    broader patterns, like motion or specific shapes. Heading deeper into the visual
    system, the patterns recognized by neurons become increasingly complex, moving
    from simple geometric forms to faces and intricate objects, ending at the (in)famous
    grandmother neuron that only fires when you see your grandma (or when you taste
    the madeleines she gave you as a kid).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf3ce844737e09885e286d48bba40d73.png)'
  prefs: []
  type: TYPE_IMG
- en: Features learned by a convolutional neural network (Inception V1) trained on
    the ImageNet data. Features increase in complexity from left to right. Figure
    from Olah, et al. (2017, CC-BY 4.0) [https://distill.pub/2017/feature-visualization/appendix/](https://distill.pub/2017/feature-visualization/appendix/).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way, the layers of a CNN extract features of increasing complexity.
    In the initial layers, the CNN might learn to detect simple structures, like lines,
    angles, and blobs of color. As we progress through the layers, these simple features
    are combined to form more complex representations: circles, rectangles, and eventually,
    discernible objects that start to look like cats, dogs, or elephants.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps these similarities shouldn’t come as a surprise: both systems have
    evolved and have been designed, respectively, to **exploit the structure inherent
    in visual data**. This understanding of what kind of patterns most frequently
    occur in all kinds of visual scenes can be repurposed or transferred to handle
    different but related tasks, just as discussed earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: This is where the concept of transfer learning and the brain’s ability to adapt
    and learn come into play. A child who learns to recognize a bicycle does not start
    from scratch when learning to recognize a motorcycle. They transfer their understanding
    of the basic structure of the bike from one context to another. Similarly, a CNN
    trained on a variety of images does not need to re-learn the concept of an “edge”
    when switching from recognizing faces to recognizing handwritten digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our own brains have stumbled onto the same truth that underpins the **‘kind
    of free lunch’** I’ve been discussing in the title: the world that is useful to
    us is very far from uniformly random, but rather full of recurring patterns and
    structures. Given these patterns are what we are interested in, our brains are
    hard-wired to selectively perceive them.'
  prefs: []
  type: TYPE_NORMAL
- en: We can even go a little further than simply saying that we are lucky that there
    are meaningful patterns in the world. Modern cognitive neuroscience theories see
    the brain more as a **prediction machine** than as a ‘reality’-perceiving tool.
  prefs: []
  type: TYPE_NORMAL
- en: '[The Bayesian Brain Hypothesis](/the-bayesian-brain-hypothesis-35b98847d331),
    for instance, suggests that our brains are constantly making probabilistic predictions
    about the world, updating these predictions based on sensory inputs. Our perception
    of the world, therefore, is not a passive process but an active one. We don’t
    simply perceive the world as it is but interpret it actively based on our priors,
    some of them based on our remembered experiences, but some of them going back
    to structural priors induced by the past experience of billions of years of evolution.'
  prefs: []
  type: TYPE_NORMAL
- en: The active, prior-driven component of cognition has such a significant influence
    on our perception that scientists like Anil Seth have coined our brain’s activity
    to be something akin to a ‘**controlled hallucination**’.
  prefs: []
  type: TYPE_NORMAL
- en: This also connects to [Donald Hoffman’s provocative idea](https://www.youtube.com/watch?v=4HFFr0-ybg0)
    (the case against reality) that states that we do not perceive reality as it is,
    but that perception has developed over millions of years as a ‘user interface’,
    and whose primary goal is to aid our survival. The icons on your computer’s desktop,
    for instance, don’t reveal the reality of what’s happening inside the machine,
    but provide an interface that makes it easy for you to use your computer.
  prefs: []
  type: TYPE_NORMAL
- en: What we perceive as a red apple is not the apple itself but a representation
    that guides us to nutritious food. Our perceptual systems, then, impose a strong
    prior on our sensory inputs, filtering out a large portion of data that does not
    fit our pre-existing models or that does not contribute directly to our survival.
    This bias towards salient patterns and away from perceived noise (the set of all
    possible visual patterns as spanned by the noisy picture I showed above) echoes
    the structure we’ve been discussing that underlies transfer learning and the **‘kind
    of free lunch’** in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Our brains are like pre-trained models that have learned to focus only on certain
    patterns in the world, helping us deal with the constant rampage of new sensory
    inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The older we get, the less likely we are to invert our model and fine-tune
    it when unseen patterns arise, and the more we walk around with an inference machine
    in our head that is the epitome of the (self-perceived) free lunch: to go with
    the meme, the ‘old white man’ is someone who is explaining everything he encounters
    through the lens of his already firmly established world model that (in his mind)
    is the universal algorithm that gets him free lunch out of every learning problem
    he encounters.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b46c8aa1351e91eb139bada82e24fed0.png)'
  prefs: []
  type: TYPE_IMG
- en: Old white politician that smiles arrogantly because he thinks he knows everything,
    as generated by DALL-E. I swear it came up with the British flag all by itself.
  prefs: []
  type: TYPE_NORMAL
- en: Jokes aside, while transfer learning within modalities is crucial, our discussion
    neatly extends to current developments in the multimodal setting, both in neuroscience
    and machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: The brain has an astonishing ability to reorganize itself known as **neuroplasticity**,
    an ability frequently observed after strokes or other dramatic cases of sensory
    loss.
  prefs: []
  type: TYPE_NORMAL
- en: Sensory loss often leads to a repurposing of certain brain areas. Blind individuals,
    for instance, often develop a heightened sense of hearing and touch. This is not
    simply a matter of increased attention or practice. Research has shown that the
    visual cortex, which normally processes visual information, becomes active during
    auditory and tactile tasks in blind individuals (the book Livewired by David Eagleman
    gives a fantastic account of the central role neuroplasticity plays in the brain).
  prefs: []
  type: TYPE_NORMAL
- en: It’s as if the brain has taken a neural network pre-trained on visual tasks
    and, finding itself no longer receiving visual input, fine-tuned it to process
    auditory and tactile information.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, deaf individuals have been found to use areas of the brain typically
    associated with processing spoken language, such as Broca’s and Wernicke’s areas,
    while using sign language. These areas are dedicated to communication more broadly,
    regardless of the specific modality of that communication. The brain’s language
    network is flexible enough to handle different forms of communication — be it
    spoken, written, or signed.
  prefs: []
  type: TYPE_NORMAL
- en: These instances of neuroplasticity show us that our brain's computations are
    underpinned by a form of a universal learning algorithm, capable of processing
    a wide range of patterns, not just those typically associated with a specific
    sensory modality. What this algorithm precisely is based on is up for debate (see
    e.g. Jeff Hawkin’s thousand brains or Kurzweil’s pattern recognizers for popular
    neuroscientific explanations, and the book The Master Algorithm by Pedro Domingues
    for a computer science perspective), but neuroplasticity clearly indicates that
    something like it exists.
  prefs: []
  type: TYPE_NORMAL
- en: The brain’s versatility is also mirrored by our most advanced machine-learning
    models. While Transformers were initially developed for natural language processing,
    mirroring language’s inductive bias, they have since been applied to a wide array
    of data types, from images and audio to time series data (whether this is primarily
    a result of the current hype around them can be argued over). Just as the visual
    cortex in blind people can repurpose itself for auditory or tactile tasks, Transformers
    can be adapted for a variety of data types, suggesting the existence of universal
    patterns that these models can capture, irrespective of the specific input modality
    (in all fairness, this might also be in part because Transformers are well suited
    to be optimized on our current computational architectures, since they can be
    heavily parallelized).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7f825afb981402d2a6e8ef04a32df3c4.png)'
  prefs: []
  type: TYPE_IMG
- en: The basic transformer architecture. Yuening Jia, CC BY-SA 3.0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Quoting the original NFL paper by Wolpert and Macready: ‘any two [optimization](https://en.wikipedia.org/wiki/Optimization_(mathematics))
    algorithms are equal when their performance is averaged across all possible problems’.
    But paraphrasing Orwell, when we look at most of the problems that really concern
    us, some optimization algorithms are more equal than others.'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the application of Transformers to image data has resulted in
    models such as Vision Transformers, which treat an image as a sequence of patches
    and apply the same self-attention mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: This idea is further exemplified in multi-modal Transformers, which can process
    and understand multiple types of data simultaneously. Text-and image embeddings
    such as the CLIP model, are trained to understand images and their related text
    descriptions concurrently. CLIP learns the relationship by incorporating both
    modalities into a joint embedding space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Such models capitalize on the common structures between different data types
    and effectively create a ‘translation’ system between them. A striking example
    of this capability of CLIP is familiar to most of us by now: by providing the
    foundation for diffusion-based models such as DALL-E, they allow us to generate
    impressive pictures from textual descriptions alone.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That this works so well might also not be altogether a coincidence: fundamental
    units of meaning in language might have counterparts in visual processing, and
    visual perception might also be understood in terms of a finite set of basic visual
    patterns or ‘visual words’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In language, the units most meaningful to humans, like ‘cat’, ‘dog’, or ‘love’,
    are short, and language is structured along the same concepts that have salience
    to us in visual scenes: the internet very likely features more pictures of cats
    than of noisy blobs of colors. More generally, it’s important to note language
    is already a derived modality, and one that large groups of people jointly develop
    to condense all the things that are most important to them into a concise symbolic
    representation.'
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps most profoundly, the fact that there `kind of is free lunch' also relates
    to artificial general intelligence (AGI), in that an AGI is an algorithm that
    manages to get free lunch out of most applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3ad29c8ce0393c5cf5292ce797e13dcd.png)'
  prefs: []
  type: TYPE_IMG
- en: AGI, as envisioned by DALL-E.
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of Chat-GPT: while the GPT models have been trained entirely on text,
    they are starting to display the capacity to comprehend, reason, and communicate
    about the world at large, well beyond the confines of textual data. Despite having
    only been trained to predict text data, these models seem to unearth some kind
    of universal logic that goes beyond the text, extending to different modalities
    and dimensions of understanding.'
  prefs: []
  type: TYPE_NORMAL
- en: Especially when co-trained with other modalities, LLMs are moving beyond textual
    description of that modality but instead understand the underlying patterns beyond
    modalities and can generate novel ideas from them, similar to what brains do.
  prefs: []
  type: TYPE_NORMAL
- en: I think one of the reasons why people (among them myself) have been so surprised
    by the success of LLMs in achieving generalizing intelligence is that we collectively
    underestimated to what extent the perceptual world that is most salient to us
    already relies on the universality of patterns and the corresponding universality
    of a learning algorithm in our brain.
  prefs: []
  type: TYPE_NORMAL
- en: While the free lunch theorem is true in theory, it’s also apparent that the
    majority of problems that concern us most are far from universal in a statistical
    sense. Instead, they tend to occupy a lower-dimensional space primarily concerned
    with vision, language, and sound, the primary sphere of human interest and saliency.
  prefs: []
  type: TYPE_NORMAL
- en: In the emergence of multimodal large language models, we have an algorithmic
    framework that capitalizes on these low-dimensional and cross-modal representations.
    It offers an exciting and slightly scary preview of the potential of AGI, and
    the way it could change our world and our understanding of the world.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
- en: If you like my writing, please [subscribe to get my stories via mail](https://manuel-brenner.medium.com/subscribe),
    or [consider becoming a referred member](https://manuel-brenner.medium.com/membership).
  prefs: []
  type: TYPE_NORMAL
