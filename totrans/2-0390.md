# 推荐系统中的偏差：主要挑战与最新突破

> 原文：[https://towardsdatascience.com/biases-in-recommender-systems-top-challenges-and-recent-breakthroughs-edcda59d30bf](https://towardsdatascience.com/biases-in-recommender-systems-top-challenges-and-recent-breakthroughs-edcda59d30bf)

## 在从偏见数据中构建无偏模型的持续探索背后

[](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)[![Samuel Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------) [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------) ·阅读时间7分钟·2023年2月23日

--

![](../Images/9efdc9be3f175bee78b1c8774b8b4d96.png)

作者使用 Midjourney 生成的图像

[推荐系统](/learning-to-rank-a-primer-40d2ff9960af)已经在我们的日常生活中无处不在，从在线购物到社交媒体再到娱乐平台。这些系统使用复杂的算法来分析历史用户互动数据，并根据他们的推断偏好和行为进行推荐。

尽管这些系统在帮助用户发现新内容或产品方面极其有用，但它们并非没有缺陷：推荐系统存在各种形式的偏差，这可能导致糟糕的推荐，从而带来糟糕的用户体验。因此，当前关于推荐系统的主要研究方向之一就是如何消除这些偏差。

在本文中，我们将深入探讨推荐系统中五种最常见的偏差，并了解来自 Google、YouTube、Netflix、快手等公司的最新研究。

让我们开始吧。

## 1 — 点击诱饵偏差

无论何处有娱乐平台，就会有[点击诱饵](https://medium.com/mind-cafe/im-boycotting-these-forms-of-youtube-clickbait-8148b0d6363b): 引人注目的或误导性的标题或视频缩略图，旨在吸引用户注意并诱使他们点击，而不提供任何实际价值。 *“你绝对不会相信接下来发生了什么！”*

如果我们使用点击作为正面反馈来训练排名模型，那么这个模型自然会偏向点击诱饵。这是不好的，因为这样的模型会进一步向用户推广更多的点击诱饵，从而放大其造成的伤害。

一种去除点击诱饵排名模型偏差的解决方案，由 [Covington 等人（2016）](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) 在 YouTube 视频推荐的背景下提出，是**加权逻辑回归**，其中权重是正训练样本（有点击的印象）的观看时间，而负训练样本（没有点击的印象）的权重为 1。

从数学上讲，可以证明这样的加权逻辑回归模型学习的赔率大致上是视频的预期观看时间。在服务时，视频根据其预测的赔率进行排名，这导致预期观看时间长的视频被排在推荐列表的顶部，而点击诱饵（预期观看时间最低）则被排在底部。

不幸的是，Covington 等人没有分享他们所有的实验结果，但他们确实表示，加权逻辑回归的表现“好得多”比直接预测点击要好。

## 2 — 时长偏差

加权逻辑回归在解决点击诱饵问题上表现良好，但它引入了一个新问题：时长偏差。简单来说，较长的视频总是倾向于被观看更长时间，这不仅仅是因为它们更相关，而是因为它们更长。

想象一个视频目录，包含 10 秒的短视频和 2 小时的长视频。在这两种情况下，10 秒的观看时间意味着完全不同的事情：在前者中是强正信号，而在后者中是弱正信号（甚至可能是负信号）。然而，Covington 方法无法区分这两种情况，并且会偏向于长视频（因为它们生成更长的观看时间，仅仅是因为它们更长）。

一种解决时长偏差的方案，由 [Zhan 等人（2022）](https://dl.acm.org/doi/abs/10.1145/3534678.3539092) 从快手提出，是**基于分位的观看时间预测**。

关键思想是将所有视频分到时长分位中，然后将时长分位中的所有观看时间也分到分位中。例如，使用 10 个分位，这种分配可能看起来像这样：

[PRE0]

通过将所有时间间隔转化为分位，模型可以理解 10 秒在后一个例子中是“高”的，而在前一个例子中是“低”的，因此作者的假设。在训练时，我们向模型提供视频的分位，并要求其预测观看分位。在推理时，我们仅按预测的观看时间对所有视频进行排序，这样现在将与视频时长本身去偏。

确实，这种方法似乎有效。通过 A/B 测试，作者报告

+   与加权逻辑回归（Covington 等人提出的想法）相比，总观看时间提高了 0.5%，以及

+   与直接预测观看时间相比，总观看时间提高了 0.75%。

结果显示，去除时长偏见在同时提供长视频和短视频的平台上可以是一种有效的方法。也许有点反直觉的是，去除对长视频的偏见实际上改善了整体用户观看时间。

## 3 — 位置偏见

位置偏见意味着排名最高的项目之所以获得最多的参与，不是因为它们实际上是最适合用户的内容，而仅仅因为它们排名最高，用户开始盲目相信他们看到的排名。模型预测变成了自我实现的预言，但这并不是我们真正想要的。我们想要预测用户的需求，而不是让他们想要我们预测的内容。

位置偏见可以通过诸如排名随机化、干预采集或使用排名本身作为特征等技术来缓解，我在我的其他帖子中有介绍 [这里](/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9)。

特别棘手的是，位置偏见总会让我们的模型在纸面上看起来比实际更好。我们的模型可能会慢慢降级，但我们在为时已晚（用户已经流失）之前不会知道发生了什么。因此，在使用推荐系统时，监控系统的多个质量指标，包括量化用户保留和推荐多样性的指标，是非常重要的。

## 4 — 人气偏见

人气偏见是指模型倾向于给那些总体上更受欢迎的项目（因为它们被更多用户评价）更高的排名，而不是基于这些项目的实际质量或对特定用户的相关性。这可能导致排名扭曲，较少受欢迎或小众的项目可能更适合用户的偏好，却未得到充分考虑。

[Yi et al (2019)](https://research.google/pubs/pub48840/) 来自 Google 提出了一个简单但有效的算法调整，以去除视频推荐模型中的人气偏见。在模型训练过程中，他们将逻辑回归层中的 logits 替换为：

[PRE1]

其中

+   `logit(u,v)` 是用户 u 参与视频 v 的 logit 函数（即 log-odds），并且

+   `log(P(v))` 是视频 v 的 log-frequency。

当然，右侧等价于：

[PRE2]

换句话说，他们仅仅通过视频概率来归一化用户/视频对的预测赔率。来自热门视频的极高赔率与来自不那么热门视频的中等高赔率一样重要。这就是全部的魔力。

的确，这种魔力似乎有效：在在线 A/B 测试中，作者发现使用去偏排名模型，整体用户参与度提高了 0.37%。

## 5 — 单一兴趣偏见

假设你主要观看戏剧电影，但有时也喜欢看喜剧，偶尔也会看纪录片。你有多个兴趣，但一个旨在最大化观看时间的排名模型可能会过分强调戏剧电影，因为那是你最可能参与的内容。这就是**单一兴趣偏差**，即模型未能理解用户本身具有多重兴趣和偏好。

为了消除单一兴趣偏差，需要对排名模型进行校准。校准简单来说，就是如果你80%的时间观看戏剧电影，那么模型的前100个推荐应该实际包含大约80部戏剧电影（而不是100部）。

Netflix的[Harald Steck](https://dl.acm.org/doi/10.1145/3240323.3240372)（2018年）展示了使用一种名为Platt scaling的简单后处理技术对模型进行校准的好处。他呈现了实验结果，展示了该方法在改善Netflix推荐的校准方面的有效性，并通过KL散度分数进行了量化。结果电影推荐更加多样化——实际上，与实际用户偏好一样多样化——并且导致总体观看时间的改善。

## 最终思考

记忆回顾：

1.  点击诱饵偏差意味着模型偏向于点击诱饵内容。

1.  时长偏差意味着模型偏向于长视频（而不是短视频）。

1.  位置偏差意味着模型偏向于自身的预测，而不是用户真正想要的内容。

1.  流行偏差意味着模型偏向于流行内容，而不是特定用户的独特兴趣。

1.  单一兴趣偏差意味着模型无法同时学习多个用户兴趣。

偏差的列表很长——我们这里只是触及了表面——并且它也在不断演变。在某些情况下，解决一个偏差甚至可能引入新的偏差，就像我们在点击诱饵和时长偏差中看到的那样。

因此，提出创新的方法来量化和减轻这些偏差仍然是今天排名工程师最重要的任务之一。仅仅假设排名模型是中立或客观的并不够：它们总是会反映出训练数据中存在的偏差。

[## 不想依赖Medium的算法？注册一下吧。

### 不想依赖Medium的算法？注册一下吧。通过注册我的电子邮件，确保不会错过我的下一篇文章……

[medium.com](https://medium.com/@samuel.flender/subscribe?source=post_page-----edcda59d30bf--------------------------------)
