- en: 'Unraveling the Design Pattern of Physics-Informed Neural Networks: Part 06'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­å¼€ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œè®¾è®¡æ¨¡å¼çš„é¢çº±ï¼šç¬¬06éƒ¨åˆ†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)
- en: Bring causality to PINN training
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°†å› æœå…³ç³»å¼•å…¥PINNè®­ç»ƒ
- en: '[](https://shuaiguo.medium.com/?source=post_page-----bcb3557199e2--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----bcb3557199e2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bcb3557199e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bcb3557199e2--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----bcb3557199e2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----bcb3557199e2--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----bcb3557199e2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bcb3557199e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bcb3557199e2--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----bcb3557199e2--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bcb3557199e2--------------------------------)
    Â·9 min readÂ·Jun 13, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----bcb3557199e2--------------------------------)
    Â·é˜…è¯»æ—¶é—´9åˆ†é’ŸÂ·2023å¹´6æœˆ13æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/0c5a39882aa4755f7434a2421e21550e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c5a39882aa4755f7434a2421e21550e.png)'
- en: Photo by [Delano Ramdas](https://unsplash.com/@delanodzr?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”±[Delano Ramdas](https://unsplash.com/@delanodzr?utm_source=medium&utm_medium=referral)æä¾›ï¼Œæ¥æºäº[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Welcome to the 6th blog of this series, where we continue our exciting journey
    of exploring ***design patterns*** of physics-informed neural networks (PINN)ğŸ™Œ
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿æ¥åˆ°æœ¬ç³»åˆ—çš„ç¬¬å…­ç¯‡åšå®¢ï¼Œæˆ‘ä»¬å°†ç»§ç»­æ¢ç´¢ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNï¼‰çš„***è®¾è®¡æ¨¡å¼***ğŸ™Œ
- en: 'In this episode, we will talk about bringing **causality** to the training
    of physics-informed neural nets. As suggested by the paper we will look at today:
    respecting causality is all you need!'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€é›†é‡Œï¼Œæˆ‘ä»¬å°†è®¨è®ºå°†**å› æœå…³ç³»**å¼•å…¥ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œè®­ç»ƒçš„å†…å®¹ã€‚æ­£å¦‚æˆ‘ä»¬ä»Šå¤©å°†è¦æŸ¥çœ‹çš„è®ºæ–‡æ‰€å»ºè®®çš„ï¼šå°Šé‡å› æœå…³ç³»å°±æ˜¯ä½ æ‰€éœ€çš„ä¸€åˆ‡ï¼
- en: As always, letâ€™s begin by talking about the current matters in question, then
    move on to the suggested remedies, the evaluation procedure, and the advantages
    and disadvantages of the proposed method. Finally, we will conclude the blog by
    exploring potential opportunities that lie ahead.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€å¦‚æ—¢å¾€ï¼Œè®©æˆ‘ä»¬é¦–å…ˆè®¨è®ºå½“å‰çš„é—®é¢˜ï¼Œç„¶åè½¬åˆ°å»ºè®®çš„è§£å†³æ–¹æ¡ˆã€è¯„ä¼°ç¨‹åºä»¥åŠæ‰€ææ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€‚æœ€åï¼Œæˆ‘ä»¬å°†é€šè¿‡æ¢ç´¢æ½œåœ¨çš„æœºä¼šæ¥ç»“æŸåšå®¢ã€‚
- en: 'As this series continues to expand, the collection of PINN design patterns
    grows even richer*ğŸ™Œ* Hereâ€™s a sneak peek at what awaits you:'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: éšç€è¿™ä¸€ç³»åˆ—çš„ä¸æ–­æ‰©å±•ï¼ŒPINNè®¾è®¡æ¨¡å¼çš„é›†åˆå˜å¾—æ›´åŠ ä¸°å¯Œ*ğŸ™Œ* è¿™é‡Œæ˜¯ä¸€äº›å³å°†åˆ°æ¥çš„å†…å®¹çš„é¢„è§ˆï¼š
- en: ''
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼01ï¼šä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼02ï¼šåŠ¨æ€è§£åŒºé—´æ‰©å±•](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: ''
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 03: Training PINN with gradient boosting](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼03ï¼šä½¿ç”¨æ¢¯åº¦æå‡è®­ç»ƒPINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 04: Gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼04ï¼šæ¢¯åº¦å¢å¼ºçš„PINNå­¦ä¹ ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: ''
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 05: Automated hyperparameter tuning](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼05ï¼šè‡ªåŠ¨åŒ–è¶…å‚æ•°è°ƒæ•´](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼07ï¼šä½¿ç”¨PINNçš„ä¸»åŠ¨å­¦ä¹ ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Letâ€™s dive in!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ï¼
- en: 1\. Paper at a glance ğŸ”
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. è®ºæ–‡æ¦‚è¿° ğŸ”
- en: '**Title**: Respecting causality is all you need for training physics-informed
    neural networks'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‡é¢˜**ï¼šå°Šé‡å› æœæ€§æ˜¯è®­ç»ƒç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œæ‰€éœ€çš„ä¸€åˆ‡'
- en: '**Authors**: S. Wang, S. Sankaran, P. Perdikaris'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½œè€…**ï¼šS. Wang, S. Sankaran, P. Perdikaris'
- en: '**Institutes**: University of Pennsylvania'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœºæ„**ï¼šå®¾å¤•æ³•å°¼äºšå¤§å­¦'
- en: '**Link**: [arXiv](https://arxiv.org/abs/2203.07404), [GitHub](https://github.com/PredictiveIntelligenceLab/CausalPINNs)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é“¾æ¥**ï¼š[arXiv](https://arxiv.org/abs/2203.07404), [GitHub](https://github.com/PredictiveIntelligenceLab/CausalPINNs)'
- en: 2\. Design pattern ğŸ¨
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. è®¾è®¡æ¨¡å¼ ğŸ¨
- en: 2.1 Problem ğŸ¯
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 é—®é¢˜ ğŸ¯
- en: Physics-informed neural networks (PINNs) are a major leap in combining observational
    data and physical laws across various fields. In practice, however, they are often
    observed to be unable to tackle high nonlinearity, multi-scale dynamics, or chaotic
    problems, and tend to converge to erroneous solutions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNsï¼‰åœ¨ç»“åˆè§‚å¯Ÿæ•°æ®å’Œç‰©ç†æ³•åˆ™æ–¹é¢æ˜¯ä¸€ä¸ªé‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œå®ƒä»¬å¸¸å¸¸æ— æ³•å¤„ç†é«˜åº¦éçº¿æ€§ã€å¤šå°ºåº¦åŠ¨æ€æˆ–æ··æ²Œé—®é¢˜ï¼Œå¹¶è¶‹å‘äºæ”¶æ•›åˆ°é”™è¯¯çš„è§£ã€‚
- en: Why this is the case?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆä¼šè¿™æ ·å‘¢ï¼Ÿ
- en: Well, the fundamental issue lies in the **violation of causality** in the PINN
    formulations, as revealed by the current paper.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œæ ¹æœ¬é—®é¢˜åœ¨äºå½“å‰è®ºæ–‡æ­ç¤ºçš„PINNå…¬å¼ä¸­çš„**å› æœæ€§è¿èƒŒ**ã€‚
- en: Causality, in the physical sense, implies that the state at a future time point
    depends on the state at the current or past time points. In PINN training, however,
    this principle may not hold true; these networks might be implicitly biased towards
    first approximating PDE solutions at future states before even resolving initial
    conditions, essentially â€œjumping aheadâ€ in time and thereby violating causality.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰©ç†æ„ä¹‰ä¸Šçš„å› æœæ€§æ„å‘³ç€æœªæ¥æ—¶åˆ»çš„çŠ¶æ€ä¾èµ–äºå½“å‰æˆ–è¿‡å»æ—¶åˆ»çš„çŠ¶æ€ã€‚ç„¶è€Œï¼Œåœ¨PINNè®­ç»ƒä¸­ï¼Œè¿™ä¸€åŸåˆ™å¯èƒ½ä¸æˆç«‹ï¼›è¿™äº›ç½‘ç»œå¯èƒ½éšå«åå‘äºé¦–å…ˆåœ¨æœªæ¥çŠ¶æ€ä¸‹è¿‘ä¼¼PDEè§£ï¼Œç„¶åæ‰è§£å†³åˆå§‹æ¡ä»¶ï¼Œå®è´¨ä¸Šæ˜¯â€œè·³è¿‡â€æ—¶é—´ï¼Œä»è€Œè¿åå› æœæ€§ã€‚
- en: In contrast, traditional numerical methods inherently preserve causality via
    a time-marching strategy. For instance, when discretizing PDE in time, these methods
    ensure the solution at time *t* is resolved before approximating the solution
    at time *t* + âˆ†*t*. Hence, each future state is sequentially built upon the resolved
    past states, thus preserving the principle of causality.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¼ ç»Ÿçš„æ•°å€¼æ–¹æ³•é€šè¿‡æ—¶é—´æ¨è¿›ç­–ç•¥å›ºæœ‰åœ°ä¿æŒå› æœæ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨æ—¶é—´ä¸Šç¦»æ•£åŒ–PDEæ—¶ï¼Œè¿™äº›æ–¹æ³•ç¡®ä¿åœ¨è¿‘ä¼¼æ—¶é—´ *t* + âˆ†*t* æ—¶çš„è§£ä¹‹å‰è§£å†³æ—¶é—´
    *t* æ—¶çš„è§£ã€‚å› æ­¤ï¼Œæ¯ä¸ªæœªæ¥çŠ¶æ€æ˜¯ä¾èµ–äºå·²è§£å†³çš„è¿‡å»çŠ¶æ€ï¼Œä»è€Œä¿æŒå› æœæ€§åŸåˆ™ã€‚
- en: 'This understanding of the problem brings us to an intriguing question: how
    do we rectify this violation of causality in PINNs, bringing them in line with
    fundamental physical laws?'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹è¿™ä¸ªé—®é¢˜çš„ç†è§£å¼•å‡ºäº†ä¸€ä¸ªæœ‰è¶£çš„é—®é¢˜ï¼šæˆ‘ä»¬å¦‚ä½•çº æ­£PINNä¸­çš„å› æœæ€§è¿èƒŒï¼Œä½¿å…¶ç¬¦åˆåŸºæœ¬ç‰©ç†æ³•åˆ™ï¼Ÿ
- en: '![](../Images/3bb498e14a463d651a5fcfaa8d26ffba.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3bb498e14a463d651a5fcfaa8d26ffba.png)'
- en: PINN workflow. Naive PINN does not have â€œcausalityâ€ baked in. One simple yet
    effective strategy is to dynamically weight the PDE residual losses at different
    time instances. (Image by this blog author)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PINNå·¥ä½œæµç¨‹ã€‚ç®€å•çš„PINNæ²¡æœ‰â€œå› æœæ€§â€åµŒå…¥å…¶ä¸­ã€‚ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç­–ç•¥æ˜¯åŠ¨æ€åŠ æƒä¸åŒæ—¶é—´å®ä¾‹çš„PDEæ®‹å·®æŸå¤±ã€‚ï¼ˆå›¾åƒç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: 2.2 Solution ğŸ’¡
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 è§£å†³æ–¹æ¡ˆ ğŸ’¡
- en: The key idea here is to **re-formulate the PINN loss function**.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„å…³é”®æ€æƒ³æ˜¯**é‡æ–°åˆ¶å®šPINNæŸå¤±å‡½æ•°**ã€‚
- en: Specifically, we can introduce a dynamic weighting scheme to account for different
    contributions of PDE residual loss evaluated at different temporal locations.
    Letâ€™s break it down using illustrations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥åŠ¨æ€åŠ æƒæ–¹æ¡ˆï¼Œä»¥è€ƒè™‘åœ¨ä¸åŒæ—¶é—´ä½ç½®è¯„ä¼°çš„PDEæ®‹å·®æŸå¤±çš„ä¸åŒè´¡çŒ®ã€‚è®©æˆ‘ä»¬é€šè¿‡æ’å›¾æ¥è¯¦ç»†åˆ†æã€‚
- en: 'For simplicity, letâ€™s assume the collocation points are uniformly sampled in
    the spatial-temporal domain of our simulation, as illustrated in the figure below:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œæˆ‘ä»¬å‡è®¾åœ¨ç©ºé—´-æ—¶é—´åŸŸä¸­çš„é…ç‚¹æ˜¯å‡åŒ€é‡‡æ ·çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
- en: '![](../Images/c1ca3613665e64381681b8090b2bf771.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1ca3613665e64381681b8090b2bf771.png)'
- en: Total PDE residual loss is calculated over all collocation points, and its gradient
    values are used to drive network parameter optimization. (Image by this blog author)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»PDEæ®‹å·®æŸå¤±æ˜¯è®¡ç®—åœ¨æ‰€æœ‰é…ç‚¹ä¸Šçš„ï¼Œå…¶æ¢¯åº¦å€¼ç”¨äºé©±åŠ¨ç½‘ç»œå‚æ•°ä¼˜åŒ–ã€‚ï¼ˆå›¾åƒç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: To proceed with one step of gradient descent, we must first calculate the cumulative
    PDE residual loss across all collocation points. One specific way to do that is
    by first calculating the losses related to the collocation points sampled at individual
    time instances, and then performing a â€œsimple sumâ€ to get the total loss. The
    following gradient descent step can then be conducted based on the calculated
    total loss to optimize the PINN weights.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¿›è¡Œä¸€æ­¥æ¢¯åº¦ä¸‹é™ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆè®¡ç®—æ‰€æœ‰é…ç‚¹çš„ç´¯è®¡PDEæ®‹å·®æŸå¤±ã€‚å…·ä½“åšæ³•æ˜¯é¦–å…ˆè®¡ç®—ä¸åœ¨å„ä¸ªæ—¶é—´ç‚¹é‡‡æ ·çš„é…ç‚¹ç›¸å…³çš„æŸå¤±ï¼Œç„¶åè¿›è¡Œâ€œç®€å•çš„æ±‚å’Œâ€ä»¥è·å¾—æ€»æŸå¤±ã€‚æ¥ä¸‹æ¥çš„æ¢¯åº¦ä¸‹é™æ­¥éª¤å¯ä»¥åŸºäºè®¡ç®—å¾—åˆ°çš„æ€»æŸå¤±æ¥ä¼˜åŒ–PINNæƒé‡ã€‚
- en: Of course, the exact order of summation over collocation points doesnâ€™t influence
    the total loss computation; all methods yield the same result. However, the decision
    to group loss calculations by temporal order is purposeful, designed to emphasize
    the element of â€˜temporalityâ€™. This concept is crucial for understanding the proposed
    causal training strategy.
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œé…ç‚¹çš„æ±‚å’Œé¡ºåºä¸ä¼šå½±å“æ€»æŸå¤±çš„è®¡ç®—ï¼›æ‰€æœ‰æ–¹æ³•éƒ½ä¼šå¾—åˆ°ç›¸åŒçš„ç»“æœã€‚ç„¶è€Œï¼ŒæŒ‰æ—¶é—´é¡ºåºåˆ†ç»„æŸå¤±è®¡ç®—çš„å†³å®šæ˜¯æœ‰ç›®çš„çš„ï¼Œæ—¨åœ¨å¼ºè°ƒâ€˜æ—¶é—´æ€§â€™çš„å…ƒç´ ã€‚è¿™ä¸ªæ¦‚å¿µå¯¹äºç†è§£æå‡ºçš„å› æœè®­ç»ƒç­–ç•¥è‡³å…³é‡è¦ã€‚
- en: In this process, the PDE residual losses evaluated at different temporal locations
    are treated equally. meaning that all temporal residual losses are simultaneously
    minimized.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œè¯„ä¼°åœ¨ä¸åŒæ—¶é—´ä½ç½®çš„PDEæ®‹å·®æŸå¤±è¢«è§†ä¸ºåŒç­‰é‡è¦ã€‚è¿™æ„å‘³ç€æ‰€æœ‰æ—¶é—´æ®‹å·®æŸå¤±åŒæ—¶è¢«æœ€å°åŒ–ã€‚
- en: This approach, however, risks the PINN violating temporal causality, as it doesnâ€™t
    enforce a chronological regularization for minimizing the temporal residual loss
    at successive time intervals.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨é£é™©ï¼Œå¯èƒ½ä¼šå¯¼è‡´PINNè¿åæ—¶é—´å› æœå…³ç³»ï¼Œå› ä¸ºå®ƒæ²¡æœ‰å¯¹åœ¨è¿ç»­æ—¶é—´é—´éš”æœ€å°åŒ–æ—¶é—´æ®‹å·®æŸå¤±è¿›è¡Œæ—¶é—´ä¸Šçš„è§„èŒƒåŒ–ã€‚
- en: So, how can we coax PINN to adhere to the temporal precedence during training?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•å¼•å¯¼PINNåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éµå¾ªæ—¶é—´ä¼˜å…ˆåŸåˆ™å‘¢ï¼Ÿ
- en: The secret is in **selectively weighting individual temporal residual losses**.
    For instance, suppose that at the current iteration, we want the PINN to focus
    on approximating the solutions at time instance *t*â‚. Then, we could simply put
    a higher weight on Láµ£(*t*â‚), which is the temporal residual lossat *t*â‚. This
    way, Láµ£(*t*â‚) will become a dominant component in the final total loss, and as
    a result, the optimization algorithm will prioritize minimizing Láµ£(*t*â‚), which
    aligns with our goal of approximating solutions at time instance *t*â‚ first.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç§˜è¯€åœ¨äº**æœ‰é€‰æ‹©åœ°åŠ æƒå„ä¸ªæ—¶é—´æ®‹å·®æŸå¤±**ã€‚ä¾‹å¦‚ï¼Œå‡è®¾åœ¨å½“å‰è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›PINNä¸“æ³¨äºåœ¨æ—¶é—´ç‚¹*t*â‚å¤„é€¼è¿‘è§£ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°åœ¨Láµ£(*t*â‚)ä¸ŠåŠ ä¸Šæ›´é«˜çš„æƒé‡ï¼Œè¿™å°±æ˜¯åœ¨*t*â‚å¤„çš„æ—¶é—´æ®‹å·®æŸå¤±ã€‚è¿™æ ·ï¼ŒLáµ£(*t*â‚)å°†æˆä¸ºæœ€ç»ˆæ€»æŸå¤±ä¸­çš„ä¸»å¯¼æˆåˆ†ï¼Œç»“æœæ˜¯ä¼˜åŒ–ç®—æ³•å°†ä¼˜å…ˆæœ€å°åŒ–Láµ£(*t*â‚)ï¼Œè¿™ä¸æˆ‘ä»¬é¦–å…ˆåœ¨æ—¶é—´ç‚¹*t*â‚é€¼è¿‘è§£çš„ç›®æ ‡ä¸€è‡´ã€‚
- en: '![](../Images/3e565859efb6486eea4297bd96b2a18d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e565859efb6486eea4297bd96b2a18d.png)'
- en: By assigning weights to temporal residual loss at different time instances,
    we can steer the optimizer to focus on minimizing loss at our desired time instances.
    (Image by this blog author)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åœ¨ä¸åŒæ—¶é—´ç‚¹åˆ†é…æ—¶é—´æ®‹å·®æŸå¤±çš„æƒé‡ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å¯¼ä¼˜åŒ–å™¨ä¸“æ³¨äºåœ¨æˆ‘ä»¬æœŸæœ›çš„æ—¶é—´ç‚¹æœ€å°åŒ–æŸå¤±ã€‚ï¼ˆå›¾ç‰‡ç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: In the subsequent iteration, we shift our focus to the solutions at time instance
    tâ‚‚. By increasing the weight on Láµ£(tâ‚‚), it now becomes the main factor in the
    total loss calculation. The optimization algorithm is thus directed towards minimizing
    Láµ£(tâ‚‚), improving the prediction accuracy of the solutions at tâ‚‚.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨éšåçš„è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬å°†æ³¨æ„åŠ›è½¬å‘æ—¶é—´ç‚¹*t*â‚‚å¤„çš„è§£ã€‚é€šè¿‡å¢åŠ Láµ£(*t*â‚‚)çš„æƒé‡ï¼Œå®ƒç°åœ¨æˆä¸ºæ€»æŸå¤±è®¡ç®—ä¸­çš„ä¸»è¦å› ç´ ã€‚å› æ­¤ï¼Œä¼˜åŒ–ç®—æ³•è¢«å¼•å¯¼å»æœ€å°åŒ–Láµ£(*t*â‚‚)ï¼Œä»è€Œæé«˜äº†åœ¨*t*â‚‚å¤„è§£çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚
- en: '![](../Images/838ffec64f1ec82607de97a20824cbe4.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/838ffec64f1ec82607de97a20824cbe4.png)'
- en: (Image by this blog author)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›¾ç‰‡ç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: As can be seen from our previous walk-through, varying the weights assigned
    to temporal residual losses at different time instances enables us to direct the
    PINN to approximate solutions at our chosen time instances.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æˆ‘ä»¬ä¹‹å‰çš„æ¼”ç¤ºå¯ä»¥çœ‹å‡ºï¼Œé€šè¿‡æ”¹å˜åœ¨ä¸åŒæ—¶é—´ç‚¹åˆ†é…çš„æ—¶é—´æ®‹å·®æŸå¤±æƒé‡ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å¯¼PINNåœ¨æˆ‘ä»¬é€‰æ‹©çš„æ—¶é—´ç‚¹é€¼è¿‘è§£ã€‚
- en: So, how does this assist in incorporating a causal structure into PINN training?
    It turns out, we can design a causal training algorithm (as proposed in the paper),
    such that **the weight for the temporal residual loss at time *t*, *i.e.*,Láµ£(*t*),is
    significant only when the losses before *t* (Láµ£(*t-1*), Láµ£(*t-2*), etc.) are sufficiently
    small**. This effectively means that the neural network begins minimizing Láµ£(t)
    only when it has achieved satisfactory approximation accuracy for prior steps.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œè¿™å¦‚ä½•å¸®åŠ©å°†å› æœç»“æ„çº³å…¥PINNè®­ç»ƒä¸­å‘¢ï¼Ÿäº‹å®è¯æ˜ï¼Œæˆ‘ä»¬å¯ä»¥è®¾è®¡ä¸€ç§å› æœè®­ç»ƒç®—æ³•ï¼ˆå¦‚è®ºæ–‡ä¸­æå‡ºçš„ï¼‰ï¼Œä½¿å¾—**æ—¶é—´*t*çš„æ—¶é—´æ®‹å·®æŸå¤±çš„æƒé‡Láµ£(*t*)ï¼Œåªæœ‰åœ¨*t*ä¹‹å‰çš„æŸå¤±ï¼ˆLáµ£(*t-1*),
    Láµ£(*t-2*), ç­‰ï¼‰è¶³å¤Ÿå°æ—¶æ‰æ˜¾è‘—**ã€‚è¿™æœ‰æ•ˆåœ°æ„å‘³ç€ç¥ç»ç½‘ç»œä»…åœ¨å¯¹å…ˆå‰æ­¥éª¤çš„è¿‘ä¼¼å‡†ç¡®åº¦ä»¤äººæ»¡æ„æ—¶æ‰å¼€å§‹æœ€å°åŒ–Láµ£(t)ã€‚
- en: 'To determine the weight, the paper proposed a simple formula: the weight Ï‰áµ¢
    is set to be inversely exponentially proportional to the magnitude of the cumulative
    temporal residual loss from all the previous time instances. This ensures that
    the weight Ï‰áµ¢ will only be active (i.e., with a sufficiently large value) when
    the cumulative loss from all previous time instances is small, i.e., PINN can
    already accurately approximate solutions at previous time steps. This is how *temporal
    causality* is reflected in the PINN training.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç¡®å®šæƒé‡ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªç®€å•çš„å…¬å¼ï¼šæƒé‡Ï‰áµ¢è®¾ç½®ä¸ºä¸æ‰€æœ‰ä¹‹å‰æ—¶é—´å®ä¾‹çš„ç´¯è®¡æ—¶é—´æ®‹å·®æŸå¤±çš„å¤§å°æˆåå‘æŒ‡æ•°æ¯”ä¾‹ã€‚è¿™ç¡®ä¿äº†å½“æ‰€æœ‰ä¹‹å‰æ—¶é—´å®ä¾‹çš„ç´¯è®¡æŸå¤±è¾ƒå°æ—¶ï¼Œæƒé‡Ï‰áµ¢æ‰ä¼šæ´»è·ƒï¼ˆå³ï¼Œå…·æœ‰è¶³å¤Ÿå¤§çš„å€¼ï¼‰ï¼Œå³PINNå·²ç»èƒ½å¤Ÿå‡†ç¡®åœ°è¿‘ä¼¼ä¹‹å‰æ—¶é—´æ­¥çš„è§£ã€‚è¿™å°±æ˜¯*æ—¶é—´å› æœå…³ç³»*åœ¨PINNè®­ç»ƒä¸­ä½“ç°çš„æ–¹å¼ã€‚
- en: '![](../Images/757433ba91f9576b3faf5815e50f1312.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/757433ba91f9576b3faf5815e50f1312.png)'
- en: (Image by this blog author)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›¾ç‰‡æ¥è‡ªåšå®¢ä½œè€…ï¼‰
- en: 'With all components explained, we can piece together the full causal training
    algorithm as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è§£é‡Šäº†æ‰€æœ‰ç»„ä»¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†å®Œæ•´çš„å› æœè®­ç»ƒç®—æ³•æ‹¼å‡‘å¦‚ä¸‹ï¼š
- en: '![](../Images/3f46749a291db166ce65e1224516938d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f46749a291db166ce65e1224516938d.png)'
- en: Illustration of the proposed causal training algorithm in the paper. (Image
    by this blog author)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡ä¸­æå‡ºçš„å› æœè®­ç»ƒç®—æ³•çš„ç¤ºæ„å›¾ã€‚ï¼ˆå›¾ç‰‡æ¥è‡ªåšå®¢ä½œè€…ï¼‰
- en: 'Before we conclude this section, there are two remarks worth mentioning:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»“æŸæœ¬èŠ‚ä¹‹å‰ï¼Œæœ‰ä¸¤ä¸ªå€¼å¾—æåŠçš„å¤‡æ³¨ï¼š
- en: The paper suggested using the magnitude of Ï‰áµ¢ as the stopping criterion for
    PINN training. Specifically, when all Ï‰áµ¢â€™s are larger than a pre-defined threshold
    Î´, the training may be deemed completed. The recommended value for Î´ is 0.99.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®ºæ–‡å»ºè®®ä½¿ç”¨Ï‰áµ¢çš„å¤§å°ä½œä¸ºPINNè®­ç»ƒçš„åœæ­¢æ ‡å‡†ã€‚å…·ä½“æ¥è¯´ï¼Œå½“æ‰€æœ‰Ï‰áµ¢çš„å€¼éƒ½å¤§äºé¢„å®šä¹‰çš„é˜ˆå€¼Î´æ—¶ï¼Œè®­ç»ƒå¯ä»¥è®¤ä¸ºå®Œæˆã€‚æ¨èçš„Î´å€¼ä¸º0.99ã€‚
- en: Selecting a proper value for Îµ is important. Although this value can be tuned
    via conventional hyperparameter tuning, the paper recommended an annealing strategy
    for adjusting Îµ. Details can be found in the [original paper](https://arxiv.org/abs/2203.07404)
    (section 3).
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©åˆé€‚çš„Îµå€¼å¾ˆé‡è¦ã€‚è™½ç„¶å¯ä»¥é€šè¿‡ä¼ ç»Ÿçš„è¶…å‚æ•°è°ƒæ•´æ¥è°ƒæ•´æ­¤å€¼ï¼Œä½†è®ºæ–‡æ¨èäº†ä¸€ç§é€€ç«ç­–ç•¥æ¥è°ƒæ•´Îµã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚è§[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2203.07404)ï¼ˆç¬¬3èŠ‚ï¼‰ã€‚
- en: 2.3 Why the solution might work ğŸ› ï¸
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 ä¸ºä»€ä¹ˆè¿™ä¸ªè§£å†³æ–¹æ¡ˆå¯èƒ½æœ‰æ•ˆ ğŸ› ï¸
- en: By dynamically weighting temporal residual losses evaluated at different time
    instances, the proposed algorithm is able to steer the PINN training to first
    approximate PDE solutions at earlier times before even trying to resolve the solution
    at later times.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åŠ¨æ€åŠ æƒåœ¨ä¸åŒæ—¶é—´å®ä¾‹è¯„ä¼°çš„æ—¶é—´æ®‹å·®æŸå¤±ï¼Œæå‡ºçš„ç®—æ³•èƒ½å¤Ÿå¼•å¯¼PINNè®­ç»ƒé¦–å…ˆåœ¨è¾ƒæ—©çš„æ—¶é—´è¿‘ä¼¼PDEè§£ï¼Œç„¶åå†å°è¯•è§£å†³è¾ƒæ™šæ—¶é—´çš„è§£ã€‚
- en: This property facilitates the explicit incorporation of temporal causality into
    the PINN training and constitutes the key factor in potentially more accurate
    simulations of physical systems.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå±æ€§æœ‰åŠ©äºå°†æ—¶é—´å› æœå…³ç³»æ˜ç¡®åœ°èå…¥PINNè®­ç»ƒä¸­ï¼Œå¹¶æ„æˆæ½œåœ¨æ›´å‡†ç¡®çš„ç‰©ç†ç³»ç»Ÿæ¨¡æ‹Ÿçš„å…³é”®å› ç´ ã€‚
- en: 2.4 Benchmark â±ï¸
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 åŸºå‡† â±ï¸
- en: The paper considered a total of 3 different benchmark equations. All problems
    are forward problems where PINN is used to solve the PDEs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡è€ƒè™‘äº†æ€»å…±3ä¸ªä¸åŒçš„åŸºå‡†æ–¹ç¨‹ã€‚æ‰€æœ‰é—®é¢˜éƒ½æ˜¯å‰å‘é—®é¢˜ï¼Œå…¶ä¸­PINNç”¨äºæ±‚è§£PDEã€‚
- en: 'Lorenz system: these equations arise in studies of convection and instability
    in planetary atmospheric convection. Lorenz system exhibits strong sensitivity
    to its initial conditions, and it is known to be challenging for vanilla PINN.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ´›ä¼¦å…¹ç³»ç»Ÿï¼šè¿™äº›æ–¹ç¨‹å‡ºç°åœ¨è¡Œæ˜Ÿå¤§æ°”å¯¹æµå’Œä¸ç¨³å®šæ€§çš„ç ”ç©¶ä¸­ã€‚æ´›ä¼¦å…¹ç³»ç»Ÿå¯¹å…¶åˆå§‹æ¡ä»¶å…·æœ‰å¼ºçƒˆçš„æ•æ„Ÿæ€§ï¼Œä¸”å¯¹æ™®é€šPINNæ¥è¯´æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚
- en: '![](../Images/24033d97a935bef0fb3fd3f9d1aa3c90.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24033d97a935bef0fb3fd3f9d1aa3c90.png)'
- en: 'Kuramotoâ€“Sivashinsky equation: this equation describes the dynamics of various
    wave-like patterns, such as flames, chemical reactions, and surface waves. It
    is known to exhibit a wealth of spatiotemporal chaotic behaviors.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuramotoâ€“Sivashinsky æ–¹ç¨‹ï¼šè¯¥æ–¹ç¨‹æè¿°äº†å„ç§æ³¢åŠ¨æ¨¡å¼çš„åŠ¨æ€ï¼Œå¦‚ç«ç„°ã€åŒ–å­¦ååº”å’Œè¡¨é¢æ³¢ã€‚å®ƒè¢«è®¤ä¸ºè¡¨ç°å‡ºä¸°å¯Œçš„æ—¶ç©ºæ··æ²Œè¡Œä¸ºã€‚
- en: '![](../Images/780bc2f9867af18779e1983004bc910d.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/780bc2f9867af18779e1983004bc910d.png)'
- en: 'Navier-Stokes equation: this set of partial differential equations describes
    the motion of fluid substances and constitutes the fundamental equations in fluid
    mechanics. The current paper considered a classical two-dimensional decaying turbulence
    example in a square domain with periodic boundary conditions.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Navier-Stokes æ–¹ç¨‹ï¼šè¿™ç»„åå¾®åˆ†æ–¹ç¨‹æè¿°äº†æµä½“ç‰©è´¨çš„è¿åŠ¨ï¼Œå¹¶æ„æˆäº†æµä½“åŠ›å­¦çš„åŸºæœ¬æ–¹ç¨‹ã€‚å½“å‰è®ºæ–‡è€ƒè™‘äº†ä¸€ä¸ªç»å…¸çš„äºŒç»´è¡°å‡æ¹æµç¤ºä¾‹ï¼Œä½äºä¸€ä¸ªå…·æœ‰å‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶çš„æ–¹å½¢åŒºåŸŸå†…ã€‚
- en: '![](../Images/2587329316d8589be36ab58853699baa.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2587329316d8589be36ab58853699baa.png)'
- en: 'The benchmark studies yielded that:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºå‡†ç ”ç©¶è¡¨æ˜ï¼š
- en: The proposed causal training algorithm was able to achieve 10â€“100x improvements
    in accuracy compared to the vanilla PINN training scheme.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸åŸå§‹PINNè®­ç»ƒæ–¹æ¡ˆç›¸æ¯”ï¼Œæå‡ºçš„å› æœè®­ç»ƒç®—æ³•èƒ½å¤Ÿå®ç°10åˆ°100å€çš„å‡†ç¡®æ€§æ”¹è¿›ã€‚
- en: Demonstrated that PINNs equipped with causal training algorithm can successfully
    simulate highly nonlinear, multi-scale, and chaotic systems.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¼”ç¤ºäº†é…å¤‡å› æœè®­ç»ƒç®—æ³•çš„PINNsèƒ½å¤ŸæˆåŠŸæ¨¡æ‹Ÿé«˜åº¦éçº¿æ€§ã€å¤šå°ºåº¦å’Œæ··æ²Œç³»ç»Ÿã€‚
- en: 2.5 Strengths and Weaknesses âš¡
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 ä¼˜åŠ¿ä¸åŠ£åŠ¿ âš¡
- en: '**Strengths** ğŸ’ª'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¼˜åŠ¿** ğŸ’ª'
- en: Respects the causality principle and makes PINN training more transparent.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°Šé‡å› æœæ€§åŸåˆ™ï¼Œä½¿PINNè®­ç»ƒæ›´åŠ é€æ˜ã€‚
- en: Introduces significant accuracy improvements, allowing it to tackle problems
    that have remained elusive to PINNs.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼•å…¥äº†æ˜¾è‘—çš„å‡†ç¡®æ€§æ”¹è¿›ï¼Œä½¿å…¶èƒ½å¤Ÿè§£å†³é‚£äº›å¯¹PINNsä»ç„¶éš¾ä»¥å¤„ç†çš„é—®é¢˜ã€‚
- en: Provides a practical quantitative criterion for assessing the training convergence
    of PINNs.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æä¾›äº†ä¸€ä¸ªå®ç”¨çš„å®šé‡æ ‡å‡†ï¼Œç”¨äºè¯„ä¼°PINNsçš„è®­ç»ƒæ”¶æ•›æ€§ã€‚
- en: Negligible added computational cost compared to the vanilla PINN training strategy.
    The only added cost is to compute the Ï‰áµ¢â€™s, which is negligible compared to auto-diff
    operations.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸åŸå§‹PINNè®­ç»ƒç­–ç•¥ç›¸æ¯”ï¼Œè®¡ç®—æˆæœ¬å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚å”¯ä¸€çš„é¢å¤–æˆæœ¬æ˜¯è®¡ç®—Ï‰áµ¢ï¼Œè¿™ä¸è‡ªåŠ¨å¾®åˆ†æ“ä½œç›¸æ¯”å‡ ä¹å¯ä»¥å¿½ç•¥ã€‚
- en: '**Weaknesses** ğŸ“‰'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**åŠ£åŠ¿** ğŸ“‰'
- en: Introduced a new hyperparameter Îµ, which controls the scheduling of the weights
    for temporal residual losses. Although the authors proposed an annealing strategy
    as an alternative to avoid the tedious hyper-parameter tuning.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼•å…¥äº†æ–°çš„è¶…å‚æ•°Îµï¼Œè¯¥å‚æ•°æ§åˆ¶æ—¶é—´æ®‹å·®æŸå¤±æƒé‡çš„è°ƒåº¦ã€‚å°½ç®¡ä½œè€…æå‡ºäº†ä¸€ç§é€€ç«ç­–ç•¥ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆï¼Œä»¥é¿å…ç¹ççš„è¶…å‚æ•°è°ƒä¼˜ã€‚
- en: Complicated the PINN training workflow. Special attention should be given to
    the temporal weights Ï‰áµ¢â€™s, as they are now functions of the network trainable
    parameters (e.g., layer weights and bias), and the gradient associated with the
    computation of Ï‰áµ¢ should not be back-propagated.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿PINNè®­ç»ƒå·¥ä½œæµç¨‹å¤æ‚åŒ–ã€‚åº”ç‰¹åˆ«å…³æ³¨æ—¶é—´æƒé‡Ï‰áµ¢ï¼Œå› ä¸ºå®ƒä»¬ç°åœ¨æ˜¯ç½‘ç»œå¯è®­ç»ƒå‚æ•°ï¼ˆå¦‚å±‚æƒé‡å’Œåå·®ï¼‰çš„å‡½æ•°ï¼Œè®¡ç®—Ï‰áµ¢çš„æ¢¯åº¦ä¸åº”åå‘ä¼ æ’­ã€‚
- en: 2.6 Alternatives ğŸ”€
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 æ›¿ä»£æ–¹æ¡ˆ ğŸ”€
- en: 'There are a couple of alternative methods that are trying to address the same
    issue as the current â€œcausal training algorithmâ€:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ç§æ›¿ä»£æ–¹æ³•è¯•å›¾è§£å†³ä¸å½“å‰â€œå› æœè®­ç»ƒç®—æ³•â€ç›¸åŒçš„é—®é¢˜ï¼š
- en: 'Adaptive time sampling strategy ([Wight et al.](https://arxiv.org/abs/2007.04542)):
    instead of weighting the collocation points at different time instances, this
    strategy modifies the sampling density of collocation points. This has a similar
    effect of shifting the focus of the optimizer on minimizing temporal losses at
    different time instances.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‡ªé€‚åº”æ—¶é—´é‡‡æ ·ç­–ç•¥ ([Wight et al.](https://arxiv.org/abs/2007.04542))ï¼šè¯¥ç­–ç•¥ä¸æ˜¯å¯¹ä¸åŒæ—¶é—´ç‚¹çš„é…ç‚¹è¿›è¡ŒåŠ æƒï¼Œè€Œæ˜¯ä¿®æ”¹é…ç‚¹çš„é‡‡æ ·å¯†åº¦ã€‚è¿™ç§æ–¹æ³•ç±»ä¼¼äºå°†ä¼˜åŒ–å™¨çš„å…³æ³¨ç‚¹è½¬ç§»åˆ°ä¸åŒæ—¶é—´ç‚¹çš„æ—¶é—´æŸå¤±æœ€å°åŒ–ä¸Šã€‚
- en: 'â€œTime-marchingâ€/â€œCurriculum trainingâ€ strategy (e.g., [Krishnapriyan et al.](https://arxiv.org/abs/2109.01050)):
    the temporal causality is respected via learning the solution sequentially within
    separate time windows.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€œæ—¶é—´æ¨è¿›â€/â€œè¯¾ç¨‹è®­ç»ƒâ€ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼Œ[Krishnapriyan et al.](https://arxiv.org/abs/2109.01050)ï¼‰ï¼šé€šè¿‡åœ¨ä¸åŒçš„æ—¶é—´çª—å£å†…é¡ºåºå­¦ä¹ è§£å†³æ–¹æ¡ˆæ¥å°Šé‡æ—¶é—´å› æœæ€§ã€‚
- en: However, compared to those alternative approaches, the â€œcausal training algorithmâ€
    put temporal causality front and center, is more adaptable to a variety of problems,
    and enjoys low added computational cost.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¸é‚£äº›æ›¿ä»£æ–¹æ³•ç›¸æ¯”ï¼Œâ€œå› æœè®­ç»ƒç®—æ³•â€å°†æ—¶é—´å› æœæ€§ç½®äºæ ¸å¿ƒï¼Œæ›´é€‚åº”å„ç§é—®é¢˜ï¼Œä¸”è®¡ç®—æˆæœ¬ä½ã€‚
- en: 3 Potential Future Improvements ğŸŒŸ
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 æ½œåœ¨çš„æœªæ¥æ”¹è¿› ğŸŒŸ
- en: 'There are several possibilities to further improve the proposed strategy:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ç§å¯èƒ½æ€§å¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›æå‡ºçš„ç­–ç•¥ï¼š
- en: Incorporating more sophisticated data sampling strategies, such as adaptive-
    and residual-based sampling methods, to further improve the training efficiency
    and accuracy.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“åˆæ›´å¤æ‚çš„æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œå¦‚è‡ªé€‚åº”å’ŒåŸºäºæ®‹å·®çš„é‡‡æ ·æ–¹æ³•ï¼Œä»¥è¿›ä¸€æ­¥æé«˜è®­ç»ƒæ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚
- en: To learn more about how to optimize the residual points distribution, check
    out [this blog](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)
    in the PINN design pattern series.
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¬²äº†è§£å¦‚ä½•ä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒï¼Œè¯·æŸ¥çœ‹[æ­¤åšå®¢](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)ä¸­çš„PINNè®¾è®¡æ¨¡å¼ç³»åˆ—ã€‚
- en: Extend to inverse problem settings. How to ensure casualty when point sources
    of information (i.e., observational data) are available would require an extension
    of the currently proposed training strategy.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰©å±•åˆ°é€†é—®é¢˜è®¾ç½®ã€‚å½“ä¿¡æ¯ç‚¹æºï¼ˆå³è§‚æµ‹æ•°æ®ï¼‰å¯ç”¨æ—¶ï¼Œå¦‚ä½•ç¡®ä¿å› æœå…³ç³»å°†éœ€è¦å¯¹ç›®å‰æå‡ºçš„è®­ç»ƒç­–ç•¥è¿›è¡Œæ‰©å±•ã€‚
- en: 4 Takeaways ğŸ“
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4ä¸ªè¦ç‚¹ğŸ“
- en: 'In this blog, we looked at how to bring causality to PINN training with a reformulation
    of the training objectives. Here are the highlights of the design pattern proposed
    in the paper:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¦‚ä½•é€šè¿‡é‡æ–°åˆ¶å®šè®­ç»ƒç›®æ ‡å°†å› æœå…³ç³»å¼•å…¥PINNè®­ç»ƒã€‚ä»¥ä¸‹æ˜¯è®ºæ–‡ä¸­æå‡ºçš„è®¾è®¡æ¨¡å¼çš„äº®ç‚¹ï¼š
- en: '[Problem]: How to make PINNs respect the causality principle underpinning the
    physical systems?'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[é—®é¢˜]ï¼šå¦‚ä½•è®©PINNéµå®ˆæ”¯æ’‘ç‰©ç†ç³»ç»Ÿçš„å› æœå…³ç³»åŸåˆ™ï¼Ÿ'
- en: '[Solution]: **Re-formulating the PINN training objective**, where a dynamic
    weighting scheme is introduced to gradually shift the training focus from earlier
    time steps to later time steps.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è§£å†³æ–¹æ¡ˆ]ï¼š**é‡æ–°åˆ¶å®šPINNè®­ç»ƒç›®æ ‡**ï¼Œå¼•å…¥åŠ¨æ€åŠ æƒæ–¹æ¡ˆï¼Œä»¥é€æ­¥å°†è®­ç»ƒé‡ç‚¹ä»æ—©æœŸæ—¶é—´æ­¥éª¤è½¬ç§»åˆ°åæœŸæ—¶é—´æ­¥éª¤ã€‚'
- en: '[Potential benefits]: 1\. Significantly improved PINNsâ€™ accuracy. 2\. Expanded
    the applicability of PINNs to complex problems.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ½œåœ¨æ”¶ç›Š]ï¼š1\. æ˜¾è‘—æé«˜PINNçš„å‡†ç¡®æ€§ã€‚2\. æ‰©å±•PINNå¯¹å¤æ‚é—®é¢˜çš„é€‚ç”¨æ€§ã€‚'
- en: 'Here is the PINN design card to summarize the takeaways:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯PINNè®¾è®¡å¡ï¼Œæ€»ç»“äº†ä¸»è¦æ”¶è·ï¼š
- en: '![](../Images/f44122165c8b0f741c7006072f4a7695.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f44122165c8b0f741c7006072f4a7695.png)'
- en: PINN design pattern proposed in the paper. (Image by this blog author)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡ä¸­æå‡ºçš„PINNè®¾è®¡æ¨¡å¼ã€‚ï¼ˆå›¾ç‰‡ç”±æ­¤åšå®¢ä½œè€…æä¾›ï¼‰
- en: 'I hope you found this blog useful! To learn more about PINN design patterns,
    feel free to check out other posts in this series:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ è§‰å¾—è¿™ç¯‡åšå®¢æœ‰ç”¨ï¼è¦äº†è§£æ›´å¤šå…³äºPINNè®¾è®¡æ¨¡å¼çš„ä¿¡æ¯ï¼Œè¯·éšæ—¶æŸ¥çœ‹æ­¤ç³»åˆ—ä¸­çš„å…¶ä»–å¸–å­ï¼š
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼01ï¼šä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼02ï¼šåŠ¨æ€è§£å†³æ–¹æ¡ˆåŒºé—´æ‰©å±•](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: '[PINN design pattern 03: PINN training with gradient boost](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼03ï¼šå¸¦æœ‰æ¢¯åº¦æå‡çš„PINNè®­ç»ƒ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: '[PINN design pattern 04: Gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼04ï¼šå¢å¼ºæ¢¯åº¦çš„PINNå­¦ä¹ ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: '[PINN design pattern 05: Hyperparameter tuning for PINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼05ï¼šPINNçš„è¶…å‚æ•°è°ƒä¼˜](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼07ï¼šä¸PINNçš„ä¸»åŠ¨å­¦ä¹ ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Looking forward to sharing more insights with you in the upcoming blogs!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸå¾…åœ¨å³å°†åˆ°æ¥çš„åšå®¢ä¸­ä¸æ‚¨åˆ†äº«æ›´å¤šè§è§£ï¼
- en: Reference ğŸ“‘
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒğŸ“‘
- en: '[1] Wang et al., Respecting causality is all you need for training physics-informed
    neural networks, [arXiv](https://arxiv.org/abs/2203.07404), 2022.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[Wangç­‰äººï¼Œå°Šé‡å› æœå…³ç³»æ˜¯è®­ç»ƒç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œæ‰€éœ€çš„ä¸€åˆ‡](https://arxiv.org/abs/2203.07404)ï¼Œ[arXiv](https://arxiv.org/abs/2203.07404)ï¼Œ2022å¹´ã€‚'
