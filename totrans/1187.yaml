- en: What is ARIMA?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-forecast-with-arima-96b3d4db111a](https://towardsdatascience.com/how-to-forecast-with-arima-96b3d4db111a)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An introduction to the ARIMA forecasting model and how to use it for time series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@egorhowell?source=post_page-----96b3d4db111a--------------------------------)[![Egor
    Howell](../Images/1f796e828f1625440467d01dcc3e40cd.png)](https://medium.com/@egorhowell?source=post_page-----96b3d4db111a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----96b3d4db111a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----96b3d4db111a--------------------------------)
    [Egor Howell](https://medium.com/@egorhowell?source=post_page-----96b3d4db111a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----96b3d4db111a--------------------------------)
    ·7 min read·Jan 31, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ed7671dae965b26c6dcdd9c5e5d2973a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In my previous posts we have covered [***autoregession (AR)***](https://medium.com/towards-data-science/how-to-forecast-time-series-using-autoregression-1d45db71683)
    and [***moving-average (MA)***](https://medium.com/towards-data-science/how-to-forecast-with-moving-average-models-6f3c9cbba60d)
    models. However, do you know what is better than these two models? A single model
    that combines them!
  prefs: []
  type: TYPE_NORMAL
- en: '[***Autoregressive Integrated Moving Average***](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)better
    known as ARIMA, is probably the most used time series forecasting model and is
    combination of the individual aforementioned models. In this article, I want to
    dive into the theory and framework behind the ARIMA model. Then, we will go through
    a simple Python walkthrough in carrying out forecast with ARIMA using the `statsmodels`
    [package](https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html)!'
  prefs: []
  type: TYPE_NORMAL
- en: Supplemental Video.
  prefs: []
  type: TYPE_NORMAL
- en: What is ARIMA?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As stated above, ARIMA stands for **A**uto**R**egressive **I**ntegrated **M**oving
    **A**verage is basically just a combination of the three (in reality two) components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AutoRegressive (AR):**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is just autoregression, where we forecast future values using a linear
    combination of the previously observed values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c89fcef7348c5e8fd54582102b3ddbaf.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation generated by author in LaTeX.
  prefs: []
  type: TYPE_NORMAL
- en: Here ***y*** is the time series we are forecasting at multiple time steps, ***ϕ***
    are the coefficients of the lags, ***ε*** is the [error term](https://en.wikipedia.org/wiki/White_noise)
    (often [**normally distributed**](https://en.wikipedia.org/wiki/Normal_distribution))
    and ***p*** is the number of lagged components, also known as the ***order.***
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to learn more about autoregression, checkout my previous post on
    it here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-forecast-time-series-using-autoregression-1d45db71683?source=post_page-----96b3d4db111a--------------------------------)
    [## How To Forecast Time-Series Using Autoregression'
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial on how to forecast using an autoregressive model in Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-forecast-time-series-using-autoregression-1d45db71683?source=post_page-----96b3d4db111a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Integrated (I):**'
  prefs: []
  type: TYPE_NORMAL
- en: The middle part of the ARIMA model is named [***integrated***](https://en.wikipedia.org/wiki/Order_of_integration)***.***
    This is the number (order ***d***) of differencing required to make the time series
    [***stationary***](/time-series-stationarity-simply-explained-125269968154).
  prefs: []
  type: TYPE_NORMAL
- en: Stationarity is where the time series has a constant mean and variance, meaning
    the statistical properties of the series does not change through time. Differencing
    ***de-trends*** a time series and tends to make the mean constant. You can apply
    differencing several times, but often the series is sufficiently stationary after
    a single differencing step.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note, that this integrated part only makes the mean constant.
    We need to apply another transform such as the [***logarithmic and Box-Cox transform***](https://en.wikipedia.org/wiki/Power_transform)
    to generate a constant variance (more on this later).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to learn more about stationarity, checkout my previous blog posts
    about it here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/time-series-stationarity-simply-explained-125269968154?source=post_page-----96b3d4db111a--------------------------------)
    [## Time-Series Stationarity Simply Explained'
  prefs: []
  type: TYPE_NORMAL
- en: A simple and intuitive explanation for the need of stationarity in time-series
    modelling.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/time-series-stationarity-simply-explained-125269968154?source=post_page-----96b3d4db111a--------------------------------)
    [](/box-cox-transform-for-time-series-cc45f26082c6?source=post_page-----96b3d4db111a--------------------------------)
    [## Box-Cox Transform for Time Series
  prefs: []
  type: TYPE_NORMAL
- en: How to create a stationary time series using the Box-Cox transformation.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/box-cox-transform-for-time-series-cc45f26082c6?source=post_page-----96b3d4db111a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Moving Average (MA):**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The last component is the moving average where you forecast using past forecast
    errors instead of the actual observed values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cdf6a947a5b15204b7124d76b4dbe89e.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation generated by author in LaTeX.
  prefs: []
  type: TYPE_NORMAL
- en: Here ***y*** is the time series we are forecasting at multiple time steps, ***μ***
    is the mean, ***θ*** are the coefficients of the lagged forecast errors, ***ε***
    arethe forecast error terms and ***q*** is the number of lagged error components.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to learn more about moving average model, checkout my previous
    post on it here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/how-to-forecast-with-moving-average-models-6f3c9cbba60d?source=post_page-----96b3d4db111a--------------------------------)
    [## How To Forecast With Moving Average Models'
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial and theory on how to carry out forecasts with moving average models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/how-to-forecast-with-moving-average-models-6f3c9cbba60d?source=post_page-----96b3d4db111a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**Final Form**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Combining all these components together, we can write the full model as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/627d38be20adaa9b8730b79b9035bd24.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation generated by author in LaTeX.
  prefs: []
  type: TYPE_NORMAL
- en: Where ***y’*** refers to the **differenced** version of the time series.
  prefs: []
  type: TYPE_NORMAL
- en: This is the full ARIMA equation and is just a linear summation of the three
    components. The model is usefully written in a short-hand way as ***ARIMA(p, d,
    q)*** where ***p***, ***d*** and ***q*** refer to the order of autoregressors,
    differencing and moving-averages components respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we touched upon earlier, the differencing component is there to help make
    the time series stationary. This is because the ARIMA model requires the data
    to be stationary for it to adequately model it. The mean is stabilised through
    differencing and the variance can be stabilised through the Box-Cox transform
    as we mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: Order Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the preprocessing steps is to determine the optimal orders (***p, d,
    q***) of our ARIMA model. The simplest one is the order of differencing ***d***
    as this can be verified by carrying out a statistical test for stationarity. The
    most popular one is the [***Augmented Dickey-Fuller***](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test)
    ***(ADF)***, where the null hypothesis is that the time series is **not** stationary.
  prefs: []
  type: TYPE_NORMAL
- en: The autoregressive and moving-average orders (***p,q***) can be deduced by analysing
    the [***partial autocorrelation function (PACF)***](https://online.stat.psu.edu/stat510/lesson/2/2.2)and
    [***autocorrelation function***](/towards-data-science/autocorrelation-for-time-series-analysis-86e68e631f77)respectively.
    The gist of of this method is to plot a [***correlogram***](https://en.wikipedia.org/wiki/Correlogram)of
    the various lags/forecast errors of the time series to determine which are [***statistically
    significant***](https://en.wikipedia.org/wiki/Statistical_significance). If this
    seems arbitrary at the moment don’t worry, in the Python tutorial later we will
    walkthrough this process.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/autocorrelation-for-time-series-analysis-86e68e631f77?source=post_page-----96b3d4db111a--------------------------------)
    [## Autocorrelation For Time Series Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: Describing what autocorrelation is and why it is useful in time series analysis.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/autocorrelation-for-time-series-analysis-86e68e631f77?source=post_page-----96b3d4db111a--------------------------------)
    [](/partial-autocorrelation-for-time-series-481a9cfa7526?source=post_page-----96b3d4db111a--------------------------------)
    [## Partial Autocorrelation for Time Series Analysis
  prefs: []
  type: TYPE_NORMAL
- en: Describing what partial autocorrelation is and its importance in time series
    analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/partial-autocorrelation-for-time-series-481a9cfa7526?source=post_page-----96b3d4db111a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: However, a more thorough technique is to simply iterate over all the possible
    combinations of orders and choose the model with the best score against a metric
    such as [***Akaike’s Information Criterion (AIC)***](https://en.wikipedia.org/wiki/Akaike_information_criterion)or
    [***Bayesian Information Criterion (BIC)***](https://en.wikipedia.org/wiki/Bayesian_information_criterion).
    This is analogous to regular hyperparameter tuning and definitely the more robust
    method, but is more computational expensive of course.
  prefs: []
  type: TYPE_NORMAL
- en: Estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After choosing our orders, we then need to find their optimal corresponding
    coefficients. This where the need for stationarity comes in. As declared above,
    a stationary time series has constant statistical properties such as mean and
    variance. Therefore, all the data points are part of the same probability distribution,
    which makes fitting our model easier. Furthermore, forecasts are treated as ***random
    variables*** and will now belong to the same probability distribution as the newly
    generated stationary time series. Overall, it helps **make the data in the future
    be somewhat like the past.**
  prefs: []
  type: TYPE_NORMAL
- en: See this [statsexchange](https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary)
    thread for the reasons why stationarity is important for ARIMA.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As the stationary data belongs to some distribution (frequently the normal distribution),
    we can estimate the coefficients using [***Maximum Likelihood Estimation (MLE)***](/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1).
    MLE deduces the optimal values of the coefficients that produce the highest probability
    of obtaining that data. The MLE for normally distributed data, is the same result
    as carrying [**ordinary least squares**](https://en.wikipedia.org/wiki/Ordinary_least_squares).
    Therefore, least squares is also frequently used for this exact reason.
  prefs: []
  type: TYPE_NORMAL
- en: Link [here](/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)
    for a great explanation of MLE.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ARIMA Python Tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The data we will use in this tutorial is the classic US airline passenger dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Data [from Kaggle](https://www.kaggle.com/datasets/ashfakyeafi/air-passenger-data-for-time-series-analysis)
    with a CC0 licence.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/87f5dd5f5d2da117e26234afff4d36d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data is not stationary as there is a **strong positive trend** and the
    **yearly seasonality fluctuations are increasing through time**, hence the variance
    is increasing. For this modelling task we will be using the [statsmodel](https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html)
    [package](https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html),
    which handily carries out differencing for us and produces a constant mean. However,
    we still need to apply the Box-Cox transform to retrieve a stabilised variance:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ac34f7e772a5cef1290f0d2cc81fc42.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The seasonal fluctuations are now on a consistent level!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Modelling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous sections, I mentioned how you can find the autoregressive and
    moving-average orders by plotting the autocorrelation and partial autocorrelation
    functions. Let’s show an example of how you can do it here:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ea79b7e572be1f51b251bf058517c236.png)![](../Images/af2254213ba4fb713b6a1e441055518d.png)'
  prefs: []
  type: TYPE_IMG
- en: Plots generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The blue region signifies where the points are **no longer statistically significant**
    and from the plot we see the last lag that is statistically significant for both
    plot is ~***12th***. Therefore, we would take the order of ***p*** and ***q***
    to be ***12***.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s fit the model using the `ARIMA` function and generate the forecasts:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Plot the forecasts:'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Gist by author.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/904ddc7d4289aafe5f67779cd7f84e26.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot generated by author in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The ARIMA model has captured the data very well!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Summary and Further Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this article we have discussed one of the most common forecasting models
    used in practise, ARIMA. This model combines: autoregression, differencing and
    moving-average models into a single univariate case. ARIMA is simple to apply
    in Python the `statsmodels` package, which does a lot of the heavy lifting for
    you when fitting an ARIMA model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Full code used in this article can be found at my GitHub here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/egorhowell/Medium-Articles/blob/main/Time%20Series/ARIMA/arima.py?source=post_page-----96b3d4db111a--------------------------------)
    [## Medium-Articles/arima.py at main · egorhowell/Medium-Articles'
  prefs: []
  type: TYPE_NORMAL
- en: Code I use in my medium blog/articles. Contribute to egorhowell/Medium-Articles
    development by creating an account on…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/egorhowell/Medium-Articles/blob/main/Time%20Series/ARIMA/arima.py?source=post_page-----96b3d4db111a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Another Thing!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I have a free newsletter, [**Dishing the Data**](https://dishingthedata.substack.com/),
    where I share weekly tips for becoming a better Data Scientist. There is no “fluff”
    or “clickbait,” just pure actionable insights from a practicing Data Scientist.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://newsletter.egorhowell.com/?source=post_page-----96b3d4db111a--------------------------------)
    [## Dishing The Data | Egor Howell | Substack'
  prefs: []
  type: TYPE_NORMAL
- en: How To Become A Better Data Scientist. Click to read Dishing The Data, by Egor
    Howell, a Substack publication with…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: newsletter.egorhowell.com](https://newsletter.egorhowell.com/?source=post_page-----96b3d4db111a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Connect With Me!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[**YouTube**](https://www.youtube.com/@egorhowell)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**LinkedIn**](https://www.linkedin.com/in/egor-howell-092a721b3/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Twitter**](https://twitter.com/EgorHowell)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**GitHub**](https://github.com/egorhowell)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References and Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Forecasting: Principles and Practice:* [https://otexts.com/fpp2/](https://otexts.com/fpp3/arima.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
