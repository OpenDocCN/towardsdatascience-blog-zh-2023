["```py\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\n\npipeline = Pipeline(\n   steps=[(\"imputer\", SimpleImputer()), \n          (\"scaler\", MinMaxScaler()), \n          (\"regression\", LinearRegression())\n   ]\n)\n\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)\n```", "```py\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\n\npipeline = make_pipeline(steps=[\n    SimpleImputer(), \n    MinMaxScaler(), \n    LinearRegression()\n    ]\n)\n```", "```py\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_transformer = ColumnTransformer(\n    transformers=[(\"encode\", OneHotEncoder())]\n)\n\npipeline = Pipeline(steps=[\n    (\"categorical\", categorical_transformer, [\"col_name\"])\n    ]\n)\n```", "```py\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\ncategorical_transformer = ColumnTransformer(\n transformers=[(\"encode\", OneHotEncoder(), [\"col_name\"])], remainder=\"passthrough\"\n)\n\ncategorical_transformer = ColumnTransformer(\n transformers=[(\"encode\", OneHotEncoder(), [\"col_name\"])], remainder=MinMaxScaler()\n)\n```", "```py\n\nSince `scikit-learn` allows Pipeline stacking we could even pass a Pipeline to the `ColumnTransformer` instead of stating each transformation we want to do in the `ColumnTransformer` itself.\n\n```", "```py\n\n# Combining features\n\nNow, you are able to run different pre-processing steps on different columns, but what if you want to derive new features from the data and add them to you feature set?\n\nFor this, you can use `FeatureUnion`, which combines transformer objects into a new transformer with the combined objects. Running a pipeline with a `FeatureUnion` fits each transformer independently and then joins their output.\n\nFor example, assume we want to add the Moving Average as a feature, we could do this:\n\n```", "```py\n\n# Transforming the target value\n\nIf you have a regression problem sometimes it can help to transform the target before fitting a regression.\n\nYou can include such a transformation using the `TransformedTargetRegressor` class. With this class you can either use transformers provided by `scikit-learn` like a MinMax scaler or write your own transformation functions.\n\nOne huge advantage of the `TransformedTargetRegressor` is that it automatically maps the predictions back to the original space by an inverse transform. So, you do not need to care about this later on when you move from model training to making predictions in production.\n\n```", "```py\n\n# Building your own custom functions\n\nSometimes it is not enough to use pre-processing methods `scikit-learn` provides. This, however, should not hold you back when using Pipelines. You can easily create your own functions that you can then include in the pipeline.\n\nFor this, you need to build a class that contains a `fit()` and `transform()` method as these are called when running the pipeline. However, these methods do no necessarily need to do anything. Moreover, we can let the class inherit from `scikit-learn`â€™s `BaseEstimator` and `TransformerMixin` class to give us some basic functionality that our pipeline needs.\n\nFor example, assume we want to make predictions on a time series and we want to smooth all features by a moving average. For this, we just set up a class with a `transform` method that contains the smoothing part.\n\n```", "```py\n\n# What else is there to know?\n\nThe default return of transformers in `scikit-learn` is a numpy array. This can lead to problems in your pipeline if you only want to apply a transformation on certain features in the second step of the pipeline, e.g., only categorical features.\n\nHowever, to prevent your pipeline from breaking you can change the default return value of all transformers to a dataframe by stating\n\n```"]