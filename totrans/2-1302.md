# 使用PyTorch和SHAP进行图像分类：你能信任自动驾驶汽车吗？

> 原文：[https://towardsdatascience.com/image-classification-with-pytorch-and-shap-can-you-trust-an-automated-car-4d8d12714eea](https://towardsdatascience.com/image-classification-with-pytorch-and-shap-can-you-trust-an-automated-car-4d8d12714eea)

## 构建一个目标检测模型，将其与强度阈值进行比较，评估并使用DeepSHAP解释它

[](https://conorosullyds.medium.com/?source=post_page-----4d8d12714eea--------------------------------)[![Conor O'Sullivan](../Images/2dc50a24edb12e843651d01ed48a3c3f.png)](https://conorosullyds.medium.com/?source=post_page-----4d8d12714eea--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4d8d12714eea--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4d8d12714eea--------------------------------) [Conor O'Sullivan](https://conorosullyds.medium.com/?source=post_page-----4d8d12714eea--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----4d8d12714eea--------------------------------) ·阅读时间14分钟·2023年3月21日

--

![](../Images/e0f878484110a05545a3b8a001d4b868.png)

（来源：作者）

如果世界不那么混乱，自驾车将会简单。但事实并非如此。为了避免严重的伤害，AI必须考虑许多变量——速度限制、交通情况和路上的障碍物（例如分心的人）。AI需要能够检测这些障碍物，并在遇到时采取适当的行动。

幸运的是，我们的应用并没有那么复杂。更幸运的是，我们将使用锡罐而不是人类。我们将建立一个模型，用于检测迷你自动驾驶汽车前方的障碍物。如果障碍物过于接近，汽车应该**停下**，否则**前进**。

到头来，这是一个二分类问题。为了解决它，我们将：

+   使用强度阈值创建基准

+   使用PyTorch构建CNN

+   使用准确率、精确率和召回率评估模型

+   使用SHAP解释模型

我们将看到模型不仅表现良好，而且*其预测方式*也似乎合理。在此过程中，我们将讨论Python代码，你可以在[GitHub](https://github.com/conorosully/medium-articles/blob/master/src/image_tools/pytorch_image_classification.ipynb)上找到完整的项目。

# 导入和数据集

[PRE0]

在图1中，你可以看到我们数据集中图像的示例。这些图像的尺寸都是224 x 224。如果没有黑色罐子或者罐子距离较远，图像被分类为GO。如果罐子过于接近，图像被分类为STOP。你可以在[Kaggle](https://www.kaggle.com/datasets/conorsully1/jatracer-images)上找到完整的数据集。

![](../Images/9c97bfc3b7fd98e5ba65bfc0a2eadf47.png)

图1：示例图像（来源：作者）

我们使用下面的代码显示上述图像。注意图像的名称。它总是以一个数字开头。这是**目标变量**。我们用0表示GO，用1表示STOP。

[PRE1]

# 基准

在建模之前，值得创建一个基准。这可以提供一些对我们问题的见解。更重要的是，它为我们提供了一个比较模型结果的标准。我们更复杂的深度学习模型应该会优于简单的基准。

在图1中，我们可以看到锡罐比周围环境更暗。我们将在创建基准时利用这一点。即，如果图像中有许多暗像素，我们将其分类为STOP。达到这一点需要几个步骤。对于每个图像，我们将：

1.  进行灰度化，使每个像素的值在0（黑色）和255（白色）之间。

1.  使用截止值，将每个像素转换为二进制值——深色像素为1，浅色像素为0。

1.  计算平均强度——暗像素的百分比

1.  如果平均强度超过某个百分比，我们将图像分类为STOP。

合并步骤1和2是一种图像数据的特征工程方法，称为**强度阈值**。你可以在这篇文章中阅读更多关于此及其他特征工程方法的信息：

[](/feature-engineering-with-image-data-14fe4fcd4353?source=post_page-----4d8d12714eea--------------------------------) [## 图像数据的特征工程

### 裁剪、灰度化、RGB通道、强度阈值、边缘检测和颜色滤镜

towardsdatascience.com](/feature-engineering-with-image-data-14fe4fcd4353?source=post_page-----4d8d12714eea--------------------------------)

我们使用下面的函数应用强度阈值。缩放后，一个像素将具有0（黑色）或1（白色）的值。对于我们的应用，颠倒这一点是有意义的。也就是说，原本深色的像素将被赋值为1。

[PRE2]

在图2中，你可以看到我们应用强度阈值的一些示例。我们可以调整截止值。较小的截止值意味着我们包括的背景噪声更少。缺点是我们捕捉到的锡罐较少。在这种情况下，我们将使用截止值60。

![](../Images/53f27a71b447255ad4b9407909dd5557.png)

图2：使用强度阈值的特征工程（来源：作者）

我们加载了所有的图像（第5行）和目标变量（第6行）。然后，我们对这些图像应用强度阈值（第9行）。请注意，我们设置了**invert=True**。最后，我们计算每个处理过的图像的平均强度（第10行）。最终，每个图像由一个单一的数字——平均强度来表示。这可以解释为**暗像素的百分比**。

[PRE3]

图 3 给出了所有标记为 GO 和 STOP 的图像的平均强度箱线图。通常，我们可以看到 STOP 的值更高。这是有道理的——罐子离得更近，因此我们会有更多的暗像素。红线在 6.5% 处。这似乎能很好地分离图像类别。

![](../Images/6bbee980983566b9bd4f150e16fa3a23.png)

图 3：目标变量的平均强度（来源：作者）

[PRE4]

我们使用 6.5% 作为预测的截断值（第 2 行）。即如果暗像素的百分比超过 6.5%，则预测为 STOP（1），否则预测为 GO（0）。其余的代码用于评估这些预测。

[PRE5]

最终，我们的准确率为 82%，精确率为 77.1%，召回率为 82.96%。不错！在混淆矩阵中，我们可以看到大多数错误是由于假阳性。这些是被预测为 STOP 的图像，而实际上我们应该 GO。这对应于图 3 的箱线图。查看 GO 强度值在红线以上的长尾。这可能是由于背景像素增加了图像中的暗像素数量。

![](../Images/9ff7962fb40f317ad80e85ae5e87da27.png)

图 4：基准预测的混淆矩阵（来源：作者）

# 卷积神经网络

如果一辆 AI 汽车的准确率只有 82%，你可能会有点担心。那么我们来看看更复杂的解决方案。

## 加载数据集

我们首先定义**ImageDataset**类。这用于加载我们的图像和目标变量。作为参数，我们需要传入所有图像路径的列表和用于转换图像的方法。我们的目标变量将是张量——[1,0] 代表 GO 和 [0,1] 代表 STOP。

[PRE6]

我们将使用常见的图像转换。为了帮助创建一个更强大的模型，我们将对颜色进行抖动（第 2 行）。这将随机改变图像的亮度、对比度、饱和度和色调。我们还会对像素值进行归一化（第 4 行）。这将帮助模型收敛。

[PRE7]

我们加载了所有图像路径（第 1 行）并随机打乱它们（第 4 行）。然后我们为训练数据（第 8 行）和验证数据（第 9 行）创建**ImageDataset**对象。为此我们使用了 80/20 的划分（第 7 行）。最终，我们将在训练集中拥有**3,892**张图像，在验证集中拥有**974**张图像。

[PRE8]

此时，实际上还没有数据加载到内存中。在我们能够使用数据训练 PyTorch 模型之前，我们需要创建**DataLoader**对象。对于**train_loader**，我们设置了**batch_size=128**。这允许我们迭代所有训练图像，每次加载 128 张。对于验证图像，我们将批处理大小设置为验证集的完整长度。这允许我们一次加载所有 974 张图像。

[PRE9]

## 模型架构

接下来，我们定义我们的 CNN 架构。你可以在图5中看到这个架构的图示。我们从224x224x3的图像张量开始。我们有3个卷积层和最大池化层。这将我们缩减到28x28x64的张量。接下来是一个drop-out层和两个全连接层。我们对所有隐藏层使用 ReLu 激活函数。对于输出节点，我们使用 sigmoid 函数。这是为了使我们的预测值在0和1之间。

![](../Images/3c6789b10af43a4c11133cccbecc3dcf.png)

图5：CNN 架构（来源：作者）

我们在下面的**Net**类中捕捉了这种架构。需要指出的一点是使用了**nn.Sequential()**函数。必须使用这种定义 PyTorch 模型的方法，否则 SHAP 包将无法工作。

[PRE10]

我们创建一个模型对象（第2行）。我们将其移动到 GPU 上（第6–7行）。我使用的是苹果 M1 笔记本电脑。你需要设置适合你机器的设备。

[PRE11]

我们定义我们的损失函数（第2行）。由于我们的目标变量是二元的，我们将使用二元交叉熵损失。最后，我们使用 Adam 作为我们的优化器（第5行）。这是用来最小化损失的算法。

[PRE12]

## 训练模型

现在是有趣的部分！我们训练我们的模型20个周期，并选择验证损失最低的那个。模型可以在同一个[GitHub Repo](https://github.com/conorosully/medium-articles/tree/master/models)中找到。

[PRE13]

需要提到的一点是**optimizer.zero_grad()**行。这将所有参数的梯度设置为0。在每次训练迭代中，我们希望使用仅来自该批次的梯度来更新参数。如果不将梯度清零，它们会积累。这意味着我们将使用新批次和旧批次的梯度组合来更新参数。

## 模型评估

现在让我们看看这个模型的表现如何。我们从加载我们保存的模型开始（第2行）。切换到评估模式很重要（第3行）。如果我们不这样做，一些模型层（例如 dropout）在推理时会被不正确地使用。

[PRE14]

我们从验证集中加载图像和目标变量（第2行）。请记住，目标变量是维度为2的张量。我们获取每个张量的第二个元素（第4行）。这意味着我们现在将有一个二元目标变量——1表示STOP，0表示GO。

[PRE15]

我们使用模型对验证图像进行预测（第2行）。同样，输出将是维度为2的张量。我们考虑第二个元素。如果概率超过0.5，我们预测STOP，否则预测GO。

[PRE16]

最后，我们使用与评估基准相同的代码将**目标**与**预测**进行比较。我们现在的准确率为98.05%，精确率为97.38%，召回率为97.5%。相比基准有了显著的提升！在混淆矩阵中，你可以看到错误的来源。

![](../Images/9fb172362d143fa80c754290c5a933c3.png)

图6：模型在验证集上的混淆矩阵（来源：作者）

在图7中，我们更详细地查看了一些这些错误。第一行显示了一些假阳性。这些是当汽车应该GO时被预测为STOP的图像。类似地，底行显示了假阴性。

![](../Images/fd3e9d6ed1c209a8a4160c1447cf7b39.png)

图7：预测错误的示例（来源：作者）

你可能已经注意到所有障碍物都在相似的距离处。当标记图像时，我们使用了一个截止距离。即当障碍物距离小于这个截止距离时，它被标记为STOP。上述障碍物都接近这个**截止距离**。它们可能被错误标记，所以当障碍物接近这个截止距离时，模型可能会“困惑”。

# 使用SHAP解释模型

我们的模型似乎表现良好。通过了解它如何做出这些预测，我们可以更确定它的效果。为此，我们使用SHAP。如果你对SHAP不熟悉，你可能会发现下面的视频很有用。否则，查看我的[**SHAP课程**](https://adataodyssey.com/courses/shap-with-python/)**。** 如果你注册我的[**新闻通讯**](https://mailchi.mp/aa82a5ce1dc0/signup)，你可以获得免费访问权 :)

下面的代码计算并显示了我们在图1中看到的3个示例图像的SHAP值。如果你想了解更多关于这段代码如何工作的细节，请查看文末提到的文章。

[PRE17]

你可以在图8中看到输出。前两行是标记为GO的图像，第三行为标记为STOP的图像。我们有目标张量中每个元素的SHAP值。第一列是GO预测的SHAP值，第二列是STOP预测的SHAP值。

颜色非常重要。蓝色SHAP值告诉我们这些像素减少了预测值。换句话说，它们使得模型预测给定标签的可能性降低。类似地，红色SHAP值则增加了这种可能性。

![](../Images/bdc97c8e9bbca541d975b2bad66f29ae.png)

图8：示例图像的SHAP值（来源：作者）

为了理解这一点，让我们关注图8的右上角。在图9中，我们有标记为GO的图像以及GO预测的SHAP值。你可以看到大多数像素是红色的。这些像素增加了该预测的值，从而导致正确的GO预测。你还可以看到像素聚集在障碍物截止位置——罐头的位置，其中标签从GO更改为STOP。

![](../Images/d0674f68a026332d803c1324d88dd886.png)

图9：GO预测和GO标签的SHAP值。

在图10中，我们可以看到标记为STOP的图像的SHAP值。罐头在GO预测中为蓝色，在STOP预测中为红色。换句话说，模型使用罐头中的像素来减少GO值并增加STOP值。这是有道理的！

![](../Images/5bc3b6180af9d611d7118df9b7d5b1f4.png)

图10：STOP预测的SHAP值

这个模型不仅能够准确地进行预测，而且它做出这些预测的方式似乎也很合逻辑。然而，你可能注意到一些背景像素被突出显示了。这没有意义。为什么背景对预测如此重要？当我们移除物体或移动到新位置时，背景可能会发生变化。

原因是模型对训练数据过拟合了。这些物体出现在许多图像中。结果是模型将它们与 STOP/GO 标签关联。在下面的文章中，我们进行类似的分析。我们讨论了如何防止这种过拟合的方法。我们还花更多时间解释 SHAP 代码。

[](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----4d8d12714eea--------------------------------) [## 使用 SHAP 调试 PyTorch 图像回归模型

### 使用 DeepShap 来理解和改进支持自动驾驶汽车的模型

towardsdatascience.com](/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d?source=post_page-----4d8d12714eea--------------------------------)

希望你喜欢这篇文章！你可以通过成为我的 [**推荐会员**](https://conorosullyds.medium.com/membership) **:)** 来支持我。

[](https://conorosullyds.medium.com/membership?source=post_page-----4d8d12714eea--------------------------------) [## 使用我的推荐链接加入 Medium — Conor O’Sullivan

### 作为 Medium 会员，你的一部分会员费会分配给你阅读的作者，你将可以完全访问所有故事…

[conorosullyds.medium.com](https://conorosullyds.medium.com/membership?source=post_page-----4d8d12714eea--------------------------------)

| [Twitter](https://twitter.com/conorosullyDS) | [YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w) | [Newsletter](https://mailchi.mp/aa82a5ce1dc0/signup) — 免费注册以获取 [Python SHAP 课程](https://adataodyssey.com/courses/shap-with-python/)

# 数据集

**JatRacer 图像** (CC0: 公共领域) [https://www.kaggle.com/datasets/conorsully1/jatracer-images](https://www.kaggle.com/datasets/conorsully1/jatracer-images)

# 参考资料

stack overflow，**为什么我们需要在 PyTorch 中调用 zero_grad()？** [https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch](https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)

[Kenneth Leung](https://medium.com/u/dcd08e36f2d0?source=post_page-----4d8d12714eea--------------------------------)，**如何轻松绘制神经网络架构图**，[https://towardsdatascience.com/how-to-easily-draw-neural-network-architecture-diagrams-a6b6138ed875](/how-to-easily-draw-neural-network-architecture-diagrams-a6b6138ed875)
