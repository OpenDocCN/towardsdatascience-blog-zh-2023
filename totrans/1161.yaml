- en: How To Deploy PyTorch Models as Production-Ready APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/how-to-deploy-pytorch-models-as-production-ready-apis-f61136fd0244](https://towardsdatascience.com/how-to-deploy-pytorch-models-as-production-ready-apis-f61136fd0244)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An end-to-end use-case combining PyTorch Lightning and BentoML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ahmedbesbes.medium.com/?source=post_page-----f61136fd0244--------------------------------)[![Ahmed
    Besbes](../Images/93804d9291439715e578f204b79c9bdd.png)](https://ahmedbesbes.medium.com/?source=post_page-----f61136fd0244--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f61136fd0244--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f61136fd0244--------------------------------)
    [Ahmed Besbes](https://ahmedbesbes.medium.com/?source=post_page-----f61136fd0244--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f61136fd0244--------------------------------)
    ¬∑12 min read¬∑Apr 3, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3d420812acc306b94ced6405638c8222.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [SpaceX](https://unsplash.com/@spacex?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: As an ML engineer, I often encounter two main challenges when working with deep
    learning models in production.
  prefs: []
  type: TYPE_NORMAL
- en: The first one is the need to rewrite boilerplate code for each project to handle
    tasks like training loops, data loading, or metric computation. As this work often
    makes the codebase more complex with unnecessary abstractions, it slows down the
    iterative process.
  prefs: []
  type: TYPE_NORMAL
- en: The second challenge involves the wide range of skills or tools required to
    efficiently deploy trained models to the cloud. This includes Docker, APIs, or
    cloud services. Not to mention the knowledge related to GPU support, multithreading,
    or scalability.
  prefs: []
  type: TYPE_NORMAL
- en: If you‚Äôre a data scientist, you‚Äôre clearly not expected to know all this.
  prefs: []
  type: TYPE_NORMAL
- en: '*There are fortunately two Python frameworks designed to mitigate these issues:*
    [***Pytorch Lightning***](https://github.com/Lightning-AI/lightning) *and* [***BentoML***](https://github.com/bentoml/BentoML)*.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this article, we will combine these frameworks together to build* ***a production-ready
    image classification service*** *deployed to a Kubernetes-native environment.*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let‚Äôs have a look üîç
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7d5f91d98b2edd4999334c0836a7614e.png)'
  prefs: []
  type: TYPE_IMG
- en: Workflow ‚Äî Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 1 ‚Äî Train a multi-label image classifier with PyTorch Lightning ‚ö°
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will focus on using PyTorch Lightning and will detail some of its
    functionalities as well as the training process.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'As a dataset, we will use the CelebFaces Attributes from [Kaggle](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset):
    it contains +200K face images of various celebrities with additional metadata
    such as identities, landmark locations, and **40 binary attribute annotations
    per image.**'
  prefs: []
  type: TYPE_NORMAL
- en: We will use the face attribute metadata to train a multi-label classifier that
    detects information such as hair color, nose size, baldness, etc.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, we will use **Pytorch Lightning** to train the model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ce375d5b7db3311dc779c06f279805b1.png)'
  prefs: []
  type: TYPE_IMG
- en: GIF modified by the author
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch Lightning is a lightweight wrapper around PyTorch that standardizes
    many aspects of the training loop, data loading, and validation process. It provides
    a higher-level interface that streamlines the training process and reduces the
    amount of boilerplate code required.
  prefs: []
  type: TYPE_NORMAL
- en: By using PyTorch Lightning, you can reduce code complexity, improve reproducibility,
    and speed up development.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b8ae887c35eca263fd04891d32cc4fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: To get the dataset, you need to log in to Kaggle and hit the download button.
  prefs: []
  type: TYPE_NORMAL
- en: You can also download it from the command line after getting your credentials
    (**kaggle.json**) from your profile page.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here‚Äôs what you get after unzipping the folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a242b65d8f654a6b265c0ad963b8a4b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 'The `**list_attr_celeba.csv**` file contains the attributes we‚Äôre interested
    in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0ee41387a47b8c50a7ff60412dcdc525.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot by the author
  prefs: []
  type: TYPE_NORMAL
- en: and the images are contained in the `img_align_celeba/img_align_celeba/` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs now start training this model:'
  prefs: []
  type: TYPE_NORMAL
- en: üëâ Create a Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just like in PyTorch, we first need to define a Dataset. This is the first step
    that indicates how the data is read from the disk and converted into tensors.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: üëâ Create a LightningDataModule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we need to create a LightningDataModule, which is simply a collection of
    a train_dataloader(s), val_dataloader(s), test_dataloader(s), and predict_dataloader(s)
    along with the matching transforms and data processing/downloads steps required.
  prefs: []
  type: TYPE_NORMAL
- en: 'A LightningDataModule groups everything and is later passed to the trainer.
    Therefore, you don‚Äôt need to explicitly call train or valid dataloaders yourself:
    it‚Äôs automatically handled by PyTorch Lightning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: üëâ Define a LightningModule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A `[LightningModule](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule)`
    doesn‚Äôt just define the architecture of your model. It organizes your PyTorch
    code into the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialization (`__init__` and `setup()`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The forward pass ‚Äî just like in PyTorch
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train Loop (`training_step()`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Validation Loop (`validation_step()`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test Loop (`test_step()`) ‚Äî not shown here
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimizers and LR Schedulers (`configure_optimizers()`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: üëâ Define callbacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Callbacks are utility functions that you can hook to your training pipeline
    to get executed at particular moments of the workflow, for example, the start
    or end of an epoch.
  prefs: []
  type: TYPE_NORMAL
- en: In the following, we‚Äôre going to use two callbacks for [model checkpointing](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint)
    (to periodically save the model on disk when the metrics improve) and [early stopping](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.EarlyStopping.html#lightning.pytorch.callbacks.EarlyStopping)
    (to stop training when metrics stop improving)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: üëâ Strat the training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you‚Äôve organized your PyTorch code into a `[LightningModule](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule)`,
    the `[Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html)`
    automates everything else.
  prefs: []
  type: TYPE_NORMAL
- en: It runs the training and validation loops, computes the metrics and logs them,
    and executes the callbacks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1ca44af3df78af503b3d4cb51dfb31de.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: After training for 10 epochs on 25K images only, the best model achieves 0.864
    [AUROC](https://lightning.ai/docs/metrics/stable/classification/auroc.html) on
    the validation set.
  prefs: []
  type: TYPE_NORMAL
- en: You can download the model from this S3 [link](https://bentoml-ts.s3.eu-west-3.amazonaws.com/ts_model.pt)
    and check out the code on [Github](https://github.com/ahmedbesbes/face-attributes-bentoml).
  prefs: []
  type: TYPE_NORMAL
- en: 2 ‚Äî Convert the Pytorch Lightning model to TorchScript üå¨
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will discuss TorchScript benefits over PyTorch (or Lightning) and
    show how the conversion is done.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: TorchScript is a feature in PyTorch that allows you to serialize your PyTorch
    models and run them in various environments. It provides a way to save a trained
    PyTorch model and load it into a Python-free environment or even on different
    hardware such as GPUs, FPGAs, or mobile devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'This has several advantages over PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Portability**: With TorchScript, you can run your PyTorch models in any environment
    that supports the TorchScript runtime, regardless of the platform or language.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Performance**: TorchScript can optimize your PyTorch model for faster execution
    by fusing operations and eliminating unused operations. This can result in significant
    speedups, especially on devices with limited resources such as mobile phones.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Security**: By deploying TorchScript models, you can protect your PyTorch
    code and models from being reverse-engineered or tampered with.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Ease of deployment**: With TorchScript, you can easily deploy your PyTorch
    models to production without requiring a Python environment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a more comprehensive overview of TorchScript, I recommend you go through
    this [tutorial](/pytorch-jit-and-torchscript-c2a77bac0fff).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can easily convert a Lightning Module to TorchScript by calling the `to_torchscript`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: After running some tests, I found that the inference time on GPU using TorchScript
    was 2 times lower than the inference time of PyTorch Lightning. However, this
    only happens for small batches (1 or 2 as per my tests)
  prefs: []
  type: TYPE_NORMAL
- en: '**In any case, if you want to enjoy the benefits of TorchScript, you need to
    run your model outside of a Python runtime.**'
  prefs: []
  type: TYPE_NORMAL
- en: 3 ‚Äî Build an image classification service with BentoML + TorchScript üç±
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will build a BentoML service and run it locally to serve
    the TorchScript model.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to follow along, I recommend you install the project‚Äôs dependencies
    using Poetry.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You need to download the model from S3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can save the TorchScript model locally using the BentoML API. This will
    automatically provide a tag for versioning and will allow you to easily load the
    model as a runner later on.
  prefs: []
  type: TYPE_NORMAL
- en: BentoML integrates well with TorchScript so you can save the model by calling
    the **bentoml.torchscript.save_model** method.
  prefs: []
  type: TYPE_NORMAL
- en: More info [here](https://docs.bentoml.org/en/latest/reference/frameworks/torchscript.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: You can check that the model has been saved with a unique identifier by running
    `**bentoml models list**`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1308db90a0ec0ba4f67e44dde99a5a78.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Now that the model is saved with BentoML API, we can create a service.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first import the dependencies, load the model, get a runner from it, and
    define a service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Then, we define an API route that takes an image as input and returns a JSON
    as output with the predicted labels and the corresponding probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To launch the service locally, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/10673f7782dab9ac0e40a54a8b51a781.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: If you want to try out the API, visit the Swagger UI (at http://localhost:3000)
    and upload your image directly.
  prefs: []
  type: TYPE_NORMAL
- en: Here‚Äôs an example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/85f1af3109eab9be40f447f7b7a3a92f.png)![](../Images/18fb9cd72b11e7201db2cceb437072fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Demo
  prefs: []
  type: TYPE_NORMAL
- en: 4 ‚Äî Deploy the service to the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we‚Äôll build a bento and deploy it to a cloud platform that‚Äôs
    specifically designed to host it and scale it.
  prefs: []
  type: TYPE_NORMAL
- en: '**what is a bento?**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: BentoML packages everything you need in an ML project into a distribution format
    called a ***bento*** üç±(this is where the analogy makes sense, as a *bento* is
    originally a Japanese lunch box that holds a single portion meal consisting of
    a main dish and some sides)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When a bento is built, you can deploy it to any cloud infrastructure.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: üëâ Build the bento
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To build a bento, you must first provide a configuration file called `bentofile.yaml`
    that tells how the bento must be built i.e what files should be included in it
    and what python dependencies are needed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Running the following command will build the bento.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0c346944701d58d3977879b38e8f893f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: üëâ Connect to BentoCloud and push the bento
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before pushing the bento, you need to make sure you‚Äôre logged in to a cloud
    platform that acts as a remote registry (something like Dockerhub for containers).
  prefs: []
  type: TYPE_NORMAL
- en: I was lucky enough that the BentoML team provided me with access to their [platform](https://default.cloud.bentoml.com/)
    where they push and host bentos.
  prefs: []
  type: TYPE_NORMAL
- en: Want to create an account on BentoCloud and start deploying awesome models?
    Check out this [link](https://www.bentoml.com/bento-cloud/) to schedule a demo
    and talk to the BentoML team.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: After signing up to BentoCloud, I was able to generate API tokens and log in
    using the `yatai` command. (*we‚Äôll see what Yatai is exactly in the last section
    of the post)*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0903b427eb3a8de6f4e7546219c87c43.png)'
  prefs: []
  type: TYPE_IMG
- en: Logging in to BentoCloud
  prefs: []
  type: TYPE_NORMAL
- en: 'Once logged in, you can push: this will upload your **bento** and the underlying
    **model** simultaneously to the cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/152cbab52fbc7f071a868063d16e756d.png)'
  prefs: []
  type: TYPE_IMG
- en: Pushing my first bento
  prefs: []
  type: TYPE_NORMAL
- en: You can check that these two artifacts are visible on the interface, along with
    other bentos and models (from other users)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0814a55f6b3c42dd5cd895ba002158f6.png)![](../Images/fb0a670457ba7f931ffdf47c0bce791e.png)'
  prefs: []
  type: TYPE_IMG
- en: the bento and the model
  prefs: []
  type: TYPE_NORMAL
- en: üëâ Create a deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deploying your bento from the platform is very simple. Head over to the Deployments
    tab and click on the top right black **Create** button.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c41ada79e9c7ddc44a97b01cc87ec1f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 'This will open up the following form where you need to fill in the deployment
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The cluster information and the deployment name**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/2b9136dfb15c86c8fed2175ff0c0f7d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: '**The bento repository and the version**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/bb31da335e8ee3ded50cee65f1336758.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: '**Configurations for the API server: number of replicas, CPU, and memory requests**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/819afa1a457ad5a190738bef214236cb.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuration for each runner: there‚Äôs only one in our case**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/26e4f5d55318af30ae6767b82ecc26e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Once you hit the **Submit** button, you can start the deployment. This will
    build the image and deploy the API server and the runners on separate pods. **This
    is a killer feature that separates BentoML from any serving platform I‚Äôve used
    before.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/79466e715e49f1f46edf877143a8480c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 'Once your bento is successfully deployed, click on your deployment, then on
    the URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0d4602dc41a74aa5ff647c88fbec0844.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If everything works as expected, opening this URL in the browser will lead
    you to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/987e5bf21635aaeaa84549e05302b3df.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The API is now deployed: you can query it from everywhere on the internet.'
  prefs: []
  type: TYPE_NORMAL
- en: Need to manage your bentos on your own infrastructure? Try Yatai
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can replicate the BentoCloud platform on your own cloud infrastructure thanks
    to the [Yatai](https://github.com/bentoml/Yatai) project that the BentoML team
    open-sourced.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f86f6feb8ad7b0e333465938d3915e03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'source: [https://github.com/bentoml/Yatai](https://github.com/bentoml/Yatai)'
  prefs: []
  type: TYPE_NORMAL
- en: Yatai acts as a centralized registry that you can deploy to any Kebernetes-native
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: It‚Äôs compatible with all major cloud platforms (AWS, Azure, and GCP),
  prefs: []
  type: TYPE_NORMAL
- en: It helps you manage the deployment lifecycle to deploy, update, or roll back
    via API or Web UI.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion üîö
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you‚Äôve made it this far, I thank you for your time and hope you‚Äôve enjoyed
    learning about PyTorch Lightning, TorchScript, and BentoML.
  prefs: []
  type: TYPE_NORMAL
- en: Combined together, these three tools help you prototype and deploy industrial-grade
    deep learning models with the best-in-class DevOps practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, there‚Äôs room for improvement in the different steps of the workflow
    I‚Äôve shown: I just hope this post was a good starter to dive into MLOps.'
  prefs: []
  type: TYPE_NORMAL
- en: Resources üóû
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://towardsdatascience.com/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d](/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://towardsdatascience.com/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d](/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://youtu.be/Dk88zv1KYMI](https://youtu.be/Dk88zv1KYMI)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://youtu.be/2awmrMRf0dA](https://youtu.be/2awmrMRf0dA)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New to Medium? You can subscribe for $5 per month and unlock unlimited articles
    on various topics (tech, design, entrepreneurship‚Ä¶) You can support me by clicking
    on my referral [link](https://ahmedbesbes.medium.com/membership)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](https://ahmedbesbes.medium.com/membership?source=post_page-----f61136fd0244--------------------------------)
    [## Join Medium with my referral link - Ahmed Besbes'
  prefs: []
  type: TYPE_NORMAL
- en: Read every story from Ahmed Besbes (and thousands of other writers on Medium).
    Your membership fee directly supports‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ahmedbesbes.medium.com](https://ahmedbesbes.medium.com/membership?source=post_page-----f61136fd0244--------------------------------)
  prefs: []
  type: TYPE_NORMAL
