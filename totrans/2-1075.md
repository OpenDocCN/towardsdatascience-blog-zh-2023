# 谷歌如何利用虚假数据集来训练生成音乐AI

> 原文：[https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19](https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19)

[](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[![Max Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------) [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------) ·6分钟阅读·2023年5月28日

--

![](../Images/ed2c5ce433310ba9f1ace3de4d277849.png)

图片由 [James Stamler](https://unsplash.com/@jamesstamler?utm_source=medium&utm_medium=referral) 提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

在这篇文章中，我们探讨了谷歌训练其杰出的文本到音乐模型（包括MusicLM和Noise2Music）的创新方法。我们将深入了解“虚假”数据集的概念以及这些突破性模型如何利用它们。如果你对这些技术的内部运作及其对推动音乐AI的影响感到好奇，那么你来对地方了。

# **标签化音乐数据的缺乏**

像ChatGPT或Bard这样的语言模型（LLMs）在大量非结构化文本数据上进行训练。虽然收集数百万个网站的内容可能会耗费大量计算资源，但公共网络上有丰富的训练数据。相比之下，像DALL-E 2这样的文本到图像模型需要完全不同类型的数据集，即配有相应描述的图像对。

同样地，文本到音乐模型依赖于带有音乐内容描述的歌曲。然而，与图片不同，互联网上很难找到标签化的音乐。有时，像乐器、风格或情绪这样的元数据是可以获得的，但完整的深入描述则极其难以获取。这对研究人员和公司收集数据以训练生成音乐模型构成了严重问题。

2023年初，谷歌研究人员通过突破性的模型MusicLM和Noise2Music引起了音乐AI领域的广泛关注。然而，在音乐家中，对于这些模型的数据如何收集知之甚少。让我们一起深入探讨这个话题，了解谷歌音乐AI研究中使用的一些技巧。

# **谷歌如何克服数据稀缺**

## **弱关联标签**

对于 MusicLM 和 Noise2Music，谷歌依赖于另一个叫做 MuLan 的模型，该模型经过训练可以计算任何音乐片段和任何文本描述之间的相似性。为了训练 MuLan，谷歌使用了我们所说的“弱关联标签”。他们没有仔细策划一个高质量文本描述的音乐数据集，而是故意采取了不同的方法。

首先，他们从 YouTube 上的 4400 万个音乐视频中提取了 30 秒的片段，得到 37 万小时的音频。然后，音乐被标记上与视频相关的各种文本：视频标题和描述、评论、播放列表的名称等。为了减少数据集中的噪音，他们使用了一个大型语言模型来识别哪些关联文本信息包含与音乐相关的内容，并丢弃所有不相关的内容。

在我看来，弱关联标签不能被视为“伪造”数据集，因为文本信息仍然是由真实的人撰写的，并且与音乐在某种程度上确实有关。然而，这种方法确实优先考虑了数量而非质量，这在过去曾引起大多数机器学习研究人员的关注。而谷歌才刚刚开始……

## **伪标签**

Noise2Music 是一个基于扩散技术的生成音乐 AI，这种技术也用于像 DALL-E 或 Midjourney 这样的图像生成模型。

为了训练 Noise2Music，谷歌将之前的方法推向极致，从弱关联标签过渡到完全人工标签。在他们称之为“伪标签”的方法中，作者采用了一种出色的方式来收集音乐描述文本。他们让一个大型语言模型（LaMDA）为 15 万首热门歌曲写多个描述，结果得到了 400 万个描述。以下是一个描述的示例：

> 皇后乐队的《Don’t Stop Me Now》：这首充满活力的摇滚歌曲由钢琴、贝斯吉他和鼓构成。歌手们充满激情，准备好出发，充满了振奋的感觉。

随后，研究人员移除了歌曲和艺术家的名字，生成的描述理论上可以适用于其他歌曲。然而，即使有了这些描述，研究人员仍然需要将它们与合适的歌曲匹配，以获得一个大规模标注的数据集。这时，MuLan，这个经过弱关联标签训练的模型，发挥了作用。

研究人员收集了一个大规模的未标记音乐数据集，总计 34 万小时的音乐。对于这些音乐曲目中的每一个，他们利用 MuLan 来识别最匹配的人工生成的歌曲描述。本质上，每段音乐并不是映射到描述歌曲本身的文本，而是映射到描述类似音乐的文本。

# **为什么这有效？**

## 问题

在传统的机器学习中，分配给每个观察（在这种情况下是音乐片段）的标签理想情况下应该代表客观的真相。然而，音乐描述本质上缺乏客观性，这提出了第一个问题。此外，通过使用音频到文本映射技术，标签不再反映对歌曲发生的事情的“真实”表示。它们没有提供对音乐的准确描述。鉴于这些明显的缺陷，人们可能会怀疑为什么这种方法仍然能够产生有用的结果。

## 偏差 vs. 噪声

当数据集的标签分配不准确时，可能有两个主要原因：偏差和噪声。偏差指的是标签在某种特定方式上的一致性倾向不真实。例如，如果数据集经常将器乐曲标记为歌曲，但从不将歌曲标记为器乐曲，这就显示了对预测存在人声的偏向。

另一方面，噪声表示标签的一般变异性，无论方向如何。例如，如果每一首曲目都标记为“悲伤的钢琴曲”，那么数据集就会严重偏向，因为它对许多歌曲提供了一致的不准确标签。然而，由于它对每个曲目应用相同的标签，因此数据集中没有变异性，也就没有噪声。

通过将曲目映射到为其他曲目写的描述文本，我们引入了噪声。这是因为，对于大多数曲目而言，数据集中不太可能存在完美的描述。因此，大多数标签都稍有偏差，即不真实，这就产生了噪声。然而，这些标签是否有偏见？

由于现有的描述是为流行歌曲生成的，因此可以合理地假设这些描述池倾向于（西方）流行音乐。尽管如此，基于150k首独特歌曲的400万条描述，仍然可以期望有多样化的描述可供选择。此外，大多数标记的音乐数据集也表现出相同的偏向，因此这并不是这种方法相较于其他方法的独特劣势。真正使这种方法与众不同的是引入了额外的噪声。

## 噪声在机器学习中可以是可以接受的

在偏向的数据集上训练机器学习模型通常不是一种理想的方法，因为这会导致模型学习和复制对任务的偏见理解。然而，在无偏但有噪声的数据上训练机器学习模型仍然可以获得令人印象深刻的结果。让我用一个例子来说明。

请考虑下图，其中展示了两个数据集，由橙色和蓝色点组成。在没有噪声的数据集中，蓝色和橙色点是完全可分的。然而，在有噪声的数据集中，一些橙色点已移动到蓝色点簇中，反之亦然。尽管有了这些附加噪声，如果我们检查经过训练的模型，会发现两者识别的模式大致相同。这是因为即使在存在噪声的情况下，AI也会学习识别最优模式，以尽可能减少错误。

![](../Images/e0233bcba3f0802135bda41d3976caa3.png)

一个AI模型在无噪声和有噪声数据上训练的例子。图像生成使用了 [Tensorflow Neural Network Playground](https://playground.tensorflow.org)。

这个例子表明，AI确实可以从噪声数据集中学习，例如谷歌生成的数据集。然而，主要的挑战在于数据集的噪声越大，所需的训练数据量就越大，以有效地训练模型。这一理由得到了支持，因为噪声数据集相对于大小相同的无噪声数据集，固有地包含较少有价值的信息。

# 结论

总之，谷歌采用了创新技术来应对训练其生成音乐AI模型时有限的标记音乐数据的问题。他们为MuLan使用了弱相关标签，利用了来自各种音乐视频相关来源的文本信息，并使用语言模型来过滤掉无关数据。在开发Noise2Music时，他们通过为热门歌曲生成多个描述并使用预训练模型将其映射到合适的曲目，从而引入了伪标签。

虽然这些方法可能偏离了传统的标记方法，但它们仍然证明了有效性。尽管引入了噪声，模型仍然能够学习并识别最佳模式。尽管使用伪造数据集可能被认为是不寻常的，但它突显了现代语言模型在创建大规模和有价值的数据集方面的巨大潜力。

我写了很多关于音乐和AI的文章。以下是你可能喜欢的三篇文章：

+   [MusicLM — 谷歌解决了AI音乐生成的问题了吗？](/musiclm-has-google-solved-ai-music-generation-c6859e76bc3c)

+   [AudioGPT — 未来音乐创作的瞥见](/audiogpt-a-glimpse-into-the-future-of-creating-music-9e8e0c65069e)

+   [使用 Whisper 的零样本歌曲歌词转录](https://medium.com/mlearning-ai/zero-shot-song-lyrics-transcription-using-whisper-3f360499bcfe)

# 参考文献

**[1]** Huang 等人 (2022)。Mulan：音乐音频与自然语言的联合嵌入。 [https://arxiv.org/abs/2208.12415](https://arxiv.org/abs/2208.12415)

**[2]** Agostinelli 等人 (2023)。MusicLM：从文本生成音乐。 [https://arxiv.org/abs/2301.11325](https://arxiv.org/abs/2301.11325)
