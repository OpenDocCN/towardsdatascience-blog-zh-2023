- en: 'L1 vs L2 Regularization in Machine Learning: Differences, Advantages and How
    to Apply Them in Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: L1与L2正则化在机器学习中的比较：区别、优势及如何在Python中应用
- en: 原文：[https://towardsdatascience.com/l1-vs-l2-regularization-in-machine-learning-differences-advantages-and-how-to-apply-them-in-72eb12f102b5](https://towardsdatascience.com/l1-vs-l2-regularization-in-machine-learning-differences-advantages-and-how-to-apply-them-in-72eb12f102b5)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/l1-vs-l2-regularization-in-machine-learning-differences-advantages-and-how-to-apply-them-in-72eb12f102b5](https://towardsdatascience.com/l1-vs-l2-regularization-in-machine-learning-differences-advantages-and-how-to-apply-them-in-72eb12f102b5)
- en: '*Delving into L1 and L2 regularization techniques in Machine Learning to explain
    why they are important to prevent model overfitting*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*深入探讨L1和L2正则化技术，解释它们为何对防止模型过拟合至关重要*'
- en: '[](https://medium.com/@theDrewDag?source=post_page-----72eb12f102b5--------------------------------)[![Andrea
    D''Agostino](../Images/58c7c218815f25278aae59cea44d8771.png)](https://medium.com/@theDrewDag?source=post_page-----72eb12f102b5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----72eb12f102b5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----72eb12f102b5--------------------------------)
    [Andrea D''Agostino](https://medium.com/@theDrewDag?source=post_page-----72eb12f102b5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@theDrewDag?source=post_page-----72eb12f102b5--------------------------------)[![Andrea
    D''Agostino](../Images/58c7c218815f25278aae59cea44d8771.png)](https://medium.com/@theDrewDag?source=post_page-----72eb12f102b5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----72eb12f102b5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----72eb12f102b5--------------------------------)
    [Andrea D''Agostino](https://medium.com/@theDrewDag?source=post_page-----72eb12f102b5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----72eb12f102b5--------------------------------)
    ·8 min read·Feb 23, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----72eb12f102b5--------------------------------)
    ·阅读时间8分钟·2023年2月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/423a619cb1e90d37b508328d6453e1d2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/423a619cb1e90d37b508328d6453e1d2.png)'
- en: Image by author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Machine Learning is a discipline that is experiencing enormous development in
    the technological and industrial fields.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个在技术和工业领域经历巨大发展的学科。
- en: Thanks to its algorithms and modeling techniques, it is possible to build models
    capable of learning from past data, generalizing and making predictions on new
    data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 得益于其算法和建模技术，我们可以构建能够从过去数据中学习、泛化并对新数据进行预测的模型。
- en: However, in some cases, **models can overfit the training data and lose their
    ability to generalize**. This phenomenon is called *overfitting*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，**模型可能会过拟合训练数据，从而失去泛化能力**。这种现象称为*过拟合*。
- en: It is quite important for analysts to understand what overfitting is and why
    it represents one of the main obstacles in machine learning when it comes to creating
    a predictive model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对分析师来说，理解过拟合是什么以及为什么它是创建预测模型时的主要障碍之一是相当重要的。
- en: A general idea of overfitting is this one
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的一个大致概念是这样的
- en: When a model is too complex or fits too well with the training data, it can
    become very accurate for that specific data, but will generalize poorly on data
    it has never seen before. **This means that the model will be ineffective when
    applied to new data in real life**.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当一个模型过于复杂或对训练数据拟合得过好时，它可能对这些特定数据非常准确，但对从未见过的数据的泛化能力差。**这意味着模型在现实生活中应用于新数据时将无效**。
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Want to learn more about overfitting? Read the article titled [*Overcome the
    biggest obstacle in machine learning: Overfitting*](https://medium.com/towards-data-science/overcome-the-biggest-obstacle-in-machine-learning-overfitting-cca026873970)published
    on TDS'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 想了解更多关于过拟合的信息？阅读标题为 [*克服机器学习中的最大障碍：过拟合*](https://medium.com/towards-data-science/overcome-the-biggest-obstacle-in-machine-learning-overfitting-cca026873970)
    的文章，该文章发表在TDS上。
- en: '**Regularization techniques can be used to prevent overfitting.**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**正则化技术可以用于防止过拟合。**'
- en: The term *regularization* encompasses a set of techniques that **tend to simplify
    a predictive model**. In this article, we will focus on two regularization techniques,
    **L1 and L2**, explain their differences and show how to apply them in Python.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*正则化*一词涵盖了一组**简化预测模型的技术**。在这篇文章中，我们将重点介绍两种正则化技术，**L1和L2**，解释它们的区别，并展示如何在Python中应用它们。'
- en: What is regularization and why is it important?
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是正则化，为什么它很重要？
- en: In simple terms, regularizing a model means changing its learning behavior during
    the training phase.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，正则化模型意味着在训练阶段改变其学习行为。
- en: Regularization helps prevent overfitting by **adding a penalty on model complexity**
    — if a model is too complex, it will be penalized during training, which helps
    maintain a good balance between the model’s complexity and its ability to generalize
    about data he has never seen before.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化通过 **对模型复杂度施加惩罚** 来帮助防止过拟合——如果模型过于复杂，在训练过程中将受到惩罚，这有助于保持模型复杂性和对未见数据的泛化能力之间的良好平衡。
- en: To add an L1 or L2 regularization, **we are going to alter the loss function
    of the model**. This is the function that the learning algorithm tries to optimize
    during the training phase.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加 L1 或 L2 正则化，**我们将修改模型的损失函数**。这是学习算法在训练阶段试图优化的函数。
- en: Regularization occurs by assigning a penalty that increases based on how complex
    the model becomes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化通过分配一个基于模型复杂度增加的惩罚来发生。
- en: If we take linear regression as an example, MSE (mean squared error — read more
    about the evaluation metrics of a regression model here) is the typical loss function
    and can be expressed as
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以线性回归为例，MSE（均方误差——有关回归模型评估指标的更多信息请点击这里）是典型的损失函数，可以表示为
- en: '![](../Images/76b22fdf87b529c31efc3660b8bd724d.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76b22fdf87b529c31efc3660b8bd724d.png)'
- en: Where the goal of the algorithm is to minimize the difference between the prediction
    *f(x)* and the observed *y*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 其中算法的目标是最小化预测值 *f(x)* 与观察值 *y* 之间的差异。
- en: In the equation, *f(x)* is the regression line, and this will have be equal
    to
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在方程中，*f(x)* 是回归线，这将等于
- en: '![](../Images/c521b27104c9033d345afdac196b95ad.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c521b27104c9033d345afdac196b95ad.png)'
- en: The algorithm will therefore have to find the values of the parameters *w* and
    *b* from the training set by minimizing MSE.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，算法将需要通过最小化 MSE 从训练集找出参数 *w* 和 *b* 的值。
- en: A model is considered less complex if some parameters *w* are close to or equal
    to zero.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果一些参数 *w* 接近或等于零，则模型被认为较少复杂。
- en: L1 vs L2 regularization
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: L1 和 L2 正则化
- en: Now let’s see the differences between L1 and L2 regularization.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 L1 和 L2 正则化之间的区别。
- en: L1 regularization
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: L1 正则化
- en: L1 regularization, **also known as “Lasso”**, adds a penalty on the sum of the
    absolute values of the model weights.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: L1 正则化，**也称为“套索”**，对模型权重的绝对值总和施加惩罚。
- en: '**This means that weights that do not contribute much to the model will be
    zeroed**, which can lead to automatic feature selection (as weights corresponding
    to less important features will in fact be zeroed).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**这意味着对模型贡献不大的权重将被归零**，这可能导致自动特征选择（因为对应于不重要特征的权重实际上会被归零）。'
- en: This makes L1 particularly useful for feature selection problems and sparse
    models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 L1 在特征选择问题和稀疏模型中尤其有用。
- en: Taking the MSE formula above as an example, an L1 regularization would look
    like this
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以上述 MSE 公式为例，L1 正则化看起来如下
- en: '![](../Images/5946f1f3ce1469a686f87f68e1975f7d.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5946f1f3ce1469a686f87f68e1975f7d.png)'
- en: where *C* is a **model hyperparameter that controls the intensity of the regularization.**
    The higher the value of *C*, the more our weights will tend towards zero.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *C* 是一个 **控制正则化强度的模型超参数**。*C* 的值越高，我们的权重越会趋向于零。
- en: In jargon, this is would be called **a sparse model**, where most of the parameters
    have the value of zero.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 行话中，这被称为 **稀疏模型**，其中大多数参数的值为零。
- en: The risk here is that **a very high value of *C* will cause the model to underfit**,
    which is the opposite of overfitting — i.e. it won’t capture the patterns in our
    data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的风险是 **非常高的 *C* 值会导致模型欠拟合**，这与过拟合相反——即它不会捕捉到我们数据中的模式。
- en: L2 regularization
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: L2 正则化
- en: On the other hand, L2 regularization, also called **Ridge regularization**,
    adds the square of the weights to the regularization term.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，L2 正则化，也称为 **岭回归正则化**，将权重的平方添加到正则化项中。
- en: '**This means that larger weights are reduced but not zeroed**, which leads
    to models with fewer variables than L1 regularization but with more distributed
    weights.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**这意味着较大的权重会被减少但不会被归零**，这导致与 L1 正则化相比，模型的变量较少但权重更分散。'
- en: L2 regularization is especially useful when you have many highly correlated
    variables, as it tends to “spread” the weight across all the variables instead
    of focusing on just a few of them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: L2 正则化在你有很多高度相关的变量时尤其有用，因为它倾向于“分散”权重到所有变量中，而不是只关注其中的一些。
- en: As before, let’s see how the initial equation changes to integrate L2
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，让我们看看初始方程如何变化以集成 L2。
- en: '![](../Images/a0e14dbcb4f39719b2ff763aa445b6b2.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0e14dbcb4f39719b2ff763aa445b6b2.png)'
- en: L2 regularization can improve model stability when training data is noisy or
    incomplete, by reducing the impact of outliers or noise on variables.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: L2 正则化可以提高模型的稳定性，尤其在训练数据噪声或不完整时，通过减少异常值或噪声对变量的影响。
- en: How to apply regularization in Sklearn and Python
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在 Sklearn 和 Python 中应用正则化
- en: In this example we will see how to applyregularization to a logistic regression
    model for a classification problem.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将看到如何将正则化应用于逻辑回归模型以解决分类问题。
- en: '**We will see how the performance changes for different values of C** and compare
    how accurate the model is in modeling the input data.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们将看到性能如何随 C 值的变化而变化**，并比较模型对输入数据的拟合准确性。'
- en: We will use the famous *breast cancer dataset* from Sklearn. Let’s start by
    seeing how to import it, along with all the libraries.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Sklearn 中著名的 *乳腺癌数据集*。让我们首先看看如何导入它以及所有的库。
- en: '[PRE0]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Being a classification problem, we will use accuracy to measure the performance
    of the model. Read one of my articles on [how to measure the performance of binary
    classification models](https://medium.com/towards-data-science/the-explanation-you-need-on-binary-classification-metrics-321d280b590f)
    if you are interested in learning more.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作为分类问题，我们将使用准确率来衡量模型的性能。如果你有兴趣了解更多，请阅读我关于[如何衡量二分类模型性能](https://medium.com/towards-data-science/the-explanation-you-need-on-binary-classification-metrics-321d280b590f)的文章。
- en: Now let’s create a function to apply the comparison between L1 and L2 regularization
    on the dataframe.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个函数来对 dataframe 上的 L1 和 L2 正则化进行比较。
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We apply this logic by looking at the L1 regularization
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过观察 L1 正则化来应用这一逻辑。
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/3a79f0cff34cf347a844335ebcbc87b0.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a79f0cff34cf347a844335ebcbc87b0.png)'
- en: How L1 regularization impacts model performance. Image by author.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: L1 正则化如何影响模型性能。图像由作者提供。
- en: We see how the L1 regularization flattens the model coefficients close to zero
    for many levels of C. **The coefficients with the highest values are, according
    to the model, the most important features for the prediction.**
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到 L1 正则化如何使模型系数在许多 C 值下接近于零。**根据模型，系数值最高的是预测中最重要的特征**。
- en: We also see the onset of overfitting — at *C=100*, the performance of the training
    set increases while that in the test set decreases.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也看到过拟合的开始——在*C=100*时，训练集的性能提高，而测试集的性能下降。
- en: We now apply the same function to evaluate the effects of L2.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在应用相同的函数来评估 L2 的效果。
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/213b3269b4e3e6e88891fe5e904ae8ad.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/213b3269b4e3e6e88891fe5e904ae8ad.png)'
- en: How L2 regularization impacts model performance. Image by author.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: L2 正则化如何影响模型性能。图像由作者提供。
- en: The coefficients are always above zero, **thus creating a distribution of gradually
    increasing weights for the most relevant features**. We note a very slight overfitting
    after the value of *C=100.*
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 系数总是大于零，**从而为最相关的特征创建了逐渐增加的权重分布**。我们注意到在*C=100*时有非常轻微的过拟合。
- en: Other regularization techniques
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他正则化技术
- en: In addition to L1 and L2 regularizations, there are other regularization techniques
    that can be used in machine learning models. Among these techniques we find **dropout
    and early stopping.**
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 L1 和 L2 正则化，还有其他正则化技术可以应用于机器学习模型。**其中包括 dropout 和 early stopping**。
- en: Dropout
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Dropout
- en: Dropout is a technique used in neural networks to reduce overfitting. **Dropout
    works by randomly shutting down some neurons during the training phase**, forcing
    the neural network to find alternative ways to represent the data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout 是一种在神经网络中减少过拟合的技术。**Dropout 通过在训练阶段随机关闭一些神经元来工作**，迫使神经网络找到其他方法来表示数据。
- en: Early stopping
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Early stopping
- en: Early stopping is another technique used to avoid overfitting in machine learning
    models. **This technique consists of stopping model training when the performance
    on the validation set starts to deteriorate**. This prevents the model from overlearning
    the training data and not generalizing well on data not seen before.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Early stopping 是另一种用于避免机器学习模型过拟合的技术。**这种技术包括在验证集上的性能开始恶化时停止模型训练**。这可以防止模型过度学习训练数据而在未见过的数据上泛化效果不好。
- en: Want to learn more about early stopping? Read the article titled [*Early Stopping
    in TensorFlow — prevent overfitting of a neural network*](/control-the-training-of-your-neural-network-in-tensorflow-with-callbacks-ba2cc0c2fbe8)published
    on TDS
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 想了解更多关于早停的信息？阅读标题为[*TensorFlow 中的早停 - 防止神经网络过拟合*](/control-the-training-of-your-neural-network-in-tensorflow-with-callbacks-ba2cc0c2fbe8)的文章，发表于
    TDS
- en: In general, overfitting can be avoided by using a combination of regularization
    techniques. However, the choice of the most appropriate techniques will depend
    on the characteristics of the dataset and the machine learning model used.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，通过使用正则化技术的组合可以避免过拟合。然而，最合适的技术选择将取决于数据集和所用机器学习模型的特性。
- en: Conclusions
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In conclusion, regularization is an important machine learning technique that
    helps improve model performance **by avoiding overfitting on training data.**
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，正则化是一种重要的机器学习技术，有助于提高模型性能**通过避免在训练数据上过拟合。**
- en: L1 and L2 regularizations are the most used techniques for this purpose, but
    there are others too that can be useful depending on context. For example, dropout
    is almost always seen in the context of deep learning, that is with neural networks.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: L1 和 L2 正则化是最常用的技术，但根据上下文，还有其他可能有用的技术。例如，dropout 几乎总是出现在深度学习中，即神经网络中。
- en: In our example we have seen how regularization affects the performance of the
    logistic regression model and how the value of C affects the regularization itself.
    We also examined how model coefficients change as the value of C changes, and
    how L1 and L2 regularization affect model coefficients differently.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们看到了正则化如何影响逻辑回归模型的性能，以及 C 的值如何影响正则化本身。我们还检查了 C 值变化时模型系数的变化，以及 L1 和
    L2 正则化如何以不同的方式影响模型系数。
- en: Thank you for taking the time to read my article! 😊
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您抽出时间阅读我的文章！😊
- en: Till next time!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下次见！
- en: '**If you want to support my content creation activity, feel free to follow
    my referral link below and join Medium’s membership program**. I will receive
    a portion of your investment and you’ll be able to access Medium’s plethora of
    articles on data science and more in a seamless way.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您想支持我的内容创作活动，请随时通过以下推荐链接加入 Medium 的会员计划**。我将获得您投资的一部分，您将能够无缝访问 Medium 上的数据科学等众多文章。'
- en: '[](https://medium.com/@theDrewDag/membership?source=post_page-----72eb12f102b5--------------------------------)
    [## Join Medium with my referral link - Andrea D''Agostino'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@theDrewDag/membership?source=post_page-----72eb12f102b5--------------------------------)
    [## 通过我的推荐链接加入 Medium - Andrea D''Agostino'
- en: Read every story from Andrea D'Agostino (and thousands of other writers on Medium).
    Your membership fee directly…
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阅读 Andrea D'Agostino 的每个故事（以及 Medium 上其他数千名作者的故事）。您的会员费直接…
- en: medium.com](https://medium.com/@theDrewDag/membership?source=post_page-----72eb12f102b5--------------------------------)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@theDrewDag/membership?source=post_page-----72eb12f102b5--------------------------------)
- en: Recommended Reads
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐阅读
- en: For the interested, here are a list of books that I recommended for each ML-related
    topic. There are ESSENTIAL books in my opinion and have greatly impacted my professional
    career.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对感兴趣的读者，这里有我推荐的每个与机器学习相关主题的书单。这些书在我看来是**必读的**，对我的职业生涯产生了重大影响。
- en: '*Disclaimer: these are Amazon affiliate links. I will receive a small commission
    from Amazon for referring you these items. Your experience won’t change and you
    won’t be charged more, but it will help me scale my business and produce even
    more content around AI.*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：这些是亚马逊附属链接。我将因推荐这些商品而从亚马逊获得少量佣金。您的体验不会改变，也不会额外收费，但这将帮助我扩大业务，并制作更多关于 AI
    的内容。*'
- en: '**Intro to ML**: [*Confident Data Skills: Master the Fundamentals of Working
    with Data and Supercharge Your Career*](https://amzn.to/3WZ51cE)by Kirill Eremenko'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习简介**: [*Confident Data Skills: Master the Fundamentals of Working with
    Data and Supercharge Your Career*](https://amzn.to/3WZ51cE)由 Kirill Eremenko 著'
- en: '**Sklearn / TensorFlow**: [*Hands-On Machine Learning with Scikit-Learn, Keras,
    and TensorFlow*](https://amzn.to/3jseVGb) by Aurelien Géron'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sklearn / TensorFlow**: [*Hands-On Machine Learning with Scikit-Learn, Keras,
    and TensorFlow*](https://amzn.to/3jseVGb) 由 Aurelien Géron 著'
- en: '**NLP**: [*Text as Data: A New Framework for Machine Learning and the Social
    Sciences*](https://amzn.to/3l9FO22)by Justin Grimmer'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理**: [*Text as Data: A New Framework for Machine Learning and the Social
    Sciences*](https://amzn.to/3l9FO22)由 Justin Grimmer 著'
- en: '**Sklearn / PyTorch**: [*Machine Learning with PyTorch and Scikit-Learn: Develop
    machine learning and deep learning models with Python*](https://amzn.to/3wYZf0e)
    by Sebastian Raschka'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sklearn / PyTorch**: [*使用 PyTorch 和 Scikit-Learn 进行机器学习：用 Python 开发机器学习和深度学习模型*](https://amzn.to/3wYZf0e)
    作者 Sebastian Raschka'
- en: '**Data Viz**: [*Storytelling with Data: A Data Visualization Guide for Business
    Professionals*](https://amzn.to/3HUtGtB) by Cole Knaflic'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据可视化**: [*用数据讲故事：商业专业人士的数据可视化指南*](https://amzn.to/3HUtGtB) 作者 Cole Knaflic'
- en: Useful Links (written by me)
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有用的链接（由我编写）
- en: '**Learn how to perform a top-tier Exploratory Data Analysis in Python**: [*Exploratory
    Data Analysis in Python — A Step-by-Step Process*](/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**了解如何在 Python 中执行顶级探索性数据分析**: [*Python 中的探索性数据分析 — 步骤指南*](/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)'
- en: '**Learn the basics of TensorFlow**: [*Get started with TensorFlow 2.0 — Introduction
    to deep learning*](https://medium.com/towards-data-science/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习 TensorFlow 的基础知识**: [*开始使用 TensorFlow 2.0 — 深度学习简介*](https://medium.com/towards-data-science/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa)'
- en: '**Perform text clustering with TF-IDF in Python**: [*Text Clustering with TF-IDF
    in Python*](https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在 Python 中使用 TF-IDF 执行文本聚类**: [*使用 TF-IDF 在 Python 中进行文本聚类*](https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7)'
