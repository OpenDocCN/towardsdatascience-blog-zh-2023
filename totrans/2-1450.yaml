- en: Low Code Time Series Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/low-code-time-series-analysis-2d5d02b5474b](https://towardsdatascience.com/low-code-time-series-analysis-2d5d02b5474b)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using Darts to streamline your Python time series analysis development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pierpaoloippolito28.medium.com/?source=post_page-----2d5d02b5474b--------------------------------)[![Pier
    Paolo Ippolito](../Images/981abb84149adab275473b76bdbde66f.png)](https://pierpaoloippolito28.medium.com/?source=post_page-----2d5d02b5474b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2d5d02b5474b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2d5d02b5474b--------------------------------)
    [Pier Paolo Ippolito](https://pierpaoloippolito28.medium.com/?source=post_page-----2d5d02b5474b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2d5d02b5474b--------------------------------)
    ·6 min read·Mar 8, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17fb463f57753c82304972f72c3e8f14.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Afif Ramdhasuma](https://unsplash.com/@javaistan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time Series Forecasting is a unique field in Machine Learning. When working
    with time series in fact there is an inherent time dependency between the different
    points in the series and therefore the different observations are highly dependent
    on each other. If you are interested in learning more about the basics of time
    series analysis, additional details can be found in [this my previous article](https://pierpaolo28.github.io/blog/blog58/).
  prefs: []
  type: TYPE_NORMAL
- en: In the case of classical classification and regression problems [***scikit-learn***](https://scikit-learn.org/stable/)
    is able to provide most of the utils we might need to get started with a good
    baseline (e.g. data pre-processing, low code models. evaluation metrics, etc…),
    although with time series the story is quite different. Many specialized libraries
    have become available throughout the years to cover some of the key steps in a
    Time Series Analysis workflow (e.g. [***statsmodels***](https://www.statsmodels.org/stable/index.html),
    [***Prophet***](https://facebook.github.io/prophet/), custom backtesting, etc…)
    but until [***Darts***](https://unit8co.github.io/darts/) was not possible to
    cover everything within a single solution.
  prefs: []
  type: TYPE_NORMAL
- en: Demonstration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As part of this article, we are going to walk through a practical demonstration
    of how to use Darts to analyze the [Delhi Daily Climate time series dataset from
    Kaggle](https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data?select=DailyDelhiClimateTrain.csv)
    [1]. All the code used throughout this article (and more!) is available on [my
    GitHub](https://github.com/pierpaolo28) and [Kaggle accounts](https://www.kaggle.com/pierpaolo28).
  prefs: []
  type: TYPE_NORMAL
- en: First of all, we need to make sure to have Darts installed in our environment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Data Preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, we are ready to import the necessary libraries and datasets (Figure
    1). In order to facilitate our analysis, the date column is first converted from
    string to datetime and then set as the index of the dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a38db0104afb4cfb1c4ef8c1cd3acb75.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: [Delhi Daily Climate time series dataset](https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data?select=DailyDelhiClimateTrain.csv)
    (Image by Author).'
  prefs: []
  type: TYPE_NORMAL
- en: Once cleaned the dataset, we can now divide it into training and test subsets
    and visualize the time series (Figure 2). For our analysis, we are just going
    to focus on the mean temperature for the moment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/8ab4246beaae05ae345aedd788c976b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Daily Temperature in Delhi Time Series (Image by Author).'
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to their nature, time series are usually processed as part of real-time
    or streaming services, this can although make them more susceptible to wrong measurements
    and the generation of outliers. In order to monitor our time series for possible
    abnormal values, different anomaly detection techniques can be used. Two possible
    approaches are using quantiles or thresholds. With quantiles, we decide to flag
    the top and bottom percent of our values in the series as outliers, while with
    thresholds we specify fixed reference levels above or below which each value is
    flagged as anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: In the example below, considering anything below 3% and above 97% as outliers
    leads to an overall percentage of values outside quantiles of 5.8% (Figure 3).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f059d64fb8e1ce3595ffbc7279336a6b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Quantile Anomaly Detection (Image by Author).'
  prefs: []
  type: TYPE_NORMAL
- en: Baseline Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, we are ready to dive deeper into our time series and check if
    it’s present any form of seasonality. As expected and shown in the code snippet
    below, the series seems to statistically follow a similar seasonal pattern approximately
    every year.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Given this information, we can train a first naive baseline model which just
    takes into account the seasonal pattern in the series and no other information
    (Figure 4). Using this approach, results in 11.35% MAPE (Mean Absolute Percentage
    Error). Two of the main advantages of using MAPE as our evaluation metrics are:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the absolute value, positive and negative errors are not canceled out.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The errors are not dependent on the scaling of the dependent variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/e54613cd5ce0c3ee567ad08f9bf82c9b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Baseline Model Forecasting (Image by Author).'
  prefs: []
  type: TYPE_NORMAL
- en: Statistical Models selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Provided now with a good baseline model, we are ready to experiment with some
    more advanced techniques (e.g. Exponential Smoothing, [ARIMA](/stock-market-analysis-using-arima-8731ded2447a),
    AutoARIMA, Prophet). If needed, many additional models such as: CatBoost, [Kalman
    Filters](/optimal-estimation-algorithms-kalman-and-particle-filters-be62dcb5e83),
    Random Forests, Recurrent Neural Networks, and Temporal Convolutional Networks
    are available as part of Darts.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Given the results above, Prophet seems to be the most promising of the models
    considered so far as part of the analysis. In any case, with some additional work,
    the results could even be improved using [Hyper-parameter optimization](/hyperparameters-optimization-526348bb8e2d),
    especially by taking advantage of business domain knowledge with traditional statistical
    models such as ARIMA and Exponential Smoothing. Additional details about how ARIMA
    works and its different hyperparameters can be found [here.](/stock-market-analysis-using-arima-8731ded2447a)
  prefs: []
  type: TYPE_NORMAL
- en: Backtesting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to further validate the goodness of our model, we can now test it by
    playing it out using the available historical data (Figure 5). In this case, a
    MAPE of 7.8% is registered.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/bd95ff3e91482cc17126330bed048a8c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Prophet Backtesting (Image by Author).'
  prefs: []
  type: TYPE_NORMAL
- en: Covariates Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To conclude our analysis, we can now check if using the information stored
    in the other columns of the dataset such as the humidity and wind speed could
    help us to create a more performant model. There are 2 main types of covariates:
    past and future. With past covariates, just the past values are available at prediction
    time, instead with future covariates also future values are available at prediction
    time.'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the [N-BEATS (Neural Basis Expansion Analysis Time Series)
    model](https://arxiv.org/abs/1905.10437) is used with the humidity and wind speed
    columns used as past covariates (Figure 6).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9b1fa7c07d5c1dc8417660bf92e5dd32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Covariates Analysis Forecasting (Image by Author).'
  prefs: []
  type: TYPE_NORMAL
- en: As a result of the training process, a MAPE score of 10.9% is registered, therefore
    underperforming our original Prophet model in this occasion.
  prefs: []
  type: TYPE_NORMAL
- en: Contacts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you want to keep updated with my latest articles and projects [follow me
    on Medium](https://pierpaoloippolito28.medium.com/subscribe) and subscribe to
    my [mailing list](http://eepurl.com/gwO-Dr). These are some of my contacts details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Linkedin](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Personal Website](https://pierpaolo28.github.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Medium Profile](https://towardsdatascience.com/@pierpaoloippolito28)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GitHub](https://github.com/pierpaolo28)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kaggle](https://www.kaggle.com/pierpaolo28)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bibliography
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] “Daily Climate time series data” (SUMANTHVRAO, License [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)).
    Accessed at: [https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data?select=DailyDelhiClimateTrain.csv](https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data?select=DailyDelhiClimateTrain.csv)'
  prefs: []
  type: TYPE_NORMAL
