["```py\n[Introduction](#b210) [1\\. Encoding](#a96e)\n  [1.1 Label Encoding using Scikit-learn](#c4cb)\n  [1.2 One-Hot Encoding using Scikit-learn, Pandas and Tensorflow](#534e)\n[2\\. Feature Hashing](#fbed)\n  [2.1 Feature Hashing using Scikit-learn](#5dc0)\n[3\\. Binning / Bucketizing](#cfdc)\n  [3.1 Bucketizing using Pandas](#fc49)\n  [3.2 Bucketizing using Tensorflow](#b15b)\n  [3.3 Bucketizing using Scikit-learn](#ba05)\n[4\\. Transformer](#dd6f)\n  [4.1 Log-Transformer using Numpy](#1a85)\n  [4.2 Box-Cox Function using Scipy](#cd49)\n[5\\. Normalize / Standardize](#cd49)\n  [5.1 Normalize and Standardize using Scikit-learn](#b359)\n[6\\. Feature Crossing](#0714)\n  [6.1 Feature Crossing in Polynomial Regression](#3918)\n  [6.2 Feature Crossing and the Kernel-Trick](#827a)\n[7\\. Principal Component Analysis (PCA)](#f4b0)\n  [7.1 PCA using Scikit-learn](#5065)\n[Summary](#863b)\n[References](#5283)\n```", "```py\nimport pandas as pd\n\n# load dataset - census income\ncensus_income = pd.read_csv(r'../input/income/train.csv')\n```", "```py\nfrom sklearn import preprocessing\n\n# define and fit LabelEncoder\nle = preprocessing.LabelEncoder()\nle.fit(census_income[\"education\"])\n\n# Use the trained LabelEncoder to label the education column\ncensus_income[\"education_labeled\"] = le.transform(census_income[\"education\"])\n\ndisplay(census_income[[\"education\", \"education_labeled\"]])\n```", "```py\neducation_labels = {'Doctorate':5, 'Masters':4, 'Bachelors':3, 'HS-grad':2, '12th':1, '11th':0}\n\ncensus_income['education_labeled_pandas']=census_income['education'].map(education_labels)\n\ncensus_income[[\"education\", \"education_labeled_pandas\"]]\n```", "```py\nimport pandas as pd\n\neducation_one_hot_pandas = pd.get_dummies(census_income[\"education\"], prefix='education')\neducation_one_hot_pandas.head(2)\n```", "```py\nfrom sklearn import preprocessing\n\nlb = preprocessing.LabelBinarizer()\nlb.fit(census_income[\"education\"])\n\neducation_one_hot_sklearn_binar = pd.DataFrame(lb.transform(census_income[\"education\"]), columns=lb.classes_)\neducation_one_hot_sklearn_binar.head(2)\n```", "```py\nfrom sklearn.preprocessing import OneHotEncoder\n\n# define and fit the OneHotEncoder\nohe = OneHotEncoder()\nohe.fit(census_income[['education']])\n\n# transform the data\neducation_one_hot_sklearn = pd.DataFrame(ohe.transform(census_income[[\"education\"]]).toarray(), columns=ohe.categories_[0])\neducation_one_hot_sklearn.head(3)\n```", "```py\nimport sklearn \nimport pandas as pd\n\n# load data set\ncensus_income = pd.read_csv(r'../input/income/train.csv')\neducation_feature = census_income.groupby(by=[\"education\"]).count().reset_index()[\"education\"].to_frame()\n\n############################################################################################################\n# Apply the hash function, here MurmurHash3 \n############################################################################################################\ndef hash_function(row):\n    return(sklearn.utils.murmurhash3_32(row.education))\n\neducation_feature[\"education_hash\"] = education_feature.apply(hash_function, axis=1)\neducation_feature\n```", "```py\n############################################################################################################\n# Apply mod function\n############################################################################################################\nn_features = 8\n\ndef mod_function(row):\n    return(abs(row.education_hash) % n_features)\n\neducation_feature[\"education_hash_mod\"] = education_feature.apply(mod_function, axis=1)\neducation_feature.head(5)\n```", "```py\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\n# define Feature Hashing Vectorizer\nvectorizer = HashingVectorizer(n_features=8, norm=None, alternate_sign=False, ngram_range=(1,1), binary=True)\n\n# fit the hashing vectorizer and transform the education column\nX = vectorizer.fit_transform(education_feature[\"education\"])\n\n# transformed and raw column to data frame\ndf = pd.DataFrame(X.toarray()).assign(education = education_feature[\"education\"])\ndisplay(df)\n```", "```py\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# creating a dictionary\nsns.set_style(\"whitegrid\")\nplt.rc('font', size=16) #controls default text size\nplt.rc('axes', titlesize=16) #fontsize of the title\nplt.rc('axes', labelsize=16) #fontsize of the x and y labels\nplt.rc('xtick', labelsize=16) #fontsize of the x tick labels\nplt.rc('ytick', labelsize=16) #fontsize of the y tick labels\nplt.rc('legend', fontsize=16) #fontsize of the legend\n\n# load dataset - census income\ncensus_income = pd.read_csv(r'../input/income/train.csv')\n\n# define figure\nfig, (ax1, ax2) = plt.subplots(2)\nfig.set_size_inches(18.5, 10.5)\n\n# plot age histogram\nage_count = census_income.groupby(by=[\"age\"])[\"age\"].count()\nax1.bar(age_count.index, age_count, color='black')\nax1.set_ylabel(\"Counts\")\nax1.set_xlabel(\"Age\")\n\n# binning age\ndef age_bins(age):\n    if age < 29:\n        return \"1 - young\"\n    if age < 60 and age >= 29:\n        return \"2 - middle-aged\"\n    else:\n        return \"3 - old-aged\"\n\n# apply trans. function\ncensus_income[\"age_bins\"] = census_income[\"age\"].apply(age_bins)\n\n# group and count all entries in the same bin\nage_bins_df = census_income.groupby(by=[\"age_bins\"])[\"age_bins\"].count()\n\nax2.bar(age_bins_df.index, age_bins_df, color='grey')\nax2.set_ylabel(\"Counts\")\nax2.set_xlabel(\"Age\")\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import feature_column\nfrom tensorflow.keras import layers\n\n# load dataset - census income\ncensus_income = pd.read_csv(r'../input/income/train.csv')\ndata = census_income.to_dict('list')\n\n# A utility method to show the transformation from feature column\ndef demo(feature_column):\n    feature_layer = layers.DenseFeatures(feature_column)\n    return feature_layer(data).numpy()\n\nage = feature_column.numeric_column(\"age\")\nage_buckets = feature_column.bucketized_column(age, boundaries=[30,50])\nbuckets = demo(age_buckets)\n\n# add buckets to the data set\nbuckets_tensorflow = pd.DataFrame(buckets)\n\n# define boundaries for buckets\nboundary1 = 30\nboundary2 = 50\n\n# define column names for buckets\nbucket1=f\"age<{boundary1}\"\nbucket2=f\"{boundary1}<age<{boundary2}\"\nbucket3=f\"age>{boundary2}\"\n\nbuckets_tensorflow_renamed = buckets_tensorflow.rename(columns = {0:bucket1,\n                                                                    1:bucket2,\n                                                                    2:bucket3})\n\nbuckets_tensorflow_renamed.assign(age=census_income[\"age\"]).head(7)\n```", "```py\nfrom sklearn.preprocessing import KBinsDiscretizer\n\n# define bucketizer\nest = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\nest.fit(census_income[[\"age\"]])\n\n# transform data\nbuckets = est.transform(census_income[[\"age\"]])\n\n# add buckets column to data frame\ncensus_income_bucketized = census_income.assign(buckets=buckets)[[\"age\", \"buckets\"]]\ncensus_income_bucketized\n```", "```py\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport seaborn as sns\n\ndef plot_transformer(chosen_dataset, chosen_transformation, chosen_feature = None, box_cox_lambda = 0):\n    plt.rcParams['font.size'] = '16'\n    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n\n    ##################################################################################################\n    # choose dataset\n    ##################################################################################################\n    if chosen_dataset == \"Online News Popularity\":\n        df = pd.read_csv(\"../input/uci-online-news-popularity-data-set/OnlineNewsPopularity.csv\")\n        X_feature = \" n_tokens_content\"\n    elif chosen_dataset == \"World Population\":\n        df = pd.read_csv(\"../input/world-population-dataset/WPP2022_TotalPopulationBySex.csv\")\n        df = df[df[\"Time\"]==2020]\n        df[\"Area\"] = df[\"PopTotal\"] / df[\"PopDensity\"]\n        X_feature = \"Area\"\n    elif chosen_dataset == \"Housing Data\":\n        df = pd.read_csv(\"../input/housing-data-set/HousingData.csv\")\n        X_feature = \"AGE\"\n\n    # in case you want to plot the histogram for another feature\n    if chosen_feature != None:\n        X_feature = chosen_feature\n\n    ##################################################################################################\n    # choose type of transformation\n    ##################################################################################################\n    #chosen_transformation = \"box-cox\" #\"log\", \"box-cox\"\n\n    if chosen_transformation == \"log\":\n        def transform_feature(df, X_feature):\n            # We add 1 to number_of_words to make sure we don't have a null value in the column to be transformed (0-> -inf) \n            return (np.log10(1+ df[[X_feature]]))\n\n    elif chosen_transformation == \"box-cox\":\n        def transform_feature(df, X_feature):\n            return stats.boxcox(df[[X_feature]]+1, lmbda=box_cox_lambda)\n            #return stats.boxcox(df[X_feature]+1)\n\n    ##################################################################################################\n    # plot histogram to chosen dataset and X_feature\n    ##################################################################################################\n    # figure settings\n    fig, (ax1, ax2) = plt.subplots(2)\n    fig.set_size_inches(18.5, 10.5)\n\n    ax1.set_title(chosen_dataset)\n    ax1.hist(df[[X_feature]], 100, facecolor='black', ec=\"white\")\n    ax1.set_ylabel(f\"Count {X_feature}\")\n    ax1.set_xlabel(f\"{X_feature}\")\n\n    ax2.hist(transform_feature(df, X_feature), 100, facecolor='black', ec=\"white\")\n    ax2.set_ylabel(f\"Count {X_feature}\")\n    ax2.set_xlabel(f\"{chosen_transformation} transformed {X_feature}\")\n\n    fig.show()\n```", "```py\nplot_transformer(chosen_dataset = \"World Population\", chosen_transformation = \"log\")\n```", "```py\nplot_transformer(chosen_dataset = \"Online News Popularity\", chosen_transformation = \"log\")\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom scipy import stats\nimport plotly.express as px\nimport seaborn as sns\n\ndef plot_cross_val_score_comparison(chosen_dataset):\n    scores_raw = []\n    scores_transformed = []\n    degrees = []\n\n    if chosen_dataset == \"Online News Popularity\":\n        df = pd.read_csv(\"../input/uci-online-news-popularity-data-set/OnlineNewsPopularity.csv\")\n        X = df[[\" n_tokens_content\"]]\n        y = df[\" shares\"]\n    elif chosen_dataset == \"World Population\":\n        df = pd.read_csv(\"../input/world-population-dataset/WPP2022_TotalPopulationBySex.csv\")\n        df = df[df[\"Time\"]==2020]\n        df[\"Area\"] = df[\"PopTotal\"] / df[\"PopDensity\"]\n        X = df[[\"Area\"]]\n        y = df[\"PopTotal\"]\n\n    for i in range(1,10):\n        degree = i\n        polynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\n\n        linear_regression = LinearRegression()\n        pipeline = Pipeline(\n            [\n                (\"polynomial_features\", polynomial_features),\n                (\"linear_regression\", linear_regression),\n            ]\n        )\n\n        # Evaluate the models using crossvalidation\n        scores = cross_val_score(\n            pipeline, X, y, scoring=\"neg_mean_absolute_error\", cv=5\n        )\n\n        scores_raw.append(scores.mean())\n        degrees.append(i)\n\n        #########################################################################\n        # Fit model with transformed data\n        #########################################################################\n        def transform_feature(X):\n            # We add 1 to number_of_words to make sure we don't have a null value in the column to be transformed (0-> -inf) \n            #return (np.log10(1+ X))\n            return stats.boxcox(X+1, lmbda=0)\n\n        X_trans = transform_feature(X)\n\n        pipeline.fit(X_trans, y)\n\n        # Evaluate the models using crossvalidation\n        scores = cross_val_score(\n            pipeline, X_trans, y, scoring=\"neg_mean_absolute_error\", cv=5\n        )\n\n        scores_transformed.append(scores.mean())\n\n    plot_df = pd.DataFrame(degrees, columns=[\"degrees\"])\n    plot_df = plot_df.assign(scores_raw = np.abs(scores_raw))\n    plot_df = plot_df.assign(scores_transformed = np.abs(scores_transformed))\n\n    fig = go.Figure()\n    fig.add_scatter(x=plot_df[\"degrees\"], y=plot_df[\"scores_transformed\"], name=\"Scores Transformed\", line=dict(color=\"#0000ff\"))\n\n    # Only thing I figured is - I could do this \n    #fig.add_scatter(x=plot_df['degrees'], y=plot_df['scores_transformed'], title='Scores Raw')  \n    fig.add_scatter(x=plot_df['degrees'], y=plot_df['scores_raw'], name='Scores Raw')\n\n    # write scores for raw and transformed data in one data frame and find degree that shows the mininmal error score\n    scores_df = pd.DataFrame(np.array([degrees,scores_raw, scores_transformed]).transpose(), columns=[\"degrees\", \"scores_raw\", \"scores_transformed\"]).abs()\n    scores_df_merged = scores_df[[\"degrees\",\"scores_raw\"]].rename(columns={\"scores_raw\":\"scores\"}).append(scores_df[[\"degrees\", \"scores_transformed\"]].rename(columns={\"scores_transformed\":\"scores\"}))\n    degree_best_performance = scores_df_merged[scores_df_merged[\"scores\"]==scores_df_merged[\"scores\"].min()][\"degrees\"]\n\n    # plot a vertical line\n    fig.add_vline(x=int(degree_best_performance), line_width=3, line_dash=\"dash\", line_color=\"red\", name=\"Best Performance\")\n\n    # update plot layout\n    fig.update_layout(\n        font=dict(\n            family=\"Arial\",\n            size=18,  # Set the font size here\n            color=\"Black\"\n        ),\n        xaxis_title=\"Degree\",\n        yaxis_title=\"Mean Absolute Error\",\n        showlegend=True,\n        width=1200,\n        height=400,\n    )\n\n    fig['data'][0]['line']['color']=\"grey\"\n    fig['data'][1]['line']['color']=\"black\"\n\n    fig.show()\n    return degree_best_performance\n```", "```py\ndegree_best_performance_online_news = plot_cross_val_score_comparison(chosen_dataset=\"Online News Popularity\")\n```", "```py\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nimport numpy as np\n\ndef plot_polynomial_regression_model(chosen_dataset, chosen_transformation, degree_best_performance):\n    # fig settings\n    plt.rcParams.update({'font.size': 16})\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n\n    if chosen_dataset == \"Online News Popularity\":\n        df = pd.read_csv(\"../input/uci-online-news-popularity-data-set/OnlineNewsPopularity.csv\")\n        y_column = \" shares\"\n        X_column = \" n_tokens_content\"\n        X = df[[X_column]]\n        y = df[y_column]\n    elif chosen_dataset == \"World Population\":\n        df = pd.read_csv(\"../input/world-population-dataset/WPP2022_TotalPopulationBySex.csv\")\n        df = df[df[\"Time\"]==2020]\n        df[\"Area\"] = df[\"PopTotal\"] / df[\"PopDensity\"]\n        y_column = \"PopTotal\"\n        X_column = \"Area\"\n        X = df[[X_column]]\n        y = df[y_column]\n\n    #########################################################################\n    # Define model\n    #########################################################################\n    # degree_best_performance was calculated in the cell above\n    degree = int(degree_best_performance)\n    polynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\n\n    linear_regression = LinearRegression()\n    pipeline = Pipeline(\n        [\n            (\"polynomial_features\", polynomial_features),\n            (\"linear_regression\", linear_regression),\n        ]\n    )\n\n    #########################################################################\n    # Fit model\n    #########################################################################\n    pipeline.fit(X, y)\n\n    ######################################################################################\n    # Fit model and plot raw features\n    ######################################################################################\n    reg = pipeline.fit(X, y)\n    X_pred = np.linspace(min(X.iloc[:,0]), max(X.iloc[:,0]),1000).reshape(-1,1)\n    X_pred = pd.DataFrame(X_pred)\n    X_pred.columns = [X.columns[0]]\n    y_pred_1 = reg.predict(X_pred)\n\n    # plot model and transformed data    \n    ax[0].scatter(X, y, color='#f3d23aff')\n    ax[0].plot(X_pred, y_pred_1, color='black')\n    ax[0].set_xlabel(f\"{X_column}\")\n    ax[0].set_ylabel(f\"{y_column}\")\n    ax[0].set_title(f\"Raw features / Poly. Regression (degree={degree})\", pad=20)\n\n    #########################################################################\n    # Fit model with transformed data\n    #########################################################################\n    def transform_feature(X, chosen_transformation):\n        # We add 1 to number_of_words to make sure we don't have a null value in the column to be transformed (0-> -inf) \n        if chosen_transformation == \"log\":\n            return (np.log10(1+ X))\n        if chosen_transformation == \"box-cox\":\n            return stats.boxcox(X+1, lmbda=0)\n\n    X_trans = transform_feature(X, chosen_transformation)\n\n    # fit model with transformed data\n    reg = pipeline.fit(X_trans, y)\n\n    # define X_pred\n    X_pred = np.linspace(min(X_trans.iloc[:,0]), max(X_trans.iloc[:,0]),1000).reshape(-1,1)\n    X_pred = pd.DataFrame(X_pred)\n    X_pred.columns = [X.columns[0]]\n\n    # predict\n    y_pred_2 = reg.predict(X_pred)\n\n    # plot model and transformed data    \n    ax[1].scatter(X_trans, y, color='#f3d23aff')\n    ax[1].plot(X_pred, y_pred_2, color='black')\n    ax[1].set_xlabel(f\"{chosen_transformation} Transformed {X_column}\")\n    ax[1].set_ylabel(f\"{y_column}\")\n    # calc cross val score and add to title\n    ax[1].set_title(f\"Transformed features  / Poly. Regression (degree={degree})\", pad=20)\n\n    fig.suptitle(chosen_dataset)\n    fig.tight_layout()\n```", "```py\nplot_polynomial_regression_model(chosen_dataset = \"Online News Popularity\", chosen_transformation = \"log\", degree_best_performance=degree_best_performance_online_news)\n```", "```py\ndegree_best_performance_world_pop = plot_cross_val_score_comparison(chosen_dataset=\"World Population\")\n```", "```py\nimport seaborn as sns\n\nplot_transformer(chosen_dataset = \"Housing Data\", chosen_transformation = \"box-cox\", chosen_feature = None, box_cox_lambda = 2.5)\n```", "```py\n# data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\nplt.rcParams['font.size'] = '16'\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n\n# load data set\ncensus_income = pd.read_csv(r'../input/income/train.csv')\n\nX = census_income[[\"age\"]]\n\n# fit scaler and transform data\nX_norm = MinMaxScaler().fit_transform(X)\nX_scaled = StandardScaler().fit_transform(X)\n\n# plots\nfig, (ax1, ax2, ax3) = plt.subplots(3)\nfig.suptitle('Normalizing')\nfig.set_size_inches(18.5, 10.5)\n\n# subplot 1 - raw data\nax1.hist(X, 25, facecolor='black', ec=\"white\")\nax1.set_xlabel(\"Age\")\nax1.set_ylabel(\"Frequency\")\n\n# subplot 2 - normalizer\nax2.hist(X_norm, 25, facecolor='black', ec=\"white\")\nax2.set_xlabel(\"Normalized Age\")\nax2.set_ylabel(\"Frequency\")\n\n# subplot 3 - standard scaler\nax3.hist(X_scaled, 25, facecolor='black', ec=\"white\")\nax3.set_xlabel(\"Normalized Age\")\nax3.set_ylabel(\"Frequency\")\n\nfig.tight_layout()\n```", "```py\nimport numpy as np\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Raw input features\nX = np.arange(6).reshape(3, 2)\nprint(\"Raw input matrix:\")\ndisplay(X)\n\n# Crossed features\npoly = PolynomialFeatures(2)\nprint(\"Transformed feature matrix:\")\npoly.fit_transform(X)\n```", "```py\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nplt.rcParams['font.size'] = '16'\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n\n# load data set: Boston Housing\nboston_housing_df = pd.read_csv(\"../input/housing-data-set/HousingData.csv\")\nboston_housing_df = boston_housing_df.dropna()\nboston_housing_df = boston_housing_df.sort_values(by=[\"LSTAT\"])\n\n# define x and target variable y\nX = boston_housing_df[[\"LSTAT\"]]\ny = boston_housing_df[\"MEDV\"]\n\n# fit model and create predictions\ndegree = 5\npolynomial_features = PolynomialFeatures(degree=degree)\nlinear_regression = LinearRegression()\npipeline = Pipeline(\n    [\n        (\"polynomial_features\", polynomial_features),\n        (\"linear_regression\", linear_regression),\n    ]\n)\npipeline.fit(X, y)\n\ny_pred = pipeline.predict(X)\n\n# train linear model\nregr = LinearRegression()\nregr.fit(X,y)\n\n# figure settings\nfig, (ax1) = plt.subplots(1)\nfig.set_size_inches(18.5, 6)\n\nax1.set_title(\"Boston Housing: Median value of owner-occupied homes\")\nax1.scatter(X, y, c=\"black\")\nax1.plot(X, y_pred, c=\"red\", linewidth=4, label=f\"Polynomial Model (degree={degree})\")\nax1.set_ylabel(f\"MEDV\")\nax1.set_xlabel(f\"LSTAT\")\nax1.legend()\n\nfig.show()\n```", "```py\nfrom sklearn.datasets import make_circles\nfrom sklearn import preprocessing\nimport plotly_express as px\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\nplt.rcParams['font.size'] = '30'\n\n# generate a data set\nX, y = make_circles(n_samples=1_000, factor=0.3, noise=0.05, random_state=0)\nX = preprocessing.scale(X)\n\nX=X[500:]\ny=y[500:]\n\n# define target value, here: binary classification, class 1 or class 2\ny=np.where(y==0,\"class 1\",\"class 2\")\n\n# define x1 and x2 of a 2-dimensional data set\nx1 = X[:,0]\nx2 = X[:,1]\n\nimport plotly_express as px\n# define the kernel function\nkernel = x1*x2 + x1**2 + x2**2\n\ncircle_df = pd.DataFrame(X).rename(columns={0:\"x1\", 1:\"x2\"})\ncircle_df = circle_df.assign(y=y)\n\ncolor_discrete_map = {circle_df.y.unique()[0]: \"black\", circle_df.y.unique()[1]: \"#f3d23a\"}\npx.scatter(circle_df, x=\"x1\", y=\"x2\", color=\"y\", color_discrete_map = color_discrete_map, width=1000, height=800)\n\n# plot the data set together with the kernel value in a 3-dimensional space\ncolor_discrete_map = {circle_df.y.unique()[0]: \"black\", circle_df.y.unique()[1]: \"grey\"}\nfig = px.scatter(circle_df, x=\"x1\", y=\"x2\", color=\"y\", color_discrete_map = color_discrete_map, width=1000, height=600)\nfig.update_layout(\n    font=dict(\n        family=\"Arial\",\n        size=24,  # Set the font size here\n        color=\"Black\"\n    ),\n    showlegend=True,\n    width=1200,\n    height=800,\n)\n```", "```py\nimport plotly_express as px\n\n# define the kernel function\nkernel = x1*x2 + x1**2 + x2**2\n\nkernel_df = pd.DataFrame(X).rename(columns={0:\"x1\", 1:\"x2\"})\nkernel_df = kernel_df.assign(kernel=kernel)\nkernel_df = kernel_df.assign(y=y)\n\n# plot the data set together with the kernel value in a 3-dimensional space\ncolor_discrete_map = {kernel_df.y.unique()[0]: \"black\", kernel_df.y.unique()[1]: \"grey\"}  \npx.scatter_3d(kernel_df, x=\"x1\", y=\"x2\", z=\"kernel\", color=\"y\", width=1000, height=600)\n```", "```py\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport math\n\nimport pandas as pd\n\n# Load the Iris dataset\niris_data = pd.read_csv(r'../input/iris-data/Iris.csv')\niris_data.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n\nsns.set_style(\"whitegrid\")\ncolors = [\"black\", \"#f3d23aff\", \"grey\"]\nplt.figure(figsize=(10, 8))\n\nwith sns.axes_style(\"darkgrid\"):\n    for cnt, column in enumerate(iris_data.columns[1:5]):\n        plt.subplot(2, 2, cnt+1)\n        for species_cnt, species in enumerate(iris_data.Species.unique()):\n            plt.hist(iris_data[iris_data.Species == species][column], label=species, color=colors[species_cnt])\n\n        plt.xlabel(column)\n    plt.legend(loc='upper right', fancybox=True, fontsize=8)\n\n    plt.tight_layout()\n    plt.show()\n```", "```py\nimport plotly_express as px\n\ncolor_discrete_map = {iris_data.Species.unique()[0]: \"black\", iris_data.Species.unique()[1]: \"#f3d23a\", iris_data.Species.unique()[2]:\"grey\"}\n\npx.scatter_3d(iris_data, x=\"PetalLengthCm\", y=\"PetalWidthCm\", z=\"SepalLengthCm\", size=\"SepalWidthCm\", color=\"Species\", color_discrete_map = color_discrete_map, width=1000, height=800)\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport matplotlib\nimport plotly.graph_objects as go\n\n# Load the Iris dataset\niris_data = pd.read_csv(r'../input/iris-data/Iris.csv')\niris_data.dropna(how=\"all\", inplace=True) # drops the empty lines\n\n# define X\nX = iris_data[[\"PetalLengthCm\", \"PetalWidthCm\", \"SepalLengthCm\", \"SepalWidthCm\"]]\n\n# fit PCA and transform X\npca = PCA(n_components=2).fit(X)\nX_transform = pca.transform(X)\niris_data_trans = pd.DataFrame(X_transform).assign(Species = iris_data.Species).rename(columns={0:\"PCA1\", 1:\"PCA2\"})\n\n# plot 2d plot\ncolor_discrete_map = {iris_data.Species.unique()[0]: \"black\", iris_data.Species.unique()[1]: \"#f3d23a\", iris_data.Species.unique()[2]:\"grey\"}\nfig = px.scatter(iris_data_trans, x=\"PCA1\", y=\"PCA2\", color=\"Species\", color_discrete_map = color_discrete_map)\n\nfig.update_layout(\n    font=dict(\n        family=\"Arial\",\n        size=18,  # Set the font size here\n        color=\"Black\"\n    ),\n    showlegend=True,\n    width=1200,\n    height=800,\n)\n```"]