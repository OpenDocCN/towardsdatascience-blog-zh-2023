- en: Can Synthetic Data Boost Machine Learning Performance?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda](https://towardsdatascience.com/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Investigating the Capability of Synthetic Data to Enhance Model Performance
    on Imbalanced Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)
    ·7 min read·Jul 5, 2023
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/71bd354c415afacf5396ba2c0956b4fc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Generated with Midjourney'
  prefs: []
  type: TYPE_NORMAL
- en: Background — Imbalanced Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imbalanced classification problems frequently occur in commercial machine learning
    use cases. You may encounter them in churn prediction, fraud detection, medical
    diagnosis, or spam detection. In all these scenarios, what we aim to detect belongs
    to the minority class, which can be highly underrepresented in our data. There
    are several approaches proposed for enhancing the performance of models on imbalanced
    datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Undersampling**: Achieve a more balanced training dataset by randomly undersampling
    the majority class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Oversampling**: Obtain a balanced training dataset by randomly oversampling
    the minority class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weighted Losses**: Assign weights to the loss function in relation to the
    minority class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synthetic Data**: Use generative AI to create high-fidelity synthetic data
    samples of the minority class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this article I demonstrate how training a model on synthetic data surpasses
    the other approaches in enhancing the performance of the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: The Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data is sourced from [Kaggle](https://www.kaggle.com/), consisting of 284,807
    credit card transactions, 492 (0.172%) of which are labelled as fraudulent. The
    data is available for both commercial and non-commercial usage under the Open
    [Data Commons license](https://opendatacommons.org/licenses/dbcl/1-0/).
  prefs: []
  type: TYPE_NORMAL
- en: For interested readers, Kaggle offers more detailed information and basic [descriptive
    statistics](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) about the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'From this Kaggle dataset, I create two subsets: a training set and a holdout
    set. The training set comprises 80% of the total data, along with synthetically
    generated samples when exploring that approach. The holdout set constitutes 20%
    of the original data, excluding any synthetic samples.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd244d3062156d0eec2447cd9c9fc53b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Data splitting process'
  prefs: []
  type: TYPE_NORMAL
- en: The Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I use [Ludwig](https://ludwig.ai/latest/), an open-source, declarative framework
    for building deep learning models due to it’s ease of implementation. Models are
    easily built and trained by declaring them in a yaml file and running a training
    job through Ludwig’s python API. I have written an [article](https://medium.com/towards-data-science/ludwig-a-friendlier-deep-learning-framework-946ee3d3b24)
    previously that details Ludwig for those who are interested.
  prefs: []
  type: TYPE_NORMAL
- en: For each approach, I use the same baseline model, only adjusting specific parameters
    as necessary. For instance, Ludwig allows for weight and sampling adjustments
    natively — These are simply adjusted in the yaml file. I have provided links to
    the model configuration yaml files for each approach for your exploration.
  prefs: []
  type: TYPE_NORMAL
- en: Baseline Model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/baseline_model.yaml)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weighted losses model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_weighted_loss.yaml)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Undersampling model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_undersample.yaml)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oversampling model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_oversample.yaml)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic data — Utilises the same model as the baseline as the classes are
    balanced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating Synthetic Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I utilise Synthetic Data Vault (SDV), an open-source library for generating
    synthetic data samples. With SDV, I generate an additional 284k synthetic fraud
    samples, thereby achieving equal representation of both classes in the training
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The synthetic samples are generated with variational autoencoders adapted for
    tabular data (TVAE). You can find more details on the theory behind TVAEs in this
    [paper](https://arxiv.org/pdf/1907.00503.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: '[SDV](https://docs.sdv.dev/sdv/) offers diagnostic statistics, giving an indication
    of fit quality. You can manually explore the fit quality by comparing variable
    distributions in the real data versus the generated data as shown in the examples
    below.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/54121d9ed8930d1145cb1c2b16a0531e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Real vs synthetic distribution for variable v1'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/046f7c574ca531d64ea1b8e845ce76e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Real vs synthetic distribution for variable v10'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e0aa806a65638bbdd960eba187b4db50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Real vs. synthetic distribution for variable amount'
  prefs: []
  type: TYPE_NORMAL
- en: Assessing Performance with Precision Recall Charts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We assess the performance of each model by plotting the precision versus recall
    curves of the models against the holdout dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Precision-Recall Curve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Precision-Recall curve, a plot of Precision (on the y-axis) against Recall
    (on the x-axis) for varying thresholds, is akin to the [ROC curve](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc#:~:text=An%20ROC%20curve%20(receiver%20operating,False%20Positive%20Rate).
    It serves as a robust diagnostic tool for evaluating model performance in scenarios
    of significant class imbalance, such as our credit card fraud detection use case,
    a prime example.
  prefs: []
  type: TYPE_NORMAL
- en: The top-right corner of the plot represents the “ideal” point — a false positive
    rate of zero and a true positive rate of one. A skilled model should reach this
    point or come close to it, implying a larger area under the curve (AUC-PR) can
    suggest a superior model.
  prefs: []
  type: TYPE_NORMAL
- en: No Skill Predictor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A “no skill” predictor is a naïve model that makes predictions randomly. For
    imbalanced datasets, the no skill line is a horizontal line at a height equivalent
    to the positive class proportion. This is because if the model randomly predicts
    the positive class, precision would be equivalent to the positive instances proportion
    in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Model Performance — Baseline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The baseline model is the deep neural network with no sample adjustments, loss
    function adjustments, or augmented training data. Each approach is compared to
    the baseline performance, which serves as a performance bench mark.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/389d22765e6bb2466c6609912444ae32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Precision-recall curve for baseline model'
  prefs: []
  type: TYPE_NORMAL
- en: Model Performance — Weighted Losses Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Weighted loss adjusts the loss function based on the ratio of fraudulent to
    non-fraudulent transactions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ad6118e9e5c3b6e863d4a4710ee78b60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Precision-recall curve for loss weighted approach'
  prefs: []
  type: TYPE_NORMAL
- en: Model Performance — Oversampling Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Oversampling randomly oversamples the fraudulent transactions until there is
    equal representation across the classes in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc225c1fbad884c19136df4a0516504d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Precision-recall curve for oversampling approach'
  prefs: []
  type: TYPE_NORMAL
- en: Model Performance — Undersampling Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Undersampling randomly undersamples the non-fraudulent transactions until there
    is equal representation across classes in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf43d3a05070ce9ad42512b9c49c2969.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Precision-recall curve for undersampling approach'
  prefs: []
  type: TYPE_NORMAL
- en: Model Performance — Synthetic Data Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Leverage the TVAEs to produce 284k synthetic, fraudulent samples to gain an
    equal representation across classes in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b46183b2f1de8ae3ae1ba925d718749.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Precision-recall curve for synthetic data approach'
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping Holdout Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To obtain a robust view of performance on the holdout set, I created fifty bootstrapped
    holdout sets from the original. Running the models associated with each approach
    across all sets provides a distribution of performance. We can then determine
    whether each approach is statistically significantly different from the baseline
    using the Kolmogorov-Smirnov test.
  prefs: []
  type: TYPE_NORMAL
- en: '**Weighted**: The weighted approach marginally underperformed across recall
    and AUC relative to the baseline. In addition to this, the variance across each
    performance metric appears quite high relative to the other approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cbf98db34757c7b0777fb03de7f26d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Weighted Loss, KS stats — AUC 0.420 p-value < 0.000, precision 0.260
    p-value 0.068, Recall 0.520 p-value < 0.000'
  prefs: []
  type: TYPE_NORMAL
- en: '**Oversampling**: The oversampling approach improves model recall relative
    to baseline, but results in a drastic deterioration of the precision.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da5bc03287b1607c6f2a95ae98c8b772.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Oversampling, KS stats — AUC 0.160 p-value 0.549, precision 1.0 p-value
    < 0.000, Recall 0.9 p-value < 0.000'
  prefs: []
  type: TYPE_NORMAL
- en: '**Undersampling**: The approach performs worse than baseline across all metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9d0481f0207a1e82b2260a9f6cd37405.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Oversampling, KS stats — AUC 0.880 p-value < 0.000, precision 0.6
    p-value < 0.000, Recall 1.0 p-value < 0.000'
  prefs: []
  type: TYPE_NORMAL
- en: '**Synthetic**: The synthetic method uplifts model recall, albeit at the cost
    of precision. While the impact on precision remains substantial, the synthetic
    approach provides a more resilient alternative for enhancing model recall with
    less of a detriment to precision when compared to the oversampling approach. The
    robustness of the synthetic approach is further evidenced by the uplift in AUC-PR.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aa624f4f7cd1058e4bd764e3c2e7b950.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Synthetic, KS stats — AUC 0.620, Precision 0.560, Recall 0.360 all
    p-values ≤ 0.003'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve noted that the synthetic data approach can boost model recall relative
    to the baseline at the expense of precision. Oversampling accomplishes a similar
    result, but model precision suffers drastically in comparison.
  prefs: []
  type: TYPE_NORMAL
- en: In our specific context of credit card fraud detection, false positives are
    not as costly as false negatives. Therefore, we can afford to compromise on model
    precision if it results in a significant boost in recall. Enriching our training
    data with synthetic instances seems to be an effective strategy to enhance recall
    while mitigating the detrimental effects on precision. This enhancement could
    notably affect profitability, especially when scaling the model to handle millions
    of transactions. Ultimately, attributing a exact cost to false positives and negatives
    will provide us with a clearer understanding of the most commercially viable approach,
    a topic beyond the scope of this article.
  prefs: []
  type: TYPE_NORMAL
- en: It would be fascinating to examine the performance across varying sample sizes
    of synthetic data, perhaps in conjunction with weighted losses. Similarly, experimenting
    with diverse oversampling ratios could potentially yield comparable effects to
    what we have observed with the synthetic approach.
  prefs: []
  type: TYPE_NORMAL
- en: The notebook for this project is available in my [GitHub repo](https://github.com/john-adeojo/synthetic_data_credit_cards/blob/main/notebook/Synthetic%20Data%20Experiment.ipynb)
  prefs: []
  type: TYPE_NORMAL
- en: '*Follow me on* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Subscribe to medium to get more insights from me:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://johnadeojo.medium.com/membership?source=post_page-----6b4041e75dda--------------------------------)
    [## Join Medium with my referral link — John Adeojo'
  prefs: []
  type: TYPE_NORMAL
- en: I share data science projects, experiences, and expertise to assist you on your
    journey You can sign up to medium via…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----6b4041e75dda--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '*Should you be interested in integrating AI or data science into your business
    operations, we invite you to schedule a complimentary initial consultation with
    us:*'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.data-centric-solutions.com/book-online?source=post_page-----6b4041e75dda--------------------------------)
    [## Book Online | Data-Centric Solutions'
  prefs: []
  type: TYPE_NORMAL
- en: Discover our expertise in helping businesses achieve ambitious goals with a
    free consultation. Our data scientists and…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----6b4041e75dda--------------------------------)
  prefs: []
  type: TYPE_NORMAL
